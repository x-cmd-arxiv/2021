"2102.01574","Thomas Plan\`es","Thomas Plan\`es, Scott Delbecq, Val\'erie Pommier-Budinger and
  Emmanuel B\'enard","Simulation and evaluation of sustainable climate trajectories for
  aviation","41 pages, 14 figures, 4 tables, Research paper",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2019, aviation was responsible for 2.6% of the world CO2 emissions as well
as additional climate impacts such as contrails. Like all industrial sectors,
the aviation sector must implement measures to reduce its climate impact. This
paper focuses on the simulation and the evaluation of climatic scenarios for
the aviation industry. For this purpose, a specific tool (CAST for ""Climate and
Aviation - Sustainable Trajectories"") has been developed. This tool follows a
methodology adapted to aviation using the concept of carbon budget and models
of the main levers of action such as the level of air traffic, reduction of
aircraft energy consumption or energy decarbonisation. These models are based
on trend projections from historical data or assumptions from the literature.
Several scenario analyses are performed in this paper using CAST and allow
several conclusions to be drawn. For instance, the modelling of the scenarios
based on the ATAG (Air Transport Action Group) commitments shows that aviation
would consume between 2.9% and 3.5% of the world carbon budget to limit global
warming to 2{\deg}C and between 6.5% and 8.1% for 1.5{\deg}C. Also, some
illustrative scenarios are proposed. By allocating 2.6% of the carbon budget to
aviation, it is shown that air transport is compatible with a +2{\deg}C
trajectory when the annual growth rate of air traffic varies between -1.8% and
+2.6%, depending on the considered technological improvements. However, in the
case of a +1.5{\deg}C trajectory, the growth rate would have to be reduced
drastically. Finally, analyses including non-CO2 effects compel to emphasize
the implementation of specific strategies for mitigating contrails.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:00:12 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 15:20:03 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 13:32:03 GMT""}]","2021-05-21"
"2102.01575","Olgur Celikbas","Olgur Celikbas, Uyen Le, Hiroki Matsui","On the depth and reflexivity of tensor products","11 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the depth of tensor products of homologically finite
complexes over commutative Noetherian local rings. As an application of our
main result, we determine new conditions under which nonzero tensor products of
finitely generated modules over hypersurface rings can be reflexive only if
both of their factors are reflexive. A result of Asgharzadeh shows that nonzero
symbolic powers of prime ideals in a local ring cannot have finite projective
dimension, unless the ring in question is a domain. We make use of this fact in
the appendix and consider the reflexivity of tensor products of prime ideals
over hypersurface rings.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:06:23 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 19:55:16 GMT""}]","2021-02-05"
"2102.01576","Hjalte Frellesvig Dr.","Hjalte Frellesvig and Luca Mattiazzi","On the Application of Intersection Theory to Feynman Integrals: The
  Univariate Case","Contribution to the proceedings of MathemAmplitudes 2019. 10 pages
  and three figures",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  This document is a contribution to the proceedings of the MathemAmplitudes
2019 conference held in December 2019 in Padova, Italy. A key step in modern
high energy physics scattering amplitudes computation is to express the latter
in terms of a minimal set of Feynman integrals using linear relations. In this
work we present an innovative approach based on intersection theory, in order
to achieve this decomposition. This allows for the direct computation of the
reduction, projecting integrals appearing in the scattering amplitudes onto an
integral basis in the same fashion as vectors may be projected onto a vector
basis. Specifically, we will derive and discuss few identities between
maximally cut Feynman integrals, showing their direct decomposition. This
contribution will focus on the univariate part of the story, with the
multivariate generalisation being discussed in a different contribution by
Gasparotto and Mandal.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:06:52 GMT""}]","2021-02-03"
"2102.01577","Alexis Bellot","Alexis Bellot, Mihaela van der Schaar","Policy Analysis using Synthetic Controls in Continuous-Time",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Counterfactual estimation using synthetic controls is one of the most
successful recent methodological developments in causal inference. Despite its
popularity, the current description only considers time series aligned across
units and synthetic controls expressed as linear combinations of observed
control units. We propose a continuous-time alternative that models the latent
counterfactual path explicitly using the formalism of controlled differential
equations. This model is directly applicable to the general setting of
irregularly-aligned multivariate time series and may be optimized in rich
function spaces -- thereby improving on some limitations of existing
approaches.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:07:39 GMT""}]","2021-02-03"
"2102.01578","Marco Gaido","Marco Gaido, Mauro Cettolo, Matteo Negri, Marco Turchi","CTC-based Compression for Direct Speech Translation","Accepted at EACL2021","Proceedings of the 16th Conference of the European Chapter of the
  Association for Computational Linguistics: Main Volume (2021), 690-696",,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Previous studies demonstrated that a dynamic phone-informed compression of
the input audio is beneficial for speech translation (ST). However, they
required a dedicated model for phone recognition and did not test this solution
for direct ST, in which a single model translates the input audio into the
target language without intermediate representations. In this work, we propose
the first method able to perform a dynamic compression of the input indirect ST
models. In particular, we exploit the Connectionist Temporal Classification
(CTC) to compress the input sequence according to its phonetic characteristics.
Our experiments demonstrate that our solution brings a 1.3-1.5 BLEU improvement
over a strong baseline on two language pairs (English-Italian and
English-German), contextually reducing the memory footprint by more than 10%.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:09:19 GMT""}]","2021-10-15"
"2102.01579","Xiangyu Xu","Xiangyu Xu, Yongrui Ma, Wenxiu Sun, Ming-Hsuan Yang","Exploiting Raw Images for Real-Scene Super-Resolution","A larger version with higher-resolution figures is available at:
  https://sites.google.com/view/xiangyuxu. arXiv admin note: text overlap with
  arXiv:1905.12156","IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2020",,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Super-resolution is a fundamental problem in computer vision which aims to
overcome the spatial limitation of camera sensors. While significant progress
has been made in single image super-resolution, most algorithms only perform
well on synthetic data, which limits their applications in real scenarios. In
this paper, we study the problem of real-scene single image super-resolution to
bridge the gap between synthetic data and real captured images. We focus on two
issues of existing super-resolution algorithms: lack of realistic training data
and insufficient utilization of visual information obtained from cameras. To
address the first issue, we propose a method to generate more realistic
training data by mimicking the imaging process of digital cameras. For the
second issue, we develop a two-branch convolutional neural network to exploit
the radiance information originally-recorded in raw images. In addition, we
propose a dense channel-attention block for better image restoration as well as
a learning-based guided filter network for effective color correction. Our
model is able to generalize to different cameras without deliberately training
on images from specific camera types. Extensive experiments demonstrate that
the proposed algorithm can recover fine details and clear structures, and
achieve high-quality results for single image super-resolution in real scenes.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:10:15 GMT""}]","2021-02-03"
"2102.01580","Daniel Z. Huang","Daniel Zhengyu Huang, Tapio Schneider, Andrew M. Stuart","Iterated Kalman Methodology For Inverse Problems","56 pages, 24 figures",,,,"math.NA cs.NA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is focused on the optimization approach to the solution of inverse
problems. We introduce a stochastic dynamical system in which the
parameter-to-data map is embedded, with the goal of employing techniques from
nonlinear Kalman filtering to estimate the parameter given the data. The
extended Kalman filter (which we refer to as ExKI in the context of inverse
problems) can be effective for some inverse problems approached this way, but
is impractical when the forward map is not readily differentiable and is given
as a black box, and also for high dimensional parameter spaces because of the
need to propagate large covariance matrices. Application of ensemble Kalman
filters, for example use of the ensemble Kalman inversion (EKI) algorithm, has
emerged as a useful tool which overcomes both of these issues: it is derivative
free and works with a low-rank covariance approximation formed from the
ensemble. In this paper, we work with the ExKI, EKI, and a variant on EKI which
we term unscented Kalman inversion (UKI).
  The paper contains two main contributions. Firstly, we identify a novel
stochastic dynamical system in which the parameter-to-data map is embedded. We
present theory in the linear case to show exponential convergence of the mean
of the filtering distribution to the solution of a regularized least squares
problem. This is in contrast to previous work in which the EKI has been
employed where the dynamical system used leads to algebraic convergence to an
unregularized problem. Secondly, we show that the application of the UKI to
this novel stochastic dynamical system yields improved inversion results, in
comparison with the application of EKI to the same novel stochastic dynamical
system.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:15:38 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 20:32:41 GMT""},{""version"":""v3"",""created"":""Tue, 6 Apr 2021 02:04:41 GMT""},{""version"":""v4"",""created"":""Sat, 15 Jan 2022 17:05:02 GMT""},{""version"":""v5"",""created"":""Thu, 28 Apr 2022 16:15:14 GMT""}]","2022-04-29"
"2102.01581","Junjun Jia","Junjun Jia, Takahiko Yanagitani","Origin of Enhanced Electromechanical Coupling in (Yb,Al)N Nitride Alloys",,"Phys. Rev. Applied 16, 044009 (2021)","10.1103/PhysRevApplied.16.044009",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our experiments demonstrate that alloying the cubic-phase YbN into the
wurtzite-phase AlN results in clear mechanical softening and enhanced
electromechanical coupling of AlN. First-principle calculations reproduce
experimental results well, and predict a maximum 270% increase in
electromechanical coupling coefficient caused by (1) an enhanced piezoelectric
response induced by the local strain of Yb ions and (2) a structural
flexibility of the (Yb,Al)N alloy. Extensive calculations suggest that the
substitutional neighbor Yb-Yb pairs in wurtzite AlN are energetically stable
along $c$ axis, and avoid forming on the basal plane of wurtzite structure due
to the repulsion between them, which explains that (Yb,Al)N films with high Yb
concentrations are difficult to fabricate in our sputtering experiments.
Moreover, the neighbor Yb-Yb pair interactions also promote structural
flexibility of (Yb,Al)N, and are considered a cause for mechanical softening of
(Yb,Al)N.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:15:56 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 09:27:51 GMT""},{""version"":""v3"",""created"":""Thu, 24 Feb 2022 04:35:08 GMT""}]","2022-02-25"
"2102.01582","Mats Richter","Mats L. Richter, Wolf Byttner, Ulf Krumnack, Ludwdig Schallner, Justin
  Shenk","Size Matters","Preprint","Artificial Neural Networks and Machine Learning ICANN 2021 133-144","10.1007/978-3-030-86340-1_11",,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Fully convolutional neural networks can process input of arbitrary size by
applying a combination of downsampling and pooling. However, we find that fully
convolutional image classifiers are not agnostic to the input size but rather
show significant differences in performance: presenting the same image at
different scales can result in different outcomes. A closer look reveals that
there is no simple relationship between input size and model performance (no
`bigger is better'), but that each each network has a preferred input size, for
which it shows best results. We investigate this phenomenon by applying
different methods, including spectral analysis of layer activations and probe
classifiers, showing that there are characteristic features depending on the
network architecture. From this we find that the size of discriminatory
features is critically influencing how the inference process is distributed
among the layers.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:17:52 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 09:00:14 GMT""}]","2021-10-13"
"2102.01583","Blake Woodworth","Blake Woodworth, Brian Bullins, Ohad Shamir, Nathan Srebro","The Min-Max Complexity of Distributed Stochastic Convex Optimization
  with Intermittent Communication","48 pages",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We resolve the min-max complexity of distributed stochastic convex
optimization (up to a log factor) in the intermittent communication setting,
where $M$ machines work in parallel over the course of $R$ rounds of
communication to optimize the objective, and during each round of
communication, each machine may sequentially compute $K$ stochastic gradient
estimates. We present a novel lower bound with a matching upper bound that
establishes an optimal algorithm.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:18:29 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 13:00:45 GMT""}]","2021-08-06"
"2102.01584","Jordan McMahon","Jordan McMahon","Boundary Idempotents and $2$-precluster-tilting categories","9 pages, comments welcome",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The homological theory of Auslander-Platzeck-Todorov on idempotent ideals
laid much of the groundwork for higher Auslander-Reiten theory, providing the
key technical lemmas for both higher Auslander correspondence as well as the
construction of higher Nakayama algebras, among other results. Given a
finite-dimensional algebra $A$ and idempotent $e$, we expand on a criterion of
Jasso-K\""ulshammer in order to determine a correspondence between the
$2$-precluster-tilting subcategories of $\mathrm{mod}(A)$ and
$\mathrm{mod}(A/\langle e\rangle)$. This is then applied in the context of
generalising dimer algebras on surfaces with boundary idempotent.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:21:10 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 16:09:14 GMT""}]","2021-02-04"
"2102.01585","Kai Cui","Kai Cui, Heinz Koeppl","Approximately Solving Mean Field Games via Entropy-Regularized Deep
  Reinforcement Learning","Accepted to the 24th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2021); v2: Fixed B.6 and some typos",,,,"cs.MA cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent mean field game (MFG) formalism facilitates otherwise intractable
computation of approximate Nash equilibria in many-agent settings. In this
paper, we consider discrete-time finite MFGs subject to finite-horizon
objectives. We show that all discrete-time finite MFGs with non-constant fixed
point operators fail to be contractive as typically assumed in existing MFG
literature, barring convergence via fixed point iteration. Instead, we
incorporate entropy-regularization and Boltzmann policies into the fixed point
iteration. As a result, we obtain provable convergence to approximate fixed
points where existing methods fail, and reach the original goal of approximate
Nash equilibria. All proposed methods are evaluated with respect to their
exploitability, on both instructive examples with tractable exact solutions and
high-dimensional problems where exact methods become intractable. In
high-dimensional scenarios, we apply established deep reinforcement learning
methods and empirically combine fictitious play with our approximations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:22:07 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jul 2022 14:01:41 GMT""}]","2022-07-11"
"2102.01586","Mohammad Hossein Jafari","Mohammad H. Jafari, Christina Luong, Michael Tsang, Ang Nan Gu, Nathan
  Van Woudenberg, Robert Rohling, Teresa Tsang, Purang Abolmaesumi","U-LanD: Uncertainty-Driven Video Landmark Detection",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper presents U-LanD, a framework for joint detection of key frames and
landmarks in videos. We tackle a specifically challenging problem, where
training labels are noisy and highly sparse. U-LanD builds upon a pivotal
observation: a deep Bayesian landmark detector solely trained on key video
frames, has significantly lower predictive uncertainty on those frames vs.
other frames in videos. We use this observation as an unsupervised signal to
automatically recognize key frames on which we detect landmarks. As a test-bed
for our framework, we use ultrasound imaging videos of the heart, where sparse
and noisy clinical labels are only available for a single frame in each video.
Using data from 4,493 patients, we demonstrate that U-LanD can exceedingly
outperform the state-of-the-art non-Bayesian counterpart by a noticeable
absolute margin of 42% in R2 score, with almost no overhead imposed on the
model size. Our approach is generic and can be potentially applied to other
challenging data with noisy and sparse training labels.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:23:54 GMT""}]","2021-02-03"
"2102.01587","Benjamin Golub","Evan Sadler and Benjamin Golub","Games on Endogenous Networks",,,,,"econ.TH cs.GT cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study network games in which players choose both the partners with whom
they associate and an action level (e.g., effort) that creates spillovers for
those partners. We introduce a framework and two solution concepts, extending
standard approaches for analyzing each choice in isolation: Nash equilibrium in
actions and pairwise stability in links. Our main results show that, under
suitable order conditions on incentives, stable networks take simple forms. The
first condition concerns whether links create positive or negative payoff
spillovers. The second concerns whether actions are strategic complements to
links, or strategic substitutes. Together, these conditions yield a taxonomy of
the relationship between network structure and economic primitives organized
around two network architectures: ordered overlapping cliques and nested split
graphs. We apply our model to understand the consequences of competition for
status, to microfound matching models that assume clique formation, and to
interpret empirical findings that highlight unintended consequences of group
design.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:27:00 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 06:01:59 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 05:58:52 GMT""},{""version"":""v4"",""created"":""Sat, 18 Sep 2021 19:32:33 GMT""},{""version"":""v5"",""created"":""Mon, 27 Sep 2021 05:46:40 GMT""},{""version"":""v6"",""created"":""Sun, 11 Sep 2022 21:07:10 GMT""},{""version"":""v7"",""created"":""Fri, 17 Feb 2023 20:16:19 GMT""}]","2023-02-21"
"2102.01588","Hong-Hao Zhang","Zhao Zhang, Chengfeng Cai, Xue-Min Jiang, Yi-Lei Tang, Zhao-Huan Yu,
  Hong-Hao Zhang","Phase transition gravitational waves from pseudo-Nambu-Goldstone dark
  matter and two Higgs doublets","35 pages, 8 figures, accepted for publication in JHEP",,"10.1007/JHEP05(2021)160",,"hep-ph astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the potential stochastic gravitational waves from first-order
electroweak phase transitions in a model with pseudo-Nambu-Goldstone dark
matter and two Higgs doublets. The dark matter candidate can naturally evade
direct detection bounds, and can achieve the observed relic abundance via the
thermal mechanism. Three scalar fields in the model obtain vacuum expectation
values, related to phase transitions at the early Universe. We search for the
parameter points that can cause first-order phase transitions, taking into
account the existed experimental constraints. The resulting gravitational wave
spectra are further evaluated. Some parameter points are found to induce strong
gravitational wave signals, which have the opportunity to be detected in future
space-based interferometer experiments LISA, Taiji, and TianQin.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:28:52 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 14:04:33 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 17:35:02 GMT""}]","2023-01-11"
"2102.01589","Julian Struck","Cl\'ement De Daniloff, Marin Tharrault, C\'edric Enesa, Christophe
  Salomon, Fr\'ed\'eric Chevy, Thomas Reimann, Julian Struck","In Situ Thermometry of Fermionic Cold-Atom Quantum Wires",,"Phys. Rev. Lett. 127, 113602 (2021)","10.1103/PhysRevLett.127.113602",,"cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study ensembles of fermionic cold-atom quantum wires with tunable
transverse mode population and single-wire resolution. From in situ density
profiles, we determine the temperature of the atomic wires in the weakly
interacting limit and reconstruct the underlying potential landscape. By
varying atom number and temperature, we control the occupation of the
transverse modes and study the 1D-3D crossover. In the 1D limit, we observe an
increase of the reduced temperature $T/T_{F}$ at nearly constant entropy per
particle $S/N k_{B}$. The ability to probe individual atomic wires in situ
paves the way to quantitatively study equilibrium and transport properties of
strongly interacting 1D Fermi gases.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:31:37 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 16:28:37 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 16:13:18 GMT""}]","2021-09-14"
"2102.01590","Michael Khayyat","Michael Khayyat, Stefano Arrigoni, and Federico Cheli","Development and Simulation-based Testing of a 5G-Connected Intersection
  AEB System",,,"10.1080/00423114.2021.1998558",,"eess.SY cs.NI cs.RO cs.SY","http://creativecommons.org/licenses/by/4.0/","  In Europe, 20% of road crashes occur at intersections. In recent years,
evolving communication technologies are making V2V and V2I faster and more
reliable; with such advancements, these crashes, as well as their economic
cost, can be partially reduced. In this work, we concentrate on straight path
intersection collisions. Connectivity-based algorithms relying on 5G technology
and smart sensors are presented and compared to a commercial radar AEB logic in
order to evaluate performances and effectiveness in collision avoidance or
mitigation. The aforementioned novel safety systems are tested in a blind
intersection and low adherence scenario. The first algorithm proposed is
obtained by incorporating connectivity information to the original control
scheme, while the second algorithm proposed is a novel control logic fully
capable of utilizing also adherence estimation provided by smart sensors. Test
results show an improvement in terms of safety for both the architecture and
high prospects for future developments.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:32:34 GMT""}]","2022-02-23"
"2102.01591","Slawomir Dinew","Slawomir Dinew and Zywomir Dinew","On a problem of CHirka","5 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observe that a slight adjustment of a method of Caffarelli, Li, and
Nirenberg yields that plurisubharmonic functions extend across subharmonic
singularities as long as the singularities form a closed set of measure zero.
This solves a problem posed by Chirka.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:33:09 GMT""}]","2021-02-03"
"2102.01592","Gennadiy Feldman","G.M. Feldman","Solution of the Kac--Bernstein functional equation on Abelian groups in
  the class of positive functions",,,,,"math.CA math.GR","http://creativecommons.org/licenses/by/4.0/","  The general form of the solutions of the Kac--Bernstein functional equation
$$ f(x+y)g(x-y)=f(x)f(y)g(x)g(-y), \ x, y\in X, $$ on an arbitrary Abelian
group $X$ in the class of positive functions is obtained. We also study the
solutions of this equation in the class of complex-valued functions that do not
vanish and satisfy the Hermitian condition.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:33:25 GMT""}]","2021-02-03"
"2102.01593","Amirhossein Malekijoo","Amirhossein Malekijoo, Mohammad Javad Fadaeieslam, Hanieh Malekijou,
  Morteza Homayounfar, Farshid Alizadeh-Shabdiz, Reza Rawassizadeh","FEDZIP: A Compression Framework for Communication-Efficient Federated
  Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning marks a turning point in the implementation of
decentralized machine learning (especially deep learning) for wireless devices
by protecting users' privacy and safeguarding raw data from third-party access.
It assigns the learning process independently to each client. First, clients
locally train a machine learning model based on local data. Next, clients
transfer local updates of model weights and biases (training data) to a server.
Then, the server aggregates updates (received from clients) to create a global
learning model. However, the continuous transfer between clients and the server
increases communication costs and is inefficient from a resource utilization
perspective due to the large number of parameters (weights and biases) used by
deep learning models. The cost of communication becomes a greater concern when
the number of contributing clients and communication rounds increases. In this
work, we propose a novel framework, FedZip, that significantly decreases the
size of updates while transferring weights from the deep learning model between
clients and their servers. FedZip implements Top-z sparsification, uses
quantization with clustering, and implements compression with three different
encoding methods. FedZip outperforms state-of-the-art compression frameworks
and reaches compression rates up to 1085x, and preserves up to 99% of bandwidth
and 99% of energy for clients during communication.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:33:44 GMT""}]","2021-02-03"
"2102.01594","Ming Li","Ming Li and Vladimir V. Skokov","First Saturation Correction in High Energy Proton-Nucleus Collisions: I.
  Time evolution of classical Yang-Mills fields beyond leading order","53 pages, 9 figures",,"10.1007/JHEP06(2021)140",,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  In high energy proton-nucleus collisions, the single- and double-inclusive
soft gluon productions at the leading order have been calculated and
phenomenologically studied in various approaches for many years. These studies
do not take into account the saturation and multiple rescatterings in the field
of the proton. The first saturation correction to these leading order results
(the terms that are enhanced by the combination $\alpha_s^2 \mu^2$, where
$\mu^2$ is the proton's color charge squared per unit transverse area) has not
been completely derived despite recent attempts using a diagrammatic approach.
This paper is the first in a series of papers towards analytically completing
the first saturation correction to physical observables in high energy
proton-nucleus collisions. Our approach is to analytically solve the classical
Yang-Mills equations in the dilute-dense regime using the Color Glass
Condensate effective theory and compute physical observables constructed from
classical gluon fields. In the current paper, the Yang-Mills equations are
solved perturbatively in the field of the dilute object (the proton).
Next-to-leading order and next-to-next-to-leading order analytic solutions are
explicitly constructed. A systematic way to obtain all higher order analytic
solutions is outlined
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:33:51 GMT""}]","2021-07-14"
"2102.01595","Boris Kopeliovich","B. Z. Kopeliovich, M. Krelina, I. K. Potashnikova","Probing the Pomeron spin structure with Coulomb-nuclear interference","18 pages, 3 figures, version published in Phys. Lett. B","Phys. Lett. B 816 (2021) 136262","10.1016/j.physletb.2021.136262",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Polarized pp elastic scattering at small angles in the Coulomb-nuclear
interference (CNI) region offers a unique opportunity to study the spin
structure of the Pomeron. Electromagnetic effects in elastic amplitude can be
equivalently treated either as Coulomb corrections to the hadronic amplitude
(Coulomb phase), or as absorption corrections to the Coulomb scattering
amplitude. We perform the first calculation of the Coulomb phase for the
spin-flip amplitude and found it significantly exceeding the widely used
non-flip Coulomb phase. The alternative description in terms of absorption
corrections, though equivalent, turned out to be a more adequate approach for
the Coulomb corrected spin-flip amplitude. Inspired by the recent high
statistics measurements of single-spin asymmetry in the fixed-target HJET
experiment at the BNL, we also performed a Regge analysis of data, aiming at
disentangling the Pomeron contribution. However, in spite of an exceptional
accuracy of the data, they do not allow to single out the Pomeron term, which
strongly correlates with the major sub-leading Reggeons. A stable solution can
be accessed only by making additional ad hoc assumptions, e.g. assuming the
Pomeron to be a simple Regge pole, or fixing some unknown parameters.
Otherwise, in addition to the STAR data at $\sqrt{s}=$200 GeV new measurements,
say at 100 GeV or 500 GeV, could become decisive.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:45:11 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 03:31:53 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 22:02:45 GMT""}]","2021-04-28"
"2102.01596","Alok Shukla","Rahul Tripathi, Pritam Bhattacharyya, Alok Shukla, Abha Misra","Role of Defect Induced Interfacial States in Molecular Sensing:
  Ultrahigh- Sensitive Region for Molecular Interaction","27 pages, 4 figures","Phys. Rev. Applied 14, 054014 (2020)","10.1103/PhysRevApplied.14.054014",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The defect induced interfacial states are created in an atomically thin
two-dimensional molybdenum disulfide channel by underlying a narrow pattern of
a graphene layer in a field effect transistor. Nondestructive method for the
generation of charge-state allowed a highly sensitive molecular interaction
with the sensitivity of nearly three-order of magnitude at room temperature.
The presence of interfacial states in the channel lead to a conductance
fluctuation and its magnitude is modulated using the nitrogen dioxide gas
molecules in the subthreshold region. The study provides a systematic approach
to establish a correlation between modulated conductance fluctuation and the
molecular concentration upto parts-per-billion. First-principles density
functional theory further explains the role of unique interfacial configuration
on conductance fluctuation. Therefore, our study demonstrates an experimental
approach to induce charge-state for the modulation of carrier concentration and
exploits the role of defect induced interfacial states in atomically thin
interfaces for the molecular interaction.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:45:39 GMT""}]","2021-02-03"
"2102.01597","Jorge Ram\'irez-Ruiz","Jorge Ram\'irez-Ruiz and Rub\'en Moreno-Bote","Optimal allocation of finite sampling capacity in accumulator models of
  multi-alternative decision making",,,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  When facing many options, we narrow down our focus to very few of them.
Although behaviors like this can be a sign of heuristics, they can actually be
optimal under limited cognitive resources. Here we study the problem of how to
optimally allocate limited sampling time to multiple options, modelled as
accumulators of noisy evidence, to determine the most profitable one. We show
that the effective sampling capacity of an agent increases with both available
time and the discriminability of the options, and optimal policies undergo a
sharp transition as a function of it. For small capacity, it is best to
allocate time evenly to exactly five options and to ignore all the others,
regardless of the prior distribution of rewards. For large capacities, the
optimal number of sampled accumulators grows sub-linearly, closely following a
power law for a wide variety of priors. We find that allocating equal times to
the sampled accumulators is better than using uneven time allocations. Our work
highlights that multi-alternative decisions are endowed with breadth-depth
tradeoffs, demonstrates how their optimal solutions depend on the amount of
limited resources and the variability of the environment, and shows that
narrowing down to a handful of options is always optimal for small capacities.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:47:55 GMT""}]","2021-02-03"
"2102.01598","Salvatore Tringali DDr","Salvatore Tringali","An Abstract Factorization Theorem and Some Applications","Final version to appear in J. Algebra (24 pages, 1 figure)","J. Algebra 602 (July 2022), 352-380","10.1016/j.jalgebra.2022.03.023",,"math.RA math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine the language of monoids with the language of preorders so as to
refine some fundamental aspects of the classical theory of factorization and
prove an abstract factorization theorem with a variety of applications. In
particular, we obtain a generalization, from cancellative to Dedekind-finite
(commutative or non-commutative) monoids, of a classical theorem on ""atomic
factorizations"" that traces back to the work of P.M. Cohn in the 1960s; recover
a theorem of D.D. Anderson and S. Valdes-Leon on ""irreducible factorizations""
in commutative rings; improve on a theorem of A.A. Antoniou and the author that
characterizes atomicity in certain ""monoids of sets"" naturally arising from
additive number theory and arithmetic combinatorics; and give a
monoid-theoretic proof that every module of finite uniform dimension over a
(commutative or non-commutative) ring $R$ is a direct sum of finitely many
indecomposable modules (this is in fact a special case of a more general
decomposition theorem for the objects of certain categories with finite
products, where the indecomposable $R$-modules are characterized as the atoms
of a suitable ""monoid of modules"").
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:50:15 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 14:48:01 GMT""},{""version"":""v3"",""created"":""Fri, 25 Feb 2022 18:43:14 GMT""}]","2022-04-15"
"2102.01599","Emanuele Aliverti","Emanuele Aliverti and Stefano Mazzuco and Bruno Scarpa","Dynamic modeling of mortality via mixtures of skewed distribution
  functions","24 pages, 6 figures, 6 tables",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  There has been growing interest on forecasting mortality. In this article, we
propose a novel dynamic Bayesian approach for modeling and forecasting the
age-at-death distribution, focusing on a three-components mixture of a Dirac
mass, a Gaussian distribution and a Skew-Normal distribution. According to the
specified model, the age-at-death distribution is characterized via seven
parameters corresponding to the main aspects of infant, adult and old-age
mortality. The proposed approach focuses on coherent modeling of multiple
countries, and following a Bayesian approach to inference we allow to borrow
information across populations and to shrink parameters towards a common mean
level, implicitly penalizing diverging scenarios. Dynamic modeling across years
is induced trough an hierarchical dynamic prior distribution that allows to
characterize the temporal evolution of each mortality component and to forecast
the age-at-death distribution. Empirical results on multiple countries indicate
that the proposed approach outperforms popular methods for forecasting
mortality, providing interpretable insights on the evolution of mortality.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:51:21 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 14:19:02 GMT""}]","2021-12-20"
"2102.01600","A. Yu. Petrov","J. R. Nascimento, A. Yu. Petrov, P. J. Porf\'irio","On the causality properties in non-local gravity theories","16 pages, version accepted to EPJ C","European Physical Journal C81, 815 (2021)","10.1140/epjc/s10052-021-09640-5",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  It is well known that non-local theories of gravity have been a flourish
arena of studies for many reasons, for instance, the UV incompleteness of
General Relativity (GR). In this paper we check the consistency of
ST-homogeneous G\""{o}del-type metrics within the non-local gravity framework.
The non-local models considered here are ghost-free but not necessarily
renormalizable since we focus on the classical solutions of the field
equations. Furthermore, the non-locality is displayed in the action through
transcendental entire functions of the d'Alembert operator $\Box$ that are
mathematically represented by a power series of the $\Box$-operator. We find
two exactly solutions for the field equations correspondent to the degenerate
($\omega=0$) and hyperbolic ($m^{2}=4\omega^2$) classes of ST-homogeneous
G\""{o}del-type metrics.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:51:44 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 16:11:13 GMT""}]","2021-09-16"
"2102.01601","Damian Orlef","Damian Orlef","Non-orderability of random triangular groups by using random 3CNF
  formulas",,,"10.1112/blms.12498",,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a random group $\Gamma$ in the triangular binomial model
$\Gamma(n, p)$ is a.a.s. not left-orderable for $p\in(cn^{-2},
n^{-3/2-\varepsilon})$, where $c, \varepsilon$ are any constants satisfying
$\varepsilon>0$, ${c>(1/8)\log_{4/3}{2}\approx 0.3012}$. We also prove that if
$p\geq (1+\varepsilon)(\log n)n^{-2}$ for any fixed $\varepsilon>0$, then a
random $\Gamma\in \Gamma(n,p)$ has a.a.s. no non-trivial left-orderable
quotients. We proceed by constructing 3CNF formulas, which encode necessary
conditions for left-orderability and then proving their unsatisfiability a.a.s.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:52:14 GMT""}]","2021-09-17"
"2102.01602","Friederike Ihssen","Eduardo Grossi, Friederike J. Ihssen, Jan M. Pawlowski, Nicolas Wink","Shocks and quark-meson scatterings at large density","26 pages, 16 figures","Phys. Rev. D 104, 016028 (2021)","10.1103/PhysRevD.104.016028",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the phase structure of the two-flavour quark-meson model including
quantum, thermal, density and critical fluctuations with the functional
renormalisation group. This study combines two technical advances in the
literature, that are also chiefly important for the quantitative access of the
phase boundary of QCD at large density or baryon chemical potential.
Specifically we allow for the formation and propagation of shocks as well as a
fully self-consistent computation of the order parameter potential for chiral
symmetry breaking.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:54:29 GMT""}]","2021-08-04"
"2102.01603","Sultan Abdul Wadood","S. A. Wadood, Kevin Liang, Yiyu Zhou, Jing Yang, M. A. Alonso, X.-F.
  Qian, T. Malhotra, S.M. Hashemi Rafsanjani, Andrew N. Jordan, Robert W. Boyd,
  and A. N. Vamivakas","Experimental demonstration of superresolution of partially coherent
  light sources using parity sorting",,,"10.1364/OE.427734",,"physics.optics quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Analyses based on quantum metrology have shown that the ability to localize
the positions of two incoherent point sources can be significantly enhanced
through the use of mode sorting. Here we theoretically and experimentally
investigate the effect of partial coherence on the sub-diffraction limit
localization of two sources based on parity sorting. With the prior information
of a negative and real-valued degree of coherence, higher Fisher information is
obtained than that for the incoherent case. Our results pave the way to
clarifying the role of coherence in quantum limited metrology.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:58:45 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 02:46:53 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 03:07:35 GMT""}]","2021-07-21"
"2102.01604","Ya\""el Balbastre","Yael Balbastre, Mikael Brudfors, Michela Azzarito, Christian Lambert,
  Martina F. Callaghan, John Ashburner","Model-based multi-parameter mapping","20 pages, 6 figures, accepted at Medical Image Analysis",,"10.1016/j.media.2021.102149",,"cs.CV eess.IV stat.AP","http://creativecommons.org/licenses/by/4.0/","  Quantitative MR imaging is increasingly favoured for its richer information
content and standardised measures. However, computing quantitative parameter
maps, such as those encoding longitudinal relaxation rate (R1), apparent
transverse relaxation rate (R2*) or magnetisation-transfer saturation (MTsat),
involves inverting a highly non-linear function. Many methods for deriving
parameter maps assume perfect measurements and do not consider how noise is
propagated through the estimation procedure, resulting in needlessly noisy
maps. Instead, we propose a probabilistic generative (forward) model of the
entire dataset, which is formulated and inverted to jointly recover (log)
parameter maps with a well-defined probabilistic interpretation (e.g., maximum
likelihood or maximum a posteriori). The second order optimisation we propose
for model fitting achieves rapid and stable convergence thanks to a novel
approximate Hessian. We demonstrate the utility of our flexible framework in
the context of recovering more accurate maps from data acquired using the
popular multi-parameter mapping protocol. We also show how to incorporate a
joint total variation prior to further decrease the noise in the maps, noting
that the probabilistic formulation allows the uncertainty on the recovered
parameter maps to be estimated. Our implementation uses a PyTorch backend and
benefits from GPU acceleration. It is available at
https://github.com/balbasty/nitorch.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:00:11 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 19:02:54 GMT""}]","2021-07-01"
"2102.01605","Mina Ketan Parida","Mina Ketan Parida (SOA Deemed to be Univ.), Riyanka Samantaray (SOA
  Deemed to be Univ.)","SU(5) unification of two triplet seesaw and leptogenesis with dark
  matter and vacuum stability","36 pages, 12 figures, related areas hep-ex, Pub version: NPB (2021)
  115484","Nucl. Phy. B (2021) 115484","10.1016/j.nuclphysb.2021.115484",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate unification prospects of two heavy scalar triplet extension of
the standard model where, in the absence of any right-handed neutrino (RHN),
type-II seesaw accounts for current oscillation data with hierarchical neutrino
masses consistent with cosmological bounds and the lighter triplet decay
explains baryon asymmetry of the Universe via leptogenesis. We note that the
absence of RHNs in the fundamental fermion representations of SU(5) delineates
its outstanding position compared to SO(10) (or $E_6$). In addition, SU(5)
needs smaller scalar representations ${15}_{H1}\oplus {15}_{H2}$ compared to
much larger representations ${126}_{H1}\oplus {126}_{H2} \subset $ SO(10) (or
${351}^{\prime}_{H1}\oplus {351}^{\prime}_{H2} \subset E_6$). We show how
precision gauge coupling unification is achieved through SU(5) with the
predictions of different sets of two heavy triplet masses which, besides being
compatible with type-II seesaw, are also consistent with unflavoured or $\tau
-$ flavoured leptogenesis. In addition to an intermediate mass colour octet
fermion, completion of precision gauge coupling unification is found to require
essentially the presence of the well known weak triplet fermion $\Sigma
(3,0,1)$ in its mass range $M_{\Sigma}\simeq {\cal O}(500-3000)$ GeV out of
which the dominant dark matter (DM) resonance mass $M_{\Sigma}\ge 2.4$ TeV is
known to account for the observed cosmological relic density. The deficiency in
relic density for lighter $\Sigma$ solutions is compensated by an additional
scalar singlet DM. A GUT ansatz is noted to ensure vacuum stability of the SM
scalar potential for all types of unification solutions realised in this work.
We discuss proton lifetime estimations for $p\to e^+\pi^0$ compatible with the
present Hyper-Kamiokande bound as a function of an unknown mixing parameter in
the model.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:02:43 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 05:27:03 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 05:50:00 GMT""}]","2021-07-21"
"2102.01606","Katharina Ensinger","Katharina Ensinger, Friedrich Solowjow, Sebastian Ziesche, Michael
  Tiemann, Sebastian Trimpe","Structure-preserving Gaussian Process Dynamics",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most physical processes posses structural properties such as constant
energies, volumes, and other invariants over time. When learning models of such
dynamical systems, it is critical to respect these invariants to ensure
accurate predictions and physically meaningful behavior. Strikingly,
state-of-the-art methods in Gaussian process (GP) dynamics model learning are
not addressing this issue. On the other hand, classical numerical integrators
are specifically designed to preserve these crucial properties through time. We
propose to combine the advantages of GPs as function approximators with
structure preserving numerical integrators for dynamical systems, such as
Runge-Kutta methods. These integrators assume access to the ground truth
dynamics and require evaluations of intermediate and future time steps that are
unknown in a learning-based scenario. This makes direct inference of the GP
dynamics, with embedded numerical scheme, intractable. Our key technical
contribution is the evaluation of the implicitly defined Runge-Kutta transition
probability. In a nutshell, we introduce an implicit layer for GP regression,
which is embedded into a variational inference-based model learning scheme.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:02:55 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 16:51:09 GMT""},{""version"":""v3"",""created"":""Sun, 9 Jan 2022 19:21:48 GMT""}]","2022-01-11"
"2102.01607","Georg Eickerling","Jan Langmann, Marcel V\""ost, Dominik Schmitz, Christof Haas, Georg
  Eickerling, Anton Jesche, Michael Nicklas, Arianna Lanza, Nicola Casati,
  Piero Macchi, Wolfgang Scherer","The structure of the superconducting high-pressure phase of
  Sc$_3$CoC$_4$",,"Phys. Rev. B 103, 184101 (2021)","10.1103/PhysRevB.103.184101",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate pressure-induced structural changes to the Peierls-type
distorted low-temperature phase of the low-dimensional Sc$_3$CoC$_4$ as a
possible origin of its pressure-enhanced superconductivity. By means of
cryogenic high-pressure x-ray diffraction experiments we could reveal subtle,
but significant structural differences between the low-temperature phase at
ambient and elevated pressures. We could thus establish the structure of the
superconducting phase of the title compound which interestingly still shows the
main features of the Peierls-type distorted low-temperature phase. This
indicates that in contrast to other low-dimensional materials a suppression of
periodic structural distortions is no prerequisite for superconducitivity in
the transition metal carbide.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:03:01 GMT""}]","2021-05-12"
"2102.01608","Michael Combi","Michael R. Combi, Terhi M\""akinen, Jean-Loup. Bertaux, Eric
  Qu\'emerais, Stephane Ferron, Ruben Coronel","Comet 21P/Giacobini-Zinner: Water Production Activity over 20 Years with
  SOHO/SWAN","12 pages, 2 figures, 2 tables","Icarus Volume 357, 15 March 2021, 114242","10.1016/j.icarus.2020.114242",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1985 Comet 21P/Giacobini-Zinner was the first comet visited by a
spacecraft, the International Cometary Explorer (ICE) satellite, several months
before the armada of Halley spacecraft had their encounters in 1986. ICE was
originally the ISEE-3 satellite, designed for magnetospheric measurements near
the Earth, and was diverted via a lunar gravity assist to pass through the
plasma tail of the comet. The comet has been observed by the all-sky hydrogen
Lyman-alpha Solar Wind Anisotropies (SWAN) camera on the SOlar and Heliospheric
Observatory satellite during its last four apparitions in 1998, 2005, 2012 and
2018. This paper compares water production rates calculated from the hydrogen
images from the 1998 and 2005 results, published by Combi et al. (2011), with
new observations from 2012 and 2018. Unlike some comets that have faded over
time, except for 2 outbursts seen in the 2012 results, the activity levels for
Comet 21P have not changed consistently over time. A power-law fit to the
pre-perihelion water production rate vs. heliocentric distance for all four
apparitions gives a result of 3.75x10^28 x r^-0.28+/-0.4, and that for the
post-perihelion production rate, discounting 2012 data dominated by outbursts,
gives 4.15 x 10^28 x r^-10.2+/-0.9. The production rates are in s^-1 and
heliocentric distances are in AU.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:06:10 GMT""}]","2021-02-03"
"2102.01609","Ateeb Akhter Shah Syed","Ateeb Akhter Shah Syed and Kaneez Fatima and Riffat Arshad","The Macroeconomic Impacts of Entitlements",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The worries expressed by Alan Greenspan that the long run economic growth of
the United States will fade away due to increasing burden of entitlements
motivated us to empirically investigate the impact of entitlements of key
macroeconomic variables. To examine this contemporary issue, we estimate a
vector error-correction model is used to analyze the impact of entitlements on
the price level, real output, and the long-term interest rate. The results show
that a shock to entitlements leads to decrease in output and lends support to
the assertion made by Alan Greenspan. Several robustness checks are conducted
and the results of the model qualitatively remains unchanged.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:07:40 GMT""}]","2021-02-03"
"2102.01610","Rong Wang","Rong Wang, Wei Kou, Ya-Ping Xie, Xurong Chen","Extraction of the proton mass radius from the vector meson
  photoproductions near thresholds","5 pages, 2 figures, minor modifications","Phys. Rev. D 103, 091501 (2021)","10.1103/PhysRevD.103.L091501",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analysis of the proton mass radius by studying the
$t$-dependence of the differential cross sections of the vector meson
photoproductions near the thresholds. At low energy, the photoproduction of a
quarkonium off the proton is connected to the scalar gravitational form factor
of the proton, which is sensitive to the proton mass distribution from the QCD
trace anomaly. Under an assumption of the scalar form factor of dipole form,
the proton mass radius is extracted via the near-threshold photoproduction data
of J/$\psi$, $\phi$ and $\omega$ vector mesons. The average value of the proton
mass radius is estimated to be $\sqrt{\left<R_{\rm m}^2\right>} = 0.67\pm0.03$
fm, with the dipole cutoff $m_{\rm s}=1.01\pm0.04$ GeV.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:13:22 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 17:38:44 GMT""},{""version"":""v3"",""created"":""Wed, 10 Mar 2021 15:29:21 GMT""},{""version"":""v4"",""created"":""Thu, 13 May 2021 01:49:46 GMT""}]","2021-05-19"
"2102.01611","Hrishikesh Dutta","Hrishikesh Dutta and Subir Biswas","Towards Multi-agent Reinforcement Learning for Wireless Network Protocol
  Synthesis","Accepted and presented in 13th International Conference on
  COMmunication Systems & NETworkS (COMSNETS) 2021, Bangalore 2021. IEEE, 2021",,,,"cs.LG cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a multi-agent reinforcement learning based medium access
framework for wireless networks. The access problem is formulated as a Markov
Decision Process (MDP), and solved using reinforcement learning with every
network node acting as a distributed learning agent. The solution components
are developed step by step, starting from a single-node access scenario in
which a node agent incrementally learns to control MAC layer packet loads for
reining in self-collisions. The strategy is then scaled up for multi-node
fully-connected scenarios by using more elaborate reward structures. It also
demonstrates preliminary feasibility for more general partially connected
topologies. It is shown that by learning to adjust MAC layer transmission
probabilities, the protocol is not only able to attain theoretical maximum
throughput at an optimal load, but unlike classical approaches, it can also
retain that maximum throughput at higher loading conditions. Additionally, the
mechanism is agnostic to heterogeneous loading while preserving that feature.
It is also shown that access priorities of the protocol across nodes can be
parametrically adjusted. Finally, it is also shown that the online learning
feature of reinforcement learning is able to make the protocol adapt to
time-varying loading conditions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:13:37 GMT""}]","2021-04-30"
"2102.01612","Dorota M{\l}ynarczyk","Dorota M{\l}ynarczyk (1), Carmen Armero (2), Virgilio G\'omez-Rubio
  (3), Pedro Puig (1 and 4) ((1) Universitat Aut\`onoma de Barcelona, (2)
  Universitat de Val\`encia, (3) Universidad de Castilla-La Mancha, (4) Centre
  de Recerca Matem\`atica (CRM))","Bayesian analysis of population health data",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  The analysis of population-wide datasets can provide insight on the health
status of large populations so that public health officials can make
data-driven decisions. The analysis of such datasets often requires highly
parameterized models with different types of fixed and randoms effects to
account for risk factors, spatial and temporal variations, multilevel effects
and other sources on uncertainty. To illustrate the potential of Bayesian
hierarchical models, a dataset of about 500 000 inhabitants released by the
Polish National Health Fund containing information about ischemic stroke
incidence for a 2-year period is analyzed using different types of models.
Spatial logistic regression and survival models are considered for analyzing
the individual probabilities of stroke and the times to the occurrence of an
ischemic stroke event. Demographic and socioeconomic variables as well as drug
prescription information are available at an individual level. Spatial
variation is considered by means of region-level random effects.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:14:44 GMT""}]","2021-02-03"
"2102.01613","Matthew Just","George E. Andrews, Matthew Just, and Greg Simay","Anti-palindromic compositions","13 pages, 2 tables",,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A palindromic composition of $n$ is a composition of $n$ which can be read
the same way forwards and backwards. In this paper we define an
anti-palindromic composition of $n$ to be a composition of $n$ which has no
mirror symmetry amongst its parts. We then give a surprising connection between
the number of anti-palindromic compositions of $n$ and the so-called tribonacci
sequence, a generalization of the Fibonacci sequence. We conclude by defining a
new q-analogue of the Fibonacci sequence, which is related to certain
equivalence classes of anti-palindromic compositions
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:14:45 GMT""}]","2021-02-03"
"2102.01614","Duc Nguyen","Duc Nguyen-Manh, Jan S. Wrobel, Michael Klimenkov, Matthew J. Lloyd,
  Luca Messina, and Sergei L. Dudarev","First principles model for voids decorated by transmutation solutes:
  Short-range order effects and application to neutron irradiated tungsten","29 pages, 13 figures, 3 tables","Phys. Rev. Materials 5, 065401 (2021)","10.1103/PhysRevMaterials.5.065401",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Understanding how properties of materials change due to nuclear
transmutations is a major challenge for the design of structural components for
a fusion power plant. In this study, by combining a first-principles matrix
Hamiltonian approach with thermodynamic integration we investigate quasi-steady
state configurations of multi-component alloys, containing defects, over a
broad range of temperature and composition. The model enables simulating
transmutation-induced segregation effects in materials, including tungsten
where the phenomenon is strongly pronounced. Finite-temperature analysis shows
that voids are decorated by Re and Os, but there is no decoration by tantalum
(Ta). The difference between the elements is correlated with the sign of the
short range order (SRO) parameter between impurity and vacancy species, in
agreement with Atom Probe Tomography (APT) observations of irradiated W-Re,
W-Os, W-Ta alloys in the solid solution limit. Statistical analyses of Re and
Os impurities in vacancy-rich tungsten show that the SRO effects involving the
two solutes are highly sensitive to the background concentration the species.
In quaternary W-Re-Os-Vac alloys containing 1.5% Re and 0.1% Os, the SRO Re-Os
parameter is negative at 1200K, driving the formation of concentrated Re and Os
precipitates. Comparison with experimental Transmission Electron Microscopy
(TEM) and APT data on W samples irradiated at the High Flux Reactor (HFR) shows
that the model explains the origin of anomalous segregation of transmutation
products (Re,Os) to vacancy clusters and voids in the high temperature limit
pertinent to the operating conditions of a fusion power plant.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:17:35 GMT""}]","2021-06-09"
"2102.01615","David M\""odinger","David M\""odinger, Jan-Hendrik Lorenz, Fanz J. Hauck","Statistical privacy-preserving message dissemination for peer-to-peer
  networks","6 figures, 19 pages, single column",,"10.1371/journal.pone.0251458",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Concerns for the privacy of communication is widely discussed in research and
overall society. For the public financial infrastructure of blockchains, this
discussion encompasses the privacy of transaction data and its broadcasting
throughout the network. To tackle this problem, we transform a discrete-time
protocol for contact networks over infinite trees into a computer network
protocol for peer-to-peer networks. Peer-to-peer networks are modeled as
organically growing graphs. We show that the distribution of shortest paths in
such a network can be modeled using a normal distribution
$\mathcal{N}(\mu,\sigma^2).$ We determine statistical estimators for
$\mu,\sigma$ via multivariate models. The model behaves logarithmic over the
number of nodes n and proportional to an inverse exponential over the number of
added edges k. These results facilitate the computation of optimal forwarding
probabilities during the dissemination phase for optimal privacy in a limited
information environment.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:18:16 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 08:55:23 GMT""},{""version"":""v3"",""created"":""Wed, 17 Mar 2021 17:30:35 GMT""}]","2021-06-09"
"2102.01616","Nakahiro Yoshida","Yuliya Mishura and Nakahiro Yoshida","Divergence of an integral of a process with small ball estimate",,,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper contains sufficient conditions on the function $f$ and the
stochastic process $X$ that supply the rate of divergence of the integral
functional $\int_0^Tf(X_t)^2dt$ at the rate $T^{1-\epsilon}$ as $T\to\infty$
for every $\epsilon>0$. These conditions include so called small ball estimates
which are discussed in detail. Statistical applications are provided.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:18:27 GMT""}]","2021-02-03"
"2102.01617","Dmitri Khveshchenko","D. V. Khveshchenko","Phase space holography with no strings attached","Latex, 10 pages, no figures","Lith. J. of Phys., Vol. 61, p. 233, 2021",,,"cond-mat.str-el gr-qc hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  This note discusses the Wigner function representation from the standpoint of
establishing a holography-like correspondence between the descriptions of a
generic quantum system in the phase space ('bulk') picture versus its spacetime
('boundary') counterpart. Under certain circumstances the former might reduce
to the classical dynamics of a local metric-like variable while the latter
takes on the form of some bosonized collective field hydrodynamics. This
generic pseudo-holographic duality neither relies on any particular symmetry of
the system in question, nor does it require any connection to an underlying
'string theory', as in the various 'ad hoc' scenarios of applied holography.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:18:52 GMT""}]","2021-12-24"
"2102.01618","Tom Bachmann","Tom Bachmann, Paul Arne {\O}stv{\ae}r","Topological models for stable motivic invariants of regular number rings","20 pages v2: minor corrections",,,,"math.KT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For an infinity of number rings we express stable motivic invariants in terms
of topological data determined by the complex numbers, the real numbers, and
finite fields. We use this to extend Morel's identification of the endomorphism
ring of the motivic sphere with the Grothendieck-Witt ring of quadratic forms
to deeper base schemes.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:19:41 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 05:18:17 GMT""}]","2021-04-02"
"2102.01619","Mohammad Talebi","Mohammad Talebi","Analytic torsion on manifolds with fibred boundary metrics",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we construct the renormalized analytic torsion in the setup of
manifold endowed with fibred boundary metrics. The method of construction is to
determine the asymptotic of heat kernel, both in short time regime and long
time regime and apply these asymptotics together with renormalization to
determine the renormalized zeta function and the determinant of Hodge
Laplacian.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:20:10 GMT""}]","2021-02-03"
"2102.01620","Jianjun Hu","Jianjun Hu, Yong Zhao, Yuqi Song, Rongzhi Dong, Wenhui Yang, Yuxin Li,
  Edirisuriya MD Siriwardane","AlphaCrystal: Contact map based crystal structure prediction using deep
  learning","13 pages; 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Crystal structure prediction is one of the major unsolved problems in
materials science. Traditionally, this problem is formulated as a global
optimization problem for which global search algorithms are combined with first
principle free energy calculations to predict the ground-state crystal
structure given only a material composition or a chemical system. These ab
initio algorithms usually cannot exploit a large amount of implicit
physicochemical rules or geometric constraints (deep knowledge) of atom
configurations embodied in a large number of known crystal structures. Inspired
by the deep learning enabled breakthrough in protein structure prediction,
herein we propose AlphaCrystal, a crystal structure prediction algorithm that
combines a deep residual neural network model that learns deep knowledge to
guide predicting the atomic contact map of a target crystal material followed
by reconstructing its 3D crystal structure using genetic algorithms. Based on
the experiments of a selected set of benchmark crystal materials, we show that
our AlphaCrystal algorithm can predict structures close to the ground truth
structures. It can also speed up the crystal structure prediction process by
predicting and exploiting the predicted contact map so that it has the
potential to handle relatively large systems. We believe that our deep learning
based ab initio crystal structure prediction method that learns from existing
material structures can be used to scale up current crystal structure
prediction practice. To our knowledge, AlphaCrystal is the first neural network
based algorithm for crystal structure contact map prediction and the first
method for directly reconstructing crystal structures from materials
composition, which can be further optimized by DFT calculations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:23:14 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 07:12:51 GMT""}]","2021-09-01"
"2102.01621","Luca Venturi","Luca Venturi, Samy Jelassi, Tristan Ozuch, Joan Bruna","Depth separation beyond radial functions",,,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dimensional depth separation results for neural networks show that
certain functions can be efficiently approximated by two-hidden-layer networks
but not by one-hidden-layer ones in high-dimensions $d$. Existing results of
this type mainly focus on functions with an underlying radial or
one-dimensional structure, which are usually not encountered in practice. The
first contribution of this paper is to extend such results to a more general
class of functions, namely functions with piece-wise oscillatory structure, by
building on the proof strategy of (Eldan and Shamir, 2016). We complement these
results by showing that, if the domain radius and the rate of oscillation of
the objective function are constant, then approximation by one-hidden-layer
networks holds at a $\mathrm{poly}(d)$ rate for any fixed error threshold.
  A common theme in the proofs of depth-separation results is the fact that
one-hidden-layer networks fail to approximate high-energy functions whose
Fourier representation is spread in the domain. On the other hand, existing
approximation results of a function by one-hidden-layer neural networks rely on
the function having a sparse Fourier representation. The choice of the domain
also represents a source of gaps between upper and lower approximation bounds.
Focusing on a fixed approximation domain, namely the sphere $\mathbb{S}^{d-1}$
in dimension $d$, we provide a characterisation of both functions which are
efficiently approximable by one-hidden-layer networks and of functions which
are provably not, in terms of their Fourier expansion.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:25:02 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 17:49:56 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 18:02:57 GMT""},{""version"":""v4"",""created"":""Wed, 22 Sep 2021 16:45:08 GMT""}]","2021-09-23"
"2102.01622","Andreas Winter","Krishna Kumar Sabapathy, Andreas Winter","Bosonic data hiding: power of linear vs non-linear optics","11 pages, 1 figure",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the positivity of the Wigner function of Gaussian states and
measurements provides an elegant way to bound the discriminating power of
""linear optics"", which we formalise as Gaussian measurement operations
augmented by classical (feed-forward) communication (GOCC). This allows us to
reproduce and generalise the result of Takeoka and Sasaki [PRA 78:022320,
2008], which tightly characterises the GOCC norm distance of coherent states,
separating it from the optimal distinguishability according to Helstrom's
theorem.
  Furthermore, invoking ideas from classical and quantum Shannon theory we show
that there are states, each a probabilistic mixture of multi-mode coherent
states, which are exponentially reliably discriminated in principle, but appear
exponentially close judging from the output of GOCC measurements. In analogy to
LOCC data hiding, which shows an irreversibility in the preparation and
discrimination of states by the restricted class of local operations and
classical communication (LOCC), we call the present effect GOCC data hiding.
  We also present general bounds in the opposite direction, guaranteeing a
minimum of distinguishability under measurements with positive Wigner function,
for any bounded-energy states that are Helstrom distinguishable. We conjecture
that a similar bound holds for GOCC measurements.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:25:26 GMT""}]","2021-02-03"
"2102.01623","Zhiyu Zhang","Zhiyu Zhang, Ashok Cutkosky, Ioannis Ch. Paschalidis","Adversarial Tracking Control via Strongly Adaptive Online Learning with
  Memory","AISTATS 2022",,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of tracking an adversarial state sequence in a linear
dynamical system subject to adversarial disturbances and loss functions,
generalizing earlier settings in the literature. To this end, we develop three
techniques, each of independent interest. First, we propose a
comparator-adaptive algorithm for online linear optimization with movement
cost. Without tuning, it nearly matches the performance of the optimally tuned
gradient descent in hindsight. Next, considering a related problem called
online learning with memory, we construct a novel strongly adaptive algorithm
that uses our first contribution as a building block. Finally, we present the
first reduction from adversarial tracking control to strongly adaptive online
learning with memory. Summarizing these individual techniques, we obtain an
adversarial tracking controller with a strong performance guarantee even when
the reference trajectory has a large range of movement.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:26:08 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 01:19:23 GMT""},{""version"":""v3"",""created"":""Tue, 22 Feb 2022 00:44:52 GMT""}]","2022-02-23"
"2102.01624","Placido Mursia","Placido Mursia and Italo Atzeni and Mari Kobayashi and David Gesbert","D2D-Aided Multi-Antenna Multicasting under Generalized CSIT","Submitted to IEEE Transactions on Wireless Communications",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Multicasting, where a base station (BS) wishes to convey the same message to
several user equipments (UEs), represents a common yet highly challenging
wireless scenario. In fact, guaranteeing decodability by the whole UE
population proves to be a major performance bottleneck since the UEs in poor
channel conditions ultimately determine the achievable rate. To overcome this
issue, two-phase cooperative multicasting schemes, which use conventional
multicasting in a first phase and leverage device-to-device (D2D)
communications in a second phase to effectively spread the message, have been
extensively studied. However, most works are limited either to the simple case
of single-antenna BS or to a specific channel state information at the
transmitter (CSIT) setup. This paper proposes a general two-phase framework
that is applicable to the cases of perfect, statistical, and topological CSIT
in the presence of multiple antennas at the BS. The proposed method exploits
the precoding capabilities at the BS, which enable targeting specific UEs that
can effectively serve as D2D relays towards the remaining UEs, and maximize the
multicast rate under some outage constraint. Numerical results show that our
schemes bring substantial gains over traditional single-phase multicasting and
overcome the worst-UE bottleneck behavior in all the considered CSIT
configurations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:26:09 GMT""}]","2021-02-03"
"2102.01625","Sohini Roychowdhury","Sohini Roychowdhury, Ebrahim Alareqi, Wenxi Li","OPAM: Online Purchasing-behavior Analysis using Machine learning","8 pages, 8 figures, 5 tables",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Customer purchasing behavior analysis plays a key role in developing
insightful communication strategies between online vendors and their customers.
To support the recent increase in online shopping trends, in this work, we
present a customer purchasing behavior analysis system using supervised,
unsupervised and semi-supervised learning methods. The proposed system analyzes
session and user-journey level purchasing behaviors to identify customer
categories/clusters that can be useful for targeted consumer insights at scale.
We observe higher sensitivity to the design of online shopping portals for
session-level purchasing prediction with accuracy/recall in range
91-98%/73-99%, respectively. The user-journey level analysis demonstrates five
unique user clusters, wherein 'New Shoppers' are most predictable and
'Impulsive Shoppers' are most unique with low viewing and high carting
behaviors for purchases. Further, cluster transformation metrics and partial
label learning demonstrates the robustness of each user cluster to
new/unlabelled events. Thus, customer clusters can aid strategic targeted nudge
models.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:29:52 GMT""}]","2021-02-03"
"2102.01626","J. Maurice Rojas","Caleb Robelle, J. Maurice Rojas, and Yuyu Zhu","Sub-Linear Point Counting for Variable Separated Curves over Prime Power
  Rings","18 pages, no figures. Submitted to a conference. Comments and
  questions welcome!",,,,"math.NT cs.CC math.AG","http://creativecommons.org/licenses/by/4.0/","  Let $k,p\in \mathbb{N}$ with $p$ prime and let $f\in\mathbb{Z}[x_1,x_2]$ be a
bivariate polynomial with degree $d$ and all coefficients of absolute value at
most $p^k$. Suppose also that $f$ is variable separated, i.e., $f=g_1+g_2$ for
$g_i\in\mathbb{Z}[x_i]$. We give the first algorithm, with complexity
sub-linear in $p$, to count the number of roots of $f$ over $\mathbb{Z}$ mod
$p^k$ for arbitrary $k$: Our Las Vegas randomized algorithm works in time
$(dk\log p)^{O(1)}\sqrt{p}$, and admits a quantum version for smooth curves
working in time $(d\log p)^{O(1)}k$. Save for some subtleties concerning
non-isolated singularities, our techniques generalize to counting roots of
polynomials in $\mathbb{Z}[x_1,\ldots,x_n]$ over $\mathbb{Z}$ mod $p^k$.
  Our techniques are a first step toward efficient point counting for varieties
over Galois rings (which is relevant to error correcting codes over
higher-dimensional varieties), and also imply new speed-ups for computing Igusa
zeta functions of curves. The latter zeta functions are fundamental in
arithmetic geometry.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:29:54 GMT""}]","2021-02-03"
"2102.01627","Fran Globlek","Giulio Bonelli, Fran Globlek, Alessandro Tanzini","Instantons to the people: the power of one-form symmetries","two columns, 5 pages","Phys. Rev. Lett. 126, 231602 (2021)","10.1103/PhysRevLett.126.231602",,"hep-th math-ph math.MP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the non-perturbative dynamics of $\mathcal{N}=2$ super
Yang-Mills theories in a self-dual $\Omega$-background and with an arbitrary
simple gauge group is fully determined by studying renormalization group
equations of vevs of surface operators generating one-form symmetries. The
corresponding system of equations is a {\it non-autonomous} Toda chain, the
time being the RG scale. We obtain new recurrence relations which provide a
systematic algorithm computing multi-instanton corrections from the tree-level
one-loop prepotential as the asymptotic boundary condition of the RGE. We
exemplify by computing the $E_6$ and $G_2$ cases up to two-instantons.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:32:34 GMT""}]","2021-06-16"
"2102.01628","Anna Jen\v{c}ov\'a","Anna Jen\v{c}ov\'a and Sylvia Pulmannov\'a","Geometric and algebraic aspects of spectrality in order unit spaces: a
  comparison","34 pages, comments welcome","Journal of Mathematical Analysis and Applications, 504
  (2021),125360","10.1016/j.jmaa.2021.125360",,"quant-ph math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Two approaches to spectral theory of order unit spaces are compared: the
spectral duality of Alfsen and Shultz and the spectral compression bases due to
Foulis. While the former approach uses the geometric properties of an order
unit space in duality with a base norm space, the latter notion is purely
algebraic. It is shown that the Foulis approach is strictly more general and
contains the Alfsen-Shultz approach as a special case. This is demonstrated on
two types of examples: the JB-algebras which are Foulis spectral if and only if
they are Rickart, and the centrally symmetric state spaces, which may be Foulis
spectral while not necessarily Alfsen-Shultz spectral.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:33:08 GMT""}]","2021-11-08"
"2102.01629","Dario Menasce","Gianluca Bonifazi, Luca Lista, Dario Menasce, Mauro Mezzetto, Alberto
  Oliva, Daniele Pedrini, Roberto Spighi, Antonio Zoccoli","A statistical analysis of death rates in Italy for the years 2015-2020
  and a comparison with the casualties reported for the COVID-19 pandemic","16 pages, 13 figures",,,,"physics.soc-ph stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We analyze the data about casualties in Italy in the period 01/01/2015 to
30/09/2020 released by the Italian National Institute of Statistics (ISTAT).
The data exhibit a clear sinusoidal behavior, whose fit allows for a robust
subtraction of the baseline trend of casualties in Italy, with a surplus of
mortality in correspondence to the flu epidemics in winter and to the hottest
periods in summer. While these peaks are symmetric in shape, the peak in
coincidence with the COVID-19 pandemics is asymmetric and more pronounced. We
fit the former with a Gaussian function and the latter with a Gompertz
function, in order to quantify number of casualties, the duration and the
position of all causes of excess deaths. The overall quality of the fit to the
data turns out to be very good. We discuss the trend of casualties in Italy by
different classes of ages and for the different genders. We finally compare the
data-subtracted casualties as reported by ISTAT with those reported by the
Italian Department for Civil Protection (DPC) relative to the deaths directly
attributed to COVID-19, and we discuss the differences.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:38:26 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 18:10:26 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 08:15:11 GMT""},{""version"":""v4"",""created"":""Thu, 11 Mar 2021 09:18:41 GMT""},{""version"":""v5"",""created"":""Tue, 23 Mar 2021 10:00:46 GMT""}]","2021-03-24"
"2102.01630","Giulia Murtas","Giulia Murtas, Andrew Hillier, Ben Snow","Coalescence Instability in Chromospheric Partially Ionised Plasmas","22 pages, 22 figures, 1 table","Phys. Plasmas 28, 032901 (2021)","10.1063/5.0032236",,"astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fast magnetic reconnection plays a fundamental role in driving explosive
dynamics and heating in the solar chromosphere. The reconnection time scale of
traditional models is shortened at the onset of the coalescence instability,
which forms a turbulent reconnecting current sheet through plasmoid
interaction. In this work we aim to investigate the role of partial ionisation
on the development of fast reconnection through the study of the coalescence
instability of plasmoids. Unlike the processes occurring in fully ionised
coronal plasmas, relatively little is known about how fast reconnection
develops in partially ionised plasmas of the chromosphere. We present 2.5D
numerical simulations of coalescing plasmoids in a single fluid
magnetohydrodynamic (MHD) model, and a two-fluid model of a partially ionised
plasma (PIP). We find that in the PIP model, which has the same total density
as the MHD model but an initial plasma density two orders of magnitude smaller,
plasmoid coalescence is faster than the MHD case, following the faster thinning
of the current sheet and secondary plasmoid dynamics. Secondary plasmoids form
in the PIP model where the effective Lundquist number $S = 7.8 \cdot 10^3$, but
are absent from the MHD case where $S = 9.7 \cdot 10^3$: these are responsible
for a more violent reconnection. Secondary plasmoids also form in linearly
stable conditions as a consequence of the non-linear dynamics of the neutrals
in the inflow. In the light of these results we can affirm that two-fluid
effects play a major role on the processes occurring in the solar chromosphere.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:39:26 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 16:15:33 GMT""},{""version"":""v3"",""created"":""Thu, 25 Mar 2021 11:14:42 GMT""}]","2021-03-26"
"2102.01631","Leonardo Humberto Silva","Leonardo Humberto Silva, Renata Xavier Castro, Marice Costa Guimaraes","Supporting Real Demands in Software Engineering with a Four Steps
  Project-Based Learning Approach","To be published in ICSE-JSEET 2021",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Project-based learning (PBL) is a student-centered and learn-by-doing
approach that organizes learning around projects. While entrepreneurship and
PBL in SE education are thrilling research topics, there seems to be very
little work focusing on the pros and cons of involving external stakeholders to
support real demands in software engineering education. Working on real
projects also supports students to acquire leadership skills, such as
communication, project management, and teamwork. This paper describes a case
study integrating students from different Software Engineering programs and
involving external stakeholders, underpinned by PBL concepts. We present how
this study was designed and implemented in a large institution, in four steps,
summarized as follows: (I) requirements gathering and design; (II) information
system development and implementation; (III) integration tests and deployment
process; (IV) support and maintenance activities. The study had the
participation of 59 students from a professional technical course in step one,
working in teams, and 10 undergraduate students from a Bachelor's program in
Information Systems in the following steps, working in pairs. Overall, the
feedback from stakeholders and students exceeded expectations, although it
increased the workload of teachers. We were able to distill a new set of
lessons learned, and we expect that at least some of them will be useful for
anyone implementing a similar course. As a consequence of this study, we plan
to institutionally formalize the PBL course improvement process by defining
specific outcomes and measurements.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:40:07 GMT""}]","2021-02-03"
"2102.01632","Aurelien Manchon","V. Bonbien, Fengjun Zhuo, A. Salimath, O. Ly, A. Abbout, A. Manchon","Topological Aspects of Antiferromagnets","77 pages, 47 figures",,"10.1088/1361-6463/ac28fa",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The long fascination antiferromagnetic materials have exerted on the
scientific community over about a century has been entirely renewed recently
with the discovery of several unexpected phenomena including various classes of
anomalous spin and charge Hall effects and unconventional magnonic transport,
but also homochiral magnetic entities such as skyrmions. With these
breakthroughs, antiferromagnets standout as a rich playground for the
investigation of novel topological behaviors, and as promising candidate
materials for disruptive low-power microelectronic applications. Remarkably,
the newly discovered phenomena are all related to the topology of the magnetic,
electronic or magnonic ground state of the antiferromagnets. This review
exposes how non-trivial topology emerges at different levels in
antiferromagnets and explores the novel mechanisms that have been discovered
recently. We also discuss how novel classes of quantum magnets could enrich the
currently expanding field of antiferromagnetic spintronics and how spin
transport can in turn favor a better understanding of exotic quantum
excitations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:43:57 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 17:45:16 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 16:03:42 GMT""}]","2021-11-17"
"2102.01633","Ji\v{r}\'i \v{S}\'ima","Ji\v{r}\'i \v{S}\'ima","Stronger Separation of Analog Neuron Hierarchy by Deterministic
  Context-Free Languages","30 pages, 4 figures",,,,"cs.NE cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the computational power of discrete-time recurrent neural networks
(NNs) with the saturated-linear activation function within the Chomsky
hierarchy. This model restricted to integer weights coincides with binary-state
NNs with the Heaviside activation function, which are equivalent to finite
automata (Chomsky level 3) recognizing regular languages (REG), while rational
weights make this model Turing-complete even for three analog-state units
(Chomsky level 0). For the intermediate model $\alpha$ANN of a binary-state NN
that is extended with $\alpha\geq 0$ extra analog-state neurons with rational
weights, we have established the analog neuron hierarchy 0ANNs $\subset$ 1ANNs
$\subset$ 2ANNs $\subseteq$ 3ANNs. The separation 1ANNs $\subsetneqq$ 2ANNs has
been witnessed by the non-regular deterministic context-free language (DCFL)
$L_\#=\{0^n1^n\mid n\geq 1\}$ which cannot be recognized by any 1ANN even with
real weights, while any DCFL (Chomsky level 2) is accepted by a 2ANN with
rational weights. In this paper, we strengthen this separation by showing that
any non-regular DCFL cannot be recognized by 1ANNs with real weights, which
means (DCFLs $\setminus$ REG) $\subset$ (2ANNs $\setminus$ 1ANNs), implying
1ANNs $\cap$ DCFLs = 0ANNs. For this purpose, we have shown that $L_\#$ is the
simplest non-regular DCFL by reducing $L_\#$ to any language in this class,
which is by itself an interesting achievement in computability theory.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:44:19 GMT""}]","2021-02-03"
"2102.01634","Luis Lomel\'i","Luis Guti\'errez Frez, Luis Lomel\'i and Jos\'e Pantoja","${\rm SL}_*$ over local and ad\`ele rings: $*$-euclideanity and Bruhat
  generators",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Let $(R,*)$ be a ring with involution and let $A = {\rm M}(n,R)$ be the
matrix ring endowed with the $*$-transpose involution. We study ${\rm
SL}_*(2,A)$ and the question of Bruhat generation over commutative and
non-commutative local and ad\`elic rings $R$. An important tool is the property
of a ring being $*$-Euclidean. In this regard, we introduce the notion of a
$*$-local ring $R$, prove that $A$ is $*$-Euclidean and explore reduction
modulo the Jacobson radical for such rings. Globally, we provide an affirmative
answer to the question wether a commutative ad\`elic ring $R$ leads towards the
ring $A$ being $*$-Euclidean; while the non-commutative ad\`elic quaternions
are such that $A$ is $*$-Euclidean and ${\rm SL}_*$ is generated by its Bruhat
elements if and only if the characteristic is $2$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:44:47 GMT""}]","2021-02-03"
"2102.01635","Barbara Verf\""urth","Axel M{\aa}lqvist and Barbara Verf\""urth","An offline-online strategy for multiscale problems with random defects",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an offline-online strategy based on the Localized
Orthogonal Decomposition (LOD) method for elliptic multiscale problems with
randomly perturbed diffusion coefficient. We consider a periodic deterministic
coefficient with local defects that occur with probability $p$. The offline
phase pre-computes entries to global LOD stiffness matrices on a single
reference element (exploiting the periodicity) for a selection of defect
configurations. Given a sample of the perturbed diffusion the corresponding LOD
stiffness matrix is then computed by taking linear combinations of the
pre-computed entries, in the online phase. Our computable error estimates show
that this yields a good coarse-scale approximation of the solution for small
$p$, which is illustrated by extensive numerical experiments. This makes the
proposed technique attractive already for moderate sample sizes in a Monte
Carlo simulation.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:45:49 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 06:40:07 GMT""},{""version"":""v3"",""created"":""Tue, 7 Dec 2021 11:34:12 GMT""}]","2021-12-08"
"2102.01636","Li Sun","Alain Hecq, Li Sun","Adaptive Random Bandwidth for Inference in CAViaR Models",,,,,"econ.EM stat.AP","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the size performance of Wald tests for CAViaR models
(Engle and Manganelli, 2004). We find that the usual estimation strategy on
test statistics yields inaccuracies. Indeed, we show that existing density
estimation methods cannot adapt to the time-variation in the conditional
probability densities of CAViaR models. Consequently, we develop a method
called adaptive random bandwidth which can approximate time-varying conditional
probability densities robustly for inference testing on CAViaR models based on
the asymptotic normality of the model parameter estimator. This proposed method
also avoids the problem of choosing an optimal bandwidth in estimating
probability densities, and can be extended to multivariate quantile regressions
straightforward.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:46:02 GMT""}]","2021-02-03"
"2102.01637","Giorgio Galanti","Giorgio Galanti, Marco Roncadelli","Precision cosmology made more precise","9 pages, 3 figures",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  So far, the standard attitude to solve the Friedmann equations in the
simultaneous presence of radiation $R$, matter $M$ and cosmological constant
${\Lambda}$ is to find solutions $R_R (t)$, $R_M (t)$ and $R_{\Lambda} (t)$
separately for each individual component alone, and next to join them together,
thereby obtaining a piecewise solution $R_{\rm pw} (t)$. We instead find the
exact and analytic solution $R (t)$ of the same equations in flat space.
Moreover, we quantify the error made when $R_{\rm pw} (t)$ is used in place of
$R (t)$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:46:29 GMT""}]","2021-02-03"
"2102.01638","Francesca Onori Dr","F. Onori, M. Fiocchi, N. Masetti, A. F. Rojas, A. Bazzano, L. Bassani,
  A.J. Bird","Multi-wavelength observations of the Galactic X-ray binaries IGR
  J20155+3827 and Swift J1713.4-4219","Accepted for publication in MNRAS",,"10.1093/mnras/stab315",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  In recent years, thanks to the continuous surveys performed by INTEGRAL and
Swift satellites, our knowledge of the hard X-ray/soft gamma-ray sky has
greatly improved. As a result it is now populated with about 2000 sources, both
Galactic and extra-galactic, mainly discovered by IBIS and BAT instruments.
Many different follow-up campaigns have been successfully performed by using a
multi-wavelength approach, shedding light on the nature of a number of these
new hard X-ray sources. However, a fraction are still of a unidentified nature.
This is mainly due to the lack of lower energy observations, which usually
deliver a better constrained position for the sources, and the unavailability
of the key observational properties, needed to obtain a proper physical
characterization. Here we report on the classification of two poorly studied
Galactic X-ray transients IGR J20155+3827 and Swift J1713.4-4219, for which the
combination of new and/or archival X-ray and Optical/NIR observations have
allowed us to pinpoint their nature. In particular, thanks to XMM\Newton
archival data together with new optical spectroscopic and archival Optical/NIR
photometric observations, we have been able to classify IGR J20155+3827 as a
distant HMXB. The new INTEGRAL and Swift data collected during the 2019 X-ray
outburst of Swift J1713.4-4219, in combination with the archival optical/NIR
observations, suggest a LMXB classification for this source.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:47:16 GMT""}]","2021-02-17"
"2102.01639","Xiao Lu","Xiao Lu, Dusit Niyato, Hai Jiang, Ekram Hossain and Ping Wang","Ambient Backscatter-Assisted Wireless-Powered Relaying","32 Pages, 11 Figs",,,,"cs.IT cs.NI math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  Internet-of-Things (IoT) is featured with low-power communications among a
massive number of ubiquitously-deployed and energy-constrained electronics,
e.g., sensors and actuators. To cope with the demand, wireless-powered
cooperative relaying emerges as a promising communication paradigm to extend
data transmission coverage and solve energy scarcity for the IoT devices. In
this paper, we propose a novel hybrid relaying strategy by combining
wireless-powered communication and ambient backscattering functions to improve
applicability and performance of data transfer. In particular, the hybrid relay
can harvest energy from radio frequency (RF) signals and use the energy for
active transmission. Alternatively, the hybrid relay can choose to perform
ambient backscattering of incident RF signals for passive transmission. To
efficiently utilize the ambient RF resource, we design mode selection protocols
to coordinate between the active and passive relaying in circumstances with and
without instantaneous channel gain. With different mode selection protocols, we
characterize the success probability and ergodic capacity of a dual-hop
relaying system with the hybrid relay in the field of randomly located ambient
transmitters. The analytical and the numerical results demonstrate the
effectiveness of the mode selection protocols in adapting the hybrid relaying
into the network environment and reveal the impacts of system parameters on the
performance gain of the hybrid relaying. As applications of our analytical
framework which is computationally tractable, we formulate optimization
problems based on the derived expressions to optimize the system parameters
with different objectives. The optimal solutions exhibit a tradeoff between the
maximum energy efficiency and target success probability.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:48:09 GMT""}]","2021-02-03"
"2102.01640","Debasish Mohapatra","Pramit Saha, Debasish Ray Mohapatra, Sidney Fels","SPEAK WITH YOUR HANDS Using Continuous Hand Gestures to control
  Articulatory Speech Synthesizer","2 pages, 1 figure",,,,"cs.SD cs.CL eess.AS","http://creativecommons.org/licenses/by/4.0/","  This work presents our advancements in controlling an articulatory speech
synthesis engine, \textit{viz.}, Pink Trombone, with hand gestures. Our
interface translates continuous finger movements and wrist flexion into
continuous speech using vocal tract area-function based articulatory speech
synthesis. We use Cyberglove II with 18 sensors to capture the kinematic
information of the wrist and the individual fingers, in order to control a
virtual tongue. The coordinates and the bending values of the sensors are then
utilized to fit a spline tongue model that smoothens out the noisy values and
outliers. Considering the upper palate as fixed and the spline model as the
dynamically moving lower surface (tongue) of the vocal tract, we compute 1D
area functional values that are fed to the Pink Trombone, generating continuous
speech sounds. Therefore, by learning to manipulate one's wrist and fingers,
one can learn to produce speech sounds just through one's hands, without the
need for using the vocal tract.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:49:51 GMT""}]","2021-02-03"
"2102.01641","Henry Cappel","Henry Fielding Cappel","A Hierarchical Multi-Robot Mapping Architecture Subject to Communication
  Constraints",,,,,"cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-robot systems are an efficient method to explore and map an unknown
environment. The simulataneous localization and mapping (SLAM) algorithm is
common for single robot systems, however multiple robots can share respective
map data in order to merge a larger global map. This thesis contributes to the
multi-robot mapping problem by considering cases in which robots have
communication range limitations. The architecture coordinates a team of robots
and the central server to explore an unknown environment by exploiting a
hierarchical choice structure. The coordination algorithms ensure that the
hierarchy of robots choose frontier points that provide maximum information
gain, while maintaining viable communication amongst themselves and the central
computer through an ad-hoc relay network. In addition, the robots employ a
backup choice algorithm in cases when no valid frontier points remain by
arranging the communication relay network as a fireline back to the source.
  This work contributes a scalable, efficient, and robust architecture towards
hybrid multi-robot mapping systems that take into account communication range
limitations. The architecture is tested in a simulation environment using
various maps.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:52:22 GMT""}]","2021-02-03"
"2102.01642","Ren\'e Wittmann","Ren\'e Wittmann, Louis B. G. Cortes, Hartmut L\""owen and Dirk G. A. L.
  Aarts","Particle-resolved topological defects of smectic colloidal liquid
  crystals in extreme confinement","Extended version of the article with integrated Supplementary
  Information. Published article available at https://rdcu.be/ceicY","Nature Communications 12, 623 (2021)","10.1038/s41467-020-20842-5",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Confined samples of liquid crystals are characterized by a variety of
topological defects and can be exposed to external constraints such as extreme
confinements with nontrivial topology. Here we explore the intrinsic structure
of smectic colloidal layers dictated by the interplay between entropy and an
imposed external topology. Considering an annular confinement as a basic
example, a plethora of competing states is found with nontrivial defect
structures ranging from laminar states to multiple smectic domains and arrays
of edge dislocations which we refer to as Shubnikov states in formal analogy to
the characteristic of type-II superconductors. Our particle-resolved results,
gained by a combination of real-space microscopy of thermal colloidal rods and
fundamental-measure-based density functional theory of hard anisotropic bodies,
agree on a quantitative level.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:53:20 GMT""}]","2021-02-03"
"2102.01643","Xiang Zhang","Xiang Zhang, Kai Wan, Hua Sun, Mingyue Ji, Giuseppe Caire","A New Design of Cache-aided Multiuser Private Information Retrieval with
  Uncoded Prefetching",,,,,"cs.IT cs.IR eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  In the problem of cache-aided multiuser private information retrieval
(MuPIR), a set of $K_{\rm u}$ cache-equipped users wish to privately download a
set of messages from $N$ distributed databases each holding a library of $K$
messages. The system works in two phases: {\it cache placement (prefetching)
phase} in which the users fill up their cache memory, and {\it private delivery
phase} in which the users' demands are revealed and they download an answer
from each database so that the their desired messages can be recovered while
each individual database learns nothing about the identities of the requested
messages. The goal is to design the placement and the private delivery phases
such that the \emph{load}, which is defined as the total number of downloaded
bits normalized by the message size, is minimized given any user memory size.
This paper considers the MuPIR problem with two messages, arbitrary number of
users and databases where uncoded prefetching is assumed, i.e., the users
directly copy some bits from the library as their cached contents. We propose a
novel MuPIR scheme inspired by the Maddah-Ali and Niesen (MAN) coded caching
scheme. The proposed scheme achieves lower load than any existing schemes,
especially the product design (PD), and is shown to be optimal within a factor
of $8$ in general and exactly optimal at very high or low memory regime.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:54:42 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 23:33:48 GMT""}]","2021-02-05"
"2102.01644","Jonathan Protzenko","Jonathan Protzenko, Son Ho","Zero-cost meta-programmed stateful functors in F*",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Writing code is hard; proving it correct is even harder. As the scale of
verified software projects reaches new heights, the problem of efficiently
verifying large amounts of software becomes more and more salient. Nowhere is
this issue more evident than in the context of verified cryptographic
libraries. To achieve feature-parity and be competitive with unverified
cryptographic libraries, a very large number of algorithms and APIs need to be
verified. However, the task is oftentimes repetitive, and factoring out
commonality between algorithms is fraught with difficulties, requiring until
now a significant amount of manual effort.
  This paper shows how a judicious combination of known functional programming
techniques leads to an order-of-magnitude improvement in the amount of verified
code produced by the popular HACL* cryptographic library, without compromising
performance. We review three techniques that build upon each other, in order of
increasing sophistication. First, we use dependent types to crisply capture the
specification and state machine of a block algorithm, a cryptographic notion
that was until now only informally and imprecisely specified. Next, we rely on
partial evaluation to author a higher-order, stateful functor that transforms
any unsafe block API into a safe counterpart. Finally, we rely on elaborator
reflection to automate the very process of authoring a functor, using a
code-rewriting tactic. This culminates in a style akin to templatized C++ code,
but relying on a userland tactic and partial evaluation, rather than built-in
compiler support.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:58:49 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 20:14:51 GMT""}]","2021-06-11"
"2102.01645","Federico Galatolo","Federico A. Galatolo and Mario G.C.A. Cimino and Gigliola Vaglini","Generating images from caption and vice versa via CLIP-Guided Generative
  Latent Space Search",,"IMPROVE, ISBN 978-989-758-511-1, pages 166-174 (2021)","10.5220/0010503701660174",,"cs.NE cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this research work we present CLIP-GLaSS, a novel zero-shot framework to
generate an image (or a caption) corresponding to a given caption (or image).
CLIP-GLaSS is based on the CLIP neural network, which, given an image and a
descriptive caption, provides similar embeddings. Differently, CLIP-GLaSS takes
a caption (or an image) as an input, and generates the image (or the caption)
whose CLIP embedding is the most similar to the input one. This optimal image
(or caption) is produced via a generative network, after an exploration by a
genetic algorithm. Promising results are shown, based on the experimentation of
the image Generators BigGAN and StyleGAN2, and of the text Generator GPT2
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:00:13 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 12:14:49 GMT""},{""version"":""v3"",""created"":""Fri, 26 Feb 2021 22:42:49 GMT""},{""version"":""v4"",""created"":""Fri, 1 Oct 2021 15:45:51 GMT""}]","2021-10-04"
"2102.01646","Steve Hanneke","Steve Hanneke, Roi Livni, and Shay Moran","Online Learning with Simple Predictors and a Combinatorial
  Characterization of Minimax in 0/1 Games",,,,,"cs.LG cs.DS cs.GT stat.ML","http://creativecommons.org/licenses/by/4.0/","  Which classes can be learned properly in the online model? -- that is, by an
algorithm that at each round uses a predictor from the concept class. While
there are simple and natural cases where improper learning is necessary, it is
natural to ask how complex must the improper predictors be in such cases. Can
one always achieve nearly optimal mistake/regret bounds using ""simple""
predictors?
  In this work, we give a complete characterization of when this is possible,
thus settling an open problem which has been studied since the pioneering works
of Angluin (1987) and Littlestone (1988). More precisely, given any concept
class C and any hypothesis class H, we provide nearly tight bounds (up to a log
factor) on the optimal mistake bounds for online learning C using predictors
from H. Our bound yields an exponential improvement over the previously best
known bound by Chase and Freitag (2020).
  As applications, we give constructive proofs showing that (i) in the
realizable setting, a near-optimal mistake bound (up to a constant factor) can
be attained by a sparse majority-vote of proper predictors, and (ii) in the
agnostic setting, a near-optimal regret bound (up to a log factor) can be
attained by a randomized proper algorithm.
  A technical ingredient of our proof which may be of independent interest is a
generalization of the celebrated Minimax Theorem (von Neumann, 1928) for binary
zero-sum games. A simple game which fails to satisfy Minimax is ""Guess the
Larger Number"", where each player picks a number and the larger number wins.
The payoff matrix is infinite triangular. We show this is the only obstruction:
if a game does not contain triangular submatrices of unbounded sizes then the
Minimax Theorem holds. This generalizes von Neumann's Minimax Theorem by
removing requirements of finiteness (or compactness), and captures precisely
the games of interest in online learning.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:02:01 GMT""}]","2021-02-03"
"2102.01648","Roman Jurowetzki","Roman Jurowetzki, Daniel Hain, Juan Mateos-Garcia, Konstantinos
  Stathoulopoulos","The Privatization of AI Research(-ers): Causes and Potential
  Consequences -- From university-industry interaction to public research
  brain-drain?",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The private sector is playing an increasingly important role in basic
Artificial Intelligence (AI) R&D. This phenomenon, which is reflected in the
perception of a brain drain of researchers from academia to industry, is
raising concerns about a privatisation of AI research which could constrain its
societal benefits. We contribute to the evidence base by quantifying transition
flows between industry and academia and studying its drivers and potential
consequences. We find a growing net flow of researchers from academia to
industry, particularly from elite institutions into technology companies such
as Google, Microsoft and Facebook. Our survival regression analysis reveals
that researchers working in the field of deep learning as well as those with
higher average impact are more likely to transition into industry. A
difference-in-differences analysis of the effect of switching into industry on
a researcher's influence proxied by citations indicates that an initial
increase in impact declines as researchers spend more time in industry. This
points at a privatisation of AI knowledge compared to a counterfactual where
those high-impact researchers had remained in academia. Our findings highlight
the importance of strengthening the public AI research sphere in order to
ensure that the future of this powerful technology is not dominated by private
interests.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:02:41 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 21:30:23 GMT""}]","2021-02-17"
"2102.01650","Natsumi Ikeno","Natsumi Ikeno, Melahat Bayar, Eulogio Oset","Combined theoretical study of the $D^+ \to \pi^+ \eta \eta$ and $D^+ \to
  \pi^+ \pi^0 \eta $ reactions","11 pages, 12 figures",,"10.1140/epjc/s10052-021-09174-w",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the $D^+ \to \pi^+ \eta \eta $ and $D^+ \to \pi^+ \pi^0 \eta$
reactions, which are single Cabibbo suppressed and can proceed both through
internal and external emission. The primary mechanisms at quark level are
considered, followed by hadronization to produce three mesons in the $D^+$
decay, and after that the final state interaction of these mesons leads to the
production of the $a_0(980)$ resonance, seen in the $\pi^+ \eta$, $\pi^0 \eta$
mass distributions. The theory has three unknown parameters to determine the
shape of the distributions and the ratio between the $D^+ \to \pi^+ \eta \eta$
and $D^+ \to \pi^+ \pi^0 \eta$ rates. This ratio restricts much the sets of
parameters but there is still much freedom leading to different shapes in the
mass distributions. We call for a measurement of these mass distributions that
will settle the reaction mechanism, while at the same time provide relevant
information on the way that the $a_0(980)$ resonance is produced in the
reactions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:04:04 GMT""}]","2021-05-19"
"2102.01651","Jiarong Hong","Kyungduck Yoon, Jiaqi Li, Siyao Shao, Ashish Karn, and Jiarong Hong","Insights into ventilation hysteresis shift due to flow unsteadiness in
  ventilated supercavitation","9 pages, 11 figures, preprint submitted to Experimental Thermal and
  Fluid Science",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Understanding ventilation strategy of a supercavity is important for
designing high-speed underwater vehicles wherein an artificial gas pocket is
created behind a flow separation device for drag reduction. Our study
investigates the effect of flow unsteadiness on the ventilation requirements to
form (CQf) and collapse (CQc) a supercavity. Imposing flow unsteadiness on the
incoming flow has shown an increment in higher CQf at low free stream velocity
and lower CQf at high free stream velocity. High-speed imaging reveals
distinctly different behaviors in the recirculation region for low and high
freestream velocity under unsteady flows. At low free stream velocities, the
recirculation region formed downstream of a cavitator shifted vertically with
flow unsteadiness, resulting in lower bubble collision and coalescence
probability, which is critical for the supercavity formation process. The
recirculation region negligibly changed with flow unsteadiness at high free
stream velocity and less ventilation is required to form a supercavity compared
to that of the steady incoming flow. Such a difference is attributed to the
increased transverse Reynolds stress that aids bubble collision in a confined
space of the recirculation region. CQc is found to heavily rely on the vertical
component of the flow unsteadiness and the free stream velocity. Interfacial
instability located upper rear of the supercavity develops noticeably with flow
unsteadiness and additional bubbles formed by the distorted interface shed from
the supercavity, resulting in an increased CQc. Further analysis on the
quantification of such additional bubble leakage rate indicates that the
development and amplitude of the interfacial instability accounts for the
variation of CQc under a wide range of flow unsteadiness. Our study provides
some insights on the design of a ventilation strategy for supercavitating
vehicles in practice.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:05:31 GMT""}]","2021-02-03"
"2102.01652","Gianmarco Manzini","Paola Francesca Antonietti, Gianmarco Manzini, Ilario Mazzieri, Simone
  Scacchi, Marco Verani","The conforming virtual element method for polyharmonic and
  elastodynamics problems: a review","30 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1912.07122",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we review recent results on the conforming virtual element
approximation of polyharmonic and elastodynamics problems. The structure and
the content of this review is motivated by three paradigmatic examples of
applications: classical and anisotropic Cahn-Hilliard equation and phase field
models for brittle fracture, that are briefly discussed in the first part of
the paper. We present and discuss the mathematical details of the conforming
virtual element approximation of linear polyharmonic problems, the classical
Cahn-Hilliard equation and linear elastodynamics problems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:10:59 GMT""}]","2021-02-03"
"2102.01653","Matteo Cardella Dr.","Matteo A. Cardella","A late times approximation for the SYK spectral form factor","v2: References added",,,,"hep-th cond-mat.dis-nn cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We find a late times approximation for the SYK spectral form factor from a
large $N$ steepest descent version of the path integral over two replica
collective fields. Main ingredients are a suitable uv regularization of the two
replica kinetic operator, the property of its Fourier transform and some
spectral analysis of the four point function two replica ladder kernel.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:11:40 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 16:32:42 GMT""}]","2021-02-24"
"2102.01654","Marco Lenci","Marco Lenci, Claudio Bonanno, Giampaolo Cristadoro","Internal-wave billiards in trapezoids and similar tables","Final preprint for Nonlinearity, 29 pages, 11 figures","Nonlinearity 36 (2023), no. 2, 1029-1052","10.1088/1361-6544/ac98ef",,"math.DS math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We call internal-wave billiard the dynamical system of a point particle that
moves freely inside a planar domain (the table) and is reflected by its
boundary according to this rule: reflections are standard Fresnel reflections
but with the pretense that the boundary at any collision point is either
horizontal or vertical (relative to a predetermined direction representing
gravity). These systems are point particle approximations for the motion of
internal gravity waves in closed containers, hence the name. For a class of
tables similar to rectangular trapezoids, but with the slanted leg replaced by
a general curve with downward concavity, we prove that the dynamics has only
three asymptotic regimes: (1) there exist a global attractor and a global
repellor, which are periodic and might coincide; (2) there exists a beam of
periodic trajectories, whose boundary (if any) comprises an attractor and a
repellor for all the other trajectories; (3) all trajectories are dense (that
is, the system is minimal). Furthermore, in the prominent case where the table
is an actual trapezoid, we study the sets in parameter space relative to the
three regimes. We prove in particular that the set for (1) has positive measure
(giving a rigorous proof of the existence of Arnol'd tongues for internal-wave
billiards), whereas the sets for (2) and (3) are non-empty but have measure
zero.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:12:03 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 15:19:47 GMT""},{""version"":""v3"",""created"":""Sat, 12 Feb 2022 12:28:58 GMT""},{""version"":""v4"",""created"":""Sun, 8 Jan 2023 14:06:35 GMT""}]","2023-01-10"
"2102.01655","Sophie Stevens","Ali Mohammadi, Sophie Stevens","Low-energy decomposition results over finite fields","20 pages, calculation error corrected",,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  We prove various low-energy decomposition results, showing that we can
decompose a finite set $A\subset \mathbb{F}_p$ satisfying $|A|<p^{5/8}$, into
$A = S\sqcup T$ so that, for a non-degenerate quadratic $f\in
\mathbb{F}_p[x,y]$, we have
  \[ |\{(s_1,s_2,s_3,s_4)\in S^4 : s_1 + s_2 = s_3 + s_4\}| \ll |A|^{3 -
\frac15 + \varepsilon}
  \] and
  \[
  |\{(t_1,t_2,t_3,t_4)\in T^4 : f(t_1, t_2) = f(t_3, t_4)\}|\ll |A|^{3 -
\frac15 + \varepsilon}\,.
  \]
  Variations include extending this result to large $A$ and a low-energy
decomposition involving additive energy of images of rational functions. This
gives a quantitative improvement to a result of Roche-Newton, Shparlinski and
Winterhof as well as a generalisation of a result of Rudnev, Shkredov and
Stevens.
  We consider applications to conditional expanders, exponential sum estimates
and the finite field Littlewood problem. In particular, we improve results of
Mirzaei, Swaenepoel and Winterhof and Garcia.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:12:23 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 17:44:53 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 14:10:43 GMT""}]","2021-07-07"
"2102.01656","Carola Dobrigkeit","X. Bertou, P.S. Allison, C. Bonifazi, P. Bauleo, C.M. Grunfeld, M.
  Aglietta, F. Arneodo, D. Barnhill, J.J. Beatty, N.G. Busca, A. Creusot, D.
  Dornic, A. Etchegoyen. A. Filevitch, P.L. Ghia, I. Lhenry-Yvon, M.C. Medina,
  E. Moreno, D. Nitz, T. Ohnuki, S. Ranchon, H. Salazar, T. Suomij\""arvi, D.
  Supanitsky, A. Tripathi, M. Urban, L. Villasenor (for the Pierre Auger
  Collaboration)","Calibration of the Surface Array of the Pierre Auger Observatory","8 pages, 6 figures","Nucl.Instrum.Meth.A 568 (2006) 839-846","10.1016/j.nima.2006.07.066","FERMILAB-PUB-21-033-AD-AE-E-TD","astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Pierre Auger Observatory is designed to study cosmic rays of the highest
energies ($>10^{19}$ eV). The ground array of the Observatory will consist of
1600 water Cherenkov detectors deployed over 3000 km^2. The remoteness and
large number of detectors require a robust, automatic self-calibration
procedure. It relies on the measurement of the average charge collected by a
photomultiplier tube from the Cherenkov light produced by a vertical and
central through-going muon determined to 5 - 10% at the detector via a novel
rate-based technique and to 3% precision through analysis of histograms of the
charge distribution. The parameters needed for the calibration are measured
every minute, allowing for an accurate determination of the signals recorded
from extensive air showers produced by primary cosmic rays. The method also
enables stable and uniform triggering conditions to be achieved.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:13:29 GMT""},{""version"":""v2"",""created"":""Sat, 13 Mar 2021 18:49:10 GMT""}]","2021-03-16"
"2102.01657","\'Akos Nagy","Benoit Charbonneau, Anuk Dayaprema, C. J. Lang, \'Akos Nagy, Haoyang
  Yu","Construction of Nahm data and BPS monopoles with continuous symmetries","37 pages, 1 table, 2 figures. Theorem 4.1 improved","Journal of Mathematical Physics, 63, Issue 1, 013507, 2022
  (Editor's Pick)","10.1063/5.0055913",,"math-ph hep-th math.DG math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study solutions to Nahm's equations with continuous symmetries and, under
certain (mild) hypotheses, we classify the corresponding Ans\""atze. Using our
classification, we construct novel Nahm data, and prescribe methods for
generating further solutions. Finally, we use these results to construct new
BPS monopoles with spherical symmetry.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:13:41 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 16:59:43 GMT""},{""version"":""v3"",""created"":""Mon, 3 May 2021 17:58:48 GMT""},{""version"":""v4"",""created"":""Mon, 31 Jan 2022 04:52:07 GMT""},{""version"":""v5"",""created"":""Mon, 14 Nov 2022 15:35:39 GMT""}]","2022-11-15"
"2102.01658","Pin-Jung Chiu","N. J. Ayres (1), G. Ban (2), G. Bison (3), K. Bodek (4), V. Bondar
  (1), P.-J. Chiu (1 and 3), B. Clement (5), C. B. Crawford (6), M. Daum (3),
  S. Emmenegger (1), M. Fertl (7), A. Fratangelo (8), W. C. Griffith (9), Z. D.
  Gruji\'c (10), P. G. Harris (9), K. Kirch (1 and 3), P. A. Koss (11), B.
  Lauss (3), T. Lefort (2), P. Mohanmurthy (1 and 3), O. Naviliat-Cuncic (2),
  D. Pais (1 and 3), F. M. Piegsa (8), G. Pignol (5), D. Rebreyend (5), I.
  Rien\""acker (1 and 3), D. Ries (12), S. Roccia (5 and 13), K. U. Ross (12),
  D. Rozpedzik (4), P. Schmidt-Wellenburg (3), A. Schnabel (14), N. Severijns
  (11), B. Shen (12), R. Tavakoli Dinani (11), J. A. Thorne (8), R. Virot (5),
  N. Yazdandoost (12), J. Zejma (4), and G. Zsigmond (3) ((1) ETH Z\""urich,
  Institute for Particle Physics and Astrophysics, Z\""urich, Switzerland, (2)
  Normandie Universit\'e, Ensicaen, Unicaen, CNRS/IN2P3, LPC Caen, Caen,
  France, (3) Paul Scherrer Institut, Villigen, Switzerland, (4) Marian
  Smoluchowski Institute of Physics, Jagiellonian University, Cracow, Poland,
  (5) Universit\'e Grenoble Alpes, CNRS, Grenoble INP, LPSC-IN2P3, Grenoble,
  France, (6) Department of Physics and Astronomy, University of Kentucky,
  Lexington, Kentucky, USA, (7) Institute of Physics, Johannes Gutenberg
  University Mainz, Mainz, Germany, (8) Laboratory for High Energy Physics and
  Albert Einstein Center for Fundamental Physics, University of Bern, Bern,
  Switzerland, (9) Department of Physics and Astronomy, University of Sussex,
  Falmer, Brighton, UK, (10) Institute of Physics Belgrade, University of
  Belgrade, Belgrade, Serbia, (11) Instituut voor Kern-en Stralingsfysica,
  University of Leuven, Leuven, Belgium, (12) Department of Chemistry - TRIGA
  site, Johannes Gutenberg University Mainz, Mainz, Germany, (13) Institut
  Laue-Langevin, Grenoble, France, (14) Physikalisch-Technische Bundesanstalt,
  Berlin, Germany)","Johnson-Nyquist Noise Effects in Neutron Electric-Dipole-Moment
  Experiments",,"Phys. Rev. A 103, 062801 (2021)","10.1103/PhysRevA.103.062801",,"nucl-ex physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Magnetic Johnson-Nyquist noise (JNN) originating from metal electrodes, used
to create a static electric field in neutron electric-dipole-moment (nEDM)
experiments, may limit the sensitivity of measurements. We present here the
first dedicated study on JNN applied to a large-scale long-measurement-time
experiment with the implementation of a co-magnetometry. In this study, we
derive surface- and volume-averaged root-mean-square normal noise amplitudes at
a certain frequency bandwidth for a cylindrical geometry. In addition, we model
the source of noise as a finite number of current dipoles and demonstrate a
method to simulate temporal and three-dimensional spatial dependencies of JNN.
The calculations are applied to estimate the impact of JNN on measurements with
the new apparatus, n2EDM, at the Paul Scherrer Institute. We demonstrate that
the performances of the optically pumped $^{133}$Cs magnetometers and
$^{199}$Hg co-magnetometers, which will be used in the apparatus, are not
limited by JNN. Further, we find that in measurements deploying a
co-magnetometer system, the impact of JNN is negligible for nEDM searches down
to a sensitivity of $4\,\times\,10^{-28}\,e\cdot{\rm cm}$ in a single
measurement; therefore, the use of economically and mechanically favored solid
aluminum electrodes is possible.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:14:03 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 12:17:14 GMT""}]","2021-07-12"
"2102.01659","Tobias Haug","Tobias Haug, Kishor Bharti, M. S. Kim","Capacity and quantum geometry of parametrized quantum circuits","13 pages, 12 figures. Code available at
  https://github.com/txhaug/quantum-geometry","PRX Quantum 2, 040309 (2021)","10.1103/PRXQuantum.2.040309",,"quant-ph cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To harness the potential of noisy intermediate-scale quantum devices, it is
paramount to find the best type of circuits to run hybrid quantum-classical
algorithms. Key candidates are parametrized quantum circuits that can be
effectively implemented on current devices. Here, we evaluate the capacity and
trainability of these circuits using the geometric structure of the parameter
space via the effective quantum dimension, which reveals the expressive power
of circuits in general as well as of particular initialization strategies. We
assess the expressive power of various popular circuit types and find striking
differences depending on the type of entangling gates used. Particular circuits
are characterized by scaling laws in their expressiveness. We identify a
transition in the quantum geometry of the parameter space, which leads to a
decay of the quantum natural gradient for deep circuits. For shallow circuits,
the quantum natural gradient can be orders of magnitude larger in value
compared to the regular gradient; however, both of them can suffer from
vanishing gradients. By tuning a fixed set of circuit parameters to randomized
ones, we find a region where the circuit is expressive, but does not suffer
from barren plateaus, hinting at a good way to initialize circuits. We show an
algorithm that prunes redundant parameters of a circuit without affecting its
effective dimension. Our results enhance the understanding of parametrized
quantum circuits and can be immediately applied to improve variational quantum
algorithms.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:16:57 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 16:54:47 GMT""}]","2022-02-28"
"2102.01660","Rodrigo Maier","Rafael F. Aranha, Carlos E. Cede\~no M., Rodrigo Maier, Ivano Dami\~ao
  Soares","Maxwell Fields in Boosted Kerr Black Holes",,,"10.1103/PhysRevD.103.064060",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spacetime of a boosted Bondi-Sachs rotating black hole is considered as a
proper background to examine electromagnetic configurations connected to
analytic solutions of Maxwell equations. In our analysis, we first use the
Bondi-Sachs transformations in order to bring the boosted rotating black hole
metric into the Kerr-Schild form, from which zero angular momentum observers
(ZAMOs) are constructed via the ADM formalism. In Kerr-Schild coordinates we
obtain the Killing fields as sources of Maxwell electrodynamics, and we fix a
ZAMO in order to evaluate the components of the electric and magnetic fields,
from which we obtain nonsingular patterns of an eventual momentum-energy
emission of a boosted Kerr-Schild black hole. Distinct patterns are examined
and discussed in the case of variations of the boost parameter $\gamma$. We
extend our analysis by considering the nonsingular electromagnetic emission in
the framework of a boosted Bondi-Sachs rotating black hole, as it moves at
relativistic speeds. We also discuss possible mechanisms that may resemble
magnetospheres of rotating boosted black holes and give rise to hydromagnetic
flows from accretion discs and to the production of jets.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:22:44 GMT""}]","2021-04-07"
"2102.01661","Grace Wolf-Chase","Grace Wolf-Chase, C. R. Kerton, Kathryn Devine, Anupa Pouydal, Johanna
  Mori, Leonardo Trujillo, Aurora Cossairt, Sarah Schoultz, Tharindu Jayasinghe
  and Matthew Povich","The Milky Way Project: Probing Star Formation with First Results on
  Yellowballs from DR2","24 pages, 10 figures (including two-panel Figure 8), to be published
  in ApJ",,"10.3847/1538-4357/abe87a",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Yellowballs (YBs) were first discovered during the Milky Way Project
citizen-science initiative (MWP; Simpson et al. 2012). MWP users noticed
compact, yellow regions in Spitzer Space Telescope mid-infrared (MIR) images of
the Milky Way plane and asked professional astronomers to explain these ""yellow
balls."" Follow-up work by Kerton et al. (2015) determined that YBs likely trace
compact photo-dissociation regions associated with massive and
intermediate-mass star formation. YBs were included as target objects in a
version of the Milky Way Project launched in 2016 (Jayasinghe et al. 2016),
which produced a listing of over 6000 YB locations. We have measured distances,
cross-match associations, physical properties, and MIR colors of ~500 YBs
within a pilot region covering the l= 30 - 40 degrees, b= +/- 1 degree region
of the Galactic plane. We find 20-30% of YBs in our pilot region contain
high-mass star formation capable of becoming expanding H II regions that
produce MIR bubbles. A majority of YBs represent intermediate-mass star-forming
regions whose placement in evolutionary diagrams suggest they are still
actively accreting, and may be precursors to optically-revealed Herbig Ae/Be
nebulae. Many of these intermediate-mass YBs were missed by surveys of massive
star-formation tracers and thus this catalog provides information for many new
sites of star formation. Future work will expand this pilot region analysis to
the entire YB catalog.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:22:47 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 17:09:10 GMT""}]","2021-04-21"
"2102.01662","Anoosheh Heidarzadeh","Nahid Esmati, Anoosheh Heidarzadeh, and Alex Sprintson","Private Linear Transformation: The Individual Privacy Case",,,,,"cs.IT cs.IR math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the single-server Private Linear Transformation (PLT)
problem when individual privacy is required. In this problem, there is a user
that wishes to obtain $L$ linear combinations of a $D$-subset of messages
belonging to a dataset of $K$ messages stored on a single server. The goal is
to minimize the download cost while keeping the identity of every message
required for the computation individually private. The individual privacy
requirement implies that, from the perspective of the server, every message is
equally likely to belong to the $D$-subset of messages that constitute the
support set of the required linear combinations. We focus on the setting in
which the matrix of coefficients pertaining to the required linear combinations
is the generator matrix of a Maximum Distance Separable code. We establish
lower and upper bounds on the capacity of PLT with individual privacy, where
the capacity is defined as the supremum of all achievable download rates. We
show that our bounds are tight under certain divisibility conditions. In
addition, we present lower bounds on the capacity of the settings in which the
user has a prior side information about a subset of messages.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:25:27 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 07:01:59 GMT""}]","2021-02-08"
"2102.01663","Sebastien Palcoux Dr.","Zhengwei Liu, Sebastien Palcoux, Yunxiang Ren","Interpolated family of non group-like simple integral fusion rings of
  Lie type","29 pages. Minor updates. Accepted in International Journal of
  Mathematics","Internat. J. Math. 34 (2023), no. 6, Paper No. 2350030, 51 pp","10.1142/S0129167X23500301",,"math.QA math.CT math.GR math.RA math.RT","http://creativecommons.org/licenses/by/4.0/","  This paper is motivated by the quest of a non-group irreducible finite index
depth 2 maximal subfactor. We compute the generic fusion rules of the
Grothendieck ring of Rep(PSL(2,q)), q prime-power, by applying a Verlinde-like
formula on the generic character table. We then prove that this family of
fusion rings R_q interpolates to all integers q>=2, providing (when q is not
prime-power) the first example of infinite family of non group-like simple
integral fusion rings. Furthermore, they pass all the known criteria of
(unitary) categorification. This provides infinitely many serious candidates
for solving the famous open problem of whether there exists an integral fusion
category which is not weakly group-theoretical. We prove that a complex
categorification (if any) of an interpolated fusion ring R_q (with q non
prime-power) cannot be braided, and so its Drinfeld center must be simple. In
general, this paper proves that a non-pointed simple fusion category is
non-braided if and only if its Drinfeld center is simple; and also that every
simple integral fusion category is weakly group-theoretical if and only if
every simple integral modular fusion category is pointed.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:31:32 GMT""},{""version"":""v2"",""created"":""Thu, 18 Aug 2022 05:10:13 GMT""},{""version"":""v3"",""created"":""Wed, 2 Nov 2022 12:39:20 GMT""},{""version"":""v4"",""created"":""Tue, 28 Feb 2023 15:08:17 GMT""}]","2023-06-06"
"2102.01664","Stefaan Vaes","Sorin Popa and Stefaan Vaes","W*-rigidity paradigms for embeddings of II$_1$ factors","v3: minor changes, final version, to appear in Communications in
  Mathematical Physics","Communications in Mathematical Physics 395 (2022), 907-961","10.1007/s00220-022-04446-2",,"math.OA math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We undertake a systematic study of W*-rigidity paradigms for the
embeddability relation $\hookrightarrow$ between separable II$_1$ factors and
its stable version $\hookrightarrow_s$, obtaining large families of non stably
isomorphic II$_1$ factors that are mutually embeddable and families of II$_1$
factors that are mutually non stably embeddable. We provide an augmentation
functor $G \mapsto H_G$ from the category of groups into icc groups, so that
$L(H_{G_1}) \hookrightarrow_s L(H_{G_2})$ iff $G_1 \hookrightarrow G_2$. We
construct complete intervals of II$_1$ factors, including a strict chain of
II$_1$ factors $(M_k)_{k\in \mathbb{Z}}$ with the property that if $N$ is any
II$_1$ factor with $M_i \hookrightarrow_s N$ and $N \hookrightarrow_s M_{j}$,
then $N \cong M_k^t$ for some $i \leq k \leq j$ and $t > 0$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:32:04 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 07:21:41 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 14:27:23 GMT""}]","2022-10-04"
"2102.01665","Anoosheh Heidarzadeh","Nahid Esmati, Anoosheh Heidarzadeh, and Alex Sprintson","Private Linear Transformation: The Joint Privacy Case","arXiv admin note: text overlap with arXiv:2102.01662",,,,"cs.IT cs.IR math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the problem of Private Linear Transformation (PLT). This problem
includes a single (or multiple) remote server(s) storing (identical copies of)
$K$ messages and a user who wants to compute $L$ linear combinations of a
$D$-subset of these messages by downloading the minimum amount of information
from the server(s) while protecting the privacy of the entire set of $D$
messages. This problem generalizes the Private Information Retrieval and
Private Linear Computation problems. In this work, we focus on the
single-server case. For the setting in which the coefficient matrix of the
required $L$ linear combinations generates a Maximum Distance Separable (MDS)
code, we characterize the capacity -- defined as the supremum of all achievable
download rates, for all parameters $K, D, L$. In addition, we present lower
and/or upper bounds on the capacity for the settings with non-MDS coefficient
matrices and the settings with a prior side information.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:35:51 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 17:10:36 GMT""}]","2021-02-07"
"2102.01666","Aljaz Godec","Alessio Lapolla, Jeremy C. Smith, Alja\v{z} Godec","Ubiquitous Dynamical Time Asymmetry in Measurements on Materials and
  Biological Systems",,,,,"cond-mat.stat-mech cond-mat.soft math-ph math.MP math.PR physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many measurements on soft condensed matter (e.g., biological and materials)
systems track low-dimensional observables projected from the full system phase
space as a function of time. Examples are dynamic structure factors,
spectroscopic and rheological response functions, and time series of distances
derived from optical tweezers, single-molecule spectroscopy and molecular
dynamics simulations. In many such systems the projection renders the reduced
dynamics non-Markovian and the observable is not prepared in, or initially
sampled from and averaged over, a stationary distribution. We prove that such
systems always exhibit non-equilibrium, time asymmetric dynamics. That is, they
evolve in time with a broken time-translation invariance in a manner closely
resembling aging dynamics. We identify the entropy associated with the breaking
of time-translation symmetry that is a measure of the instantaneous
thermodynamic displacement of latent, hidden degrees of freedom from their
stationary state. Dynamical time asymmetry is a general phenomenon, independent
of the underlying energy surface, and is frequently even visible in
measurements on systems that have fully reached equilibrium. This finding has
fundamental implications for the interpretation of many experiments on, and
simulations of, biological and materials systems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:37:25 GMT""}]","2021-02-03"
"2102.01667","Juan Antonio Aguilar-Saavedra","J. A. Aguilar-Saavedra","Pulling the Higgs and Top needles from the jet stack with Feature
  Extended Supervised Tagging","Published version, substantially enlarged: 5 -> 10 pages",,"10.1140/epjc/s10052-021-09530-w",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jet tagging has become an essential tool for new physics searches at the
high-energy frontier. For jets that contain energetic charged leptons we
introduce Feature Extended Supervised Tagging (FEST) which, in addition to jet
substructure, considers the features of the charged lepton within the jet. With
this method we build dedicated taggers to discriminate among boosted $H \to
\ell \nu q \bar q$, $t \to \ell \nu b$, and QCD jets (with $\ell$ an electron
or muon). The taggers have an impressive performance, allowing for overall
light jet rejection factors of $10^4-10^5$, for top quark / Higgs boson
efficiencies of $0.5$. The taggers are also excellent in the discrimination of
Higgs bosons from top quarks and vice versa, for example rejecting top quarks
by factors of $100-300$ for Higgs boson efficiencies of $0.5$. We demonstrate
the potential of these taggers to improve the sensitivity to new physics by
using as example a search for a new $Z'$ boson decaying into $Z H$, in the
fully-hadronic final state.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:37:38 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 08:53:46 GMT""}]","2021-09-01"
"2102.01668","Peter K.F. Kuhfittig","Peter K.F. Kuhfittig","Noncommutative-geometry wormholes with isotropic pressure","10 pages, no figures","Letters in High Energy Physics (LHEP), vol. 2021, ID: 190 (2021)",,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The strategy adopted in the original Morris-Thorne wormhole was to retain
complete control over the geometry at the expense of certain engineering
considerations. The purpose of this paper is to obtain several complete
wormhole solutions by assuming a noncommutative-geometry background with a
concomitant isotropic-pressure condition. This condition allows us to consider
a cosmological setting with a perfect-fluid equation of state. An extended form
of the equation generalizes the first solution and subsequently leads to the
generalized Chaplygin-gas model and hence to a third solution. The solutions
obtained extend several previous results. This paper also reiterates the need
for a noncommutative-geometry background to account for the enormous radial
tension that is characteristic of Morris-Thorne wormholes.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:38:58 GMT""}]","2021-02-03"
"2102.01669","Lisa Sauermann","Steven Klee, Bhargav Narayanan and Lisa Sauermann","Sharp estimates for spanning trees","It has been pointed out to us when this paper was under review that
  the results are not new; in fact a stronger bound was proved by Grone and
  Merris [Discrete Math. 69 (1988), 97-99]",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the following sharp estimate for the number of spanning trees of a
graph in terms of its vertex-degrees: a simple graph $G$ on $n$ vertices has at
most $(1/n^{2}) \prod_{v \in V(G)} (d(v)+1)$ spanning trees. This result is
tight (for complete graphs), and improves earlier estimates of Alon from 1990
and Kostochka from 1995 by a factor of about $1/n$ (for dense graphs). We
additionally show that an analogous bound holds for the weighted spanning tree
enumerator of a (nonnegatively) weighted graph as well.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:39:09 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 18:30:58 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 16:35:57 GMT""},{""version"":""v4"",""created"":""Tue, 12 Apr 2022 18:19:42 GMT""}]","2022-04-14"
"2102.01670","Kale-Ab Tessera","Kale-ab Tessera, Sara Hooker, Benjamin Rosman","Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network
  Optimization",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training sparse networks to converge to the same performance as dense neural
architectures has proven to be elusive. Recent work suggests that
initialization is the key. However, while this direction of research has had
some success, focusing on initialization alone appears to be inadequate. In
this paper, we take a broader view of training sparse networks and consider the
role of regularization, optimization, and architecture choices on sparse
models. We propose a simple experimental framework, Same Capacity Sparse vs
Dense Comparison (SC-SDC), that allows for a fair comparison of sparse and
dense networks. Furthermore, we propose a new measure of gradient flow,
Effective Gradient Flow (EGF), that better correlates to performance in sparse
networks. Using top-line metrics, SC-SDC and EGF, we show that default choices
of optimizers, activation functions and regularizers used for dense networks
can disadvantage sparse networks. Based upon these findings, we show that
gradient flow in sparse networks can be improved by reconsidering aspects of
the architecture design and the training regime. Our work suggests that
initialization is only one piece of the puzzle and taking a wider view of
tailoring optimization to sparse networks yields promising results.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:40:26 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 02:49:34 GMT""}]","2021-06-17"
"2102.01671","Mohammad Vahid Jamali","Mohammad Vahid Jamali, Xiyang Liu, Ashok Vardhan Makkuva, Hessam
  Mahdavifar, Sewoong Oh, Pramod Viswanath","Reed-Muller Subcodes: Machine Learning-Aided Design of Efficient Soft
  Recursive Decoding",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reed-Muller (RM) codes are conjectured to achieve the capacity of any
binary-input memoryless symmetric (BMS) channel, and are observed to have a
comparable performance to that of random codes in terms of scaling laws. On the
negative side, RM codes lack efficient decoders with performance close to that
of a maximum likelihood decoder for general parameters. Also, they only admit
certain discrete sets of rates. In this paper, we focus on subcodes of RM codes
with flexible rates that can take any code dimension from 1 to n, where n is
the blocklength. We first extend the recursive projection-aggregation (RPA)
algorithm proposed recently by Ye and Abbe for decoding RM codes. To lower the
complexity of our decoding algorithm, referred to as subRPA in this paper, we
investigate different ways for pruning the projections. We then derive the
soft-decision based version of our algorithm, called soft-subRPA, that is shown
to improve upon the performance of subRPA. Furthermore, it enables training a
machine learning (ML) model to search for \textit{good} sets of projections in
the sense of minimizing the decoding error rate. Training our ML model enables
achieving very close to the performance of full-projection decoding with a
significantly reduced number of projections. For instance, our simulation
results on a (64,14) RM subcode show almost identical performance for
full-projection decoding and pruned-projection decoding with 15 projections
picked via training our ML model. This is equivalent to lowering the complexity
by a factor of more than 4 without sacrificing the decoding performance.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:41:43 GMT""}]","2021-02-03"
"2102.01672","Sebastian Gehrmann","Sebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan Sasanka
  Ammanamanchi, Aremu Anuoluwapo, Antoine Bosselut, Khyathi Raghavi Chandu,
  Miruna Clinciu, Dipanjan Das, Kaustubh D. Dhole, Wanyu Du, Esin Durmus,
  Ond\v{r}ej Du\v{s}ek, Chris Emezue, Varun Gangal, Cristina Garbacea,
  Tatsunori Hashimoto, Yufang Hou, Yacine Jernite, Harsh Jhamtani, Yangfeng Ji,
  Shailza Jolly, Mihir Kale, Dhruv Kumar, Faisal Ladhak, Aman Madaan, Mounica
  Maddela, Khyati Mahajan, Saad Mahamood, Bodhisattwa Prasad Majumder, Pedro
  Henrique Martins, Angelina McMillan-Major, Simon Mille, Emiel van Miltenburg,
  Moin Nadeem, Shashi Narayan, Vitaly Nikolaev, Rubungo Andre Niyongabo,
  Salomey Osei, Ankur Parikh, Laura Perez-Beltrachini, Niranjan Ramesh Rao,
  Vikas Raunak, Juan Diego Rodriguez, Sashank Santhanam, Jo\~ao Sedoc, Thibault
  Sellam, Samira Shaikh, Anastasia Shimorina, Marco Antonio Sobrevilla
  Cabezudo, Hendrik Strobelt, Nishant Subramani, Wei Xu, Diyi Yang, Akhila
  Yerukola, Jiawei Zhou","The GEM Benchmark: Natural Language Generation, its Evaluation and
  Metrics",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce GEM, a living benchmark for natural language Generation (NLG),
its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly
evolving ecosystem of automated metrics, datasets, and human evaluation
standards. Due to this moving target, new models often still evaluate on
divergent anglo-centric corpora with well-established, but flawed, metrics.
This disconnect makes it challenging to identify the limitations of current
models and opportunities for progress. Addressing this limitation, GEM provides
an environment in which models can easily be applied to a wide set of tasks and
in which evaluation strategies can be tested. Regular updates to the benchmark
will help NLG research become more multilingual and evolve the challenge
alongside models. This paper serves as the description of the data for which we
are organizing a shared task at our ACL 2021 Workshop and to which we invite
the entire NLG community to participate.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:42:05 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 18:09:36 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 17:42:26 GMT""}]","2021-04-02"
"2102.01673","Benjamin Linowitz","Sara Lapan, Benjamin Linowitz, Jeffrey S. Meyer","Universal systole bounds for arithmetic locally symmetric spaces",,,,,"math.DG math.GT math.NT","http://creativecommons.org/licenses/by/4.0/","  The systole of a closed Riemannian manifold is the minimal length of a
non-contractible closed loop. We give a uniform lower bound for the systole for
large classes of simple arithmetic locally symmetric orbifolds. We establish
new bounds for the translation length of a semisimple element x in SL_n(R) in
terms of its associated Mahler measure. We use these geometric methods to prove
the existence of extensions of number fields in which fixed sets of primes have
certain prescribed splitting behavior.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:43:59 GMT""}]","2021-02-03"
"2102.01674","Alessandro Della Corte","Alessandro Della Corte, Stefano Isola, Riccardo Piergallini","The simplest erasing substitution",,,"10.1088/1361-6544/ac7690",,"math.DS","http://creativecommons.org/licenses/by/4.0/","  In this work, we begin the study of a new class of dynamical systems
determined by interval maps generated by the symbolic action of erasing
substitution rules. We do this by discussing in some detail the geometric,
analytical, dynamical and arithmetic properties of a particular example, which
has the virtue of being arguably the simplest and that at the same time
produces interesting properties and new challenging problems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:45:25 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 17:02:30 GMT""}]","2022-07-27"
"2102.01675","Jean-Yves Desaules","Jean-Yves Desaules, Ana Hudomal, Christopher J. Turner and Zlatko
  Papi\'c","A proposal for realising quantum scars in the tilted 1D Fermi-Hubbard
  model","13 pages, 15 figures","Phys. Rev. Lett. 126, 210601 (2021)","10.1103/PhysRevLett.126.210601",,"cond-mat.str-el cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by/4.0/","  Motivated by recent observations of ergodicity breaking due to Hilbert space
fragmentation in 1D Fermi-Hubbard chains with a tilted potential [Scherg et
al., arXiv:2010.12965], we show that the same system also hosts quantum
many-body scars in a regime $U\approx \Delta \gg J$ at electronic filling
factor $\nu=1$. We numerically demonstrate that the scarring phenomenology in
this model is similar to other known realisations such as Rydberg atom chains,
including persistent dynamical revivals and ergodicity-breaking many-body
eigenstates. At the same time, we show that the mechanism of scarring in the
Fermi-Hubbard model is different from other examples in the literature: the
scars originate from a subgraph, representing a free spin-1 paramagnet, which
is weakly connected to the rest of the Hamiltonian's adjacency graph. Our work
demonstrates that correlated fermions in tilted optical lattices provide a
platform for understanding the interplay of many-body scarring and other forms
of ergodicity breaking, such as localisation and Hilbert space fragmentation.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:47:01 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 14:35:27 GMT""}]","2021-08-16"
"2102.01676","Matteo Buzzegoli","M. Buzzegoli and Dmitri E. Kharzeev","Anomalous gravitomagnetic moment and non-universality of the axial
  vortical effect at finite temperature","37 pages, 2 figures; final version published in Phys Rev D","Phys. Rev. D 103, 116005 (2021)","10.1103/PhysRevD.103.116005",,"hep-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  The coupling between the spin of a massive Dirac fermion and the angular
momentum of the medium, i.e. the gravitomagnetic moment, is shown here to be
renormalized by QED interactions at finite temperature. This means that the
anomalous gravitomagnetic moment (AGM) does not vanish, and implies that
thermal effects can break the Einstein equivalence principle in quantum field
theory, as argued previously. We also show that the AGM causes radiative
corrections to the axial current of massive fermions induced by vorticity in
quantum relativistic fluids, similarly to the previous findings for massless
fermions. The radiative QCD effects on the AGM should significantly affect the
production of polarized hadrons in heavy-ion collisions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:47:27 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 19:11:25 GMT""}]","2021-06-16"
"2102.01677","Sajjad Marri","J. Esmaili, S. Marri, M. Raeisi and A. Naderi Beni","Trace of $\Lambda(1405)$ resonance in low energy $K^{-}+\,
  ^{3}\mathrm{He}\rightarrow (\pi^{0}\Sigma^{0})+d$ reaction","9 pages, 5 figures",,"10.1140/epja/s10050-021-00379-x",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In present work, we investigated $K^{-}+\, ^{3}\mathrm{He}$ reaction at low
energies. The coupled-channel Faddeev AGS equations were solved for
$\bar{K}Nd-\pi\Sigma{d}$ three-body system in momentum representation to
extract the scattering amplitudes. To trace the signature of the
$\Lambda$(1405) resonance in the $\pi\Sigma$ invariant mass, the deuteron
energy spectrum for $K^{-}+\,^{3}\mathrm{He}\rightarrow\pi\Sigma{d}$ reaction
was obtained. Different types of $\bar{K}N-\pi\Sigma$ potentials based on
phenomenological and chiral SU(3) approaches were used. As a remarkable result
of this investigation, it was found that the deuteron energy spectrum,
reflecting the $\Lambda$(1405) mass distribution and width, depends quite
sensitively on the $\bar{K}N-\pi\Sigma$ model of interaction. Hence accurate
measurements of the $\pi\Sigma$ mass distribution have the potential to
discriminate between possible mechanisms at work in the formation of the
$\Lambda$(1405).
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:50:14 GMT""}]","2021-04-28"
"2102.01678","Rikiya Yamashita","Rikiya Yamashita, Jin Long, Snikitha Banda, Jeanne Shen, Daniel L.
  Rubin","Learning domain-agnostic visual representation for computational
  pathology using medically-irrelevant style transfer augmentation",,,"10.1109/TMI.2021.3101985",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suboptimal generalization of machine learning models on unseen data is a key
challenge which hampers the clinical applicability of such models to medical
imaging. Although various methods such as domain adaptation and domain
generalization have evolved to combat this challenge, learning robust and
generalizable representations is core to medical image understanding, and
continues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation
for histoPathology), a form of data augmentation based on random style transfer
from non-medical style source such as artistic paintings, for learning
domain-agnostic visual representations in computational pathology. Style
transfer replaces the low-level texture content of an image with the
uninformative style of randomly selected style source image, while preserving
the original high-level semantic content. This improves robustness to domain
shift and can be used as a simple yet powerful tool for learning
domain-agnostic representations. We demonstrate that STRAP leads to
state-of-the-art performance, particularly in the presence of domain shifts, on
two particular classification tasks in computational pathology.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:50:16 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 23:07:49 GMT""}]","2021-08-04"
"2102.01679","Mikhail Petrov","A. A. Fomin, M. Yu. Petrov, G. G. Kozlov, A. K. Vershovskii, M. M.
  Glazov, and V. S. Zapasskii","Anomalous light-induced broadening of the spin-noise resonance in cesium
  vapor","9 pages, 9 figures, revised version","Phys. Rev. A 103, 042820 (2021)","10.1103/PhysRevA.103.042820",,"physics.optics physics.atom-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We uncover a highly nontrivial dependence of the spin-noise (SN) resonance
broadening induced by the intense probe beam. The measurements were performed
by probing the cell with cesium vapor at the wavelengths of the transition
${6}^2S_{1/2} \leftrightarrow {6}^2P_{3/2}$ ($\mathrm{D}_2$ line) with the
unresolved hyperfine structure of the excited state. The light-induced
broadening of the SN resonance was found to differ strongly at different slopes
of the $\mathrm{D}_2$ line and, generally, varied nonmonotonically with light
power. We discuss the effect in terms of the phenomenological Bloch equations
for the spin fluctuations and demonstrate that the SN broadening behavior
strongly depends on the relation between the pumping and excited-level decay
rates, the spin precession, and decoherence rates. To reconcile the puzzling
experimental results, we propose that the degree of optical perturbation of the
spin-system is controlled by the route of the excited-state relaxation of the
atom or, in other words, that the act of optical excitation of the atom does
not necessarily break down completely its ground-state coherence and continuity
of the spin precession. Spectral asymmetry of the effect, in this case, is
provided by the position of the ""closed"" transition $F = 4 \leftrightarrow F' =
5$ at the short-wavelength side of the line. This hypothesis, however, remains
to be proven by microscopic calculations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:50:32 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 20:33:00 GMT""}]","2021-05-03"
"2102.01680","Silvia Nagy","Miguel Campiglia and Silvia Nagy","A double copy for asymptotic symmetries in the self-dual sector","45 pages, 1 figure, replaced to match published version",,"10.1007/JHEP03(2021)262",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a double copy construction for the symmetries of the self-dual
sectors of Yang-Mills (YM) and gravity, in the light-cone formulation. We find
an infinite set of double copy constructible symmetries. We focus on two
families which correspond to the residual diffeomorphisms on the gravitational
side. For the first one, we find novel non-perturbative double copy rules in
the bulk. The second family has a more striking structure, as a
non-perturbative gravitational symmetry is obtained from a perturbatively
defined symmetry on the YM side.
  At null infinity, we find the YM origin of the subset of extended
Bondi-Metzner-Sachs (BMS) symmetries that preserve the self-duality condition.
In particular, holomorphic large gauge YM symmetries are double copied to
holomorphic supertranslations. We also identify the single copy of
superrotations with certain non-gauge YM transformations that to our knowledge
have not been previously presented in the literature.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:50:58 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 21:35:21 GMT""}]","2021-12-23"
"2102.01681","Walter Dempsey","Jieru Shi, Zhenke Wu, Walter Dempsey","Assessing Time-Varying Causal Effect Moderation in the Presence of
  Cluster-Level Treatment Effect Heterogeneity",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The micro-randomized trial (MRT) is a sequential randomized experimental
design to empirically evaluate the effectiveness of mobile health (mHealth)
intervention components that may be delivered at hundreds or thousands of
decision points. MRTs have motivated a new class of causal estimands, termed
""causal excursion effects"", for which semiparametric inference can be conducted
via a weighted, centered least squares criterion (Boruvka et al., 2018).
Existing methods assume between-subject independence and non-interference.
Deviations from these assumptions often occur. In this paper, causal excursion
effects are revisited under potential cluster-level treatment effect
heterogeneity and interference, where the treatment effect of interest may
depend on cluster-level moderators. Utility of the proposed methods is shown by
analyzing data from a multi-institution cohort of first year medical residents
in the United States.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:51:18 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 22:16:35 GMT""}]","2021-12-14"
"2102.01682","Antonio Corcoles","Antonio D. Corcoles, Maika Takita, Ken Inoue, Scott Lekuch, Zlatko K.
  Minev, Jerry M. Chow, Jay M. Gambetta","Exploiting dynamic quantum circuits in a quantum algorithm with
  superconducting qubits","7 pages, 4 figures, plus supplement","Phys. Rev. Lett. 127, 100501 (2021)","10.1103/PhysRevLett.127.100501",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The execution of quantum circuits on real systems has largely been limited to
those which are simply time-ordered sequences of unitary operations followed by
a projective measurement. As hardware platforms for quantum computing continue
to mature in size and capability, it is imperative to enable quantum circuits
beyond their conventional construction. Here we break into the realm of dynamic
quantum circuits on a superconducting-based quantum system. Dynamic quantum
circuits involve not only the evolution of the quantum state throughout the
computation, but also periodic measurements of a subset of qubits mid-circuit
and concurrent processing of the resulting classical information within
timescales shorter than the execution times of the circuits. Using noisy
quantum hardware, we explore one of the most fundamental quantum algorithms,
quantum phase estimation, in its adaptive version, which exploits dynamic
circuits, and compare the results to a non-adaptive implementation of the same
algorithm. We demonstrate that the version of real-time quantum computing with
dynamic circuits can offer a substantial and tangible advantage when noise and
latency are sufficiently low in the system, opening the door to a new realm of
available algorithms on real quantum systems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:51:23 GMT""}]","2021-09-08"
"2102.01683","Adam Freese","Adam Freese and Gerald A. Miller","Forces within hadrons on the light front","2 figures","Phys. Rev. D 103, 094023 (2021)","10.1103/PhysRevD.103.094023","NT@UW-21-02","hep-ph nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we find the light front densities for momentum and forces,
including pressure and shear forces, within hadrons. This is achieved by
deriving relativistically correct expressions relating these densities to the
gravitational form factors $A(t)$ and $D(t)$ associated with the energy
momentum tensor. The derivation begins from the fundamental definition of
density in a quantum field theory, namely the expectation value of a local
operator within a spatially-localized state. We find that it is necessary to
use the light front formalism to define a density that corresponds to internal
hadron structure. When using the instant form formalism, it is impossible to
remove the spatial extent of the hadron wave function from any density, and --
even within instant form dynamics -- one does not obtain a Breit frame Fourier
transform for a properly defined density. Within the front formalism, we derive
new expressions for various mechanical properties of hadrons, including the
mechanical radius, as well as for stability conditions. The multipole ansatz
for the form factors is used as an example to illustrate all of these findings.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:51:31 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 23:05:01 GMT""}]","2021-05-26"
"2102.01684","Jonathan Tidor","Aaron Berger, Ashwin Sah, Mehtaab Sawhney, and Jonathan Tidor","Popular differences for matrix patterns","24 pages","Trans. Amer. Math. Soc. 375 (2022), 2677--2704","10.1090/tran/8593",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The following combinatorial conjecture arises naturally from recent
ergodic-theoretic work of Ackelsberg, Bergelson, and Best. Let $M_1$, $M_2$ be
$k\times k$ integer matrices, $G$ be a finite abelian group of order $N$, and
$A\subseteq G^k$ with $|A|\ge\alpha N^k$. If $M_1$, $M_2$, $M_1-M_2$, and
$M_1+M_2$ are automorphisms of $G^k$, is it true that there exists a popular
difference $d \in G^k\setminus\{0\}$ such that \[\#\{x \in G^k: x, x+M_1d,
x+M_2d, x+(M_1+M_2)d \in A\} \ge (\alpha^4-o(1))N^k.\] We show that this
conjecture is false in general, but holds for $G = \mathbb{F}_p^n$ with $p$ an
odd prime given the additional spectral condition that no pair of eigenvalues
of $M_1M_2^{-1}$ (over $\overline{\mathbb{F}}_p$) are negatives of each other.
In particular, the ""rotated squares"" pattern does not satisfy this eigenvalue
condition, and we give a construction of a set of positive density in
$(\mathbb{F}_5^n)^2$ for which that pattern has no nonzero popular difference.
This is in surprising contrast to three-point patterns, which we handle over
all compact abelian groups and which do not require an additional spectral
condition.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:52:22 GMT""}]","2022-06-03"
"2102.01685","Ryan Carey","Tom Everitt, Ryan Carey, Eric Langlois, Pedro A Ortega, Shane Legg","Agent Incentives: A Causal Perspective","In Proceedings of the AAAI 2021 Conference. Supersedes
  arXiv:1902.09980, arXiv:2001.07118",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present a framework for analysing agent incentives using causal influence
diagrams. We establish that a well-known criterion for value of information is
complete. We propose a new graphical criterion for value of control,
establishing its soundness and completeness. We also introduce two new concepts
for incentive analysis: response incentives indicate which changes in the
environment affect an optimal decision, while instrumental control incentives
establish whether an agent can influence its utility via a variable X. For both
new concepts, we provide sound and complete graphical criteria. We show by
example how these results can help with evaluating the safety and fairness of
an AI system.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:52:41 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 20:08:39 GMT""}]","2021-03-17"
"2102.01686","Patrick G\""orrn","Andreas Henkel, Maik Meudt, Maximilian Buchm\""uller, and Patrick
  G\""orrn","Electrically Switchable Broadband Photonic Bound States in the Continuum",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The question of how to continuously manipulate a photonic system between a
radiating state and a bound state is an important challenge in photonics, as
its solution promises broad technological relevance for optical sensors,
modulators, switches and displays. Existing approaches utilise the inherent
wave-nature of electromagnetic fields to their advantage, and are commonly
identified as bound states in the continuum (BICs), as they resemble singular
bound states embedded in a band of radiating states. Although quasi-BICs have
been demonstrated for numerous symmetric periodic photonic crystals, their
existence so far has been limited to narrow spectral ranges, and their
application in switches or modulators needs large changes of the refractive
index. Here, we show that the incidence of two guided symmetric substrate waves
of opposite phase onto a symmetric periodic film waveguide enables the
excitation of self-stabilising BICs which are electrically switchable in a
broad optical range, with small changes of the refractive index. An
experimental verification of the concept shows a switching contrast C=700 at a
wavelength of 532 nm and C=1000 at a wavelength of 632.8 nm.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:54:02 GMT""}]","2021-02-03"
"2102.01687","Ignacio Laguna","Hal Finkel, Ignacio Laguna","Report of the Workshop on Program Synthesis for Scientific Computing","29 pages, workshop website:
  https://prog-synth-science.github.io/2020/",,,,"cs.LG cs.AI cs.PL cs.SE","http://creativecommons.org/licenses/by/4.0/","  Program synthesis is an active research field in academia, national labs, and
industry. Yet, work directly applicable to scientific computing, while having
some impressive successes, has been limited. This report reviews the relevant
areas of program synthesis work for scientific computing, discusses successes
to date, and outlines opportunities for future work. This report is the result
of the Workshop on Program Synthesis for Scientific Computing was held
virtually on August 4-5 2020 (https://prog-synth-science.github.io/2020/).
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:55:23 GMT""}]","2021-02-03"
"2102.01688","Joa Weber","Urs Frauenfelder and Joa Weber","The regularized free fall I -- Index computations","34 pages, 5 figures, v2: change of notation","Russian Journal of Mathematical Physics 28 no.4 (2021), 464-487","10.1134/S1061920821040063",,"math.SG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Main results are, firstly, a generalization of the Conley-Zehnder index from
ODEs to the delay equation at hand and, secondly, the equality of the Morse
index and the clockwise normalized Conley-Zehnder index.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:56:42 GMT""},{""version"":""v2"",""created"":""Sun, 17 Oct 2021 14:04:18 GMT""}]","2022-10-20"
"2102.01689","Alessandro Alberto Trani","Alessandro Alberto Trani, Ataru Tanikawa, Michiko S. Fujii, Nathan
  W.C. Leigh, Jun Kumamoto","Spin misalignment of black hole binaries from young star clusters:
  implications for the origin of gravitational waves events","10 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab967",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies indicate that the progenitors of merging black hole (BH)
binaries from young star clusters can undergo a common envelope phase just like
isolated binaries. If the stars emerge from the common envelope as naked cores,
tidal interactions can efficiently synchronize their spins before they collapse
into BHs. Contrary to the isolated case, these binary BHs can also undergo
dynamical interactions with other BHs in the cluster before merging. The
interactions can tilt the binary orbital plane, leading to spin-orbit
misalignment. We estimate the spin properties of merging binary BHs undergoing
this scenario by combining up-to-date binary population synthesis and accurate
few-body simulations. We show that post-common envelope binary BHs are likely
to undergo only a single encounter, due to the high binary recoil velocity and
short coalescence times. Adopting conservative limits on the binary-single
encounter rates, we obtain a local BH merger rate density of ~6.6 yr^-1 Gpc^-3.
Assuming low (<0.2) natal BH spins, this scenario reproduces the trends in the
distributions of effective spin Xeff and precession parameters Xp inferred from
GWTC-2, including the peaks at (Xeff, Xp) ~ (0.1, 0.2) and the tail at negative
Xeff values.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:58:02 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 12:49:56 GMT""}]","2021-04-21"
"2102.01690","Wei-Lin Hsiao","Wei-Lin Hsiao, Kristen Grauman","From Culture to Clothing: Discovering the World Events Behind A Century
  of Fashion Images","Accepted to ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fashion is intertwined with external cultural factors, but identifying these
links remains a manual process limited to only the most salient phenomena. We
propose a data-driven approach to identify specific cultural factors affecting
the clothes people wear. Using large-scale datasets of news articles and
vintage photos spanning a century, we present a multi-modal statistical model
to detect influence relationships between happenings in the world and people's
choice of clothing. Furthermore, on two image datasets we apply our model to
improve the concrete vision tasks of visual style forecasting and photo
timestamping. Our work is a first step towards a computational, scalable, and
easily refreshable approach to link culture to clothing.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:58:21 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 18:41:00 GMT""}]","2021-09-22"
"2102.01691","Adri\`a Garriga-Alonso","Adri\`a Garriga-Alonso and Vincent Fortuin","Exact Langevin Dynamics with Stochastic Gradients","13 pages, 2 figures. Accepted to the 3rd Symposium on Advances in
  Approximate Bayesian Inference (AABI 2021)",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Stochastic gradient Markov Chain Monte Carlo algorithms are popular samplers
for approximate inference, but they are generally biased. We show that many
recent versions of these methods (e.g. Chen et al. (2014)) cannot be corrected
using Metropolis-Hastings rejection sampling, because their acceptance
probability is always zero. We can fix this by employing a sampler with
realizable backwards trajectories, such as Gradient-Guided Monte Carlo
(Horowitz, 1991), which generalizes stochastic gradient Langevin dynamics
(Welling and Teh, 2011) and Hamiltonian Monte Carlo. We show that this sampler
can be used with stochastic gradients, yielding nonzero acceptance
probabilities, which can be computed even across multiple steps.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:59:31 GMT""}]","2021-02-03"
"2102.01693","Lakshya Bhardwaj","Lakshya Bhardwaj, Max Hubner, Sakura Schafer-Nameki","1-form Symmetries of 4d N=2 Class S Theories","62 pages, 43 TikZ figures; v2: Important typos corrected","SciPost Phys. 11, 096 (2021)","10.21468/SciPostPhys.11.5.096",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the 1-form symmetry group for any 4d N = 2 class S theory
constructed by compactifying a 6d N=(2,0) SCFT on a Riemann surface with
arbitrary regular untwisted and twisted punctures. The 6d theory has a group of
mutually non-local dimension-2 surface operators, modulo screening.
Compactifying these surface operators leads to a group of mutually non-local
line operators in 4d, modulo screening and flavor charges. Complete
specification of a 4d theory arising from such a compactification requires a
choice of a maximal subgroup of mutually local line operators, and the 1-form
symmetry group of the chosen 4d theory is identified as the Pontryagin dual of
this maximal subgroup. We also comment on how to generalize our results to
compactifications involving irregular punctures. Finally, to complement the
analysis from 6d, we derive the 1-form symmetry from a Type IIB realization of
class S theories.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 17:39:40 GMT""}]","2021-12-01"
"2102.01694","Sean Ressler","Sean M. Ressler, Eliot Quataert, Christopher J. White, Omer Blaes","Magnetically Modified Spherical Accretion in GRMHD: Reconnection-Driven
  Convection and Jet Propagation","Accepted by MNRAS. For animations see
  [https://smressle.bitbucket.io/animations.html]",,"10.1093/mnras/stab311",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present 3D general relativistic magnetohydrodynamic(GRMHD) simulations of
zero angular momentum accretion around a rapidly rotating black hole, modified
by the presence of initially uniform magnetic fields. We consider serveral
angles between the magnetic field direction and the black hole spin. In the
resulting flows, the midplane dynamics are governed by magnetic
reconnection-driven turbulence in a magnetically arrested (or a nearly
arrested) state. Electromagnetic jets with outflow efficiencies ~10-200% occupy
the polar regions, reaching several hundred gravitational radii before they
dissipate due to the kink instability. The jet directions fluctuate in time and
can be tilted by as much as ~30 degrees with respect to black hole spin, but
this tilt does not depend strongly on the tilt of the initial magnetic field. A
jet forms even when there is no initial net vertical magnetic flux since
turbulent, horizon-scale fluctuations can generate a net vertical field
locally. Peak jet power is obtained for an initial magnetic field tilted by
40-80 degrees with respect to the black hole spin because this maximizes the
amount of magnetic flux that can reach the black hole. These simulations may be
a reasonable model for low luminosity black hole accretion flows such as Sgr A*
or M87.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:00 GMT""}]","2021-02-17"
"2102.01695","Francisco Leal Machado","Antonis Kyprianidis, Francisco Machado, William Morong, Patrick
  Becker, Kate S. Collins, Dominic V. Else, Lei Feng, Paul W. Hess, Chetan
  Nayak, Guido Pagano, Norman Y. Yao, Christopher Monroe","Observation of a prethermal discrete time crystal","9 + 10 pages, 3 + 6 figures","Science 372, 1192-1196 (2021)","10.1126/science.abg8102",,"quant-ph cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conventional framework for defining and understanding phases of matter
requires thermodynamic equilibrium. Extensions to non-equilibrium systems have
led to surprising insights into the nature of many-body thermalization and the
discovery of novel phases of matter, often catalyzed by driving the system
periodically. The inherent heating from such Floquet drives can be tempered by
including strong disorder in the system, but this can also mask the generality
of non-equilibrium phases. In this work, we utilize a trapped-ion quantum
simulator to observe signatures of a non-equilibrium driven phase without
disorder: the prethermal discrete time crystal (PDTC). Here, many-body heating
is suppressed not by disorder-induced many-body localization, but instead via
high-frequency driving, leading to an expansive time window where
non-equilibrium phases can emerge. We observe a number of key features that
distinguish the PDTC from its many-body-localized disordered counterpart, such
as the drive-frequency control of its lifetime and the dependence of
time-crystalline order on the energy density of the initial state. Floquet
prethermalization is thus presented as a general strategy for creating,
stabilizing and studying intrinsically out-of-equilibrium phases of matter.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:00 GMT""}]","2021-06-30"
"2102.01696","Lado Samushia","Lado Samushia, Zachary Slepian, Francisco Villaescusa-Navarro","Information Content of Higher-Order Galaxy Correlation Functions","14 pages, 5 figures. Summitted to the Monthly Notices of the Royal
  Astronomical Society",,"10.1093/mnras/stab1199",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The shapes of galaxy N-point correlation functions can be used as standard
rulers to constrain the distance-redshift relationship and thence the expansion
rate of the Universe. The cosmological density fields traced by late-time
galaxy formation are initially nearly Gaussian, and hence all the cosmological
information can be extracted from their 2-Point Correlation Function (2PCF) or
its Fourier-space analog the power spectrum. Subsequent nonlinear evolution
under gravity, as well as halo and then galaxy formation, generate higher-order
correlation functions. Since the mapping of the initial to the final density
field is, on large scales, invertible, it is often claimed that the information
content of the initial field's power spectrum is equal to that of all the
higher-order functions of the final, nonlinear field. This claim implies that
reconstruction of the initial density field from the nonlinear field renders
analysis of higher-order correlation functions of the latter superfluous. We
here show that this claim is false when the N-point functions are used as
standard rulers. Constraints available from joint analysis of the galaxy power
spectrum and bispectrum (Fourier-space analog of the 3-Point Correlation
Function) can, in some cases, exceed those offered by the initial power
spectrum even when the reconstruction is perfect. We provide a mathematical
justification for this claim and also demonstrate it using a large suite of
N-body simulations. In particular, we show that for the z = 0 real-space matter
field in the limit of vanishing shot noise, taking modes up to k_max = 0.2
h/Mpc, using the bispectrum alone offers a factor of two reduction in the
variance on the cosmic distance scale relative to that available from the power
spectrum.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:00 GMT""}]","2021-07-07"
"2102.01697","Rodrigo Luger","Rodrigo Luger, Daniel Foreman-Mackey, and Christina Hedges","Mapping stellar surfaces II: An interpretable Gaussian process model for
  light curves","91 pages, 30 figures. Updated references. Interactive visualization
  at http://starry-process.flatironinstitute.org",,"10.3847/1538-3881/abfdb9",,"astro-ph.SR astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of Gaussian processes (GPs) as models for astronomical time series
datasets has recently become almost ubiquitous, given their ease of use and
flexibility. GPs excel in particular at marginalization over the stellar signal
in cases where the variability due to starspots rotating in and out of view is
treated as a nuisance, such as in exoplanet transit modeling. However, these
effective models are less useful in cases where the starspot signal is of
primary interest since it is not obvious how the parameters of the GP model are
related to the physical properties of interest, such as the size, contrast, and
latitudinal distribution of the spots. Instead, it is common practice to
explicitly model the effect of individual starspots on the light curve and
attempt to infer their properties via optimization or posterior inference.
Unfortunately, this process is degenerate, ill-posed, and often computationally
intractable when applied to stars with more than a few spots and/or to
ensembles of many light curves. In this paper, we derive a closed-form
expression for the mean and covariance of a Gaussian process model that
describes the light curve of a rotating, evolving stellar surface conditioned
on a given distribution of starspot sizes, contrasts, and latitudes. We
demonstrate that this model is correctly calibrated, allowing one to robustly
infer physical parameters of interest from one or more stellar light curves,
including the typical radii and the mean and variance of the latitude
distribution of starspots. Our GP has far-ranging implications for
understanding the variability and magnetic activity of stars from both light
curves and radial velocity (RV) measurements, as well as for robustly modeling
correlated noise in both transiting and RV exoplanet searches. Our
implementation is efficient, user-friendly, and open source, available as the
Python package starry-process.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 20:35:49 GMT""}]","2021-09-08"
"2102.01698","Fran Lane Dr","F. C. Lane, A. N. Taylor and D. Sorini","The Cosmological Trajectories Method: Modelling cosmic structure
  formation in the non-linear regime","15 pages, 8 figures. CTM code available at
  https://github.com/franlane94/CTM",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel approach, the Cosmological Trajectories Method (CTM), to
model nonlinear structure formation in the Universe by expanding
gravitationally-induced particle trajectories around the Zel'dovich
approximation. A new Beyond Zel'dovich approximation is presented, which
expands the CTM to leading second-order in the gravitational interaction and
allows for post-Born gravitational scattering. In the Beyond Zel'dovich
approximation we derive the exact expression for the matter clustering power
spectrum. This is calculated to leading order and is available in the CTM
MODULE. We compare the Beyond Zel'dovich approximation power spectrum and
correlation function to other methods including 1-loop Standard Perturbation
Theory (SPT), 1-loop Lagrangian Perturbation Theory (LPT) and Convolution
Lagrangian Perturbation Theory (CLPT). We find that the Beyond Zel'dovich
approximation power spectrum performs well, matching simulations to within
$\pm{10}\%$, on mildly non-linear scales, and at redshifts above $z=1$ it
outperforms the Zel'dovich approximation. We also find that the Beyond
Zel'dovich approximation models the BAO peak in the correlation function at
$z=0$ more accurately, to within $\pm{5}\%$ of simulations, than the Zel'dovich
approximation, SPT 1-loop and CLPT.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""}]","2021-02-04"
"2102.01699","Charlotte Beneke","Charlotte Beneke and Matthias Vojta","Divergence of the Gr\""uneisen ratio at symmetry-enhanced first-order
  quantum phase transitions","10 pages, 7 figures","Phys. Rev. B 103, 174420 (2021)","10.1103/PhysRevB.103.174420",,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies of the Gr\""uneisen ratio, i.e., the ratio between thermal expansion
and specific heat, have become a powerful tool in the context of quantum
criticality, since it was shown theoretically that the Gr\""uneisen ratio
displays characteristic power-law divergencies upon approaching the transition
point of a continuous quantum phase transition. Here we show that the
Gr\""uneisen ratio also diverges at a symmetry-enhanced first-order quantum
phase transition, albeit with mean-field exponents, as the enhanced symmetry
implies the vanishing of a mode gap which is finite away from the transition.
We provide explicit results for simple pseudo-spin models, both with and
without Goldstone modes in the stable phases, and discuss implications.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 21:02:54 GMT""}]","2021-06-08"
"2102.01700","Chenyuan Li","Chenyuan Li, Darshan G. Joshi, Subir Sachdev","Critical anomalous metals near superconductivity in models with random
  interactions","54 pages, 5 figures","Phys. Rev. B 103, 115147 (2021)","10.1103/PhysRevB.103.115147",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomalous metals are observed in numerous experiments on disordered
two-dimensional systems proximate to superconductivity. A characteristic
feature of an anomalous metal is that its low temperature conductivity has a
weakly temperature dependent value, significantly higher than that of a
disordered Fermi liquid. We propose a dynamical mean-field model of an
anomalous metal: interacting electrons similar in structure to that of the
well-studied universal Hamiltonian of mesoscopic metallic grains, but with
independent random interactions between pairs of sites, involving Cooper pair
hopping and spin exchange. We find evidence for critical anomalous phases or
points between a superconducting phase and a disordered Fermi liquid phase in
this model. Our results are obtained by a renormalization group analysis in a
weak coupling limit, and a complementary solution at large $M$ when the spin
symmetry is generalized to USp($M$). The large $M$ limit describes the
anomalous metal by fractionalization of the electron into spinons, holons, and
doublons, with these partons forming critical non-Fermi liquids in the
Sachdev-Ye-Kitaev class. We compute the low temperature conductivity in the
large $M$ limit, and find temperature-independent values moderately enhanced
from that in the disordered metal.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 20:09:56 GMT""}]","2021-03-31"
"2102.01701","Jun-Sung Moon","Jun-Sung Moon, Sung-Ho An, Suk-Jin Yoon","Living with Neighbors. III. The Origin of the Spin$-$Orbit Alignment of
  Galaxy Pairs: A Neighbor versus the Large-scale Structure","16 pages, 12 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abda3b",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations revealed a coherence between the spin vector of a galaxy
and the orbital motion of its neighbors. We refer to the phenomenon as ""the
spin$-$orbit alignment (SOA)"" and explore its physical origin via the
IllustrisTNG simulation. This is the first study to utilize a cosmological
hydrodynamic simulation to investigate the SOA of galaxy pairs. In particular,
we identify paired galaxies at $z = 0$ having the nearest neighbor with mass
ratios from 1/10 to 10 and calculate the spin$-$orbit angle for each pair. Our
results are as follows. (a) There exists a clear preference for prograde
orientations (i.e., SOA) for galaxy pairs, qualitatively consistent with
observations. (b) The SOA is significant for both baryonic and dark matter
spins, being the strongest for gas and the weakest for dark matter. (c) The SOA
is stronger for less massive targets and for targets having closer neighbors.
(d) The SOA strengthens for galaxies in low-density regions, and the signal is
dominated by central$-$satellite pairs in low-mass halos. (e) There is an
explicit dependence of the SOA on the duration of interaction with its current
neighbor. Taken together, we propose that the SOA witnessed at $z = 0$ has been
developed mainly by interactions with a neighbor for an extended period of
time, rather than tidal torque from the ambient large-scale structure.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""}]","2021-03-10"
"2102.01702","Craig Anderson","C. S. Anderson, G. H. Heald, J. A. Eilek, E. Lenc, B. M. Gaensler,
  Lawrence Rudnick, C. L. Van Eck, S. P. O'Sullivan, J. M. Stil, A.
  Chippendale, C. J. Riseley, E. Carretti, J. West, J. Farnes, L. Harvey-Smith,
  N. M. McClure-Griffiths, Douglas C. J. Bock, J. D. Bunton, B. Koribalski, C.
  D. Tremblay, M. A. Voronkov, K. Warhurst","Early Science from POSSUM: Shocks, turbulence, and a massive new
  reservoir of ionised gas in the Fornax cluster","Accepted for publication in PASA. 27 pages, 14 figures, 1 table",,"10.1017/pasa.2021.4",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the first Faraday rotation measure (RM) grid study of an
individual low-mass cluster -- the Fornax cluster -- which is presently
undergoing a series of mergers. Exploiting commissioning data for the
POlarisation Sky Survey of the Universe's Magnetism (POSSUM) covering a
$\sim34$ square degree sky area using the Australian Square Kilometre Array
Pathfinder (ASKAP), we achieve an RM grid density of $\sim25$ RMs per square
degree from a 280 MHz band centred at 887 MHz, which is similar to expectations
for forthcoming GHz-frequency all-sky surveys. We thereby probe the extended
magnetoionic structure of the cluster in unprecedented detail. We find that the
scatter in the Faraday RM of confirmed background sources is increased by
$16.8\pm2.4$ rad m$^{-2}$ within 1 degree (360 kpc) projected distance to the
cluster centre, which is 2--4 times more extended than the presently-detectable
X-ray-emitting intracluster medium (ICM). The Faraday-active plasma is more
massive than the X-ray-emitting ICM, with an average density that broadly
matches expectations for the Warm-Hot Intergalactic Medium. The morphology of
the Faraday depth enhancement exhibits the classic morphology of an
astrophysical bow shock on the southwest side of the main Fornax cluster, and
an extended, swept-back wake on the northeastern side. Our favoured explanation
is an ongoing merger between the main cluster and a sub-cluster to the
southwest. The shock's Mach angle and stand-off distance lead to a
self-consistent transonic merger speed with Mach 1.06. The region hosting the
Faraday depth enhancement shows a decrement in both total and polarised
intensity. We fail to identify a satisfactory explanation for this; further
observations are warranted. Generally, our study illustrates the scientific
returns that can be expected from all-sky grids of discrete sources generated
by forthcoming all-sky radio surveys.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""}]","2021-04-28"
"2102.01703","Alexandre Pombo","Carlos A. R. Herdeiro, Alexandre M. Pombo, Eugen Radu, Pedro V. P.
  Cunha and Nicolas Sanchis-Gual","The imitation game: Proca stars that can mimic the Schwarzschild shadow","Abstract abridged due to arXiv length limit; 22 pages, 9 figures",,"10.1088/1475-7516/2021/04/051",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Can a dynamically robust bosonic star (BS) produce an (effective) shadow that
mimics that of a black hole (BH)? The BH shadow is linked to the existence of
light rings (LRs). For free bosonic fields, yielding mini-BSs, it is known that
these stars can become ultra-compact - i.e., possess LRs - but only for
perturbatively unstable solutions. We show this remains the case even when
different self-interactions are considered. However, an effective shadow can
arise in a different way: if BSs reproduce the existence of an innermost stable
circular orbit (ISCO) for timelike geodesics (located at $r_{\rm ISCO}=6M$ for
a Schwarzschild BH of mass M), the accretion flow morphology around BHs is
mimicked and an effective shadow arises in an astrophysical environment. Even
though spherical BSs may accommodate stable timelike circular orbits all the
way down to their centre, we show the angular velocity along such orbits may
have a maximum away from the origin, at $R_{\Omega}$; this scale was recently
observed to mimic the BH's ISCO in some scenarios of accretion flow. Then: (i)
for free scalar fields or with quartic self-interactions, $R_{\Omega}\neq 0$
only for perturbatively unstable BSs; (ii) for higher scalar self-interactions,
e.g. axionic, $R_{\Omega}\neq 0$ is possible for perturbatively stable BSs, but
no solution with $R_{\Omega}=6M$ was found in the parameter space explored;
(iii) but for free vector fields, yielding Proca stars (PSs), perturbatively
stable solutions with $R_{\Omega}\neq 0$ exist, and indeed $R_{\Omega}=6M$ for
a particular solution. Thus, dynamically robust spherical PSs can mimic the
shadow of a (near-)equilibrium Schwarzschild BH with the same M, in an
astrophysical environment, despite the absence of a LR, at least under some
observation conditions, as we confirm by comparing the lensing of such PSs and
Schwarzschild BHs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 16:23:57 GMT""}]","2021-04-20"
"2102.01704","Lina Necib","Lina Necib and Tongyan Lin","Substructure at High Speed I: Inferring the Escape Velocity in the
  Presence of Kinematic Substructure","17+13 pages, 13+14 figures",,"10.3847/1538-4357/ac4243",,"astro-ph.GA hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The local escape velocity provides valuable inputs to the mass profile of the
Galaxy, and requires understanding the tail of the stellar speed distribution.
Following Leonard $\&$ Tremaine (1990), various works have since modeled the
tail of the stellar speed distribution as $\propto (v_{\rm{esc}} -v)^k$, where
$v_{\rm{esc}}$ is the escape velocity, and $k$ is the slope of the
distribution. In such studies, however, these two parameters were found to be
largely degenerate and often a narrow prior is imposed on $k$ in order to
constrain $v_{\rm{esc}}$. Furthermore, the validity of the power law form is
likely to break down in the presence of multiple kinematic substructures. In
this paper, we introduce a strategy that for the first time takes into account
the presence of kinematic substructure. We model the tail of the velocity
distribution as a sum of multiple power laws without imposing strong priors.
Using mock data, we show the robustness of this method in the presence of
kinematic structure that is similar to the recently-discovered Gaia Sausage. In
a companion paper, we present the new measurement of the escape velocity and
subsequently the mass of the Milky Way using Gaia DR2 data.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:01 GMT""}]","2022-03-02"
"2102.01705","Rahul Nandkishore","Rahul Nandkishore and Sarang Gopalakrishnan","Lifetimes of local excitations in disordered dipolar quantum systems",,"Phys. Rev. B 103, 134423 (2021)","10.1103/PhysRevB.103.134423",,"cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  When a strongly disordered system of interacting quantum dipoles is locally
excited, the excitation relaxes on some (potentially very long) timescale. We
analyze this relaxation process, both for electron glasses with strong Coulomb
interactions - in which particle-hole dipoles are emergent excitations - and
for systems (e.g., quantum magnets or ultracold dipolar molecules) made up of
microscopic dipoles. We consider both energy relaxation rates ($T_1$ times) and
dephasing rates ($T_2$ times), and their dependence on frequency, temperature,
and polarization. Systems in both two and three dimensions are considered,
along with the dimensional crossover in quasi-two dimensional geometries. A
rich set of scaling laws is found.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:02 GMT""}]","2021-04-21"
"2102.01706","Jose G. Fernandez-Trincado","Jos\'e G. Fern\'andez-Trincado, Timothy C. Beers, Dante Minniti,
  Leticia Carigi, Vinicius M. Placco, Sang-Hyun Chun, Richard R. Lane, Doug
  Geisler, Sandro Villanova, Stefano O. Souza, Beatriz Barbuy, Angeles
  P\'erez-Villegas, Cristina Chiappini, Anna. B. A. Queiroz, Baitian Tang,
  Javier Alonso-Garc\'ia, Andr\'es E. Piatti, Tali Palma, Alan Alves-Brito,
  Christian Moni Bidin, Alexandre Roman-Lopes, Ricardo R. Mu\~noz, Harinder P.
  Singh, Richa Kundu, Leonardo Chaves-Velasquez, Mar\'ia Romero-Colmenares,
  Penelope Longa-Pe\~na, Mario Soto, Katherine Vieira","APOGEE discovery of a chemically atypical star disrupted from NGC 6723
  and captured by the Milky Way bulge","Astronomy & Astrophysics, in press. 16 pages, 8 figures, 2 tables",,"10.1051/0004-6361/202040255",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The central (`bulge') region of the Milky Way is teeming with a significant
fraction of mildly metal-deficient stars with atmospheres that are strongly
enriched in cyanogen ($^{12}$C$^{14}$N). Some of these objects, which are also
known as nitrogen-enhanced stars, are hypothesised to be relics of the ancient
assembly history of the Milky Way. Although the chemical similarity of
nitrogen-enhanced stars to the unique chemical patterns observed in globular
clusters has been observed, a direct connection between field stars and
globular clusters has not yet been proven. In this work, we report on
high-resolution, near-infrared spectroscopic observations of the bulge globular
cluster NGC 6723, and the serendipitous discovery of a star,
2M18594405$-$3651518, located outside the cluster (near the tidal radius) but
moving on a similar orbit, providing the first clear piece of evidence of a
star that was very likely once a cluster member and has recently been ejected.
Its nitrogen abundance ratio ([N/Fe]$\gtrsim + 0.94$) is well above the typical
Galactic field-star levels, and it exhibits noticeable enrichment in the heavy
$s$-process elements (Ce, Nd, and Yb), along with moderate carbon enrichment;
all characteristics are known examples in globular clusters. This result
suggests that some of the nitrogen-enhanced stars in the bulge likely
originated from the tidal disruption of globular clusters.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:02 GMT""}]","2021-02-04"
"2102.01707","Antonio Sollima","A. Sollima","Monte Carlo simulations of multiple populations in globular clusters:
  constraints on the cooling flow vs. accretion scenario using million bodies
  simulations","19 pages, 15 figures, accepted for publication by MNRAS",,"10.1093/mnras/stab154",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I simulate the evolution of a stellar system hosting two stellar populations
whose initial set up is defined according to the two main scenarios proposed
for the origin of multiple populations in Galactic globular clusters: (i)
formation of a second generation from a cooling flow of pristine+polluted gas
and (ii) accretion of polluted gas onto the proto-stellar disks of a fraction
of low-mass stars. For this purpose, Monte Carlo simulations containing from
$10^{5}$ up to $3\cdot 10^{6}$ particles have been run including the effect of
stellar evolution, binary interactions, external tidal field and a detailed
modelling of the proto-stellar disk structure. The early accretion of gas onto
proto-stellar disks is unable to produce discrete populations and to alter the
chemical composition of a significant ($>10\%$) fraction of stars unless a disk
lifetime larger ($t_{disk}\sim20~Myr$) than that predicted by models is
assumed. Moreover, in this scenario the mixing timescale of the two populations
is too short to reproduce the observed segregation of the chemically enriched
population. On the other hand, simulations run within the cooling flow scenario
can evolve after a Hubble time into stellar systems with a first-to-second
population mass ratio similar to that observed in globular clusters, provided
that an initial filling-factor $r_{h}/r_{J}>0.15$ is adopted. However, in the
weak tidal field regime a radial segregation of the second population stronger
than what observed in Milky Way globular clusters at large Galactocentric
distances is predicted. This discrepancy disappears in simulations following
eccentric orbits in a realistic axisymmetric potential.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:02 GMT""}]","2021-02-17"
"2102.01708","Danny Laghi","Danny Laghi, Nicola Tamanini, Walter Del Pozzo, Alberto Sesana,
  Jonathan Gair, Stanislav Babak, David Izquierdo-Villalba","Gravitational wave cosmology with extreme mass-ratio inspirals","22 pages, 9 figures. v2: new author in author list, new sub-Appendix
  with additional results, new Fig. A1; some explicative paragraphs added, Fig.
  3 updated. Matches the journal version","Monthly Notices of the Royal Astronomical Society, Volume 508,
  Issue 3, December 2021, Pages 4512-4531","10.1093/mnras/stab2741",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  The Laser Interferometer Space Antenna (LISA) will open the mHz frequency
window of the gravitational wave (GW) landscape. Among all the new GW sources
expected to emit in this frequency band, extreme mass-ratio inspirals (EMRIs)
constitute a unique laboratory for astrophysics and fundamental physics. Here
we show that EMRIs can also be used to extract relevant cosmological
information, complementary to both electromagnetic (EM) and other GW
observations. By using the loudest EMRIs (SNR$>$100) detected by LISA as dark
standard sirens, statistically matching their sky localisation region with mock
galaxy catalogs, we find that constraints on $H_0$ can reach $\sim$1.1%
($\sim$3.6%) accuracy, at the 90% credible level, in our best (worst) case
scenario. By considering a dynamical dark energy (DE) cosmological model, with
$\Lambda$CDM parameters fixed by other observations, we further show that in
our best (worst) case scenario $\sim$5.9% ($\sim$12.3%) relative uncertainties
at the 90% credible level can be obtained on $w_0$, the DE equation of state
parameter. Besides being relevant in their own right, EMRI measurements will be
affected by different systematics compared to both EM and ground-based GW
observations. Cross validation with complementary cosmological measurements
will therefore be of paramount importance, especially if convincing evidence of
physics beyond $\Lambda$CDM emerges from future observations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 22:03:08 GMT""}]","2021-11-03"
"2102.01709","Sebastian Hutschenreuter","Sebastian Hutschenreuter, Craig S. Anderson, Sarah Betti, Geoffrey C.
  Bower, Jo-Anne Brown, Marcus Br\""uggen, Ettore Carretti, Tracy Clarke, Andrew
  Clegg, Allison Costa, Steve Croft, Cameron Van Eck, B. M. Gaensler, Francesco
  de Gasperin, Marijke Haverkorn, George Heald, Charles L.H. Hull, Makoto
  Inoue, Melanie Johnston-Hollitt, Jane Kaczmarek, Casey Law, Yik Ki Ma, David
  MacMahon, Sui Ann Mao, Christopher Riseley, Subhashis Roy, Russell Shanahan,
  Timothy Shimwell, Jeroen Stil, Charlotte Sobey, Shane O'Sullivan, Cyril
  Tasse, Valentina Vacca, Tessa Vernstrom, Peter K.G. Williams, Melvyn Wright
  and Torsten A. En{\ss}lin","The Galactic Faraday rotation sky 2020","accepted in A&A; 15 pages, 12 Figures; results at
  https://wwwmpa.mpa-garching.mpg.de/~ensslin/research/data/faraday2020.html
  and http://cutouts.cirada.ca/rmcutout","A&A 657, A43 (2022)","10.1051/0004-6361/202140486",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  This work gives an update to existing reconstructions of the Galactic Faraday
rotation sky by processing almost all Faraday rotation data sets available at
the end of the year 2020. Observations of extra-Galactic sources in recent
years have, among other regions, further illuminated the previously
under-constrained southern celestial sky, as well as parts of the inner disc of
the Milky Way. This has culminated in an all-sky data set of 55,190 data
points, which is a significant expansion on the 41,330 used in previous works,
hence making an updated separation of the Galactic component a promising
venture. The increased source density allows us to present our results in a
resolution of about $1.3\cdot 10^{-2}\, \mathrm{deg}^2$
($46.8\,\mathrm{arcmin}^2$), which is a twofold increase compared to previous
works. As for previous Faraday rotation sky reconstructions, this work is based
on information field theory, a Bayesian inference scheme for field-like
quantities which handles noisy and incomplete data. In contrast to previous
reconstructions, we find a significantly thinner and pronounced Galactic disc
with small-scale structures exceeding values of several thousand
$\mathrm{rad}\,\mathrm{m}^{-2}$. The improvements can mainly be attributed to
the new catalog of Faraday data, but are also supported by advances in
correlation structure modeling within numerical information field theory. We
furthermore give a detailed discussion on statistical properties of the Faraday
rotation sky and investigate correlations to other data sets.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:00:09 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 21:55:43 GMT""}]","2022-01-05"
"2102.01710","Ruiyu Zhang","Ruiyu Zhang and Fulai Guo","Probing the Halo Gas Distribution in the Inner Galaxy with Fermi Bubble
  Observations","16 pages, 12 figures. Accepted for publication ApJ",,"10.3847/1538-4357/abfdb1",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hot halo gas distribution in the inner Milky Way (MW) contains key fossil
records of the past energetic feedback processes in the Galactic center. Here
we adopt a variety of spherical and disk-like MW halo gas models as initial
conditions in a series of simulations to investigate the formation of the Fermi
bubbles in the jet-shock scenario. The simulation results are compared directly
with relevant X-ray and gamma-ray observations of the Fermi bubbles to
constrain the halo gas distribution in the inner Galaxy before the Fermi bubble
event. Our best-fit gas density distribution can be described by a power law in
radius $n_{\rm e}(r)=0.01(r/1 \text{~kpc})^{-1.5}$ cm$^{-3}$. Our study can not
determine if there is an inner density core, which if exists, should be very
small with size $r_{c} \lesssim 0.5$ kpc. When extrapolating to large radii
$r\sim 50-90$ kpc, our derived density distribution lies appreciably below the
recently estimated gas densities from ram-pressure stripping calculations,
suggesting that the halo gas density profile either flattens out or has one or
more discontinuities within $10 \lesssim r \lesssim 50$ kpc. Some of these
discontinuities may be related to the eROSITA bubbles, and our derived gas
density profile may correspond to the hot gas distribution in the inner eROSITA
bubbles about $5$ Myr ago.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:01:15 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 16:06:35 GMT""}]","2021-07-21"
"2102.01711","Dr Cesar Salas-Guerra","Dr. Cesar R Salas-Guerra","Skills-based on technological knowledge in the digital economy activity",,,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This research seeks to measure the impact of people with technological
knowledge on regional digital economic activity and the implications of
prosperous cities' contagion effect on neighbouring ones. The focus of this
study is quantitative, cross-sectional, and its design is correlational-causal.
This study covers seven micro-regions of Minas Gerais in Brazil, organized in
89 municipalities, with 69% urban population and 31% rural. The data used
consisted of 4,361 observations obtained in the Brazilian government's public
repositories, organized into panel data, and analysed using partial least
squares, micro-regional spatial regression, and identification patterns with
machine learning. The confirmatory analysis of the regression test establishes
a significant impact between the CE's technological knowledge and the digital
economic activity AED through a predictive value of R2 = .749, \b{eta} = .867,
p = .000 (value t = 18,298). With high notoriety among the variables, public
and private university institutions (IUPP), professors with doctorates and
masters (DCNT), and information technology occupations (CBO). A geographic
concentration of companies that demand technology-based skills had effects by
slowing down the development of small municipalities, suggesting the
development of new government technology initiatives that support new business
models based on technological knowledge.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:03:53 GMT""}]","2021-02-04"
"2102.01712","Pedro Resende","Pedro Resende","An abstract theory of physical measurements",,"Found. Phys. 51, 108 (2021)","10.1007/s10701-021-00513-1",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The question of what should be meant by a measurement is tackled from a
mathematical perspective whose physical interpretation is that a measurement is
a fundamental process via which a finite amount of classical information is
produced. This translates into an algebraic and topological definition of
measurement space that caters for the distinction between quantum and classical
measurements and allows a notion of observer to be derived.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:04:15 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 05:11:36 GMT""},{""version"":""v3"",""created"":""Thu, 23 Sep 2021 23:04:30 GMT""},{""version"":""v4"",""created"":""Sat, 10 Dec 2022 17:08:12 GMT""}]","2023-01-10"
"2102.01713","Sietske Bouma","Sietske J. D. Bouma, Philipp Richter, Martin Wendt","On the relation between Lya absorbers and local galaxy filaments","Accepted for publication in A&A. 16 pages, 19 figures","A&A 647, A166 (2021)","10.1051/0004-6361/202039786",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The intergalactic medium (IGM) is believed to contain the majority of baryons
in the universe and to trace the same dark matter structure as galaxies,
forming filaments and sheets. Lya absorbers, which sample the neutral component
of the IGM, have been extensively studied at low and high redshift, but the
exact relation between Lya absorption, galaxies and the large-scale structure
is observationally not well-constrained. In this study, we aim at
characterising the relation between Lya absorbers and nearby overdense
cosmological structures (galaxy filaments) at recession velocities Delta v \leq
6700 km/s by using archival observational data from various instruments. We
analyse 587 intervening Lya absorbers in the spectra of 302 extragalactic
background sources obtained with the COS installed on the HST. We combine the
absorption-line information with galaxy data of five local galaxy filaments
originally mapped by Courtois et al. (2013). Along the 91 sightlines that pass
close to a filament, we identify 215 (227) Lya absorption systems (components).
Among these, 74 Lya systems are aligned in position and velocity with the
galaxy filaments, indicating that these absorbers and the galaxies trace the
same large-scale structure. The filament-aligned Lya absorbers have a ~90
percent higher rate of incidence (dN/dz=189 for log N HI \geq 13.2) and a
mildly shallower slope (-beta = -1.47) of the column density distribution
function than the general Lya population at z=0, reflecting the filaments'
matter overdensity. The strongest Lya absorbers are preferentially found near
galaxies or close to the axis of a filament, although there is substantial
scatter in this relation. Our sample of absorbers clusters more strongly around
filament axes than a randomly distributed sample would do (as confirmed by a KS
test), but the clustering signal is less pronounced than for the galaxies in
the filaments.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:04:21 GMT""}]","2021-03-31"
"2102.01714","Huaike Guo","Alba Romero, Katarina Martinovic, Thomas A. Callister, Huai-Ke Guo,
  Mario Mart\'inez, Mairi Sakellariadou, Feng-Wei Yang, Yue Zhao","Implications for First-Order Cosmological Phase Transitions from the
  Third LIGO-Virgo Observing Run","7 pages, 3 figures, version published in Physical Review Letters","Phys. Rev. Lett. 126, 151301 (2021)","10.1103/PhysRevLett.126.151301",,"hep-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We place constraints on the normalized energy density in gravitational waves
from first-order strong phase transitions using data from Advanced LIGO and
Virgo's first, second and third observing runs. First, adopting a broken power
law model, we place $95 \%$ confidence level upper limits simultaneously on the
gravitational-wave energy density at 25 Hz from unresolved compact binary
mergers, $\Omega_{\rm CBC} < 6.1 \times 10^{-9}$, and strong first-order phase
transitions, $\Omega_{\rm BPL} < 4.4 \times 10^{-9}$. The inclusion of the
former is necessary since we expect this astrophysical signal to be the
foreground of any detected spectrum. We then consider two more complex
phenomenological models, limiting at 25 Hz the gravitational-wave background
due to bubble collisions to $\Omega_{\rm pt} < 5.0\times 10^{-9}$ and the
background due to sound waves to $\Omega_{\rm pt} < 5.8\times10^{-9}$ at $95
\%$ confidence level for phase transitions occurring at temperatures above
$10^8$GeV.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:11:18 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 20:38:33 GMT""}]","2021-04-21"
"2102.01715","B. Scott Gaudi","B. Scott Gaudi","The Demographics of Wide-Separation Planets","69 pages, 17 Figures. Review chapter to appear in the Lecture Notes
  of the 3rd Advanced School on Exoplanetary Science (Editors L. Mancini, K.
  Biazzo, V. Bozza, A. Sozzetti)",,"10.1007/978-3-030-88124-5_4",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I begin this review by first defining what is meant by exoplanet
demographics, and then motivating why we would like as broad a picture of
exoplanet demographics as possible. I then outline the methodology and pitfalls
to measuring exoplanet demographics in practice. I next review the methods of
detecting exoplanets, focusing on the ability of these methods to detect wide
separation planets. For the purposes of this review, I define wide separation
as separations beyond the 'snow line' of the protoplanetary disk, which is at
roughly $\sim3$ au for a sunlike star. I note that this definition is somewhat
arbitrary, and the practical boundary depends on the host star mass, planet
mass and radius, and detection method. I review the approximate scaling
relations for the signal-to-noise ratio for the detectability of exoplanets as
a function of the relevant physical parameters, including the host star
properties. I provide abroad overview of what has already been learned from the
transit, radial velocity, direct imaging, and microlensing methods. I outline
the challenges to synthesizing the demographics using different methods and
discuss some preliminary first steps in this direction. Finally, I describe
future prospects for providing a nearly complete statistical census of
exoplanets.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:15:25 GMT""}]","2022-03-02"
"2102.01716","Alfred Galichon","Alfred Galichon","A survey of some recent applications of optimal transport methods to
  econometrics",,"The Econometrics Journal 20-2 (2017) C1-C11","10.1111/ectj.12083",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper surveys recent applications of methods from the theory of optimal
transport to econometric problems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:16:59 GMT""}]","2021-02-04"
"2102.01717","Enrico Vesperini","E. Vesperini, J. Hong, M. Giersz, A. Hypki","Dynamical Evolution of Multiple-Population Globular Clusters","16 pages, 19 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stab223",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have carried out a set of Monte Carlo simulations to study a number of
fundamental aspects of the dynamical evolution of multiple stellar populations
in globular clusters with different initial masses, fractions of second
generation (2G) stars, and structural properties. Our simulations explore and
elucidate: 1) the role of early and long-term dynamical processes and stellar
escape in the evolution of the fraction of 2G stars and the link between the
evolution of the fraction of 2G stars and various dynamical parameters; 2) the
link between the fraction of 2G stars inside the cluster and in the population
of escaping stars during a cluster's dynamical evolution; 3) the dynamics of
the spatial mixing of the first-generation (1G) and 2G stars and the details of
the structural properties of the two populations as they evolve toward mixing;
4) the implications of the initial differences between the spatial distribution
of 1G and 2G stars for the evolution of the anisotropy in the velocity
distribution and the expected radial profile of the 1G and 2G anisotropy for
clusters at different stages of their dynamical history; 5) the variation of
the degree of energy equipartition of the 1G and the 2G populations as a
function of the distance from the cluster's centre and the cluster's
evolutionary phase.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:17:44 GMT""}]","2021-03-03"
"2102.01718","Jacek Malecki","Krzysztof Burdzy and Jacek Ma{\l}ecki","Archimedes' principle for ideal gas","33 pages, 4 figures",,"10.1007/s00220-022-04347-4",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove Archimedes' principle for a macroscopic ball in ideal gas consisting
of point particles with non-zero mass. The main result is an asymptotic
theorem, as the number of point particles goes to infinity and their total mass
remains constant. We also show that, asymptotically, the gas has an exponential
density as a function of height. We find the asymptotic inverse temperature of
the gas. We derive an accurate estimate of the volume of the phase space using
the local central limit theorem.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:18:13 GMT""}]","2022-03-30"
"2102.01719","Corentin Martens","Corentin Martens, Laetitia Lebrun, Christine Decaestecker, Thomas
  Vandamme, Yves-R\'emi Van Eycke, Antonin Rovai, Thierry Metens, Olivier
  Debeir, Serge Goldman, Isabelle Salmon, Gaetan Van Simaeys","Initial condition assessment for reaction-diffusion glioma growth
  models: A translational MRI/histology (in)validation study",,,"10.3390/tomography7040055",,"physics.med-ph cs.LG eess.IV physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffuse gliomas are highly infiltrative tumors whose early diagnosis and
follow-up usually rely on magnetic resonance imaging (MRI). However, the
limited sensitivity of this technique makes it impossible to directly assess
the extent of the glioma cell invasion, leading to sub-optimal treatment
planing. Reaction-diffusion growth models have been proposed for decades to
extrapolate glioma cell infiltration beyond margins visible on MRI and predict
its spatial-temporal evolution. These models nevertheless require an initial
condition, that is the tumor cell density values at every location of the brain
at diagnosis time. Several works have proposed to relate the tumor cell density
function to abnormality outlines visible on MRI but the underlying assumptions
have never been verified so far. In this work we propose to verify these
assumptions by stereotactic histological analysis of a non-operated brain with
glioblastoma using a tailored 3D-printed slicer. Cell density maps are computed
from histological slides using a deep learning approach. The density maps are
then registered to a postmortem MR image and related to an MR-derived geodesic
distance map to the tumor core. The relation between the edema outlines visible
on T2 FLAIR MRI and the distance to the core is also investigated. Our results
suggest that (i) the previously suggested exponential decrease of the tumor
cell density with the distance to the tumor core is not unreasonable but (ii)
the edema outlines may in general not correspond to a cell density iso-contour
and (iii) the commonly adopted tumor cell density value at these outlines is
likely overestimated. These findings highlight the limitations of using
conventional MRI to derive glioma cell density maps and point out the need of
validating other methods to initialize reaction-diffusion growth models and
make them usable in clinical practice.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:21:48 GMT""}]","2021-11-23"
"2102.01720","Saul Rappaport","S.A. Rappaport, D.W. Kurtz, G. Handler, D. Jones, L.A. Nelson, H.
  Saio, J. Fuller, D.L. Holdsworth, A. Vanderburg, J.\v{Z}\'ak, M. Skarka, J.
  Aiken, P.F.L. Maxted, D.J. Stevens, D.L. Feliz, and F. Kahraman
  Ali\c{c}avu\c{s}","A tidally tilted sectoral dipole pulsation mode in the eclipsing binary
  TIC 63328020","16 pages, 12 figures, and 8 tables",,"10.1093/mnras/stab336",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report the discovery of the third tidally tilted pulsator, TIC 63328020.
Observations with the TESS satellite reveal binary eclipses with an orbital
period of 1.1057 d, and $\delta$ Scuti-type pulsations with a mode frequency of
21.09533 d$^{-1}$. This pulsation exhibits a septuplet of orbital sidelobes as
well as a harmonic quintuplet. Using the oblique pulsator model, the primary
oscillation is identified as a sectoral dipole mode with $l = 1, |m| = 1$. We
find the pulsating star to have $M_1 \simeq 2.5\, {\rm M}_\odot$, $R_1 \simeq 3
\, {\rm R}_\odot$, and $T_{\rm eff,1} \simeq 8000$ K, while the secondary has
$M_2 \simeq 1.1 \, {\rm M}_\odot$, $R_2 \simeq 2 \, {\rm R}_\odot$, and $T_{\rm
eff,2} \simeq 5600$ K. Both stars appear to be close to filling their
respective Roche lobes. The properties of this binary as well as the tidally
tilted pulsations differ from the previous two tidally tilted pulsators,
HD74423 and CO Cam, in important ways. We also study the prior history of this
system with binary evolution models and conclude that extensive mass transfer
has occurred from the current secondary to the primary.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:23:45 GMT""}]","2021-02-17"
"2102.01721","Alban Poth\'erat","Long Chen, Alban Poth\'erat, Ming-Jiu Ni and Ren\'e Moreau","Direct numerical simulation of quasi-two-dimensional MHD turbulent shear
  flows",,,"10.1017/jfm.2021.103",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Direct numerical simulations (DNS) are performed to study the turbulent shear
flow of an electrically conducting fluid in a cylindrical container. The flow
is driven by the interaction between the radial electric currents ($I$)
injected through a large number of small electrodes at the bottom wall and an
axial magnetic field. All the numerical parameters, including the geometry of
the container, the total injcected currents and the magnetic field, are in line
with the experiment performed in J. Fluid Mech. 456, 137-159. First, witth
laminar Hartmann layers, three dimensional simulations recover experimentally
measured quantities (global angular momentum, velocity profiles). The variation
laws for the wall shear stresses, the energy spectra and visualizations of flow
structures near the side wall highlight separation and turbulence within the
side wall layers. Furthermore, a parametric analysis of the flow reveals that
Ekman recirculations have significant influence on the vortex size, the free
shear layer, and the global dissipation. Second, we recover the scaling laws of
the cutoff scale that separate the large quasi-two-dimensional scales from the
small three-dimensional ones (J. Fluid Mech. 118, 507-518), and thus establish
their validity in sheared MHD turbulence. Furthermore, we find that
three-componentality are and the three-dimensionality appear concurrently and
that both the two-dimensional cutoff frequency and the mean energy associated
to the axial component of velocity scale with $N_t$, respectively as
$0.063N_t^{0.37}$ and $0.126 N_t^{-0.92}$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:33:15 GMT""}]","2021-04-21"
"2102.01722","Assane Gueye","Assane Gueye and Peter Mell","A Historical and Statistical Studyof the Software Vulnerability
  Landscape","7 pages",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Understanding the landscape of software vulnerabilities is key for developing
effective security solutions. Fortunately, the evaluation of vulnerability
databases that use a framework for communicating vulnerability attributes and
their severity scores, such as the Common Vulnerability Scoring System (CVSS),
can help shed light on the nature of publicly published vulnerabilities. In
this paper, we characterize the software vulnerability landscape by performing
a historical and statistical analysis of CVSS vulnerability metrics over the
period of 2005 to 2019 through using data from the National Vulnerability
Database. We conduct three studies analyzing the following: the distribution of
CVSS scores (both empirical and theoretical), the distribution of CVSS metric
values and how vulnerability characteristics change over time, and the relative
rankings of the most frequent metric value over time. Our resulting analysis
shows that the vulnerability threat landscape has been dominated by only a few
vulnerability types and has changed little during the time period of the study.
The overwhelming majority of vulnerabilities are exploitable over the network.
The complexity to successfully exploit these vulnerabilities is dominantly low;
very little authentication to the target victim is necessary for a successful
attack. And most of the flaws require very limited interaction with users.
However on the positive side, the damage of these vulnerabilities is mostly
confined within the security scope of the impacted components. A discussion of
lessons that could be learned from this analysis is presented.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:35:50 GMT""}]","2021-02-04"
"2102.01723","Amir Yazdanbakhsh","Amir Yazdanbakhsh, Christof Angermueller, Berkin Akin, Yanqi Zhou,
  Albin Jones, Milad Hashemi, Kevin Swersky, Satrajit Chatterjee, Ravi
  Narayanaswami, James Laudon","Apollo: Transferable Architecture Exploration","10 pages, 5 figures, Accepted to Workshop on ML for Systems at the
  34th Conference on Neural Information Processing Systems (NeurIPS 2020)",,,,"cs.LG cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The looming end of Moore's Law and ascending use of deep learning drives the
design of custom accelerators that are optimized for specific neural
architectures. Architecture exploration for such accelerators forms a
challenging constrained optimization problem over a complex, high-dimensional,
and structured input space with a costly to evaluate objective function.
Existing approaches for accelerator design are sample-inefficient and do not
transfer knowledge between related optimizations tasks with different design
constraints, such as area and/or latency budget, or neural architecture
configurations. In this work, we propose a transferable architecture
exploration framework, dubbed Apollo, that leverages recent advances in
black-box function optimization for sample-efficient accelerator design. We use
this framework to optimize accelerator configurations of a diverse set of
neural architectures with alternative design constraints. We show that our
framework finds high reward design configurations (up to 24.6% speedup) more
sample-efficiently than a baseline black-box optimization approach. We further
show that by transferring knowledge between target architectures with different
design constraints, Apollo is able to find optimal configurations faster and
often with better objective value (up to 25% improvements). This encouraging
outcome portrays a promising path forward to facilitate generating higher
quality accelerators.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:36:02 GMT""}]","2021-02-04"
"2102.01724","Itamar Cohen","Itamar Cohen, Gil Einziger and Gabriel Scalosub","On the Power of False Negative Awareness in Indicator-based Caching
  Systems","Replaced by arXiv:2203.09119, which is a pre-print of the journal
  version of the same paper",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed caching systems such as content distribution networks often
advertise their content via lightweight approximate indicators (e.g., Bloom
filters) to efficiently inform clients where each datum is likely cached. While
false-positive indications are necessary and well understood, most existing
works assume no false-negative indications. Our work illustrates practical
scenarios where false-negatives are unavoidable and ignoring them has a
significant impact on system performance. Specifically, we focus on
false-negatives induced by indicator staleness, which arises whenever the
system advertises the indicator only periodically, rather than immediately
reporting every change in the cache. Such scenarios naturally occur, e.g., in
bandwidth-constraint environments or when latency impedes the ability of each
client to obtain an updated indicator. Our work introduces novel false-negative
aware access policies that continuously estimate the false-negative ratio and
sometimes access caches despite negative indications. We present optimal
policies for homogeneous settings and provide approximation guarantees for our
algorithms in heterogeneous environments. We further perform an extensive
simulation study with multiple real system traces. We show that our
false-negative aware algorithms incur a significantly lower access cost than
existing approaches or match the cost of these approaches while requiring an
order of magnitude fewer resources (e.g., caching capacity or bandwidth).
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:36:11 GMT""},{""version"":""v2"",""created"":""Sun, 18 Apr 2021 13:15:25 GMT""},{""version"":""v3"",""created"":""Sat, 19 Mar 2022 06:08:45 GMT""}]","2022-03-22"
"2102.01725","Raymond Centner","Catherine B\'en\'eteau, Raymond Centner","A survey of optimal polynomial approximants, applications to digital
  filter design, and related open problems",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In the last few years, the notion of optimal polynomial approximant has
appeared in the mathematics literature in connection with Hilbert spaces of
analytic functions of one or more variables. In the 70s, researchers in
engineering and applied mathematics introduced least-squares inverses in the
context of digital filters in signal processing. It turns out that in the Hardy
space $H^2$ these objects are identical. This paper is a survey of known
results about optimal polynomial approximants. In particular, we will examine
their connections with orthogonal polynomials and reproducing kernels in
weighted spaces and digital filter design. We will also describe what is known
about the zeros of optimal polynomial approximants, their rates of decay, and
convergence results. Throughout the paper, we state many open questions that
may be of interest.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:42:41 GMT""}]","2021-02-04"
"2102.01726","Cynthia Vinzant","Faye Pasley Simon and Cynthia Vinzant","Invariant hyperbolic curves: determinantal representations and
  applications to the numerical range","24 pages, 5 figures, minor revisions",,,,"math.AG math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we study the space of real hyperbolic plane curves that are invariant
under actions of the cyclic and dihedral groups and show they have
determinantal representations that certify this invariance. We show an analogue
of Nuij's theorem for the set of invariant hyperbolic polynomials of a given
degree. The main theorem is that every invariant hyperbolic plane curve has a
determinantal representation using a block cyclic weighted shift matrix. This
generalizes previous work by Lentzos and the first author, as well as by Chien
and Nakazato. One consequence is that if the numerical range of a matrix is
invariant under rotation, then it is the numerical range of a block cyclic
weighted shift matrix.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:44:05 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 21:14:23 GMT""}]","2021-04-23"
"2102.01727","Reed Oei","Reed Oei, Dun Ma, Christian Schulz, and Philipp Hieronymi","Pecan: An Automated Theorem Prover for Automatic Sequences using B\""uchi
  Automata","Working draft",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pecan is an automated theorem prover for reasoning about properties of
Sturmian words, an important object in the field of combinatorics on words. It
is capable of efficiently proving non-trivial mathematical theorems about all
Sturmian words.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:49:04 GMT""}]","2021-02-04"
"2102.01728","Ramith Hettiarachchi","Ramith Hettiarachchi, Udith Haputhanthri, Kithmini Herath, Hasindu
  Kariyawasam, Shehan Munasinghe, Kithmin Wickramasinghe, Duminda Samarasinghe,
  Anjula De Silva and Chamira U. S. Edussooriya","A Novel Transfer Learning-Based Approach for Screening Pre-existing
  Heart Diseases Using Synchronized ECG Signals and Heart Sounds","Paper accepted to IEEE International Symposium on Circuits and
  Systems (ISCAS) 2021",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diagnosing pre-existing heart diseases early in life is important as it helps
prevent complications such as pulmonary hypertension, heart rhythm problems,
blood clots, heart failure and sudden cardiac arrest. To identify such
diseases, phonocardiogram (PCG) and electrocardiogram (ECG) waveforms convey
important information. Therefore, effectively using these two modalities of
data has the potential to improve the disease screening process. We evaluate
this hypothesis on a subset of the PhysioNet Challenge 2016 Dataset which
contains simultaneously acquired PCG and ECG recordings. Our novel
Dual-Convolutional Neural Network based approach uses transfer learning to
tackle the problem of having limited amounts of simultaneous PCG and ECG data
that is publicly available, while having the potential to adapt to larger
datasets. In addition, we introduce two main evaluation frameworks named
record-wise and sample-wise evaluation which leads to a rich performance
evaluation for the transfer learning approach. Comparisons with methods which
used single or dual modality data show that our method can lead to better
performance. Furthermore, our results show that individually collected ECG or
PCG waveforms are able to provide transferable features which could effectively
help to make use of a limited number of synchronized PCG and ECG waveforms and
still achieve significant classification performance.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:51:12 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 16:37:46 GMT""}]","2021-02-16"
"2102.01729","Adam B. Block","Adam Block, Yuval Dagan, and Sasha Rakhlin","Majorizing Measures, Sequential Complexities, and Online Learning",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce the technique of generic chaining and majorizing measures for
controlling sequential Rademacher complexity. We relate majorizing measures to
the notion of fractional covering numbers, which we show to be dominated in
terms of sequential scale-sensitive dimensions in a horizon-independent way,
and, under additional complexity assumptions establish a tight control on
worst-case sequential Rademacher complexity in terms of the integral of
sequential scale-sensitive dimension. Finally, we establish a tight contraction
inequality for worst-case sequential Rademacher complexity. The above
constitutes the resolution of a number of outstanding open problems in
extending the classical theory of empirical processes to the sequential case,
and, in turn, establishes sharp results for online learning.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:52:58 GMT""}]","2021-02-04"
"2102.01730","Alexandra Porter","Alexandra Porter and Mary Wootters","On Greedy Approaches to Hierarchical Aggregation","Example figures replaced",,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We analyze greedy algorithms for the Hierarchical Aggregation (HAG) problem,
a strategy introduced in [Jia et al., KDD 2020] for speeding up learning on
Graph Neural Networks (GNNs). The idea of HAG is to identify and remove
redundancies in computations performed when training GNNs. The associated
optimization problem is to identify and remove the most redundancies.
  Previous work introduced a greedy approach for the HAG problem and claimed a
1-1/e approximation factor. We show by example that this is not correct, and
one cannot hope for better than a 1/2 approximation factor. We prove that this
greedy algorithm does satisfy some (weaker) approximation guarantee, by showing
a new connection between the HAG problem and maximum matching problems in
hypergraphs. We also introduce a second greedy algorithm which can out-perform
the first one, and we show how to implement it efficiently in some parameter
regimes. Finally, we introduce some greedy heuristics that are much faster than
the above greedy algorithms, and we demonstrate that they perform well on
real-world graphs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:59:10 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 01:34:03 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 21:11:51 GMT""}]","2021-02-09"
"2102.01731","Aissa Guesmia Mr","Aissa Guesmia","Study on the stability of thermoelastic Bresse and Timoshenko type
  systems with Gurtin-Pipkin's law via the vertical displacements",,,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The objective of this paper is to study the stability of a linear
one-dimensional thermoelastic Bresse system in a bounded domain, where the
coupling is given through the first component of the Bresse model with the heat
conduction of Gurtin-Pipkin type. Two kinds of coupling are considered; the
first coupling is of order one with respect to space variable, and the second
one is of order zero. We state the well-posedness and show the polynomial
stability of the systems, where the decay rates depend on the smoothness of
initial data. Moreover, in case of coupling of order one, we prove the
equivalence between the exponential stability and some new conditions on the
parameters of the system. However, when the coupling is of order zero, we prove
the non-exponential stability independently of the parameters of the system.
Applications to the corresponding particular Timoshenko models are also given,
where we prove that both couplings lead to the exponential stability if and
only if some conditions on the parameters of the systems are satisfied, and
both couplings guarantee the polynomial stability independently of the
parameters of the systems. The proof is based on the semigroup theory and a
combination of the energy method and the frequency domain approach.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:59:35 GMT""}]","2021-02-04"
"2102.01732","Selima Curci","Selima Curci, Decebal Constantin Mocanu, Mykola Pechenizkiyi","Truly Sparse Neural Networks at Scale","30 pages, 17 figures",,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, sparse training methods have started to be established as a de
facto approach for training and inference efficiency in artificial neural
networks. Yet, this efficiency is just in theory. In practice, everyone uses a
binary mask to simulate sparsity since the typical deep learning software and
hardware are optimized for dense matrix operations. In this paper, we take an
orthogonal approach, and we show that we can train truly sparse neural networks
to harvest their full potential. To achieve this goal, we introduce three novel
contributions, specially designed for sparse neural networks: (1) a parallel
training algorithm and its corresponding sparse implementation from scratch,
(2) an activation function with non-trainable parameters to favour the gradient
flow, and (3) a hidden neurons importance metric to eliminate redundancies. All
in one, we are able to break the record and to train the largest neural network
ever trained in terms of representational power -- reaching the bat brain size.
The results show that our approach has state-of-the-art performance while
opening the path for an environmentally friendly artificial intelligence era.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:06:47 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 09:29:49 GMT""}]","2022-07-13"
"2102.01733","Wentai Wu","Wentai Wu, Ligang He, Weiwei Lin, Carsten Maple","FedProf: Selective Federated Learning with Representation Profiling","29 pages (references and appendices included)",,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Federated Learning (FL) has shown great potential as a privacy-preserving
solution to learning from decentralized data that are only accessible to end
devices (i.e., clients). In many scenarios, however, a large proportion of the
clients are probably in possession of low-quality data that are biased, noisy
or even irrelevant. As a result, they could significantly slow down the
convergence of the global model we aim to build and also compromise its
quality. In light of this, we propose FedProf, a novel algorithm for optimizing
FL under such circumstances without breaching data privacy. The key of our
approach is a distributional representation profiling and matching scheme that
uses the global model to dynamically profile data representations and allows
for low-cost, lightweight representation matching. Based on the scheme we
adaptively score each client and adjust its participation probability so as to
mitigate the impact of low-value clients on the training process. We have
conducted extensive experiments on public datasets using various FL settings.
The results show that the selective behaviour of our algorithm leads to a
significant reduction in the number of communication rounds and the amount of
time (up to 2.4x speedup) for the global model to converge and also provides
accuracy gain.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:10:14 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 10:50:02 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 08:50:29 GMT""},{""version"":""v4"",""created"":""Thu, 20 May 2021 19:40:21 GMT""},{""version"":""v5"",""created"":""Tue, 25 May 2021 09:52:49 GMT""},{""version"":""v6"",""created"":""Thu, 9 Sep 2021 18:37:58 GMT""},{""version"":""v7"",""created"":""Thu, 16 Sep 2021 15:07:17 GMT""},{""version"":""v8"",""created"":""Thu, 30 Sep 2021 08:59:25 GMT""},{""version"":""v9"",""created"":""Fri, 28 Jan 2022 12:30:13 GMT""}]","2022-01-31"
"2102.01734","Edward A. Baron","Peter H. Hauschildt and E. Baron","A 3D radiative transfer framework: XII. Many-core, vector and GPU
  methods","31 pages, 8 figures, to appear in Astronomy and Computing",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D detailed radiative transfer is computationally taxing, since the solution
of the radiative transfer equation involves traversing the six dimensional
phase space of the 3D domain. With modern supercomputers the hardware available
for wallclock speedup is rapidly changing, mostly in response to requirements
to minimize the cost of electrical power. Given the variety of modern computing
architectures, we aim to develop and adapt algorithms for different computing
architectures to improve performance on a wide variety of platforms. We
implemented the main time consuming kernels for solving 3D radiative transfer
problems for vastly different computing architectures using MPI, OpenMP,
OpenACC and vector algorithms. Adapted algorithms lead to massively improved
speed for all architectures, making extremely large model calculations easily
feasible. These calculations would have previously been considered impossible
or prohibitively expensive. Efficient use of modern computing devices is
entirely feasible, but unfortunately requires the implementation of specialized
algorithms for them.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:14:32 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 12:40:05 GMT""}]","2021-02-05"
"2102.01735","Aissa Guesmia Mr","Aissa Guesmia","On the decay rates for two Cauchy thermoelastic laminated Timoshenko
  problems of type III with interfacial slip",,,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The subject of this paper is to study the decay of solutions for two systems
of laminated Timoshenko beams with interfacial slip in the whole space R
subject to a thermal effect of type III acting only on one component. When the
thermal effect is acting via the second or third component of the laminated
Timoshenko beam (rotation angle displacement or dynamic of the slip), we prove
that both systems are polynomially stable and obtain stability estimates in the
L2 -norm of solutions and their higher order derivatives with respect of the
space variable. The decay rates, as well as the absence and presence of the
regularity-loss type property, depend on the regularity of the initial data and
the speeds of wave propagations. However, when the thermal effect is acting via
the first comoponent (transversal displacement), we introduce a new stability
number \c{hi} and prove that the stability of systems is equivalent to \c{hi}
6= 0. An application to a case of lower order coupling terms will be also
given. To prove our results, we use the energy method in Fourier space combined
with well chosen weight functions to build appropriate Lyapunov functionals.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:15:55 GMT""}]","2021-02-04"
"2102.01736","Xiaojun Yao","Xiaojun Yao","Open Quantum Systems for Quarkonia","54 pages, 6 figures, invited review for International Journal of
  Modern Physics A; v2: minor change","Int. J. of Mod. Phys. A, Vol. 36, No. 20, 2130010 (2021)","10.1142/S0217751X21300106","MIT-CTP/5273","hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I review recent applications of the open quantum system framework in the
understanding of quarkonium suppression in heavy-ion collisions, which has been
used as a probe of the quark-gluon plasma for decades. The derivation of the
Lindblad equations for quarkonium in both the quantum Brownian motion and the
quantum optical limits and their semiclassical counterparts is explained. The
hierarchy of time scales assumed in the derivation is justified from the
separation of energy scales in nonrelativistic effective field theories of QCD.
Physical implications of the open quantum system approach are also discussed.
Finally, I list some open questions for future studies.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:18:20 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 15:28:47 GMT""}]","2021-08-10"
"2102.01737","Myroslav Sparavalo","Myroslav K. Sparavalo","Canonical Form of Lyapunov Second Method in Mathematical Modelling and
  Control Design","12 pages, 3 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The objective of the paper is to put canonical Lyapunov function(CLF),
canonizing diffeomorphism (CD) and canonical form of dynamical systems (CFDS),
which have led to the generalization of the Lyapunov second method, in
perspective of their high efficiency for Mathematical Modelling and Control
Design. We show how the symbiosis of the ideas of Henri Poincare and Nikolay
Chetaev leads us to CD, CFDS and CLF. Our approach successfully translates into
mathematical modelling and control design for special two-angles synchronized
longitudinal maneuvering of a thrust-vectored aircraft. The essentially
nonlinear five-dimensional mathematical model of the longitudinal flight
dynamics of a thrust-vectored aircraft in a wing-body coordinate system with
two controls, namely the angular deflections of a movable horizontal stabilizer
and a turbojet engine nozzle, is investigated. The wide-sense robust and stable
in the large tracking control law is designed. Its core is the hierarchical
cascade of two controlling attractor-mediators and two controlling terminal
attractors embedded in the extended phase space of the mathematical model of
the aircraft longitudinal motion. The detailed demonstration of the elaborated
technique of designing wide-sense robust tracking control for the nonlinear
multidimensional mathematical model constitutes the quintessence of the paper.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:20:59 GMT""}]","2021-02-04"
"2102.01738","Yunchao Liu","Adam Bouland, Bill Fefferman, Zeph Landau, Yunchao Liu","Noise and the frontier of quantum supremacy","43 pages, 2 figures, presented at QIP 2021","2021 IEEE 62nd Annual Symposium on Foundations of Computer Science
  (FOCS), 2022, pp. 1308-1317","10.1109/FOCS52979.2021.00127",,"quant-ph cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noise is the defining feature of the NISQ era, but it remains unclear if
noisy quantum devices are capable of quantum speedups. Quantum supremacy
experiments have been a major step forward, but gaps remain between the theory
behind these experiments and their actual implementations. In this work we
initiate the study of the complexity of quantum random circuit sampling
experiments with realistic amounts of noise.
  Actual quantum supremacy experiments have high levels of uncorrected noise
and exponentially decaying fidelities. It is natural to ask if there is any
signal of exponential complexity in these highly noisy devices. Surprisingly,
we show that it remains hard to compute the output probabilities of noisy
random quantum circuits without error correction. More formally, so long as the
noise rate of the device is below the error detection threshold, we show it is
#P-hard to compute the output probabilities of random circuits with a constant
rate of noise per gate. This hardness persists even though these probabilities
are exponentially close to uniform.
  Interestingly these hardness results also have implications for the
complexity of experiments in a low-noise setting. The issue here is that prior
hardness results for computing output probabilities of random circuits are not
robust enough to imprecision to connect with the Stockmeyer argument for
hardness of sampling from circuits with constant fidelity. We exponentially
improve the robustness of prior results to imprecision, both in the cases of
Random Circuit Sampling and BosonSampling. In the latter case we bring the
proven hardness within a constant factor in the exponent of the robustness
required for hardness of sampling for the first time. We then show that our
results are in tension with one another -- the high-noise result implies the
low-noise result is essentially optimal, even with generalizations of our
techniques.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:23:13 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 23:00:41 GMT""}]","2022-03-08"
"2102.01739","Jacopo Marconi","Jacopo Marconi, Paolo Tiso, Davide E. Quadrelli, Francesco Braghin","An enhanced parametric nonlinear reduced order model for imperfect
  structures using Neumann expansion",,"Nonlinear Dyn 104, 3039-3063 (2021)","10.1007/s11071-021-06496-y",,"cs.CE cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  We present an enhanced version of the parametric nonlinear reduced order
model for shape imperfections in structural dynamics we studied in a previous
work [1]. The model is computed intrusively and with no training using
information about the nominal geometry of the structure and some user-defined
displacement fields representing shape defects, i.e. small deviations from the
nominal geometry parametrized by their respective amplitudes. The linear
superposition of these artificial displacements describe the defected geometry
and can be embedded in the strain formulation in such a way that, in the end,
nonlinear internal elastic forces can be expressed as a polynomial function of
both these defect fields and the actual displacement field. This way, a
tensorial representation of the internal forces can be obtained and, owning the
reduction in size of the model given by a Galerkin projection, high simulation
speed-ups can be achieved. We show that by adopting a rigorous deformation
framework we are able to achieve better accuracy as compared to the previous
work. In particular, exploiting Neumann expansion in the definition of the
Green-Lagrange strain tensor, we show that our previous model is a lower order
approximation with respect to the one we present now. Two numerical examples of
a clamped beam and a MEMS gyroscope finally demonstrate the benefits of the
method in terms of speed and increased accuracy.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:24:02 GMT""}]","2022-01-02"
"2102.01740","Yili Hong","Yili Hong and Jie Min and Caleb B. King and William Q. Meeker","Reliability Analysis of Artificial Intelligence Systems Using Recurrent
  Events Data from Autonomous Vehicles","30 pages, 9 figures",,,,"cs.AI stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:25:23 GMT""}]","2021-02-04"
"2102.01741","Naritaka Oshita","Naritaka Oshita, Niayesh Afshordi, Shinji Mukohyama","Lifshitz scaling, ringing black holes, and superradiance","25 pages, 14 figures","JCAP 05 (2021) 005","10.1088/1475-7516/2021/05/005","YITP-21-07, IPMU21-0006","gr-qc astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the ringdown waveform and reflectivity of a Lifshitz scalar
field around a fixed Schwarzschild black hole. The radial wave equation is
modified due to the Lorentz breaking terms, which leads to a diversity of
ringdown waveforms. Also, it turns out that Lifshitz waves scattered by the
Schwarzschild black hole exhibits superradiance. The Lorentz breaking terms
lead to superluminal propagation and high-frequency modes can enter and leave
the interior of the Killing horizon where negativity of energy is not
prohibited. This allows the Lifshitz waves to carry out additional positive
energy to infinity while leaving negative energy inside the Killing horizon,
similar to the Penrose process in the ergosphere of a Kerr spacetime. Another
interesting phenomenon is emergence of long-lived quasinormal modes, associated
with roton-type dispersion relations. These effects drastically modify the
greybody factor of a microscopic black hole, whose Hawking temperature is
comparable with or higher than the Lifshitz energy scale.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:26:20 GMT""}]","2021-05-07"
"2102.01742","Juan B\'ogalo Rom\'an","Juan B\'ogalo, Pilar Poncela, Eva Senra","cissa(): A MATLAB Function for Signal Extraction","20 pages, 8 figures",,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  cissa() is a MATLAB function for signal extraction by Circulant Singular
Spectrum Analysis, a procedure proposed in Bogalo et al (2021). cissa()
extracts the underlying signals in a time series identifying their frequency of
oscillation in an automated way, by just introducing the data and the window
length. This solution can be applied to stationary as well as to non-stationary
and non-linear time series. Additionally, in this paper, we solve some
technical issues regarding the beginning and end of sample data points. We also
introduce novel criteria in order to reconstruct the underlying signals
grouping some of the extracted components. The output of cissa() is the input
of the function group() to reconstruct the desired signals by further grouping
the extracted components. group() allows a novel user to create standard
signals by automated grouping options while an expert user can decide on the
number of groups and their composition. To illustrate its versatility and
performance in several fields we include 3 examples: an AM-FM synthetic signal,
an example of the physical world given by a voiced speech signal and an
economic time series. Possible applications include de-noising,
de-seasonalizing, de-trending and extracting business cycles, among others.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:26:25 GMT""}]","2021-02-04"
"2102.01743","Omar El-Fallah","M. Bourass, O. El-Fallah, I. Marrhich and H. Naqos","On singular values of Hankel operators on Bergman spaces","34 pages",,,,"math.CA math.CV math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the behavior of the singular values of Hankel
operators on weighted Bergman spaces $A^2_{\omega _\varphi}$, where $\omega
_\varphi= e^{-\varphi}$ and $\varphi$ is a subharmonic function. We consider
compact Hankel operators $H_{\overline {\phi}}$, with anti-analytic symbols
${\overline {\phi}}$, and give estimates of the trace of $h(|H_{\overline
\phi}|)$ for any convex function $h$. This allows us to give asymptotic
estimates of the singular values $(s_n(H_{\overline {\phi}}))_n$ in terms of
decreasing rearrangement of $|\phi '|/\sqrt{\Delta \varphi}$. For the radial
weights, we first prove that the critical decay of $(s_n(H_{\overline
{\phi}}))_n$ is achieved by $(s_n (H_{\overline{z}}))_n$. Namely, we establish
that if $s_n(H_{\overline {\phi}})= o (s_n(H_{\overline {z}}))$, then
$H_{\overline {\phi}} = 0$. Then, we show that if $\Delta \varphi (z) \asymp
\frac{1}{(1-|z|^2)^{2+\beta}}$ with $\beta \geq 0$, then $s_n(H_{\overline
{\phi}}) = O(s_n(H_{\overline {z}}))$ if and only if $\phi '$ belongs to the
Hardy space $H^p$, where $p= \frac{2(1+\beta)}{2+\beta}$. Finally, we compute
the asymptotics of $s_n(H_{\overline {\phi}})$ whenever $ \phi ' \in H^{p }$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:27:10 GMT""}]","2021-02-04"
"2102.01744","Roger Zhe Li","Roger Zhe Li, Juli\'an Urbano, Alan Hanjalic","Leave No User Behind: Towards Improving the Utility of Recommender
  Systems for Non-mainstream Users","9 pages, 6 figures, accepted to WSDM 2021",,"10.1145/3437963.3441769 10.1145/3437963.3441769 10.1145/3437963.3441769",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  In a collaborative-filtering recommendation scenario, biases in the data will
likely propagate in the learned recommendations. In this paper we focus on the
so-called mainstream bias: the tendency of a recommender system to provide
better recommendations to users who have a mainstream taste, as opposed to
non-mainstream users. We propose NAECF, a conceptually simple but effective
idea to address this bias. The idea consists of adding an autoencoder (AE)
layer when learning user and item representations with text-based Convolutional
Neural Networks. The AEs, one for the users and one for the items, serve as
adversaries to the process of minimizing the rating prediction error when
learning how to recommend. They enforce that the specific unique properties of
all users and items are sufficiently well incorporated and preserved in the
learned representations. These representations, extracted as the bottlenecks of
the corresponding AEs, are expected to be less biased towards mainstream users,
and to provide more balanced recommendation utility across all users. Our
experimental results confirm these expectations, significantly improving the
recommendations for non-mainstream users while maintaining the recommendation
quality for mainstream users. Our results emphasize the importance of deploying
extensive content-based features, such as online reviews, in order to better
represent users and items to maximize the de-biasing effect.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:31:20 GMT""}]","2021-02-04"
"2102.01745","Martin Singh","Martin S. Singh and Morgan E O'Neill","The climate system and the second law of thermodynamics","70 pages, 14 figures, 2 tables","Reviews of Modern Physics, 94, 015001 (2022)","10.1103/RevModPhys.94.015001",,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  The second law of thermodynamics implies a relationship between the net
entropy export by the Earth and its internal irreversible entropy production.
The application of this constraint for the purpose of understanding Earth's
climate is reviewed. Both radiative processes and material processes are
responsible for irreversible entropy production in the climate system. Focusing
on material processes, an entropy budget for the climate system is derived
which accounts for the multi-phase nature of the hydrological cycle. The
entropy budget facilitates a heat-engine perspective of atmospheric
circulations that has been used to propose theories for convective updraft
velocities, tropical cyclone intensity, and the atmospheric meridional heat
transport. Such theories can only be successful, however, if they properly
account for the irreversible entropy production associated with water in all
its phases in the atmosphere. Irreversibility associated with such moist
processes is particularly important in the context of global climate change,
for which the concentration of water vapor in the atmosphere is expected to
increase, and recent developments toward understanding the response of the
atmospheric heat engine to climate change are discussed. Finally, the
application of variational approaches to the climate and geophysical flows is
briefly reviewed, including the use of equilibrium statistical mechanics to
predict behavior of long-lived coherent structures, and the controversial
maximum entropy production principle.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:33:13 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 01:53:45 GMT""},{""version"":""v3"",""created"":""Mon, 17 Jan 2022 06:12:13 GMT""}]","2022-01-19"
"2102.01746","Ivine Kuruvila","Ivine Kuruvila, Kubilay Can Demir, Eghart Fischer and Ulrich Hoppe","Inference of the Selective Auditory Attention using Sequential LMMSE
  Estimation","12 pages, 13 figures",,,,"eess.AS eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attentive listening in a multispeaker environment such as a cocktail party
requires suppression of the interfering speakers and the noise around. People
with normal hearing perform remarkably well in such situations. Analysis of the
cortical signals using electroencephalography (EEG) has revealed that the EEG
signals track the envelope of the attended speech stronger than that of the
interfering speech. This has enabled the development of algorithms that can
decode the selective attention of a listener in controlled experimental
settings. However, often these algorithms require longer trial duration and
computationally expensive calibration to obtain a reliable inference of
attention. In this paper, we present a novel framework to decode the attention
of a listener within trial durations of the order of two seconds. It comprises
of three modules: 1) Dynamic estimation of the temporal response functions
(TRF) in every trial using a sequential linear minimum mean squared error
(LMMSE) estimator, 2) Extract the N1-P2 peak of the estimated TRF that serves
as a marker related to the attentional state and 3) Obtain a probabilistic
measure of the attentional state using a support vector machine followed by a
logistic regression. The efficacy of the proposed decoding framework was
evaluated using EEG data collected from 27 subjects. The total number of
electrodes required to infer the attention was four: One for the signal
estimation, one for the noise estimation and the other two being the reference
and the ground electrodes. Our results make further progress towards the
realization of neuro-steered hearing aids.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:39:03 GMT""}]","2021-02-04"
"2102.01747","Vin\'icius da Silva","Vin\'icius da Silva, Tiago Novello, H\'elio Lopes, Luiz Velho","Real-time rendering of complex fractals","11 pages, 4 figures",,,,"cs.GR math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This chapter describes how to use intersection and closest-hit shaders to
implement real-time visualizations of complex fractals using distance
functions. The Mandelbulb and Julia Sets are used as examples.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:44:59 GMT""}]","2021-02-04"
"2102.01748","Ming Yin","Ming Yin, Yu Bai, Yu-Xiang Wang","Near-Optimal Offline Reinforcement Learning via Double Variance
  Reduction",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of offline reinforcement learning (RL) -- a
well-motivated setting of RL that aims at policy optimization using only
historical data. Despite its wide applicability, theoretical understandings of
offline RL, such as its optimal sample complexity, remain largely open even in
basic settings such as \emph{tabular} Markov Decision Processes (MDPs).
  In this paper, we propose Off-Policy Double Variance Reduction (OPDVR), a new
variance reduction based algorithm for offline RL. Our main result shows that
OPDVR provably identifies an $\epsilon$-optimal policy with
$\widetilde{O}(H^2/d_m\epsilon^2)$ episodes of offline data in the
finite-horizon stationary transition setting, where $H$ is the horizon length
and $d_m$ is the minimal marginal state-action distribution induced by the
behavior policy. This improves over the best known upper bound by a factor of
$H$. Moreover, we establish an information-theoretic lower bound of
$\Omega(H^2/d_m\epsilon^2)$ which certifies that OPDVR is optimal up to
logarithmic factors. Lastly, we show that OPDVR also achieves rate-optimal
sample complexity under alternative settings such as the finite-horizon MDPs
with non-stationary transitions and the infinite horizon MDPs with discounted
rewards.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:47:35 GMT""}]","2021-02-04"
"2102.01749","Ali Rahimpour Jounghani","Zahra Salahshoori Nejad, Hamed Heravi, Ali Rahimpour Jounghani,
  Abdollah Shahrezaie, Afshin Ebrahimi","Vehicle trajectory prediction in top-view image sequences based on deep
  learning method",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Annually, a large number of injuries and deaths around the world are related
to motor vehicle accidents. This value has recently been reduced to some
extent, via the use of driver-assistance systems. Developing driver-assistance
systems (i.e., automated driving systems) can play a crucial role in reducing
this number. Estimating and predicting surrounding vehicles' movement is
essential for an automated vehicle and advanced safety systems. Moreover,
predicting the trajectory is influenced by numerous factors, such as drivers'
behavior during accidents, history of the vehicle's movement and the
surrounding vehicles, and their position on the traffic scene. The vehicle must
move over a safe path in traffic and react to other drivers' unpredictable
behaviors in the shortest time. Herein, to predict automated vehicles' path, a
model with low computational complexity is proposed, which is trained by images
taken from the road's aerial image. Our method is based on an encoder-decoder
model that utilizes a social tensor to model the effect of the surrounding
vehicles' movement on the target vehicle. The proposed model can predict the
vehicle's future path in any freeway only by viewing the images related to the
history of the target vehicle's movement and its neighbors. Deep learning was
used as a tool for extracting the features of these images. Using the HighD
database, an image dataset of the road's aerial image was created, and the
model's performance was evaluated on this new database. We achieved the RMSE of
1.91 for the next 5 seconds and found that the proposed method had less error
than the best path-prediction methods in previous studies.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:48:19 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 03:06:01 GMT""},{""version"":""v3"",""created"":""Sun, 16 May 2021 18:39:08 GMT""}]","2021-05-18"
"2102.01750","Shira Faigenbaum-Golovin","Shira Faigenbaum-Golovin, David Levin","Manifold Repairing, Reconstruction and Denoising from Scattered Data in
  High-Dimension","arXiv admin note: text overlap with arXiv:2012.13804,
  arXiv:2012.12546",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We consider a problem of great practical interest: the repairing and recovery
of a low-dimensional manifold embedded in high-dimensional space from noisy
scattered data. Suppose that we observe a point cloud sampled from the
low-dimensional manifold, with noise, and let us assume that there are holes in
the data. Can we recover missing information inside the holes? While in
low-dimension the problem was extensively studied, manifold repairing in high
dimension is still an open problem. We introduce a new approach, called
Repairing Manifold Locally Optimal Projection (R-MLOP), that expands the MLOP
method introduced by Faigenbaum-Golovin et al. in 2020, to cope with manifold
repairing in low and high-dimensional cases. The proposed method can deal with
multiple holes in a manifold. We prove the validity of the proposed method, and
demonstrate the effectiveness of our approach by considering different manifold
topologies, for single and multiple holes repairing, in low and high
dimensions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:52:48 GMT""}]","2021-02-04"
"2102.01751","Qianqian Zhang","Qianqian Zhang, Aidin Ferdowsi, Walid Saad, Mehdi Bennis","Distributed Conditional Generative Adversarial Networks (GANs) for
  Data-Driven Millimeter Wave Communications in UAV Networks",,,,,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a novel framework is proposed to perform data-driven
air-to-ground (A2G) channel estimation for millimeter wave (mmWave)
communications in an unmanned aerial vehicle (UAV) wireless network. First, an
effective channel estimation approach is developed to collect mmWave channel
information, allowing each UAV to train a stand-alone channel model via a
conditional generative adversarial network (CGAN) along each beamforming
direction. Next, in order to expand the application scenarios of the trained
channel model into a broader spatial-temporal domain, a cooperative framework,
based on a distributed CGAN architecture, is developed, allowing each UAV to
collaboratively learn the mmWave channel distribution in a fully-distributed
manner. To guarantee an efficient learning process, necessary and sufficient
conditions for the optimal UAV network topology that maximizes the learning
rate for cooperative channel modeling are derived, and the optimal CGAN
learning solution per UAV is subsequently characterized, based on the
distributed network structure. Simulation results show that the proposed
distributed CGAN approach is robust to the local training error at each UAV.
Meanwhile, a larger airborne network size requires more communication resources
per UAV to guarantee an efficient learning rate. The results also show that,
compared with a stand-alone CGAN without information sharing and two other
distributed schemes, namely: A multi-discriminator CGAN and a federated CGAN
method, the proposed distributed CGAN approach yields a higher modeling
accuracy while learning the environment, and it achieves a larger average data
rate in the online performance of UAV downlink mmWave communications.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:56:46 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 20:48:24 GMT""}]","2021-08-03"
"2102.01752","Alexander Korotin","Alexander Korotin, Lingxiao Li, Justin Solomon, Evgeny Burnaev","Continuous Wasserstein-2 Barycenter Estimation without Minimax
  Optimization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wasserstein barycenters provide a geometric notion of the weighted average of
probability measures based on optimal transport. In this paper, we present a
scalable algorithm to compute Wasserstein-2 barycenters given sample access to
the input measures, which are not restricted to being discrete. While past
approaches rely on entropic or quadratic regularization, we employ input convex
neural networks and cycle-consistency regularization to avoid introducing bias.
As a result, our approach does not resort to minimax optimization. We provide
theoretical analysis on error bounds as well as empirical evidence of the
effectiveness of the proposed approach in low-dimensional qualitative scenarios
and high-dimensional quantitative experiments.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:01:13 GMT""}]","2022-01-02"
"2102.01753","Alexander Giessing","Alexander Giessing and Jingshen Wang","Debiased Inference on Heterogeneous Quantile Treatment Effects with
  Regression Rank-Scores","123 pages, 4 figures, 2 tables",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Understanding treatment effect heterogeneity is vital to many scientific
fields because often the same treatment affects different individuals
differently. Quantile regression provides a natural framework for modeling such
heterogeneity. We propose a new method for inference on heterogeneous quantile
treatment effects in the presence of high-dimensional covariates. Our estimator
combines an $\ell_1$-penalized regression adjustment with a quantile-specific
bias correction scheme based on rank scores. We study the theoretical
properties of this estimator, including weak convergence of the heterogeneous
quantile treatment effect process to a Gaussian process. We illustrate the
finite-sample performance of our approach through simulations and an empirical
example, dealing with the differential effect of statin usage for lowering
low-density lipoprotein cholesterol levels for the Alzheimer's disease patients
who participated in the UK Biobank study.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:06:41 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 00:08:19 GMT""},{""version"":""v3"",""created"":""Mon, 17 Jan 2022 10:39:30 GMT""},{""version"":""v4"",""created"":""Mon, 14 Nov 2022 18:01:37 GMT""}]","2022-11-15"
"2102.01755","Natalia Tapia Arellano","Natalia Tapia Arellano, Shunsaku Horiuchi","Measuring solar neutrinos over Gigayear timescales with Paleo Detectors","9 pages, 7 figures","Phys. Rev. D 103, 123016 (2021)","10.1103/PhysRevD.103.123016",,"hep-ph astro-ph.HE astro-ph.IM astro-ph.SR hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measuring the solar neutrino flux over gigayear timescales could provide a
new window to inform the Solar Standard Model as well as studies of the Earth's
long-term climate. We demonstrate the feasibility of measuring the
time-evolution of the $^8$B solar neutrino flux over gigayear timescales using
paleo detectors, naturally occurring minerals which record neutrino-induced
recoil tracks over geological times. We explore suitable minerals and identify
track lengths of 15--30 nm to be a practical window to detect the $^8$B solar
neutrino flux. A collection of ultra-radiopure minerals of different ages, each
some 0.1 kg by mass, can be used to probe the rise of the $^8$B solar neutrino
flux over the recent gigayear of the Sun's evolution. We also show that models
of the solar abundance problem can be distinguished based on the
time-integrated tracks induced by the $^8$B solar neutrino flux.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:09:31 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 15:44:53 GMT""}]","2021-06-23"
"2102.01756","Manh-Huong Phan","Kee Young Hwang, Valery Ortiz Jimenez, Baleeswaraiah Muchharla,
  Tatiana Eggers, Anh-Tuan Le, Vu Dinh Lam, and Manh-Huong Phan","A Novel Magnetic Respiratory Sensor for Human Healthcare",,,,,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Breathing is vital to life. Therefore, the real-time monitoring of breathing
pattern of a patient is crucial to respiratory rehabilitation therapies such as
magnetic resonance exams for respiratory-triggered imaging, chronic pulmonary
disease treatment, and synchronized functional electrical stimulation. While
numerous respiratory devices have been developed, they are often in direct
contact with a patient, which can yield inaccurate or limited data. In this
study, we developed a novel, non-invasive, and contactless magnetic sensing
platform that can precisely monitor breathing, movement, or sleep patterns of a
patient, thus providing efficient monitoring at a clinic or home. A magneto-LC
resonance (MLCR) sensor converts the magnetic oscillations generated by
breathing of the patient into an impedance spectrum, which allows for a deep
analysis of breath variation to identify respiratory-related diseases like
COVID-19. Owing to its ultrahigh sensitivity, the MLCR sensor yields a distinct
breathing pattern for each patient tested. The sensor also provides an accurate
measure of the strength of breath at multiple stages as well as anomalous
variations in respiratory rate and amplitude. This suggests that the MLCR
sensor can detect symptoms of COVID-19 in a patient due to shortness of breath
or difficulty breathing as well as track the progress of the disease in real
time.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:14:33 GMT""}]","2021-02-04"
"2102.01757","Elizabeth Salesky","Elizabeth Salesky, Matthew Wiesner, Jacob Bremerman, Roldano Cattoni,
  Matteo Negri, Marco Turchi, Douglas W. Oard, Matt Post","The Multilingual TEDx Corpus for Speech Recognition and Translation","Accepted to Interspeech 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Multilingual TEDx corpus, built to support speech recognition
(ASR) and speech translation (ST) research across many non-English source
languages. The corpus is a collection of audio recordings from TEDx talks in 8
source languages. We segment transcripts into sentences and align them to the
source-language audio and target-language translations. The corpus is released
along with open-sourced code enabling extension to new talks and languages as
they become available. Our corpus creation methodology can be applied to more
languages than previous work, and creates multi-way parallel evaluation sets.
We provide baselines in multiple ASR and ST settings, including multilingual
models to improve translation performance for low-resource language pairs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:16:25 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 03:36:12 GMT""}]","2021-06-16"
"2102.01758","Andrew Miller","Andrew J. Miller and Mitchell Brickson and Will J. Hardy and Chia-You
  Liu and Jiun-Yun Li and Andrew Baczewski and Michael P. Lilly and Tzu-Ming Lu
  and Dwight R. Luhman","Effective out-of-plane g-factor in strained-Ge/SiGe quantum dots",,,"10.1103/PhysRevB.106.L121402",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, lithographic quantum dots in strained-Ge/SiGe have become a
promising candidate for quantum computation, with a remarkably quick
progression from demonstration of a quantum dot to qubit logic demonstrations.
Here we present a measurement of the out-of-plane $g$-factor for single-hole
quantum dots in this material. As this is a single-hole measurement, this is
the first experimental result that avoids the strong orbital effects present in
the out-of-plane configuration. In addition to verifying the expected
$g$-factor anisotropy between in-plane and out-of-plane magnetic ($B$)-fields,
variations in the $g$-factor dependent on the occupation of the quantum dot are
observed. These results are in good agreement with calculations of the
$g$-factor using the heavy- and light-hole spaces of the Luttinger Hamiltonian,
especially the first two holes, showing a strong spin-orbit coupling and
suggesting dramatic $g$-factor tunability through both the $B$-field and the
charge state.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:18:08 GMT""}]","2022-10-05"
"2102.01759","Hideyuki Miyahara","Hideyuki Miyahara and Vwani Roychowdhury","Ansatz-Independent Variational Quantum Classifier","95 pages",,,,"quant-ph cond-mat.stat-mech stat.ML","http://creativecommons.org/licenses/by/4.0/","  The paradigm of variational quantum classifiers (VQCs) encodes
\textit{classical information} as quantum states, followed by quantum
processing and then measurements to generate classical predictions. VQCs are
promising candidates for efficient utilization of a near-term quantum device:
classifiers involving $M$-dimensional datasets can be implemented with only
$\lceil \log_2 M \rceil$ qubits by using an amplitude encoding. A general
framework for designing and training VQCs, however, has not been proposed, and
a fundamental understanding of its power and analytical relationships with
classical classifiers are not well understood. An encouraging specific
embodiment of VQCs, quantum circuit learning (QCL), utilizes an ansatz: it
expresses the quantum evolution operator as a circuit with a predetermined
topology and parametrized gates; training involves learning the gate parameters
through optimization. In this letter, we first address the open questions about
VQCs and then show that they, including QCL, fit inside the well-known kernel
method. Based on such correspondence, we devise a design framework of efficient
ansatz-independent VQCs, which we call the unitary kernel method (UKM): it
directly optimizes the unitary evolution operator in a VQC. Thus, we show that
the performance of QCL is bounded from above by the UKM. Next, we propose a
variational circuit realization (VCR) for designing efficient quantum circuits
for a given unitary operator. By combining the UKM with the VCR, we establish
an efficient framework for constructing high-performing circuits. We finally
benchmark the relatively superior performance of the UKM and the VCR via
extensive numerical simulations on multiple datasets.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:25:39 GMT""}]","2021-02-04"
"2102.01760","Luciana Ferrer","Luciana Ferrer, Mitchell McLaren, Niko Brummer","A Speaker Verification Backend with Robust Performance across Conditions",,"Computer Speech and Language, Volume 71, 2021","10.1016/j.csl.2021.101258",,"cs.SD cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we address the problem of speaker verification in conditions
unseen or unknown during development. A standard method for speaker
verification consists of extracting speaker embeddings with a deep neural
network and processing them through a backend composed of probabilistic linear
discriminant analysis (PLDA) and global logistic regression score calibration.
This method is known to result in systems that work poorly on conditions
different from those used to train the calibration model. We propose to modify
the standard backend, introducing an adaptive calibrator that uses duration and
other automatically extracted side-information to adapt to the conditions of
the inputs. The backend is trained discriminatively to optimize binary
cross-entropy. When trained on a number of diverse datasets that are labeled
only with respect to speaker, the proposed backend consistently and, in some
cases, dramatically improves calibration, compared to the standard PLDA
approach, on a number of held-out datasets, some of which are markedly
different from the training data. Discrimination performance is also
consistently improved. We show that joint training of the PLDA and the adaptive
calibrator is essential -- the same benefits cannot be achieved when freezing
PLDA and fine-tuning the calibrator. To our knowledge, the results in this
paper are the first evidence in the literature that it is possible to develop a
speaker verification system with robust out-of-the-box performance on a large
variety of conditions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:27:52 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 17:30:49 GMT""}]","2021-08-18"
"2102.01761","Sensong An","Sensong An, Bowen Zheng, Mikhail Y. Shalaginov, Hong Tang, Hang Li, Li
  Zhou, Yunxi Dong, Mohammad Haerinia, Anuradha Murthy Agarwal, Clara
  Rivero-Baleine, Myungkoo Kang, Kathleen A. Richardson, Tian Gu, Juejun Hu,
  Clayton Fowler and Hualiang Zhang","Deep Convolutional Neural Networks to Predict Mutual Coupling Effects in
  Metasurfaces","16 pages, 10 figures",,,,"physics.optics cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metasurfaces have provided a novel and promising platform for the realization
of compact and large-scale optical devices. The conventional metasurface design
approach assumes periodic boundary conditions for each element, which is
inaccurate in most cases since the near-field coupling effects between elements
will change when surrounded by non-identical structures. In this paper, we
propose a deep learning approach to predict the actual electromagnetic (EM)
responses of each target meta-atom placed in a large array with near-field
coupling effects taken into account. The predicting neural network takes the
physical specifications of the target meta-atom and its neighbors as input, and
calculates its phase and amplitude in milliseconds. This approach can be
applied to explain metasurfaces' performance deterioration caused by mutual
coupling and further used to optimize their efficiencies once combined with
optimization algorithms. To demonstrate the efficacy of this methodology, we
obtain large improvements in efficiency for a beam deflector and a metalens
over the conventional design approach. Moreover, we show the correlations
between a metasurface's performance and its design errors caused by mutual
coupling are not bound to certain specifications (materials, shapes, etc.). As
such, we envision that this approach can be readily applied to explore the
mutual coupling effects and improve the performance of various metasurface
designs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:27:56 GMT""}]","2021-02-04"
"2102.01762","Genildo Nery","Genildo de Jesus Nery","Profinite genus of fundamental groups of compact flat manifolds with the
  cyclic holonomy group of square-free order",,,,,"math.GR","http://creativecommons.org/licenses/by-sa/4.0/","  In this article we study the extent to which an $n$-dimensional compact flat
manifold with the cyclic holonomy group of square-free order may be
distinguished by the finite quotients of its fundamental group. In particular,
we display a formula for the cardinality of profinite genus of the fundamental
group of an $n$-dimensional compact flat manifold with the cyclic holonomy
group of square-free order.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:29:30 GMT""}]","2021-02-04"
"2102.01763","Manh-Huong Phan","O. Thiabgoh, T. Eggers, C. Albrecht, V.O. Jimenez, H. Shen, S.D.
  Jiang, J. F. Sun, D.S. Lam, V.D. Lam, and M.H. Phan","Optimization of the high-frequency magnetoimpedance response in
  melt-extracted Co-rich microwires through novel multiple-step Joule heating",,,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The optimization of high frequency giant magnetoimpedance (GMI) effect and
its magnetic field sensitivity in melt-extracted Co69.25Fe4.25Si13B12.5Nb1
amorphous microwires, through a multi-step Joule annealing (MSA) technique, was
systematically studied. The surface morphology, microstructure, surface
magnetic property, and high frequency GMI response of the Co-rich microwires
were explored using scanning electron microscopy (SEM), magneto-optical Kerr
effect (MOKE) magnetometry, transmission electron microscopy (TEM), and
impedance analyzer, respectively. An initial dc current (idc) of 20 mA, which
was then increased by 20 mA at every time-step (10 min) up to 300 mA, was
applied to the microwires. The MSA of 20 mA to 100 mA remarkably improved the
GMI ratio and its field sensitivity up to 760% (1.75 time of that of the
as-prepared), and 925%/Oe (more than 17.92 times of that of the as-prepared) at
an operating frequency of 20 MHz, respectively. Our study indicates that the
MSA technique can enhance the microstructures and the surface magnetic domain
structures of the Co-rich magnetic microwires, giving rise to the GMI
enhancement. This technique is suitable for improving the GMI sensitivity at
small magnetic fields, which is highly promising for biomedical sensing and
healthcare monitoring.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:30:55 GMT""}]","2021-02-04"
"2102.01764","Fatemeh Golshan","Ali Ansari and Fatemeh Golshan and Pejman Lotfi-Kamran and Hamid
  Sarbazi-Azad","MANA: Microarchitecting an Instruction Prefetcher","24 pages with 15 figures",,,,"cs.AR","http://creativecommons.org/licenses/by-sa/4.0/","  L1 instruction (L1-I) cache misses are a source of performance bottleneck.
Sequential prefetchers are simple solutions to mitigate this problem; however,
prior work has shown that these prefetchers leave considerable potentials
uncovered. This observation has motivated many researchers to come up with more
advanced instruction prefetchers. In 2011, Proactive Instruction Fetch (PIF)
showed that a hardware prefetcher could effectively eliminate all of the
instruction-cache misses. However, its enormous storage cost makes it an
impractical solution. Consequently, reducing the storage cost was the main
research focus in the instruction prefetching in the past decade. Several
instruction prefetchers, including RDIP and Shotgun, were proposed to offer
PIF-level performance with significantly lower storage overhead. However, our
findings show that there is a considerable performance gap between these
proposals and PIF. While these proposals use different mechanisms for
instruction prefetching, the performance gap is largely not because of the
mechanism, and instead, is due to not having sufficient storage. Prior
proposals suffer from one or both of the following shortcomings: (1) a large
number of metadata records to cover the potential, and (2) a high storage cost
of each record. The first problem causes metadata miss, and the second problem
prohibits the prefetcher from storing enough records within reasonably-sized
storage.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:32:52 GMT""}]","2021-02-04"
"2102.01765","Craig Roberts","Craig D. Roberts, David G. Richards, Tanja Horn and Lei Chang","Insights into the Emergence of Mass from Studies of Pion and Kaon
  Structure","110 pages, 41 figures, 5 tables. Accepted for publication in Prog.
  Part. Nucl. Phys",,"10.1016/j.ppnp.2021.103883","NJU-INP 034/21","hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are two mass generating mechanisms in the standard model of particle
physics (SM). One is related to the Higgs boson and fairly well understood. The
other is embedded in quantum chromodynamics (QCD), the SM's strong interaction
piece; and although responsible for emergence of the roughly 1 GeV mass scale
that characterises the proton and hence all observable matter, the source and
impacts of this emergent hadronic mass (EHM) remain puzzling. As bound states
seeded by a valence-quark and -antiquark, pseudoscalar mesons present a simpler
problem in quantum field theory than that associated with the nucleon.
Consequently, there is a large array of robust predictions for pion and kaon
properties whose empirical validation will provide a clear window onto many
effects of both mass generating mechanisms and the constructive interference
between them. This has now become significant because new-era experimental
facilities, in operation, construction, or planning, are capable of conducting
such tests and thereby contributing greatly to resolving the puzzles of EHM.
These aspects of experiment, phenomenology, and theory, along with contemporary
successes and challenges, are sketched herein, simultaneously highlighting the
potential gains that can accrue from a coherent effort aimed at finally
reaching an understanding of the character and structure of Nature's
Nambu-Goldstone modes.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:35:10 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 02:54:48 GMT""}]","2021-07-28"
"2102.01766","Pranab Sen","Sayantan Chakraborty and Aditya Nema and Pranab Sen","Novel one-shot inner bounds for unassisted fully quantum channels via
  rate splitting","34 pages, 5 figures",,,,"quant-ph cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We prove the first non-trivial one-shot inner bounds for sending quantum
information over an entanglement unassisted two-sender quantum multiple access
channel (QMAC) and an unassisted two-sender two-receiver quantum interference
channel (QIC). Previous works only studied the unassisted QMAC in the limit of
many independent and identical uses of the channel also known as the asymptotic
iid limit, and did not study the unassisted QIC at all. We employ two
techniques, rate splitting and successive cancellation}, in order to obtain our
inner bound. Rate splitting was earlier used to obtain inner bounds, avoiding
time sharing, for classical channels in the asymptotic iid setting. Our main
technical contribution is to extend rate splitting from the classical
asymptotic iid setting to the quantum one-shot setting. In the asymptotic iid
limit our one-shot inner bound for QMAC approaches the rate region of Yard,
Devetak and Hayden. For the QIC we get novel non-trivial rate regions in the
asymptotic iid setting. All our results also extend to the case where limited
entanglement assistance is provided, in both one-shot and asymptotic iid
settings. The limited entanglement results for one-setting for both QMAC and
QIC are new. For the QIC the limited entanglement results are new even in the
asymptotic iid setting.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:36:09 GMT""}]","2021-02-04"
"2102.01767","Jorge Miguel Ferreira Da Silva","Jorge Miguel Silva, Diogo Pratas, Rui Antunes, S\'ergio Matos, and
  Armando J. Pinho","Automatic analysis of artistic paintings using information-based
  measures","Website: http://panther.web.ua.pt 24 Pages; 19 pages article; 5 pages
  supplementary material","Pattern Recognition (2021) 107864","10.1016/j.patcog.2021.107864",,"cs.CV cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The artistic community is increasingly relying on automatic computational
analysis for authentication and classification of artistic paintings. In this
paper, we identify hidden patterns and relationships present in artistic
paintings by analysing their complexity, a measure that quantifies the sum of
characteristics of an object. Specifically, we apply Normalized Compression
(NC) and the Block Decomposition Method (BDM) to a dataset of 4,266 paintings
from 91 authors and examine the potential of these information-based measures
as descriptors of artistic paintings. Both measures consistently described the
equivalent types of paintings, authors, and artistic movements. Moreover,
combining the NC with a measure of the roughness of the paintings creates an
efficient stylistic descriptor. Furthermore, by quantifying the local
information of each painting, we define a fingerprint that describes critical
information regarding the artists' style, their artistic influences, and shared
techniques. More fundamentally, this information describes how each author
typically composes and distributes the elements across the canvas and,
therefore, how their work is perceived. Finally, we demonstrate that regional
complexity and two-point height difference correlation function are useful
auxiliary features that improve current methodologies in style and author
classification of artistic paintings. The whole study is supported by an
extensive website (http://panther.web.ua.pt) for fast author characterization
and authentication.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:40:30 GMT""}]","2021-02-10"
"2102.01768","Rasmus Andersson","Rasmus Andersson, Fabian {\AA}r\'en, Alejandro A. Franco and Patrik
  Johansson","CHAMPION: Chalmers Hierarchical Atomic, Molecular, Polymeric & Ionic
  Analysis Toolkit","11 pages, 8 figures",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present CHAMPION: a software developed to automatically detect
time-dependent bonds between atoms based on their dynamics, classify the local
graph topology around them, and analyze the physicochemical properties of these
topologies by statistical physics. In stark contrast to methodologies where
bonds are detected based on static conditions such as cut-off distances,
CHAMPION considers pairs of atoms to be bound only if they move together and
act as a bound pair over time. Furthermore, the time-dependent global bond
graph is possible to split into dynamically shifting connected components or
subgraphs around a certain chemical motif and thereby allow the physicochemical
properties of each such topology to be analyzed by statistical physics.
Applicable to condensed matter and liquids in general, and electrolytes in
particular, this allows both quantitative and qualitative descriptions of local
structure, as well as dynamical processes such as speciation and diffusion. We
present here a detailed overview of CHAMPION, including its underlying
methodology, implementation and capabilities.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:40:52 GMT""}]","2021-02-04"
"2102.01769","Adriano Zambom","Adriano Zanin Zambom, Qing Wang, Ronaldo Dias","A Basis Approach to Surface Clustering",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel method for clustering surfaces. The proposal
involves first using basis functions in a tensor product to smooth the data and
thus reduce the dimension to a finite number of coefficients, and then using
these estimated coefficients to cluster the surfaces via the k-means algorithm.
An extension of the algorithm to clustering tensors is also discussed. We show
that the proposed algorithm exhibits the property of strong consistency, with
or without measurement errors, in correctly clustering the data as the sample
size increases. Simulation studies suggest that the proposed method outperforms
the benchmark k-means algorithm which uses the original vectorized data. In
addition, an EGG real data example is considered to illustrate the practical
application of the proposal.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:41:28 GMT""}]","2021-02-04"
"2102.01770","Brendan David-John","Brendan David-John, Diane Hosfelt, Kevin Butler, Eakta Jain","A privacy-preserving approach to streaming eye-tracking data","12 pages, 4 figures, to appear in IEEE TVCG Special Issue on IEEE VR
  2021",,"10.1109/TVCG.2021.3067787",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eye-tracking technology is being increasingly integrated into mixed reality
devices. Although critical applications are being enabled, there are
significant possibilities for violating user privacy expectations. We show that
there is an appreciable risk of unique user identification even under natural
viewing conditions in virtual reality. This identification would allow an app
to connect a user's personal ID with their work ID without needing their
consent, for example. To mitigate such risks we propose a framework that
incorporates gatekeeping via the design of the application programming
interface and via software-implemented privacy mechanisms. Our results indicate
that these mechanisms can reduce the rate of identification from as much as 85%
to as low as 30%. The impact of introducing these mechanisms is less than
1.5$^\circ$ error in gaze position for gaze prediction. Gaze data streams can
thus be made private while still allowing for gaze prediction, for example,
during foveated rendering. Our approach is the first to support
privacy-by-design in the flow of eye-tracking data within mixed reality use
cases.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:43:01 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 20:36:31 GMT""}]","2021-03-23"
"2102.01771","Praneeth Kumar Vippathalla","Praneeth Kumar Vippathalla, Chung Chan, Navin Kashyap and Qiaoqiao
  Zhou","Secret Key Agreement and Secure Omniscience of Tree-PIN Source with
  Linear Wiretapper","13 pages, 2 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the wiretap secret key capacity remains unknown for general source
models even in the two-user case, we obtained a single-letter characterization
for a large class of multi-user source models with a linear wiretapper who can
observe any linear combinations of the source. We introduced the idea of
irreducible sources to show existence of an optimal communication scheme that
achieves perfect omniscience with minimum leakage of information to the
wiretapper. This implies a duality between the problems of wiretap secret key
agreement and secure omniscience, and such duality potentially holds for more
general sources.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:46:39 GMT""}]","2021-02-04"
"2102.01772","Yuxi Lu","Yuxi (Lucy) Lu, Ruth Angus, Jason L. Curtis, Trevor J. David, Rocio
  Kiman","Gyro-Kinematic Ages for around 30,000 Kepler Stars",,,"10.3847/1538-3881/abe4d6",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Estimating stellar ages is important for advancing our understanding of
stellar and exoplanet evolution and investigating the history of the Milky Way.
However, ages for low-mass stars are hard to infer as they evolve slowly on the
main sequence. In addition, empirical dating methods are difficult to calibrate
for low-mass stars as they are faint. In this work, we calculate ages for
Kepler F, G, and crucially K and M dwarfs, using their rotation and kinematic
properties. We apply the simple assumption that the velocity dispersion of
stars increases over time and adopt an age--velocity--dispersion relation (AVR)
to estimate average stellar ages for groupings of coeval stars. We calculate
the vertical velocity dispersion of stars in bins of absolute magnitude,
temperature, rotation period, and Rossby number and then convert velocity
dispersion to kinematic age via an AVR. Using this method, we estimate
gyro-kinematic ages for 29,949 Kepler stars with measured rotation periods. We
are able to estimate ages for clusters and asteroseismic stars with an RMS of
1.22 Gyr and 0.26 Gyr respectively. With our Astraea machine learning
algorithm, which predicts rotation periods, we suggest a new selection
criterion (a weight of 0.15) to increase the size of the McQuillian et al.
(2014) catalog of Kepler rotation periods by up to 25%. Using predicted
rotation periods, we estimated gyro-kinematic ages for stars without measured
rotation periods and found promising results by comparing 12 detailed
age--element abundance trends with literature values.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:49:48 GMT""}]","2022-03-23"
"2102.01773","Niels Kj{\ae}rgaard","R. Thomas, J. S. Otto, M. Chilcott, A.B. Deb, and N. Kj{\ae}rgaard","Reducing number fluctuations in an ultracold atomic sample using Faraday
  rotation and iterative feedback","This updated version is based on new data set",,,,"cond-mat.quant-gas physics.ins-det quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We demonstrate a method to reduce number fluctuations in an ultracold atomic
sample using real-time feedback. By measuring the Faraday rotation of an
off-resonant probe laser beam with a pair of avalanche photodetectors in a
polarimetric setup we produce a proxy for the number of atoms in the sample. We
iteratively remove a fraction of the excess atoms from the sample to converge
on a target proxy value in a way that is insensitive to environmental
perturbations and robust to errors in light polarization. Using absorption
imaging for out-of-loop verification, we demonstrate a reduction in the number
fluctuations from $3\%$ to $0.45\%$ for samples at a temperature of 16.4 $\mu$K
over the time-scale of several hours which is limited by temperature
fluctuations, beam pointing noise, and photon shot noise.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:57:12 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 02:57:12 GMT""}]","2021-09-17"
"2102.01774","Rodrigo Luger","Rodrigo Luger, Daniel Foreman-Mackey, and Christina Hedges","starry_process: Interpretable Gaussian processes for stellar light
  curves","4 pages, 3 figures. To be submitted to JOSS. Updated references",,,,"astro-ph.SR astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we present the starry_process code, which implements an
interpretable Gaussian process (GP) for modeling variability in stellar light
curves. As dark starspots rotate in and out of view, the total flux received
from a distant star will change over time. Unresolved flux time series
therefore encode information about the spatial structure of features on the
stellar surface. The starry_process software package allows one to easily model
the flux variability due to starspots, whether one is interested in
understanding the properties of these spots or marginalizing over the stellar
variability when it is treated as a nuisance signal. The main difference
between the GP implemented here and typical GPs used to model stellar
variability is the explicit dependence of our GP on physical properties of the
star, such as its period, inclination, and limb darkening coefficients, and on
properties of the spots, such as their radius and latitude distributions. This
code is the Python implementation of the interpretable GP algorithm developed
in Luger, Foreman-Mackey, and Hedges (2021).
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:00:50 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 14:15:42 GMT""}]","2021-02-10"
"2102.01775","Chun Kai Ling","Chun Kai Ling, Noam Brown","Safe Search for Stackelberg Equilibria in Extensive-Form Games",,,,,"cs.GT cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Stackelberg equilibrium is a solution concept in two-player games where the
leader has commitment rights over the follower. In recent years, it has become
a cornerstone of many security applications, including airport patrolling and
wildlife poaching prevention. Even though many of these settings are sequential
in nature, existing techniques pre-compute the entire solution ahead of time.
In this paper, we present a theoretically sound and empirically effective way
to apply search, which leverages extra online computation to improve a
solution, to the computation of Stackelberg equilibria in general-sum games.
Instead of the leader attempting to solve the full game upfront, an approximate
""blueprint"" solution is first computed offline and is then improved online for
the particular subgames encountered in actual play. We prove that our search
technique is guaranteed to perform no worse than the pre-computed blueprint
strategy, and empirically demonstrate that it enables approximately solving
significantly larger games compared to purely offline methods. We also show
that our search operation may be cast as a smaller Stackelberg problem, making
our method complementary to existing algorithms based on strategy generation.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:01:19 GMT""}]","2021-02-04"
"2102.01776","Brodie Popovic","Brodie Popovic, Dillon Brout, Richard Kessler, Dan Scolnic, Lisa Lu","Improved Treatment of Host-Galaxy Correlations in Cosmological Analyses
  With Type Ia Supernovae",,,"10.3847/1538-4357/abf14f",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Improving the use of Type Ia supernovae (SNIa) as standard candles requires a
better approach to incorporate the relationship between SNIa and the properties
of their host galaxies. Using a spectroscopically-confirmed sample of
$\sim$1600 SNIa, we develop the first empirical model of underlying populations
for SNIa light-curve properties that includes their dependence on host-galaxy
stellar mass. These populations are important inputs to simulations that are
used to model selection effects and correct distance biases within the BEAMS
with Bias Correction (BBC) framework. Here we improve BBC to also account for
SNIa-host correlations, and we validate this technique on simulated data
samples. We recover the input relationship between SNIa luminosity and
host-galaxy stellar mass (the mass step, $\gamma$) to within 0.004 mags, which
is a factor of 5 improvement over the previous method that results in a
$\gamma$-bias of ${\sim}0.02$. We adapt BBC for a novel dust-based model of
intrinsic brightness variations, which results in a greatly reduced mass step
for data ($\gamma = 0.017 \pm 0.008$), and for simulations ($\gamma =0.006 \pm
0.007$). Analysing simulated SNIa, the biases on the dark energy
equation-of-state, $w$, vary from $\Delta w = 0.006(5)$ to $0.010(5)$ with our
new BBC method; these biases are significantly smaller than the $0.02(5)$
$w$-bias using previous BBC methods that ignore SNIa-host correlations.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:01:19 GMT""}]","2021-06-02"
"2102.01777","Enrique Vasco","Enrique Vasco (1), Mar\'ia J. Ram\'irez-Peral (1 and 2), Alfredo
  Jacas-Rodr\'iguez (1) and Celia Polop (2 and 3 and 4), ((1) Instituto de
  Ciencia de Materiales de Madrid-CSIC, (2) Departamento de F\'isica de la
  Materia Condensada-Universidad Aut\'onoma de Madrid, (3) Condensed Matter
  Physics Center-Universidad Aut\'onoma de Madrid, (4) Instituto Universitario
  de Ciencia de Materiales Nicol\'as Cabrera-Universidad Aut\'onoma de Madrid)","Kinetics of Intrinsic Stress in Nanocrystalline Films","19 pages including Accepted Manuscript, 3 Figures and Supplementary
  Information (pages 15-18)",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional polycrystalline materials acquire high levels of intrinsic
mechanical stress (ranging from MPa to a few GPa) during preparation and use,
but this stress decays quickly (~minutes) to small residual values (~kPa) under
standard resting conditions. Nanocrystalline materials reach similar or even
higher levels of intrinsic stress, but surprisingly retain a significant
portion of this stress over much longer time scales (~hours). This behavior
directly contradicts current theoretical models that predict stress relaxation
through diffusive currents. Diffusive currents, which flow mainly on the
surfaces of grains, are expected to produce faster relaxation kinetics when the
stress to be released is higher. In this work, we study the kinetics of
intrinsic stress relaxation in nanocrystalline films and identify the
limitations of this process as a preliminary step towards designing a strategy
for high-stress stabilization in nanostructured systems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:01:48 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 09:19:57 GMT""}]","2021-05-26"
"2102.01778","Christina Giannitsi","Christina Giannitsi","Averaging with the Divisor Function: $\ell^p$-improving and Sparse
  Bounds","13 pages. Updated version: some typos fixed and some references added
  as per reviewer recommendations. To appear in Rocky Mountain Journal of
  Mathematics",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  We study averages along the integers using the divisor function $d(n)$, and
defined as $$K_N f (x) = \frac{1}{D(N)} \sum _{n \leq N} d(n) \,f(x+n) , $$
where $D(N) = \sum _{n=1} ^N d(n) $. We shall show that these averages satisfy
a uniform, scale free $\ell^p$-improving estimate for $p \in (1,2)$, that is $$
\left( \frac{1}{N} \sum |K_Nf|^{p'} \right)^{1/p'} \lesssim \left(\frac{1}{N}
\sum |f|^p \right)^{1/p} $$ as long as $f$ is supported on $[0,N]$.
  We also show that the associated maximal function $K^*f = \sup_N |K_N f|$
satisfies $(p,p)$ sparse founds for $p \in (1,2)$, which implies that $K^*$ is
bounded on $\ell ^p (w)$ for $p \in (1, \infty )$, for all weights $w$ in the
Muckenhoupt $A_p$ class.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:09:32 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 21:03:12 GMT""}]","2022-04-01"
"2102.01779","Luc  Vinet","Luc Vinet, Alexei Zhedanov","An algebraic treatment of the Askey biorthogonal polynomials on the unit
  circle","28 pages, 1 figure",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A joint algebraic interpretation of the biorthogonal Askey polynomials on the
unit circle and of the orthogonal Jacobi polynomials is offered. It ties their
bispectral properties to an algebra called the meta-Jacobi algebra
$m\mathfrak{J}$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:14:05 GMT""}]","2021-02-04"
"2102.01780","Daniel Severin Dr.","Mauro Lucci, Daniel Sever\'in, Paula Zabala","A metaheuristic for crew scheduling in a pickup-and-delivery problem
  with time windows",,,,,"cs.AI cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A vehicle routing and crew scheduling problem (VRCSP) consists of
simultaneously planning the routes of a fleet of vehicles and scheduling the
crews, where the vehicle-crew correspondence is not fixed through time. This
allows a greater planning flexibility and a more efficient use of the fleet,
but in counterpart, a high synchronisation is demanded. In this work, we
present a VRCSP where pickup-and-delivery requests with time windows have to be
fulfilled over a given planning horizon by using trucks and drivers. Crews can
be composed of 1 or 2 drivers and any of them can be relieved in a given set of
locations. Moreover, they are allowed to travel among locations with
non-company shuttles, at an additional cost that is minimised. As our problem
considers distinct routes for trucks and drivers, we have an additional
flexibility not contemplated in other previous VRCSP given in the literature
where a crew is handled as an indivisible unit. We tackle this problem with a
two-stage sequential approach: a set of truck routes is computed in the first
stage and a set of driver routes consistent with the truck routes is obtained
in the second one. We design and evaluate the performance of a metaheuristic
based algorithm for the latter stage. Our algorithm is mainly a GRASP with a
perturbation procedure that allows reusing solutions already found in case the
search for new solutions becomes difficult. This procedure together with other
to repair infeasible solutions allow us to find high-quality solutions on
instances of 100 requests spread across 15 cities with a fleet of 12-32 trucks
(depending on the planning horizon) in less than an hour. We also conclude that
the possibility of carrying an additional driver leads to a decrease of the
cost of external shuttles by about 60% on average with respect to individual
crews and, in some cases, to remove this cost completely.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:14:10 GMT""}]","2021-02-04"
"2102.01781","Robert de Keijzer","R.J.P.T. de Keijzer, V.E. Colussi, B. \v{S}kori\'c, and S.J.J.M.F.
  Kokkelmans","Optimization of the Variational Quantum Eigensolver for Quantum
  Chemistry Applications","13 pages, 6 figures","AVS Quantum Sci. 4, 013803 (2022)","10.1116/5.0076435",,"quant-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  This work studies the variational quantum eigensolver algorithm, designed to
determine the ground state of a quantum mechanical system by combining
classical and quantum hardware. Methods of reducing the number of required
qubit manipulations, prone to induce errors, for the variational quantum
eigensolver are studied. We formally justify the qubit removal process as
sketched by Bravyi, Gambetta, Mezzacapo and Temme [arXiv:1701.08213 (2017)].
Furthermore, different classical optimization and entangling methods, both gate
based and native, are surveyed by computing ground state energies of H$_2$ and
LiH. This paper aims to provide performance-based recommendations for
entangling methods and classical optimization methods. Analyzing the VQE
problem is complex, where the optimization algorithm, the method of entangling,
and the dimensionality of the search space all interact. In specific cases
however, concrete results can be shown, and an entangling method or
optimization algorithm can be recommended over others. In particular we find
that for high dimensionality (many qubits and/or entanglement depth) certain
classical optimization algorithms outperform others in terms of energy error.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:20:12 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 13:19:48 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 16:01:19 GMT""}]","2022-03-01"
"2102.01782","Viktor Iv\'ady","Oscar Bulancea Lindvall, Nguyen Tien Son, Igor A. Abrikosov, and
  Viktor Iv\'ady","Dipolar spin relaxation of divacancy qubits in silicon carbide",,,,,"cond-mat.mes-hall cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Divacancy spins in silicon carbide implement qubits with outstanding
characteristics and capabilities in an industrial semiconductor host. On the
other hand, there are still numerous open questions about the physics of
divacancy point defects, for instance, spin relaxation has not been thoroughly
studied yet. Here, we carry out a theoretical study on environmental spin
induced spin relaxation processes of divacancy qubits in 4H-SiC. We reveal all
the relevant magnetic field values where the longitudinal spin relaxation time
T$_1$ drops resonantly due to the coupling to either nuclear spins or electron
spins. We quantitatively analyze the dependence of the T$_1$ time on the
concentration of point defect spins and the applied magnetic field in the most
relevant cases and provide an analytical expression. We demonstrate that
dipolar spin relaxation plays a significant role both in as-grown and ion
implanted samples and it often limits the coherence time in 4H-SiC.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:23:43 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 08:09:21 GMT""}]","2021-09-29"
"2102.01783","Kun Zhang","Kun Zhang, Pooja Rao, Kwangmin Yu, Hyunkyung Lim, Vladimir Korepin","Implementation of efficient quantum search algorithms on NISQ computers","Published version, 26 pages, 8 figures","Quantum Inf. Process. 20, 233 (2021)","10.1007/s11128-021-03165-2",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the advent of Grover's algorithm for the unstructured search, its
successful implementation on near-term quantum devices is still limited. We
apply three strategies to reduce the errors associated with implementing
quantum search algorithms. Our improved search algorithms have been implemented
on the IBM quantum processors. Using them, we demonstrate three- and four-qubit
search algorithm with higher average success probabilities compared to previous
works. We present the successful execution of the five-qubit search on the IBM
quantum processor for the first time. The results have been benchmarked using
degraded ratio, which is the ratio between the experimental and the theoretical
success probabilities. The fast decay of the degraded ratio supports our
divide-and-conquer strategy. Our proposed strategies are also useful for
implementation of quantum search algorithms in the post-NISQ era.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:30:30 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 14:20:47 GMT""}]","2021-07-13"
"2102.01784","Scott Bruce","Pramita Bagchi and Scott A. Bruce","Adaptive Frequency Band Analysis for Functional Time Series","33 pages, 5 figures, 1 table",,,,"stat.ME math.ST stat.AP stat.CO stat.TH","http://creativecommons.org/licenses/by/4.0/","  The frequency-domain properties of nonstationary functional time series often
contain valuable information. These properties are characterized through its
time-varying power spectrum. Practitioners seeking low-dimensional summary
measures of the power spectrum often partition frequencies into bands and
create collapsed measures of power within bands. However, standard frequency
bands have largely been developed through manual inspection of time series data
and may not adequately summarize power spectra. In this article, we propose a
framework for adaptive frequency band estimation of nonstationary functional
time series that optimally summarizes the time-varying dynamics of the series.
We develop a scan statistic and search algorithm to detect changes in the
frequency domain. We establish theoretical properties of this framework and
develop a computationally-efficient implementation. The validity of our method
is also justified through numerous simulation studies and an application to
analyzing electroencephalogram data in participants alternating between eyes
open and eyes closed conditions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:33:37 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 21:19:25 GMT""}]","2021-03-12"
"2102.01785","Yong-Seon Song","Yong-Seon Song, Yi Zheng, Atsushi Taruya","Toward a more stringent test of gravity with redshift space power
  spectrum: simultaneous probe of growth and amplitude of large-scale structure","12 pages, 9 figures","Phys. Rev. D 104, 043528 (2021)","10.1103/PhysRevD.104.043528","YITP-21-09","astro-ph.CO","http://creativecommons.org/publicdomain/zero/1.0/","  Redshift-space distortions (RSD) offers an exciting opportunity to test the
gravity on cosmological scales. In the presence of galaxy bias, however, the
RSD measurement at large scales, where the linear theory prediction is safely
applied, is known to exhibit a degeneracy between the parameters of structure
growth f and fluctuation amplitude sigma8, and one can only constrain the
parameters in the form of fsigma8. In order to disentangle this degeneracy, in
this paper, we go beyond the linear theory, and consider the model of RSD
applicable to a weakly nonlinear regime. Based on the Fisher matrix analysis,
we show explicitly that the degeneracy of the parameter fsigma8 can be broken,
and sigma8 is separately estimated in the presence of galaxy bias. Performing
further the Markov chain Monte Carlo analysis, we verify that our model
correctly reproduces the fiducial values of fsigma8 and sigma8, with the
statistical errors consistent with those estimated from the Fisher matrix
analysis. We show that upcoming galaxy survey of the stage-IV class can
unambiguously determine sigma8 at the precision down to 10% at higher redshifts
even if we restrict the accessible scales to k<0.16h/Mpc
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:37:36 GMT""}]","2021-08-25"
"2102.01786","Nicos Makris","Nicos Makris","Impulse Response Function for Brownian Motion","arXiv admin note: substantial text overlap with arXiv:2004.05918","Soft Matter, Royal Society of Chemistry 2021","10.1039/d1sm00380a",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Motivated from the central role of the mean-square displacement and its
second time-derivative -- that is the velocity autocorrelation function
$\left\langle v(0)v(t)\right\rangle=\frac{1}{2} \frac{\mathrm{d}^{2}
\left\langle \Delta r^{2} (t)\right\rangle}{\mathrm{d}t^{2}} $ in the
description of Brownian motion, we revisit the physical meaning of the first
time-derivative of the mean-square displacement of Brownian particles. By
employing a rheological analogue for Brownian motion, we show that the
time-derivative of the mean-square displacement $\frac{\mathrm{d}\left\langle
\Delta r^{2} (t) \right\rangle}{\mathrm{d}t}$ of Brownian microspheres with
mass $m$ and radius $R$ immersed in any linear, isotropic viscoelastic material
is identical to $\frac{N K_B T}{3 \pi R}h(t)$, where $h(t)$ is the impulse
response function of a rheological network that is a parallel connection of the
linear viscoelastic material with an inerter with distributed inertance
$m_R=\frac{m}{6 \pi R}$. The impulse response function $h(t)=\frac{3\pi R}{N
K_B T}\frac{\mathrm{d}\left\langle \Delta r^{2} (t)
\right\rangle}{\mathrm{d}t}$ of the viscoelastic material-inerter parallel
connection derived in this paper at the stress-strain level of the rheological
analogue is essentially the response function $\chi(t)=\frac{h(t)}{6\pi R}$ of
the Brownian particles expressed at the force-displacement level by Nishi
\textit{et al.} (2018). By employing the viscoelastic material-inerter
rheological analogue we derive the mean-square displacement and its
time-derivatives of Brownian particles immersed in a viscoelastic material
described with a Maxwell element connected in parallel with a dashpot which
captures the high-frequency viscous behavior and we show that for Brownian
motion in such fluid-like soft matter the impulse response function, $h(t)$
maintains a finite constant value in the long term.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:37:47 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 19:30:10 GMT""},{""version"":""v3"",""created"":""Fri, 30 Apr 2021 21:56:35 GMT""}]","2021-05-12"
"2102.01787","Dmitry Ryabogin","Dmitry Ryabogin","A negative answer to Ulam's Problem 19 from the Scottish Book","7 figures. arXiv admin note: text overlap with arXiv:1201.0393",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a negative answer to Ulam's Problem 19 from the Scottish Book asking
{\it is a solid of uniform density which will float in water in every position
a sphere?} Assuming that the density of water is $1$, we show that there exists
a strictly convex body of revolution $K\subset {\mathbb R^3}$ of uniform
density $\frac{1}{2}$, which is not a Euclidean ball, yet floats in equilibrium
in every orientation. We prove an analogous result in all dimensions $d\ge 3$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:37:54 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 14:30:38 GMT""},{""version"":""v3"",""created"":""Thu, 11 Feb 2021 18:29:28 GMT""},{""version"":""v4"",""created"":""Fri, 19 Feb 2021 15:50:21 GMT""},{""version"":""v5"",""created"":""Tue, 9 Nov 2021 13:28:03 GMT""}]","2021-11-10"
"2102.01788","Ray Chang","Yi-Shiou Duh, Ray Chang","Recurrent Neural Network for MoonBoard Climbing Route Classification and
  Generation","9 pages, 4 figures, 4 appendix figures",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Classifying the difficulties of climbing routes and generating new routes are
both challenging. Existing machine learning models not only fail to accurately
predict a problem's difficulty, but they are also unable to generate reasonable
problems. In this work, we introduced ""BetaMove"", a new move preprocessing
pipeline we developed, in order to mimic a human climber's hand sequence. The
preprocessed move sequences were then used to train both a route generator and
a grade predictor. By preprocessing a MoonBoard problem into a proper move
sequence, the accuracy of our grade predictor reaches near human-level
performance, and our route generator produces new routes of much better quality
compared to previous work. We demonstrated that with BetaMove, we are able to
inject human insights into the machine learning problems, and this can be the
foundations for future transfer learning on climbing style classification
problems.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:38:23 GMT""}]","2021-02-04"
"2102.01789","Iz-Iddine EL-Fassi","Iz-iddine El-Fassi","A new type of functional equations on semigroups with involutions",,,,,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  Let $S$ be a commutative semigroup, $K$ a quadratically closed commutative
field of characteristic different from $2$, $G$ a $2$-cancellative abelian
group and $H$ an abelian group uniquely divisible by $2$. The aim of this paper
is to determine the general solution $f:S^2\to K$ of the d'Alembert type
equation: $$ f(x+y,z+w)+f(x+\sigma(y),z+\tau(w)) =2f(x,z)f(y,w),\quad\quad
(x,y,z,w\in S) $$ the general solution $f:S^2\to G$ of the Jensen type
equation: $$ f(x+y,z+w)+f(x+\sigma(y),z+\tau(w)) =2f(x,z),\quad\quad
(x,y,z,w\in S) $$ the general solution $f:S^2\to H$ of the quadratic type
equation quation: $$ f(x+y,z+w)+f(x+\sigma(y),z+\tau(w))
=2f(x,z)+2f(y,w),\quad\quad (x,y,z,w\in S) $$ where $\sigma,\tau: S\to S$ are
two involutions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:45:44 GMT""}]","2021-02-04"
"2102.01790","John O'Leary","John O'Leary","Couplings of the Random-Walk Metropolis algorithm","28 pages, 8 figures",,,,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  Couplings play a central role in contemporary Markov chain Monte Carlo
methods and in the analysis of their convergence to stationarity. In most
cases, a coupling must induce relatively fast meeting between chains to ensure
good performance. In this paper we fix attention on the random walk Metropolis
algorithm and examine a range of coupling design choices. We introduce proposal
and acceptance step couplings based on geometric, optimal transport, and
maximality considerations. We consider the theoretical properties of these
choices and examine their implication for the meeting time of the chains. We
conclude by extracting a few general principles and hypotheses on the design of
effective couplings.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:46:26 GMT""}]","2021-02-04"
"2102.01791","William Mitchell","William H. Mitchell, Henry G. Bell, Yoichiro Mori, Laurel Ohm and
  Daniel Spirn","A single-layer based numerical method for the slender body boundary
  value problem","24 pages, 11 figures, 4 tables",,"10.1016/j.jcp.2021.110865",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Fluid flows containing dilute or dense suspensions of thin fibers are
widespread in biological and industrial processes. To describe the motion of a
thin immersed fiber, or to describe the forces acting on it, it is convenient
to work with one-dimensional fiber centerlines and force densities rather than
two-dimensional surfaces and surface tractions. Slender body theories offer
ways to model and simulate the motion of immersed fibers using only
one-dimensional data. However, standard formulations can break down when the
fiber surface comes close to intersecting itself or other fibers. In this paper
we introduce a numerical method for a recently derived three-dimensional
slender body boundary value problem that can be stated entirely in terms of a
one-dimensional distribution of forces on the centerline. The method is based
on a new completed single-layer potential formulation of fluid velocity which
removes the nullspace associated with the unmodified single layer potential. We
discretize the model and present numerical results demonstrating the good
conditioning and improved performance of the method in the presence of
near-intersections. To avoid the modeling and numerical choices involved with
free ends, we consider closed fibers.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:49:50 GMT""},{""version"":""v2"",""created"":""Mon, 22 Nov 2021 15:03:34 GMT""}]","2021-12-03"
"2102.01792","Atefeh Shahroudnejad","Atefeh Shahroudnejad","A Survey on Understanding, Visualizations, and Explanation of Deep
  Neural Networks",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recent advancements in machine learning and signal processing domains have
resulted in an extensive surge of interest in Deep Neural Networks (DNNs) due
to their unprecedented performance and high accuracy for different and
challenging problems of significant engineering importance. However, when such
deep learning architectures are utilized for making critical decisions such as
the ones that involve human lives (e.g., in control systems and medical
applications), it is of paramount importance to understand, trust, and in one
word ""explain"" the argument behind deep models' decisions. In many
applications, artificial neural networks (including DNNs) are considered as
black-box systems, which do not provide sufficient clue on their internal
processing actions. Although some recent efforts have been initiated to explain
the behaviors and decisions of deep networks, explainable artificial
intelligence (XAI) domain, which aims at reasoning about the behavior and
decisions of DNNs, is still in its infancy. The aim of this paper is to provide
a comprehensive overview on Understanding, Visualization, and Explanation of
the internal and overall behavior of DNNs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 22:57:22 GMT""}]","2021-02-04"
"2102.01793","Luis  Balicas Dr","Aikaterini Flessa Savvidou, Judith K. Clark, Hua Wang, Kaya Wei, Eun
  Sang Choi, Shirin Mozaffari, Xiaofeng Qian, Michael Shatruk, Luis Balicas","Complex Dirac-like Electronic Structure in Atomic Site Ordered
  Rh3In3.4Ge3.6","20 pages, including supplementary information file. 10 figures plus 3
  supplementary figures","Chem. Mater. (2021)","10.1021/acs.chemmater.0c03943",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We report the synthesis via an indium flux method of a novel
single-crystalline compound Rh3In3.4Ge3.6 that belongs to the cubic Ir3Ge7
structure type. In Rh3In3.4Ge3.6, the In and Ge atoms choose to preferentially
occupy, respectively, the 12d and 16f sites of the Im-3m space group, thus
creating a colored version of the Ir3Ge7 structure. Like the other compounds of
the Ir3Ge7 family, Rh3In3.4Ge3.6 shows potential as a thermoelectric displaying
a relatively large power factor, PF ~ 2 mW/cmK2, at a temperature T ~ 225 K
albeit showing a modest figure of merit, ZT = 8 x 10-4, due to the lack of a
finite band gap. These figures might improve through a use of chemical
substitution strategies to achieve band gap opening. Remarkably, electronic
band structure calculations reveal that this compound displays a complex
Dirac-like electronic structure relatively close to the Fermi level. The
electronic structure is composed of several Dirac type-I and type-II nodes, and
even Dirac type-III nodes that result from the touching between a flat band and
a linearly dispersing band. This rich Dirac-like electronic dispersion offers
the possibility to observe Dirac type-III nodes and study their role in the
physical properties of Rh3In3.4Ge3.6 and related Ir3Ge7-type materials.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:04:38 GMT""}]","2021-02-04"
"2102.01794","Angel Zald\'ivar","Francisco \'Avila, Julio Urenda, Angel Zald\'ivar","On the Cantor and Hilbert Cube Frames and the Alexandroff-Hausdorff
  Theorem","1 figure",,,,"math.CT math.GN","http://creativecommons.org/licenses/by/4.0/","  The aim of this work is to give a pointfree description of the Cantor set. It
can be shown that the Cantor set is homeomorphic to the $p$-adic integers
$\mathbb{Z}_{p}:=\{x\in\mathbb{Q}_{p}: |x|_p\leq 1\}$ for every prime number
$p$. To give a pointfree description of the Cantor set, we specify the frame of
$\mathbb{Z}_{p}$ by generators and relations. We use the fact that the open
balls centered at integers generate the open subsets of $\mathbb{Z}_{p}$ and
thus we think of them as the basic generators; on this poset we impose some
relations and then the resulting quotient is the frame of the Cantor set
$\mathcal{L}(\mathbb{Z}_{p})$. We prove that $\mathcal{L}(\mathbb{Z}_{p})$ is a
spatial frame whose space of points is homeomorphic to $\mathbb{Z}_{p}$. In
particular, we show with pointfree arguments that $\mathcal{L}(\mathbb{Z}_{p})$
is $0$-dimensional, (completely) regular, compact, and metrizable (it admits a
countably generated uniformity). Finally, we give a point-free counterpart of
the Hausdorff-Alexandroff Theorem which states that \emph{every compact metric
space is a continuous image of the Cantor space} (see, e.g. \cite{Alexandroff}
and \cite{Hausdorff}). We prove the point-free analog: if $L$ is a compact
metrizable frame, then there is an injective frame homomorphism from $L$ into
$\mathcal{L}(\mathbb{Z}_{2})$.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:13:45 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 18:05:45 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 02:41:45 GMT""}]","2021-02-08"
"2102.01795","Jihn E. Kim","Jihn E. Kim","Anomalies and parities for quintessential and ultra-light axions",,"Phys. Lett. B 817 (2021) 136248","10.1016/j.physletb.2021.136248",,"hep-ph astro-ph.CO hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We discuss the energy scales of the explicit breaking terms of the global
symmetries \USW~ needed for the quinessential axion (QA) and the ultra-light
axion (ULA). The appropriate scale of QA is about $10^{8}$ GeV.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:16:53 GMT""}]","2021-04-23"
"2102.01796","Carsten A. Ullrich","Jiuyu Sun, Cheng-Wei Lee, Alina Kononov, Andr\'e Schleife, and Carsten
  A. Ullrich","Real-time exciton dynamics with time-dependent density-functional theory","7 pages, 4 figures","Phys. Rev. Lett. 127, 077401 (2021)","10.1103/PhysRevLett.127.077401",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Linear-response time-dependent density-functional theory (TDDFT) can describe
excitonic features in the optical spectra of insulators and semiconductors,
using exchange-correlation (xc) kernels behaving as $-1/k^{2}$ to leading
order. We show how excitons can be modeled in real-time TDDFT, using an xc
vector potential constructed from approximate, long-range corrected xc kernels.
We demonstrate for various materials that this real-time approach is consistent
with frequency-dependent linear response, gives access to femtosecond exciton
dynamics following short-pulse excitations, and can be extended with some
caution into the nonlinear regime.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:21:21 GMT""}]","2021-08-18"
"2102.01797","Madi Zholbaryssov","Madi Zholbaryssov and Alejandro D. Dominguez-Garcia","Data-Driven Secondary Control of Distributed Energy Resources",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a data-driven secondary controller for regulating
to some desired values several variables of interest in a power system, namely,
electrical frequency, voltage magnitudes at critical buses, and active power
flows through critical lines. The power generation system is based on
distributed energy resources (DERs) interfaced with either grid-forming (GFM)
or grid-following (GFL) inverters. The secondary controller is based on online
feedback optimization leveraging the learned sensitivities of the changes in
the system frequency, voltage magnitudes at critical buses, and active power
flows through critical lines to the changes in inverter active and reactive
power setpoints. To learn the sensitivities accurately from data, the feedback
optimization has a built-in mechanism for keeping the secondary control inputs
persistently exciting without degrading its performance. The feedback
optimization also utilizes the learned power-voltage characteristics of
photovoltaic (PV) arrays to compute DC-link voltage setpoints so as to allow
the PV arrays to track the power setpoints. To learn the power-voltage
characteristics, we separately execute a data-driven approach that fits a
concave polynomial to the collected power-voltage measurements by solving a
sum-of-squares (SoS) optimization. We showcase the secondary controller using
the modified IEEE-14 bus test system, in which conventional energy sources are
replaced with inverter-interfaced DERs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:28:29 GMT""}]","2021-02-04"
"2102.01798","Thomas Breithaupt","Thomas Breithaupt, Lars N. Hansen, Srikanth Toppaladoddi, Richard F.
  Katz","The role of grain-environment heterogeneity in normal grain growth: a
  stochastic approach","24 pages, 8 figures, to be published in Acta Materialia",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The size distribution of grains is a fundamental characteristic of
polycrystalline solids. In the absence of deformation, the grain-size
distribution is controlled by normal grain growth. The canonical model of
normal grain growth, developed by Hillert, predicts a grain-size distribution
that bears a systematic discrepancy with observed distributions. To address
this, we propose a change to the Hillert model that accounts for the influence
of heterogeneity in the local environment of grains. In our model, each grain
evolves in response to its own local environment of neighbouring grains, rather
than to the global population of grains. The local environment of each grain
evolves according to an Ornstein-Uhlenbeck stochastic process. Our results are
consistent with accepted grain-growth kinetics. Crucially, our model indicates
that the size of relatively large grains evolves as a random walk due to the
inherent variability in their local environments. This leads to a broader
grain-size distribution than the Hillert model and indicates that heterogeneity
has a critical influence on the evolution of microstructure.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:30:57 GMT""}]","2021-02-04"
"2102.01799","Louis Esser","Louis Esser","Non-torsion Brauer groups in positive characteristic","5 pages. Comments welcome! v3: final version, to appear in
  Proceedings of the American Mathematical Society",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unlike the classical Brauer group of a field, the Brauer-Grothendieck group
of a singular scheme need not be torsion. We show that there exist integral
normal projective surfaces over a large field of positive characteristic with
non-torsion Brauer group. In contrast, we demonstrate that such examples cannot
exist over the algebraic closure of a finite field.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:31:54 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 22:51:14 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 03:32:02 GMT""}]","2022-05-23"
"2102.01800","Ariah Klages-Mundt","Ariah Klages-Mundt, Andreea Minca","Optimal Intervention in Economic Networks using Influence Maximization
  Methods",,,"10.1016/j.ejor.2021.10.042",,"cs.GT q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider optimal intervention in the Elliott-Golub-Jackson network model
\cite{jackson14} and we show that it can be transformed into an influence
maximization-like form, interpreted as the reverse of a default cascade. Our
analysis of the optimal intervention problem extends well-established targeting
results to the economic network setting, which requires additional theoretical
steps. We prove several results about optimal intervention: it is NP-hard and
cannot be approximated to a constant factor in polynomial time. In turn, we
show that randomizing failure thresholds leads to a version of the problem
which is monotone submodular, for which existing powerful approximations in
polynomial time can be applied. In addition to optimal intervention, we also
show practical consequences of our analysis to other economic network problems:
(1) it is computationally hard to calculate expected values in the economic
network, and (2) influence maximization algorithms can enable efficient
importance sampling and stress testing of large failure scenarios. We
illustrate our results on a network of firms connected through input-output
linkages inferred from the World Input Output Database.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:36:25 GMT""},{""version"":""v2"",""created"":""Sun, 19 Mar 2023 11:28:30 GMT""}]","2023-03-21"
"2102.01801","Joshua Pritchard","Joshua Pritchard, Tara Murphy, Andrew Zic, Christene Lynch, George
  Heald, David L. Kaplan, Craig Anderson, Julie Banfield, Catherine Hale, Aidan
  Hotan, Emil Lenc, James K. Leung, David McConnell, Vanessa A. Moss, Wasim
  Raja, Adam J. Stewart, and Matthew Whiting","A circular polarisation survey for radio stars with the Australian SKA
  Pathfinder","18 pages, 10 figures, to be published in MNRAS",,"10.1093/mnras/stab299",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present results from a circular polarisation survey for radio stars in the
Rapid ASKAP Continuum Survey (RACS). RACS is a survey of the entire sky south
of $\delta=+41^\circ$ being conducted with the Australian Square Kilometre
Array Pathfinder telescope (ASKAP) over a 288 MHz wide band centred on 887.5
MHz. The data we analyse includes Stokes I and V polarisation products to an
RMS sensitivity of 250 $\mu$Jy PSF$^{-1}$. We searched RACS for sources with
fractional circular polarisation above 6 per cent, and after excluding imaging
artefacts, polarisation leakage, and known pulsars we identified radio emission
coincident with 33 known stars. These range from M-dwarfs through to magnetic,
chemically peculiar A- and B-type stars. Some of these are well known radio
stars such as YZ CMi and CU Vir, but 23 have no previous radio detections. We
report the flux density and derived brightness temperature of these detections
and discuss the nature of the radio emission. We also discuss the implications
of our results for the population statistics of radio stars in the context of
future ASKAP and Square Kilometre Array surveys.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:47:10 GMT""}]","2021-02-04"
"2102.01802","Stephane Bonhomme","Stephane Bonhomme","Teams: Heterogeneity, Sorting, and Complementarity",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  How much do individuals contribute to team output? I propose an econometric
framework to quantify individual contributions when only the output of their
teams is observed. The identification strategy relies on following individuals
who work in different teams over time. I consider two production technologies.
For a production function that is additive in worker inputs, I propose a
regression estimator and show how to obtain unbiased estimates of variance
components that measure the contributions of heterogeneity and sorting. To
estimate nonlinear models with complementarity, I propose a mixture approach
under the assumption that individual types are discrete, and rely on a
mean-field variational approximation for estimation. To illustrate the methods,
I estimate the impact of economists on their research output, and the
contributions of inventors to the quality of their patents.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:52:12 GMT""}]","2021-02-04"
"2102.01803","Ganchao Wei","Ganchao Wei, Ian H. Stevenson","Tracking fast and slow changes in synaptic weights from simultaneously
  observed pre- and postsynaptic spiking",,"Neural Computation (2021) 33 (10) 2682-2709","10.1162/neco_a_01426",,"q-bio.NC stat.AP stat.CO","http://creativecommons.org/publicdomain/zero/1.0/","  Synapses change on multiple timescales, ranging from milliseconds to minutes,
due to a combination of both short- and long-term plasticity. Here we develop
an extension of the common Generalized Linear Model to infer both short- and
long-term changes in the coupling between a pre- and post-synaptic neuron based
on observed spiking activity. We model short-term synaptic plasticity using
additive effects that depend on the presynaptic spike timing, and we model
long-term changes in both synaptic weight and baseline firing rate using point
process adaptive smoothing. Using simulations, we first show that this model
can accurately recover time-varying synaptic weights 1) for both depressing and
facilitating synapses, 2) with a variety of long-term changes (including
realistic changes, such as due to STDP), 3) with a range of pre- and
post-synaptic firing rates, and 4) for both excitatory and inhibitory synapses.
We then apply our model to two experimentally recorded putative synaptic
connections. We find that simultaneously tracking fast changes in synaptic
weights, slow changes in synaptic weights, and unexplained variations in
baseline firing is essential. Omitting any one of these factors can lead to
spurious inferences for the others. Altogether, this model provides a flexible
framework for tracking short- and long-term variation in spike transmission.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:54:00 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 02:12:41 GMT""}]","2022-08-15"
"2102.01804","EPTCS","Patrick Bahr (IT University of Copenhagen)","Proceedings 11th International Workshop on Computing with Terms and
  Graphs","This volume contains a selection of the papers presented at TERMGRAPH
  2020, the 11th International Workshop on Computing with Terms and Graphs","EPTCS 334, 2021","10.4204/EPTCS.334",,"cs.SC","http://creativecommons.org/licenses/by/4.0/","  Graphs, and graph transformation systems, are used in many areas within
Computer Science: to represent data structures and algorithms, to define
computation models, as a general modelling tool to study complex systems, etc.
Research in term and graph rewriting ranges from theoretical questions to
practical implementation issues. Relevant research areas include: the modelling
of first- and higher-order term rewriting by graph rewriting, graphical
frameworks such as interaction nets and sharing graphs (optimal reduction),
rewrite calculi for the analysis of functional programs, graph reduction
implementations of programming languages, graphical calculi modelling
concurrent and mobile computations, object-oriented systems, graphs as a model
of biological or chemical systems, and automated reasoning and symbolic
computation systems working on shared structures. The aim of the TERMGRAPH
workshop is to bring together researchers working in these different domains
and to foster their interaction, to provide a forum for presenting new ideas
and work in progress, and to enable newcomers to learn about current activities
in this area.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:58:54 GMT""}]","2021-02-04"
"2102.01805","Yijia Zhou","Vineetha Naniyil, Yijia Zhou, Guy Simmonds, Nathan Cooper, Weibin Li,
  Lucia Hackerm\""uller","Observation of collectivity enhanced magnetoassociation of $^6$Li in the
  quantum degenerate regime","18 pages, 6 figures","New J. Phys. 24 (2022) 113005","10.1088/1367-2630/ac9b81",,"physics.atom-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The association process of Feshbach molecules is well described by a
Landau-Zener (LZ) transition above the Fermi temperature, such that two-body
physics dominates the dynamics. However, using $^6$Li atoms and the associated
Feshbach resonance at $B_r=834.1$ G, we observe an enhancement of the
atom-molecule coupling as the fermionic atoms reach degeneracy, demonstrating
the importance of many-body coherence not captured by the conventional LZ
model. In the experiment, we apply a linear association ramp ranging from
adiabatic to non-equilibrium molecule association for various temperatures. We
develop a theoretical model that explains the temperature dependence of the
atom-molecule coupling. Furthermore, we characterize this dependence
experimentally and extract the atom-molecule coupling coefficient as a function
of temperature, finding qualitative agreement between our model and
experimental results. In addition, we simulate the dynamics of molecular
association during a nonlinear field ramp. We find that, in the non-equilibrium
regime, molecular association efficiency can be enhanced by sweeping the
magnetic field cubically with time. Accurate measurement of the atom-molecule
coupling coefficient is important for both theoretical and experimental studies
of molecular association and many-body collective dynamics.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:00:49 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 22:03:53 GMT""},{""version"":""v3"",""created"":""Mon, 21 Nov 2022 14:11:37 GMT""}]","2022-11-22"
"2102.01806","Cheongho Han","Cheongho Han, Chung-Uk Lee, Yoon-Hyun Ryu, Doeon Kim, Michael D.
  Albrow, Sun-Ju Chung, Andrew Gould, Kyu-Ha Hwang, Youn Kil Jung, Hyoun-Woo
  Kim, In-Gu Shin, Yossi Shvartzvald, Jennifer C. Yee, Weicheng Zang, Sang-Mok
  Cha, Dong-Jin Kim, Seung-Lee Kim, Dong-Joo Lee, Yongseok Lee, Byeong-Gon
  Park, Richard W. Pogge","KMT-2019-BLG-0797: binary-lensing event occurring on a binary stellar
  system","9 pages, 10 figures, 7 tables",,"10.1051/0004-6361/202040149",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We analyze the microlensing event KMT-2019-BLG-0797. The light curve of the
event exhibits two anomalous features from a single-lens single-source model,
and we aim to reveal the nature of the anomaly. It is found that a model with
two lenses plus a single source (2L1S model) can explain one feature of the
anomaly, but the other feature cannot be explained. We test various models and
find that both anomalous features can be explained by introducing an extra
source to a 2L1S model (2L2S model), making the event the third confirmed case
of a 2L2S event, following on MOA-2010-BLG-117 and OGLE-2016-BLG-1003. It is
estimated that the extra source comprises $\sim 4\%$ of the $I$-band flux from
the primary source. Interpreting the event is subject to a close--wide
degeneracy. According to the close solution, the lens is a binary consisting of
two brown dwarfs with masses $(M_1, M_2)\sim (0.034, 0.021)~M_\odot$, and it is
located at a distance of $\dl\sim 8.2$~kpc. According to the wide solution, on
the other hand, the lens is composed of an object at the star/brown-dwarf
boundary and an M dwarf with masses $(M_1, M_2)\sim (0.06, 0.33)~M_\odot$
located at $\dl\sim 7.7$~kpc. The source is composed of a
late-G-dwarf/early-K-dwarf primary and an early-to-mid M-dwarf companion.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:04:49 GMT""}]","2021-05-26"
"2102.01807","Cole Hurwitz","Cole Hurwitz, Nina Kudryashova, Arno Onken, Matthias H. Hennig","Building population models for large-scale neural recordings:
  opportunities and pitfalls",,,,,"q-bio.NC cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Modern recording technologies now enable simultaneous recording from large
numbers of neurons. This has driven the development of new statistical models
for analyzing and interpreting neural population activity. Here we provide a
broad overview of recent developments in this area. We compare and contrast
different approaches, highlight strengths and limitations, and discuss
biological and mechanistic insights that these methods provide.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:06:49 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 04:47:18 GMT""},{""version"":""v3"",""created"":""Mon, 28 Jun 2021 17:03:02 GMT""},{""version"":""v4"",""created"":""Sat, 10 Jul 2021 16:05:31 GMT""}]","2021-07-13"
"2102.01808","Matthew Brown Ph.D.","Matthew F. Brown","Schr\""odinger's Cat","19 pages",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The basic idea here is that observation (or one's experience) is fundamental
and the `atomic world' is postulated as the source of such observation. Once
this source has been inferred to exist one may attempt to explicitly derive its
structure in such a way that the observation itself can be reproduced. And so
here is a purely quantum mechanical model of observation coupled to its
supposed source, and the observation itself is realised as a projection of this
quantum system.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:11:36 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 09:06:31 GMT""},{""version"":""v3"",""created"":""Tue, 27 Sep 2022 12:55:34 GMT""}]","2022-09-28"
"2102.01809","Sayed Amir Hoseini","Sayed Amir Hoseini and Ming Ding and Mahbub Hassan and Youjia Chen","Analyzing the Impact of Molecular Re-Radiation on the MIMO Capacity in
  High-Frequency Bands",,"in IEEE Transactions on Vehicular Technology, vol. 69, no. 12, pp.
  15458-15471, Dec. 2020","10.1109/TVT.2020.3041488",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show how the absorption and re-radiation energy from
molecules in the air can influence the Multiple Input Multiple Output (MIMO)
performance in high-frequency bands, e.g., millimeter wave (mmWave) and
terahertz. In more detail, some common atmosphere molecules, such as oxygen and
water, can absorb and re-radiate energy in their natural resonance frequencies,
such as 60 GHz, 180 GHz and 320 GHz. Hence, when hit by electromagnetic waves,
molecules will get excited and absorb energy, which leads to an extra path loss
and is known as molecular attenuation. Meanwhile, the absorbed energy will be
re-radiated towards a random direction with a random phase. These re-radiated
waves also interfere with the signal transmission. Although, the molecular
re-radiation was mostly considered as noise in literature, recent works show
that it is correlated to the main signal and can be viewed as a composition of
multiple delayed or scattered signals. Such a phenomenon can provide
non-line-of-sight (NLoS) paths in an environment that lacks scatterers, which
increases spatial multiplexing and thus greatly enhances the performance of
MIMO systems. Therefore in this paper, we explore the scattering model and
noise models of molecular re-radiation to characterize the channel transfer
function of the NLoS channels created by atmosphere molecules. Our simulation
results show that the re-radiation can increase MIMO capacity up to 3 folds in
mmWave and 6 folds in terahertz for a set of realistic transmit power,
distance, and antenna numbers. We also show that in the high SNR, the
re-radiation makes the open-loop precoding viable, which is an alternative to
beamforming to avoid beam alignment sensitivity in high mobility applications.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:15:03 GMT""}]","2021-02-04"
"2102.01810","Alex May","Alex May, David Wakeham","Quantum tasks require islands on the brane","v4: typo fixes",,"10.1088/1361-6382/ac025d",,"hep-th gr-qc quant-ph","http://creativecommons.org/licenses/by/4.0/","  In recent work, it was argued that quantum computations with inputs and
outputs distributed in spacetime, or quantum tasks, impose constraints on
entanglement in holographic theories. The resulting constraint was named the
connected wedge theorem and can verified by a direct bulk proof using focusing
arguments in general relativity. In this article we extend this work to the
context of AdS/BCFT, where an end-of-the-world brane is present in the bulk. By
considering quantum tasks which exploit information localized to the brane, we
find a new connected wedge theorem. We apply this theorem to brane models of
black holes, where it relates the formation of islands in the Ryu-Takayanagi
formula to causal features of the ambient spacetime. In particular, we find
that if the black hole interior is causally connected to the radiation system
through the ambient spacetime, then an island forms. For constant tension
branes in pure AdS the converse also holds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:23:35 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 19:03:38 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 18:20:56 GMT""},{""version"":""v4"",""created"":""Mon, 5 Apr 2021 02:47:57 GMT""}]","2021-07-07"
"2102.01811","Yuval Shahar","Yuval Shahar","The Ethical Implications of Shared Medical Decision Making without
  Providing Adequate Computational Support to the Care Provider and to the
  Patient","10 pages; no figures",,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  There is a clear need to involve patients in medical decisions. However,
cognitive psychological research has highlighted the cognitive limitations of
humans with respect to 1. Probabilistic assessment of the patient state and of
potential outcomes of various decisions, 2. Elicitation of the patient utility
function, and 3. Integration of the probabilistic knowledge and of patient
preferences to determine the optimal strategy. Therefore, without adequate
computational support, current shared decision models have severe ethical
deficiencies. An informed consent model unfairly transfers the responsibility
to a patient who does not have the necessary knowledge, nor the integration
capability. A paternalistic model endows with exaggerated power a physician who
might not be aware of the patient preferences, is prone to multiple cognitive
biases, and whose computational integration capability is bounded. Recent
progress in Artificial Intelligence suggests adding a third agent: a computer,
in all deliberative medical decisions: Non emergency medical decisions in which
more than one alternative exists, the patient preferences can be elicited, the
therapeutic alternatives might be influenced by these preferences, medical
knowledge exists regarding the likelihood of the decision outcomes, and there
is sufficient decision time. Ethical physicians should exploit computational
decision support technologies, neither making the decisions solely on their
own, nor shirking their duty and shifting the responsibility to patients in the
name of informed consent. The resulting three way (patient, care provider,
computer) human machine model that we suggest emphasizes the patient
preferences, the physician knowledge, and the computational integration of both
aspects, does not diminish the physician role, but rather brings out the best
in human and machine.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:30:21 GMT""}]","2021-02-04"
"2102.01812","Muslum Ozgur Ozmen","Muslum Ozgur Ozmen, Xuansong Li, Andrew Chu, Z. Berkay Celik, Bardh
  Hoxha and Xiangyu Zhang","Discovering IoT Physical Channel Vulnerabilities","Published in ACM CCS 2022",,"10.1145/3548606.3560644",,"cs.CR cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smart homes contain diverse sensors and actuators controlled by IoT apps that
provide custom automation. Prior works showed that an adversary could exploit
physical interaction vulnerabilities among apps and put the users and
environment at risk, e.g., to break into a house, an adversary turns on the
heater to trigger an app that opens windows when the temperature exceeds a
threshold. Currently, the safe behavior of physical interactions relies on
either app code analysis or dynamic analysis of device states with manually
derived policies by developers. However, existing works fail to achieve
sufficient breadth and fidelity to translate the app code into their physical
behavior or provide incomplete security policies, causing poor accuracy and
false alarms. In this paper, we introduce a new approach, IoTSeer, which
efficiently combines app code analysis and dynamic analysis with new security
policies to discover physical interaction vulnerabilities. IoTSeer works by
first translating sensor events and actuator commands of each app into a
physical execution model (PeM) and unifying PeMs to express composite physical
execution of apps (CPeM). CPeM allows us to deploy IoTSeer in different smart
homes by defining its execution parameters with minimal data collection.
IoTSeer supports new security policies with intended/unintended physical
channel labels. It then efficiently checks them on the CPeM via falsification,
which addresses the undecidability of verification due to the continuous and
discrete behavior of IoT devices. We evaluate IoTSeer in an actual house with
14 actuators, six sensors, and 39 apps. IoTSeer discovers 16 unique policy
violations, whereas prior works identify only 2 out of 16 with 18 falsely
flagged violations. IoTSeer only requires 30 mins of data collection for each
actuator to set the CPeM parameters and is adaptive to newly added, removed,
and relocated devices.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:31:59 GMT""},{""version"":""v2"",""created"":""Thu, 8 Sep 2022 03:49:29 GMT""}]","2022-09-09"
"2102.01813","Mingke Xu","Mingke Xu, Fan Zhang, Xiaodong Cui, Wei Zhang","Speech Emotion Recognition with Multiscale Area Attention and Data
  Augmentation","Accepted by ICASSP 2021",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Speech Emotion Recognition (SER), emotional characteristics often appear
in diverse forms of energy patterns in spectrograms. Typical attention neural
network classifiers of SER are usually optimized on a fixed attention
granularity. In this paper, we apply multiscale area attention in a deep
convolutional neural network to attend emotional characteristics with varied
granularities and therefore the classifier can benefit from an ensemble of
attentions with different scales. To deal with data sparsity, we conduct data
augmentation with vocal tract length perturbation (VTLP) to improve the
generalization capability of the classifier. Experiments are carried out on the
Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. We achieved
79.34% weighted accuracy (WA) and 77.54% unweighted accuracy (UA), which, to
the best of our knowledge, is the state of the art on this dataset.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:39:09 GMT""}]","2021-02-04"
"2102.01814","Christopher Monahan","Ra\'ul A. Brice\~no, Christopher J. Monahan","A model-independent framework for determining finite-volume effects of
  spatially nonlocal operators","15 pages, 5 figures","Phys. Rev. D 103, 094521 (2021)","10.1103/PhysRevD.103.094521","JLAB-THY-21-3315","hep-lat","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a model-independent framework to determine finite-volume
corrections of matrix elements of spatially-separated current-current
operators. We define these matrix elements in terms of Compton-like amplitudes,
i.e. amplitudes coupling single-particle states via two current insertions. We
show that the infrared behavior of these matrix elements is dominated by the
single-particle pole, which is approximated by the elastic form factors of the
lowest-lying hadron. Therefore, given lattice data on the relevant elastic form
factors, the finite-volume effects can be estimated non-perturbatively and
without recourse to effective field theories. For illustration purposes, we
investigate the implications of the proposed formalism for a class of scalar
theories in two and four dimensions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:45:22 GMT""}]","2021-06-02"
"2102.01815","Xinqiao Zhang","Xinqiao Zhang, Huili Chen and Farinaz Koushanfar","TAD: Trigger Approximation based Black-box Trojan Detection for AI","6 body pages",,,,"cs.CR cs.AI cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  An emerging amount of intelligent applications have been developed with the
surge of Machine Learning (ML). Deep Neural Networks (DNNs) have demonstrated
unprecedented performance across various fields such as medical diagnosis and
autonomous driving. While DNNs are widely employed in security-sensitive
fields, they are identified to be vulnerable to Neural Trojan (NT) attacks that
are controlled and activated by the stealthy trigger. We call this vulnerable
model adversarial artificial intelligence (AI). In this paper, we target to
design a robust Trojan detection scheme that inspects whether a pre-trained AI
model has been Trojaned before its deployment. Prior works are oblivious of the
intrinsic property of trigger distribution and try to reconstruct the trigger
pattern using simple heuristics, i.e., stimulating the given model to incorrect
outputs. As a result, their detection time and effectiveness are limited. We
leverage the observation that the pixel trigger typically features spatial
dependency and propose TAD, the first trigger approximation based Trojan
detection framework that enables fast and scalable search of the trigger in the
input space. Furthermore, TAD can also detect Trojans embedded in the feature
space where certain filter transformations are used to activate the Trojan. We
perform extensive experiments to investigate the performance of the TAD across
various datasets and ML models. Empirical results show that TAD achieves a
ROC-AUC score of 0:91 on the public TrojAI dataset 1 and the average detection
time per model is 7:1 minutes.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:49:50 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 18:45:48 GMT""},{""version"":""v3"",""created"":""Tue, 20 Apr 2021 21:46:32 GMT""}]","2021-04-22"
"2102.01816","In-Jee Jeong","Young-Pil Choi and In-Jee Jeong","Classical solutions for fractional porous medium flow","13 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We consider the fractional porous medium flow introduced by
Caffarelli-Vazquez and obtain local in time existence, uniqueness, and blow-up
criterion for smooth solutions. The proof is based on establishing a commutator
estimate involving fractional Laplacian operators.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:53:12 GMT""}]","2021-02-04"
"2102.01817","In-Jee Jeong","Young-Pil Choi and In-Jee Jeong","Relaxation to fractional porous medium equation from Euler--Riesz system","19 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We perform asymptotic analysis for the Euler--Riesz system posed in either
$\mathbb{T}^d$ or $\mathbb{R}^d$ in the high-force regime and establish a
quantified relaxation limit result from the Euler--Riesz system to the
fractional porous medium equation. We provide a unified approach for asymptotic
analysis regardless of the presence of pressure, based on the modulated energy
estimates, the Wasserstein distance of order $2$, and the bounded Lipschitz
distance.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:55:58 GMT""}]","2021-02-04"
"2102.01818","Karin Verspoor","Aparna Elangovan, Jiayuan He, Karin Verspoor","Memorization vs. Generalization: Quantifying Data Leakage in NLP
  Performance Evaluation","To appear EACL 2021",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Public datasets are often used to evaluate the efficacy and generalizability
of state-of-the-art methods for many tasks in natural language processing
(NLP). However, the presence of overlap between the train and test datasets can
lead to inflated results, inadvertently evaluating the model's ability to
memorize and interpreting it as the ability to generalize. In addition, such
data sets may not provide an effective indicator of the performance of these
methods in real world scenarios. We identify leakage of training data into test
data on several publicly available datasets used to evaluate NLP tasks,
including named entity recognition and relation extraction, and study them to
assess the impact of that leakage on the model's ability to memorize versus
generalize.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:58:45 GMT""}]","2021-02-04"
"2102.01819","Giuseppe Baio","Giuseppe Baio, Gordon R. M. Robb, Alison M. Yao, Gian-Luca Oppo,
  Thorsten Ackemann","Multiple self-organized phases and spatial solitons in cold atoms
  mediated by optical feedback","6 pages, 6 figures","Phys. Rev. Lett. 126, 203201 (2021)","10.1103/PhysRevLett.126.203201",,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the transverse self-structuring of a cloud of cold atoms with
effective atomic interactions mediated by a coherent driving beam
retro-reflected by means of a single mirror. The resulting self-structuring due
to optomechanical forces is much richer than that of an effective-Kerr medium,
displaying hexagonal, stripe and honeycomb phases depending on the interaction
strength parametrized by the linear susceptibility. Phase domains are described
by real Ginzburg-Landau amplitude equations. In the stripe phase the system
recovers inversion symmetry. Moreover, the subcritical character of the
honeycomb phase allows for light-density feedback solitons functioning as
self-sustained dark atomic traps with motion controlled by phase gradients in
the driving beam.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:58:46 GMT""}]","2021-05-26"
"2102.01820","Federico Buccioni","Bakul Agarwal, Federico Buccioni, Andreas von Manteuffel, Lorenzo
  Tancredi","Two-loop leading colour QCD corrections to $q \bar{q} \to \gamma \gamma
  g$ and $q g \to \gamma \gamma q$","20 pages, 2 figures, 2 tables, ancillary files with analytic results;
  v2: corrected issue related to \epsilon_5, table 2 changed, updated ancillary
  files, updated numerical code",,"10.1007/JHEP04(2021)201","MSUHEP-21-005, OUTP-21-04P","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the leading colour and light fermionic planar two-loop corrections
for the production of two photons and a jet in the quark-antiquark and
quark-gluon channels. In particular, we compute the interference of the
two-loop amplitudes with the corresponding tree level ones, summed over colours
and polarisations. Our calculation uses the latest advancements in the
algorithms for integration-by-parts reduction and multivariate partial fraction
decomposition to produce compact and easy-to-use results. We have implemented
our results in an efficient C++ numerical code. We also provide their analytic
expressions in Mathematica format.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:59:01 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 17:25:37 GMT""}]","2021-05-05"
"2102.01821","Ian Frankenburg","Ian Frankenburg and Sudipto Banerjee","A Compartment Model of Human Mobility and Early Covid-19 Dynamics in NYC",,,"10.51387/21-NEJSDS2",,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  In this paper, we build a mechanistic system to understand the relation
between a reduction in human mobility and Covid-19 spread dynamics within New
York City. To this end, we propose a multivariate compartmental model that
jointly models smartphone mobility data and case counts during the first 90
days of the epidemic. Parameter calibration is achieved through the formulation
of a general Bayesian hierarchical model to provide uncertainty quantification
of resulting estimates. The open-source probabilistic programming language Stan
is used for the requisite computation. Through sensitivity analysis and
out-of-sample forecasting, we find our simple and interpretable model provides
evidence that reductions in human mobility altered case dynamics.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 19:59:27 GMT""}]","2023-01-06"
"2102.01822","Md. Kamrul Hasan","Tarun Kanti Ghosh, Md. Kamrul Hasan, Shidhartho Roy, Md. Ashraful
  Alam, Eklas Hossain, Mohiuddin Ahmad","Multi-class probabilistic atlas-based whole heart segmentation method in
  cardiac CT and MRI","17 pages",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accurate and robust whole heart substructure segmentation is crucial in
developing clinical applications, such as computer-aided diagnosis and
computer-aided surgery. However, segmentation of different heart substructures
is challenging because of inadequate edge or boundary information, the
complexity of the background and texture, and the diversity in different
substructures' sizes and shapes. This article proposes a framework for
multi-class whole heart segmentation employing non-rigid registration-based
probabilistic atlas incorporating the Bayesian framework. We also propose a
non-rigid registration pipeline utilizing a multi-resolution strategy for
obtaining the highest attainable mutual information between the moving and
fixed images. We further incorporate non-rigid registration into the
expectation-maximization algorithm and implement different deep convolutional
neural network-based encoder-decoder networks for ablation studies. All the
extensive experiments are conducted utilizing the publicly available dataset
for the whole heart segmentation containing 20 MRI and 20 CT cardiac images.
The proposed approach exhibits an encouraging achievement, yielding a mean
volume overlapping error of 14.5 % for CT scans exceeding the state-of-the-art
results by a margin of 1.3 % in terms of the same metric. As the proposed
approach provides better-results to delineate the different substructures of
the heart, it can be a medical diagnostic aiding tool for helping experts with
quicker and more accurate results.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:02:09 GMT""}]","2021-02-04"
"2102.01823","Qi Yan","Qi Yan and Xian'an Jin","Partial-dual genus polynomials and signed intersection graphs","21 pages, 10 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Gross, Mansour and Tucker introduced the partial-dual genus
polynomial of a ribbon graph as a generating function that enumerates the
partial duals of the ribbon graph by genus. It is analogous to the
extensively-studied polynomial in topological graph theory that enumerates by
genus all embeddings of a given graph. To investigate the partial-dual genus
polynomial one only needs to focus on bouquets, i.e. ribbon graphs with only
one vertex. In this paper, we shall further show that the partial-dual genus
polynomial of a bouquet essentially depends on the signed intersection graph of
the bouquet rather than on the bouquet itself. That is to say the bouquets with
the same signed intersection graph will have the same partial-dual genus
polynomial. We then prove that the partial-dual genus polynomial of a bouquet
contains non-zero constant term if and only if its signed intersection graph is
positive and bipartite. Finally we consider a conjecture posed by Gross,
Mansour and Tucker. that there is no orientable ribbon graph whose partial-dual
genus polynomial has only one non-constant term, we give a characterization of
non-empty bouquets whose partial-dual genus polynomials have only one term by
consider non-orientable case and orientable case separately.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:11:17 GMT""}]","2021-02-04"
"2102.01824","Md. Kamrul Hasan","Md. Kamrul Hasan, Shidhartho Roy, Chayan Mondal, Md. Ashraful Alam,
  Md.Toufick E Elahi, Aishwariya Dutta, S. M. Taslim Uddin Raju, Md. Tasnim
  Jawad, Mohiuddin Ahmad","Dermo-DOCTOR: A framework for concurrent skin lesion detection and
  recognition using a deep convolutional neural network with end-to-end dual
  encoders","39 Pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Automated skin lesion analysis for simultaneous detection and recognition is
still challenging for inter-class homogeneity and intra-class heterogeneity,
leading to low generic capability of a Single Convolutional Neural Network
(CNN) with limited datasets. This article proposes an end-to-end deep CNN-based
framework for simultaneous detection and recognition of the skin lesions, named
Dermo-DOCTOR, consisting of two encoders. The feature maps from two encoders
are fused channel-wise, called Fused Feature Map (FFM). The FFM is utilized for
decoding in the detection sub-network, concatenating each stage of two
encoders' outputs with corresponding decoder layers to retrieve the lost
spatial information due to pooling in the encoders. For the recognition
sub-network, the outputs of three fully connected layers, utilizing feature
maps of two encoders and FFM, are aggregated to obtain a final lesion class. We
train and evaluate the proposed Dermo-Doctor utilizing two publicly available
benchmark datasets, such as ISIC-2016 and ISIC-2017. The achieved segmentation
results exhibit mean intersection over unions of 85.0 % and 80.0 % respectively
for ISIC-2016 and ISIC-2017 test datasets. The proposed Dermo-DOCTOR also
demonstrates praiseworthy success in lesion recognition, providing the areas
under the receiver operating characteristic curves of 0.98 and 0.91
respectively for those two datasets. The experimental results show that the
proposed Dermo-DOCTOR outperforms the alternative methods mentioned in the
literature, designed for skin lesion detection and recognition. As the
Dermo-DOCTOR provides better-results on two different test datasets, even with
limited training data, it can be an auspicious computer-aided assistive tool
for dermatologists.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:14:52 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 13:46:30 GMT""}]","2021-02-24"
"2102.01825","Xinyue Kan","Xinyue Kan, Thomas C. Thayer, Stefano Carpin, Konstantinos Karydis","Task Planning on Stochastic Aisle Graphs for Precision Agriculture","To appear in Robotics and Automation Letters",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This work addresses task planning under uncertainty for precision agriculture
applications whereby task costs are uncertain and the gain of completing a task
is proportional to resource consumption (such as water consumption in precision
irrigation). The goal is to complete all tasks while prioritizing those that
are more urgent, and subject to diverse budget thresholds and stochastic costs
for tasks. To describe agriculture-related environments that incorporate
stochastic costs to complete tasks, a new Stochastic-Vertex-Cost Aisle Graph
(SAG) is introduced. Then, a task allocation algorithm, termed Next-Best-Action
Planning (NBA-P), is proposed. NBA-P utilizes the underlying structure enabled
by SAG, and tackles the task planning problem by simultaneously determining the
optimal tasks to perform and an optimal time to exit (i.e. return to a base
station), at run-time. The proposed approach is tested with both simulated data
and real-world experimental datasets collected in a commercial vineyard, in
both single- and multi-robot scenarios. In all cases, NBA-P outperforms other
evaluated methods in terms of return per visited vertex, wasted resources
resulting from aborted tasks (i.e. when a budget threshold is exceeded), and
total visited vertices.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:17:54 GMT""}]","2021-02-04"
"2102.01826","Zhewei Sun","Zhewei Sun, Richard Zemel, Yang Xu","A Computational Framework for Slang Generation","Accepted for publication in TACL 2021. Author's final version","Transactions of the Association for Computational Linguistics
  2021; 9 462-478","10.1162/tacl_a_00378",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Slang is a common type of informal language, but its flexible nature and
paucity of data resources present challenges for existing natural language
systems. We take an initial step toward machine generation of slang by
developing a framework that models the speaker's word choice in slang context.
Our framework encodes novel slang meaning by relating the conventional and
slang senses of a word while incorporating syntactic and contextual knowledge
in slang usage. We construct the framework using a combination of probabilistic
inference and neural contrastive learning. We perform rigorous evaluations on
three slang dictionaries and show that our approach not only outperforms
state-of-the-art language models, but also better predicts the historical
emergence of slang word usages from 1960s to 2000s. We interpret the proposed
models and find that the contrastively learned semantic space is sensitive to
the similarities between slang and conventional senses of words. Our work
creates opportunities for the automated generation and interpretation of
informal language.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:19:07 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 04:46:48 GMT""}]","2021-05-25"
"2102.01827","Bolin Liao","Yujie Quan, Shengying Yue, Bolin Liao","Impact of Electron-Phonon Interaction on Thermal Transport: A Review","23 pages, 5 figures. Comments are welcome",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  A thorough understanding of the microscopic picture of heat conduction in
solids is critical to a broad range of applications, from thermal management of
microelectronics to more efficient thermoelectric materials. The transport
properties of phonons, the major microscopic heat carriers in semiconductors
and insulators, particularly their scattering mechanisms, have been a central
theme in microscale heat conduction research. In the past two decades,
significant advancements have been made in computational and experimental
efforts to probe phonon-phonon, phonon-impurity, and phonon-boundary scattering
channels in detail. In contrast, electron-phonon scatterings were long thought
to have negligible effects on thermal transport in most materials under ambient
conditions. This article reviews the recent progress in first-principles
computations and experimental methods that show clear evidence for a strong
impact of electron-phonon interaction on phonon transport in a wide variety of
technologically relevant solid-state materials. Under thermal equilibrium
conditions, electron-phonon interactions can modify the total phonon scattering
rates and renormalize the phonon frequency, as determined by the imaginary part
and the real part of the phonon self-energy, respectively. Under nonequilibrium
transport conditions, electron-phonon interactions can affect the coupled
transport of electrons and phonons in the bulk through the ""phonon or electron
drag"" mechanism as well as the interfacial thermal transport. Based on these
recent results, we evaluate the potential use of electron-phonon interactions
to control thermal transport in solids. We also provide an outlook on future
directions of computational and experimental developments.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:23:30 GMT""}]","2021-02-04"
"2102.01828","Xiao-Shan Gao","Chen Zhao and Xiao-Shan Gao","Analyzing the barren plateau phenomenon in training quantum neural
  networks with the ZX-calculus",,"Quantum 5, 466 (2021)","10.22331/q-2021-06-04-466",,"quant-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a general scheme to analyze the gradient vanishing
phenomenon, also known as the barren plateau phenomenon, in training quantum
neural networks with the ZX-calculus. More precisely, we extend the barren
plateaus theorem from unitary 2-design circuits to any parameterized quantum
circuits under certain reasonable assumptions. The main technical contribution
of this paper is representing certain integrations as ZX-diagrams and computing
them with the ZX-calculus. The method is used to analyze four concrete quantum
neural networks with different structures. It is shown that, for the hardware
efficient ansatz and the MPS-inspired ansatz, there exist barren plateaus,
while for the QCNN ansatz and the tree tensor network ansatz, there exists no
barren plateau.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:24:22 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 06:36:20 GMT""}]","2021-06-09"
"2102.01829","Chanyong Park","Chanyong Park","Holographic RG flow triggered by a classically marginal operator","21 pages, 1 figure",,"10.1103/PhysRevD.105.046004",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the holographic renormalization group (RG) flow triggered by a
classically marginal operator. When a marginal operator deforms a conformal
field theory, it does not yield a nontrivial renormalization group flow at the
classical level. At the quantum level, however, quantum corrections modify a
marginal operator into one of the truly marginal, marginally relevant, and
marginally irrelevant operators and can generate a nontrivial RG flow. We
investigate the holographic description of a RG flow triggered by a marginal
operator with quantum corrections. We look into how the physical quantities of
a deformed theory, a coupling constant and the vacuum expectation value, rely
on the RG scale. We further discuss the holographic description of the trace
anomaly caused by the gluon condensation.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:29:00 GMT""}]","2022-02-16"
"2102.01830","Ricardo Di Pasquale","Ricardo Di Pasquale and Javier Marenco","Machine learning for improving performance in an evolutionary algorithm
  for minimum path with uncertain costs given by massively simulated scenarios","6 pages, 7 figures, IEEE IJCAI DSO 2020",,,,"cs.NE stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work we introduce an implementation for which machine learning
techniques helped improve the overall performance of an evolutionary algorithm
for an optimization problem, namely a variation of robust minimum-cost path in
graphs. In this big data optimization problem, a path achieving a good cost in
most scenarios from an available set of scenarios (generated by a simulation
process) must be obtained. The most expensive task of our evolutionary
algorithm, in terms of computational resources, is the evaluation of candidate
paths: the fitness function must calculate the cost of the candidate path in
every generated scenario. Given the large number of scenarios, this task must
be implemented in a distributed environment. We implemented gradient boosting
decision trees to classify candidate paths in order to identify good
candidates. The cost of the not-so-good candidates is simply forecasted. We
studied the training process, gain performance, accuracy, and other variables.
Our computational experiments show that the computational performance was
significantly improved at the expense of a limited loss of accuracy.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:38:35 GMT""}]","2021-02-04"
"2102.01831","Matt Visser","Aden Jowsey (Victoria University of Wellington) and Matt Visser
  (Victoria University of Wellington)","Counterexamples to the maximum force conjecture","V1: 29 pages; 6 figures; V2: minor typos fixed",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dimensional analysis shows that the speed of light and Newton's constant of
gravitation can be combined to define a quantity $F_* = {c^4\over G_N}$ with
the dimensions of force (equivalently, tension). Then in any physical situation
we must have $F_{physical} = f \; F_*$, where the quantity $f$ is some
dimensionless function of dimensionless parameters. In many physical situations
explicit calculation yields $f= O(1)$, and quite often $f \leq {1\over4}$. This
has lead multiple authors to suggest a (weak or strong) maximum force/maximum
tension conjecture. Working within the framework of standard general
relativity, we will instead focus on counter-examples to this conjecture,
paying particular attention to the extent to which the counter-examples are
physically reasonable. The various counter-examples we shall explore strongly
suggest that one should not put too much credence into any universal maximum
force/maximum tension conjecture. Specifically, fluid spheres on the verge of
gravitational collapse will generically violate the weak (and strong) maximum
force conjectures. If one wishes to retain any general notion of ""maximum
force"" then one will have to very carefully specify precisely which forces are
to be allowed within the domain of discourse.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:41:19 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 06:38:06 GMT""}]","2021-03-03"
"2102.01832","Ricardo Di Pasquale","Ricardo Di Pasquale and Javier Marenco","Optimization meets Big Data: A survey","8 pages, 3 figures, IEEE CEC DSO 2017",,,,"cs.NE cs.DB cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper reviews recent advances in big data optimization, providing the
state-of-art of this emerging field. The main focus in this review are
optimization techniques being applied in big data analysis environments.
Integer linear programming, coordinate descent methods, alternating direction
method of multipliers, simulation optimization and metaheuristics like
evolutionary and genetic algorithms, particle swarm optimization, differential
evolution, fireworks, bat, firefly and cuckoo search algorithms implementations
are reviewed and discussed. The relation between big data optimization and
software engineering topics like information work-flow styles, software
architectures, and software framework is discussed. Comparative analysis in
platforms being used in big data optimization environments are highlighted in
order to bring a state-or-art of possible architectures and topologies.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:44:39 GMT""}]","2021-02-04"
"2102.01833","Nasser Moazzen-Ahmadi","A.R.W. McKellar and Moazzen-Ahmadi","Intermolecular vibrational states far above the van der Waals minimum:
  combination bands of the polar N2O dimer","15 page, 2 figures",,"10.1016/j.jms.2021.111428",,"physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared combination bands of the polar isomer of the N2O dimer are observed
for the first time, using a tunable infrared laser source to probe a pulsed
slit-jet supersonic expansion in the N2O nu1 region (~2240 cm-1). One band
involves the torsional (out-of-plane) intermolecular mode and yields a
torsional frequency of 19.83 cm-1 if associated with the out-of-phase
fundamental (N2O nu1) vibration of the N2O monomers in the dimer. The other
band, which is highly perturbed, yields an intermolecular in-plane geared bend
frequency of 22.74 cm-1. The results are compared with high level ab initio
calculations. The less likely alternate assignment to the in-phase fundamental
would give torsional and geared bend frequencies of 17.25 and 20.16 cm-1,
respectively.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:46:24 GMT""}]","2021-03-17"
"2102.01834","Beth Klein","Beth Klein, Alexandra E. Doyle, B. Zuckerman, P. Dufour, Simon Blouin,
  Carl Melis, Alycia J. Weinberger, and Edward D. Young","Discovery of Beryllium in White Dwarfs Polluted by Planetesimal
  Accretion","23 pages, 11 figures, 9 tables, v2: revised, accepted for publication
  in ApJ",,"10.3847/1538-4357/abe40b",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The element beryllium is detected for the first time in white dwarf stars.
This discovery in the spectra of two helium-atmosphere white dwarfs was made
possible only because of the remarkable overabundance of Be relative to all
other elements, heavier than He, observed in these stars. The measured Be
abundances, relative to chondritic, are by far the largest ever seen in any
astronomical object. We anticipate that the Be in these accreted planetary
bodies was produced by spallation of one or more of O, C, and N in a region of
high fluence of particles of MeV or greater energy.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:53:30 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 22:12:06 GMT""}]","2021-06-23"
"2102.01835","Alexandra Doyle","Alexandra E. Doyle and Steven J. Desch and Edward D. Young","Icy Exomoons Evidenced by Spallogenic Nuclides in Polluted White Dwarfs","13 pages, 4 figures, 1 table","ApJL 907 L35 (2021)","10.3847/2041-8213/abd9ba",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present evidence that excesses in Be in polluted white dwarfs (WDs) are
the result of accretion of icy exomoons that formed in the radiation belts of
giant exoplanets. Here we use excess Be in the white dwarf GALEX J2339-0424 as
an example. We constrain the parent body abundances of rock-forming elements in
GALEX J2339-0424 and show that the overabundance of beryllium in this WD cannot
be accounted for by differences in diffusive fluxes through the WD outer
envelope nor by chemical fractionations during typical rock-forming processes.
We argue instead that the Be was produced by energetic proton irradiation of
ice mixed with rock. We demonstrate that the MeV proton fluence required to
form the high Be/O ratio in the accreted parent body is consistent with
irradiation of ice in the rings of a giant planet within its radiation belt,
followed by accretion of the ices to form a moon that is later accreted by the
WD. The icy moons of Saturn serve as useful analogs. Our results provide an
estimate of spallogenic nuclide excesses in icy moons formed by rings around
giant planets in general, including those in the solar system. While excesses
in Be have been detected in two polluted WDs to date, including the WD
described here, we predict that excesses in the other spallogenic elements Li
and B, although more difficult to detect, should also be observed, and that
such detections would also indicate pollution by icy exomoons formed in the
ring systems of giant planets.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:54:17 GMT""}]","2021-02-04"
"2102.01836","Y. Jack Ng","Y. Jack Ng","Holographic Foam Cosmology: From the Late to the Early Universe","10 pages, LaTeX. arXiv admin note: substantial text overlap with
  arXiv:1910.00040",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum fluctuations endow spacetime with a foamy texture. The degree of
foaminess is dictated by blackhole physics to be of the holographic type.
Applied to cosmology, the holographic foam model predicts the existence of dark
energy with critical energy density in the current (late) universe, the quanta
of which obey infinite statistics. Furthermore we use the deep similarities
between turbulence and the spacetime foam phase of strong quantum gravity to
argue that the early universe was in a turbulent regime when it underwent a
brief cosmic inflation with a ""graceful"" transition to a laminar regime. In
this scenario, both the late and the early cosmic accelerations have their
origins in spacetime foam.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:54:26 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 22:08:37 GMT""}]","2021-02-10"
"2102.01837","Facundo Manuel Delfino","Facundo M. Delfino (1 and 2), Claudia G. Scoccola (1 and 2), Sofia A.
  Cora (1 and 2 and 3), Cristian A. Vega-Martinez (4 and 5) and Ignacio D.
  Gargiulo (2 and 3) ((1) Facultad de Ciencias Astronomicas y Geofisicas,
  Universidad Nacional de La Plata, Observatorio Astronomico, (2) Consejo
  Nacional de Investigaciones Cientificas y Tecnicas (CONICET), (3) Instituto
  de Astrofisica de La Plata (CCT La Plata, CONICET, UNLP), Observatorio
  Astronomico, (4) Instituto de Investigacion Multidisciplinar en Ciencia y
  Tecnologia, Universidad de La Serena, (5) Departamento de Astronomia,
  Universidad de La Serena)","Tracking the orbit of unresolved subhalos for semi-analytic models","21 pages, 9 figures. Replaced to match the version accepted by MNRAS",,"10.1093/mnras/stab3494",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model to track the orbital evolution of ""unresolved subhaloes""
(USHs) in cosmological simulations. USHs are subhaloes that are no longer
distinguished by halo finders as self-bound overdensities within their larger
host system due to limited mass resolution. These subhaloes would host ""orphan
galaxies"" in semi-analytic models of galaxy formation and evolution (SAMs).
Predicting the evolution of the phase-space components of USHs is crucial for
the adequate modelling of environmental processes, interactions and mergers
implemented in SAMs that affect the baryonic properties of orphan satellites.
Our model takes into account dynamical friction drag, mass loss by tidal
stripping and merger with the host halo, involving three free parameters. To
calibrate this model, we consider two DM-only simulations of different mass
resolution (MultiDark simulations). The simulation with higher-mass resolution
({\sc smdpl}; $ m_{\rm DM} = 9.6 \times 10^7 ~ h^{-1}\,\mathrm{M_{\odot}}$)
provides information about subhaloes that are not resolved in the lower-mass
resolution one ({\sc mdpl2}; $ m_{\rm DM} = 1.5 \times 10^9 ~
h^{-1}\,\mathrm{M_{\odot}}$); the orbit of those USHs is tracked by our model.
We use as constraining functions the subhalo mass function (SHMF) and the
two-point correlation function (2PCF) obtained from {\sc smdpl}, being the
latter a novel aspect of our approach. While the SHMF fails to put tight
constraints on the efficiency of dynamical friction and the merger condition,
the addition of clustering information helps to specify the parameters of the
model related to the spatial distribution of subhaloes. Our model allows to
achieve good convergence between the results of simulations of different mass
resolution, with a precision better than 10 per cent for both SHMF and 2PCF.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:01:51 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 02:51:58 GMT""}]","2021-12-07"
"2102.01838","Changkun Wei","Changkun Wei, Jiaqing Yang and Bo Zhang","Time domain analysis for electromagnetic scattering by an elastic
  obstacle in a two-layered medium","33 pages, 2 figures",,,,"math.AP cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the scattering of a time-dependent electromagnetic
wave by an elastic body immersed in the lower half-space of a two-layered
background medium which is separated by an unbounded rough surface. By
proposing two exact transparent boundary conditions (TBCs) on the artificial
planes, we reformulate the unbounded scattering problem into an equivalent
initial-boundary value problem in a strip domain with the well-posedness and
stability proved using the Laplace transform, variational method and energy
method. A perfectly matched layer (PML) is then introduced to truncate the
interaction problem with two finite layers containing the elastic body, leading
to a PML problem in a finite strip domain. We further verify the existence,
uniqueness and stability estimate of solution for the PML problem. Finally, we
establish the exponential convergence in terms of the thickness and parameters
of the PML layers via an error estimate on the electric-to-magnetic (EtM)
capacity operators between the original problem and the PML problem.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:02:43 GMT""}]","2021-02-04"
"2102.01839","Mary Wootters","Reyna Hulett, Shubham Chandak, Mary Wootters","On Coding for an Abstracted Nanopore Channel for DNA Storage",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In the emerging field of DNA storage, data is encoded as DNA sequences and
stored. The data is read out again by sequencing the stored DNA. Nanopore
sequencing is a new sequencing technology that has many advantages over other
methods; in particular, it is cheap, portable, and can support longer reads.
While several practical coding schemes have been developed for DNA storage with
nanopore sequencing, the theory is not well understood. Towards that end, we
study a highly abstracted (deterministic) version of the nanopore sequencer,
which highlights key features that make its analysis difficult. We develop
methods and theory to understand the capacity of our abstracted model, and we
propose efficient coding schemes and algorithms.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:05:43 GMT""}]","2021-02-04"
"2102.01840","Yuanlu Bai","Yuanlu Bai, Zhiyuan Huang, Henry Lam","Model Calibration via Distributionally Robust Optimization: On the NASA
  Langley Uncertainty Quantification Challenge","arXiv admin note: substantial text overlap with arXiv:2006.15689",,"10.1016/j.ymssp.2021.108211",,"stat.ME math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a methodology to tackle the NASA Langley Uncertainty Quantification
Challenge, a model calibration problem under both aleatory and epistemic
uncertainties. Our methodology is based on an integration of robust
optimization, more specifically a recent line of research known as
distributionally robust optimization, and importance sampling in Monte Carlo
simulation. The main computation machinery in this integrated methodology
amounts to solving sampled linear programs. We present theoretical statistical
guarantees of our approach via connections to nonparametric hypothesis testing,
and numerical performances including parameter calibration and downstream
decision and risk evaluation tasks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:08:17 GMT""}]","2021-08-18"
"2102.01841","Leo Tzou","Leo Tzou","Determining Riemannian Manifolds From Nonlinear Wave Observations at a
  Single Point","Updated introduction and references to reflect current state of this
  problem",,,,"math.AP math.DG","http://creativecommons.org/licenses/by/4.0/","  We show that on an a-priori unknown Riemannian manifold $(M,g)$, measuring
the source-to-solution map for the semilinear wave equation at a single point
determines the topological, differential, and geometric structure.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:11:25 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 04:46:03 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 02:26:10 GMT""}]","2021-06-23"
"2102.01842","Hai-Bing Fu","Long Zeng, Hai-Bing Fu, Dan-Dan Hu, Ling-Li Chen, Wei Cheng, Xing-Gang
  Wu","Revisiting the production of $J/\psi+\eta_c$ via the $e^+e^-$
  annihilation within the QCD light-cone sum rules","8 pages, 3 figures, version to be published in Physical Review D","Phys. Rev. D 103, 056012 (2021)","10.1103/PhysRevD.103.056012",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We make a detailed study on the typical production channel of double
charmoniums, $e^+e^-\to J/\psi+\eta_c$, at the center-of-mass collision energy
$\sqrt{s}=10.58$ GeV. The key component of the process is the form factor
$F_{\rm VP}(q^2)$, which has been calculated within the QCD light-cone sum
rules (LCSR). To improve the accuracy of the derived LCSR, we keep the $J/\psi$
light-cone distribution amplitude up to twist-4 accuracy. Total cross sections
for $e^+e^-\to J/\psi+\eta_c$ at three typical factorization scales are
$\sigma|_{\mu_s} = 22.53^{+3.46}_{-3.49}~{\rm fb}$, $\sigma|_{\mu_k} =
21.98^{+3.35}_{-3.38}~{\rm fb}$ and $\sigma|_{\mu_0} =
21.74^{+3.29}_{-3.33}~{\rm fb}$, respectively. The factorization scale
dependence is small, and those predictions are consistent with the BABAR and
Belle measurements within errors.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:12:35 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 23:51:26 GMT""}]","2021-03-24"
"2102.01843","Changkun Wei","Changkun Wei, Jiaqing Yang and Bo Zhang","Convergence of the uniaxial PML method for time-domain electromagnetic
  scattering problems","23 pages, 1 figure. arXiv admin note: text overlap with
  arXiv:1907.08901",,,,"math.AP cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose and study the uniaxial perfectly matched layer
(PML) method for three-dimensional time-domain electromagnetic scattering
problems, which has a great advantage over the spherical one in dealing with
problems involving anisotropic scatterers. The truncated uniaxial PML problem
is proved to be well-posed and stable, based on the Laplace transform technique
and the energy method. Moreover, the $L^2$-norm and $L^{\infty}$-norm error
estimates in time are given between the solutions of the original scattering
problem and the truncated PML problem, leading to the exponential convergence
of the time-domain uniaxial PML method in terms of the thickness and absorbing
parameters of the PML layer. The proof depends on the error analysis between
the EtM operators for the original scattering problem and the truncated PML
problem, which is different from our previous work (SIAM J. Numer. Anal. 58(3)
(2020), 1918-1940).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:13:39 GMT""}]","2021-02-04"
"2102.01844","Yanrong Yang","Lingyu He, Fei Huang, Jianjie Shi, Yanrong Yang","Mortality Forecasting using Factor Models: Time-varying or
  Time-invariant Factor Loadings?",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Many existing mortality models follow the framework of classical factor
models, such as the Lee-Carter model and its variants. Latent common factors in
factor models are defined as time-related mortality indices (such as $\kappa_t$
in the Lee-Carter model). Factor loadings, which capture the linear
relationship between age variables and latent common factors (such as $\beta_x$
in the Lee-Carter model), are assumed to be time-invariant in the classical
framework. This assumption is usually too restrictive in reality as mortality
datasets typically span a long period of time. Driving forces such as medical
improvement of certain diseases, environmental changes and technological
progress may significantly influence the relationship of different variables.
In this paper, we first develop a factor model with time-varying factor
loadings (time-varying factor model) as an extension of the classical factor
model for mortality modelling. Two forecasting methods to extrapolate the
factor loadings, the local regression method and the naive method, are proposed
for the time-varying factor model. From the empirical data analysis, we find
that the new model can capture the empirical feature of time-varying factor
loadings and improve mortality forecasting over different horizons and
countries. Further, we propose a novel approach based on change point analysis
to estimate the optimal `boundary' between short-term and long-term
forecasting, which is favoured by the local linear regression and naive method,
respectively. Additionally, simulation studies are provided to show the
performance of the time-varying factor model under various scenarios.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:28:16 GMT""}]","2021-02-04"
"2102.01845","Linhao Zhang","Linhao Zhang, Min Chen and Jingyu Tang","Study on multi-fold bunch splitting in a high-intensity medium-energy
  proton synchrotron","19 pages, 11 figures",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bunch splitting is an RF manipulation method of changing the bunch structure,
bunch numbers and bunch intensity in the high-intensity synchrotrons that serve
as the injector for a particle collider. An efficient way to realize bunch
splitting is to use the combination of different harmonic RF systems, such as
the two-fold bunch splitting of a bunch with a combination of fundamental
harmonic and doubled harmonic RF systems. The two-fold bunch splitting and
three-fold bunch splitting methods have been experimentally verified and
successfully applied to the LHC/PS. In this paper, a generalized multi-fold
bunch splitting method is given. The five-fold bunch splitting method using
specially designed multi-harmonic RF systems was studied and tentatively
applied to the medium-stage synchrotron (MSS), the third accelerator of the
injector chain of the Super Proton-Proton Collider (SPPC), to mitigate the
pileup effects and collective instabilities of a single bunch in the SPPC. The
results show that the five-fold bunch splitting is feasible and both the bunch
population distribution and longitudinal emittance growth after the splitting
are acceptable, e.g., a few percent in the population deviation and less than
10% in the total emittance growth.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:42:33 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 10:46:10 GMT""}]","2021-02-05"
"2102.01846","Benjamin Williams","Benjamin Williams, Will Palmquist, Ryan Elmore","Simulation-Based Decision Making in the NFL using NFLSimulatoR",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce an R software package for simulating plays and
drives using play-by-play data from the National Football League. The
simulations are generated by sampling play-by-play data from previous football
seasons.The sampling procedure adds statistical rigor to any decisions or
inferences arising from examining the simulations. We highlight that the
package is particularly useful as a data-driven tool for evaluating potential
in-game strategies or rule changes within the league. We demonstrate its
utility by evaluating the oft-debated strategy of $\textit{going for it}$ on
fourth down and investigating whether or not teams should pass more than the
current standard.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:44:01 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 19:05:40 GMT""},{""version"":""v3"",""created"":""Tue, 11 Jan 2022 22:56:39 GMT""}]","2022-01-13"
"2102.01847","Yasufumi Taniguchi","Yasufumi Taniguchi, Hiroki Nakayama, Kubo Takahiro, Jun Suzuki","An Investigation Between Schema Linking and Text-to-SQL Performance",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-to-SQL is a crucial task toward developing methods for understanding
natural language by computers. Recent neural approaches deliver excellent
performance; however, models that are difficult to interpret inhibit future
developments. Hence, this study aims to provide a better approach toward the
interpretation of neural models. We hypothesize that the internal behavior of
models at hand becomes much easier to analyze if we identify the detailed
performance of schema linking simultaneously as the additional information of
the text-to-SQL performance. We provide the ground-truth annotation of schema
linking information onto the Spider dataset. We demonstrate the usefulness of
the annotated data and how to analyze the current state-of-the-art neural
models.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 02:50:10 GMT""}]","2021-02-04"
"2102.01848","Liudmyla Kryvonos","Liudmyla Kryvonos","Polynomial approximation of piecewise analytic functions on quasi-smooth
  arcs","16 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a function $f$ that is piecewise analytic on a quasi-smooth arc
$\mathcal{L}$ and any $0<\sigma<1$ we construct a sequence of ""near-best""
polynomials that converge at a rate $e^{-n^{\sigma}}$ at each point of
analyticity of $f$ and are close to the best polynomial approximants on the
whole $\mathcal{L}$. Also we give examples of quasi-smooth arcs for which
convergence of ""near-best"" approximants at points of analiticity of $f$ is
geometric, i.e. has a rate $e^{-cn}$ with some $c>0$.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:01:26 GMT""}]","2021-02-04"
"2102.01849","Tsao-Hsien Chen","Tsao-Hsien Chen and Ngo Bao Chau","Invariant theory for the commuting scheme of symplectic Lie algebras",,,,,"math.RT math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove the Chevalley restriction theorem for the commuting scheme of
symplectic Lie algebras. The key step is the construction of the inverse map of
the Chevalley restriction map called the spectral data map. Along the way, we
establish a certain multiplicative property of the Pfaffian which is of
independent interest.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:04:06 GMT""}]","2021-02-04"
"2102.01850","Ru Li","Ru Li, Chuan Wang, Jue Wang, Guanghui Liu, Heng-Yu Zhang, Bing Zeng,
  Shuaicheng Liu","UPHDR-GAN: Generative Adversarial Network for High Dynamic Range Imaging
  with Unpaired Data","Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology (TCSVT)","IEEE Transactions on Circuits and Systems for Video Technology,
  2022","10.1109/TCSVT.2022.3190057",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper proposes a method to effectively fuse multi-exposure inputs and
generate high-quality high dynamic range (HDR) images with unpaired datasets.
Deep learning-based HDR image generation methods rely heavily on paired
datasets. The ground truth images play a leading role in generating reasonable
HDR images. Datasets without ground truth are hard to be applied to train deep
neural networks. Recently, Generative Adversarial Networks (GAN) have
demonstrated their potentials of translating images from source domain X to
target domain Y in the absence of paired examples. In this paper, we propose a
GAN-based network for solving such problems while generating enjoyable HDR
results, named UPHDR-GAN. The proposed method relaxes the constraint of the
paired dataset and learns the mapping from the LDR domain to the HDR domain.
Although the pair data are missing, UPHDR-GAN can properly handle the ghosting
artifacts caused by moving objects or misalignments with the help of the
modified GAN loss, the improved discriminator network and the useful
initialization phase. The proposed method preserves the details of important
regions and improves the total image perceptual quality. Qualitative and
quantitative comparisons against the representative methods demonstrate the
superiority of the proposed UPHDR-GAN.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:09:14 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 07:54:33 GMT""}]","2022-07-18"
"2102.01851","Karen E. Daniels","Omid Dorostkar, Karen E. Daniels, Dominik Strebel, Jan Carmeliet","Betweenness centrality illuminates intermittent frictional dynamics",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dense granular systems subjected to an imposed shear stress undergo
stick-slip dynamics with systematic patterns of dilation-compaction. During
each stick phase, as the frictional strength builds up, the granular system
dilates to accommodate shear strain, developing stronger force networks. During
each slip event, when the stored energy is released, particles experience large
rearrangements and the granular network can significantly change. Here, we use
numerical simulations of 3D, sheared frictional packings to show that the mean
betweenness centrality -- a property of network of interparticle connections --
follows consistent patterns during the stick-slip dynamics, showing sharp
spikes at each slip event. We identify the source of this behavior as arising
from the connectivity and contact arrangements of granular network during
dilation-compaction cycles, and find that a lower potential for connection
between particles leads to an increase of mean betweenness centrality in the
system. Furthermore, we show that at high confinements, few particles lose
contact during slip events, leading to a smaller change in granular
connectivity and betweenness centrality.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:12:43 GMT""}]","2021-02-04"
"2102.01852","Hiroki Kojima","Hiroki Kojima and Takashi Ikegami","Organization of a Latent Space structure in VAE/GAN trained by
  navigation data",,,,,"cs.LG cs.NE q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel artificial cognitive mapping system using generative deep
neural networks, called variational autoencoder/generative adversarial network
(VAE/GAN), which can map input images to latent vectors and generate temporal
sequences internally. The results show that the distance of the predicted image
is reflected in the distance of the corresponding latent vector after training.
This indicates that the latent space is self-organized to reflect the proximity
structure of the dataset and may provide a mechanism through which many aspects
of cognition are spatially represented. The present study allows the network to
internally generate temporal sequences that are analogous to the hippocampal
replay/pre-play ability, where VAE produces only near-accurate replays of past
experiences, but by introducing GANs, the generated sequences are coupled with
instability and novelty.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:13:26 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 02:29:27 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 04:31:20 GMT""}]","2022-04-14"
"2102.01853","Eduardo Villase\~nor Alvarez","Eduardo Villase\~nor, Mingjian He, Ziqing Wang, Robert Malaney and Moe
  Z. Win","Enhanced Uplink Quantum Communication with Satellites via Downlink
  Channels",,"IEEE Transactions on Quantum Engineering (2021)","10.1109/TQE.2021.3091709",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In developing the global Quantum Internet, quantum communication with
low-Earth-orbit satellites will play a pivotal role. Such communication will
need to be two way: effective not only in the satellite-to-ground (downlink)
channel but also in the ground-to-satellite channel (uplink). Given that losses
on this latter channel are significantly larger relative to the former,
techniques that can exploit the superior downlink to enhance quantum
communication in the uplink should be explored. In this work we do just that -
exploring how continuous variable entanglement in the form of two-mode squeezed
vacuum (TMSV) states can be used to significantly enhance the fidelity of
ground-to-satellite quantum-state transfer relative to direct uplink-transfer.
More specifically, through detailed phase-screen simulations of beam evolution
through turbulent atmospheres in both the downlink and uplink channels, we
demonstrate how a TMSV teleportation channel created by the satellite can be
used to dramatically improve the fidelity of uplink coherent-state transfer
relative to direct transfer. We then show how this, in turn, leads to the
uplink-transmission of a higher alphabet of coherent states. Additionally, we
show how non-Gaussian operations acting on the received component of the TMSV
state at the ground station can lead to even further enhancement. Since TMSV
states can be readily produced in situ on a satellite platform and form a
reliable teleportation channel for most quantum states, our work suggests
future satellites forming part of the emerging Quantum Internet should be
designed with uplink-communication via TMSV teleportation in mind.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:16:26 GMT""}]","2021-10-13"
"2102.01854","Xiaoyu Cao","Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong","Provably Secure Federated Learning against Malicious Clients","Accepted by AAAI-21. For slides, see
  https://people.duke.edu/~zg70/code/Secure_Federated_Learning.pdf . For the
  talk, see https://www.youtube.com/watch?v=LP4uqW18yA0",,,,"cs.CR cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning enables clients to collaboratively learn a shared global
model without sharing their local training data with a cloud server. However,
malicious clients can corrupt the global model to predict incorrect labels for
testing examples. Existing defenses against malicious clients leverage
Byzantine-robust federated learning methods. However, these methods cannot
provably guarantee that the predicted label for a testing example is not
affected by malicious clients. We bridge this gap via ensemble federated
learning. In particular, given any base federated learning algorithm, we use
the algorithm to learn multiple global models, each of which is learnt using a
randomly selected subset of clients. When predicting the label of a testing
example, we take majority vote among the global models. We show that our
ensemble federated learning with any base federated learning algorithm is
provably secure against malicious clients. Specifically, the label predicted by
our ensemble global model for a testing example is provably not affected by a
bounded number of malicious clients. Moreover, we show that our derived bound
is tight. We evaluate our method on MNIST and Human Activity Recognition
datasets. For instance, our method can achieve a certified accuracy of 88% on
MNIST when 20 out of 1,000 clients are malicious.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:24:17 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 03:43:50 GMT""},{""version"":""v3"",""created"":""Tue, 16 Feb 2021 16:14:35 GMT""},{""version"":""v4"",""created"":""Wed, 27 Oct 2021 02:14:38 GMT""}]","2021-10-28"
"2102.01855","Jianliang Li","Jiaqing Yang, Jianliang Li, and Bo Zhang","Simultaneous recovery of a locally rough interface and the embedded
  obstacle with its surrounding medium","19 pages,1 figure",,"10.1088/1361-6420/ac572a",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Consider the scattering of time-harmonic point sources by an infinite locally
rough interface with bounded obstacles embedded in the lower half-space. The
model problem is first reduced to an equivalent integral equation formulation
defined in a bounded domain, where the well-posedness is obtained in $L^p$ by
the classical Fredholm theory. Then a global uniqueness theorem is proved for
the inverse problem of recovering the locally rough interface, the embedded
obstacles and the wave number in the lower-half space by means of near-field
measurements above the interface.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:24:33 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 12:37:50 GMT""}]","2022-04-06"
"2102.01856","Said Al-Abri","Said Al-Abri and Fumin Zhang","A Distributed Active Perception Strategy for Source Seeking and Level
  Curve Tracking",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Algorithms for multi-agent systems to locate a source or to follow a desired
level curve of spatially distributed scalar fields generally require sharing
field measurements among the agents for gradient estimation. Yet, in this
paper, we propose a distributed active perception strategy that enables swarms
of various sizes and graph structures to perform source seeking and level curve
tracking without the need to explicitly estimate the field gradient or
explicitly share measurements. The proposed method utilizes a consensus-like
Principal Component Analysis perception algorithm that does not require
explicit communication in order to compute a local body frame. This body frame
is used to design a distributed control law where each agent modulates its
motion based only on its instantaneous field measurement. Several stability
results are obtained within a singular perturbation framework which justifies
the convergence and robustness of the strategy. Additionally, efficiency is
validated through various computer simulations and robots implementation in
$2$-D scalar fields. The active perception strategy leverages the available
local information and has the potential to be used in various applications such
as modeling information propagation in biological and robotic swarms.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:28:45 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 20:06:05 GMT""}]","2021-04-08"
"2102.01857","Andrew Giuliani","Andrew Giuliani","A two-dimensional stabilized discontinuous Galerkin method on
  curvilinear embedded boundary grids",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We propose a state redistribution method for high order discontinuous
Galerkin methods on curvilinear embedded boundary grids. State redistribution
relaxes the overly restrictive CFL condition that results from arbitrarily
small cut cells and explicit time stepping. Thus, the scheme can take time
steps that are proportional to the size of cells in the background grid. The
discontinuous Galerkin scheme is stabilized by postprocessing the numerical
solution after each stage or step of an explicit time stepping method. This is
done by temporarily merging the small cells into larger, possibly overlapping
neighborhoods using a special weighted inner product. Then, the numerical
solution on the neighborhoods is returned to the base grid in a conservative
fashion. The advantage of this approach is that it uses only basic mesh
information that is already available in many cut cell codes and does not
require complex geometric manipulations. Finally, we present a number of test
problems that demonstrate the encouraging potential of this technique for
applications on curvilinear embedded geometries. Numerical experiments reveal
that our scheme converges with order $p+1$ in $L_1$ and between $p$ and $p+1$
in $L_\infty$ for problems with smooth solutions. We also demonstrate that
state redistribution is capable of capturing shocks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:35:40 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 00:59:19 GMT""}]","2021-12-07"
"2102.01858","Jean-Pierre Barriot","Jean-Pierre Barriot, Jonathan Serafini and Lydie Sichoix","Estimating the 3D Time Variable Water Vapor Contents of the Troposphere
  from a Single GNSS Receiver","Conference paper: 2013 International Conference on Earth Observations
  and Societal Impacts (2013 ICEO&SI), JUNE 23-25, Tainan. Taiwan",,,,"physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We describe here a new algorithm to model the water contents of the
atmosphere from GNSS slant wet delays relative to a single receiver. We first
make the assumption that the water vapor contents are mainly governed by a
scale height (exponential law), and secondly that the departures from this
decaying exponential can be mapped as a set of low degree 3D Zernike functions
(w.r.t. space) and Tchebyshev polynomials (w.r.t. time.) We give an example of
inversion with data acquired over a one day time span at the Geodesy
Observatory of Tahiti.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:38:35 GMT""}]","2021-02-04"
"2102.01859","Zhou Yang","Muhammad Hilmi Asyrofi, Zhou Yang, Imam Nur Bani Yusuf, Hong Jin Kang,
  Ferdian Thung, and David Lo","BiasFinder: Metamorphic Test Generation to Uncover Bias for Sentiment
  Analysis Systems",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Artificial Intelligence (AI) software systems, such as Sentiment Analysis
(SA) systems, typically learn from large amounts of data that may reflect human
biases. Consequently, the machine learning model in such software systems may
exhibit unintended demographic bias based on specific characteristics (e.g.,
gender, occupation, country-of-origin, etc.). Such biases manifest in an SA
system when it predicts a different sentiment for similar texts that differ
only in the characteristic of individuals described. Existing studies on
revealing bias in SA systems rely on the production of sentences from a small
set of short, predefined templates.
  To address this limitation, we present BisaFinder, an approach to discover
biased predictions in SA systems via metamorphic testing. A key feature of
BisaFinder is the automatic curation of suitable templates based on the pieces
of text from a large corpus, using various Natural Language Processing (NLP)
techniques to identify words that describe demographic characteristics. Next,
BisaFinder instantiates new text from these templates by filling in
placeholders with words associated with a class of a characteristic (e.g.,
gender-specific words such as female names, ""she"", ""her""). These texts are used
to tease out bias in an SA system. BisaFinder identifies a bias-uncovering test
case when it detects that the SA system exhibits demographic bias for a pair of
texts, i.e., it predicts a different sentiment for texts that differ only in
words associated with a different class (e.g., male vs. female) of a target
characteristic (e.g., gender). Our empirical evaluation showed that BiasFinder
can effectively create a larger number of fluent and diverse test cases that
uncover various biases in an SA system.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:39:19 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 03:16:41 GMT""}]","2021-10-06"
"2102.01860","An Yan","An Yan, Xin Eric Wang, Tsu-Jui Fu, William Yang Wang","L2C: Describing Visual Differences Needs Semantic Understanding of
  Individuals","EACL-2021 short",,,,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in language and vision push forward the research of
captioning a single image to describing visual differences between image pairs.
Suppose there are two images, I_1 and I_2, and the task is to generate a
description W_{1,2} comparing them, existing methods directly model { I_1, I_2
} -> W_{1,2} mapping without the semantic understanding of individuals. In this
paper, we introduce a Learning-to-Compare (L2C) model, which learns to
understand the semantic structures of these two images and compare them while
learning to describe each one. We demonstrate that L2C benefits from a
comparison between explicit semantic representations and single-image captions,
and generalizes better on the new testing image pairs. It outperforms the
baseline on both automatic evaluation and human evaluation for the
Birds-to-Words dataset.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:44:42 GMT""}]","2021-02-04"
"2102.01861","Su-Dan Wang","Victor J. W. Guo and Su-Dan Wang","Factors of certain sums involving central q-binomial coefficients",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Ni and Pan proved a $q$-congruence on certain sums involving
central $q$-binomial coefficients, which was conjectured by Guo. In this paper,
we give a generalization of this $q$-congruence and confirm another
$q$-congruence, also conjectured by Guo. Our proof uses Ni and Pan's technique
and a simple $q$-congruence observed by Guo and Schlosser.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:48:30 GMT""}]","2021-02-04"
"2102.01862","Zhuotong Chen","Zhuotong Chen, Qianxiao Li, Zheng Zhang","Towards Robust Neural Networks via Close-loop Control","Published as a conference paper at ICLR 2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite their success in massive engineering applications, deep neural
networks are vulnerable to various perturbations due to their black-box nature.
Recent study has shown that a deep neural network can misclassify the data even
if the input data is perturbed by an imperceptible amount. In this paper, we
address the robustness issue of neural networks by a novel close-loop control
method from the perspective of dynamic systems. Instead of modifying the
parameters in a fixed neural network architecture, a close-loop control process
is added to generate control signals adaptively for the perturbed or corrupted
data. We connect the robustness of neural networks with optimal control using
the geometrical information of underlying data to design the control objective.
The detailed analysis shows how the embedding manifolds of state trajectory
affect error estimation of the proposed method. Our approach can simultaneously
maintain the performance on clean data and improve the robustness against many
types of data perturbations. It can also further improve the performance of
robustly trained neural networks against different perturbations. To the best
of our knowledge, this is the first work that improves the robustness of neural
networks with close-loop control.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:50:35 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 02:45:44 GMT""}]","2021-04-29"
"2102.01863","Raj Prateek Kosaraju","Raj Prateek Kosaraju","Deep CNNs for large scale species classification",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Large Scale image classification is a challenging problem within the field of
computer vision. As the real world contains billions of different objects,
understanding the performance of popular techniques and models is vital in
order to apply them to real world tasks. In this paper, we evaluate techniques
and popular CNN based deep learning architectures to perform large scale
species classification on the dataset from iNaturalist 2019 Challenge. Methods
utilizing dataset pruning and transfer learning are shown to outperform models
trained without either of the two techniques. The ResNext based classifier
outperforms other model architectures over 10 epochs and achieves a top-one
validation error of 0.68 when classifying amongst the 1,010 species.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:53:03 GMT""}]","2021-02-04"
"2102.01864","Geza Kovacs","Geza Kovacs, Darren Edge","QuizCram: A Quiz-Driven Lecture Viewing Interface","Extended version of ""QuizCram: A Quiz-Driven Lecture Viewing
  Interface"", which was published as part of the Student Research Competition
  at CHI 2015",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  QuizCram is an interface for navigating lecture videos that uses quizzes to
help users determine what they should view. We developed it in response to
observing peaks in video seeking behaviors centered around Coursera's in-video
quizzes. QuizCram shows users a question to answer, with an associated video
segment. Users can use these questions to navigate through video segments, and
find video segments they need to review. We also allow users to review using a
timeline of previously answered questions and videos. To encourage users to
review the material, QuizCram keeps track of their question-answering and
video-watching history and schedules sections they likely have not mastered for
review. QuizCram-format materials can be generated from existing lectures with
in-video quizzes. Our user study comparing QuizCram to in-video quizzes found
that users practice answering and reviewing questions more when using QuizCram,
and are better able to remember answers to questions they encountered.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:56:36 GMT""}]","2021-02-04"
"2102.01865","Geza Kovacs","Geza Kovacs","Edvertisements: Adding Microlearning to Social News Feeds and Websites","Extended version of ""FeedLearn: Using facebook feeds for
  microlearning"", which was published as an extended abstract at CHI 2015",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many long-term goals, such as learning a language, require people to
regularly practice every day to achieve mastery. At the same time, people
regularly surf the web and read social news feeds in their spare time. We have
built a browser extension that teaches vocabulary to users in the context of
Facebook feeds and arbitrary websites, by showing users interactive quizzes
they can answer without leaving the website. On Facebook, the quizzes show up
as part of the news feed, while on other sites, the quizzes appear where
advertisements normally would. In our user study, we examined the effectiveness
of inserting microlearning tasks into social news feeds. We compared vocabulary
learning rates when we inserted interactive quizzes into feeds, versus
inserting links that lead them to a website where they could do the quizzes.
Our results suggest that users engage with and learn from our embedded quizzes,
and engagement increases when the quizzes can be done directly within their
feeds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:57:04 GMT""}]","2021-02-04"
"2102.01866","Jae-Hyuk Oh","Jae-Hyuk Oh and Phillial Oh","Aspects of $(d+D)$-dimensional Anisotropic Conformal Gravity","23+1 pages, a new section is added, a few typos are corrected.
  Several references are added",,"10.1007/s40042-021-00351-4",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss various aspects of anisotropic gravity in $(d+D)$-dimensional
spacetime where $D$ dimensions are treated as extra dimensions. It is based on
the foliation preserving diffeomorphism invariance and anisotropic conformal
invariance. The anisotropy is embodied by introducing a factor $z$ which
discriminates the scaling degree of the extra $D$ dimensions against the
$d$-dimensional base spacetime and Weyl scalar field which mediates the
anisotropic scaling symmetry. There is no intrinsic scale but a physical scale
$M_*$ emerges as a consequence of spontaneous conformal symmetry breaking. Some
vacuum solutions are obtained and we discuss an issue of `size separation'
between the base spacetime and the extra dimensions. The size separation means
large hierarchy between the scales appearing in the base spacetime and the
extra dimensions respectively. We also discuss interesting theories obtained
from our model. In the case of (4,1), we propose a resolution of hierarchy
problem and discuss comparison with the results of the brane-world model. In a
$(d,D)=(2,2)$ case, we suggest a UV-complete unitary quantum gravity which
might become Einstein gravity in IR. In a certain (2,1) case, we obtain
CGHS-model.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:11:21 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 07:58:27 GMT""},{""version"":""v3"",""created"":""Thu, 5 Aug 2021 06:00:43 GMT""}]","2022-01-05"
"2102.01867","Sajad Khodadadian","Sajad Khodadadian, AmirEmad Ghassami, Negar Kiyavash","Impact of Data Processing on Fairness in Supervised Learning","18 pages, 4 figures",,,,"cs.LG cs.AI cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We study the impact of pre and post processing for reducing discrimination in
data-driven decision makers. We first analyze the fundamental trade-off between
fairness and accuracy in a pre-processing approach, and propose a design for a
pre-processing module based on a convex optimization program, which can be
added before the original classifier. This leads to a fundamental lower bound
on attainable discrimination, given any acceptable distortion in the outcome.
Furthermore, we reformulate an existing post-processing method in terms of our
accuracy and fairness measures, which allows comparing post-processing and
pre-processing approaches. We show that under some mild conditions,
pre-processing outperforms post-processing. Finally, we show that by
appropriate choice of the discrimination measure, the optimization problem for
both pre and post processing approaches will reduce to a linear program and
hence can be solved efficiently.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:11:39 GMT""}]","2021-02-04"
"2102.01868","Yongfeng Zhang","Shuyuan Xu, Yingqiang Ge, Yunqi Li, Zuohui Fu, Xu Chen, Yongfeng Zhang","Causal Collaborative Filtering","14 pages, 5 figures, 3 tables",,,,"cs.IR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems are important and valuable tools for many personalized
services. Collaborative Filtering (CF) algorithms -- among others -- are
fundamental algorithms driving the underlying mechanism of personalized
recommendation. Many of the traditional CF algorithms are designed based on the
fundamental idea of mining or learning correlative patterns from data for
matching, including memory-based methods such as user/item-based CF as well as
learning-based methods such as matrix factorization and deep learning models.
However, advancing from correlative learning to causal learning is an important
problem, because causal/counterfactual modeling can help us to think outside of
the observational data for user modeling and personalization. In this paper, we
propose Causal Collaborative Filtering (CCF) -- a general framework for
modeling causality in collaborative filtering and recommendation. We first
provide a unified causal view of CF and mathematically show that many of the
traditional CF algorithms are actually special cases of CCF under simplified
causal graphs. We then propose a conditional intervention approach for
$do$-calculus so that we can estimate the causal relations based on
observational data. Finally, we further propose a general counterfactual
constrained learning framework for estimating the user-item preferences.
Experiments are conducted on two types of real-world datasets -- traditional
and randomized trial data -- and results show that our framework can improve
the recommendation performance of many CF algorithms.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:16:11 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 18:31:40 GMT""},{""version"":""v3"",""created"":""Wed, 10 Feb 2021 16:28:07 GMT""},{""version"":""v4"",""created"":""Thu, 29 Apr 2021 03:32:42 GMT""}]","2021-04-30"
"2102.01869","Shuichi Murakami","Ken Osumi, Tiantian Zhang, Shuichi Murakami","Kinetic magnetoelectric effect in topological insulators","24 pages, 8 figures","Commun. Phys. 4, 211 (2021)","10.1038/s42005-021-00702-4",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The kinetic magnetoelectric effect is an orbital analogue of the Edelstein
effect and offers an additional degree of freedom to control magnetisation via
the charge current. Here we theoretically propose a gigantic kinetic
magnetoelectric effect in topological insulators and interpret the results in
terms of topological surface currents. We construct a theory of the kinetic
magnetoelectric effect for a surface Hamiltonian of a topological insulator,
and show that it well describes the results by direct numerical calculation.
This kinetic magnetoelectric effect depends on the details of the surface,
meaning that it cannot be defined as a bulk quantity. We propose that Chern
insulators and Z_2 topological insulators can be a platform with a large
kinetic magnetoelectric effect, compared to metals by 5 - 8 orders of
magnitude, because the current flows only along the surface. We demonstrate the
presence of said effect in a topological insulator, identifying
Cu$_2$ZnSnSe$_4$ as a potential candidate.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:16:38 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 13:33:28 GMT""}]","2021-09-22"
"2102.01870","Aidan Hotan","A. W. Hotan, J. D. Bunton, A. P. Chippendale, M. Whiting, J. Tuthill,
  V. A. Moss, D. McConnell, S. W. Amy, M. T. Huynh, J. R. Allison, C. S.
  Anderson, K. W. Bannister, E. Bastholm, R. Beresford, D. C.-J. Bock, R.
  Bolton, J. M. Chapman, K. Chow, J. D. Collier, F. R. Cooray, T. J. Cornwell,
  P. J. Diamond, P. G. Edwards, I. J. Feain, T. M. O. Franzen, D. George, N.
  Gupta, G. A. Hampson, L. Harvey-Smith, D. B. Hayman, I. Heywood, C. Jacka, C.
  A. Jackson, S. Jackson, K. Jeganathan, S. Johnston, M. Kesteven, D. Kleiner,
  B. S. Koribalski, K. Lee-Waddell, E. Lenc, E. S. Lensson, S. Mackay, E. K.
  Mahony, N. M. McClure-Griffiths, R. McConigley, P. Mirtschin, A. K. Ng, R. P.
  Norris, S. E. Pearce, C. Phillips, M. A. Pilawa, W. Raja, J. E. Reynolds, P.
  Roberts, D. N. Roxby, E. M. Sadler, M. Shields, A. E. T. Schinckel, P. Serra,
  R. D. Shaw, T. Sweetnam, E. R. Troup, A. Tzioumis, M. A. Voronkov, T.
  Westmeier","Australian Square Kilometre Array Pathfinder: I. System Description","38 pages, 24 figures, accepted for publication in PASA","Publ. Astron. Soc. Aust. 38 (2021) e009","10.1017/pasa.2021.1",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we describe the system design and capabilities of the
Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope at the
conclusion of its construction project and commencement of science operations.
ASKAP is one of the first radio telescopes to deploy phased array feed (PAF)
technology on a large scale, giving it an instantaneous field of view that
covers 31 square degrees at 800 MHz. As a two-dimensional array of 36x12m
antennas, with baselines ranging from 22m to 6km, ASKAP also has excellent
snapshot imaging capability and 10 arcsecond resolution. This, combined with
288 MHz of instantaneous bandwidth and a unique third axis of rotation on each
antenna, gives ASKAP the capability to create high dynamic range images of
large sky areas very quickly. It is an excellent telescope for surveys between
700 MHz and 1800 MHz and is expected to facilitate great advances in our
understanding of galaxy formation, cosmology and radio transients while opening
new parameter space for discovery of the unknown.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:16:57 GMT""}]","2021-07-01"
"2102.01871","Suo Tang","Suo Tang","Generation of quasi-monoenergetic positron beams in chirped laser fields",,"Phys. Rev. A 104, 022209 (2021)","10.1103/PhysRevA.104.022209",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  High energy photons can decay to electron-positron pairs via the nonlinear
Breit-Wheeler process when colliding with an intense laser pulse. The energy
spectrum of the produced particles is broadened because of the variation of
their effective mass in the course of the laser pulse. Applying a suitable
chirp to the laser pulse can narrow the energy distribution of the generated
electrons and positrons. We present a scenario where a high-energy electron
beam is collided with a chirped laser pulse to generate a beam of
quasi-monoenergetic $\gamma$-photons, which then decay in a second chirped, UV
pulse to produce a quasi-monoenergetic source of high-energy electrons and
positrons.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:20:47 GMT""}]","2021-08-25"
"2102.01872","Guo-Liang Ma","Long Ma, Guo-Liang Ma, Yu-Gang Ma","Parton collisional effect on the conversion of geometry eccentricities
  into momentum anisotropies in relativistic heavy-ion collisions","11 pages, 12 figues","Phys.Rev. C103 (2021) no.1, 014908","10.1103/PhysRevC.103.014908",,"nucl-th hep-ph nucl-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We explore parton collisional effects on the conversion of geometry
eccentricities into azimuthal anisotropies in Pb+Pb collisions at
$\sqrt{s_{NN}}$ = 5.02 TeV using a multi-phase transport model. The initial
eccentricity $\varepsilon_{n}$ (n = 2,3) and flow harmonics $v_{n}$ (n = 2,3)
are investigated as a function of the number of parton collisions ($N_{coll}$)
during the source evolution of partonic phase. It is found that partonic
collisions leads to generate elliptic flow $v_{2}$ and triangular flow $v_{3}$
in Pb+Pb collisions. On the other hand, partonic collisions also result in an
evolution of the eccentricity of geometry. The collisional effect on the flow
conversion efficiency is therefore studied. We find that the partons with
larger $N_{coll}$ show a lower flow conversion efficiency, which reflect
differential behaviors with respect to $N_{coll}$. It provides an additional
insight into the dynamics of the space-momentum transformation during the QGP
evolution from a transport model point of view.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:23:17 GMT""}]","2021-02-04"
"2102.01873","Praneet Singh","Praneet Singh, Jishnu Jaykumar, Akhil Pankaj, Reshmi Mitra","Edge-Detect: Edge-centric Network Intrusion Detection using Deep Neural
  Network",,,"10.1109/CCNC49032.2021.9369469",,"cs.CR cs.LG cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge nodes are crucial for detection against multitudes of cyber attacks on
Internet-of-Things endpoints and is set to become part of a multi-billion
industry. The resource constraints in this novel network infrastructure tier
constricts the deployment of existing Network Intrusion Detection System with
Deep Learning models (DLM). We address this issue by developing a novel light,
fast and accurate 'Edge-Detect' model, which detects Distributed Denial of
Service attack on edge nodes using DLM techniques. Our model can work within
resource restrictions i.e. low power, memory and processing capabilities, to
produce accurate results at a meaningful pace. It is built by creating layers
of Long Short-Term Memory or Gated Recurrent Unit based cells, which are known
for their excellent representation of sequential data. We designed a practical
data science pipeline with Recurring Neural Network to learn from the network
packet behavior in order to identify whether it is normal or attack-oriented.
The model evaluation is from deployment on actual edge node represented by
Raspberry Pi using current cybersecurity dataset (UNSW2015). Our results
demonstrate that in comparison to conventional DLM techniques, our model
maintains a high testing accuracy of 99% even with lower resource utilization
in terms of cpu and memory. In addition, it is nearly 3 times smaller in size
than the state-of-art model and yet requires a much lower testing time.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:24:34 GMT""}]","2022-07-07"
"2102.01874","Ghazal Mazaheri","Ghazal Mazaheri, Kevin Urrutia Avila, Amit K. Roy-Chowdhury","Learning to identify image manipulations in scientific publications",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adherence to scientific community standards ensures objectivity, clarity,
reproducibility, and helps prevent bias, fabrication, falsification, and
plagiarism. To help scientific integrity officers and journal/publisher
reviewers monitor if researchers stick with these standards, it is important to
have a solid procedure to detect duplication as one of the most frequent types
of manipulation in scientific papers. Images in scientific papers are used to
support the experimental description and the discussion of the findings.
Therefore, in this work we focus on detecting the duplications in images as one
of the most important parts of a scientific paper. We propose a framework that
combines image processing and deep learning methods to classify images in the
articles as duplicated or unduplicated ones. We show that our method leads to a
90% accuracy rate of detecting duplicated images, a ~ 13% improvement in
detection accuracy in comparison to other manipulation detection methods. We
also show how effective the pre-processing steps are by comparing our method to
other state-of-art manipulation detectors which lack these steps.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:47:34 GMT""}]","2021-02-04"
"2102.01875","Nafiul Rashid","Nafiul Rashid, Berken Utku Demirel, Mohammad Abdullah Al Faruque","AHAR: Adaptive CNN for Energy-efficient Human Activity Recognition in
  Low-power Edge Devices","11 pages, 9 figures, Accepted to be published in IEEE Internet of
  Things Journal",,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human Activity Recognition (HAR) is one of the key applications of health
monitoring that requires continuous use of wearable devices to track daily
activities. This paper proposes an Adaptive CNN for energy-efficient HAR (AHAR)
suitable for low-power edge devices. Unlike traditional early exit architecture
that makes the exit decision based on classification confidence, AHAR proposes
a novel adaptive architecture that uses an output block predictor to select a
portion of the baseline architecture to use during the inference phase.
Experimental results show that traditional early exit architectures suffer from
performance loss whereas our adaptive architecture provides similar or better
performance as the baseline one while being energy-efficient. We validate our
methodology in classifying locomotion activities from two datasets- Opportunity
and w-HAR. Compared to the fog/cloud computing approaches for the Opportunity
dataset, our baseline and adaptive architecture shows a comparable weighted F1
score of 91.79%, and 91.57%, respectively. For the w-HAR dataset, our baseline
and adaptive architecture outperforms the state-of-the-art works with a
weighted F1 score of 97.55%, and 97.64%, respectively. Evaluation on real
hardware shows that our baseline architecture is significantly energy-efficient
(422.38x less) and memory-efficient (14.29x less) compared to the works on the
Opportunity dataset. For the w-HAR dataset, our baseline architecture requires
2.04x less energy and 2.18x less memory compared to the state-of-the-art work.
Moreover, experimental results show that our adaptive architecture is 12.32%
(Opportunity) and 11.14% (w-HAR) energy-efficient than our baseline while
providing similar (Opportunity) or better (w-HAR) performance with no
significant memory overhead.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:49:16 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 19:14:35 GMT""},{""version"":""v3"",""created"":""Mon, 3 Jan 2022 06:10:09 GMT""}]","2022-01-04"
"2102.01876","Haitao Liu","Dali Zhu, Haitao Liu, Ting Li, Jiyan Sun, Jie Liang, Hangsheng Zhang,
  Liru Geng and Yinlong Liu","Deep Reinforcement Learning-based Task Offloading in
  Satellite-Terrestrial Edge Computing Networks",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  In remote regions (e.g., mountain and desert), cellular networks are usually
sparsely deployed or unavailable. With the appearance of new applications
(e.g., industrial automation and environment monitoring) in remote regions,
resource-constrained terminals become unable to meet the latency requirements.
Meanwhile, offloading tasks to urban terrestrial cloud (TC) via satellite link
will lead to high delay. To tackle above issues, Satellite Edge Computing
architecture is proposed, i.e., users can offload computing tasks to visible
satellites for executing. However, existing works are usually limited to
offload tasks in pure satellite networks, and make offloading decisions based
on the predefined models of users. Besides, the runtime consumption of existing
algorithms is rather high.
  In this paper, we study the task offloading problem in satellite-terrestrial
edge computing networks, where tasks can be executed by satellite or urban TC.
The proposed Deep Reinforcement learning-based Task Offloading (DRTO) algorithm
can accelerate learning process by adjusting the number of candidate locations.
In addition, offloading location and bandwidth allocation only depend on the
current channel states. Simulation results show that DRTO achieves near-optimal
offloading cost performance with much less runtime consumption, which is more
suitable for satellite-terrestrial network with fast fading channel.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:53:20 GMT""}]","2021-02-04"
"2102.01877","Haoxiang Luo","Zheng Li, Ye Chen, Siyuan Chang, Bernard Rousseau, Haoxiang Luo","A one-dimensional flow model enhanced by machine learning for simulation
  of vocal fold vibration",,,"10.1121/10.0003561",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We describe a one-dimensional (1D) unsteady and viscous flow model that is
derived from the momentum and mass conservation equations, and to enhance this
physics-based model, we use a machine learning approach to determine the
unknown modeling parameters. Specifically, we first construct an idealized
larynx model and perform ten cases of three-dimensional (3D) fluid--structure
interaction (FSI) simulations. The flow data are then extracted to train the 1D
flow model using a sparse identification approach for nonlinear dynamical
systems. As a result of training, we obtain the analytical expressions for the
entrance effect and pressure loss in the glottis, which are then incorporated
in the flow model to conveniently handle different glottal shapes due to vocal
fold vibration. We apply the enhanced 1D flow model in the FSI simulation of
both idealized vocal fold geometries and subject-specific anatomical geometries
reconstructed from the MRI images of rabbits' larynges. The 1D flow model is
evaluated in both of these setups and is shown to have robust performance.
Therefore, it provides a fast simulation tool superior to the previous 1D
models.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:57:40 GMT""}]","2021-04-07"
"2102.01878","Tzonelih Hwang","Jun Gu and Tzonelih Hwang","Lightweight authenticated quantum key distribution protocols with key
  recycling",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum key distribution (QKD) has been developed for decades and several
different QKD protocols have been proposed. But two difficulties limit the
implementation of most QKD protocols. First, the involved participants are
required to have heavy quantum capabilities, such as quantum joint operation,
quantum register, and so on. Second, a hypothetical authenticated classical
channel is used in most of the existing QKD protocols and this assumed channel
does not exist in reality. To solve both the above limitations at the same
time, this study proposes three lightweight authenticated QKD protocols with
key recycling and shows these proposed protocols are robust under the
collective attack.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:02:49 GMT""}]","2021-02-04"
"2102.01879","David Mattingly","Jonathan Cheyne, David Mattingly","Energy-entropy relation for asymptotically Lifshitz spacetimes with
  universal horizons","7 pages","Phys. Rev. D 103, 086012 (2021)","10.1103/PhysRevD.103.086012",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We numerically solve for 2+1 asymptotically Lifshitz universal horizon
solutions in Horava-Lifshitz gravity for dynamical exponents $z=2$ through
$z=8$. We find that for all $z$ there is a thermodynamical first law and Smarr
formula. Furthermore, we find that the energy-entropy relation expected for a
thermal state in a two dimensional Lifshitz field theory, $E=\frac{2}{z+2}TS$,
is also satisfied for universal horizons, including the correct $z$ scaling.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:04:18 GMT""}]","2021-04-21"
"2102.01880","Jianjun Hu","Yong Zhao, Mohammed Al-Fahdi, Ming Hu, Edirisuriya MD Siriwardane,
  Yuqi Song, Alireza Nasiri, Jianjun Hu","High-throughput discovery of novel cubic crystal materials using deep
  generative neural networks","14 pages, 4 figures","Advanced Science 2021","10.1002/advs.202100566",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  High-throughput screening has become one of the major strategies for the
discovery of novel functional materials. However, its effectiveness is severely
limited by the lack of quantity and diversity of known materials deposited in
the current materials repositories such as ICSD and OQMD. Recent progress in
machine learning and especially deep learning have enabled a generative
strategy that learns implicit chemical rules for creating chemically valid
hypothetical materials with new compositions and structures. However, current
materials generative models have difficulty in generating structurally diverse,
chemically valid, and stable materials. Here we propose CubicGAN, a generative
adversarial network (GAN) based deep neural network model for large scale
generation of novel cubic crystal structures. When trained on 375,749 ternary
crystal materials from the OQMD database, we show that our model is able to not
only rediscover most of the currently known cubic materials but also generate
hypothetical materials of new structure prototypes. A total of 506 such new
materials (all of them are either ternary or quarternary) have been verified by
DFT based phonon dispersion stability check, several of which have been found
to potentially have exceptional functional properties. Considering the
importance of cubic materials in wide applications such as solar cells and
lithium batteries, our GAN model provides a promising approach to significantly
expand the current repository of materials, enabling the discovery of new
functional materials via screening. The new crystal structures finally verified
by DFT are freely accessible at our Carolina Materials Database
http://www.carolinamatdb.org.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:19:36 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 20:19:02 GMT""}]","2021-12-15"
"2102.01881","Wen Jun Lim","Wen Jun Lim, Rana Abbas, Yonghui Li, Branka Vucetic, Mahyar
  Shirvanimoghaddam","Analysis and Design of Analog Fountain Codes for Short Packet
  Communications","13 pages, 15 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on the design and analysis of the Analog Fountain
Code (AFC) for short packet communications. We first propose a density
evolution (DE) based framework, which tracks the evolution of the probability
density function of the messages exchanged between variable and check nodes of
AFC in the belief propagation decoder. Using the proposed DE framework, we
formulate an optimisation problem to find the optimal AFC code parameters,
including the weight-set, which minimises the bit error rate at a given
signal-to-noise ratio (SNR). Our results show the superiority of our AFC code
design compared to existing designs of AFC in the literature and thus the
validity of the proposed DE framework in the asymptotically long block length
regime. We then focus on selecting the precoder to improve the performance of
AFC at short block lengths. Simulation results show that lower precode rates
obtain better realised rates over a wide SNR range for short information block
lengths. We also discuss the complexity of the AFC decoder and propose a
threshold-based decoder to reduce the complexity.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:23:29 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 07:26:58 GMT""},{""version"":""v3"",""created"":""Fri, 15 Oct 2021 01:18:32 GMT""}]","2021-10-18"
"2102.01882","Ammar Kamoona","Ammar Mansoor Kamoona, Amirali Khodadadian Gostar, Alireza
  Bab-Hadiashar, Reza Hoseinnezhad","Evaluation of Point Pattern Features for Anomaly Detection of Defect
  within Random Finite Set Framework","under review. 6 pages",,"10.1109/ACCESS.2021.3130261",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Defect detection in the manufacturing industry is of utmost importance for
product quality inspection. Recently, optical defect detection has been
investigated as an anomaly detection using different deep learning methods.
However, the recent works do not explore the use of point pattern features,
such as SIFT for anomaly detection using the recently developed set-based
methods. In this paper, we present an evaluation of different point pattern
feature detectors and descriptors for defect detection application. The
evaluation is performed within the random finite set framework. Handcrafted
point pattern features, such as SIFT as well as deep features are used in this
evaluation. Random finite set-based defect detection is compared with
state-of-the-arts anomaly detection methods. The results show that using point
pattern features, such as SIFT as data points for random finite set-based
anomaly detection achieves the most consistent defect detection accuracy on the
MVTec-AD dataset.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:30:32 GMT""}]","2021-11-29"
"2102.01883","Sergiy Shelyag","Maia Angelova, Philip M. Holloway, Sergiy Shelyag, Sutharshan
  Rajasegarar, and H.G. Laurie Rauch","Effect of stress on cardiorespiratory synchronization of Ironmen
  athletes","Accepted for publication in Frontiers in Physiology -- Fractal and
  Network Physiology",,"10.3389/fphys.2021.612245",,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to investigate the cardiorespiratory synchronization
in athletes subjected to extreme physical stress combined with a cognitive
stress tasks. ECG and respiration were measured in 14 athletes before and after
the Ironmen competition. Stroop test was applied between the measurements
before and after the Ironmen competition to induce cognitive stress.
Synchrogram and empirical mode decomposition analysis were used for the first
time to investigate the effects of physical stress, induced by the Ironmen
competition, on the phase synchronization of the cardiac and respiratory
systems of Ironmen athletes before and after the competition. A cognitive
stress task (Stroop test) was performed both pre- and post-Ironman event in
order to prevent the athletes from cognitively controlling their breathing
rates. Our analysis showed that cardiorespiratory synchronization increased
post-Ironman race compared to pre-Ironman. The results suggest that the amount
of stress the athletes are recovering from post-competition is greater than the
effects of the Stroop test. This indicates that the recovery phase after the
competition is more important for restoring and maintaining homeostasis, which
could be another reason for stronger synchronization.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:33:54 GMT""}]","2021-03-03"
"2102.01884","Bekir Sait Ciftler","Bekir Sait Ciftler, Abdulmalik Alwarafy, Mohamed Abdallah, Mounir
  Hamdi","DQN-Based Multi-User Power Allocation for Hybrid RF/VLC Networks","6 pages, 4 figures, accepted to IEEE ICC 2021",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a Deep Q-Network (DQN) based multi-agent multi-user power
allocation algorithm is proposed for hybrid networks composed of radio
frequency (RF) and visible light communication (VLC) access points (APs). The
users are capable of multihoming, which can bridge RF and VLC links for
accommodating their bandwidth requirements. By leveraging a non-cooperative
multi-agent DQN algorithm, where each AP is an agent, an online power
allocation strategy is developed to optimize the transmit power for providing
users' required data rate. Our simulation results demonstrate that DQN's median
convergence time training is 90% shorter than the Q-Learning (QL) based
algorithm. The DQN-based algorithm converges to the desired user rate in half
duration on average while converging with the rate of 96.1% compared to the
QL-based algorithm's convergence rate of 72.3% Additionally, thanks to its
continuous state-space definition, the DQN-based power allocation algorithm
provides average user data rates closer to the target rates than the QL-based
algorithm when it converges.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:42:49 GMT""}]","2021-02-04"
"2102.01885","Sergei Gninenko","Yu.M. Andreev, D. Banerjee, J. Bernhard, V.E. Burtsev, A.G. Chumakov,
  D. Cooke, P. Crivelli, E. Depero, A.V. Dermenev, S.V. Donskov, R.R. Dusaev,
  T. Enik, N. Charitonidis, A.Feshchenko, V.N. Frolov, A.Gardikiotis, S.G.
  Gerassimov, S.N. Gninenko, M. Hosgen, V.A. Kachanov, A.E. Karneyeu, G.
  Kekelidze, B. Ketzer, D.V.Kirpichnikov, M.M. Kirsanov, V.N. Kolosov, I.V.
  Konorov, S.G. Kovalenko, V.A. Kramarenko, L.V. Kravchuk, N.V. Krasnikov, S.V.
  Kuleshov, V.E. Lyubovitskij, V.Lysan, V.A. Matveev, Yu.V. Mikhailov, L.
  Molina Bueno, D.V. Peshekhonov, V.A. Polyakov, B. Radics, R. Rojas, A.
  Rubbia, V.D. Samoylenko, H. Sieber, D. Shchukin, V.O.Tikhomirov, I. Tlisova,
  A.N. Toropin, A.Yu. Trifonov, B.I. Vasilishin, P.V. Volkov, V.Yu. Volkov","Constraints on New Physics in the Electron g-2 from a Search for
  Invisible Decays of a Scalar, Pseudoscalar, Vector, and Axial Vector","6 pages, 4 figures","Phys. Rev. Lett. 126, 211802 (2021)","10.1103/PhysRevLett.126.211802","CERN-EP-2021-017","hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  We performed a search for a new generic $X$ boson, which could be a scalar
($S$), pseudoscalar ($P$), vector ($V$) or an axial vector ($A$) particle
produced in the 100 GeV electron scattering off nuclei, $e^- Z \to e^- Z X$,
followed by its invisible decay in the NA64 experiment at CERN. No evidence for
such process was found in the full NA64 data set of $2.84\times 10^{11}$
electrons on target. We place new bounds on the $S, P, V, A$ coupling strengths
to electrons, and set constraints on their contributions to the electron
anomalous magnetic moment $a_e$, $|\Delta a_{X}| \lesssim 10^{-15} - 10^{-13}$
for the $X$ mass region $m_X\lesssim 1$ GeV. These results are an order of
magnitude more sensitive compared to the current accuracy on $a_e$ from the
electron $g-2$ experiments and recent high-precision determination of the fine
structure constant.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:47:06 GMT""}]","2021-06-02"
"2102.01886","Xuefeng Du","Xuefeng Du, Jingfeng Zhang, Bo Han, Tongliang Liu, Yu Rong, Gang Niu,
  Junzhou Huang, Masashi Sugiyama","Learning Diverse-Structured Networks for Adversarial Robustness","ICML2021, code: https://github.com/d12306/dsnet",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In adversarial training (AT), the main focus has been the objective and
optimizer while the model has been less studied, so that the models being used
are still those classic ones in standard training (ST). Classic network
architectures (NAs) are generally worse than searched NAs in ST, which should
be the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NAs in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best one in a searched block of DS-Net, which is an essential trade-off between
exploring diverse structures and exploiting the best structures. Empirical
results demonstrate the advantages of DS-Net, i.e., weighting the atomic
blocks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:52:11 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 14:48:27 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 03:09:39 GMT""},{""version"":""v4"",""created"":""Fri, 18 Jun 2021 06:57:10 GMT""}]","2021-06-21"
"2102.01887","Francisco Romero","Francisco Romero, Mark Zhao, Neeraja J. Yadwadkar, Christos Kozyrakis","Llama: A Heterogeneous & Serverless Framework for Auto-Tuning Video
  Analytics Pipelines",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  The proliferation of camera-enabled devices and large video repositories has
led to a diverse set of video analytics applications. These applications rely
on video pipelines, represented as DAGs of operations, to transform videos,
process extracted metadata, and answer questions like, ""Is this intersection
congested?"" The latency and resource efficiency of pipelines can be optimized
using configurable knobs for each operation (e.g., sampling rate, batch size,
or type of hardware used). However, determining efficient configurations is
challenging because (a) the configuration search space is exponentially large,
and (b) the optimal configuration depends on users' desired latency and cost
targets, (c) input video contents may exercise different paths in the DAG and
produce a variable amount intermediate results. Existing video analytics and
processing systems leave it to the users to manually configure operations and
select hardware resources.
  We present Llama: a heterogeneous and serverless framework for auto-tuning
video pipelines. Given an end-to-end latency target, Llama optimizes for cost
efficiency by (a) calculating a latency target for each operation invocation,
and (b) dynamically running a cost-based optimizer to assign configurations
across heterogeneous hardware that best meet the calculated per-invocation
latency target. This makes the problem of auto-tuning large video pipelines
tractable and allows us to handle input-dependent behavior, conditional
branches in the DAG, and execution variability. We describe the algorithms in
Llama and evaluate it on a cloud platform using serverless CPU and GPU
resources. We show that compared to state-of-the-art cluster and serverless
video analytics and processing systems, Llama achieves 7.8x lower latency and
16x cost reduction on average.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:03:18 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 17:59:03 GMT""}]","2021-05-31"
"2102.01888","Jnanadeva Maharana","Jnanadeva Maharana","PCT Theorem, Wightman Axioms and Conformal Bootstrap","13 pages; no figures",,"10.1142/S0217732321500723",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The axiomatic Wightman formulation for nonderivative conformal field theory
is adopted to derive conformal bootstrap equation for the four point function.
The equivalence between PCT theorem and {\it weak local commutativity}, due to
Jost, play a very crucial role in axiomatic field theory. The theorem is
suitably adopted for conformal field theory to derive the desired equations in
CFT. We demonstrate that the two Wightman functions are analytic continuation
of each other.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:04:39 GMT""}]","2021-04-21"
"2102.01889","Yangling Ma","Yangling Ma, Zhouwang Yang","Multi-Instance Learning by Utilizing Structural Relationship among
  Instances","22 pages,5 figures",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multi-Instance Learning(MIL) aims to learn the mapping between a bag of
instances and the bag-level label. Therefore, the relationships among instances
are very important for learning the mapping. In this paper, we propose an MIL
algorithm based on a graph built by structural relationship among instances
within a bag. Then, Graph Convolutional Network(GCN) and the graph-attention
mechanism are used to learn bag-embedding. In the task of medical image
classification, our GCN-based MIL algorithm makes full use of the structural
relationships among patches(instances) in an original image space domain, and
experimental results verify that our method is more suitable for handling
medical high-resolution images. We also verify experimentally that the proposed
method achieves better results than previous methods on five bechmark MIL
datasets and four medical image datasets.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:06:03 GMT""}]","2021-02-04"
"2102.01890","Cheongho Han","Cheongho Han, Andrzej Udalski, Chung-Uk Lee, Michael D. Albrow, Sun-Ju
  Chung, Andrew Gould, Kyu-Ha Hwang, Youn Kil Jung, Doeon Kim, Hyoun-Woo Kim,
  Yoon-Hyun Ryu, In-Gu Shin, Yossi Shvartzvald, Jennifer C. Yee, Weicheng Zang,
  Sang-Mok Cha, Dong-Jin Kim, Seung-Lee Kim, Dong-Joo Lee, Yongseok Lee,
  Byeong-Gon Park, Richard W. Pogge, Chun-Hwey Kim, Woong-Tae Kim, Przemek
  Mr\'oz, Micha{\l} K. Szyma\'nski, Jan Skowron, Rados{\l}aw Poleski, Igor
  Soszy\'nski, Pawe{\l} Pietrukowicz, Szymon Koz{\l}owski, Krzysztof Ulaczyk,
  Krzysztof A. Rybicki, Patryk Iwanek, Marcin Wrona","KMT-2018-BLG-1025Lb: microlensing super-Earth planet orbiting a low-mass
  star","10 pages, 10 figures, 5 tables",,"10.1051/0004-6361/202039817",,"astro-ph.EP astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We aim to find missing microlensing planets hidden in the unanalyzed lensing
events of previous survey data. For this purpose, we conduct a systematic
inspection of high-magnification microlensing events, with peak magnifications
$A_{\rm peak}\gtrsim 30$, in the data collected from high-cadence surveys in
and before the 2018 season. From this investigation, we identify an anomaly in
the lensing light curve of the event KMT-2018-BLG-1025. The analysis of the
light curve indicates that the anomaly is caused by a very low mass-ratio
companion to the lens. We identify three degenerate solutions, in which the
ambiguity between a pair of solutions (solutions B) is caused by the previously
known close--wide degeneracy, and the degeneracy between these and the other
solution (solution A) is a new type that has not been reported before. The
estimated mass ratio between the planet and host is $q\sim 0.8\times 10^{-4}$
for the solution A and $q\sim 1.6\times 10^{-4}$ for the solutions B. From the
Bayesian analysis conducted with measured observables, we estimate that the
masses of the planet and host and the distance to the lens are $(M_{\rm p},
M_{\rm h}, D_{\rm L})\sim (6.1~M_\oplus, 0.22~M_\odot, 6.7~{\rm kpc})$ for the
solution A and $\sim (4.4~M_\oplus, 0.08~M_\odot, 7.5~{\rm kpc})$ for the
solutions B. The planet mass is in the category of a super-Earth regardless of
the solutions, making the planet the eleventh super-Earth planet, with masses
lying between those of Earth and the Solar system's ice giants, discovered by
microlensing.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:11:53 GMT""}]","2021-05-26"
"2102.01891","Zhiwei Tao","Zhiwei Tao, Yichong Ren, Azezigul Abdukirim, Shiwei Liu and Ruizhong
  Rao","Physical meaning of the deviation scale under arbitrary turbulence
  strengths of optical orbital angular momentum","10 pages, 6 figures; This paper aims to give a suitable physical
  interpretation for the recently so-called deviation scale [C. M. Mabena et
  al., Phys. Rev. A 99, 013828 (2019)]","J. Opt. Soc. Am. A 38, 1120-1129 (2021)","10.1364/JOSAA.418947",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  The recently so-called deviation scale [C. M. Mabena et al., Phys. Rev. A 99,
013828 (2019)] bridges the connection between the result of the infinitesimal
propagation equation (IPE) prediction and that of the single phase screen (SPS)
approximation. Thanks to the multiple phase screen (MPS) approach, in this
paper we elaborate the physical meaning of the deviation scale: the spatial
accumulation of slight intensity modulation of incident orbital angular
momentum (OAM) carrying beam splits the original vortex into multiple
individual vortices with a topological charge (TC) of +1 and re-generates the
vortex-antivortex pairs with a TC of +1 and with a TC of -1, leading to a
significant deviation between these two different results only when the
disruption of this compound effect on the phase distribution of the incident
OAM-carrying beam becomes more significant. Other than that, we also show that
the appearance of the deviation scale cannot be predicted only by the Rytov
variance, which can be predicted through the vortex-splitting ratio of the
received optical field alone or with the help of the normalized propagation
distance.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:12:56 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 01:28:34 GMT""},{""version"":""v3"",""created"":""Fri, 9 Jul 2021 01:47:02 GMT""}]","2021-07-12"
"2102.01892","Noel Cressie","Noel Cressie","A few statistical principles for data science","19 pages; written for a special issue (festschrift) of the Australian
  and New Zealand Journal of Statistics",,,,"stat.OT stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In any other circumstance, it might make sense to define the extent of the
terrain (Data Science) first, and then locate and describe the landmarks
(Principles). But this data revolution we are experiencing defies a cadastral
survey. Areas are continually being annexed into Data Science. For example,
biometrics was traditionally statistics for agriculture in all its forms but
now, in Data Science, it means the study of characteristics that can be used to
identify an individual. Examples of non-intrusive measurements include height,
weight, fingerprints, retina scan, voice, photograph/video (facial landmarks
and facial expressions), and gait. A multivariate analysis of such data would
be a complex project for a statistician, but a software engineer might appear
to have no trouble with it at all. In any applied-statistics project, the
statistician worries about uncertainty and quantifies it by modelling data as
realisations generated from a probability space. Another approach to
uncertainty quantification is to find similar data sets, and then use the
variability of results between these data sets to capture the uncertainty. Both
approaches allow 'error bars' to be put on estimates obtained from the original
data set, although the interpretations are different. A third approach, that
concentrates on giving a single answer and gives up on uncertainty
quantification, could be considered as Data Engineering, although it has staked
a claim in the Data Science terrain. This article presents a few (actually
nine) statistical principles for data scientists that have helped me, and
continue to help me, when I work on complex interdisciplinary projects.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:28:03 GMT""}]","2021-02-04"
"2102.01893","Teruaki Akazawa","Teruaki Akazawa, Yuma Kinoshita and Hitoshi Kiya","Multi-color balancing for correctly adjusting the intensity of target
  colors","\c{opyright} 2021 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","In Proc. of 2021 IEEE 3rd Global Conference on Life Sciences and
  Technologies (LifeTech), pp.8-12, Mar., 2021","10.1109/LifeTech52111.2021.9391973",,"cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel multi-color balance method for reducing
color distortions caused by lighting effects. The proposed method allows us to
adjust three target-colors chosen by a user in an input image so that each
target color is the same as the corresponding destination (benchmark) one. In
contrast, white balancing is a typical technique for reducing the color
distortions, however, they cannot remove lighting effects on colors other than
white. In an experiment, the proposed method is demonstrated to be able to
remove lighting effects on selected three colors, and is compared with existing
white balance adjustments.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:28:18 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 09:21:37 GMT""}]","2021-05-24"
"2102.01894","Limin Wang","Jing Tan, Jiaqi Tang, Limin Wang, Gangshan Wu","Relaxed Transformer Decoders for Direct Action Proposal Generation","ICCV 2021 camera ready version",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Temporal action proposal generation is an important and challenging task in
video understanding, which aims at detecting all temporal segments containing
action instances of interest. The existing proposal generation approaches are
generally based on pre-defined anchor windows or heuristic bottom-up boundary
matching strategies. This paper presents a simple and efficient framework
(RTD-Net) for direct action proposal generation, by re-purposing a
Transformer-alike architecture. To tackle the essential visual difference
between time and space, we make three important improvements over the original
transformer detection framework (DETR). First, to deal with slowness prior in
videos, we replace the original Transformer encoder with a boundary attentive
module to better capture long-range temporal information. Second, due to the
ambiguous temporal boundary and relatively sparse annotations, we present a
relaxed matching scheme to relieve the strict criteria of single assignment to
each groundtruth. Finally, we devise a three-branch head to further improve the
proposal confidence estimation by explicitly predicting its completeness.
Extensive experiments on THUMOS14 and ActivityNet-1.3 benchmarks demonstrate
the effectiveness of RTD-Net, on both tasks of temporal action proposal
generation and temporal action detection. Moreover, due to its simplicity in
design, our framework is more efficient than previous proposal generation
methods, without non-maximum suppression post-processing. The code and models
are made available at https://github.com/MCG-NJU/RTD-Action.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:29:28 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 08:43:34 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 13:42:57 GMT""}]","2021-08-20"
"2102.01895","Barak Or","Barak Or and Liam Hazan","Length Learning for Planar Euclidean Curves","5 pages",,,,"cs.GR cs.CG cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we used deep neural networks (DNNs) to solve a fundamental
problem in differential geometry. One can find many closed-form expressions for
calculating curvature, length, and other geometric properties in the
literature. As we know these concepts, we are highly motivated to reconstruct
them by using deep neural networks. In this framework, our goal is to learn
geometric properties from examples. The simplest geometric object is a curve.
Therefore, this work focuses on learning the length of planar sampled curves
created by a sine waves dataset. For this reason, the fundamental length axioms
were reconstructed using a supervised learning approach. Following these axioms
a simplified DNN model, we call ArcLengthNet, was established. The robustness
to additive noise and discretization errors were tested.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:30:03 GMT""}]","2021-02-04"
"2102.01896","Vinayak Kamble PhD","Soumya Biswas, Saurabh Singh, Shubham Singh, Shashwata Chattopadhyay,
  K. K. H. De Silva, M. Yoshimura, J. Mitra, Vinayak Kamble","Selective Enhancement in Phonon Scattering leads to High Thermoelectric
  Figure of Merit in ZnO -- Graphene Oxide Core-shell Nanohybrids",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  ZnO is a promising candidate as an environment friendly thermoelectric (TE)
material. However, the poor TE figure of merit (zT) needs to be addressed to
achieve significant TE efficiency for commercial applications. Here we
demonstrate that selective enhancement in phonon scattering leads to increase
in zT of RGO encapsulated Al-doped ZnO core shell nanohybrids, synthesized via
a facile and scalable method. The incorporation of 1 at% Al with 1.5 wt% RGO
into ZnO (AGZO) has been found to show significant enhancement in zT (=0.52 at
1100 K) which is an order of magnitude larger compared to that of bare undoped
ZnO. Photoluminescence and X-ray photoelectron spectroscopy measurements
confirm that RGO encapsulation significantly quenches surface oxygen vacancies
in ZnO along with nucleation of new interstitial Zn donor states. Tunneling
spectroscopy reveals that the band gap of ~ 3.4 eV for bare ZnO reduces
effectively to ~ 0.5 eV upon RGO encapsulation, facilitating charge transport.
The electrical conductivity enhancement also benefits from the more than 95%
densification achieved, using the spark plasma sintering method, which aids
reduction of GO into RGO. The same Al doping and RGO capping synergistically
brings about drastic reduction of thermal conductivity, through enhanced
phonon-phonon and point defect-phonon scatterings. These opposing effects on
electrical and thermal conductivities enhances the power factors as well as the
zT value. Overall, a practically viable route for synthesis of oxide - RGO TE
material which could find its practical applications for the high-temperature
TE power generation.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:31:26 GMT""}]","2021-02-04"
"2102.01897","WenHui Lei","Wenhui Lei, Haochen Mei, Zhengwentai Sun, Shan Ye, Ran Gu, Huan Wang,
  Rui Huang, Shichuan Zhang, Shaoting Zhang, Guotai Wang","Automatic Segmentation of Organs-at-Risk from Head-and-Neck CT using
  Separable Convolutional Neural Network with Hard-Region-Weighted Loss","Accepted by Neurocomputing",,,,"eess.IV cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Nasopharyngeal Carcinoma (NPC) is a leading form of Head-and-Neck (HAN)
cancer in the Arctic, China, Southeast Asia, and the Middle East/North Africa.
Accurate segmentation of Organs-at-Risk (OAR) from Computed Tomography (CT)
images with uncertainty information is critical for effective planning of
radiation therapy for NPC treatment. Despite the stateof-the-art performance
achieved by Convolutional Neural Networks (CNNs) for automatic segmentation of
OARs, existing methods do not provide uncertainty estimation of the
segmentation results for treatment planning, and their accuracy is still
limited by several factors, including the low contrast of soft tissues in CT,
highly imbalanced sizes of OARs and large inter-slice spacing. To address these
problems, we propose a novel framework for accurate OAR segmentation with
reliable uncertainty estimation. First, we propose a Segmental Linear Function
(SLF) to transform the intensity of CT images to make multiple organs more
distinguishable than existing methods based on a simple window width/level that
often gives a better visibility of one organ while hiding the others. Second,
to deal with the large inter-slice spacing, we introduce a novel 2.5D network
(named as 3D-SepNet) specially designed for dealing with clinic HAN CT scans
with anisotropic spacing. Thirdly, existing hardness-aware loss function often
deal with class-level hardness, but our proposed attention to hard voxels (ATH)
uses a voxel-level hardness strategy, which is more suitable to dealing with
some hard regions despite that its corresponding class may be easy. Our code is
now available at https://github.com/HiLab-git/SepNet.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:31:38 GMT""}]","2021-02-04"
"2102.01898","Run-Qiu Yang","Run-Qiu Yang","Gravity dualities of quantum distances","1 figure, 11 pages",,"10.1007/JHEP08(2021)156",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By choosing modular ground state as the reference state, this paper finds
that three most frequently-used distances and a quantum quasi-distance, i.e.
the trace distance, Fubini-Study distance, Bures distance and R\'{e}nyi
relative entropy, all have gravity dualities. Their gravity dualities have two
equivalent descriptions: one is given by the integration of the area of a
cosmic brane, the other one is given by the Euclidian on-shell action of dual
theory and the area of the cosmic brane. It then applies these dualities into
the 2-dimensional conformal field theory as examples and finds the results
match with the computations of field theory exactly.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:32:39 GMT""}]","2021-09-15"
"2102.01899","Koki Satsukawa","Haoran Fu, Takashi Akamatsu, Koki Satsukawa, Kentaro Wada","Dynamic traffic assignment in a corridor network: Optimum versus
  Equilibrium","34 pages, 14figures",,,,"math.OC cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates dynamic system-optimal (DSO) and dynamic user
equilibrium (DUE) traffic assignment of departure/arrival-time choices in a
corridor network. The morning commute problems with a many-to-one pattern of
origin-destination demand and the evening commute problems with a one-to-many
pattern are considered. Specifically, a novel approach to derive closed-form
solutions for both DSO and DUE problems is developed. We first derive a
closed-form solution to the DSO problem based on the regularities of the cost
and flow variables at an optimal state. By utilizing this solution, we prove
that the queuing delay at a bottleneck in a DUE solution is equal to an optimal
toll that eliminates the queue in a DSO solution under certain conditions of a
schedule delay function. This enables us to derive a closed-form DUE solution
by using the DSO solution. We also show the theoretical relationship between
the DSO and DUE assignment. Numerical examples are provided to illustrate and
verify the analytical results.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:33:51 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 13:01:23 GMT""}]","2021-08-24"
"2102.01900","Rucha Joshi","Rucha Bhalchandra Joshi and Annada Prasad Behera and Subhankar Mishra","Temporal Motifs in Smart Grid",,"Proceedings of the 9th International Conference on Smart Cities
  and Green ICT Systems - Volume 1: SMARTGREENS 2020, ISBN 978-989-758-418-3,
  pages 122-127","10.5220/0009575301220127",,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  A complex network can be characterized by patterns. Such frequently occurring
significant patterns are called motifs and in a time dependent network, they
are called temporal motifs. One of the temporal networks where temporal motifs
are observed and play a major role; is the Smart Grid. The energy consumption
pattern across the appliances, houses, communities and entire cities help
energy utility companies and consumers plan their electricity generation and
consumption. The temporal motifs for the smart grid constitutes of the
consumers and producers and the edge or connection represents energy flow
between two participants of the network, these connections last till the power
is being consumed/generated. This paper formally defines the temporal motifs
for smart grid network and proposes a way to create such temporal motifs in the
network. We also discuss how the temporal motifs fit into the hierarchical
structure of power distribution system of Smart Grid.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:41:08 GMT""}]","2021-02-04"
"2102.01901","Harry Septanto","Harry Septanto, Djoko Suprijanto","Linear Continuous Sliding Mode-based Attitude Controller with Modified
  Rodrigues Parameters Feedback",,,"10.1109/ICRAMET51080.2020.9298661",,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies an attitude control system design based on modified
Rodrigues parameters feedback. It employs a linear continuous sliding mode
controller. The sliding mode controller is able to bring the existence of the
sliding motion asymptotically. Besides, the attitude control system equilibrium
point is proved to have an asymptotic stability guarantee through further
analysis. This stability analysis is conducted since the sliding mode existence
on the designed sliding surface does not imply the stability guarantee of the
system's equilibrium. This paper ends with some numerical examples that confirm
the effectiveness of the designed attitude control system.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:42:28 GMT""}]","2021-02-04"
"2102.01902","Chen Liang","Tianchi Cai, Daxi Cheng, Chen Liang, Ziqi Liu, Lihong Gu, Huizhi Xie,
  Zhiqiang Zhang, Xiaodong Zeng, Jinjie Gu","LinkLouvain: Link-Aware A/B Testing and Its Application on Online
  Marketing Campaign","Accepted by the Industrial & Practitioner Track of the 26th
  International Conference on Database Systems for Advanced Applications
  (DASFAA 2021)","DASFAA 2021","10.1007/978-3-030-73200-4_34",,"cs.SI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A lot of online marketing campaigns aim to promote user interaction. The
average treatment effect (ATE) of campaign strategies need to be monitored
throughout the campaign. A/B testing is usually conducted for such needs,
whereas the existence of user interaction can introduce interference to normal
A/B testing. With the help of link prediction, we design a network A/B testing
method LinkLouvain to minimize graph interference and it gives an accurate and
sound estimate of the campaign's ATE. In this paper, we analyze the network A/B
testing problem under a real-world online marketing campaign, describe our
proposed LinkLouvain method, and evaluate it on real-world data. Our method
achieves significant performance compared with others and is deployed in the
online marketing campaign.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:45:14 GMT""}]","2023-04-28"
"2102.01903","Thoshara Nawarathne","Thoshara Nawarathne, Thanushi Withanage, Samitha Gunarathne, Upekha
  Delay, Eranda Somathilake, Janith Senanayake, Roshan Godaliyadda, Parakrama
  Ekanayake, Janaka Wijayakulasooriya, and Chathura Rathnayake","Comprehensive Study on Denoising of Medical Images Utilizing Neural
  Network Based Auto-Encoder","7 pages, 16 figures, 2 tables",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Fetal motion discernment utilizing spectral images extracted from
accelerometric data incident on pregnant mothers abdomen has gained substantial
attention in the state-of-the-art research. It is an essential practice to
avoid adverse scenarios such as stillbirths and intrauterine growth
restrictions. However, this endeavor of ensuring fetus safety has been arduous
due to the existence of random noise in medical images. This novel research is
an in depth approach to analyze how the interference of different noise
variations affect the retrieval of information in those images. For that, an
algorithm employing auto-encoder-based deep learning was modeled and the
accuracy of reconstruction of the STFT images mitigating the noise has been
measured examining the loss. From the results, it is manifested that even a
substantial addition of the Super-Gaussian noises which have a higher
correlation of the frequencies possessed by the Fetal movement images can be
restored successfully with the slightest error.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:49:47 GMT""}]","2021-02-04"
"2102.01904","Alexey Ignatiev","Alexey Ignatiev, Edward Lam, Peter J. Stuckey, and Joao Marques-Silva","A Scalable Two Stage Approach to Computing Optimal Decision Sets",,,,,"cs.AI cs.LG cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning (ML) is ubiquitous in modern life. Since it is being
deployed in technologies that affect our privacy and safety, it is often
crucial to understand the reasoning behind its decisions, warranting the need
for explainable AI. Rule-based models, such as decision trees, decision lists,
and decision sets, are conventionally deemed to be the most interpretable.
Recent work uses propositional satisfiability (SAT) solving (and its
optimization variants) to generate minimum-size decision sets. Motivated by
limited practical scalability of these earlier methods, this paper proposes a
novel approach to learn minimum-size decision sets by enumerating individual
rules of the target decision set independently of each other, and then solving
a set cover problem to select a subset of rules. The approach makes use of
modern maximum satisfiability and integer linear programming technologies.
Experiments on a wide range of publicly available datasets demonstrate the
advantage of the new approach over the state of the art in SAT-based decision
set learning.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:51:49 GMT""}]","2021-02-04"
"2102.01905","Efstathios Charalampidis","Efstathios G. Charalampidis, Vera Mikyoung Hur","Numerical bifurcation and stability for the capillary-gravity Whitham
  equation","24 pages, 22 figures",,"10.1016/j.wavemoti.2021.102793",,"physics.flu-dyn math.DS nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We adopt a robust numerical continuation scheme to examine the global
bifurcation of periodic traveling waves of the capillary-gravity Whitham
equation, which combines the dispersion in the linear theory of
capillary-gravity waves and a shallow water nonlinearity. We employ a highly
accurate numerical method for space discretization and time stepping, to
address orbital stability and instability for a rich variety of the solutions.
Our findings can help classify capillary-gravity waves and understand their
long-term dynamics.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:52:54 GMT""}]","2021-08-27"
"2102.01906","Vinod Kumar Kurmi","Vinod K Kurmi, Badri N. Patro, Venkatesh K. Subramanian, Vinay P.
  Namboodiri","Do Not Forget to Attend to Uncertainty while Mitigating Catastrophic
  Forgetting","Accepted WACV 2021","WACV 2021",,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One of the major limitations of deep learning models is that they face
catastrophic forgetting in an incremental learning scenario. There have been
several approaches proposed to tackle the problem of incremental learning. Most
of these methods are based on knowledge distillation and do not adequately
utilize the information provided by older task models, such as uncertainty
estimation in predictions. The predictive uncertainty provides the
distributional information can be applied to mitigate catastrophic forgetting
in a deep learning framework. In the proposed work, we consider a Bayesian
formulation to obtain the data and model uncertainties. We also incorporate
self-attention framework to address the incremental learning problem. We define
distillation losses in terms of aleatoric uncertainty and self-attention. In
the proposed work, we investigate different ablation analyses on these losses.
Furthermore, we are able to obtain better results in terms of accuracy on
standard benchmarks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:54:52 GMT""}]","2021-02-04"
"2102.01907","Yong Wang","Yong Wang","Affine connections and Gauss-Bonnet theorems in the Heisenberg group","no. arXiv admin note: substantial text overlap with arXiv:1912.00302",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we compute sub-Riemannian limits of Gaussian curvature
associated to two kinds of Schouten-Van Kampen affine connections and the
adapted connection for a Euclidean $C^2$-smooth surface in the Heisenberg group
away from characteristic points and signed geodesic curvature associated to two
kinds of Schouten-Van Kampen affine connections and the adapted connection for
Euclidean $C^2$-smooth curves on surfaces. We get Gauss-Bonnet theorems
associated to two kinds of Schouten-Van Kampen affine connections in the
Heisenberg group.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:55:24 GMT""}]","2021-02-04"
"2102.01908","Yucheng Liu","Yucheng Liu, Lawrence Ong, Sarah Johnson, Joerg Kliewer, Parastoo
  Sadeghi, Phee Lep Yeoh","Information Leakage in Zero-Error Source Coding: A Graph-Theoretic
  Perspective","A shortened version has been submitted to ISIT 2021",,,,"cs.IT cs.CR math.IT","http://creativecommons.org/licenses/by/4.0/","  We study the information leakage to a guessing adversary in zero-error source
coding. The source coding problem is defined by a confusion graph capturing the
distinguishability between source symbols. The information leakage is measured
by the ratio of the adversary's successful guessing probability after and
before eavesdropping the codeword, maximized over all possible source
distributions. Such measurement under the basic adversarial model where the
adversary makes a single guess and allows no distortion between its estimator
and the true sequence is known as the maximum min-entropy leakage or the
maximal leakage in the literature. We develop a single-letter characterization
of the optimal normalized leakage under the basic adversarial model, together
with an optimum-achieving scalar stochastic mapping scheme. An interesting
observation is that the optimal normalized leakage is equal to the optimal
compression rate with fixed-length source codes, both of which can be
simultaneously achieved by some deterministic coding schemes. We then extend
the leakage measurement to generalized adversarial models where the adversary
makes multiple guesses and allows certain level of distortion, for which we
derive single-letter lower and upper bounds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:58:12 GMT""}]","2021-02-04"
"2102.01909","Inbal Yahav","Avihay Chriqui, Inbal Yahav","HeBERT & HebEMO: a Hebrew BERT Model and a Tool for Polarity Analysis
  and Emotion Recognition",,,"10.1287/ijds.2022.0016",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces HeBERT and HebEMO. HeBERT is a Transformer-based model
for modern Hebrew text, which relies on a BERT (Bidirectional Encoder
Representations for Transformers) architecture. BERT has been shown to
outperform alternative architectures in sentiment analysis, and is suggested to
be particularly appropriate for MRLs. Analyzing multiple BERT specifications,
we find that while model complexity correlates with high performance on
language tasks that aim to understand terms in a sentence, a more-parsimonious
model better captures the sentiment of entire sentence. Either way, out
BERT-based language model outperforms all existing Hebrew alternatives on all
common language tasks. HebEMO is a tool that uses HeBERT to detect polarity and
extract emotions from Hebrew UGC. HebEMO is trained on a unique
Covid-19-related UGC dataset that we collected and annotated for this study.
Data collection and annotation followed an active learning procedure that aimed
to maximize predictability. We show that HebEMO yields a high F1-score of 0.96
for polarity classification. Emotion detection reaches F1-scores of 0.78-0.97
for various target emotions, with the exception of surprise, which the model
failed to capture (F1 = 0.41). These results are better than the best-reported
performance, even among English-language models of emotion detection.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 06:59:59 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 07:43:43 GMT""},{""version"":""v3"",""created"":""Thu, 25 Feb 2021 07:04:34 GMT""}]","2022-06-28"
"2102.01910","Geoffrey W. Marcy","Geoffrey W. Marcy","A Search for Optical Laser Emission from Proxima Centauri",,,"10.1093/mnras/stab1440",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  A search for laser light from Proxima Centauri was performed, including 107
high-resolution, optical spectra obtained between 2004 and 2019. Among them, 57
spectra contain multiple, confined spectral combs, each consisting of 10
closely-spaced frequencies of light. The spectral combs, as entities, are
themselves equally spaced with a frequency separation of 5800 GHz, rendering
them unambiguously technological in origin. However, the combs do not originate
at Proxima Centauri. Otherwise, the 107 spectra of Proxima Centauri show no
evidence of technological signals, including 29 observations between March and
July 2019 when the candidate technological radio signal, BLC1, was captured by
Breakthrough Listen. This search would have revealed lasers pointed toward
Earth having a power of 20 to 120 kilowatts and located within the 1.3au field
of view centered on Proxima Centauri, assuming a benchmark laser launcher
having a 10-meter aperture.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:02:22 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 02:27:58 GMT""}]","2021-06-09"
"2102.01911","Shota Kikuchi","Shota Kikuchi","Sharper estimates of Ohsawa--Takegoshi $L^2$-extension theorem in higher
  dimensional case","16 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hosono obtained sharper estimates of the Ohsawa--Takegoshi $L^2$-extention
theorem by allowing the constant depending on the weight function for a domain
in $\mathbb{C}$. In this article, we show the higher dimensional case of
sharper estimates of the Ohsawa--Takegoshi $L^2$-extention theorem. To prove
the higher dimensional case of them, we establish an analogue of
Berndtsson--Lempert type $L^2$-extension theorem by using the pluricomplex
Green functions with poles along subvarieties. As a special case, we consider
the sharper estimates in terms of the Azukawa pseudometric and show that the
higher dimensional case of sharper estimate provides the $L^2$-minimum
extension for radial case.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:06:58 GMT""}]","2021-02-04"
"2102.01912","George Alexandropoulos","Qiang Li and Miaowen Wen and Shuai Wang and George C. Alexandropoulos
  and Yik-Chung Wu","Space Shift Keying with Reconfigurable Intelligent Surfaces: Phase
  Configuration Designs and Performance Analysis","10 pages, 6 figures, accepted to an IEEE journal",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Reconfigurable intelligent surface (RIS)-assisted transmission and space
shift keying (SSK) appear as promising candidates for future energy-efficient
wireless systems. In this paper, two RIS-based SSK schemes are proposed to
efficiently improve the error and throughput performance of conventional SSK
systems, respectively. The first one, termed RIS-SSK with passive beamforming
(RIS-SSK-PB), employs an RIS for beamforming and targets the maximization of
the minimum squared Euclidean distance between any two decision points. The
second one, termed RIS-SSK with Alamouti space-time block coding
(RIS-SSK-ASTBC), employs an RIS for ASTBC and enables the RIS to transmit its
own Alamouti-coded information while reflecting the incident SSK signals to the
destination. A low-complexity beamformer and an efficient maximum-likelihood
(ML) detector are designed for RIS-SSK-PB and RIS-SSK-ASTBC, respectively.
Approximate expressions for the average bit error probabilities of the source
and/or the RIS are derived in closed-form assuming ML detection. Extensive
computer simulations are conducted to verify the performance analysis. Results
show that RIS-SSK-PB significantly outperforms the existing RIS-free and
RIS-based SSK schemes, and RIS-SSK-ASTBC enables highly reliable transmission
with throughput improvement.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:13:26 GMT""}]","2021-02-04"
"2102.01913","Binghai Wen","Tingting Ji, Yongcai Pan, Yufu Shao, Bing He, Binghai Wen","Lateral Drop Rebound on Hydrophobic and Chemically Heterogeneous Surface","26 pages, 11 figures, 7200 words",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A drop rebounding from a hydrophobic and chemically heterogeneous surface is
investigated using the multiphase lattice Boltzmann method. The behaviors of
drop rebounding are dependent on the degrees of the hydrophobicity and
heterogeneity of the surface. When the surface is homogeneous, the drop
rebounds vertically and the height is getting higher and higher with increases
of the surface hydrophobicity. When the surface consists of two different
hydrophobic surfaces, the drop rebounds laterally towards the low hydrophobic
side. The asymmetrical rebounding is because the unbalanced Young's force
exerted on the contact line by the high hydrophobic side is greater than that
by the low hydrophobic surface. A set of contours of momentum distribution
illustrate the dynamic process of drop spreading, shrinking and rebounding.
This work promotes the understanding of the rebound mechanism of a drop
impacting the surface and also provides a guiding strategy for precisely
controlling the lateral behavior of rebounding drops by hydrophobic degrees and
heterogeneous surfaces.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:20:58 GMT""}]","2021-02-04"
"2102.01914","Srujan Teja Thomdapu","Srujan Teja Thomdapu and Ketan Rajawat","Optimizing QoS for Erasure-Coded Wireless Data Centers","This work is accepted for publication in proceedings of IEEE ICC 2021",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Cloud computing facilitates the access of applications and data from any
location by a distributed storage system. Erasure codes offer better data
replication technique with reduced storage costs for more reliability. This
paper considers the erasure-coded data center with multiple servers in a
wireless network where each is equipped with a base-station. The cause of
latency in the file retrieval process is mainly due to queuing delays at each
server. This work puts forth a stochastic optimization framework for obtaining
the optimal scheduling policy that maximizes users' quality of service (QoS)
while adhering to the latency requirements. We further show that the problem
has non-linear functions of expectations in objective and constraints and is
impossible to solve with traditional SGD like algorithms. We propose a new
algorithm that addresses compositional structure in the problem. Further, we
show that the proposed algorithm achieves a faster convergence rate than the
best-known results. Finally, we test the efficacy of the proposed method in a
simulated environment.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:31:41 GMT""}]","2021-02-04"
"2102.01915","Sreedhar B. Dutta","Shakul Awasthi and Sreedhar B. Dutta","Oscillating states of periodically driven anharmonic Langevin systems","11 pages, 2 figures","Phys. Rev. E 103, 062143 (2021)","10.1103/PhysRevE.103.062143",,"cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the asymptotic distributions of periodically driven anharmonic
Langevin systems. Utilizing the underlying $SL_2$ symmetry of the Langevin
dynamics, we develop a perturbative scheme in which the effect of periodic
driving can be treated nonperturbatively to any order of perturbation in
anharmonicity. We spell out the conditions under which the asymptotic
distributions exist and are periodic, and show that the distributions can be
determined exactly in terms of the solutions of the associated Hill equations.
We further find that the oscillating states of these driven systems are stable
against anharmonic perturbations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:32:03 GMT""}]","2021-06-30"
"2102.01916","Yibing Liu","Yibing Liu, Yangyang Guo, Jianhua Yin, Xuemeng Song, Weifeng Liu,
  Liqiang Nie","Answer Questions with Right Image Regions: A Visual Attention
  Regularization Approach","ACM TOMM 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Visual attention in Visual Question Answering (VQA) targets at locating the
right image regions regarding the answer prediction, offering a powerful
technique to promote multi-modal understanding. However, recent studies have
pointed out that the highlighted image regions from the visual attention are
often irrelevant to the given question and answer, leading to model confusion
for correct visual reasoning. To tackle this problem, existing methods mostly
resort to aligning the visual attention weights with human attentions.
Nevertheless, gathering such human data is laborious and expensive, making it
burdensome to adapt well-developed models across datasets. To address this
issue, in this paper, we devise a novel visual attention regularization
approach, namely AttReg, for better visual grounding in VQA. Specifically,
AttReg firstly identifies the image regions which are essential for question
answering yet unexpectedly ignored (i.e., assigned with low attention weights)
by the backbone model. And then a mask-guided learning scheme is leveraged to
regularize the visual attention to focus more on these ignored key regions. The
proposed method is very flexible and model-agnostic, which can be integrated
into most visual attention-based VQA models and require no human attention
supervision. Extensive experiments over three benchmark datasets, i.e., VQA-CP
v2, VQA-CP v1, and VQA v2, have been conducted to evaluate the effectiveness of
AttReg. As a by-product, when incorporating AttReg into the strong baseline
LMH, our approach can achieve a new state-of-the-art accuracy of 60.00% with an
absolute performance gain of 7.01% on the VQA-CP v2 benchmark dataset...
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:33:30 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 08:28:36 GMT""}]","2021-11-09"
"2102.01917","Panki Kim","Soobin Cho, Panki Kim, Jaehun Lee","General Law of iterated logarithm for Markov processes: Limsup law","49 pages, 3 figures, Liminf LIL is taken out. The part on Random
  conductance models with long range jumps is expanded",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we discuss general criteria of limsup law of iterated
logarithm (LIL) for continuous-time Markov processes. We consider minimal
assumptions for LILs to hold at zero (at infinity, respectively) in general
metric measure spaces. We establish LILs under local assumptions near zero
(near infinity, respectively) on uniform bounds of the expectations of first
exit times from balls in terms of a function $\phi$ and uniform bounds on the
tails of the jumping measure in terms of a function $\psi$. One of the main
results is that a simple ratio test in terms of the functions $\phi$ and $\psi$
completely determines whether there exists a positive nondecreasing function
$\Psi$ such that $\limsup |X_t|/\Psi(t)$ is positive and finite a.s., or not.
Our results cover a large class of subordinate diffusions, jump processes with
mixed polynomial local growths, jump processes with singular jumping kernels
and random conductance models with long range jumps.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:37:21 GMT""},{""version"":""v2"",""created"":""Thu, 7 Apr 2022 11:08:15 GMT""}]","2022-04-08"
"2102.01918","Akhil Anil Rajput","Akhil Anil Rajput, Qingchun Li, Xinyu Gao and Ali Mostafavi","Revealing Critical Characteristics of Mobility Patterns in New York City
  during the Onset of COVID-19 Pandemic","18 pages, 8 figures",,,,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New York has become one of the worst-affected COVID-19 hotspots and a
pandemic epicenter due to the ongoing crisis. This paper identifies the impact
of the pandemic and the effectiveness of government policies on human mobility
by analyzing multiple datasets available at both macro and micro levels for the
New York City. Using data sources related to population density, aggregated
population mobility, public rail transit use, vehicle use, hotspot and
non-hotspot movement patterns, and human activity agglomeration, we analyzed
the inter-borough and intra-borough moment for New York City by aggregating the
data at the borough level. We also assessed the internodal population movement
amongst hotspot and non-hotspot points of interest for the month of March and
April 2020. Results indicate a drop of about 80% in people's mobility in the
city, beginning in mid-March. The movement to and from Manhattan showed the
most disruption for both public transit and road traffic. The city saw its
first case on March 1, 2020, but disruptions in mobility can be seen only after
the second week of March when the shelter in place orders was put in effect.
Owing to people working from home and adhering to stay-at-home orders,
Manhattan saw the largest disruption to both inter- and intra-borough movement.
But the risk of spread of infection in Manhattan turned out to be high because
of higher hotspot-linked movements. The stay-at-home restrictions also led to
an increased population density in Brooklyn and Queens as people were not
commuting to Manhattan. Insights obtained from this study would help
policymakers better understand human behavior and their response to the news
and governmental policies.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:38:09 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 07:54:44 GMT""}]","2021-02-05"
"2102.01919","Thorsten Aull","T. Aull, E. \c{S}a\c{s}{\i}o\u{g}lu, and I. Mertig","First principles design of Ohmic spin diodes based on quaternary Heusler
  compounds","7 pages, 5 figures","Appl. Phys. Lett. 118, 052405 (2021)","10.1063/5.0037085",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ohmic spin diode (OSD) is a recent concept in spintronics, which is based
on half-metallic magnets (HMMs) and spin-gapless semiconductors (SGSs).
Quaternary Heusler compounds offer a unique platform to realize the OSD for
room temperature applications as these materials possess very high Curie
temperatures as well as half-metallic and spin-gapless semiconducting behavior
within the same family. Using state-of-the-art first-principles calculations
combined with the non-equilibrium Green's function method we design four
different OSDs based on half-metallic and spin-gapless semiconducting
quaternary Heusler compounds. All four OSDs exhibit linear current-voltage
($I-V$) characteristics with zero threshold voltage $V_T$. We show that these
OSDs possess a small leakage current, which stems from the overlap of the
conduction and valence band edges of opposite spin channels around the Fermi
level in the SGS electrodes. The obtained on/off current ratios vary between
$30$ and $10^5$. Our results can pave the way for the experimental fabrication
of the OSDs within the family of ordered quaternary Heusler compounds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:38:39 GMT""}]","2021-02-04"
"2102.01920","Nicoletta Tardini","Anna Fino, Nicoletta Tardini, Luigi Vezzoni","Pluriclosed and Strominger K\""ahler-like metrics compatible with abelian
  complex structures",,,,,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the existence of a left-invariant pluriclosed Hermitian metric
on a unimodular Lie group with a left-invariant abelian complex structure
forces the group to be $2$-step nilpotent. Moreover, we prove that the
pluriclosed flow starting from a left-invariant Hermitian metric on a $2$-step
nilpotent Lie group preserves the Strominger K\""ahler-like condition.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:42:28 GMT""}]","2021-02-04"
"2102.01921","Wolfgang Fuhl","Wolfgang Fuhl","1000 Pupil Segmentations in a Second using Haar Like Features and
  Statistical Learning",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a new approach for pupil segmentation. It can be
computed and trained very efficiently, making it ideal for online use for high
speed eye trackers as well as for energy saving pupil detection in mobile eye
tracking. The approach is inspired by the BORE and CBF algorithms and
generalizes the binary comparison by Haar features. Since these features are
intrinsically very susceptible to noise and fluctuating light conditions, we
combine them with conditional pupil shape probabilities. In addition, we also
rank each feature according to its importance in determining the pupil shape.
Another advantage of our method is the use of statistical learning, which is
very efficient and can even be used online.
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FStatsPupil&mode=list
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:45:04 GMT""}]","2021-02-04"
"2102.01922","Jun Fang","Jun Fang","Session-based Recommendation with Self-Attention Networks","12 pages,5 figures",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Session-based recommendation aims to predict user's next behavior from
current session and previous anonymous sessions. Capturing long-range
dependencies between items is a vital challenge in session-based
recommendation. A novel approach is proposed for session-based recommendation
with self-attention networks (SR-SAN) as a remedy. The self-attention networks
(SAN) allow SR-SAN capture the global dependencies among all items of a session
regardless of their distance. In SR-SAN, a single item latent vector is used to
capture both current interest and global interest instead of session embedding
which is composed of current interest embedding and global interest embedding.
Some experiments have been performed on some open benchmark datasets.
Experimental results show that the proposed method outperforms some
state-of-the-arts by comparisons.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:50:34 GMT""}]","2021-02-04"
"2102.01923","Giulio Giuseppe Giusteri","Giulio G. Giusteri and Ryohei Seto","Shear jamming and fragility of suspensions in a continuum model with
  elastic constraints","Updated figures and included Supplemental material","Phys. Rev. Lett. 127, 138001 (2021)","10.1103/PhysRevLett.127.138001",,"cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under an applied traction, highly concentrated suspensions of solid particles
in fluids can turn from a state in which they flow to a state in which they
counteract the traction as an elastic solid: a shear-jammed state. Remarkably,
the suspension can turn back to the flowing state simply by inverting the
traction. A tensorial model is presented and tested in paradigmatic cases. We
show that, to reproduce the phenomenology of shear jamming in generic
geometries, it is necessary to link this effect to the elastic response
supported by the suspension microstructure rather than to a divergence of the
viscosity.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:54:33 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 06:02:42 GMT""}]","2021-09-29"
"2102.01924","Fangzhou Ren","Fangzhou Ren, Richard de Grijs, Huawei Zhang, Licai Deng, Xiaodian
  Chen, Noriyuki Matsunaga, Chao Liu, Weijia Sun, Hiroyuki Maehara, Nobuharu
  Ukita, Naoto Kobayashi","Eclipsing Binary Populations across the Northern Galactic Plane from the
  KISOGP survey","17 pages, 9 figures, 2 tables. Accepted for publication in AJ",,"10.3847/1538-3881/abe30e",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a catalog of eclipsing binaries in the northern Galactic Plane
from the Kiso Wide-Field Camera Intensive Survey of the Galactic Plane
(KISOGP). We visually identified 7055 eclipsing binaries spread across
$\sim$330 square degrees, including 4197 W Ursa Majoris/EW-, 1458 $\beta$
Lyrae/EB-, and 1400 Algol/EA-type eclipsing binaries. For all systems, $I$-band
light curves were used to obtain accurate system parameters. We derived the
distances and extinction values for the EW-type objects from their
period--luminosity relation. We also obtained the structure of the thin disk
from the distribution of our sample of eclipsing binary systems, combined with
those of high-mass star-forming regions and Cepheid tracers. We found that the
thin disk is inhomogeneous in number density as a function of Galactic
longitude. Using this new set of distance tracers, we constrain the detailed
structure of the thin disk. Finally, we report a global parallax zero-point
offset of $ \Delta \pi=-42.1\pm1.9\mbox{(stat.)}\pm12.9\mbox{(syst.)}$ $\mu$as
between our carefully calibrated EW-type eclipsing binary positions and those
provided by Gaia Early Data Release 3. Implementation of the officially
recommended parallax zero-point correction results in a significantly reduced
offset. Additionally, we provide a photometric characterization of our EW-type
eclipsing binaries that can be applied to further analyses.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:54:59 GMT""}]","2021-03-17"
"2102.01925","Ke Sun","I\~naki Esnaola, Samir M. Perlaza, and Ke Sun","Data-Injection Attacks","arXiv admin note: substantial text overlap with arXiv:1808.04184","Chapter 9 of: Advanced Data Analytics for Power Systems, A. Tajer,
  S. M. Perlaza and H. V. Poor, Eds., Cambridge University Press, Cambridge,
  UK, 2021, pp. 197-229",,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this chapter we review some of the basic attack constructions that exploit
a stochastic description of the state variables. We pose the state estimation
problem in a Bayesian setting and cast the bad data detection procedure as a
Bayesian hypothesis testing problem. This revised detection framework provides
the benchmark for the attack detection problem that limits the achievable
attack disruption. Indeed, the trade-off between the impact of the attack, in
terms of disruption to the state estimator, and the probability of attack
detection is analytically characterized within this Bayesian attack setting. We
then generalize the attack construction by considering information-theoretic
measures that place fundamental limits to a broad class of detection,
estimation, and learning techniques. Because the attack constructions proposed
in this chapter rely on the attacker having access to the statistical structure
of the random process describing the state variables, we conclude by studying
the impact of imperfect statistics on the attack performance. Specifically, we
study the attack performance as a function of the size of the training data set
that is available to the attacker to estimate the second-order statistics of
the state variables.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:56:22 GMT""}]","2021-02-04"
"2102.01926","Topi Kuutela","J. Dard\'e, N. Hyv\""onen, T. Kuutela, T. Valkonen","Electrodeless electrode model for electrical impedance tomography","23 pages, 2 figures",,"10.1137/21M1396125",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrical impedance tomography is an imaging modality for extracting
information on the interior structure of a physical body from boundary
measurements of current and voltage. This work studies a new robust way of
modeling the contact electrodes used for driving current patterns into the
examined object and measuring the resulting voltages. The idea is to not define
the electrodes as strict geometric objects on the measurement boundary, but
only to assume approximate knowledge about their whereabouts and let a boundary
admittivity function determine the actual locations of the current inputs. Such
an approach enables reconstructing the boundary admittivity, i.e. the locations
and strengths of the contacts, at the same time and with analogous methods as
the interior admittivity. The functionality of the new model is verified by
two-dimensional numerical experiments based on water tank data.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:57:42 GMT""}]","2022-07-06"
"2102.01927","Keisuke Imoto","Keisuke Imoto, Sakiko Mishima, Yumi Arai, Reishi Kondo","Impact of Sound Duration and Inactive Frames on Sound Event Detection
  Performance","Accepted to ICASSP 2021. arXiv admin note: text overlap with
  arXiv:2006.15253",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many methods of sound event detection (SED), a segmented time frame is
regarded as one data sample to model training. The durations of sound events
greatly depend on the sound event class, e.g., the sound event ""fan"" has a long
duration, whereas the sound event ""mouse clicking"" is instantaneous. Thus, the
difference in the duration between sound event classes results in a serious
data imbalance in SED. Moreover, most sound events tend to occur occasionally;
therefore, there are many more inactive time frames of sound events than active
frames. This also causes a severe data imbalance between active and inactive
frames. In this paper, we investigate the impact of sound duration and inactive
frames on SED performance by introducing four loss functions, such as simple
reweighting loss, inverse frequency loss, asymmetric focal loss, and focal
batch Tversky loss. Then, we provide insights into how we tackle this imbalance
problem.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:00:43 GMT""}]","2021-02-04"
"2102.01928","Heejong Park","Heejong Park, Arvind Easwaran, Etienne Borde","Online Cycle Detection for Models with Mode-Dependent Input and Output
  Dependencies","\c{opyright} 2021. This manuscript version is made available under
  the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/","Journal of Systems Architecture (2021)","10.1016/j.sysarc.2021.102017",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the fields of co-simulation and component-based modelling, designers
import models as building blocks to create a composite model that provides more
complex functionalities. Modelling tools perform instantaneous cycle detection
(ICD) on the composite models having feedback loops to reject the models if the
loops are mathematically unsound and to improve simulation performance. In this
case, the analysis relies heavily on the availability of dependency information
from the imported models. However, the cycle detection problem becomes harder
when the model's input to output dependencies are mode-dependent, i.e. changes
for certain events generated internally or externally as inputs. The number of
possible modes created by composing such models increases significantly and
unknown factors such as environmental inputs make the offline (statical) ICD a
difficult task. In this paper, an online ICD method is introduced to address
this issue for the models used in cyber-physical systems. The method utilises
an oracle as a central source of information that can answer whether the
individual models can make mode transition without creating instantaneous
cycles. The oracle utilises three types of data-structures created offline that
are adaptively chosen during online (runtime) depending on the frequency as
well as the number of models that make mode transitions. During the analysis,
the models used online are stalled from running, resulting in the discrepancy
with the physical system. The objective is to detect an absence of the
instantaneous cycle while minimising the stall time of the model simulation
that is induced from the analysis. The benchmark results show that our method
is an adequate alternative to the offline analysis methods and significantly
reduces the analysis time.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:02:01 GMT""}]","2021-02-04"
"2102.01929","Dogyoon Lee","Dogyoon Lee, Jaeha Lee, Junhyeop Lee, Hyeongmin Lee, Minhyeok Lee,
  Sungmin Woo, and Sangyoun Lee","Regularization Strategy for Point Cloud via Rigidly Mixed Sample","CVPR2021 Accepted, 10 pages, 5 figures, 7 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data augmentation is an effective regularization strategy to alleviate the
overfitting, which is an inherent drawback of the deep neural networks.
However, data augmentation is rarely considered for point cloud processing
despite many studies proposing various augmentation methods for image data.
Actually, regularization is essential for point clouds since lack of generality
is more likely to occur in point cloud due to small datasets. This paper
proposes a Rigid Subset Mix (RSMix), a novel data augmentation method for point
clouds that generates a virtual mixed sample by replacing part of the sample
with shape-preserved subsets from another sample. RSMix preserves structural
information of the point cloud sample by extracting subsets from each sample
without deformation using a neighboring function. The neighboring function was
carefully designed considering unique properties of point cloud, unordered
structure and non-grid. Experiments verified that RSMix successfully
regularized the deep neural networks with remarkable improvement for shape
classification. We also analyzed various combinations of data augmentations
including RSMix with single and multi-view evaluations, based on abundant
ablation studies.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:03:59 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 07:22:35 GMT""},{""version"":""v3"",""created"":""Wed, 10 Mar 2021 08:47:21 GMT""}]","2021-03-11"
"2102.01930","Chong Luo","Yucheng Zhao, Dacheng Yin, Chong Luo, Zhiyuan Zhao, Chuanxin Tang,
  Wenjun Zeng, Zheng-Jun Zha","General-Purpose Speech Representation Learning through a Self-Supervised
  Multi-Granularity Framework",,,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a self-supervised learning framework, named MGF, for
general-purpose speech representation learning. In the design of MGF, speech
hierarchy is taken into consideration. Specifically, we propose to use
generative learning approaches to capture fine-grained information at small
time scales and use discriminative learning approaches to distill
coarse-grained or semantic information at large time scales. For phoneme-scale
learning, we borrow idea from the masked language model but tailor it for the
continuous speech signal by replacing classification loss with a contrastive
loss. We corroborate our design by evaluating MGF representation on various
downstream tasks, including phoneme classification, speaker classification,
speech recognition, and emotion classification. Experiments verify that
training at different time scales needs different training targets and loss
functions, which in general complement each other and lead to a better
performance.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:13:21 GMT""}]","2021-02-04"
"2102.01931","Helin Wang","Helin Wang, Yuexian Zou and Wenwu Wang","A Global-local Attention Framework for Weakly Labelled Audio Tagging","Accepted to ICASSP2021",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by/4.0/","  Weakly labelled audio tagging aims to predict the classes of sound events
within an audio clip, where the onset and offset times of the sound events are
not provided. Previous works have used the multiple instance learning (MIL)
framework, and exploited the information of the whole audio clip by MIL pooling
functions. However, the detailed information of sound events such as their
durations may not be considered under this framework. To address this issue, we
propose a novel two-stream framework for audio tagging by exploiting the global
and local information of sound events. The global stream aims to analyze the
whole audio clip in order to capture the local clips that need to be attended
using a class-wise selection module. These clips are then fed to the local
stream to exploit the detailed information for a better decision. Experimental
results on the AudioSet show that our proposed method can significantly improve
the performance of audio tagging under different baseline network
architectures.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:13:47 GMT""}]","2021-02-04"
"2102.01932","Seunghyuk Cho","Seunghyuk Cho, Minsoo Koo, Dongwoo Kim, Juyong Lee, Yeonwoo Jung,
  Kibyung Nam, Changmo Hwang","Roughly Collected Dataset for Contact Force Sensing Catheter","7 pages, 6 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With rise of interventional cardiology, Catheter Ablation Therapy (CAT) has
established itself as a first-line solution to treat cardiac arrhythmia.
Although CAT is a promising technique, cardiologist lacks vision inside the
body during the procedure, which may cause serious clinical syndromes. To
support accurate clinical procedure, Contact Force Sensing (CFS) system is
developed to find a position of the catheter tip through the measure of contact
force between catheter and heart tissue. However, the practical usability of
commercialized CFS systems is not fully understood due to inaccuracy in the
measurement. To support the development of more accurate system, we develop a
full pipeline of CFS system with newly collected benchmark dataset through a
contact force sensing catheter in simplest hardware form. Our dataset was
roughly collected with human noise to increase data diversity. Through the
analysis of the dataset, we identify a problem defined as Shift of Reference
(SoR), which prevents accurate measurement of contact force. To overcome the
problem, we conduct the contact force estimation via standard deep neural
networks including for Recurrent Neural Network (RNN), Fully Convolutional
Network (FCN) and Transformer. An average error in measurement for RNN, FCN and
Transformer are, respectively, 2.46g, 3.03g and 3.01g. Through these studies,
we try to lay a groundwork, serve a performance criteria for future CFS system
research and open a publicly available dataset to public.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:27:22 GMT""}]","2021-02-04"
"2102.01933","Deepak Deepak","Deepak Mahla and Shivi Agarwal","A Credibility Approach on Fuzzy Slacks Based Measure (SBM) DEA Model",,,"10.22111/ijfs.2020.31572.5443",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data Envelopment Analysis (DEA) is a multi-criteria technique based on linear
programming to deal with many real-life problems, mostly in nonprofit
organizations. The slacks-based measure (SBM) model is one of the DEA model
used to assess the relative efficiencies of decision-making units (DMUs). The
SBM DEA model directly used input slacks and output slacks to determine the
relative efficiency of DMUs. In order to deal with qualitative or uncertain
data, a fuzzy SBM DEA model is used to assess the performance of DMUs in this
study. The credibility measure approach, transform the fuzzy SBM DEA model into
a crisp linear programming model at different credibility levels is used. The
results came from the fuzzy DEA model are more rational to the real-world
situation than the conventional DEA model. In the end, the data of Indian oil
refineries is collected, and the efficiency behavior of the companies obtained
by applying the proposed model for its numerical illustration.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:28:59 GMT""}]","2021-02-04"
"2102.01934","Loc Hoang Tran","Nguyen Trinh Vu Dang, Loc Tran, Linh Tran","Noise-robust classification with hypergraph neural network",,,,,"stat.ML cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  This paper presents a novel version of the hypergraph neural network method.
This method is utilized to solve the noisy label learning problem. First, we
apply the PCA dimensional reduction technique to the feature matrices of the
image datasets in order to reduce the ""noise"" and the redundant features in the
feature matrices of the image datasets and to reduce the runtime constructing
the hypergraph of the hypergraph neural network method. Then, the classic
graph-based semi-supervised learning method, the classic hypergraph based
semi-supervised learning method, the graph neural network, the hypergraph
neural network, and our proposed hypergraph neural network are employed to
solve the noisy label learning problem. The accuracies of these five methods
are evaluated and compared. Experimental results show that the hypergraph
neural network methods achieve the best performance when the noise level
increases. Moreover, the hypergraph neural network methods are at least as good
as the graph neural network.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:34:53 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 03:45:24 GMT""},{""version"":""v3"",""created"":""Sat, 3 Sep 2022 10:08:39 GMT""}]","2022-09-07"
"2102.01935","Wen Wei Loh","Wen Wei Loh, Stijn Vansteelandt","Sensitivity Analysis for Unmeasured Confounding via Effect Extrapolation",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Inferring the causal effect of a non-randomly assigned exposure on an outcome
requires adjusting for common causes of the exposure and outcome to avoid
biased conclusions. Notwithstanding the efforts investigators routinely make to
measure and adjust for such common causes (or confounders), some confounders
typically remain unmeasured, raising the prospect of biased inference in
observational studies. Therefore, it is crucial that investigators can
practically assess their substantive conclusions' relative (in)sensitivity to
potential unmeasured confounding. In this article, we propose a sensitivity
analysis strategy that is informed by the stability of the exposure effect over
different, well-chosen subsets of the measured confounders. The proposal
entails first approximating the process for recording confounders to learn
about how the effect is potentially affected by varying amounts of unmeasured
confounding, then extrapolating to the effect had hypothetical unmeasured
confounders been additionally adjusted for. A large set of measured confounders
can thus be exploited to provide insight into the likely presence of unmeasured
confounding bias, albeit under an assumption about how data on the confounders
are recorded. The proposal's ability to reveal the true effect and ensure valid
inference after extrapolation is empirically compared with existing methods
using simulation studies. We demonstrate the procedure using two different
publicly available datasets commonly used for causal inference.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:35:46 GMT""}]","2021-02-04"
"2102.01936","Liangxi Liu","Liangxi Liu, Feng Zheng, Hong Chen, Guo-Jun Qi, Heng Huang and Ling
  Shao","A Bayesian Federated Learning Framework with Online Laplace
  Approximation",,,,,"cs.LG cs.AI cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Federated learning (FL) allows multiple clients to collaboratively learn a
globally shared model through cycles of model aggregation and local model
training, without the need to share data. Most existing FL methods train local
models separately on different clients, and then simply average their
parameters to obtain a centralized model on the server side. However, these
approaches generally suffer from large aggregation errors and severe local
forgetting, which are particularly bad in heterogeneous data settings. To
tackle these issues, in this paper, we propose a novel FL framework that uses
online Laplace approximation to approximate posteriors on both the client and
server side. On the server side, a multivariate Gaussian product mechanism is
employed to construct and maximize a global posterior, largely reducing the
aggregation errors induced by large discrepancies between local models. On the
client side, a prior loss that uses the global posterior probabilistic
parameters delivered from the server is designed to guide the local training.
Binding such learning constraints from other clients enables our method to
mitigate local forgetting. Finally, we achieve state-of-the-art results on
several benchmarks, clearly demonstrating the advantages of the proposed
method.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:36:58 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 16:44:04 GMT""}]","2021-07-21"
"2102.01937","Haimiao Chen","Haimiao Chen","The ${\rm SL}(2,\mathbb{C})$-character variety of a Montesinos knot","18 pages, 5 figures; final version","Studia Scientiarum Mathematicarum Hungarica 59 (2022), no.1","10.1556/012.2022.01519",,"math.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  For each Montesinos knot $K$, we propose an efficient method to explicitly
determine the irreducible ${\rm SL}(2,\mathbb{C})$-character variety, and show
that it can be decomposed as
$\mathcal{X}_0(K)\sqcup\mathcal{X}_1(K)\sqcup\mathcal{X}_2(K)\sqcup\mathcal{X}'(K)$,
where $\mathcal{X}_0(K)$ consists of trace-free characters, $\mathcal{X}_1(K)$
consists of characters of ""unions"" of representations of rational knots (or
rational link, which appears at most once), $\mathcal{X}_2(K)$ is an algebraic
curve, and $\mathcal{X}'(K)$ consists of finitely many points when $K$
satisfies a generic condition.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:37:49 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 17:00:31 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 09:01:47 GMT""},{""version"":""v4"",""created"":""Wed, 20 Apr 2022 12:13:47 GMT""}]","2022-04-21"
"2102.01938","Prafulla Chandra Mr","Prafulla Chandra, Andrew Thangaraj and Nived Rajaraman","How good is Good-Turing for Markov samples?",,,,,"cs.IT math.IT math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Good-Turing (GT) estimator for the missing mass (i.e., total probability
of missing symbols) in $n$ samples is the number of symbols that appeared
exactly once divided by $n$. For i.i.d. samples, the bias and squared-error
risk of the GT estimator can be shown to fall as $1/n$ by bounding the expected
error uniformly over all symbols. In this work, we study convergence of the GT
estimator for missing stationary mass (i.e., total stationary probability of
missing symbols) of Markov samples on an alphabet $\mathcal{X}$ with stationary
distribution $[\pi_x:x \in \mathcal{X}]$ and transition probability matrix
(t.p.m.) $P$. This is an important and interesting problem because GT is widely
used in applications with temporal dependencies such as language models
assigning probabilities to word sequences, which are modelled as Markov. We
show that convergence of GT depends on convergence of $(P^{\sim x})^n$, where
$P^{\sim x}$ is $P$ with the $x$-th column zeroed out. This, in turn, depends
on the Perron eigenvalue $\lambda^{\sim x}$ of $P^{\sim x}$ and its
relationship with $\pi_x$ uniformly over $x$. For randomly generated t.p.ms and
t.p.ms derived from New York Times and Charles Dickens corpora, we numerically
exhibit such uniform-over-$x$ relationships between $\lambda^{\sim x}$ and
$\pi_x$. This supports the observed success of GT in language models and
practical text data scenarios. For Markov chains with rank-2, diagonalizable
t.p.ms having spectral gap $\beta$, we show minimax rate upper and lower bounds
of $1/(n\beta^5)$ and $1/(n\beta)$, respectively, for the estimation of
stationary missing mass. This theoretical result extends the $1/n$ minimax rate
for i.i.d. or rank-1 t.p.ms to rank-2 Markov, and is a first such minimax rate
result for missing mass of Markov samples.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:38:21 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 09:22:02 GMT""},{""version"":""v3"",""created"":""Sat, 27 May 2023 16:05:07 GMT""}]","2023-05-30"
"2102.01939","Diego Uribe Mr.","D. Uribe, M. Delbo, P.-O. Bouchard, D. Pino Mu\~noz","Diurnal temperature variation as the source of the preferential
  direction of fractures on asteroids: theoretical model for the case of Bennu","To be published in Icarus-Journal",,,,"astro-ph.EP physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown that temperature cycles on airless bodies of our Solar
System can cause damaging of surface materials. Nevertheless, propagation
mechanisms in the case of space objects are still poorly understood. Present
work combines a thermoelasticity model together with linear elastic fracture
mechanics theory to predict fracture propagation in the presence of thermal
gradients generated by diurnal temperature cycling and under conditions similar
to those existing on the asteroid Bennu. The crack direction is computed using
the maximal strain energy release rate criterion, which is implemented using
finite elements and the so-called G$\theta$ method (Uribe-Su\'arez et al. 2020.
Eng. Fracture Mech. 227:106918). Using the implemented methodology, crack
propagation direction for an initial crack tip in different positions and for
different orientations is computed. It is found that cracks preferentially
propagate in the North to South (N-S), in the North-East to South-West (NE-SW)
and in the North-West to South-East (NW-SE) directions. Finally, thermal
fatigue analysis was performed in order to estimate the crack growth rate.
Computed value is in good agreement with available experimental evidence.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:39:26 GMT""}]","2021-02-04"
"2102.01940","Xiaogang Jia","Xiaogang Jia, Wei Chen, Zhengfa Liang, Mingfei Wu, Yusong Tan, Libo
  Huang","Multi-Scale Cost Volumes Cascade Network for Stereo Matching",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Stereo matching is essential for robot navigation. However, the accuracy of
current widely used traditional methods is low, while methods based on CNN need
expensive computational cost and running time. This is because different cost
volumes play a crucial role in balancing speed and accuracy. Thus we propose
MSCVNet, which combines traditional methods and neural networks to improve the
quality of cost volume. Concretely, our network first generates multiple 3D
cost volumes with different resolutions and then uses 2D convolutions to
construct a novel cascade hourglass network for cost aggregation. Meanwhile, we
design an algorithm to distinguish and calculate the loss for discontinuous
areas of disparity result. According to the KITTI official website, our network
is much faster than most top-performing methods (24 times than CSPN, 44 times
than GANet, etc.). Meanwhile, compared to traditional methods (SPS-St, SGM) and
other real-time stereo matching networks (Fast DS-CS, DispNetC, and RTSNet,
etc.), our network achieves a big improvement in accuracy, demonstrating the
feasibility and capability of the proposed method.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:40:17 GMT""},{""version"":""v2"",""created"":""Sat, 13 Mar 2021 05:18:44 GMT""}]","2021-03-16"
"2102.01941","Mikhail Braun","M.A.Braun","On the Markov evolution of the $\rho$-matrix of a subsystem","17 pages, 10 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Evolution of the reduced density matrix for a subsystem is studied to
determine deviations from its Markov character for a system consisting of a
closed chain of $N$ oscillators with one of them serving as a subsystem. The
dependence on $N$ and on the coupling of the two subsystems is investigated
numerically. The found deviations strongly depend on $N$ and the coupling. In
the most beneficial case with $N-1=100$ and the coupling randomized in its
structure the deviations fall with the evolution time up 3\%. In other cases
they remain to be of the order 30\% or even more.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:40:47 GMT""}]","2021-02-04"
"2102.01942","Brendan McKay","Brendan D. McKay","Reconstruction of small graphs and digraphs","Previously called ""Reconstruction of small graphs and tournaments"".
  Fixed summary error on page 7 for 5 vertices",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe computer searches that prove the graph reconstruction conjecture
for graphs with up to 13 vertices and some limited classes on larger sizes. We
also investigate the reconstructibility of tournaments up to 13 vertices,
digraphs up to 9 vertices, and posets up to 13 points. In all cases, our
results also apply to the set reconstruction problem that uses the
isomorph-reduced deck.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:41:15 GMT""},{""version"":""v2"",""created"":""Sun, 3 Oct 2021 11:44:22 GMT""},{""version"":""v3"",""created"":""Sat, 23 Oct 2021 06:29:45 GMT""},{""version"":""v4"",""created"":""Sun, 2 Jan 2022 11:03:58 GMT""}]","2022-01-04"
"2102.01943","Efstathios Paparoditis","Marco Meyer and Efstathios Paparoditis","A Frequency Domain Bootstrap for General Multivariate Stationary
  Processes","43 pages",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  For many relevant statistics of multivariate time series, no valid frequency
domain bootstrap procedures exist. This is mainly due to the fact that the
distribution of such statistics depends on the fourth-order moment structure of
the underlying process in nearly every scenario, except for some special cases
like Gaussian time series. In contrast to the univariate case, even additional
structural assumptions such as linearity of the multivariate process or a
standardization of the statistic of interest do not solve the problem. This
paper focuses on integrated periodogram statistics as well as functions thereof
and presents a new frequency domain bootstrap procedure for multivariate time
series, the multivariate frequency domain hybrid bootstrap (MFHB), to fill this
gap. Asymptotic validity of the MFHB procedure is established for general
classes of periodogram-based statistics and for stationary multivariate
processes satisfying rather weak dependence conditions. A simulation study is
carried out which compares the finite sample performance of the MFHB with that
of the moving block bootstrap.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:43:35 GMT""}]","2021-02-04"
"2102.01944","Zainab Abaid","Zainab Abaid and Dilip Sarkar and Mohamed Ali Kaafar and Sanjay Jha","All Infections are Not Created Equal: Time-Sensitive Prediction of
  Malware Generated Network Attacks","14 pages, 7 figures",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Many techniques have been proposed for quickly detecting and containing
malware-generated network attacks such as large-scale denial of service
attacks; unfortunately, much damage is already done within the first few
minutes of an attack, before it is identified and contained. There is a need
for an early warning system that can predict attacks before they actually
manifest, so that upcoming attacks can be prevented altogether by blocking the
hosts that are likely to engage in attacks. However, blocking responses may
disrupt legitimate processes on blocked hosts; in order to minimise user
inconvenience, it is important to also foretell the time when the predicted
attacks will occur, so that only the most urgent threats result in
auto-blocking responses, while less urgent ones are first manually
investigated. To this end, we identify a typical infection sequence followed by
modern malware; modelling this sequence as a Markov chain and training it on
real malicious traffic, we are able to identify behaviour most likely to lead
to attacks and predict 98\% of real-world spamming and port-scanning attacks
before they occur. Moreover, using a Semi-Markov chain model, we are able to
foretell the time of upcoming attacks, a novel capability that allows
accurately predicting the times of 97% of real-world malware attacks. Our work
represents an important and timely step towards enabling flexible threat
response models that minimise disruption to legitimate users.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:45:34 GMT""}]","2021-02-04"
"2102.01945","Markus Reiher","Stephanie A. Grimmel and Markus Reiher","On the Predictive Power of Chemical Concepts","23 pages, 2 figures, 1 table","CHIMIA 75(4) (2021) 311-318","10.2533/chimia.2021.311",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many chemical concepts can be well defined in the context of quantum chemical
theories. Examples are the electronegativity scale of Mulliken and Jaffe and
the hard and soft acids and bases concept of Pearson. The sound theoretical
basis allows for a systematic definition of such concepts. However, while they
are often used to describe and compare chemical processes in terms of
reactivity, their predictive power remains unclear. In this work, we elaborate
on the predictive potential of chemical reactivity concepts, which can be
crucial for autonomous reaction exploration protocols to guide them by
first-principles heuristics that expoit these concepts.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:47:51 GMT""},{""version"":""v2"",""created"":""Sun, 16 May 2021 22:09:25 GMT""}]","2021-05-18"
"2102.01946","Jan Gertheiss","Jan Gertheiss, Fabian Scheipl, Tina Lauer, Harald Ehrhardt","Statistical Inference for Ordinal Predictors in Generalized Linear and
  Additive Models with Application to Bronchopulmonary Dysplasia",,"BMC Research Notes (2022) 15:112","10.1186/s13104-022-05995-4",,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Discrete but ordered covariates are quite common in applied statistics, and
some regularized fitting procedures have been proposed for proper handling of
ordinal predictors in statistical modeling. In this study, we show how
quadratic penalties on adjacent dummy coefficients of ordinal predictors
proposed in the literature can be incorporated in the framework of generalized
additive models, making tools for statistical inference developed there
available for ordinal predictors as well. Motivated by an application from
neonatal medicine, we discuss whether results obtained when constructing
confidence intervals and testing significance of smooth terms in generalized
additive models are useful with ordinal predictors/penalties as well.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:54:10 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 08:32:31 GMT""}]","2022-04-25"
"2102.01947","Cesar Cuenca","Cesar Cuenca and Grigori Olshanski","Infinite-dimensional groups over finite fields and Hall-Littlewood
  symmetric functions","46 pages; v2: minor modifications, shortened abstract, journal
  version, to appear in Adv. Math","Advances in Mathematics 395 (2022), paper 108087","10.1016/j.aim.2021.108087",,"math.RT math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The groups mentioned in the title are certain matrix groups of infinite size
over a finite field $\mathbb F_q$. They are built from finite classical groups
and at the same time they are similar to reductive $p$-adic Lie groups. In the
present paper, we initiate the study of invariant measures for the coadjoint
action of these infinite-dimensional groups.
  We examine first the group $\mathbb{GLB}$, a topological completion of the
inductive limit group $\varinjlim GL(n, \mathbb F_q)$. As was shown by Gorin,
Kerov, and Vershik [arXiv:1209.4945], the traceable factor representations of
$\mathbb{GLB}$ admit a complete classification, achieved in terms of harmonic
functions on the Young graph $\mathbb Y$.
  We show that there exists a parallel theory for ergodic coadjoint-invariant
measures, which is linked with a deformed version of harmonic functions on
$\mathbb Y$. Here the deformation means that the edges of $\mathbb Y$ are
endowed with certain formal multiplicities coming from the simplest version of
Pieri rule (multiplication by the first power sum $p_1$) for the
Hall-Littlewood (HL) symmetric functions with parameter $t:=q^{-1}$.
  This fact serves as a prelude to our main results, which concern topological
completions of two inductive limit groups built from finite unitary groups. We
show that in this case, coadjoint-invariant measures are linked to some new
branching graphs. The latter are still related to the HL functions, but the
novelty is that now the formal edge multiplicities come from the multiplication
by $p_2$ (not $p_1$) and the HL parameter $t$ turns out to be negative (as in
Ennola's duality).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:58:27 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 01:49:55 GMT""}]","2022-06-15"
"2102.01948","James Leung","James K. Leung, Tara Murphy, Giancarlo Ghirlanda, David L. Kaplan,
  Emil Lenc, Dougal Dobie, Julie Banfield, Catherine Hale, Aidan Hotan, David
  McConnell, Vanessa A. Moss, Joshua Pritchard, Wasim Raja, Adam J. Stewart and
  Matthew Whiting","A search for radio afterglows from gamma-ray bursts with the Australian
  Square Kilometre Array Pathfinder","18 pages, 7 figures; accepted for publication in MNRAS",,"10.1093/mnras/stab326",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a search for radio afterglows from long gamma-ray bursts using the
Australian Square Kilometre Array Pathfinder (ASKAP). Our search used the Rapid
ASKAP Continuum Survey, covering the entire celestial sphere south of
declination $+41^\circ$, and three epochs of the Variables and Slow Transients
Pilot Survey (Phase 1), covering $\sim 5,000$ square degrees per epoch. The
observations we used from these surveys spanned a nine-month period from 2019
April 21 to 2020 January 11. We crossmatched radio sources found in these
surveys with 779 well-localised (to $\leq 15''$) long gamma-ray bursts
occurring after 2004 and determined whether the associations were more likely
afterglow- or host-related through the analysis of optical images. In our
search, we detected one radio afterglow candidate associated with GRB 171205A,
a local low-luminosity gamma-ray burst with a supernova counterpart SN 2017iuk,
in an ASKAP observation 511 days post-burst. We confirmed this detection with
further observations of the radio afterglow using the Australia Telescope
Compact Array at 859 days and 884 days post-burst. Combining this data with
archival data from early-time radio observations, we showed the evolution of
the radio spectral energy distribution alone could reveal clear signatures of a
wind-like circumburst medium for the burst. Finally, we derived semi-analytical
estimates for the microphysical shock parameters of the burst: electron
power-law index $p = 2.84$, normalised wind-density parameter $A_* = 3$,
fractional energy in electrons $\epsilon_{e} = 0.3$, and fractional energy in
magnetic fields $\epsilon_{B} = 0.0002$.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 08:58:59 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 06:00:49 GMT""}]","2021-03-09"
"2102.01949","Igor Shparlinski","Dragos Ghioca, Alina Ostafe, Sina Saleh and Igor E. Shparlinski","On sparsity of representations of polynomials as linear combinations of
  exponential functions",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Given an integer $g$ and also some given integers $m$ (sufficiently large)
and $c_1,\dots, c_m$, we show that the number of all non-negative integers
$n\le M$ with the property that there exist non-negative integers $k_1,\dots,
k_m$ such that $$n^2=\sum_{i=1}^m c_i g^{k_i}$$ is $o\left(\left(\log M
\right)^{m-1/2}\right)$. We also obtain a similar bound when dealing with more
general inequalities $$\left|Q(n)-\sum_{i=1}^m c_i\lambda^{k_i}\right|\le B,$$
where $Q\in {\mathbb C}[X]$ and also $\lambda\in {\mathbb C}$ (while $B$ is a
real number).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:01:06 GMT""}]","2021-02-04"
"2102.01950","Matthieu Simeoni","Matthieu Simeoni and Paul Hurley","SiML: Sieved Maximum Likelihood for Array Signal Processing","5 pages, 2 figures. Published in ICASSP 2021-2021 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for
  6-11 June 2021 in Toronto, Ontario, Canada",,,,"stat.AP math.OC stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic Maximum Likelihood (SML) is a popular direction of arrival (DOA)
estimation technique in array signal processing. It is a parametric method that
jointly estimates signal and instrument noise by maximum likelihood, achieving
excellent statistical performance. Some drawbacks are the computational
overhead as well as the limitation to a point-source data model with fewer
sources than sensors. In this work, we propose a Sieved Maximum Likelihood
(SiML) method. It uses a general functional data model, allowing an
unrestricted number of arbitrarily-shaped sources to be recovered. To this end,
we leverage functional analysis tools and express the data in terms of an
infinite-dimensional sampling operator acting on a Gaussian random function. We
show that SiML is computationally more efficient than traditional SML,
resilient to noise, and results in much better accuracy than spectral-based
methods.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:01:06 GMT""}]","2021-02-04"
"2102.01951","Angeliki  Lazaridou","Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang
  Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d'Autume,
  Tomas Kocisky, Sebastian Ruder, Dani Yogatama, Kris Cao, Susannah Young, Phil
  Blunsom","Mind the Gap: Assessing Temporal Generalization in Neural Language
  Models","To appear as a Spotlight at NeurIPS 2021",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our world is open-ended, non-stationary, and constantly evolving; thus what
we talk about and how we talk about it change over time. This inherent dynamic
nature of language contrasts with the current static language modelling
paradigm, which trains and evaluates models on utterances from overlapping time
periods. Despite impressive recent progress, we demonstrate that Transformer-XL
language models perform worse in the realistic setup of predicting future
utterances from beyond their training period, and that model performance
becomes increasingly worse with time. We find that, while increasing model size
alone -- a key driver behind recent progress -- does not solve this problem,
having models that continually update their knowledge with new information can
indeed mitigate this performance degradation over time. Hence, given the
compilation of ever-larger language modelling datasets, combined with the
growing list of language-model-based NLP applications that require up-to-date
factual knowledge about the world, we argue that now is the right time to
rethink the static way in which we currently train and evaluate our language
models, and develop adaptive language models that can remain up-to-date with
respect to our ever-changing and non-stationary world. We publicly release our
dynamic, streaming language modelling benchmarks for WMT and arXiv to
facilitate language model evaluation that takes temporal dynamics into account.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:01:49 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 15:47:43 GMT""}]","2021-10-27"
"2102.01952","Daniel Dinsdale","Will G\""urp{\i}nar-Morgan, Daniel Dinsdale, Joe Gallagher, Aditya
  Cherukumudi and Patrick Lucey","You Cannot Do That Ben Stokes: Dynamically Predicting Shot Type in
  Cricket Using a Personalized Deep Neural Network","20 pages, 12 figures, accepted paper for the 2020 MIT Sloan Sports
  Analytics Conference",,,,"stat.AP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to predict what shot a batsman will attempt given the type of
ball and match situation is both one of the most challenging and strategically
important tasks in cricket.
  The goal of the batsman is to score as many runs without being dismissed,
whilst for bowlers their goal is to stem the flow of runs and ideally to
dismiss their opponent. Getting the best batsman vs bowler match-up is of
paramount importance. For example, for the fielding team, the choice of bowler
against the opposition star batsman could be the key difference between winning
or losing. Therefore, the ability to have a predefined playbook (as in the NFL)
which would allow a team to predict how best to set their fielders given the
context of the game, the batsman they are bowling to and bowlers at their
disposal would give them a significant strategic advantage.
  To this end, we present a personalized deep neural network approach which can
predict the probabilities of where a specific batsman will hit a specific
bowler and bowl type, in a specific game-scenario. We demonstrate how our
personalized predictions provide vital information to inform the
decision-making of coaches and captains, both in terms of pre-match and in-game
tactical choices, using the 2019 World Cup final between England and New
Zealand as a case study example.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:03:59 GMT""}]","2021-02-04"
"2102.01953","Kallol Paul","Pintu Bhunia and Kallol Paul","Furtherance of Numerical radius inequalities of Hilbert space operators","9 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If $A,B$ are bounded linear operators on a complex Hilbert space, then %
$w(A) \leq \frac{1}{2}\left( \|A\|+\sqrt{r\left(|A||A^*|\right)}\right)$ and
$w(AB \pm BA)\leq 2\sqrt{2}\|B\|\sqrt{ w^2(A)-\frac{c^2(\Re (A))+c^2(\Im
(A))}{2} },$ \begin{eqnarray*} w(A) &\leq& \frac{1}{2}\left(
\|A\|+\sqrt{r\left(|A||A^*|\right)}\right),\\ w(AB \pm BA)&\leq&
2\sqrt{2}\|B\|\sqrt{ w^2(A)-\frac{c^2(\Re (A))+c^2(\Im (A))}{2} },
\end{eqnarray*} where $w(.),\|.\|,c(.)$ and $r(.)$ are the numerical radius,
the operator norm, the Crawford number and the spectral radius respectively,
and $\Re (A)$, $\Im (A)$ are the real part, the imaginary part of $A$
respectively. The inequalities obtained here generalize and improve on the
existing well known inequalities.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:04:42 GMT""}]","2021-02-04"
"2102.01954","Baptiste Gault","Patrick Stender, Baptiste Gault, Tim M. Schwarz, Eric V. Woods, Se-Ho
  Kim, Jonas Ott, Leigh T. Stephenson, Guido Schmitz, Christoph Freysoldt,
  Johannes K\""astner, Ayman A. El-Zoka","Status and direction of atom probe analysis of frozen liquids","submitted for publication assocaited to the APT&M 2020 conference",,"10.1017/S1431927621013994",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imaging of liquids and cryogenic biological materials by electron microscopy
has been recently enabled by innovative approaches for specimen preparation and
the fast development of optimised instruments for cryo-enabled electron
microscopy (cryo-EM). Yet, Cryo-EM typically lacks advanced analytical
capabilities, in particular for light elements. With the development of
protocols for frozen wet specimen preparation, atom probe tomography (APT)
could advantageously complement insights gained by cryo-EM. Here, we report on
different approaches that have been recently proposed to enable the analysis of
relatively large volumes of frozen liquids from either a flat substrate or the
fractured surface of a wire. Both allowed for analysing water ice layers which
are several microns thick consisting of pure water, pure heavy-water and
aqueous solutions. We discuss the merits of both approaches, and prospects for
further developments in this area. Preliminary results raise numerous
questions, in part concerning the physics underpinning field evaporation. We
discuss these aspects and lay out some of the challenges regarding the APT
analysis of frozen liquids.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:06:38 GMT""}]","2022-07-27"
"2102.01955","Zhaoyang Pang","Zhaoyang Pang, Callum Biggs O'May, Bhavin Choksi, Rufin VanRullen","Predictive coding feedback results in perceived illusory contours in a
  recurrent neural network","Manuscript under review",,,,"cs.CV q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Modern feedforward convolutional neural networks (CNNs) can now solve some
computer vision tasks at super-human levels. However, these networks only
roughly mimic human visual perception. One difference from human vision is that
they do not appear to perceive illusory contours (e.g. Kanizsa squares) in the
same way humans do. Physiological evidence from visual cortex suggests that the
perception of illusory contours could involve feedback connections. Would
recurrent feedback neural networks perceive illusory contours like humans? In
this work we equip a deep feedforward convolutional network with brain-inspired
recurrent dynamics. The network was first pretrained with an unsupervised
reconstruction objective on a natural image dataset, to expose it to natural
object contour statistics. Then, a classification decision layer was added and
the model was finetuned on a form discrimination task: squares vs. randomly
oriented inducer shapes (no illusory contour). Finally, the model was tested
with the unfamiliar ''illusory contour'' configuration: inducer shapes oriented
to form an illusory square. Compared with feedforward baselines, the iterative
''predictive coding'' feedback resulted in more illusory contours being
classified as physical squares. The perception of the illusory contour was
measurable in the luminance profile of the image reconstructions produced by
the model, demonstrating that the model really ''sees'' the illusion. Ablation
studies revealed that natural image pretraining and feedback error correction
are both critical to the perception of the illusion. Finally we validated our
conclusions in a deeper network (VGG): adding the same predictive coding
feedback dynamics again leads to the perception of illusory contours.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:07:09 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 14:43:15 GMT""}]","2021-06-17"
"2102.01956","Alperen Karan","Alperen Karan, Atabey Kaygun","Time Series Classification via Topological Data Analysis","31 pages, 20 figures",,"10.1016/j.eswa.2021.115326",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop topological data analysis methods for
classification tasks on univariate time series. As an application, we perform
binary and ternary classification tasks on two public datasets that consist of
physiological signals collected under stress and non-stress conditions. We
accomplish our goal by using persistent homology to engineer stable topological
features after we use a time delay embedding of the signals and perform a
subwindowing instead of using windows of fixed length. The combination of
methods we use can be applied to any univariate time series and in this
application allows us to reduce noise and use long window sizes without
incurring an extra computational cost. We then use machine learning models on
the features we algorithmically engineered to obtain higher accuracies with
fewer features.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:09:05 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 21:15:35 GMT""}]","2021-06-15"
"2102.01957","Andrea Di Falco","Meisam Askari, Blair C. Kirkpatrick, Tomas \v{C}i\v{z}m\'ar and Andrea
  Di Falco","All-optical manipulation of photonic membranes",,,"10.1364/OE.420364",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Here we demonstrate the all-optical manipulation of polymeric membranes in
microfluidic environments. The membranes are decorated with handles for their
use in holographic optical tweezers setups. Our results show that due to their
form factor the membranes present an 8-fold increase in their mechanical
stability, respect to micrometric dielectric particles. This intrinsic superior
stability is expected to improve profoundly a wide range of bio-photonic
applications that rely on the optical manipulation of micrometric objects while
studying single-molecule mechanics and sub-cellular scale transport processes.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:09:29 GMT""}]","2021-05-12"
"2102.01958","Anna Taranenko","Anna A. Taranenko","On a metric property of perfect colorings","7 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a perfect coloring of a graph, we prove that the $L_1$ distance between
two rows of the adjacency matrix of the graph is not less than the $L_1$
distance between the corresponding rows of the parameter matrix of the
coloring. With the help of an algebraic approach, we deduce corollaries of this
result for perfect $2$-colorings, perfect colorings in distance-$l$ graphs and
in distance-regular graphs. We also provide examples when the obtained property
reject several putative parameter matrices of perfect colorings in infinite
graphs.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:12:32 GMT""}]","2021-02-04"
"2102.01959","Erkko Lehtonen","Erkko Lehtonen","Majority-closed minions of Boolean functions","37 pages, 3 figures, 1 table",,,,"math.RA math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The 93 minions of Boolean functions stable under left composition with the
clone of self-dual monotone functions are described. As an easy consequence,
all $(C_1,C_2)$-stable classes of Boolean functions are determined for an
arbitrary clone $C_1$ and for any clone $C_2$ containing the clone of self-dual
monotone functions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:13:30 GMT""}]","2021-02-04"
"2102.01960","Ramis Movassagh","Yasuhiro Kondo, Ryuhei Mori, Ramis Movassagh","Quantum supremacy and hardness of estimating output probabilities of
  quantum circuits","10 pages + References + short appendix. Has 2 figures. v3: New
  material added and changed the original title in v1 ""Fine-Grained Analysis
  and Improved Robustness of Quantum Supremacy for Random Circuit Sampling""","2021 IEEE 62nd Annual Symposium on Foundations of Computer Science
  (FOCS)",,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent experimental demonstrations of quantum supremacy,
proving the hardness of the output of random quantum circuits is an imperative
near term goal. We prove under the complexity theoretical assumption of the
non-collapse of the polynomial hierarchy that approximating the output
probabilities of random quantum circuits to within $\exp(-\Omega(m\log m))$
additive error is hard for any classical computer, where $m$ is the number of
gates in the quantum computation. More precisely, we show that the above
problem is $\#\mathsf{P}$-hard under $\mathsf{BPP}^{\mathsf{NP}}$ reduction. In
the recent experiments, the quantum circuit has $n$-qubits and the architecture
is a two-dimensional grid of size $\sqrt{n}\times\sqrt{n}$. Indeed for constant
depth circuits approximating the output probabilities to within
$2^{-\Omega(n\log{n})}$ is hard. For circuits of depth $\log{n}$ or $\sqrt{n}$
for which the anti-concentration property holds, approximating the output
probabilities to within $2^{-\Omega(n\log^2{n})}$ and $2^{-\Omega(n^{3/2}\log
n)}$ is hard respectively. We then show that the hardness results extend to any
open neighborhood of an arbitrary (fixed) circuit including the trivial circuit
with identity gates. We made an effort to find the best proofs and proved these
results from first principles, which do not use the standard techniques such as
the Berlekamp--Welch algorithm, the usual Paturi's lemma, and Rakhmanov's
result.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:20:32 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 18:00:10 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 13:23:38 GMT""}]","2021-12-13"
"2102.01961","Patrick de Laverny","J. Perdigon, P. de Laverny, A. Recio-Blanco, E. Fernandez-Alvar, P.
  Santos-Peral, G. Kordopatis and M.A. Alvarez","The AMBRE Project: Origin and evolution of sulfur in the Milky Way","A&A in press (14 pages, 8 figures)","A&A 647, A162 (2021)","10.1051/0004-6361/202040147",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Sulfur is a volatile chemical element that plays an important role in tracing
the chemical evolution of galaxies. However, its nucleosynthesis origin and
abundance variations are still unclear. The goal of the present article is to
accurately and precisely study the S-content of large number of stars located
in the solar neighbourhood. We use the parametrisation of thousands of HR
stellar spectra provided by the AMBRE Project, and combine it with the
automated abundance determination GAUGUIN to derive LTE sulfur abundances for
1855 slow-rotating FGK-type stars. This is the largest and most precise
catalogue of S-abundances published to date. It covers a metallicity domain as
high as ~2.5dex starting at [M/H]~-2.0dex. We find that the [S/M] abundances
ratio is compatible with a plateau-like distribution in the metal-poor regime,
and then starts to decrease continuously at [M/H]~-1.0dex. This decrease
continues towards negative values for supersolar metallicity stars as recently
reported for Mg and as predicted by Galactic chemical evolution models.
Moreover, sulfur-rich stars having [M/H] in the range [-1.0,-0.5] have very
different kinematical and orbital properties with respect to more metal-rich
and sulfur-poor ones. Two disc components, associated with the thin and thick
discs, are thus seen independently in kinematics and sulfur abundances. The
sulfur radial gradients in the Galactic discs have also been estimated.
Finally, the enrichment in sulfur with respect to iron is nicely correlated
with stellar ages: older metal-poor stars have higher [S/M] ratios than younger
metal-rich ones. This work has confirmed that sulfur is an alfa-element that
could be considered to explore the Galactic populations properties.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:25:04 GMT""}]","2021-03-31"
"2102.01962","Josef Teichmann","Blanka Horvath, Josef Teichmann, Zan Zuric","Deep Hedging under Rough Volatility",,,,,"q-fin.CP cs.CE","http://creativecommons.org/licenses/by/4.0/","  We investigate the performance of the Deep Hedging framework under training
paths beyond the (finite dimensional) Markovian setup. In particular we analyse
the hedging performance of the original architecture under rough volatility
models with view to existing theoretical results for those. Furthermore, we
suggest parsimonious but suitable network architectures capable of capturing
the non-Markoviantity of time-series. Secondly, we analyse the hedging
behaviour in these models in terms of P\&L distributions and draw comparisons
to jump diffusion models if the the rebalancing frequency is realistically
small.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:27:16 GMT""}]","2021-02-04"
"2102.01963","Hojung Lee","Hojung Lee, Cho-Jui Hsieh, Jong-Seok Lee","Local Critic Training for Model-Parallel Learning of Deep Neural
  Networks",,"IEEE Transactions on Neural Networks and Learning Systems (2021)","10.1109/TNNLS.2021.3057380",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a novel model-parallel learning method, called
local critic training, which trains neural networks using additional modules
called local critic networks. The main network is divided into several layer
groups and each layer group is updated through error gradients estimated by the
corresponding local critic network. We show that the proposed approach
successfully decouples the update process of the layer groups for both
convolutional neural networks (CNNs) and recurrent neural networks (RNNs). In
addition, we demonstrate that the proposed method is guaranteed to converge to
a critical point. We also show that trained networks by the proposed method can
be used for structural optimization. Experimental results show that our method
achieves satisfactory performance, reduces training time greatly, and decreases
memory consumption per machine. Code is available at
https://github.com/hjdw2/Local-critic-training.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:30:45 GMT""}]","2021-02-04"
"2102.01964","Mykhaylo Yu Skulskyy","M.Yu. Skulskyy","Formation of magnetized spatial structures in the Beta Lyrae system III.
  Reflection of magnetically controlled matter in circumbinary structures in
  helium lines, in particular arising from metastable levels",,,"10.31577/caosp.2021.51.1.7",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Spatial gaseous structures in the Beta Lyrae system have been studied with
the fact of change in the longitudinal component of the donor's magnetic field
during the orbital period in mind. The investigation was based primarily on the
study of the dynamics of the circumstellar structures surrounding the binary
system as a whole. The special emphasis was placed on the study of complex
helium lines, in particular those arising from metastable levels. A number of
different observable facts from the ultraviolet to the red spectral region were
analyzed. The configuration of the donor magnetic field is a factor that not
only enhances mass transfer and influences the formation of spatial gas
structures between stellar components but, to some extent, also affects the
outflow of matter and the formation of external gas structures around this
interacting binary system. Together with previous articles
\citep{Skulskyy2020a, Skulskyy2020b}, the pieces of evidence of this work,
confirming the reflection of magnetically controlled matter in circumbinary
structures, define the basis for a coherent picture of the mass exchange
between components and outflows of matter outwards
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:32:17 GMT""}]","2021-02-04"
"2102.01965","Prasenjit Ghosh","Prasenjit Ghosh and T. K. Samanta","Generalized atomic subspaces for operators in Hilbert spaces","22 pages",,"10.21136/MB.2021.0130-20",,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  We introduce the notion of a g-atomic subspace for a bounded linear operator
and construct several useful resolutions of the identity operator on a Hilbert
space using the theory of g-fusion frames. Also we shall describe the concept
of frame operator for a pair of g-fusion Bessel sequences and some of their
properties.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:32:31 GMT""}]","2021-08-31"
"2102.01966","Omar Zahra","Omar Zahra, David Navarro-Alarcon and Silvia Tolu","A Neurorobotic Embodiment for Exploring the Dynamical Interactions of a
  Spiking Cerebellar Model and a Robot Arm During Vision-based Manipulation
  Tasks",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the original goal for developing robots is replacing humans in
dangerous and tedious tasks, the final target shall be completely mimicking the
human cognitive and motor behaviour. Hence, building detailed computational
models for the human brain is one of the reasonable ways to attain this. The
cerebellum is one of the key players in our neural system to guarantee
dexterous manipulation and coordinated movements as concluded from lesions in
that region. Studies suggest that it acts as a forward model providing
anticipatory corrections for the sensory signals based on observed
discrepancies from the reference values. While most studies consider providing
the teaching signal as error in joint-space, few studies consider the error in
task-space and even fewer consider the spiking nature of the cerebellum on the
cellular-level. In this study, a detailed cellular-level forward cerebellar
model is developed, including modeling of Golgi and Basket cells which are
usually neglected in previous studies. To preserve the biological features of
the cerebellum in the developed model, a hyperparameter optimization method
tunes the network accordingly. The efficiency and biological plausibility of
the proposed cerebellar-based controller is then demonstrated under different
robotic manipulation tasks reproducing motor behaviour observed in human
reaching experiments.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:36:47 GMT""}]","2021-02-04"
"2102.01967","Lhoussain El Fadil","Hamid Ben Yakkou and Lhoussain El Fadil","On monogenity of certain pure number fields defined by $x^{p^r}-m$","Submitted. arXiv admin note: text overlap with arXiv:2006.11230",,,,"math.NT","http://creativecommons.org/publicdomain/zero/1.0/","  Let $K = \mathbb{Q} (\alpha) $ be a pure number field generated by a complex
root $\alpha$ a monic irreducible polynomial $ F(x) = x^{p^r} -m$, with $ m
\neq 1 $ is a square free rational integer, $p$ is a rational prime integer,
and $r$ is a positive integer. In this paper, we study the monogenity of $K$.
We prove that if {{$\nu_p(m^p-m)=1$}}, then $K$ is monogenic. But if $r\ge p$
and {$\nu_p(m^{p}-m)> p$}, then $K$ is not monogenic. Some illustrating
examples are given.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:37:12 GMT""}]","2021-02-04"
"2102.01968","Claire Theobald","Claire Theobald (LORIA), Fr\'ed\'eric Pennerath (LORIA), Brieuc
  Conan-Guez (LORIA), Miguel Couceiro (LORIA), Amedeo Napoli (LORIA)","A Bayesian Neural Network based on Dropout Regulation",,"Workshop on Uncertainty in Machine Learning (WUML) at ECML-PKDD
  2020 Conference, Eyke H{\""u}llermeier; S{\'e}bastien Destercke, 2020, N.A.
  (online), France",,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian Neural Networks (BNN) have recently emerged in the Deep Learning
world for dealing with uncertainty estimation in classification tasks, and are
used in many application domains such as astrophysics, autonomous driving...BNN
assume a prior over the weights of a neural network instead of point estimates,
enabling in this way the estimation of both aleatoric and epistemic uncertainty
of the model prediction.Moreover, a particular type of BNN, namely MC Dropout,
assumes a Bernoulli distribution on the weights by using Dropout.Several
attempts to optimize the dropout rate exist, e.g. using a variational
approach.In this paper, we present a new method called ""Dropout Regulation""
(DR), which consists of automatically adjusting the dropout rate during
training using a controller as used in automation.DR allows for a precise
estimation of the uncertainty which is comparable to the state-of-the-art while
remaining simple to implement.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:39:50 GMT""}]","2021-02-04"
"2102.01969","Rasmus M{\o}gelberg","Magnus Baunsgaard Kristensen, Rasmus Ejlers M{\o}gelberg and Andrea
  Vezzosi","Greatest HITs: Higher inductive types in coinductive definitions via
  induction under clocks","29 pages",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Guarded recursion is a powerful modal approach to recursion that can be seen
as an abstract form of step-indexing. It is currently used extensively in
separation logic to model programming languages with advanced features by
solving domain equations also with negative occurrences. In its multi-clocked
version, guarded recursion can also be used to program with and reason about
coinductive types, encoding the productivity condition required for recursive
definitions in types. This paper presents the first type theory combining
multi-clocked guarded recursion with the features of Cubical Type Theory, as
well as a denotational semantics. Using the combination of Higher Inductive
Types (HITs) and guarded recursion allows for simple programming and reasoning
about coinductive types that are traditionally hard to represent in type
theory, such as the type of finitely branching labelled transition systems. For
example, our results imply that bisimilarity for these imply path equality, and
so proofs can be transported along bisimilarity proofs. Among our technical
contributions is a new principle of induction under clocks. This allows
universal quantification over clocks to commute with HITs up to equivalence of
types, and is crucial for the encoding of coinductive types. Such commutativity
requirements have been formulated for inductive types as axioms in previous
type theories with multi-clocked guarded recursion, but our present formulation
as an induction principle allows for the formulation of general computation
rules.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:41:14 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 14:29:36 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jun 2022 13:41:17 GMT""}]","2022-06-06"
"2102.01970","Jiashuo Zhang","Jiashuo Zhang, Jianbo Gao, Ke Wang, Zhenhao Wu, Ying Lan, Zhi Guan,
  Zhong Chen","Efficient Byzantine Fault Tolerance using Trusted Execution Environment:
  Preventing Equivocation is only the Beginning",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid development of blockchain, Byzantine fault-tolerant protocols
have attracted revived interest recently. To overcome the theoretical bounds of
Byzantine fault tolerance, many protocols attempt to use Trusted Execution
Environment (TEE) to prevent equivocation and improve performance and
scalability. However, due to the broken quorum intersection assumption caused
by the reduction of the replica number, the improvement is mostly at the cost
of increased communication complexity which prevents existing TEE-based
protocols to be applied to large-scale blockchain systems. In this paper, we
propose TBFT, an efficient Byzantine fault-tolerant protocol in the partial
synchrony setting, which has O(n) message complexity in both normal-case and
view-change. Compared to previous protocols, TBFT uses TEE-assisted primitives
to limit more types of malicious behaviors of replicas rather than preventing
equivocation only, thereby reducing the latency and communication complexity of
clients and replicas. Besides, we also introduce lightweight cryptographic
primitives including a novel leader election mechanism and an efficient voting
message aggregation mechanism for better security and performance. We evaluate
TBFT via systematic analysis and experiments, and the results show that TBFT
has better performance and scalability compared to other protocols.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:41:56 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 08:42:37 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 08:41:10 GMT""}]","2021-07-07"
"2102.01971","Radoslav K. Zamanov","R. K. Zamanov, K. A. Stoyanov, J. Marti, V. D. Marchev, Y. M. Nikolov","Radius, rotational period and inclination of the Be stars in the
  Be/gamma-ray binaries MWC 148 and MWC 656","6 pages, Accepted by Astronomische Nachrichten / Astronomical Notes",,"10.1002/asna.202123856",,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Using TESS photometry and Rozhen spectra of the Be/gamma-ray binaries MWC 148
and MWC 656, we estimate the projected rotational velocity ($ {v} \sin i$), the
rotational period (P$_{\rm rot}$), radius (R$_{\rm 1}$), and inclination ($i$)
of the mass donor. For MWC 148 we derive P$_{\rm rot} = 1.10 \pm 0.03$~d,
R$_{\rm 1}= 9.2 \pm 0.5$~R$_\odot$, $i = 40^\circ \pm 2^\circ$, and $ {v} \sin
i =272 \pm 5$~km~s$^{-1}$. For MWC 656 we obtain P$_{\rm rot} = 1.12 \pm
0.03$~d, R$_{\rm 1}= 8.8 \pm 0.5$~R$_\odot$, $i = 52^\circ \pm 3^\circ$, and $
{v} \sin i =313 \pm 3$~km~s$^{-1}$. For MWC 656 we also find that the rotation
of the mass donor is coplanar with the orbital plane.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:43:34 GMT""}]","2021-04-28"
"2102.01972","Song Lu","Changle Li and Song Lu and Levente Vitos","Predicting grain boundary energies of complex alloys from ab initio
  calculations",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Investigating the grain boundary energies of pure fcc metals and their
surface energies obtained from ab initio modeling, we introduce a robust method
to estimate the grain boundary energies for complex multicomponent alloys. The
input parameter is the surface energy of the alloy, which can easily be
accessed by modern ab initio calculations based on density functional theory.
The method is demonstrated in the case of paramagnetic Fe-Cr-Ni alloys for
which reliable grain boundary data is available.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:43:35 GMT""}]","2021-02-04"
"2102.01973","Itai Ben Yaacov","Ita\""i Ben Yaacov (AGL, ICJ)","Reconstruction of non-$\aleph_0$-categorical theories",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalise the correspondence between $\aleph 0$-categorical theories and
their automorphism groups to arbitrary complete theories in classical logic,
and to some theories (including, in particular, all $\aleph 0$-categorical
ones) in continuous logic.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:44:12 GMT""}]","2021-02-04"
"2102.01974","Alasdair Tran","Minjeong Shin, Alasdair Tran, Siqi Wu, Alexander Mathews, Rong Wang,
  Georgiana Lyall, Lexing Xie","AttentionFlow: Visualising Influence in Networks of Time Series","Published in WSDM 2021. The demo is available at
  https://attentionflow.ml and code is available at
  https://github.com/alasdairtran/attentionflow","The Proceedings of the Fourteenth ACM International Conference on
  Web Search and Data Mining (WSDM), 2021","10.1145/3437963.3441703",,"cs.SI cs.HC cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The collective attention on online items such as web pages, search terms, and
videos reflects trends that are of social, cultural, and economic interest.
Moreover, attention trends of different items exhibit mutual influence via
mechanisms such as hyperlinks or recommendations. Many visualisation tools
exist for time series, network evolution, or network influence; however, few
systems connect all three. In this work, we present AttentionFlow, a new system
to visualise networks of time series and the dynamic influence they have on one
another. Centred around an ego node, our system simultaneously presents the
time series on each node using two visual encodings: a tree ring for an
overview and a line chart for details. AttentionFlow supports interactions such
as overlaying time series of influence and filtering neighbours by time or
flux. We demonstrate AttentionFlow using two real-world datasets, VevoMusic and
WikiTraffic. We show that attention spikes in songs can be explained by
external events such as major awards, or changes in the network such as the
release of a new song. Separate case studies also demonstrate how an artist's
influence changes over their career, and that correlated Wikipedia traffic is
driven by cultural interests. More broadly, AttentionFlow can be generalised to
visualise networks of time series on physical infrastructures such as road
networks, or natural phenomena such as weather and geological measurements.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:44:46 GMT""}]","2021-02-04"
"2102.01975","Alain Rapaport","Josh Taylor (ECE), Alain Rapaport (MISTEA)","Second-order cone optimization of the gradostat",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We maximize the production of biogas in a gradostat at steady state. The
physical decision variables are the water, substrate, and biomass entering each
tank and the flows through the interconnecting pipes. Our main technical focus
is the nonconvex constraint describing microbial growth. We formulate a
relaxation and prove that it is exact when the gradostat is outflow connected,
its system matrix is irreducible, and the growth rate satisfies a simple
condition. The relaxation has second-order cone representations for the Monod
and Contois growth rates. We extend the steady state models to the case of
multiple time periods by replacing the derivatives with numerical
approximations instead of setting them to zero. The resulting optimizations are
second-order cone programs, which can be solved at large scales using standard
industrial software.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:49:29 GMT""}]","2021-02-04"
"2102.01976","Carlos Quezada-Calonge","Antonio Dobado, Carlos Quezada-Calonge, Juan Jos\'e Sanz-Cillero","Importance of fermion loops $W^+W^-$ in elastic scattering","5 pages, 7 jpg figures; proceedings of the International Conference
  in Quantum Chromodynamics: QCD20 - 35 years later} (QCD 20), 27-30 October
  2020, Montpellier, France. arXiv admin note: substantial text overlap with
  arXiv:2012.12242",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We test the assumption that fermion-loop corrections to high energy $W^+W^-$
scattering are negligible when compared to the boson-loop ones. Indeed, we find
that, if the couplings of the interactions deviate from their Standard Model
values, fermion-loop corrections can in fact become as important or even
greater than boson-loop corrections for some particular regions of the
parameter space, and both types of loops should be taken into account. Some
preliminary results are shown.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:50:47 GMT""}]","2021-02-04"
"2102.01977","Sebastien Gerchinovitz","Fran\c{c}ois Bachoc (IMT, GdR MASCOT-NUM), Tommaso R Cesari (TSE-R),
  S\'ebastien Gerchinovitz (IMT)","Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with
  Error Certificates",,"NeurIPS 2021, Dec 2021, Virtual conference, France. 24 p",,,"math.ST cs.LG stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of zeroth-order (black-box) optimization of a Lipschitz
function $f$ defined on a compact subset $\mathcal X$ of $\mathbb R^d$, with
the additional constraint that algorithms must certify the accuracy of their
recommendations. We characterize the optimal number of evaluations of any
Lipschitz function $f$ to find and certify an approximate maximizer of $f$ at
accuracy $\varepsilon$. Under a weak assumption on $\mathcal X$, this optimal
sample complexity is shown to be nearly proportional to the integral
$\int_{\mathcal X} \mathrm{d}\boldsymbol x/( \max(f) - f(\boldsymbol x) +
\varepsilon )^d$. This result, which was only (and partially) known in
dimension $d=1$, solves an open problem dating back to 1991. In terms of
techniques, our upper bound relies on a packing bound by Bouttier al. (2020)
for the Piyavskii-Shubert algorithm that we link to the above integral. We also
show that a certified version of the computationally tractable DOO algorithm
matches these packing and integral bounds. Our instance-dependent lower bound
differs from traditional worst-case lower bounds in the Lipschitz setting and
relies on a local worst-case analysis that could likely prove useful for other
learning tasks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:51:03 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 09:01:28 GMT""},{""version"":""v3"",""created"":""Wed, 9 Jun 2021 14:16:24 GMT""},{""version"":""v4"",""created"":""Thu, 10 Jun 2021 08:19:36 GMT""},{""version"":""v5"",""created"":""Wed, 22 Mar 2023 09:17:12 GMT""}]","2023-03-23"
"2102.01978","Valentina Zannier","Omer Arif, Valentina Zannier, Ang Li, Francesca Rossi, Daniele
  Ercolani, Fabio Beltram, and Lucia Sorba","Growth and Strain Relaxation Mechanisms of InAs/InP/GaAsSb
  Core-Dual-Shell Nanowires","This document is the Accepted Manuscript version of a Published Work
  that appeared in final form in Crystal Growth and Design, copyright
  \c{opyright} American Chemical Society after peer review and technical
  editing by the publisher. To access the final edited and published work see
  https://pubs.acs.org/doi/abs/10.1021/acs.cgd.9b01421","Crystal Growth & Design 2020 20 (2), 1088-1096","10.1021/acs.cgd.9b01421",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The combination of core/shell geometry and band gap engineering in nanowire
heterostructures can be employed to realize systems with novel transport and
optical properties. Here, we report on the growth of InAs/InP/GaAsSb
core-dual-shell nanowires by catalyst-free chemical beam epitaxy on Si(111)
substrates. Detailed morphological, structural, and compositional analyses of
the nanowires as a function of growth parameters were carried out by scanning
and transmission electron microscopy and by energy-dispersive X-ray
spectroscopy. Furthermore, by combining the scanning transmission electron
microscopy-Moire technique with geometric phase analysis, we studied the
residual strain and the relaxation mechanisms in this system. We found that InP
shell facets are well-developed along all the crystallographic directions only
when the nominal thickness is above 1 nm, suggesting an island-growth mode.
Moreover, the crystallographic analysis indicates that both InP and GaAsSb
shells grow almost coherently to the InAs core along the 112 direction and
elastically compressed along the 110 direction. For InP shell thickness above 8
nm, some dislocations and roughening occur at the interfaces. This study
provides useful general guidelines for the fabrication of high-quality devices
based on these core-dual-shell nanowires.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:51:42 GMT""}]","2021-02-04"
"2102.01979","Viraj Kulkarni","Viraj Kulkarni, Manish Gawali, Amit Kharat","Key Technology Considerations in Developing and Deploying Machine
  Learning Models in Clinical Radiology Practice",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The use of machine learning to develop intelligent software tools for
interpretation of radiology images has gained widespread attention in recent
years. The development, deployment, and eventual adoption of these models in
clinical practice, however, remains fraught with challenges. In this paper, we
propose a list of key considerations that machine learning researchers must
recognize and address to make their models accurate, robust, and usable in
practice. Namely, we discuss: insufficient training data, decentralized
datasets, high cost of annotations, ambiguous ground truth, imbalance in class
representation, asymmetric misclassification costs, relevant performance
metrics, generalization of models to unseen datasets, model decay, adversarial
attacks, explainability, fairness and bias, and clinical validation. We
describe each consideration and identify techniques to address it. Although
these techniques have been discussed in prior research literature, by freshly
examining them in the context of medical imaging and compiling them in the form
of a laundry list, we hope to make them more accessible to researchers,
software developers, radiologists, and other stakeholders.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:53:43 GMT""}]","2021-02-04"
"2102.01980","Hanna Sophia Wutte","Nicolas Curin, Michael Kettler, Xi Kleisinger-Yu, Vlatka Komaric,
  Thomas Krabichler, Josef Teichmann, Hanna Wutte","A deep learning model for gas storage optimization",,,,,"q-fin.CP","http://creativecommons.org/licenses/by/4.0/","  To the best of our knowledge, the application of deep learning in the field
of quantitative risk management is still a relatively recent phenomenon. In
this article, we utilize techniques inspired by reinforcement learning in order
to optimize the operation plans of underground natural gas storage facilities.
We provide a theoretical framework and assess the performance of the proposed
method numerically in comparison to a state-of-the-art least-squares
Monte-Carlo approach. Due to the inherent intricacy originating from the
high-dimensional forward market as well as the numerous constraints and
frictions, the optimization exercise can hardly be tackled by means of
traditional techniques.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:54:44 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 13:53:33 GMT""}]","2021-03-08"
"2102.01981","Alexander Holevo","A. S. Holevo","Accessible information of a general quantum Gaussian ensemble","18 pages, 1 figure, notations improved. In the single mode case a new
  ex[licit form of the threshold condition is given",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accessible information, which is a basic quantity in quantum information
theory, is computed for a general quantum Gaussian ensemble under certain
""threshold condition"". It is shown that the maximizing measurement is Gaussian,
constituting a far-reaching generalization of the optical heterodyning. This
substantially extends the previous result concerning the gauge-invariant case,
even for a single bosonic mode.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:01:01 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 10:09:12 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 08:34:07 GMT""}]","2022-03-09"
"2102.01982","Michael Fop","Michael Fop, Pierre-Alexandre Mattei, Charles Bouveyron, Thomas
  Brendan Murphy","Unobserved classes and extra variables in high-dimensional discriminant
  analysis","29 pages, 29 figures",,,,"stat.ME stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  In supervised classification problems, the test set may contain data points
belonging to classes not observed in the learning phase. Moreover, the same
units in the test data may be measured on a set of additional variables
recorded at a subsequent stage with respect to when the learning sample was
collected. In this situation, the classifier built in the learning phase needs
to adapt to handle potential unknown classes and the extra dimensions. We
introduce a model-based discriminant approach, Dimension-Adaptive Mixture
Discriminant Analysis (D-AMDA), which can detect unobserved classes and adapt
to the increasing dimensionality. Model estimation is carried out via a full
inductive approach based on an EM algorithm. The method is then embedded in a
more general framework for adaptive variable selection and classification
suitable for data of large dimensions. A simulation study and an artificial
experiment related to classification of adulterated honey samples are used to
validate the ability of the proposed framework to deal with complex situations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:01:52 GMT""}]","2021-02-04"
"2102.01983","Anatoly Slobodchikov","M. M. Korshunov, I. A. Nekrasov, N. S. Pavlov, A. A. Slobodchikov","Band structure of tungsten oxide W$_{20}$O$_{58}$ with ideal octahedra","4 pages, 4 figures","JETP Letters, 2021, Vol. 113, No. 1","10.1134/S0021364021010057",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The band structure, density of states, and the Fermi surface of a tungsten
oxide WO$_{2.9}$ with idealized crystal structure (ideal octahedra WO$_6$
creating a ""square lattice"") is obtained within the density functional theory
in the generalized gradient approximation. Because of the oxygen vacancies
ordering this system is equivalent to the compound W$_{20}$O$_{58}$
(Magn\'{e}li phase), which has 78 atoms in unit cell. We show that
5$d$-orbitals of tungsten atoms located immediately around the voids in the
zigzag chains of edge-sharing octahedra give the dominant contribution near the
Fermi level. These particular tungsten atoms are responsible of a low-energy
properties of the system.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:02:57 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 12:23:08 GMT""}]","2021-03-08"
"2102.01984","Kao-Yueh Kuo","Kao-Yueh Kuo, I-Chun Chern, and Ching-Yi Lai","Decoding of Quantum Data-Syndrome Codes via Belief Propagation",,"in Proc. IEEE International Symposium on Information Theory
  (ISIT), 2021, pp. 1552--1557","10.1109/ISIT45174.2021.9518018",,"quant-ph cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Quantum error correction is necessary to protect logical quantum states and
operations. However, no meaningful data protection can be made when the
syndrome extraction is erroneous due to faulty measurement gates. Quantum
data-syndrome (DS) codes are designed to protect the data qubits and syndrome
bits concurrently. In this paper, we propose an efficient decoding algorithm
for quantum DS codes with sparse check matrices. Based on a refined belief
propagation (BP) decoding for stabilizer codes, we propose a DS-BP algorithm to
handle the quaternary quantum data errors and binary syndrome bit errors.
Moreover, a sparse quantum code may inherently be able to handle minor syndrome
errors so that fewer redundant syndrome measurements are necessary. We
demonstrate this with simulations on a quantum hypergraph-product code.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:05:36 GMT""}]","2021-09-10"
"2102.01985","Arushi Jain","Arushi Jain, Gandharv Patil, Ayush Jain, Khimya Khetarpal, Doina
  Precup","Variance Penalized On-Policy and Off-Policy Actor-Critic","Accepted to the Thirty-Fifth AAAI Conference on Artificial
  Intelligence (AAAI-21), 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning algorithms are typically geared towards optimizing the
expected return of an agent. However, in many practical applications, low
variance in the return is desired to ensure the reliability of an algorithm. In
this paper, we propose on-policy and off-policy actor-critic algorithms that
optimize a performance criterion involving both mean and variance in the
return. Previous work uses the second moment of return to estimate the variance
indirectly. Instead, we use a much simpler recently proposed direct variance
estimator which updates the estimates incrementally using temporal difference
methods. Using the variance-penalized criterion, we guarantee the convergence
of our algorithm to locally optimal policies for finite state action Markov
decision processes. We demonstrate the utility of our algorithm in tabular and
continuous MuJoCo domains. Our approach not only performs on par with
actor-critic and prior variance-penalization baselines in terms of expected
return, but also generates trajectories which have lower variance in the
return.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:06:16 GMT""}]","2021-02-04"
"2102.01986","J. Pascal Gollin","J. Pascal Gollin and Kevin Hendrey and Ken-ichi Kawarabayashi and
  O-joung Kwon and Sang-il Oum","A unified half-integral Erd\H{o}s-P\'{o}sa theorem for cycles in graphs
  labelled by multiple abelian groups","28 pages, 4 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Erd\H{o}s and P\'{o}sa proved in 1965 that there is a duality between the
maximum size of a packing of cycles and the minimum size of a vertex set
hitting all cycles. Such a duality does not hold if we restrict to odd cycles.
However, in 1999, Reed proved an analogue for odd cycles by relaxing packing to
half-integral packing. We prove a far-reaching generalisation of the theorem of
Reed; if the edges of a graph are labelled by finitely many abelian groups,
then there is a duality between the maximum size of a half-integral packing of
cycles whose values avoid a fixed finite set for each abelian group and the
minimum size of a vertex set hitting all such cycles.
  A multitude of natural properties of cycles can be encoded in this setting,
for example cycles of length at least $\ell$, cycles of length $p$ modulo $q$,
cycles intersecting a prescribed set of vertices at least $t$ times, and cycles
contained in given $\mathbb{Z}_2$-homology classes in a graph embedded on a
fixed surface. Our main result allows us to prove a duality theorem for cycles
satisfying a fixed set of finitely many such properties.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:09:51 GMT""}]","2021-02-04"
"2102.01987","Muhammad Ferjad Naeem","Muhammad Ferjad Naeem, Yongqin Xian, Federico Tombari, Zeynep Akata","Learning Graph Embeddings for Compositional Zero-shot Learning","Accepted in IEEE CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In compositional zero-shot learning, the goal is to recognize unseen
compositions (e.g. old dog) of observed visual primitives states (e.g. old,
cute) and objects (e.g. car, dog) in the training set. This is challenging
because the same state can for example alter the visual appearance of a dog
drastically differently from a car. As a solution, we propose a novel graph
formulation called Compositional Graph Embedding (CGE) that learns image
features, compositional classifiers, and latent representations of visual
primitives in an end-to-end manner. The key to our approach is exploiting the
dependency between states, objects, and their compositions within a graph
structure to enforce the relevant knowledge transfer from seen to unseen
compositions. By learning a joint compatibility that encodes semantics between
concepts, our model allows for generalization to unseen compositions without
relying on an external knowledge base like WordNet. We show that in the
challenging generalized compositional zero-shot setting our CGE significantly
outperforms the state of the art on MIT-States and UT-Zappos. We also propose a
new benchmark for this task based on the recent GQA dataset. Code is available
at: https://github.com/ExplainableML/czsl
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:11:03 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 09:15:22 GMT""},{""version"":""v3"",""created"":""Mon, 3 May 2021 19:12:00 GMT""}]","2021-05-05"
"2102.01988","Agota Koszorus","Agota Koszorus, Liam Vormawah, Randolf Beerwerth, Mark Bissell, Paul
  Campbell, Bradley Cheal, Charlie Devlin, Tommi Eronen, Stephan Fritzsche,
  Sarina Geldhof, Hanne Heylen, Jason Holt, Ari Jokinen, Sam Kelly, Iain Moore,
  Takayuki Miyagi, Sami Rinta-Antila, Annika Voss, Calvin Wraith","Proton-neutron pairing correlations in the self-conjugate nucleus
  $^{42}$Sc",,"Phys. Lett. B 819, 136439 (2021)","10.1016/j.physletb.2021.136439",,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collinear laser spectroscopy of the $N=Z=21$ self-conjugate nucleus $^{42}$Sc
has been performed at the JYFL IGISOL IV facility in order to determine the
change in nuclear mean-square charge radius between the $I^{\pi}=0^{+}$ ground
state and the $I^{\pi}=7^{+}$ isomer via the measurement of the
$^{42\mathrm{g},42\mathrm{m}}$Sc isomer shift. New multi-configurational
Dirac-Fock calculations for the atomic mass shift and field shift factors have
enabled a recalibration of the charge radii of the $^{42-46}$Sc isotopes which
were measured previously. While consistent with the treatment of
proton-neutron, proton-proton and neutron-neutron pairing on an equal footing,
the reduction in size for the isomer is observed to be of a significantly
larger magnitude than that expected from both shell model and ab-initio
calculations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:11:24 GMT""}]","2021-06-24"
"2102.01989","Ali Yilmaz","Ali Yilmaz","Search for the limits on anomalous neutral triple gauge couplings via
  $ZZ$ production in the $\ell \ell \nu \nu$ channel at FCC-hh","7 pages",,"10.1016/j.nuclphysb.2021.115471",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  This paper presents the projections on the anomalous neutral triple gauge
couplings ($aNTGC$) via $pp \rightarrow ZZ$ production in the 2$\ell$2$\nu$
final state at a 100 TeV proton-proton collider, \verb""FCC-hh"". %100 TeV center
of mass energy of The realistic \verb""FCC-hh"" detector environments and its
effects taken into account in the analysis. The study is carried out in the
mode where one Z boson decays into a pair of same-flavor, opposite-sign leptons
(electrons or muons) and the other one decays to the two neutrinos. The new
bounds on the charge-parity (CP)-conserving couplings $C_{\widetilde{B}W} /
\Lambda^{4}$ and CP-violating couplings $C_{WW} / \Lambda^{4}$, $C_{BW} /
\Lambda^{4}$ and $C_{BB} / \Lambda^{4}$ achived at 95\% Confidence Level (C.L.)
using the transverse momentum of the dilepton system ($p_{T}^{\ell \ell}$) are
$[-\, 0.042, \,\, +\,0.042]$, $[-\,0.050, \,\, +\,0.050]$, $[-\,0.050, \,\,
+\,0.050]$, and $[-\,0.048, \,\, +\,0.048]$ in units of TeV$^{-4}$,
respectively.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:16:27 GMT""}]","2021-06-29"
"2102.01990","Yu Deng","Yu Deng, Ling Wang, Chen Zhao, Shaojie Tang, Xiaoguang Cheng, Hong-Wen
  Deng, Weihua Zhou","A Deep Learning-Based Approach to Extracting Periosteal and Endosteal
  Contours of Proximal Femur in Quantitative CT Images",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic CT segmentation of proximal femur is crucial for the diagnosis and
risk stratification of orthopedic diseases; however, current methods for the
femur CT segmentation mainly rely on manual interactive segmentation, which is
time-consuming and has limitations in both accuracy and reproducibility. In
this study, we proposed an approach based on deep learning for the automatic
extraction of the periosteal and endosteal contours of proximal femur in order
to differentiate cortical and trabecular bone compartments. A three-dimensional
(3D) end-to-end fully convolutional neural network, which can better combine
the information between neighbor slices and get more accurate segmentation
results, was developed for our segmentation task. 100 subjects aged from 50 to
87 years with 24,399 slices of proximal femur CT images were enrolled in this
study. The separation of cortical and trabecular bone derived from the QCT
software MIAF-Femur was used as the segmentation reference. We randomly divided
the whole dataset into a training set with 85 subjects for 10-fold
cross-validation and a test set with 15 subjects for evaluating the performance
of models. Two models with the same network structures were trained and they
achieved a dice similarity coefficient (DSC) of 97.87% and 96.49% for the
periosteal and endosteal contours, respectively. To verify the excellent
performance of our model for femoral segmentation, we measured the volume of
different parts of the femur and compared it with the ground truth and the
relative errors between predicted result and ground truth are all less than 5%.
It demonstrated a strong potential for clinical use, including the hip fracture
risk prediction and finite element analysis.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:23:41 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 12:56:03 GMT""}]","2021-02-09"
"2102.01991","Shengkui Zhao","Shengkui Zhao, Hao Wang, Trung Hieu Nguyen, Bin Ma","Towards Natural and Controllable Cross-Lingual Voice Conversion Based on
  Neural TTS Model and Phonetic Posteriorgram","5 pages, 2 figures, 4 tables, accepted by ICASSP 2021",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Cross-lingual voice conversion (VC) is an important and challenging problem
due to significant mismatches of the phonetic set and the speech prosody of
different languages. In this paper, we build upon the neural text-to-speech
(TTS) model, i.e., FastSpeech, and LPCNet neural vocoder to design a new
cross-lingual VC framework named FastSpeech-VC. We address the mismatches of
the phonetic set and the speech prosody by applying Phonetic PosteriorGrams
(PPGs), which have been proved to bridge across speaker and language
boundaries. Moreover, we add normalized logarithm-scale fundamental frequency
(Log-F0) to further compensate for the prosodic mismatches and significantly
improve naturalness. Our experiments on English and Mandarin languages
demonstrate that with only mono-lingual corpus, the proposed FastSpeech-VC can
achieve high quality converted speech with mean opinion score (MOS) close to
the professional records while maintaining good speaker similarity. Compared to
the baselines using Tacotron2 and Transformer TTS models, the FastSpeech-VC can
achieve controllable converted speech rate and much faster inference speed.
More importantly, the FastSpeech-VC can easily be adapted to a speaker with
limited training utterances.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:28:07 GMT""}]","2021-02-04"
"2102.01992","Olivier Limousin","Olivier Gevin, Francis Lugiez, Alicja Michalowska, Aline Meuris,
  Olivier Limousin, Eric Delagnes, Olivier Lemaire, Fr\'ed\'eric Pinsard","IDeF-X HD: a CMOS ASIC for the readout of Cd(Zn)Te Detectors for
  space-borne applications",,,,,"astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  IDeF-X HD is a 32-channel analog front-end with self-triggering capability
optimized for the readout of 16 x 16 pixels CdTe or CdZnTe pixelated detectors
to build low power micro gamma camera. IDeF-X HD has been designed in the
standard AMS CMOS 0.35 microns process technology. Its power consumption is 800
micro watt per channel. The dynamic range of the ASIC can be extended to 1.1
MeV thanks to the in-channel adjustable gain stage. When no detector is
connected to the chip and without input current, a 33 electrons rms ENC level
is achieved after shaping with 10.7 micro seconds peak time. Spectroscopy
measurements have been performed with CdTe Schottky detectors. We measured an
energy resolution of 4.2 keV FWHM at 667 keV (137-Cs) on a mono-pixel
configuration. Meanwhile, we also measured 562 eV and 666 eV FWHM at 14 keV and
60 keV respectively (241-Am) with a 256 small pixel array and a low detection
threshold of 1.2 keV. Since IDeF-X HD is intended for space-borne applications
in astrophysics, we evaluated its radiation tolerance and its sensitivity to
single event effects. We demonstrated that the ASIC remained fully functional
without significant degradation of its performances after 200 krad and that no
single event latch-up was detected putting the Linear Energy Transfer threshold
above 110 MeV/(mg/cm2). Good noise performance and radiation tolerance make the
chip well suited for X-rays energy discrimination and high-energy resolution.
The chip is space qualified and flies on board the Solar Orbiter ESA mission
launched in 2020.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:30:35 GMT""}]","2021-02-04"
"2102.01993","Shengkui Zhao","Shengkui Zhao, Trung Hieu Nguyen, Bin Ma","Monaural Speech Enhancement with Complex Convolutional Block Attention
  Module and Joint Time Frequency Losses","5 pages, 4 figures, 2 tables, accepted by ICASSP 2021",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Deep complex U-Net structure and convolutional recurrent network (CRN)
structure achieve state-of-the-art performance for monaural speech enhancement.
Both deep complex U-Net and CRN are encoder and decoder structures with skip
connections, which heavily rely on the representation power of the
complex-valued convolutional layers. In this paper, we propose a complex
convolutional block attention module (CCBAM) to boost the representation power
of the complex-valued convolutional layers by constructing more informative
features. The CCBAM is a lightweight and general module which can be easily
integrated into any complex-valued convolutional layers. We integrate CCBAM
with the deep complex U-Net and CRN to enhance their performance for speech
enhancement. We further propose a mixed loss function to jointly optimize the
complex models in both time-frequency (TF) domain and time domain. By
integrating CCBAM and the mixed loss, we form a new end-to-end (E2E) complex
speech enhancement framework. Ablation experiments and objective evaluations
show the superior performance of the proposed approaches.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:30:52 GMT""}]","2021-02-04"
"2102.01994","Davide Ramaccia Dr.","Davide Ramaccia, Dimitrios L. Sounas, Andrea Alu', Alessandro Toscano,
  and Filiberto Bilotti","Phase-Induced Frequency Conversion and Doppler Effect with
  Time-Modulated Metasurfaces",,"IEEE Transactions on Antennas and Propagation, vol. 68, no. 3, pp.
  1607-1617, March 2020","10.1109/TAP.2019.2952469",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metasurfaces consisting of electrically thin and densely packed planar arrays
of subwavelength elements enable an unprecedented control of the impinging
electromagnetic fields. Spatially modulated metasurfaces can efficiently tailor
the spatial distribution of these fields with great flexibility. Similarly,
time modulated metasurfaces can be successfully used to manipulate the
frequency content and time variations of the impinging field. In this paper, we
present time-modulated reflective metasurfaces that cause a frequency shift to
the impinging radiation, thus realizing an artificial Doppler effect in a
non-moving electrically thin structure. Starting from the theoretical analysis,
we analytically derive the required time modulation of the surface admittance
to achieve this effect, and present a realistic time-varying structure, based
on a properly designed and dynamically tuned high-impedance surface. It is
analytically and numerically demonstrated that the field emerging from the
metasurface is up-,down-converted in frequency according to the modulation
profile of the metasurface. The proposed metasurface concept, enabling a
frequency modulation of the electromagnetic field on-the-fly, may find
application in telecommunication, radar, and sensing scenarios.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:35:20 GMT""}]","2021-02-04"
"2102.01995","Wojciech Jamroga","Gergei Bana, Wojciech Jamroga, David Naccache, Peter Y. A. Ryan","Convergence Voting: From Pairwise Comparisons to Consensus",,,,,"cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An important aspect of AI design and ethics is to create systems that reflect
aggregate preferences of the society. To this end, the techniques of social
choice theory are often utilized. We propose a new social choice function
motivated by the PageRank algorithm. The function ranks voting options based on
the Condorcet graph of pairwise comparisons. To this end, we transform the
Condorcet graph into a Markov chain whose stationary distribution provides the
scores of the options. We show how the values in the stationary distribution
can be interpreted as quantified aggregate support for the voting options, to
which the community of voters converges through an imaginary sequence of
negotiating steps. Because of that, we suggest the name ""convergence voting""
for the new voting scheme, and ""negotiated community support"" for the resulting
stationary allocation of scores.
  Our social choice function can be viewed as a consensus voting method,
sitting somewhere between Copeland and Borda. On the one hand, it does not
necessarily choose the Condorcet winner, as strong support from a part of the
society can outweigh mediocre uniform support. On the other hand, the influence
of unpopular candidates on the outcome is smaller than in the primary technique
of consensus voting, i.e., the Borda count. We achieve that without having to
introduce an ad hoc weighting that some other methods do.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:50:41 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 11:00:22 GMT""},{""version"":""v3"",""created"":""Mon, 1 Mar 2021 09:17:15 GMT""}]","2021-03-02"
"2102.01996","Ulas Ozdem","Ula\c{s} \""Ozdem","Magnetic dipole moments of the hidden-charm pentaquark states:
  $P_c(4440)$, $P_c(4457)$ and $P_{cs}(4459)$","12 pages and 1 figure",,"10.1140/epjc/s10052-021-09070-3",,"hep-ph hep-ex hep-lat","http://creativecommons.org/licenses/by/4.0/","  In this work, we employ the light-cone QCD sum rule to calculate the magnetic
dipole moments of the $P_c(4440)$, $P_c(4457)$ and $P_{cs}(4459)$ pentaquark
states by considering them as the diquark-diquark-antiquark and molecular
pictures with quantum numbers $J^P = \frac{3}{2}^-$, $J^P = \frac{1}{2}^-$ and
$J^P = \frac{1}{2}^-$, respectively. In the analyses, we use the
diquark-diquark-antiquark and molecular form of interpolating currents, and
photon distribution amplitudes to obtain the magnetic dipole moment of
pentaquark states. Theoretical examinations on magnetic dipole moments of the
hidden-charm pentaquark states, are essential as their results can help us
better figure out their substructure and the dynamics of the QCD as the theory
of the strong interaction. As a by product, we extract the electric quadrupole
and magnetic octupole moments of the $P_c(4440)$ pentaquark. These values show
a non-spherical charge distribution.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:51:41 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 20:13:54 GMT""}]","2021-04-21"
"2102.01997","John Sheekey","Michel Lavrauw and John Sheekey","The Tensor Rank of Semifields of Order 16 and 81",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the tensor rank of all semifields of order 16 over
$\mathbb{F}_2$ and of all semifields of order 81 over $\mathbb{F}_3$. Our
results imply that some semifields of order 81 have lower multiplicative
complexity than the finite field $\mathbb{F}_{81}$ over $\mathbb{F}_3$. We
prove new results on the correspondence between linear codes and tensor rank,
including a generalisation of a theorem of Brockett and Dobkin to arbitrary
tensors, which makes the problem computationally feasible.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:53:06 GMT""}]","2021-02-04"
"2102.01998","Guang Yang A","Guang Yang, Qinghao Ye, Jun Xia","Unbox the Black-box for the Medical Explainable AI via Multi-modal and
  Multi-centre Data Fusion: A Mini-Review, Two Showcases and Beyond","68 pages, 19 figures, submitted to the Information Fusion journal",,,,"cs.AI cs.CV cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explainable Artificial Intelligence (XAI) is an emerging research topic of
machine learning aimed at unboxing how AI systems' black-box choices are made.
This research field inspects the measures and models involved in
decision-making and seeks solutions to explain them explicitly. Many of the
machine learning algorithms can not manifest how and why a decision has been
cast. This is particularly true of the most popular deep neural network
approaches currently in use. Consequently, our confidence in AI systems can be
hindered by the lack of explainability in these black-box models. The XAI
becomes more and more crucial for deep learning powered applications,
especially for medical and healthcare studies, although in general these deep
neural networks can return an arresting dividend in performance. The
insufficient explainability and transparency in most existing AI systems can be
one of the major reasons that successful implementation and integration of AI
tools into routine clinical practice are uncommon. In this study, we first
surveyed the current progress of XAI and in particular its advances in
healthcare applications. We then introduced our solutions for XAI leveraging
multi-modal and multi-centre data fusion, and subsequently validated in two
showcases following real clinical scenarios. Comprehensive quantitative and
qualitative analyses can prove the efficacy of our proposed XAI solutions, from
which we can envisage successful applications in a broader range of clinical
questions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:56:58 GMT""}]","2021-02-04"
"2102.01999","Paul Heeren","Paul Heeren, Sabine Reffert, Trifon Trifonov, Ka Ho Wong, Man Hoi Lee,
  Jorge Lillo-Box, Andreas Quirrenbach, Torben Arentoft, Simon Albrecht, Frank
  Grundahl, Mads Fredslund Andersen, Victoria Antoci, Pere L. Pall\'e","Precise radial velocities of giant stars XV. Mysterious nearly periodic
  radial velocity variations in the eccentric binary $\epsilon$ Cygni","17 pages, 13 figures, accepted to A&A","A&A 647, A160 (2021)","10.1051/0004-6361/202040087",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the Hamilton Echelle Spectrograph at Lick Observatory, we have obtained
precise radial velocities (RVs) of a sample of 373 G- and K-giant stars over
more than 12 years, leading to the discovery of several single and multiple
planetary systems. The RVs of the long-period (~53 years) spectroscopic binary
$\epsilon$ Cyg (HIP 102488) are found to exhibit additional regular variations
with a much shorter period (~291 days). We intend to improve the orbital
solution of the $\epsilon$ Cyg system and attempt to identify the cause of the
nearly periodic shorter period variations, which might be due to an additional
substellar companion. We used precise RV measurements of the K-giant star
$\epsilon$ Cyg from Lick Observatory, in combination with a large set of RVs
collected more recently with the SONG telescope, as well as archival data sets.
Our Keplerian model to the RVs characterizes the orbit of the spectroscopic
binary to higher precision than achieved previously, resulting in a semi-major
axis of $a = 15.8 \mathrm{AU}$, an eccentricity of $e = 0.93$, and a minimum
mass of the secondary of $m \sin i = 0.265 M_\odot$. Additional short-period RV
variations closely resemble the signal of a Jupiter-mass planet orbiting the
evolved primary component with a period of $291 \mathrm{d}$, but the period and
amplitude of the putative orbit change strongly over time. Furthermore, in our
stability analysis of the system, no stable orbits could be found in a large
region around the best fit. Both of these findings deem a planetary cause of
the RV variations unlikely. Most of the investigated alternative scenarios,
such as an hierarchical triple or stellar spots, also fail to explain the
observed variability convincingly. Due to its very eccentric binary orbit, it
seems possible, however, that $\epsilon$ Cyg could be an extreme example of a
heartbeat system.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:59:25 GMT""}]","2021-03-31"
"2102.02000","David Sinclair D.Phil Oxon","Dr David Sinclair and Dr Christopher Town","A generalised feature for low level vision","12 pages 8 figure",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This papers presents a novel quantised transform (the Sinclair-Town or ST
transform for short) that subsumes the rolls of both edge-detector, MSER style
region detector and corner detector. The transform is similar to the $unsharp$
transform but the difference from the local mean is quantised to 3 values
(dark-neutral-light). The transform naturally leads to the definition of an
appropriate local scale. A range of methods for extracting shape features form
the transformed image are presented. The generalized feature provides a robust
basis for establishing correspondence between images. The transform readily
admits more complicated kernel behaviour including multi-scale and asymmetric
elements to prefer shorter scale or oriented local features.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:02:03 GMT""}]","2021-02-04"
"2102.02001","Orestis Georgiou","Orestis Georgiou, Constantinos Psomas, Eleni Demarchou, Ioannis
  Krikidis","LoRa Network Performance Under Ambient Energy Harvesting and Random
  Transmission Schemes","6 pages, 5 figures, proceedings of the IEEE ICC 2021",,,,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LoRa networks have been deployed all over the world and are a major enabling
wireless technology for the Internet of Things (IoT). Massive connectivity
applications such as smart metering, agriculture, and supply chain \& logistics
are most suitable for LoRa deployments due to their long range, low cost, and
low power features. Meanwhile, energy harvesting technologies that extract
energy from ambient sources have enabled the battery-less operation of many
small wireless sensors. This paper studies the merger of these two technologies
and mathematically models device and network performance using tools from
stochastic geometry and Markov analysis. To that end, we derive the
steady-state distribution of the capacitor voltage, the outage probability due
to co-spreading factor interference at the LoRa gateway, and propose adaptive
charging time schemes in order to mitigate energy outage events.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:02:34 GMT""}]","2021-02-04"
"2102.02002","Fan Yang","Fan Yang, Morteza Davari, Wenchao Wei, Ben Hermans, Roel Leus","Scheduling a single parallel-batching machine with non-identical job
  sizes and incompatible job families",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the scheduling of jobs on a single parallel-batching machine with
non-identical job sizes and incompatible job families. Jobs from the same
family have the same processing time and can be loaded into a batch, as long as
the batch size respects the machine capacity. The objective is to minimize the
total weighted completion time. The problem combines two classic combinatorial
problems, namely bin packing and single machine scheduling. We develop three
new mixed-integer linear-programming formulations, namely an assignment-based
formulation, a time-indexed formulation (TIF), and a set-partitioning
formulation (SPF). We also propose a column generation (CG) algorithm for the
SPF, which is the basis for a branch-and-price (B&P) algorithm and a CG-based
heuristic. We develop a preprocessing method to reduce the formulation size. A
heuristic framework based on proximity search is also developed using the TIF.
The SPF and B&P can solve instances with non-unit and unit job durations to
optimality with up to 80 and 150 jobs within reasonable runtime limits,
respectively. The proposed heuristics perform better than the methods from the
literature.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:02:59 GMT""}]","2021-02-04"
"2102.02003","Dayu Yan","D. Yu. Yan, M. Yang, C. X. Wang, P. B. Song, C. J. Yi, Y. G. Shi","Superconductivity in centrosymmetric topological superconductor
  candidate TaC","23 pages, 5 figures, 2 tables",,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We report the synthesis and physical properties of the single crystals of
TaC, which are proposed to hold topological band structure as a topological
superconductor (TSC) candidate. Magnetization, resistivity and specific heat
measurements are performed and indicate that TaC is bulk superconductor with
critical temperature of 10.3 K. TaC is a strongly coupled type-II
superconductor and the superconducting state can be well described by s-wave
Bardeen-Cooper-Schrieffer (BCS) theory with a single gap. The upper critical
field (Hc2) of TaC shows linear temperature dependence, which is quite
different from most conventional superconductors and isostructural NbC, which
is proposed to manifest topological nodal-loops or type-II Dirac points as well
as superconductivity. Our results suggest that TaC would be a new candidate for
further research of TSCs.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:06:31 GMT""}]","2021-02-04"
"2102.02004","Nicolas Chamel","Lo\""ic Perot, Nicolas Chamel","Role of dense matter in tidal deformations of inspiralling neutron stars
  and in gravitational waveform with unified equations of state","35 pages, 25 figures, accepted for publication in Physical Review C",,"10.1103/PhysRevC.103.025801",,"gr-qc astro-ph.HE nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The role of dense-matter properties in the tidal deformability of a cold
nonaccreted neutron star is further investigated. Using the set of
Brussels-Montreal unified equations of state, we have computed the
gravitoelectric Love numbers $k_\ell$ and the gravitomagnetic Love numbers
$j_\ell$ up to $\ell=5$. Their relative importance and their sensitivity to the
symmetry energy and the neutron-matter stiffness are numerically assessed.
Their impact on the phase of the gravitational-wave signal emitted by binary
neutron star inspirals is also discussed.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:07:08 GMT""}]","2021-02-24"
"2102.02005","Lorenzo Berlincioni","My Kieu, Lorenzo Berlincioni, Leonardo Galteri, Marco Bertini, Andrew
  D. Bagdanov, Alberto Del Bimbo","Robust pedestrian detection in thermal imagery using synthesized images","Accepted at ICPR2020",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we propose a method for improving pedestrian detection in the
thermal domain using two stages: first, a generative data augmentation approach
is used, then a domain adaptation method using generated data adapts an RGB
pedestrian detector. Our model, based on the Least-Squares Generative
Adversarial Network, is trained to synthesize realistic thermal versions of
input RGB images which are then used to augment the limited amount of labeled
thermal pedestrian images available for training. We apply our generative data
augmentation strategy in order to adapt a pretrained YOLOv3 pedestrian detector
to detection in the thermal-only domain. Experimental results demonstrate the
effectiveness of our approach: using less than 50\% of available real thermal
training data, and relying on synthesized data generated by our model in the
domain adaptation phase, our detector achieves state-of-the-art results on the
KAIST Multispectral Pedestrian Detection Benchmark; even if more real thermal
data is available adding GAN generated images to the training data results in
improved performance, thus showing that these images act as an effective form
of data augmentation. To the best of our knowledge, our detector achieves the
best single-modality detection results on KAIST with respect to the
state-of-the-art.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:08:31 GMT""}]","2021-02-04"
"2102.02006","Andrzej Piotr K\k{a}dzielawa","Dominik Legut, Andrzej P. K\k{a}dzielawa, Petr P\'anek, Krist\'yna
  Markov\'a, Petra V\'a\v{n}ov\'a, Kate\v{r}ina Kone\v{c}n\'a, and \v{S}\'arka
  Langov\'a","Inhibition of steel corrosion with imidazolium-based compounds --
  experimental and theoretical study","19 pages, 18 figures, 9 tables","Corrosion Science 191, 109716 (2021)","10.1016/j.corsci.2021.109716",,"physics.chem-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work aims to investigate the corrosion inhibition of the mild steel in
the 1 M HCl solution by 1-octyl-3-methylimidazolium hydrogen sulphate
1-butyl-3-methylimidazolium hydrogen sulphate, and 1-octyl-3-methylimidazolium
chloride, using electrochemical, weight loss, and surface analysis methods as
well as the full quantum-mechanical treatment. Polarization measurements prove
that studied compounds are mixed-type inhibitors with a predominantly anodic
reaction. The inhibition efficiency obtained from the polarization curves is
about 80-92% for all of the 1-octyl-3-methylimidazolium salts with a
concentration higher than 0.005 mol/l, while it is much lower for
1-butyl-3-methylimidazolium hydrogen sulphate. The values measured in the
weight loss experiments (after seven days) are to some extent higher (reaching
up to 98% efficiency). Furthermore, we have shown that the influence of the
alkyl chain length on the inhibition efficiency is much larger than that of the
anion type. Furthermore, we obtain a realistic model of a single molecule on
iron surface Fe(110) by applying the Density Functional Theory calculations. We
use the state-of-the-art computational approach, including the meta-GGA
strongly-constrained and appropriately normed semilocal density functional to
model the electronic structure properties of both free and bounded-to-surface
molecules of 1-butyl-, 1-hexyl-, and 1-octyl-3-methylimizadolium bromide,
chloride, and hydrogen sulphate. From the calculations we extract, the
HOMO/LUMO gap, hardness, electronegativity, and charge transfer of electrons
from/to molecules-in-question. It supports the experimental findings and
explains the influence of the alkyl chain length and the functional group on
the inhibition process.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:09:52 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 17:05:32 GMT""}]","2021-08-02"
"2102.02007","Eteri Gelagutashvili","E. Gelagutashvili, N.Bagdavadze, A.Gongadze, M.Gogebashvili,
  N.Ivanishvili","Effect of Ag(I), Ni(II), Zn(II) ions on Irradiated Spirulina platensis","8 pages,0 figures",,,,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Combined effects of 137Cs gamma irradiation and heavy metal ions Ni(II),
Zn(II), Ag(I) on Spirulina platensis cells using UV-VIS spectrometry after
three times irradiation and recultivation were discussed.
  It was shown, that possible use of gamma irradiation together with Ni(II) and
Zn(II) ions does not change nature of interaction of these metal ions on
Spirulina platensis. Whereas in contrast to the ions Ni (II) and Zn (II) for
silver ions, an increase in intensity is observed in both the irradiated and
non-irradiated states. The combined effects of ionizing radiation and other
stressors such is silver ions for Spirulina platensis exhibit synergetic
effects for C-phycocyanin as a stimulatory agent to raise the contents of it.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:20:49 GMT""}]","2021-02-04"
"2102.02008","Ana Paula Luz","B. P. Bezerra, A. P. Luz, V. C. Pandolfelli","Novel drying additives and their evaluation for self-flowing refractory
  castables",,"Ceramics International46 [3] (2020) 3209-3217","10.1016/j.ceramint.2019.10.025",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The drying step of dense refractory castables containing hydraulic binders is
a critical process, which usually requires using slow heating rates due to the
high explosion trend of such materials during their first thermal treatment.
Thus, this work investigated the performance of alternative additives to induce
faster and safer drying of self-flowing high-alumina refractory castables
bonded with calcium aluminate cement (CAC) or hydratable alumina (HA). The
following materials were analyzed for this purpose: polymeric fibers, a
permeability enhancing compound (RefPac MIPORE 20) and an organic additive
(aluminum salt of 2-hydroxypropanoic acid). The drying behavior and explosion
resistance of the cured samples were evaluated when subjecting the prepared
castables to heating rates of 2, 5 or 20C/min and the obtained data were then
correlated to the potential of the drying agents to improve the permeability
and mechanical strength level of the refractories at different temperatures.
The collected results attested that the selected additives were more efficient
in optimizing the drying behavior of the CAC-bonded compositions, whereas the
HA-containing castables performed better when the aluminum-based salt was
blended with a small amount of CAC (0.5 wt.%), which changed the binders
hydration reaction sequence and optimized the permeability level of the
resulting microstructure. Consequently, some of the designed compositions
evaluated in this work showed improved drying behavior and no explosion was
observed even during the tests carried out under a high heating rate (20C/min).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:22:11 GMT""}]","2021-02-04"
"2102.02009","Tanvir Alam","Tanvir Alam, Jens Schneider","Social Network Analysis of Hadith Narrators from Sahih Bukhari","Social Network Analysis of Hadith Narrators from Sahih Bukhari",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  The ahadith, prophetic traditions for the Muslims around the world, are
narrations originating from the sayings and the deeds of Prophet Muhammad
(pbuh). They are considered one of the fundamental sources of Islamic
legislation along with the Quran. The list of persons involved in the narration
of each hadith is carefully scrutinized by scholars studying the hadith, with
respect to their reputation and authenticity of the hadith. This is due to the
its legislative importance in Islamic principles. There were many narrators who
contributed to this responsibility of preserving prophetic narrations over the
centuries. But to date, no systematic and comprehensive study, based on the
social network, has been adapted to understand the contribution of early hadith
narrators and the propagation of hadith across generations. In this study, we
represented the chain of narrators of the hadith collection from Sahih Bukhari
as a social graph. Based on social network analysis (SNA) on this graph, we
found that the network of narrators is a scale-free network. We identified a
list of influential narrators from the companions as well as the narrators from
the second and third-generation who contribute significantly in the propagation
of hadith collected in Sahih Bukhari. We discovered sixteen communities from
the narrators of Sahih Bukhari. In each of these communities, there are other
narrators who contributed significantly to the propagation of prophetic
narrations. We also found that most narrators were centered in Makkah and
Madinah in the era of companions and, then, gradually the center of hadith
narrators shifted towards Kufa, Baghdad and central Asia over a period of time.
To the best of our knowledge, this the first comprehensive and systematic study
based on SNA, representing the narrators as a social graph to analyze their
contribution to the preservation and propagation of hadith.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:24:32 GMT""}]","2021-02-04"
"2102.02010","Timothy Fong Nam Chan","Timothy F. N. Chan, Daniel Kral, Bojan Mohar, David R. Wood","Inducibility and universality for trees","31 pages, 8 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We answer three questions posed by Bubeck and Linial on the limit densities
of subtrees in trees. We prove there exist positive $\varepsilon_1$ and
$\varepsilon_2$ such that every tree that is neither a path nor a star has
inducibility at most $1-\varepsilon_1$, where the inducibility of a tree $T$ is
defined as the maximum limit density of $T$, and that there are infinitely many
trees with inducibility at least $\varepsilon_2$. Finally, we construct a
universal sequence of trees; that is, a sequence in which the limit density of
any tree is positive.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:25:00 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 21:45:30 GMT""}]","2022-07-01"
"2102.02011","Dongsheng Ding","Ying-Hao Ye, Lei Zeng, Yi-Chen Yu, Ming-Xin Dong, En-Ze Li, Wei-Hang
  Zhang, Zong-Kai Liu, Li-Hua Zhang, Guang-Can Guo, Dong-Sheng Ding and Bao-Sen
  Shi","Synchronized resistance to inhomogeneous magnetic field-induced
  dephasing of an image stored in a cold atomic ensemble","5 figures","Phys. Rev. A 103, 053316 (2021)","10.1103/PhysRevA.103.053316",,"quant-ph physics.atom-ph physics.optics","http://creativecommons.org/licenses/by-sa/4.0/","  Long-lived storage of arbitrary transverse multimodes is important for
establishing a high-channel-capacity quantum network. Most of the pioneering
works focused on atomic diffusion as the dominant impact on the retrieved
pattern in an atom-based memory. In this work, we demonstrate that the
unsynchronized Larmor precession of atoms in the inhomogeneous magnetic field
dominates the distortion of the pattern stored in a cold-atom-based memory. We
find that this distortion effect can be eliminated by applying a strong uniform
polarization magnetic field. By preparing atoms in magnetically insensitive
states, the destructive interference between different spin-wave components is
diminished, and the stored localized patterns are synchronized further in a
single spin-wave component; then, an obvious enhancement in preserving patterns
for a long time is obtained. The reported results are very promising for
studying transverse multimode decoherence in storage and high-dimensional
quantum networks in the future.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:25:53 GMT""}]","2021-05-26"
"2102.02012","Eteri Gelagutashvili","E.Gelagutashvili, O.Rcheulishvili, A.Rcheulishvili","Effect of Na(I) on Bioavailability for Cr(VI)_ and Cr(III)_ Arthrobacter
  species","5 pages, 0 figures",,,,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  The biosorption of Cr(VI)_ and Cr(III)_ of Arthrobacter species (Arthrobacter
globiformis and Arthrobacter oxidas) was studied application dialysis and
atomic absorption analysis at various Na(I) concentrations. Is was shown
significant difference between the binding constants as for Cr(VI)_ and
Cr(III)_Arthrobacter oxidas, as well as Cr(VI)_ and Cr(III)_ Arthrobacter
globiformis at various Na(I) concentrations.
  It was shown, that bioavailability increases in both cases with decreases
Na(I) concentration.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:26:49 GMT""}]","2021-02-04"
"2102.02013","Jonathan Klawitter","Steven Chaplick, Philipp Kindermann, Jonathan Klawitter, Ignaz Rutter,
  Alexander Wolff","Extending Partial Representations of Rectangular Duals with Given
  Contact Orientations","An earier version appeared in the Proceedings of CIAC 2021","Theoretical Computer Science, 919:66-74 (2022)","10.1016/j.tcs.2022.03.031",,"cs.CG cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A rectangular dual of a graph $G$ is a contact representation of $G$ by
axis-aligned rectangles such that (i)~no four rectangles share a point and
(ii)~the union of all rectangles is a rectangle. The partial representation
extension problem for rectangular duals asks whether a given partial
rectangular dual can be extended to a rectangular dual, that is, whether there
exists a rectangular dual where some vertices are represented by prescribed
rectangles. Combinatorially, a rectangular dual can be described by a regular
edge labeling (REL), which determines the orientations of the rectangle
contacts.
  We describe two approaches to solve the partial representation extension
problem for rectangular duals with given REL. On the one hand, we characterise
the RELs that admit an extension, which leads to a linear-time testing
algorithm. In the affirmative, we can construct an extension in linear time.
This partial representation extension problem can also be formulated as a
linear program (LP). We use this LP to solve the simultaneous representation
problem for the case of rectangular duals when each input graph is given
together with a REL.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:26:55 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 15:34:58 GMT""},{""version"":""v3"",""created"":""Mon, 8 Nov 2021 17:36:23 GMT""}]","2022-09-23"
"2102.02014","Alaa Ali","A. Ali and Wedad R. Alharbi","An investigation of planetary nebulae accompanying PG1159 central stars,
  based on Gaia DR2 measurements","9 pages, 2 figures",,"10.1088/1674-4527/21/6/151",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article discusses the physical and kinematical characteristics of
planetary nebulae accompanying PG1159 central stars. The study is based on the
parallax and proper motion measurements recently offered by Gaia space mission.
Two approaches were used to investigate the kinematical properties of the
sample. The results revealed that most of the studied nebulae arise from
progenitor stars of mass range; $0.9-1.75$\,M$_{\odot}$. Furthermore, they tend
to live within the Galactic thick-disk and moving with an average peculiar
velocity of $61.7\pm19.2$\,km\,s$^{-1}$ at a mean vertical height of $469\pm79$
pc. The locations of the PG1159 stars on the H-R diagram indicate that they
have an average final stellar mass and evolutionary age of
$0.58\pm0.08$\,M$_{\odot}$ and $25.5\pm5.3 \rm{x}10^3$ yr, respectively. We
found a good agreement between the mean evolutionary age of the PG1159 stars
and the mean dynamical age of their companion planetary nebulae ($28.0\pm6.4
\rm{x}10^3$ yr).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:31:45 GMT""}]","2021-08-18"
"2102.02015","Ho-Meoyng Choi","Ho-Meoyng Choi (Kyungpook National University)","Self-consistent light-front quark model analysis of $B\to D\ell\nu_\ell$
  transition form factors","10 pages, 3 figures, minor corrections in Sec. IV, version to appear
  in Phys. Rev. D","Phys. Rev. D 103, 073004 (2021)","10.1103/PhysRevD.103.073004",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the transition form factors $f_+(q^2)$ and $f_-(q^2)$ [or
$f_0(q^2)$] for the exclusive semileptonic $B\to D\ell\nu_\ell$ $(\ell=e,
\mu,\tau)$ decays in the standard light-front quark model (LFQM) based on the
LF quantization. The common belief is that while $f_+(q^2)$ can be obtained
without involving any treacherous contributions such as the zero mode and the
instantaneous contribution, $f_-(q^2)$ receives those treacherous contributions
since it involves at least two components of the current, e.g. $(J^+, J^-)$ or
$(J^+, {\bf J}_\perp)$. Contrary to the common belief, we show in the Drell-Yan
($q^+=0$) frame that $f_-(q^2)$ obtained from $(J^+, J^-)$ gives identical
result to $f_-(q^2)$ obtained from $(J^+, {\bf J}_\perp)$ without involving
such treacherous contributions in the standard LFQM. In our numerical
calculations, we obtain the form factors and branching ratios for $B\to
D\ell\nu_\ell$ $(\ell=e, \mu,\tau)$ and compare with the experimental data as
well as other theoretical model predictions. Our results for ${\rm Br}(B\to
D\ell\nu_\ell)$ show reasonable agreement with the experimental data except for
the semitauonic $B^0\to D^-\tau\nu_\tau$ decay. The ratio ${\cal
R}(D)=\frac{{\rm Br}(B\to D\tau\nu_\tau)}{{\rm Br}(B\to D\ell'\nu_{\ell'})}$
$(\ell'=e,\mu)$ is also estimated and compared with the experimental data as
well as other theoretical predictions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:33:41 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 03:58:55 GMT""}]","2021-04-28"
"2102.02016","Gholamali Aminian","Gholamali Aminian, Laura Toni, Miguel R. D. Rodrigues","Information-Theoretic Bounds on the Moments of the Generalization Error
  of Learning Algorithms","7 pages, 3 figures, to be published in ISIT 2021. Some typos are
  fixed in the new version. The Re'yni divergence results are added in the new
  version",,,,"cs.IT cs.LG math.IT stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  Generalization error bounds are critical to understanding the performance of
machine learning models. In this work, building upon a new bound of the
expected value of an arbitrary function of the population and empirical risk of
a learning algorithm, we offer a more refined analysis of the generalization
behaviour of a machine learning models based on a characterization of (bounds)
to their generalization error moments. We discuss how the proposed bounds --
which also encompass new bounds to the expected generalization error -- relate
to existing bounds in the literature. We also discuss how the proposed
generalization error moment bounds can be used to construct new generalization
error high-probability bounds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:38:00 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 23:39:01 GMT""}]","2021-05-07"
"2102.02017","Antonio Mastropaolo","Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader
  Palacio, Denys Poshyvanyk, Rocco Oliveto, Gabriele Bavota","Studying the Usage of Text-To-Text Transfer Transformer to Support
  Code-Related Tasks","Accepted to the 43rd International Conference on Software Engineering
  (ICSE 2021)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning (DL) techniques are gaining more and more attention in the
software engineering community. They have been used to support several
code-related tasks, such as automatic bug fixing and code comments generation.
Recent studies in the Natural Language Processing (NLP) field have shown that
the Text-To-Text Transfer Transformer (T5) architecture can achieve
state-of-the-art performance for a variety of NLP tasks. The basic idea behind
T5 is to first pre-train a model on a large and generic dataset using a
self-supervised task ( e.g: filling masked words in sentences). Once the model
is pre-trained, it is fine-tuned on smaller and specialized datasets, each one
related to a specific task ( e.g: language translation, sentence
classification). In this paper, we empirically investigate how the T5 model
performs when pre-trained and fine-tuned to support code-related tasks. We
pre-train a T5 model on a dataset composed of natural language English text and
source code. Then, we fine-tune such a model by reusing datasets used in four
previous works that used DL techniques to: (i) fix bugs, (ii) inject code
mutants, (iii) generate assert statements, and (iv) generate code comments. We
compared the performance of this single model with the results reported in the
four original papers proposing DL-based solutions for those four tasks. We show
that our T5 model, exploiting additional data for the self-supervised
pre-training phase, can achieve performance improvements over the four
baselines.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:41:36 GMT""}]","2021-02-04"
"2102.02018","Christian K\""onig","Christian K\""onig, James C. Greer, and Stephen Fahy","Effect of strain and many-body corrections on the band inversions and
  topology of bismuth",,"Phys. Rev. B 104, 035127 (2021)","10.1103/PhysRevB.104.035127",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electronic band structure of Bi is calculated using state of the art
electronic structure methods, including density functional theory and
G$_0$W$_0$ quasiparticle approximations. The delicate ordering of states at the
L point of the Brillouin zone, which determines the topological character of
the electronic bands, is investigated in detail. The effect on the bands of
strain, changing the structural parameters of the rhombohedral crystal
structure, is shown to be important in determining this ordering and the
resulting topological character.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:41:43 GMT""},{""version"":""v2"",""created"":""Thu, 25 Aug 2022 18:31:30 GMT""}]","2022-08-29"
"2102.02019","Jack King","Jack King and Steven Lind","High-order simulations of isothermal flows using the local anisotropic
  basis function method (LABFM)","28pages,20 figs, submitted to J. Comput. Phys. Feb 2021, accepted
  Sept 2021",,"10.1016/j.jcp.2021.110760",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Mesh-free methods have significant potential for simulations of flows in
complex geometries, with the difficulties of domain discretisation greatly
reduced. However, many mesh-free methods are limited to low order accuracy. In
order to compete with conventional mesh-based methods, high order accuracy is
essential. The Local Anisotropic Basis Function Method (LABFM) is a mesh-free
method introduced in King et al., J. Comput. Phys. 415:109549 (2020), which
enables the construction of highly accurate difference operators on disordered
node discretisations. Here, we introduce a number of developments to LABFM, in
the areas of basis function construction, stencil optimisation, stabilisation,
variable resolution, and high order boundary conditions. With these
developments, direct numerical simulations of the Navier Stokes equations are
possible at extremely high order (up to 10th order in characteristic node
spacing internally). We numerically solve the isothermal compressible Navier
Stokes equations for a range of geometries: periodic and channel flows, flows
past a cylinder, and porous media. Excellent agreement is seen with analytical
solutions, published numerical results (using a spectral element method), and
experiments. The potential of the method for direct numerical simulations in
complex geometries is demonstrated with simulations of subsonic and transonic
flows through an inhomogeneous porous media at pore Reynolds numbers up to
Re=968.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:42:35 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 10:45:34 GMT""}]","2021-11-10"
"2102.02020","Shao-Jiang Wang","Rong-Gen Cai, Zong-Kuan Guo, Li Li, Shao-Jiang Wang, Wang-Wei Yu","Chameleon dark energy can resolve the Hubble tension","v4, to match the published version in Physical Review D as a Letter","Phys. Rev. D 103, 121302 (2021)","10.1103/PhysRevD.103.L121302",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Values of the Hubble constant between the direct measurements from various
independent local observations and that inferred from the cosmic microwave
background with the $\Lambda$-cold-dark-matter model are in tension with
persistent significance. We propose a late-time inhomogeneous resolution
suggesting that a chameleon field coupled to a local overdensity of matter
could be trapped at a higher potential energy density as an effective
cosmological constant driving the local expansion rate faster than that of the
background with lower matter density. We illustrate this mechanism in a toy
model in which a region with only $20\%$ overdensity of matter is sufficient to
resolve the Hubble tension, and the Hubble constant measured by the local
distance ladders could be accommodated by the chameleon coupled to the observed
overdensities from the large-scale structure surveys.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:44:08 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 06:37:34 GMT""},{""version"":""v3"",""created"":""Fri, 7 May 2021 03:32:21 GMT""},{""version"":""v4"",""created"":""Sun, 6 Jun 2021 05:08:23 GMT""}]","2021-06-09"
"2102.02021","A. N. Ivanov","A. N. Ivanov, R. H\""ollwieser, N. I. Troitskaya, M. Wellenzohn, Ya. A.
  Berdnikov","On the structure of the correlation coefficients S(E_e) and U(E_e) of
  the neutron beta decay","13 pages, the manuscript is revised. arXiv admin note: text overlap
  with arXiv:2101.01014","Phys. Rev. C 104, 025503 (2021)","10.1103/PhysRevC.104.025503",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the standard effective V - A theory of low-energy weak interactions (i.e.
in the Standard Model (SM)) we analyze the structure of the correlation
coefficients S(E_e) and U(E_e), where E_e is the electron energy. These
correlation coefficients were introduced to the electron-energy and angular
distribution of the neutron beta decay by Ebel and Feldman ( Nucl. Phys. 4, 213
(1957)) in addition to the set of correlation coefficients proposed by Jackson
et al. (Phys. Rev. 106, 517 (1957)). The correlation coefficients $S(E_e)$ and
$U(E_e)$ are induced by simultaneous correlations of the neutron and electron
spins and electron and antineutrino 3-momenta. These correlation structures do
no violate discrete P, C and T symmetries. We analyze the contributions of the
radiative corrections of order O(alpha/pi), taken to leading order in the large
nucleon mass m_N expansion, and corrections of order O(E_e/m_N), caused by weak
magnetism and proton recoil. In addition to the obtained SM corrections we
calculate the contributions of interactions beyond the SM (BSM contributions)
in terms of the phenomenological coupling constants of BSM interactions by
Jackson et al. (Phys. Rev. 106, 517 (1957)) and the second class currents by
Weinberg (Phys. Rev. 112, 1375 (1958)).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:45:12 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 07:43:04 GMT""}]","2021-08-18"
"2102.02022","Orestis Georgiou","Orestis Georgiou, Constantinos Psomas, Christodoulos Skouroumounis,
  Ioannis Krikidis","Optimal Non-Uniform Deployments of LoRa Networks","5 pages, 7 figures",,"10.1109/LWC.2020.3008103",,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LoRa wireless technology is an increasingly prominent solution for massive
connectivity and the Internet of Things. Stochastic geometry and numerical
analysis of LoRa networks usually consider uniform end-device deployments. Real
deployments however will often be non-uniform, for example due to mobility.
This letter mathematically investigates how non-uniform deployments affect
network coverage and suggest optimal deployment strategies and uplink random
access transmission schemes. We find that concave deployments of LoRa
end-devices with a sub-linear spread of random access inter-transmission times
provide optimal network coverage performance.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:46:25 GMT""}]","2021-02-04"
"2102.02023","Samuel Roth","Jaroslav Brad\'ik and Samuel Roth","Typical behaviour of random interval homeomorphisms",,"Published online in Qualitative Theory of Dynamical Systems, 2021","10.1007/s12346-021-00509-2",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the typical behaviour of random dynamical systems of
order-preserving interval homeomorphisms with a positive Lyapunov exponent
condition at the endpoints. Our study removes any requirement for continuous
differentiability save the existence of finite derivatives of the
homeomorphisms at the endpoints of the interval. We construct a suitable Baire
space structure for this class of systems. Generically within our Baire space,
we show that the stationary measure is singular with respect to the Lebesgue
measure, but has full support on $[0,1]$. This provides an answer to a question
raised by Alsed\`a and Misiurewicz.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:51:53 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 12:03:58 GMT""}]","2021-08-19"
"2102.02024","Sebastian Cmentowski","Sebastian Cmentowski, Andrey Krekhov, Andr\'e Zenner, Daniel
  Kucharski, Jens Kr\""uger","Towards Sneaking as a Playful Input Modality for Virtual Environments","to appear: accepted IEEE VR 2021 conference paper",,"10.1109/VR50410.2021.00071",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using virtual reality setups, users can fade out of their surroundings and
dive fully into a thrilling and appealing virtual environment. The success of
such immersive experiences depends heavily on natural and engaging interactions
with the virtual world. As developers tend to focus on intuitive hand controls,
other aspects of the broad range of full-body capabilities are easily left
vacant. One repeatedly overlooked input modality is the user's gait. Even
though users may walk physically to explore the environment, it usually does
not matter how they move. However, gait-based interactions, using the variety
of information contained in human gait, could offer interesting benefits for
immersive experiences. For instance, stealth VR-games could profit from this
additional range of interaction fidelity in the form of a sneaking-based input
modality.
  In our work, we explore the potential of sneaking as a playful input modality
for virtual environments. Therefore, we discuss possible sneaking-based
gameplay mechanisms and develop three technical approaches, including precise
foot-tracking and two abstraction levels. Our evaluation reveals the potential
of sneaking-based interactions in IVEs, offering unique challenges and
thrilling gameplay. For these interactions, precise tracking of individual
footsteps is unnecessary, as a more abstract approach focusing on the players'
intention offers the same experience while providing better comprehensible
feedback. Based on these findings, we discuss the broader potential and
individual strengths of our gait-centered interactions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:55:28 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 08:21:44 GMT""}]","2021-03-30"
"2102.02025","Antonio Calcagn\`i","Antonio Calcagn\`i","fIRTree: An Item Response Theory modeling of fuzzy rating data",,"IFSA-EUSFLAT 2021, Atlantis Studies in Uncertainty Modelling (vol.
  3), 2021, 471-479","10.2991/asum.k.210827.062",,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution we describe a novel procedure to represent fuzziness in
rating scales in terms of fuzzy numbers. Following the rationale of fuzzy
conversion scale, we adopted a two-step procedure based on a psychometric model
(i.e., Item Response Theory-based tree) to represent the process of answer
survey questions. This provides a coherent context where fuzzy numbers, and the
related fuzziness, can be interpreted in terms of decision uncertainty that
usually affects the rater's response process. We reported results from a
simulation study and an empirical application to highlight the characteristics
and properties of the proposed approach.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:59:50 GMT""}]","2021-12-10"
"2102.02026","Rucha Joshi","Rucha Bhalchandra Joshi and Subhankar Mishra","Learning Graph Representations",,"Principles of Social Networking: The New Horizon and Emerging
  Challenges (PSN 2020)",,,"cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Social and information networks are gaining huge popularity recently due to
their various applications. Knowledge representation through graphs in the form
of nodes and edges should preserve as many characteristics of the original data
as possible. Some of the interesting and useful applications on these graphs
are graph classification, node classification, link prediction, etc. The Graph
Neural Networks have evolved over the last few years. Graph Neural Networks
(GNNs) are efficient ways to get insight into large and dynamic graph datasets
capturing relationships among billions of entities also known as knowledge
graphs.
  In this paper, we discuss the graph convolutional neural networks graph
autoencoders and spatio-temporal graph neural networks. The representations of
the graph in lower dimensions can be learned using these methods. The
representations in lower dimensions can be used further for downstream machine
learning tasks.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:07:55 GMT""}]","2021-02-08"
"2102.02027","Rajarshi Sen","Rajarshi Sen and Sarang Pendharker (Department of Electronics and
  Electrical Communication Engineering, Indian Institute of Technology
  Kharagpur, Kharagpur, West Bengal, India)","Spin-governed topological surfaces and broken spin-momentum locking in a
  gyromagnetic medium","13 pages, 13 figures",,"10.1103/PhysRevA.105.023528",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Topology of isofrequency surfaces plays a crucial role in characterizing the
interaction of an electromagnetic wave with a medium. Thus, engineering the
topology in complex media is leading to novel applications, ranging from
super-resolution microscopy with hyperbolic metamaterials to sub-wavelength
waveguiding structures. Here, we investigate the spin-governed nature of
isofrequency surfaces in a general gyromagnetic medium. We show that gyrotropy
also plays an important role in the topological properties of a medium, along
with the anisotropic permeability and permittivity. Even though the topology
primarily depends on permeability, gyrotropy can suppress or support the
existence of certain topological surfaces. We reveal the connection between the
gyrotropy imposed constraints and the photonic spin-profile of the topological
surfaces. The spin-profile along the isofrequency surface is locked to the
material, resulting in the non-reciprocity and breaking of the spin-momentum
locking in the gyromagnetic medium. Further, we show that the conflict between
spin-momentum locking and material locked spin leads to asymmetric mode profile
and gyrotropy-induced cutoff in guided wave structures. Our work provides
important insights into the underlying link between topology, spin, and
non-reciprocity in gyrotropic media.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:13:49 GMT""}]","2022-03-01"
"2102.02028","Francesc Llu\'is","Francesc Llu\'is, Vasileios Chatziioannou, Alex Hofmann","Music source separation conditioned on 3D point clouds",,,,,"cs.SD cs.CV eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, significant progress has been made in audio source separation by
the application of deep learning techniques. Current methods that combine both
audio and visual information use 2D representations such as images to guide the
separation process. However, in order to (re)-create acoustically correct
scenes for 3D virtual/augmented reality applications from recordings of real
music ensembles, detailed information about each sound source in the 3D
environment is required. This demand, together with the proliferation of 3D
visual acquisition systems like LiDAR or rgb-depth cameras, stimulates the
creation of models that can guide the audio separation using 3D visual
information. This paper proposes a multi-modal deep learning model to perform
music source separation conditioned on 3D point clouds of music performance
recordings. This model extracts visual features using 3D sparse convolutions,
while audio features are extracted using dense convolutions. A fusion module
combines the extracted features to finally perform the audio source separation.
It is shown, that the presented model can distinguish the musical instruments
from a single 3D point cloud frame, and perform source separation qualitatively
similar to a reference case, where manually assigned instrument labels are
provided.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:18:35 GMT""}]","2021-02-04"
"2102.02029","Dan Garber","Dan Garber, Noam Wolf","Frank-Wolfe with a Nearest Extreme Point Oracle","Appeared in Conference on Learning Theory (COLT), 2021",,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider variants of the classical Frank-Wolfe algorithm for constrained
smooth convex minimization, that instead of access to the standard oracle for
minimizing a linear function over the feasible set, have access to an oracle
that can find an extreme point of the feasible set that is closest in Euclidean
distance to a given vector. We first show that for many feasible sets of
interest, such an oracle can be implemented with the same complexity as the
standard linear optimization oracle. We then show that with such an oracle we
can design new Frank-Wolfe variants which enjoy significantly improved
complexity bounds in case the set of optimal solutions lies in the convex hull
of a subset of extreme points with small diameter (e.g., a low-dimensional face
of a polytope). In particular, for many $0\text{--}1$ polytopes, under
quadratic growth and strict complementarity conditions, we obtain the first
linearly convergent variant with rate that depends only on the dimension of the
optimal face and not on the ambient dimension.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:20:24 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 13:56:42 GMT""}]","2022-02-10"
"2102.02030","Dipak Debnath","Riya Bhowmick, Dipak Debnath, Kaushik Chatterjee, Shreeram Nagarkoti,
  Sandip Kumar Chakrabarti, Ritabrata Sarkar, Debjit Chatterjee, and Arghajit
  Jana","Relation Between Quiescence and Outbursting Properties of GX 339-4","13 Pages, 6 Figues, 2 Tables (Accepted for Publication in ApJ)",,"10.3847/1538-4357/abe134",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic black hole candidate (BHC) GX~339-4 underwent several outbursting
phases in the past two and a half decades at irregular intervals of $2-3$
years. Nature of these outbursts in terms of the duration, number of peaks,
maximum peak intensity, etc. varies. We present a possible physical reason
behind the variation of outbursts. From a physical point of view, if the supply
of matter from the companion is roughly constant, the total energy release in
an outburst is expected to be proportional to the quiescence period prior to
the outburst when the matter is accumulated. We use archival data of RXTE/ASM
from January 1996 to June 2011, and MAXI/GSC from August 2009 to July 2020
data. Initial five outbursts of GX~339-4 between 1997 and 2011 were observed by
ASM and showed a good linear relation between the accumulation period and the
amount of energy released in each outburst, but the outbursts after 2013
behaved quite differently. The 2013, $2017-18$, and $2018-19$ outbursts were of
short duration, and incomplete or `failed' in nature. We suggest that the
matter accumulated during the quiescence periods prior to these outbursts were
not cleared through accretion due to lack of viscosity. The leftover matter was
cleared in the immediate next outbursts. Our study thus sheds light on long
term accretion dynamics in outbursting sources.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:23:27 GMT""}]","2021-04-14"
"2102.02031","Antonio Galbis","Antonio Galbis","Norm estimates for selfadjoint Toeplitz operators on the Fock space",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An estimate for the norm of selfadjoint Toeplitz operators with a radial,
bounded and integrable symbol is obtained. This emphasizes the fact that the
norm of such operator is strictly less than the supremum norm of the symbol.
Consequences for time-frequency localization operators are also given.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:25:20 GMT""}]","2021-02-04"
"2102.02032","Beate Heinemann","Halina Abramowicz, Uwe Hernandez Acosta, Massimo Altarelli, Ralph
  Assmann, Zhaoyu Bai, Ties Behnke, Yan Benhammou, Thomas Blackburn, Stewart
  Boogert, Oleksandr Borysov, Maryna Borysova, Reinhard Brinkmann, Marco
  Bruschi, Florian Burkart, Karsten B\""u{\ss}er, Niall Cavanagh, Oz Davidi,
  Winfried Decking, Umberto Dosselli, Nina Elkina, Alexander Fedotov, Miroslaw
  Firlej, Tomasz Fiutowski, Kyle Fleck, Mikhail Gostkin, Christophe Grojean,
  John Andrew Hallford, Harsh Harsh, Anthony Hartin, Beate Heinemann, Tom
  Heinzl, Louis Helary, Marius Hoffmann, Shan Huang, Xinhe Huang, Marek Idzik,
  Anton Ilderton, Ruth Magdalena Jacobs, Burkhard Kaempfer, Ben King, Hlib
  Lakhno, Assaf Levanon, Aharon Levy, Itamar Levy, Jenny List, Wolfgang
  Lohmann, Teng Ma, Alexander John Macleod, Victor Malka, Federico Meloni,
  Arseny Mironov, Mauro Morandin, Jakub Moron, Evgueni Negodin, Gilad Perez,
  Ishay Pomerantz, Roman Poeschl, Rajendra Prasad, Fabien Quere, Andreas
  Ringwald, Christian Roedel, Sergey Rykovanov, Felipe Salgado, Arka Santra,
  Gianluca Sarri, Alexander Saevert, Antonio Sbrizzi, Stefan Schmitt, Ulrich
  Schramm, Sergej Schuwalow, Daniel Seipt, Leila Shaimerdenova, Mykyta
  Shchedrolosiev, Maksim Skakunov, Yotam Soreq, Matthew Streeter, Krzysztof
  Swientek, Noam Tal Hod, Suo Tang, Thomas Teter, Daniel Thoden, Alexander
  Titov, Oleg Tolbanov, Greger Torgrimsson, Anton Tyazhev, Matthew Wing, Marco
  Zanetti, Andrei Zarubin, Karl Zeil, Matt Zepf, and Aleksey Zhemchukov","Conceptual Design Report for the LUXE Experiment",,,"10.1140/epjs/s11734-021-00249-z","DESY 21-016","hep-ex hep-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  This Conceptual Design Report describes LUXE (Laser Und XFEL Experiment), an
experimental campaign that aims to combine the high-quality and high-energy
electron beam of the European XFEL with a powerful laser to explore the
uncharted terrain of quantum electrodynamics characterised by both high energy
and high intensity. We will reach this hitherto inaccessible regime of quantum
physics by analysing high-energy electron-photon and photon-photon interactions
in the extreme environment provided by an intense laser focus. The physics
background and its relevance are presented in the science case which in turn
leads to, and justifies, the ensuing plan for all aspects of the experiment:
Our choice of experimental parameters allows (i) effective field strengths to
be probed at and beyond the Schwinger limit and (ii) a precision to be achieved
that permits a detailed comparison of the measured data with calculations. In
addition, the high photon flux predicted will enable a sensitive search for new
physics beyond the Standard Model. The initial phase of the experiment will
employ an existing 40 TW laser, whereas the second phase will utilise an
upgraded laser power of 350 TW. All expectations regarding the performance of
the experimental set-up as well as the expected physics results are based on
detailed numerical simulations throughout.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:27:10 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 19:17:12 GMT""}]","2021-09-22"
"2102.02033","Yuhang Ding","Yuhang Ding, Xin Yu, Yi Yang","Modeling the Probabilistic Distribution of Unlabeled Data forOne-shot
  Medical Image Segmentation","AAAI 2021",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing image segmentation networks mainly leverage large-scale labeled
datasets to attain high accuracy. However, labeling medical images is very
expensive since it requires sophisticated expert knowledge. Thus, it is more
desirable to employ only a few labeled data in pursuing high segmentation
performance. In this paper, we develop a data augmentation method for one-shot
brain magnetic resonance imaging (MRI) image segmentation which exploits only
one labeled MRI image (named atlas) and a few unlabeled images. In particular,
we propose to learn the probability distributions of deformations (including
shapes and intensities) of different unlabeled MRI images with respect to the
atlas via 3D variational autoencoders (VAEs). In this manner, our method is
able to exploit the learned distributions of image deformations to generate new
authentic brain MRI images, and the number of generated samples will be
sufficient to train a deep segmentation network. Furthermore, we introduce a
new standard segmentation benchmark to evaluate the generalization performance
of a segmentation network through a cross-dataset setting (collected from
different sources). Extensive experiments demonstrate that our method
outperforms the state-of-the-art one-shot medical segmentation methods. Our
code has been released at
https://github.com/dyh127/Modeling-the-Probabilistic-Distribution-of-Unlabeled-Data.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:28:04 GMT""}]","2021-02-04"
"2102.02034","Li Huang","Li Huang and Haiyan Lu","Collapse of quasiparticle multiplets and $5f$ itinerant-localized
  crossovers in cubic phase Pu$_{3}$Ga","22 pages, 7 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The physical properties of plutonium and plutonium-based intermetallic
compounds are extremely sensitive to temperature, pressure, and chemical
alloying. A celebrated example is the high-temperature $\delta$ phase
plutonium, which can be stabilized at room temperature by doping it with a few
percent trivalent metal impurities, such as gallium or aluminum. The cubic
phase Pu$_{3}$Ga, one of the plutonium-gallium intermetallic compounds, plays a
key role in understanding the phase stability and phase transformation of the
plutonium-gallium system. Its electronic structure might be essential to figure
out the underlying mechanism that stabilizes the $\delta$ phase
plutonium-gallium alloy. In the present work, we studied the
temperature-dependent correlated electronic states of cubic phase Pu$_{3}$Ga by
means of a combination of the density functional theory and the embedded
dynamical mean-field theory. We identified orbital selective 5$f$
itinerant-localized (coherent-incoherent) crossovers which could occur upon
temperature. Actually, there exist two well-separated electronic coherent
temperatures. The higher one is for the $5f_{5/2}$ state
[$T_{\text{coh}}(5f_{5/2}) \approx 700$ K], while the lower one is for the
$5f_{7/2}$ state [$T_{\text{coh}}(5f_{7/2}) \approx 100$ K]. In addition, the
quasiparticle multiples which originate from the many-body transitions among
the $5f^{4}$, $5f^{5}$, and $5f^{6}$ electronic configurations, decay
gradually. The hybridizations between the localized 5$f$ bands and conduction
bands are subdued by high temperature. Consequently, the Fermi surface topology
is changed, which signals a temperature-driven electronic Lifshitz transition.
Finally, the calculated linear specific heat coefficient $\gamma$ is
approximately 112 mJ / (mol K$^2$) at $T = 80$ K.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:30:48 GMT""}]","2021-02-04"
"2102.02035","Koen Bertels","K. Bertels, A. Sarkar, A. Krol, R. Budhrani, J. Samadi, E. Geoffroy,
  J. Matos, R. Abreu, G. Gielen, I. Ashraf","Quantum Accelerator Stack: A Research Roadmap","39 pages. arXiv admin note: text overlap with arXiv:1903.09575",,,,"quant-ph cs.AR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper presents the definition and implementation of a quantum computer
architecture to enable creating a new computational device - a quantum computer
as an accelerator In this paper, we present explicitly the idea of a quantum
accelerator which contains the full stack of the layers of an accelerator. Such
a stack starts at the highest level describing the target application of the
accelerator. Important to realise is that qubits are defined as perfect qubits,
implying they do not decohere and perform good quantum gate operations. The
next layer abstracts the quantum logic outlining the algorithm that is to be
executed on the quantum accelerator. In our case, the logic is expressed in the
universal quantum-classical hybrid computation language developed in the group,
called OpenQL. We also have to start thinking about how to verify, validate and
test the quantum software such that the compiler generates a correct version of
the quantum circuit. The OpenQL compiler translates the program to a common
assembly language, called cQASM. We need to develop a quantum operating system
that manages all the hardware of the micro-architecture. The layer below the
micro-architecture is responsible of the mapping and routing of the qubits on
the topology such that the nearest-neighbour-constraint can be be respected. At
any moment in the future when we are capable of generating multiple good
qubits, the compiler can convert the cQASM to generate the eQASM, which is
executable on a particular experimental device incorporating the
platform-specific parameters. This way, we are able to distinguish clearly the
experimental research towards better qubits, and the industrial and societal
applications that need to be developed and executed on a quantum device.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:33:12 GMT""},{""version"":""v2"",""created"":""Sun, 21 Mar 2021 08:26:53 GMT""},{""version"":""v3"",""created"":""Sun, 28 Mar 2021 20:11:57 GMT""},{""version"":""v4"",""created"":""Mon, 17 May 2021 12:17:47 GMT""}]","2021-05-18"
"2102.02036","Marios Costa","Marios Costa, George Panagopoulos, Haralambos Panagopoulos and
  Gregoris Spanoudes","Gauge-invariant Renormalization of the Gluino-Glue operator","8 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:2010.02683",,"10.1016/j.physletb.2021.136225","Phys. Lett. B 816 (2021) 136225","hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Gluino-Glue operator in the context of Supersymmetric ${\cal
N}{=}1$ Yang-Mills (SYM) theory. This composite operator is gauge invariant,
and it is directly connected to light bound states of the theory; its
renormalization is very important as a necessary step for the study of
low-lying bound states via numerical simulations. We make use of a
Gauge-Invariant Renormalization Scheme (GIRS). This requires the calculation of
the Green's function of a product of two Gluino-Glue operators, situated at
distinct space-time points. Within this scheme, the mixing with non-gauge
invariant operators which have the same quantum numbers is inconsequential. We
compute the one-loop conversion factor relating the GIRS scheme to
$\overline{\rm MS}$. This conversion factor can be used in order to convert to
$\overline{\rm MS}$ Green's functions which are obtained via lattice
simulations and are renormalized nonperturbatively in GIRS.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:36:43 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 07:00:28 GMT""}]","2021-04-13"
"2102.02037","D\'aniel Virosztek","Gy\""orgy P\'al Geh\'er, Tam\'as Titkos, D\'aniel Virosztek","The isometry group of Wasserstein spaces: the Hilbertian case","30 pages, 2 figures. v2: minor changes",,,,"math.MG math-ph math.FA math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by Kloeckner's result on the isometry group of the quadratic
Wasserstein space $\mathcal{W}_2\left(\mathbb{R}^n\right)$, we describe the
isometry group $\mathrm{Isom}\left(\mathcal{W}_p (E)\right)$ for all parameters
$0 < p < \infty$ and for all separable real Hilbert spaces $E.$ In particular,
we show that $\mathcal{W}_p(X)$ is isometrically rigid for all Polish space $X$
whenever $0<p<1$. This is a consequence of our more general result: we prove
that $\mathcal{W}_1(X)$ is isometrically rigid if $X$ is a complete separable
metric space that satisfies the strict triangle inequality. Furthermore, we
show that this latter rigidity result does not generalise to parameters $p>1$,
by solving Kloeckner's problem affirmatively on the existence of mass-splitting
isometries.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:44:09 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 08:48:18 GMT""}]","2021-12-16"
"2102.02038","Lu Liu","Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Xuanyi Dong, Chengqi
  Zhang","Isometric Propagation Network for Generalized Zero-shot Learning","Accepted by ICLR 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero-shot learning (ZSL) aims to classify images of an unseen class only
based on a few attributes describing that class but no access to any training
sample. A popular strategy is to learn a mapping between the semantic space of
class attributes and the visual space of images based on the seen classes and
their data. Thus, an unseen class image can be ideally mapped to its
corresponding class attributes. The key challenge is how to align the
representations in the two spaces. For most ZSL settings, the attributes for
each seen/unseen class are only represented by a vector while the seen-class
data provide much more information. Thus, the imbalanced supervision from the
semantic and the visual space can make the learned mapping easily overfitting
to the seen classes. To resolve this problem, we propose Isometric Propagation
Network (IPN), which learns to strengthen the relation between classes within
each space and align the class dependency in the two spaces. Specifically, IPN
learns to propagate the class representations on an auto-generated graph within
each space. In contrast to only aligning the resulted static representation, we
regularize the two dynamic propagation procedures to be isometric in terms of
the two graphs' edge weights per step by minimizing a consistency loss between
them. IPN achieves state-of-the-art performance on three popular ZSL
benchmarks. To evaluate the generalization capability of IPN, we further build
two larger benchmarks with more diverse unseen classes and demonstrate the
advantages of IPN on them.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:45:38 GMT""}]","2021-02-04"
"2102.02039","Mohsen Amini Abchuyeh","Mohsen Rezaei, Hossein Karbaschi, M. Amini, M. Soltani, Gholamreza
  Rashedi","Thermoelectric properties of armchair phosphorene nanoribbons in the
  presence of vacancy-induced impurity band",,,"10.1088/1361-6528/ac08ba",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Armchair phosphorene nanoribbons (APNRs) are known to be semiconductors with
an indirect bandgap. Here, we propose to introduce new states in the gap of
APNRs by creating a periodic structure of vacancies (antidots). Based on the
tight-binding model, we show that a periodic array of vacancies or nanopores
leads to the formation of an impurity band inside the gap region. We first
present an analytical expression for the dispersion relation of an impurity
band induced by hybridization of bound states associated with each single
vacancy defect. Then, we increase the size of vacancy defects to include a
bunch of atoms and theoretically investigate the effect of nanopores size and
their spacing on electronic band structure, carrier transmission function, and
thermoelectric properties. Our analysis of the power generation rate and
thermoelectric efficiency of these structures reveals that an ANPR can be used
as a superb thermoelectric power generation module.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:56:31 GMT""}]","2021-08-11"
"2102.02040","Orizon Ferreira","Orizon P. Ferreira, Yingchao Gao and S\'andor Z. N\'emeth","Reducing the projection onto the monotone extended second-order cone to
  the pool-adjacent-violators algorithm of isotonic regression","13 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the monotone extended second-order cone (MESOC), which
is related to the monotone cone and the second-order cone. Some properties of
the MESOC are presented and its dual cone is computed. Projecting onto the
MESOC is reduced to the pool-adjacent-violators algorithm (PAVA) of isotonic
regression. An application of MESOC to portfolio optimisation is provided. Some
broad descriptions of possible MESOC-regression models are also outlined.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:02:13 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 12:51:29 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 17:10:49 GMT""},{""version"":""v4"",""created"":""Mon, 19 Apr 2021 17:45:10 GMT""},{""version"":""v5"",""created"":""Sat, 21 Aug 2021 21:52:48 GMT""},{""version"":""v6"",""created"":""Sat, 28 Aug 2021 00:33:44 GMT""},{""version"":""v7"",""created"":""Fri, 15 Jul 2022 15:21:56 GMT""}]","2022-07-18"
"2102.02041","Linping Yuan","Lin-Ping Yuan, Ziqi Zhou, Jian Zhao, Yiqiu Guo, Fan Du, Huamin Qu","InfoColorizer: Interactive Recommendation of Color Palettes for
  Infographics",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  When designing infographics, general users usually struggle with getting
desired color palettes using existing infographic authoring tools, which
sometimes sacrifice customizability, require design expertise, or neglect the
influence of elements' spatial arrangement. We propose a data-driven method
that provides flexibility by considering users' preferences, lowers the
expertise barrier via automation, and tailors suggested palettes to the spatial
layout of elements. We build a recommendation engine by utilizing deep learning
techniques to characterize good color design practices from data, and further
develop InfoColorizer, a tool that allows users to obtain color palettes for
their infographics in an interactive and dynamic manner. To validate our
method, we conducted a comprehensive four-part evaluation, including case
studies, a controlled user study, a survey study, and an interview study. The
results indicate that InfoColorizer can provide compelling palette
recommendations with adequate flexibility, allowing users to effectively obtain
high-quality color design for input infographics with low effort.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:02:26 GMT""}]","2021-02-04"
"2102.02042","Gian-Luca Oppo","William J. Firth, John B. Geddes, Nathaniel J. Karst, and Gian-Luca
  Oppo","Analytic instability thresholds in folded Kerr resonators of arbitrary
  finesse","6 pages, 2 figures",,"10.1103/PhysRevA.103.023510",,"nlin.PS physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present analytic threshold formulae applicable to both dispersive
(time-domain) and diffractive (pattern-forming) instabilities in Fabry-Perot
Kerr cavities of arbitrary finesse. We do so by extending the gain-circle
technique, recently developed for counter-propagating fields in
single-mirror-feedback systems, to allow for an input mirror. In time-domain
counter-propagating systems walk-off effects are known to suppress cross-phase
modulation contributions to dispersive instabilities. Applying the gain-circle
approach with appropriately-adjusted cross-phase couplings extends previous
results to arbitrary finesse, beyond mean-field approximations, and describes
Ikeda instabilities.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:02:41 GMT""}]","2021-02-24"
"2102.02043","Lucas Franceschini","Lucas Franceschini, Denis Sipp, Olivier Marquet, Johann Moulin, Julien
  Dandois","Identification and reconstruction of high-frequency broadband
  fluctuations in a turbulent flow exhibiting low-frequency deterministic
  motions","20 pages, 12 figures, submitted to JFM",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The turbulent flow around a squared-section cylinder at $Re=22000$ exhibits
both a low-frequency Vortex-Shedding (VS), a common feature of all bluff-body
flows, and high-frequency Kelvin-Helmholtz (KH) structures evolving on the
shear layers formed at the top and bottom side of the cylinder. The VS motion
triggers a periodic movement of these shear layers, inducing oscillations of
the strength of their velocity gradients. The high-frequency KH structures
respond to these low-frequency oscillations of the base-flow gradients in a
quasi-steady manner. In this paper we will propose a general framework to
capture and reconstruct stochastic high-frequency fluctuations (the KH
structures) evolving on top of a low-frequency deterministic motion (the
periodic VS). Based on a generic triple decomposition, that allows separation
of the stochastic component from the deterministic one, we propose a
Phase-Conditioned Localized Spectral Proper Orthogonal Decomposition
(PCL-SPOD), which isolates high-frequency spatio-temporal structures within the
stochastic component at different phases of the VS motion, with a short-time
Fourier transform. Finally, we compare these structures to those obtained with
a Phase-Conditioned Localized Resolvent formalism (PCL-Resolvent), which
consists in a Resolvent analysis around instantaneous snapshots of the periodic
VS.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:07:21 GMT""}]","2021-02-04"
"2102.02044","Luca Giuliani","Luca Giuliani, Gabriele Ghisellini, Tullia Sbarrato","A new panchromatic classification of unclassified Burst Alert Telescope
  active galactic nuclei","11 pages, LaTeX; Acknowledgments added","A&A 647, A195 (2021)","10.1051/0004-6361/202037912",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We collect data at all frequencies for the new sources classified as unknown
active galactic nuclei (AGNs) in the latest Burst Alert Telescope (BAT) all-sky
hard X-ray catalog. Focusing on the 36 sources with measured redshift, we
compute their spectral energy distribution (SED) from radio to $\gamma$-rays
with the aim to classify these objects. We apply emission models that attempt
to reproduce the obtained SEDs, including: i) a standard thin accretion disk
together with an obscuring torus and a X-ray corona; ii) a two temperature
thick advection-dominated flow; iii) an obscured AGN model, accounting for
absorption along the line of sight at kiloelectronvolt energies and in the
optical band; and iv) a phenomenological model to describe the jet emission in
blazar-like objects. We integrate the models with the SWIRE template libraries
to account for the emission of the host galaxy. For every source we found a
good agreement between data and our model. Considering that the sources were
selected in the hard X-ray band, which is rather unaffected by absorption, we
expected and found a large fraction of absorbed radio-quiet AGNs (31 out of 36)
and some additional rare radio-loud sources (5 out of 36), since the jet
emission in hard X-rays is important for aligned jets owing to the boost
produced by the beaming effect. With our work we can confirm the hypothesis
that a number of galaxies, whose optical spectra lack AGN emission features,
host an obscured active nucleus. The approach we used proved to be efficient in
rapidly identifying objects, which commonly used methods were not able to
classify.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:12:50 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 16:02:36 GMT""}]","2021-04-07"
"2102.02045","M. Marques Alves","M. Marques Alves","Variants of the A-HPE and large-step A-HPE algorithms for strongly
  convex problems with applications to accelerated high-order tensor methods","minor corrections; to appear in optimization methods and software",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  For solving strongly convex optimization problems, we propose and study the
global convergence of variants of the A-HPE and large-step A-HPE algorithms of
Monteiro and Svaiter. We prove linear and the superlinear
$\mathcal{O}\left(k^{\,-k\left(\frac{p-1}{p+1}\right)}\right)$ global rates for
the proposed variants of the A-HPE and large-step A-HPE methods, respectively.
The parameter $p\geq 2$ appears in the (high-order) large-step condition of the
new large-step A-HPE algorithm. We apply our results to high-order tensor
methods, obtaning a new inexact (relative-error) tensor method for (smooth)
strongly convex optimization with iteration-complexity
$\mathcal{O}\left(k^{\,-k\left(\frac{p-1}{p+1}\right)}\right)$. In particular,
for $p=2$, we obtain an inexact Newton-proximal algorithm with fast global
$\mathcal{O}\left(k^{\,-k/3}\right)$ convergence rate.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:14:28 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 17:47:43 GMT""}]","2021-10-05"
"2102.02046","Akke Mats Houben","Akke Mats Houben","Matched transient and steady-state approximation of first-passage-time
  distributions of coloured noise driven leaky neurons","11 pages, 3 figures",,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first-passage-time distribution of a leaky integrate-and-fire neuron
driven by a characteristically coloured noise is approximated by matching a
transient and a steady-state solution of the membrane voltage distribution.
These approximations follow from a simple manipulation, made possible by the
specific `eigen' colouring of the noise, which allows to express the membrane
potential as a Gaussian diffusion process on top of a deterministic exponential
movement. Following, the presented method is extended to the case of an
arbitrarily coloured noise driving by factoring out the `eigen' noise and
replacing the residue with an equivalent Gaussian process. It is shown that the
obtained expressions agree well with numerical simulations for different values
of the neuron parameters and noise colouring.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:14:51 GMT""}]","2021-02-04"
"2102.02047","Bal\'azs B\'ar\'any Dr.","Bal\'azs B\'ar\'any and Natalia Jurga and Istv\'an Kolossv\'ary","On the convergence rate of the chaos game","29 pages, 3 figures, 2 tables",,"10.1093/imrn/rnab370",,"math.DS math.CA math.MG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies how long it takes the orbit of the chaos game to reach a
certain density inside the attractor of a strictly contracting iterated
function system of which we only assume that its lower dimension is positive.
We show that the rate of growth of this cover time is determined by the
Minkowski dimension of the push-forward of the shift invariant measure with
exponential decay of correlations driving the chaos game. Moreover, we bound
the expected value of the cover time from above and below with multiplicative
logarithmic correction terms. As an application, for Bedford-McMullen carpets
we completely characterise the family of probability vectors which minimise the
Minkowski dimension of Bernoulli measures. Interestingly, these vectors have
not appeared in any other aspect of Bedford-McMullen carpets before.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:14:52 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 18:57:02 GMT""}]","2022-02-15"
"2102.02048","Diego Rubiera-Garcia","Francisco Cabral, Francisco S. N. Lobo, Diego Rubiera-Garcia","Imprints from a Riemann-Cartan space-time on the energy levels of Dirac
  spinors","12 pages; v2: minor corrections and additions","Class. Quant. Grav. 38, no.19, 195008 (2021)","10.1088/1361-6382/ac1cca",,"gr-qc astro-ph.HE hep-th","http://creativecommons.org/licenses/by/4.0/","  In this work, we investigate the effects of the torsion-fermionic interaction
on the energy levels of fermions within a Riemann-Cartan geometry using a
model-independent approach. We consider the case of fermions minimally coupled
to the background torsion as well as non-minimal extensions via additional
couplings with the vector and axial fermionic currents which include
parity-breaking interactions. In the limit of zero-curvature, and for the cases
of constant and spherically symmetric torsion, we find a Zeeman-like effect on
the energy levels of fermions and anti-fermions depending on whether they are
aligned/anti-aligned with respect to the axial vector part of the torsion (or
to specific combination of torsion quantities), and determine the corresponding
fine-structure energy transitions. We also discuss non-minimal couplings
between fermionic fields and torsion within the Einstein-Cartan theory and its
extension to include the (parity-breaking) Holst term. Finally we elaborate on
the detection of torsion effects related to the splitting of energy levels in
astrophysics, cosmology and solid state physics using current capabilities.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:18:55 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 13:38:13 GMT""}]","2021-10-25"
"2102.02049","Gellert Weisz","Gell\'ert Weisz, Philip Amortila, Barnab\'as Janzer, Yasin
  Abbasi-Yadkori, Nan Jiang, Csaba Szepesv\'ari","On Query-efficient Planning in MDPs under Linear Realizability of the
  Optimal State-value Function",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider local planning in fixed-horizon MDPs with a generative model
under the assumption that the optimal value function lies close to the span of
a feature map. The generative model provides a local access to the MDP: The
planner can ask for random transitions from previously returned states and
arbitrary actions, and features are only accessible for states that are
encountered in this process. As opposed to previous work (e.g. Lattimore et al.
(2020)) where linear realizability of all policies was assumed, we consider the
significantly relaxed assumption of a single linearly realizable
(deterministic) policy. A recent lower bound by Weisz et al. (2020) established
that the related problem when the action-value function of the optimal policy
is linearly realizable requires an exponential number of queries, either in $H$
(the horizon of the MDP) or $d$ (the dimension of the feature mapping). Their
construction crucially relies on having an exponentially large action set. In
contrast, in this work, we establish that poly$(H,d)$ planning is possible with
state value function realizability whenever the action set has a constant size.
In particular, we present the TensorPlan algorithm which uses
poly$((dH/\delta)^A)$ simulator queries to find a $\delta$-optimal policy
relative to any deterministic policy for which the value function is linearly
realizable with some bounded parameter. This is the first algorithm to give a
polynomial query complexity guarantee using only linear-realizability of a
single competing value function. Whether the computation cost is similarly
bounded remains an open question. We extend the upper bound to the
near-realizable case and to the infinite-horizon discounted setup. We also
present a lower bound in the infinite-horizon episodic setting: Planners that
achieve constant suboptimality need exponentially many queries, either in $d$
or the number of actions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:23:15 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 13:53:07 GMT""},{""version"":""v3"",""created"":""Fri, 9 Jul 2021 11:37:09 GMT""}]","2021-07-12"
"2102.02050","Yana Vaynzof","Alexander D. Taylor, Qing Sun, Katelyn P. Goetz, Qingzhi An, Tim
  Schramm, Yvonne Hofstetter, Maximillian Litterst, Fabian Paulus and Yana
  Vaynzof","A General Approach to High Efficiency Perovskite Solar Cells by Any
  Antisolvent",,,"10.1038/s41467-021-22049-8",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deposition of perovskite thin films by antisolvent engineering is one of the
most common methods employed in perovskite photovoltaics research. Herein, we
report on a general method that allows the fabrication of highly efficient
perovskite solar cells by any antisolvent via the manipulation of the
antisolvent application rate. Through a detailed structural, compositional and
microstructural characterization of perovskite layers fabricated by 14
different antisolvents, we identify two key factors that influence the quality
of the perovskite active layer: the solubility of the organic precursors in the
antisolvent and its miscibility with the host solvent(s) of the perovskite
precursor solution. Depending on these two factors, each antisolvent can be
utilized to produce high performance devices reaching power conversion
efficiencies (PCEs) that exceed 21%. Moreover, we demonstrate that by employing
the optimal antisolvent application procedure, highly efficient solar cells can
be fabricated from a broad range of precursor stoichiometries, with either a
significant excess or deficiency of organic iodides.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:23:15 GMT""}]","2021-04-14"
"2102.02051","Zongbo Han","Zongbo Han, Changqing Zhang, Huazhu Fu, Joey Tianyi Zhou","Trusted Multi-View Classification","Accepted by ICLR 2021",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Multi-view classification (MVC) generally focuses on improving classification
accuracy by using information from different views, typically integrating them
into a unified comprehensive representation for downstream tasks. However, it
is also crucial to dynamically assess the quality of a view for different
samples in order to provide reliable uncertainty estimations, which indicate
whether predictions can be trusted. To this end, we propose a novel multi-view
classification method, termed trusted multi-view classification, which provides
a new paradigm for multi-view learning by dynamically integrating different
views at an evidence level. The algorithm jointly utilizes multiple views to
promote both classification reliability and robustness by integrating evidence
from each view. To achieve this, the Dirichlet distribution is used to model
the distribution of the class probabilities, parameterized with evidence from
different views and integrated with the Dempster-Shafer theory. The unified
learning framework induces accurate uncertainty and accordingly endows the
model with both reliability and robustness for out-of-distribution samples.
Extensive experimental results validate the effectiveness of the proposed model
in accuracy, reliability and robustness.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:30:26 GMT""}]","2021-02-04"
"2102.02054","Debarshi Das","Arkaprabha Ghosal, Debarshi Das, Subhashish Banerjee","Characterizing qubit channels in the context of quantum teleportation","Close to published version","Phys. Rev. A 103, 052422 (2021)","10.1103/PhysRevA.103.052422",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a scenario where a party, say, Alice prepares a pure two-qubit
(either maximally entangled or non-maximally entangled) state and sends one
half of this state to another distant party, say, Bob through a qubit (either
unital or non-unital) channel. Finally, the shared state is used as a
teleportation channel. In this scenario, we focus on characterizing the set of
qubit channels with respect to the final state's efficacy as a resource of
quantum teleportation (QT) in terms of maximal average fidelity and fidelity
deviation (fluctuation in fidelity values over the input states). Importantly,
we point out the existence of a subset of qubit channels for which the final
state becomes useful for universal QT (having maximal average fidelity strictly
greater than the classical bound and having zero fidelity deviation) when the
initially prepared state is either useful for universal QT (i.e., for a
maximally entangled state) or not useful for universal QT (i.e., for a subset
of non-maximally entangled pure states). Interestingly, in the latter case, we
show that non-unital channels (dissipative interactions) are more effective
than unital channels (non-dissipative interactions) in producing useful states
for universal QT from non-maximally entangled pure states.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:37:08 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 15:59:49 GMT""}]","2021-05-19"
"2102.02057","Manuel Dahmen","Marco Langiu, David Yang Shu, Florian Joseph Baader, Dominik Hering,
  Uwe Bau, Andr\'e Xhonneux, Dirk M\""uller, Andr\'e Bardow, Alexander Mitsos,
  Manuel Dahmen","COMANDO: A Next-Generation Open-Source Framework for Energy Systems
  Optimization","24 pages, 1 graphical abstract, 13 figures, 4 tables","Langiu et al. Computers and Chemical Engineering (2021) 152,
  107366","10.1016/j.compchemeng.2021.107366",,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Existing open-source modeling frameworks dedicated to energy systems
optimization typically utilize (mixed-integer) linear programming ((MI)LP)
formulations, which lack modeling freedom for technical system design and
operation. We present COMANDO, an open-source Python package for
component-oriented modeling and optimization for nonlinear design and operation
of integrated energy systems. COMANDO allows to assemble system models from
component models including nonlinear, dynamic and discrete characteristics.
Based on a single system model, different deterministic and stochastic problem
formulations can be obtained by varying objective function and underlying data,
and by applying automatic or manual reformulations. The flexible open-source
implementation allows for the integration of customized routines required to
solve challenging problems, e.g., initialization, problem decomposition, or
sequential solution strategies. We demonstrate features of COMANDO via case
studies, including automated linearization, dynamic optimization, stochastic
programming, and the use of nonlinear artificial neural networks as surrogate
models in a reduced-space formulation for deterministic global optimization.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:38:08 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 14:26:18 GMT""}]","2021-11-10"
"2102.02058","Giovanni Barbarino","Giovanni Barbarino, Vanni Noferini","The limit empirical spectral distribution of complex matrix polynomials","arXiv admin note: text overlap with arXiv:2005.07501","Random Matrices: Theory and Applications, 2021","10.1142/S201032632250023X",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the empirical spectral distribution (ESD) for complex n x n matrix
polynomials of degree k. We obtain exact formulae for the almost sure limit of
the ESD in two distinct scenarios: (1) n -> \infty with k constant and (2) k ->
\infty with n bounded by O(k^P) for some P>0. The main tools used are the
logarithmic potential of some measure related to the matrix polynomial, and
some classical estimates on the singular values of full random matrices with
i.i.d. entries.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:40:00 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 13:12:15 GMT""},{""version"":""v3"",""created"":""Wed, 29 Sep 2021 13:33:25 GMT""}]","2022-02-22"
"2102.02060","Qiang Zhang","Lu-Chuan Liu, Luo-Yuan Qu, Cheng Wu, Jordan Cotler, Fei Ma, Ming-Yang
  Zheng, Xiu-Ping Xie, Yu-Ao Chen, Qiang Zhang, Frank Wilczek, and Jian-Wei Pan","Improved Spatial Resolution Achieved by Chromatic Intensity
  Interferometry","5 pages, 3 figures","Phys. Rev. Lett. 127, 103601 (2021)","10.1103/PhysRevLett.127.103601",,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Interferometers are widely used in imaging technologies to achieve enhanced
spatial resolution, but require that the incoming photons be indistinguishable.
In previous work, we built and analyzed color erasure detectors which expand
the scope of intensity interferometry to accommodate sources of different
colors. Here we experimentally demonstrate how color erasure detectors can
achieve improved spatial resolution in an imaging task, well beyond the
diffraction limit. Utilizing two 10.9 mm-aperture telescopes and a 0.8 m
baseline, we measure the distance between a 1063.6 nm source and a 1064.4 nm
source separated by 4.2 mm at a distance of 1.43 km, which surpasses the
diffraction limit of a single telescope by about 40 times. Moreover, chromatic
intensity interferometry allows us to recover the phase of the Fourier
transform of the imaged objects - a quantity that is, in the presence of modest
noise, inaccessible to conventional intensity interferometry.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:40:31 GMT""}]","2021-09-08"
"2102.02062","Rob Ward","Rob Ward, Burak Sencer, Bryn Jones, Erdem Ozturk","Accurate Prediction Of Machining Feedrate And Cycle Time Prediction
  Considering Interpolator Dynamics",,,"10.1007/s00170-021-07211-2",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper presents an accurate machining feedrate prediction technique by
modeling the trajectory generation behaviour of modern CNC machine tools.
Typically, CAM systems simulate machines motion based on the commanded feedrate
and the path geometry. Such approach does not consider the feed planning and
interpolation strategy of the machines numerical control (NC) system. In this
study, trajectory generation behaviour of the NC system is modelled and
accurate cycle time prediction for complex machining toolpaths is realized. NC
systems linear interpolation dynamics and commanded axis kinematic profiles are
predicted by using Finite Impulse Response (FIR) based low-pass filters. The
corner blending behaviour during nonstop interpolation of linear segments is
modeled, and for the first time, the minimum cornering feedrate, that satisfies
both the tolerance and machining constraints, has been calculated analytically
for 3 axis toolpaths of any geometry. The proposed method is applied to 4
different case studies including complex machining tool-paths. Experimental
validations show actual cycle times can be estimated with greater than 90
percent accuracy, greatly outperforming CAM-based predictions. It is expected
that the proposed approach will help improve the accuracy of virtual machining
models and support businesses decision making when costing machining processes.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:41:36 GMT""}]","2021-06-21"
"2102.02064","Hassnaa El-Derhalli","Hassnaa El-Derhalli, Lea Constans, Sebastien Le Beux, Alfredo De
  Rossi, Fabrice Raineri, Sofiene Tahar","Optical Stochastic Computing Architectures Using Photonic Crystal
  Nanocavities",,,,,"cs.ET physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic computing allows a drastic reduction in hardware complexity using
serial processing of bit streams. While the induced high computing latency can
be overcome using integrated optics technology, the design of realistic optical
stochastic computing architectures calls for energy efficient switching
devices. Photonics Crystal (PhC) nanocavities are $\mu m^2$ scale devices
offering 100fJ switching operation under picoseconds-scale switching speed.
Fabrication process allows controlling the Quality factor of each nanocavity
resonance, leading to opportunities to implement architectures involving
cascaded gates and multi-wavelength signaling. In this report, we investigate
the design of cascaded gates architecture using nanocavities in the context of
stochastic computing. We propose a transmission model considering key
nanocavity device parameters, such as Quality factors, resonance wavelength and
switching efficiency. The model is calibrated with experimental measurements.
We propose the design of XOR gate and multiplexer. We illustrate the use of the
gates to design an edge detection filter. System-level exploration of laser
power, bit-stream length and bit-error rate is carried out for the processing
of gray-scale images. The results show that the proposed architecture leads to
8.5nJ/pixel energy consumption and 512ns/pixel processing time.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:42:58 GMT""}]","2021-02-04"
"2102.02065","Sotaro Katayama","Sotaro Katayama and Toshiyuki Ohtsuka","Riccati Recursion for Optimal Control Problems of Nonlinear Switched
  Systems","7 pages, 2 figures. This paper has been accepted to be presented IFAC
  NMPC2021",,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an efficient algorithm for the optimal control problems (OCPs) of
nonlinear switched systems that optimizes the control input and switching
instants simultaneously for a given switching sequence. We consider the
switching instants as the optimization variables and formulate the OCP based on
the direct multiple shooting method. We derive a linear equation to be solved
in Newton's method and propose a Riccati recursion algorithm to solve the
linear equation efficiently. The computational time of the proposed method
scales linearly with respect to the number of time stages of the horizon as the
standard Riccati recursion. Numerical experiments show that the proposed method
converges with a significantly shorter computational time than the conventional
methods.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:50:52 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 08:09:51 GMT""}]","2021-06-09"
"2102.02066","Aidan Chatwin-Davies","Aidan Chatwin-Davies","Modave Lectures on Quantum Information: An Introduction to Channels and
  Applications to Black Holes and AdS/CFT","45 pages, 9+3 figures. Based on lectures given at the XVI Modave
  Summer School in Mathematical Physics, 9-11 September 2020, Brussels,
  Belgium. v2: Added references, tweaked discussion in 2.4",,"10.22323/1.389.0003",,"quant-ph hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  These notes introduce a handful of core ideas from quantum information
science that figure prominently in modern research on quantum gravity. The
central concept that forms the base of these notes is that of a quantum
channel; that is, the most general physically-reasonable map between quantum
states and between operators on Hilbert space. After reviewing some
fundamentals, we will study channels and their properties, and then go on to
formulate quantum error correction in terms of quantum channels. Along the way,
we will see how a handful of problems in high energy physics, such as the black
hole information problem and bulk reconstruction in AdS/CFT, can be cast in the
information-theoretic language being set up.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:52:38 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 11:07:39 GMT""}]","2021-03-08"
"2102.02067","Claude Hillaire-Marcel","Claude Hillaire-Marcel, Anne de Vernal, Michel Crucifix","Sea-level and summer season orbital insolation as drivers of Arctic
  sea-ice","9 pages, 2 figures",,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  The sea-ice cover of the Arctic Ocean is an important element of the climate
and ocean system in the Northern Hemisphere as it impacts albedo, atmospheric
pressure regimes, CO2-exchange at the ocean/atmosphere interface as well as the
North Atlantic freshwater budget and thermohaline circulation [1]. Due to
global warming, the Arctic sea-ice cover is presently evolving at an
unprecedent rate towards full melt during the summer season, driving the
so-called ""Arctic amplification"" [2]. However, the Arctic sea-ice has also
experienced large amplitude variations, from seasonal to orbital (Milankovitch)
time scales, in the past. Recent studies led to suggest that whereas insolation
has been a major driver of Arctic sea-ice variability through time, sea-level
changes governed the development of ""sea-ice factories"" over shelves (Figure
1), thus fine-tuning the response of the Arctic Ocean to glacial/interglacial
oscillations that is slightly out of phase compared to lower latitudes [3,4].
We discuss below how insolation and sea-level changes may have interacted and
controlled the sea-ice cover of the Arctic Ocean during warm past intervals and
how they could still interfere in the future.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:52:57 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 14:04:25 GMT""}]","2021-02-09"
"2102.02068","Preden Roulleau","A. Assouline, M. Jo, P. Brasseur, K. Watanabe, T. Taniguchi,
  T.Jolicoeur, P. Roche, D.C. Glattli, N. Kumada, F.D. Parmentier and P.
  Roulleau","Unveiling excitonic properties of magnons in a quantum Hall ferromagnet","11 pages, 4 figures","Nature Physics 17, 1369 (2021)","10.1038/s41567-021-01411-z",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Magnons enable transferring a magnetic moment or spin over macroscopic
distance. In quantum Hall ferromagnet, it has been predicted in the early 90s
that spin and charges are entangled, meaning that any change of the spin
texture modifies the charge distribution. As a direct consequence of this
entanglement, magnons carry an electric dipole moment. Here we report the first
evidence of the existence of this electric dipole moment in a graphene quantum
Hall ferromagnet using a Mach-Zehnder interferometer as a quantum sensor. By
propagating towards the interferometer through an insulating bulk, the magnon
electric dipole moment modifies the Aharonov-Bohm flux through the
interferometer, changing both its phase and its visibility. In particular, we
relate the phase shift to the sign of this electric dipole moment, and the
exponential loss of visibility to the flux of emitted magnons. Finally, we
probe the emission energy threshold of the magnons close to filling factor v=1.
Approaching v=0, we observe that the emission energy threshold diminishes
towards zero, which might be linked to the existence of gapless mode in the
canted-antiferromagnetic (CAF) phase at v=0. The detection and manipulation of
magnons based on their electric dipole open the field for a new type of
coherent magnon quantum circuits that will be electrostatically controlled.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:57:42 GMT""}]","2021-12-13"
"2102.02069","Xuxue Sun","Xuxue Sun, Nazmus Sakib, Nan Kong, Hongdao Meng, Kathryn Hyer, Chris
  Masterson, and Mingyang Li","An Analytics-based Decision Support System for Resource Planning under
  Heterogeneous Service Demand of Nursing Home Residents","19 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Nursing homes (NHs) are critical healthcare infrastructures for caring frail
older adults with 24/7 formal care and personal assistance. Adequate NH
resource planning is of great importance to ensure desired quality of care and
resident outcomes yet challenging. The challenge lies in the heterogeneous
service demand of NH residents, due to the varied individual characteristics,
the diverse dwelling duration with multiple competing discharge dispositions,
and the diverse service need. Existing healthcare staffing literature often
assumed a homogeneous population of NH residents and neglected the complexity
of service demand heterogeneity. This work proposes an analytics-based modeling
framework with a user-friendly decision support platform for NH resource
planning. The proposed framework characterizes the heterogeneous service demand
of NH residents via novel integration of advanced statistical modeling,
computer simulation and optimization techniques. We further provide a case
study using real data from our industrial collaborator to demonstrate the
effectiveness and superior performance of the proposed work. The impacts of
service utilization heterogeneity and service need heterogeneity on resource
planning decisions are investigated as well.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:00:24 GMT""}]","2021-02-04"
"2102.02070","Andreas Savas-Halilaj","Michael Markellos and Andreas Savas-Halilaj","Rigidity of the Hopf fibration","References updated",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study minimal maps between euclidean spheres. The Hopf
fibrations provide explicit examples of such minimal maps. Moreover, their
corresponding graphs have second fundamental form of constant norm. We prove
that a minimal submersion from $S^3$ to $S^2$ whose Gauss map satisfies a
suitable pinching condition must be weakly conformal and with totally geodesic
fibers. As a consequence, we obtain that an equivariant minimal submersion from
$S^3$ to $S^2$ coincides with the Hopf fibration. Furthermore, we prove that a
minimal map $f:S^3 \to S^2$ with constant singular values and constant norm of
the second fundamental form is either constant or, up to isometries, coincides
with the Hopf fibration.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:02:36 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 18:47:59 GMT""}]","2021-02-11"
"2102.02071","Simon Weber","Liang Chen, Eugene Choo, Alfred Galichon and Simon Weber","Matching Function Equilibria with Partial Assignment: Existence,
  Uniqueness and Estimation",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we argue that models coming from a variety of fields share a
common structure that we call matching function equilibria with partial
assignment. This structure revolves around an aggregate matching function and a
system of nonlinear equations. This encompasses search and matching models,
matching models with transferable, non-transferable and imperfectly
transferable utility, and matching with peer effects. We provide a proof of
existence and uniqueness of an equilibrium as well as an efficient algorithm to
compute it. We show how to estimate parametric versions of these models by
maximum likelihood. We also propose an approach to construct counterfactuals
without estimating the matching functions for a subclass of models. We
illustrate our estimation approach by analyzing the impact of the elimination
of the Social Security Student Benefit Program in 1982 on the marriage market
in the United States.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:02:39 GMT""}]","2021-02-04"
"2102.02072","Niccol\`o Baldelli","Niccol\`o Baldelli, Bruno Juli\'a-D\'iaz, Utso Bhattacharya, Maciej
  Lewenstein, Tobias Gra{\ss}","Tracing non-Abelian anyons via impurity particles","11 pages, 5 figures","Phys. Rev. B 104, 035133 (2021)","10.1103/PhysRevB.104.035133",,"cond-mat.mes-hall cond-mat.quant-gas cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-Abelian excitations are an interesting feature of many fractional quantum
Hall phases, including those phases described by the Moore-Read (or Pfaffian)
wave function. However, the detection of the non-Abelian quasiparticles is
challenging. Here, we consider a system described by the Moore-Read wave
function, and assume that impurity particles bind to its quasiholes. Then, the
angular momentum of the impurities, reflected also by the impurity density,
provides a useful witness of the physics of the non-Abelian excitations. By
demanding that the impurities are constrained to the lowest Landau level, we
are able to write down the corresponding many-body wave function describing
both the Moore-Read liquid and the impurities. Through Monte Carlo sampling we
determine the impurity angular momentum, and we show that it suggests a
quantum-statistical parameter $\alpha = a\nu -b +P/2$ for the quasiholes, where
$\alpha$ ranges from $0$ for bosons to $1$ for fermions. A reasonable agreement
with the Monte Carlo results is obtained for $a=1/4$, $b=1/8$ and $P=0,1$
depending on the parity of the particle number in the Moore-Read liquid. This
parity-dependence of the angular momentum serves as an unambiguous
demonstration of the non-Abelian nature of the excitations. In addition to the
studies of excitations in the Moore-Read liquid, we also apply our scheme to
Laughlin liquids, for which we focus on interacting bosonic impurities. With
this, the impurities themselves form Laughlin states, which allows for a study
of hierarchical fractional quantum Hall states.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:03:30 GMT""}]","2021-07-21"
"2102.02073","Yuhua Sun","Yuhua Sun and Fanheng Xu","Liouville's theorems to quasilinear differential inequalities involving
  gradient nonlinearity term on manifolds",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the nonexistence and existence of nontrivial positive
solutions to $\Delta_m u+u^p|\nabla u|^q\leq0$ on noncompact geodesically
complete Riemannian manifolds, where $m>1$, and $(p,q)\in \mathbb{R}^2$.
According to classification of $(p, q)$, we establish different volume growth
conditions to obtain Liouville's theorems for the above quasilinear
differential inequalities, and we also show these volume growth conditions are
sharp in most cases. Moreover, the results are completely new for $(p, q)$ of
negative pair, even in the Euclidean space.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:04:06 GMT""}]","2021-02-04"
"2102.02074","Achintya Sarkar","Achintya Kumar Sarkar, Md Sahidullah, Zheng-Hua Tan","Data Generation Using Pass-phrase-dependent Deep Auto-encoders for
  Text-Dependent Speaker Verification",,,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel method that trains pass-phrase specific
deep neural network (PP-DNN) based auto-encoders for creating augmented data
for text-dependent speaker verification (TD-SV). Each PP-DNN auto-encoder is
trained using the utterances of a particular pass-phrase available in the
target enrollment set with two methods: (i) transfer learning and (ii) training
from scratch. Next, feature vectors of a given utterance are fed to the PP-DNNs
and the output from each PP-DNN at frame-level is considered one new set of
generated data. The generated data from each PP-DNN is then used for building a
TD-SV system in contrast to the conventional method that considers only the
evaluation data available. The proposed approach can be considered as the
transformation of data to the pass-phrase specific space using a non-linear
transformation learned by each PP-DNN. The method develops several TD-SV
systems with the number equal to the number of PP-DNNs separately trained for
each pass-phrases for the evaluation. Finally, the scores of the different
TD-SV systems are fused for decision making. Experiments are conducted on the
RedDots challenge 2016 database for TD-SV using short utterances. Results show
that the proposed method improves the performance for both conventional
cepstral feature and deep bottleneck feature using both Gaussian mixture model
- universal background model (GMM-UBM) and i-vector framework.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:06:29 GMT""}]","2021-02-04"
"2102.02075","Samaporn Tinyanont","Samaporn Tinyanont, Maxwell Millar-Blanchaer, Mansi Kasliwal, Dimitri
  Mawet, Douglas C Leonard, Mattia Bulla, Kishalay De, Nemanja Jovanovic,
  Matthew Hankins, Gautam Vasisht, Eugene Serabyn","Infrared Spectropolarimetric Detection of Intrinsic Polarization from a
  Core-Collapse Supernova",,,,,"astro-ph.SR astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive stars die an explosive death as a core-collapse supernova (CCSN). The
exact physical processes that cause the collapsing star to rebound into an
explosion are not well-understood, and the key in resolving this issue may lie
in the measurement of the shape of CCSNe ejecta. Spectropolarimetry is the only
way to perform this measurement for CCSNe outside of the Milky Way and
Magellanic Clouds. We present an infrared (IR) spectropolarimetric detection of
a CCSN, enabled by the new highly sensitive WIRC+Pol instrument at Palomar
Observatory, that can observe CCSNe (M = -17 mags) out to 20 Mpc to ~0.1%
polarimetric precision. IR spectropolarimetry is less affected than optical by
dust scattering in the circumstellar and interstellar media, thereby providing
a more unbiased probe of the intrinsic geometry of the SN ejecta. SN 2018hna, a
SN 1987A-like explosion, shows 2.0+-0.3% continuum polarization in the J band
oriented at ~160 degree on-sky at 182 d after the explosion. Assuming prolate
geometry like in SN 1987A, we infer an ejecta axis ratio of <0.48 with the axis
of symmetry pointing at 70 degree position angle. The axis ratio is similar to
that of SN 1987A suggesting that they may share intrinsic geometry and
inclination angle. Our data do not rule out oblate ejecta. We also observe one
other core-collapse and two thermonuclear SNe in the J band. SN 2020oi, a
stripped-envelope Type Ic SN in Messier 100 has p = 0.37+-0.09% at peak light,
indicative of either a 10% asymmetry or host interstellar polarization. The SNe
Ia, 2019ein and 2020ue have p < 0.33% and < 1.08% near peak light, indicative
of asymmetries of less than 10% and 20%, respectively.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:08:34 GMT""}]","2021-02-04"
"2102.02076","Masaki Taniguchi","Nobuo Iida, Anubhav Mukherjee and Masaki Taniguchi","An adjunction inequality for the Bauer-Furuta type invariants, with
  applications to sliceness and 4-manifold topology","31 pages, 2 figures, the introduction is changed",,,"RIKEN-iTHEMS-Report-21","math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our main result gives an adjunction inequality for embedded surfaces in
certain $4$-manifolds with contact boundary under a non-vanishing assumption on
the Bauer--Furuta type invariants. Using this, we give infinitely many knots in
$S^3$ that are not smoothly H-slice (that is, bounding a null-homologous disk)
in many $4$-manifolds but they are topologically H-slice. In particular, we
give such knots in the boundaries of the punctured elliptic surfaces $E(2n)$.
In addition, we give obstructions to codimension-0 orientation-reversing
embedding of weak symplectic fillings with $b_3=0$ into closed symplectic
4-manifolds with $b_1=0$ and $b_2^+\equiv 3$ mod $4$. From here we prove a
Bennequin type inequality for symplectic caps of $(S^3,\xi_{std})$. We also
show that any weakly symplectically fillable $3$-manifold bounds a $4$-manifold
with at least two smooth structures.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:20:53 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 12:37:07 GMT""},{""version"":""v3"",""created"":""Fri, 4 Feb 2022 03:08:08 GMT""}]","2022-02-07"
"2102.02077","Pilar Cossio Dr.","Julian Giraldo-Barreto, Sebastian Ortiz, Erik H. Thiede, Karen
  Palacio-Rodriguez, Bob Carpenter, Alex H. Barnett, Pilar Cossio","A Bayesian approach for extracting free energy profiles from
  cryo-electron microscopy experiments using a path collective variable",,,,,"q-bio.BM physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Cryo-electron microscopy (cryo-EM) extracts single-particle density
projections of individual biomolecules. Although cryo-EM is widely used for 3D
reconstruction, due to its single-particle nature, it has the potential to
provide information about the biomolecule's conformational variability and
underlying free energy landscape. However, treating cryo-EM as a
single-molecule technique is challenging because of the low signal-to-noise
ratio (SNR) in the individual particles. In this work, we developed the
cryo-BIFE method, cryo-EM Bayesian Inference of Free Energy profiles, that uses
a path collective variable to extract free energy profiles and their
uncertainties from cryo-EM images. We tested the framework over several
synthetic systems, where we controlled the imaging parameters and conditions.
We found that for realistic cryo-EM environments and relevant biomolecular
systems, it is possible to recover the underlying free energy, with the pose
accuracy and SNR as crucial determinants. Then, we used the method to study the
conformational transitions of a calcium-activated channel with real cryo-EM
particles. Interestingly, we recover the most probable conformation (used to
generate a high resolution reconstruction of the calcium-bound state), and we
find two additional meta-stable states, one which corresponds to the
calcium-unbound conformation. As expected for turnover transitions within the
same sample, the activation barriers are of the order of a couple $k_BT$.
Extracting free energy profiles from cryo-EM will enable a more complete
characterization of the thermodynamic ensemble of biomolecules.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:22:28 GMT""}]","2021-02-04"
"2102.02078","Yicheng Chen","Huan Chang, Yicheng Chen, Baochang Zhang, David Doermann","Multi-UAV Mobile Edge Computing and Path Planning Platform based on
  Reinforcement Learning","The source code can be found at https://github.com/bczhangbczhang",,,,"cs.MA cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unmanned Aerial vehicles (UAVs) are widely used as network processors in
mobile networks, but more recently, UAVs have been used in Mobile Edge
Computing as mobile servers. However, there are significant challenges to use
UAVs in complex environments with obstacles and cooperation between UAVs. We
introduce a new multi-UAV Mobile Edge Computing platform, which aims to provide
better Quality-of-Service and path planning based on reinforcement learning to
address these issues. The contributions of our work include: 1) optimizing the
quality of service for mobile edge computing and path planning in the same
reinforcement learning framework; 2) using a sigmoid-like function to depict
the terminal users' demand to ensure a higher quality of service; 3) applying
synthetic considerations of the terminal users' demand, risk and geometric
distance in reinforcement learning reward matrix to ensure the quality of
service, risk avoidance, and the cost-savings. Simulations have shown the
effectiveness and feasibility of our platform, which can help advance related
researches.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:22:36 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 02:15:25 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 08:44:35 GMT""}]","2021-05-20"
"2102.02079","Qinbin Li","Qinbin Li, Yiqun Diao, Quan Chen, Bingsheng He","Federated Learning on Non-IID Data Silos: An Experimental Study",,,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the increasing privacy concerns and data regulations, training data
have been increasingly fragmented, forming distributed databases of multiple
""data silos"" (e.g., within different organizations and countries). To develop
effective machine learning services, there is a must to exploit data from such
distributed databases without exchanging the raw data. Recently, federated
learning (FL) has been a solution with growing interests, which enables
multiple parties to collaboratively train a machine learning model without
exchanging their local data. A key and common challenge on distributed
databases is the heterogeneity of the data distribution among the parties. The
data of different parties are usually non-independently and identically
distributed (i.e., non-IID). There have been many FL algorithms to address the
learning effectiveness under non-IID data settings. However, there lacks an
experimental study on systematically understanding their advantages and
disadvantages, as previous studies have very rigid data partitioning strategies
among parties, which are hardly representative and thorough. In this paper, to
help researchers better understand and study the non-IID data setting in
federated learning, we propose comprehensive data partitioning strategies to
cover the typical non-IID data cases. Moreover, we conduct extensive
experiments to evaluate state-of-the-art FL algorithms. We find that non-IID
does bring significant challenges in learning accuracy of FL algorithms, and
none of the existing state-of-the-art FL algorithms outperforms others in all
cases. Our experiments provide insights for future studies of addressing the
challenges in ""data silos"".
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:29:09 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 06:45:28 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 14:01:16 GMT""},{""version"":""v4"",""created"":""Thu, 28 Oct 2021 15:22:21 GMT""}]","2021-10-29"
"2102.02080","Fajri Koto","Fajri Koto and Jey Han Lau and Timothy Baldwin","Top-down Discourse Parsing via Sequence Labelling","Accepted at EACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We introduce a top-down approach to discourse parsing that is conceptually
simpler than its predecessors (Kobayashi et al., 2020; Zhang et al., 2020). By
framing the task as a sequence labelling problem where the goal is to
iteratively segment a document into individual discourse units, we are able to
eliminate the decoder and reduce the search space for splitting points. We
explore both traditional recurrent models and modern pre-trained transformer
models for the task, and additionally introduce a novel dynamic oracle for
top-down parsing. Based on the Full metric, our proposed LSTM model sets a new
state-of-the-art for RST parsing.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:30:21 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 20:32:38 GMT""}]","2021-04-07"
"2102.02081","Gary McGuire","Robin Chapman and Gary McGuire","On a Family of Twisted Trace Curves over Finite Fields, and Fibonacci
  Numbers",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present some results about the number of rational points on a certain
family of curves defined over a finite field. In a small number of cases the
curves have more rational points than expected. Fibonacci numbers make an
appearance, as do cyclotomic polynomials.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:33:06 GMT""}]","2021-02-04"
"2102.02082","David Katz","D. Katz, A. Gomez, M. Haywood, O. Snaith and P. Di Matteo","Radial structure and formation of the Milky Way disc","18 pages, 21 figures, submitted to A&A on 29/01/2021","A&A 655, A111 (2021)","10.1051/0004-6361/202140453",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation of the Galactic disc is an enthusiastically debated issue.
Numerous studies and models seek to identify the dominant physical process(es)
that shaped its observed properties. Taking advantage of the improved coverage
of the inner Milky Way provided by the SDSS DR16 APOGEE catalogue and of the
ages published in the APOGEE-AstroNN Value Added Catalogue (VAC), we examine
the radial evolution of the chemical and age properties of the Galactic stellar
disc, with the aim to better constrain its formation. Using a sample of 199,307
giant stars with precise APOGEE abundances and APOGEE-astroNN ages, selected in
a +/-2 kpc layer around the galactic plane, we assess the dependency with
guiding radius of: (i) the median metallicity, (ii) the ridge lines of the
[Fe/H]-[Mg/Fe] and age-[Mg/Fe] distributions and (iii) the Age Distribution
Function (ADF). The giant star sample allows us to probe the radial behaviour
of the Galactic disc from Rg = 0 to 14-16 kpc. The thick disc [Fe/H]-[Mg/Fe]
ridge lines follow closely grouped parallel paths, supporting the idea that the
thick disc did form from a well-mixed medium. However, the ridge lines present
a small drift in [Mg/Fe], which decreases with increasing guiding radius. At
sub-solar metallicity, the intermediate and outer thin disc [Fe/H]-[Mg/Fe]
ridge lines follow parallel sequences shifted to lower metallicity as the
guiding radius increases. We interpret this pattern, as the signature of a
dilution of the inter-stellar medium from Rg~6 kpc to the outskirt of the disc,
which occured before the onset of the thin disc formation. The APOGEE-AstroNN
VAC provides stellar ages for statistically significant samples of thin disc
stars from the Galactic centre up to Rg~14 kpc. An important result provided by
this dataset, is that the thin disc presents evidence of an inside-out
formation up to R_g~10-12 kpc.(Abridged)
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:35:13 GMT""}]","2021-12-01"
"2102.02083","Gao-Ming Deng","Gao-Ming Deng, Jinbo Fan, Xinfei Li","Effects of global monopole on critical behaviors and microstructure of
  charged AdS black holes","14 pages, 18 figures",,"10.1142/S0217732321501911",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an intriguing topological defect, global monopole's influence on behaviors
of black holes has always been anticipated but still remains less clear.
Analyzing the thermodynamics of charged AdS black hole incorporating a global
monopole manifests that the black hole undergoes a first-order phase transition
at critical point, and of special interest, the critical behaviors
qualitatively resemble a Van der Waals liquid-gas system. This paper
concentrates on further investigating the charged AdS black hole with a global
monopole, aiming at clarifying the significant effects of the global monopole
on criticality and microstructure of charged AdS black holes. An interesting
dependence on the internal global monopole can be witnessed intuitively by
employing contrastive illustrations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:37:07 GMT""}]","2021-09-15"
"2102.02084","Eelco Empting","Berthold Reisz, Eelco Empting, Matthias Zwadlo, Martin Hodas, Giuliano
  Duva, Valentina Belova, Clemens Zeiser, Jan Hagenlocher, Santanu Maiti,
  Alexander Hinderhofer, Alexander Gerlach, Martin Oettel, Frank Schreiber","Thin Film Growth of Phase-Separating Phthalocyanine-Fullerene Blends: A
  Combined Experimental and Computational Study","30 pages, 11 figures","Phys. Rev. Materials 5, 045601 (2021)","10.1103/PhysRevMaterials.5.045601",,"cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blended organic thin films have been studied during the last decades due to
their applicability in organic solar cells. Although their optical and
electronic features have been examined intensively, there is still lack of
detailed knowledge about their growth processes and resulting morphologies,
which play a key role for the efficiency of optoelectronic devices such as
organic solar cells. In this study, pure and blended thin films of copper
phthalocyanine (CuPc) and the Buckminster fullerene (C60) were grown by vacuum
deposition onto a native silicon oxide substrate at two different substrate
temperatures, 310 K and 400 K. The evolution of roughness was followed by
in-situ real-time X-ray reflectivity. Crystal orientation, island densities and
morphology were examined after the growth by X-ray diffraction experiments and
microscopy techniques. The formation of a smooth wetting layer followed by
rapid roughening was found in pure CuPc thin films, whereas C60 shows a fast
formation of distinct islands at a very early stage of growth. The growth of
needle-like CuPc crystals loosing their alignment with the substrate was
identified in co-deposited thin films. Furthermore, the data demonstrates that
structural features become larger and more pronounced and that the island
density decreases by a factor of four when going from 310 K to 400 K. Finally,
the key parameters roughness and island density were well reproduced on a
smaller scale by kinetic Monte-Carlo simulations of a generic, binary lattice
model with simple nearest-neighbor interaction energies.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:38:22 GMT""}]","2021-04-14"
"2102.02085","Maria Madjarska","Kyung-Suk Cho and Il-Hyun Cho and Maria S. Madjarska and Valery M.
  Nakariakov and Heesu Yang and Seonghwan Choi and Eun-Kyung Lim and Kyung-Sun
  Lee and Jung-Jun Seough and Jaeok Lee and Yeon-Han Kim","On the Nature of Propagating Intensity Disturbances in Polar Plumes
  during the 2017 Total Solar Eclipse","18 pages, 8 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abdfd5",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The propagating intensity disturbances (PIDs) in plumes are still poorly
understood and their identity (magnetoacoustic waves or flows) remains an open
question. We investigate PIDs in five plumes located in the northern polar
coronal hole observed during the 2017 total solar eclipse. Three plumes are
associated with coronal bright points, jets and macrospicules at their base
(active plumes) and the other two plumes are not (quiet plumes). The electron
temperature at the base of the plumes is obtained from the filter ratio of
images taken with the X-ray Telescope on board Hinode and the passband ratio
around 400 nm from an eclipse instrument, the Diagnostic Coronagraph Experiment
(DICE). The phase speed (v_r), frequency (omega), and wavenumber (k) of the
PIDs in the plumes are obtained by applying a Fourier transformation to the
space-time (r-t plane) plots in images taken with the Atmospheric Imaging
Assembly (AIA) in three different wavelength channels (171 A, 193 A, and 211
A). We found that the PIDs in the higher temperature AIA channels, 193 and 211
A, are faster than that of the cooler AIA 171 A channel. This tendency is more
significant for the active plumes than the quiet ones. The observed speed ratio
(~1.3) between the AIA 171 and 193 A channels is similar to the theoretical
value (1.25) of a slow magnetoacoustic wave. Our results support the idea that
PIDs in plumes represent a superposition of slow magnetoacoustic waves and
plasma outflows that consist of dense cool flows and hot coronal jets.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:39:48 GMT""}]","2021-03-24"
"2102.02086","Zahra Ahmadi","Patrick Abels, Zahra Ahmadi, Sophie Burkhardt, Benjamin Schiller,
  Iryna Gurevych, Stefan Kramer","Focusing Knowledge-based Graph Argument Mining via Topic Modeling",,,,,"cs.IR cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Decision-making usually takes five steps: identifying the problem, collecting
data, extracting evidence, identifying pro and con arguments, and making
decisions. Focusing on extracting evidence, this paper presents a hybrid model
that combines latent Dirichlet allocation and word embeddings to obtain
external knowledge from structured and unstructured data. We study the task of
sentence-level argument mining, as arguments mostly require some degree of
world knowledge to be identified and understood. Given a topic and a sentence,
the goal is to classify whether a sentence represents an argument in regard to
the topic. We use a topic model to extract topic- and sentence-specific
evidence from the structured knowledge base Wikidata, building a graph based on
the cosine similarity between the entity word vectors of Wikidata and the
vector of the given sentence. Also, we build a second graph based on
topic-specific articles found via Google to tackle the general incompleteness
of structured knowledge bases. Combining these graphs, we obtain a graph-based
model which, as our evaluation shows, successfully capitalizes on both
structured and unstructured data.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:39:58 GMT""}]","2021-02-04"
"2102.02087","Marie Roald","Marie Roald, Carla Schenker, Jeremy E. Cohen, Evrim Acar","PARAFAC2 AO-ADMM: Constraints in all modes","5 pages, 4 figures, submitted to EUSIPCO21",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The PARAFAC2 model provides a flexible alternative to the popular
CANDECOMP/PARAFAC (CP) model for tensor decompositions. Unlike CP, PARAFAC2
allows factor matrices in one mode (i.e., evolving mode) to change across
tensor slices, which has proven useful for applications in different domains
such as chemometrics, and neuroscience. However, the evolving mode of the
PARAFAC2 model is traditionally modelled implicitly, which makes it challenging
to regularise it. Currently, the only way to apply regularisation on that mode
is with a flexible coupling approach, which finds the solution through
regularised least-squares subproblems. In this work, we instead propose an
alternating direction method of multipliers (ADMM)-based algorithm for fitting
PARAFAC2 and widen the possible regularisation penalties to any proximable
function. Our numerical experiments demonstrate that the proposed ADMM-based
approach for PARAFAC2 can accurately recover the underlying components from
simulated data while being both computationally efficient and flexible in terms
of imposing constraints.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:42:18 GMT""}]","2021-02-04"
"2102.02088","Jinpeng Li","Jinpeng Li, Yaling Tao, Ting Cai","Investigating Critical Risk Factors in Liver Cancer Prediction","8 pages, 4 figures, conference paper",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We exploit liver cancer prediction model using machine learning algorithms
based on epidemiological data of over 55 thousand peoples from 2014 to the
present. The best performance is an AUC of 0.71. We analyzed model parameters
to investigate critical risk factors that contribute the most to prediction.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:42:58 GMT""}]","2021-02-04"
"2102.02089","Tianlong Ma","Tianlong Ma, Xian'an Jin, Fuji Zhang","Tutte polynomials of fan-like graphs with applications in benzenoid
  systems",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the computation of the Tutte polynomials of fan-like graphs and
obtain expressions of their Tutte polynomials via generating functions. As
applications, Tutte polynomials, in particular, the number of spanning trees,
of two kinds of benzenoid systems, i.e. pyrene chains and triphenylene chains,
are obtained.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:45:39 GMT""}]","2021-02-04"
"2102.02090","Michael Franklin Mbouopda","Michael Franklin Mbouopda and Engelbert Mephu Nguifo","Uncertain Time Series Classification With Shapelet Transform","2020 International Conference on Data Mining Workshops, Sorrento,
  Italy, November 17-20, 2020","2020 IEEE International Conference on Data Mining Workshops
  (ICDMW)","10.1109/ICDMW51313.2020.00044",,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Time series classification is a task that aims at classifying chronological
data. It is used in a diverse range of domains such as meteorology, medicine
and physics. In the last decade, many algorithms have been built to perform
this task with very appreciable accuracy. However, applications where time
series have uncertainty has been under-explored. Using uncertainty propagation
techniques, we propose a new uncertain dissimilarity measure based on Euclidean
distance. We then propose the uncertain shapelet transform algorithm for the
classification of uncertain time series. The large experiments we conducted on
state of the art datasets show the effectiveness of our contribution. The
source code of our contribution and the datasets we used are all available on a
public repository.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:46:01 GMT""}]","2021-06-16"
"2102.02091","Subhankar Dutta","Subhankar Dutta, Suchandan Kayal","Estimation of parameters of the logistic exponential distribution under
  progressive type-I hybrid censored sample",,,"10.1080/16843703.2022.2027601",,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  The paper addresses the problem of estimation of the model parameters of the
logistic exponential distribution based on progressive type-I hybrid censored
sample. The maximum likelihood estimates are obtained and computed numerically
using Newton-Raphson method. Further, the Bayes estimates are derived under
squared error, LINEX and generalized entropy loss functions. Two types
(independent and bivariate) of prior distributions are considered for the
purpose of Bayesian estimation. It is seen that the Bayes estimates are not of
explicit forms.Thus, Lindley's approximation technique is employed to get
approximate Bayes estimates. Interval estimates of the parameters based on
normal approximate of the maximum likelihood estimates and normal approximation
of the log-transformed maximum likelihood estimates are constructed. The
highest posterior density credible intervals are obtained by using the
importance sampling method. Furthermore, numerical computations are reported to
review some of the results obtained in the paper. A real life dataset is
considered for the purpose of illustrations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:46:45 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 07:39:07 GMT""}]","2023-02-13"
"2102.02092","Winston Heap","Winston Heap","On the splitting conjecture in the hybrid model for the Riemann zeta
  function","47 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We show that the splitting conjecture in the hybrid model of
Gonek--Hughes--Keating holds to order on the Riemann hypothesis. Our results
are valid in a larger range of the parameter $X$ which mediates between the
partial Euler and Hadamard products. We also show that the asymptotic splitting
conjecture holds for this larger range of $X$ in the cases of the second and
fourth moments.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:49:46 GMT""}]","2021-02-04"
"2102.02093","Jean-Guy Caputo","Jean-Guy Caputo, Valerie Girardin, Arnaud Knippel, Hieu Nguyen,
  Nathalie Niquil, Quentin Nogues","Analysis of trophic networks: an optimisation approach",,,,,"nlin.AO math.OC","http://creativecommons.org/licenses/by/4.0/","  We introduce a methodology to study the possible matter flows of an ecosystem
defined by observational biomass data and realistic biological constraints. The
flows belong to a polyhedron in a multi dimensional space making statistical
exploration difficult in practice; instead, we propose to solve a convex
optimization problem. Five criteria corresponding to ecological network indices
have been selected to be used as convex goal functions. Numerical results show
that the method is fast and can be used for large systems. Minimum flow
solutions are analyzed using flow decomposition in paths and circuits. Their
consistency is also tested by introducing a system of differential equations
for the biomasses and examining the stability of the biomass fixed point. The
method is illustrated and explained throughout the text on an ecosystem toy
model. It is also applied to realistic food models.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:56:10 GMT""}]","2021-02-04"
"2102.02094","Philip Doyle","Philip R Doyle, Leigh Clark and Benjamin R Cowan","What Do We See in Them? Identifying Dimensions of Partner Models for
  Speech Interfaces Using a Psycholexical Approach","Pre-print version. 14 pages (inc. bib), 3 figures, 5 tables",,"10.1145/3411764.3445206",,"cs.HC cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Perceptions of system competence and communicative ability, termed partner
models, play a significant role in speech interface interaction. Yet we do not
know what the core dimensions of this concept are. Taking a psycholexical
approach, our paper is the first to identify the key dimensions that define
partner models in speech agent interaction. Through a repertory grid study
(N=21), a review of key subjective questionnaires, an expert review of
resulting word pairs and an online study of 356 user of speech interfaces, we
identify three key dimensions that make up a users' partner model: 1)
perceptions toward competence and capability; 2) assessment of human-likeness;
and 3) a system's perceived cognitive flexibility. We discuss the implications
for partner modelling as a concept, emphasising the importance of salience and
the dynamic nature of these perceptions.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:57:08 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 09:43:53 GMT""}]","2021-04-19"
"2102.02095","Turker Ozsari","T\""urker \""Ozsar{\i} and Kemal Cem Y{\i}lmaz","Stabilization of higher order Schr\""odinger equations on a finite
  interval: Part II","78 pages, 16 figures, 1 table",,,,"math.OC math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Backstepping based controller and observer models were designed for higher
order linear and nonlinear Schr\""odinger equations on a finite interval in Part
I of this study where the controller was assumed to be acting from the left
endpoint of the medium. In this companion paper, we further the analysis by
considering boundary controller(s) acting at the right endpoint of the domain.
It turns out that the problem is more challenging in this scenario as the
associated boundary value problem for the backstepping kernel becomes
overdetermined and lacks a smooth solution. The latter is essential to switch
back and forth between the original plant and the so called target system. To
overcome this difficulty we rely on the strategy of using an imperfect kernel,
namely one of the boundary conditions in kernel PDE model is disregarded. The
drawback is that one loses rapid stabilization in comparison with the left
endpoint controllability. Nevertheless, the exponential decay of the $L^2$-norm
with a certain rate still holds. The observer design is associated with new
challenges from the point of view of wellposedness and one has to prove
smoothing properties for an associated initial boundary value problem with
inhomogeneous boundary data. This problem is solved by using Laplace transform
in time. However, the Bromwich integral that inverts the transformed solution
is associated with certain analyticity issues which are treated through a
subtle analysis. Numerical algorithms and simulations verifying the theoretical
results are given.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:58:54 GMT""}]","2021-02-04"
"2102.02096","Siqi Bao","Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zhengyu Niu, Haifeng
  Wang","Learning to Select External Knowledge with Multi-Scale Negative Sampling","To be presented at AAAI-21 DSTC9 Workshop. First two authors
  contributed equally to this work",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Track-1 of DSTC9 aims to effectively answer user requests or questions
during task-oriented dialogues, which are out of the scope of APIs/DB. By
leveraging external knowledge resources, relevant information can be retrieved
and encoded into the response generation for these out-of-API-coverage queries.
In this work, we have explored several advanced techniques to enhance the
utilization of external knowledge and boost the quality of response generation,
including schema guided knowledge decision, negatives enhanced knowledge
selection, and knowledge grounded response generation. To evaluate the
performance of our proposed method, comprehensive experiments have been carried
out on the publicly available dataset. Our approach was ranked as the best in
human evaluation of DSTC9 Track-1.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:59:35 GMT""}]","2021-02-04"
"2102.02097","Takahiro Ishikawa","Takahiro Ishikawa, Taro Fukazawa, Guangzong Xing, Terumasa Tadano,
  Takashi Miyake","Evolutionary search for cobalt-rich compounds in the
  yttrium-cobalt-boron system","5 pages, 4 figures","Phys. Rev. Materials 5, 054408 (2021)","10.1103/PhysRevMaterials.5.054408",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Modern high-performance permanent magnets are made from alloys of rare earth
and transition metal elements, and large magnetization is achieved in the
alloys with high concentration of transition metals. We applied evolutionary
search scheme based on first-principles calculations to the Y-Co-B system and
predicted 37 cobalt-rich compounds with high probability of being stable.
Focusing on remarkably cobalt-rich compounds, YCo$_{16}$ and YCo$_{20}$, we
found that, although they are metastable phases, the phase stability is
increased with increase of temperature due to the contribution of vibrational
entropy. The magnetization and Curie temperature are higher by 0.22 T and 204 K
in YCo$_{16}$ and by 0.29 T and 204 K in YCo$_{20}$ than those of
Y$_{2}$Co$_{17}$ which has been well studied as strong magnetic compounds.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:59:38 GMT""}]","2021-05-26"
"2102.02098","Eoin \'O Colg\'ain","Aritra Banerjee, Eoin \'O Colg\'ain, Misao Sasaki, M. M.
  Sheikh-Jabbari","Lost in the Log-Polynomial Expansion: Comment on arXiv:2101.08278","This timely comment has been absorbed into the earlier preprint
  arXiv:2009.04109, which is now published at PLB. It no longer serves an
  independent purpose",,,,"astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [1] we highlighted the fact that the log polynomial expansion employed in
Nature Astron. 3, no.3, 272-277 (2019) [2] is a poor approximation to flat
$\Lambda$CDM, so using it to infer deviations from flat $\Lambda$CDM is not
well-motivated. The ""orthogonalized logarithmic polynomials"" recently presented
in arXiv:2101.08278 [3] are an attempt to respond to the earlier criticism [1].
Here we demonstrate that this new technique [3] - interesting though it may be
- fails to address the fundamental problem raised in [1]. Unfortunately, the
claim made in [2] may still be lost in the expansion.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:08:17 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 01:05:20 GMT""}]","2021-06-01"
"2102.02099","Serkan Sar{\i}ta\c{s}","Serkan Sar{\i}ta\c{s}, Photios A. Stavrou, Ragnar Thobaben, Mikael
  Skoglund","Quadratic Signaling Games with Channel Combining Ratio","19 pages, 2 figures",,,,"math.OC cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, Nash and Stackelberg equilibria of single-stage and
multi-stage quadratic signaling games between an encoder and a decoder are
investigated. In the considered setup, the objective functions of the encoder
and the decoder are misaligned, there is a noisy channel between the encoder
and the decoder, the encoder has a soft power constraint, and the decoder has
also noisy observation of the source to be estimated. We show that there exist
only linear encoding and decoding strategies at the Stackelberg equilibrium,
and derive the equilibrium strategies and costs. Regarding the Nash
equilibrium, we explicitly characterize affine equilibria for the single-stage
setup and show that the optimal encoder (resp. decoder) is affine for an affine
decoder (resp. encoder) for the multi-stage setup. For the decoder side,
between the information coming from the encoder and noisy observation of the
source, our results describe what should be the combining ratio of these two
channels. Regarding the encoder, we derive the conditions under which it is
meaningful to transmit a message.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:08:18 GMT""}]","2021-02-04"
"2102.02100","Ahmet Ercan Tekden","Ahmet E. Tekden, Aykut Erdem, Erkut Erdem, Tamim Asfour, Emre Ugur","Object and Relation Centric Representations for Push Effect Prediction","Project Page: https://fzaero.github.io/push_learning/",,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pushing is an essential non-prehensile manipulation skill used for tasks
ranging from pre-grasp manipulation to scene rearrangement, reasoning about
object relations in the scene, and thus pushing actions have been widely
studied in robotics. The effective use of pushing actions often requires an
understanding of the dynamics of the manipulated objects and adaptation to the
discrepancies between prediction and reality. For this reason, effect
prediction and parameter estimation with pushing actions have been heavily
investigated in the literature. However, current approaches are limited because
they either model systems with a fixed number of objects or use image-based
representations whose outputs are not very interpretable and quickly accumulate
errors. In this paper, we propose a graph neural network based framework for
effect prediction and parameter estimation of pushing actions by modeling
object relations based on contacts or articulations. Our framework is validated
both in real and simulated environments containing different shaped multi-part
objects connected via different types of joints and objects with different
masses, and it outperforms image-based representations on physics prediction.
Our approach enables the robot to predict and adapt the effect of a pushing
action as it observes the scene. It can also be used for tool manipulation with
never-seen tools. Further, we demonstrate 6D effect prediction in the lever-up
action in the context of robot-based hard-disk disassembly.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:09:12 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 14:29:41 GMT""}]","2023-02-23"
"2102.02101","Bernd Fritzsche","Bernd Fritzsche and Conrad M\""adler","$2\times2$ block representations of the Moore-Penrose inverse and
  orthogonal projection matrices",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, new block representations of Moore-Penrose inverses for
arbitrary complex $2\times2$ block matrices are given. The approach is based on
block representations of orthogonal projection matrices.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:11:56 GMT""}]","2021-02-04"
"2102.02102","F\'elix Cabello S\'anchez","F\'elix Cabello S\'anchez","An example regarding Kalton's paper ""Isomorphisms between spaces of
  vector-valued continuous functions""","4 pages",,,,"math.FA math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper alluded to in the title contains the following striking result: Let
$I$ be the unit interval and $\Delta$ the Cantor set. If $X$ is a quasi Banach
space containing no copy of $c_0$ which is isomorphic to a closed subspace of a
space with a basis and $C(I, X)$ is linearly homeomorphic to $C(\Delta, X)$,
then $X$ is locally convex, i.e., a Banach space.
  It is shown that Kalton result is sharp by exhibiting non locally convex
quasi Banach spaces X with a basis for which $C(I, X)$ and $C(\Delta, X)$ are
isomorphic. Our examples are rather specific and actually in all cases X is
isomorphic to $C(\Delta, X)$ if $K$ is a metric compactum of finite covering
dimension.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:15:53 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 10:50:05 GMT""}]","2021-05-28"
"2102.02103","Christian Reiher","Xizhi Liu, Dhruv Mubayi, and Christian Reiher","Hypergraphs with many extremal configurations","updated references",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  For every positive integer $t$ we construct a finite family of triple systems
${\mathcal M}_t$, determine its Tur\'{a}n number, and show that there are $t$
extremal ${\mathcal M}_t$-free configurations that are far from each other in
edit-distance. We also prove a strong stability theorem: every ${\mathcal
M}_t$-free triple system whose size is close to the maximum size is a subgraph
of one of these $t$ extremal configurations after removing a small proportion
of vertices. This is the first stability theorem for a hypergraph problem with
an arbitrary (finite) number of extremal configurations. Moreover, the extremal
hypergraphs have very different shadow sizes (unlike the case of the famous
Tur\'an tetrahedron conjecture). Hence a corollary of our main result is that
the boundary of the feasible region of ${\mathcal M}_t$ has exactly $t$ global
maxima.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:17:31 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 10:49:42 GMT""}]","2021-02-17"
"2102.02104","Hipolito Treffinger","Hipolito Treffinger","The size of a stratifying system can be arbitrarily large","This version has been accepted for publication in \emph{Comptes
  Rendus Math\'ematique}. A simpler example of stratifying system of infinite
  size is given, leading to a more direct proof",,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this short note we construct two families of examples of large stratifying
systems in module categories of algebras. The first examples consists on
stratifying systems of infinite size in the module category of an algebra $A$.
In the second family of examples we show that the size of a finite stratifying
system in the module category of a finite dimensional algebra $A$ can be
arbitrarily large in comparison to the number of isomorphism classes of simple
$A$-modules. We note that both families of examples are built using
well-established results in higher homological algebra.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:18:04 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 16:50:00 GMT""},{""version"":""v3"",""created"":""Wed, 14 Apr 2021 09:48:33 GMT""},{""version"":""v4"",""created"":""Mon, 20 Jun 2022 09:45:00 GMT""}]","2022-06-22"
"2102.02105","Qingying Xue","Shifen Wang and Qingying Xue","On weighted Compactness of Commutator of semi-group maximal function
  associated to Schr\""odinger operators","arXiv admin note: text overlap with arXiv:2012.12747",,,,"math.CA math.AP","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal{T}^*$ be the semi-group maximal function associated to the
Schr\""odinger operator $-\Delta+V(x)$ with $V$ satisfying an appropriate
reverse H\""{o}lder inequality. In this paper, we show that the commutator of
$\mathcal{T}^*$ is a compact operator on $L^p(w)$ for $1<p<\infty$ if $b\in
\text{CMO}_\theta(\rho)(\mathbb{R}^n)$ and $w\in
A_p^{\rho,\theta}(\mathbb{R}^n)$. Here $\text{ CMO}_\theta(\rho)(\mathbb{R}^n)$
denotes the closure of $\mathcal{C}_c^\infty(\mathbb{R}^n)$ in the
$\text{BMO}_\theta(\rho)(\mathbb{R}^n)$ (which is larger than the classical
$\text{BMO}(\mathbb{R}^n)$ space) topology. The space where $b$ belongs and the
weighs class $w$ belongs are more larger than the usual
$\text{CMO}(\mathbb{R}^n)$ space and the Muckenhoupt $A_p$ weights class,
respectively.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:18:24 GMT""}]","2021-02-04"
"2102.02106","Martin Campos Pinto","Martin Campos Pinto, Jakob Ameres, Katharina Kormann, Eric
  Sonnendr\""ucker","On Geometric Fourier Particle In Cell Methods","40 pages, 34 figures",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we describe a unifying framework for variational
electromagnetic particle schemes of spectral type, and we propose a novel
spectral Particle-In-Cell (PIC) scheme that preserves a discrete Hamiltonian
structure. Our work is based on a new abstract variational derivation of
particle schemes which builds on a de Rham complex where Low's Lagrangian is
discretized using a particle approximation of the distribution function. In
this framework, which extends the recent Finite Element based Geometric
Electromagnetic PIC (GEMPIC) method to a variety of field solvers, the
discretization of the electromagnetic potentials and fields is represented by a
de Rham sequence of compatible spaces, and the particle-field coupling
procedure is described by approximation operators that commute with the
differential operators in the sequence. In particular, for spectral Maxwell
solvers the choice of truncated $L^2$ projections using continuous Fourier
transform coefficients for the commuting approximation operators yields the
gridless Particle-in-Fourier method, whereas spectral Particle-in-Cell methods
are obtained by using discrete Fourier transform coefficients computed from a
grid. By introducing a new sequence of spectral pseudo-differential
approximation operators, we then obtain a novel variational spectral PIC method
with discrete Hamiltonian structure that we call Fourier-GEMPIC. Fully discrete
schemes are then derived using a Hamiltonian splitting procedure, leading to
explicit time steps that preserve the Gauss laws and the discrete Poisson
bracket associated with the Hamiltonian structure. These explicit steps share
many similarities with standard spectral PIC methods. As arbitrary filters are
allowed in our framework, we also discuss aliasing errors and study a natural
back-filtering procedure to mitigate the damping caused by anti-aliasing
smoothing particle shapes.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:19:40 GMT""}]","2021-02-04"
"2102.02107","Mariachiara Manoccio","Mariachiara Manoccio, Marco Esposito, Elisabetta Primiceri, Angelo
  Leo, Massimo Cuscun\`a, Vittorianna Tasco, Dmitry Zuev, Yali Sun, Giuseppe
  Maruccio, Giuseppe Gigli and Adriana Passaseo","Femtomolar Biodetection by a Compact Core-Shell 3D Chiral Metamaterial","13 pages 6 figures plus supporting",,"10.1021/acs.nanolett.1c01791",,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Highly sensitive and selective label free devices for real-time
identification of specific biomarkers are expected to significantly impact the
biosensing field. The ability of plasmonic systems to confine the light in
nanometer volume and to manipulate it by tuning the size, shape and material
features of the nanostructures, makes these systems promising candidates for
biomedical devices. In this work we demonstrate the engineered sensing
capabilities of a compact array of 3D metal dielectric core-shell chiral
metamaterial. The intrinsic chirality of the nano-helices makes the system
circular polarization dependent and unaffected by the background interferences,
allowing to work even in complex environment. The core-shell architecture
enhances the sensing properties of the chiral metamaterial on both in the far
and near field, offering also a large surface to molecular immobilization. With
our system we recorded sensitivity of about 800nm/RIU and FOM= 1276 RIU-1. The
sensing abilities of the system is demonstrated with the detection of the of
the TAR DNA-binding protein 43 (TDP-43) , a critical biomarker for the
screening of neurodegenerative diseases. In particular, the sensor was tested
in different environments, such as human serum, with concentrations ranging
from 1pM down to 10fM, opening new perspectives for novel diagnostic tools.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:23:36 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 08:25:28 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 14:55:58 GMT""},{""version"":""v4"",""created"":""Wed, 10 Feb 2021 13:29:47 GMT""}]","2021-09-14"
"2102.02108","Veit Krause","Veit Krause and Axel Voigt","Deformable active nematic particles and emerging edge currents in
  circular confinements",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a microscopic field theoretical approach for interacting active
nematic particles. With only steric interactions the self-propulsion strength
in such systems can lead to different collective behaviour, e.g., synchronized
self-spinning and collective translation. The different behaviour results from
the delicate interplay between internal nematic structure, particle shape
deformation and particle-particle interaction. For intermediate active strength
an asymmetric shape emerges and leads to chirality and self-spinning crystals.
For larger active strength the shape is symmetric and translational collective
motion emerges. Within circular confinements, depending on the packing
fraction, the self-spinning regime either stabilizes positional and
orientational order or can lead to edge currents and global rotation which
destroys the synchronized self-spinning crystalline structure.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:31:01 GMT""}]","2021-02-04"
"2102.02109","Nick Brown","Maurice Jamieson, Nick Brown","Compact Native Code Generation for Dynamic Languages on Micro-core
  Architectures","Preprint of paper accepted to ACM SIGPLAN 2021 International
  Conference on Compiler Construction (CC 2021)",,,,"cs.PL cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Micro-core architectures combine many simple, low memory, low power-consuming
CPU cores onto a single chip. Potentially providing significant performance and
low power consumption, this technology is not only of great interest in
embedded, edge, and IoT uses, but also potentially as accelerators for
data-center workloads. Due to the restricted nature of such CPUs, these
architectures have traditionally been challenging to program, not least due to
the very constrained amounts of memory (often around 32KB) and idiosyncrasies
of the technology. However, more recently, dynamic languages such as Python
have been ported to a number of micro-cores, but these are often delivered as
interpreters which have an associated performance limitation.
  Targeting the four objectives of performance, unlimited code-size,
portability between architectures, and maintaining the programmer productivity
benefits of dynamic languages, the limited memory available means that classic
techniques employed by dynamic language compilers, such as just-in-time (JIT),
are simply not feasible. In this paper we describe the construction of a
compilation approach for dynamic languages on micro-core architectures which
aims to meet these four objectives, and use Python as a vehicle for exploring
the application of this in replacing the existing micro-core interpreter. Our
experiments focus on the metrics of performance, architecture portability,
minimum memory size, and programmer productivity, comparing our approach
against that of writing native C code. The outcome of this work is the
identification of a series of techniques that are not only suitable for
compiling Python code, but also applicable to a wide variety of dynamic
languages on micro-cores.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:36:31 GMT""}]","2021-02-04"
"2102.02110","Maximin Coavoux","Maximin Coavoux, Shay B. Cohen","Learning to Match Mathematical Statements with Proofs",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel task consisting in assigning a proof to a given
mathematical statement. The task is designed to improve the processing of
research-level mathematical texts. Applying Natural Language Processing (NLP)
tools to research level mathematical articles is both challenging, since it is
a highly specialized domain which mixes natural language and mathematical
formulae. It is also an important requirement for developing tools for
mathematical information retrieval and computer-assisted theorem proving. We
release a dataset for the task, consisting of over 180k statement-proof pairs
extracted from mathematical research articles. We carry out preliminary
experiments to assess the difficulty of the task. We first experiment with two
bag-of-words baselines. We show that considering the assignment problem
globally and using weighted bipartite matching algorithms helps a lot in
tackling the task. Finally, we introduce a self-attention-based model that can
be trained either locally or globally and outperforms baselines by a wide
margin.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:38:54 GMT""}]","2021-02-04"
"2102.02111","Sandra Wankm\""uller","Sandra Wankm\""uller","Introduction to Neural Transfer Learning with Transformers for Social
  Science Text Analysis","80 pages, 12 figures; changed the title; more focused presentation of
  contents; moved contents to the appendix; created a new Figure 9; discussion
  of additional aspects (zero-shot learning, cross-lingual learning,
  interpretability, foundation models); removed old Figures 4 and 5; made
  non-essential changes to Figures 1, 2, 4, 6, 7, 8 and 10; changed notation.
  The original results are unchanged",,,,"cs.CL stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer-based models for transfer learning have the potential to achieve
high prediction accuracies on text-based supervised learning tasks with
relatively few training data instances. These models are thus likely to benefit
social scientists that seek to have as accurate as possible text-based measures
but only have limited resources for annotating training data. To enable social
scientists to leverage these potential benefits for their research, this paper
explains how these methods work, why they might be advantageous, and what their
limitations are. Additionally, three Transformer-based models for transfer
learning, BERT (Devlin et al. 2019), RoBERTa (Liu et al. 2019), and the
Longformer (Beltagy et al. 2020), are compared to conventional machine learning
algorithms on three applications. Across all evaluated tasks, textual styles,
and training data set sizes, the conventional models are consistently
outperformed by transfer learning with Transformers, thereby demonstrating the
benefits these models can bring to text-based social science research.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:41:20 GMT""},{""version"":""v2"",""created"":""Wed, 31 Aug 2022 14:28:33 GMT""}]","2022-09-01"
"2102.02112","Wang Yusheng","Shengqi Hu, Xiaole Su, Yusheng Wang","On the definition of Alexandrov space","12 pages",,,,"math.DG math.MG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper shows that, in the definition of Alexandrov space with lower
([BGP]) or upper ([AKP]) curvature bound, the original conditions can be
replaced with much weaker ones, which can be viewed as comparison versions of
the second variation formula in Riemannian geometry (and thus if we define
Alexandrov spaces using these weakened conditions, then the original definition
will become a local version of Toponogov's Comparison Theorem on such spaces).
As an application, we give a new proof for the Doubling Theorem by Perel'man.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:42:32 GMT""}]","2021-02-04"
"2102.02113","Arvind Suresh","Arvind Suresh","Constructing curves of high rank via composite polynomials","Comments appreciated!",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We improve on a construction of Mestre--Shioda to produce some families of
curves $X/\mathbb{Q}$ of record rank relative to the genus $g$ of $X$. Our
first main result is that for any integer $g \geqslant 8$ with $g \equiv 2
\pmod 3$, there exist infinitely many genus $g$ hyperelliptic curves over
$\mathbb{Q}$ with at least $8g+32$ $\mathbb{Q}$-points and Mordell--Weil rank
$\geqslant 4g + 15$ over $\mathbb{Q}$. Our second main theorem is that if $g+1$
is an odd prime and $K$ contains the $g+1$-th roots of unity, then there exist
infinitely many genus $g$ hyperelliptic curves over $K$ with Mordell--Weil rank
at least $6g$ over $K$.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:44:42 GMT""}]","2021-02-04"
"2102.02114","Irene Li","Irene Li","Detecting Bias in Transfer Learning Approaches for Text Classification","3 figures",,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  Classification is an essential and fundamental task in machine learning,
playing a cardinal role in the field of natural language processing (NLP) and
computer vision (CV). In a supervised learning setting, labels are always
needed for the classification task. Especially for deep neural models, a large
amount of high-quality labeled data are required for training. However, when a
new domain comes out, it is usually hard or expensive to acquire the labels.
Transfer learning could be an option to transfer the knowledge from a source
domain to a target domain. A challenge is that these two domains can be
different, either on the feature distribution, or the class distribution for
the nature of the samples. In this work, we evaluate some existing transfer
learning approaches on detecting the bias of imbalanced classes including
traditional and deep models. Besides, we propose an approach to bridge the gap
of the domain class imbalance issue.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:48:21 GMT""}]","2021-02-04"
"2102.02115","Wolfgang Fuhl","Wolfgang Fuhl and Gjergji Kasneci and Enkelejda Kasneci","TEyeD: Over 20 million real-world eye images with Pupil, Eyelid, and
  Iris 2D and 3D Segmentations, 2D and 3D Landmarks, 3D Eyeball, Gaze Vector,
  and Eye Movement Types","Download: Just connect via FTP as user TEyeDUser and without password
  to nephrit.cs.uni-tuebingen.de (ftp://nephrit.cs.uni-tuebingen.de)",,"10.1109/ismar52148.2021.00053",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present TEyeD, the world's largest unified public data set of eye images
taken with head-mounted devices. TEyeD was acquired with seven different
head-mounted eye trackers. Among them, two eye trackers were integrated into
virtual reality (VR) or augmented reality (AR) devices. The images in TEyeD
were obtained from various tasks, including car rides, simulator rides, outdoor
sports activities, and daily indoor activities. The data set includes 2D and 3D
landmarks, semantic segmentation, 3D eyeball annotation and the gaze vector and
eye movement types for all images. Landmarks and semantic segmentation are
provided for the pupil, iris and eyelids. Video lengths vary from a few minutes
to several hours. With more than 20 million carefully annotated images, TEyeD
provides a unique, coherent resource and a valuable foundation for advancing
research in the field of computer vision, eye tracking and gaze estimation in
modern VR and AR applications.
  Download: Just connect via FTP as user TEyeDUser and without password to
nephrit.cs.uni-tuebingen.de (ftp://nephrit.cs.uni-tuebingen.de).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:48:22 GMT""},{""version"":""v2"",""created"":""Mon, 22 Aug 2022 09:09:11 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jun 2023 08:47:49 GMT""}]","2023-06-07"
"2102.02116","Kazuo Hida","Kazuo Hida","Infinite Series of Ferrimagnetic Phases Emergent from the Gapless Spin
  Liquid Phase of Mixed Diamond Chains",,"J. Phys. Soc. Jpn. 90, 054701 (2021)","10.7566/JPSJ.90.054701",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ground-state phases of mixed diamond chains with ($S, \tau^{(1)},
\tau^{(2)})=(1/2,1/2,1)$, where $S$ is the magnitude of vertex spins, and
$\tau^{(1)}$ and $\tau^{(2)}$ are those of apical spins, are investigated. The
apical spins $\tau^{(1)}$ and $\tau^{(2)}$ are connected with each other by an
exchange coupling $\lambda$. Other exchange couplings are set equal to unity.
This model has an infinite number of local conservation laws. For large
$\lambda$, the ground state is equivalent to that of the uniform spin $1/2$
chain. Hence, the ground state is a gapless spin liquid. For $\lambda \leq 0$,
the ground state is a Lieb-Mattis ferrimagnetic phase with spontaneous
magnetization $m_{\rm sp}=1$ per unit cell. For intermediate $\lambda$, we find
a series of ferrimagnetic phases with $m_{\rm sp}=1/p$ where $p$ takes positive
integer values. The phases with $p \geq 2$ are accompanied by the spontaneous
breakdown of the $p$-fold translational symmetry. It is suggested that the
phase with arbitrarily large $p$, namely infinitesimal spontaneous
magnetization, is allowed as $\lambda$ approaches the transition point to the
gapless spin liquid phase.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:48:30 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 06:54:16 GMT""}]","2021-04-07"
"2102.02117","Anitha Thillaisundaram","Iker de las Heras, Anitha Thillaisundaram","A pro-2 group with full normal Hausdorff spectra","14 pages, revised version",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a $2$-generated pro-$2$ group with full normal Hausdorff
spectrum $[0,1]$, with respect to each of the four standard filtration series:
the $2$-power series, the lower $2$-series, the Frattini series, and the
dimension subgroup series. This answers a question of Klopsch and the second
author, for the even prime case; the odd prime case was settled by the first
author and Klopsch. Also, our construction gives the first example of a
finitely generated pro-$2$ group with full Hausdorff spectrum with respect to
the lower $2$-series.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:48:44 GMT""},{""version"":""v2"",""created"":""Thu, 13 Jan 2022 10:11:18 GMT""}]","2022-01-14"
"2102.02118","Zhongchang Liu","Zhongchang Liu and Wing Shing Wong","Group Consensus of Linear Multi-agent Systems under Nonnegative Directed
  Graphs","to be published in IEEE Transactions on Automatic Control",,"10.1109/TAC.2021.3124985",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Group consensus implies reaching multiple groups where agents belonging to
the same cluster reach state consensus. This paper focuses on linear
multi-agent systems under nonnegative directed graphs. A new necessary and
sufficient condition for ensuring group consensus is derived, which requires
the spanning forest of the underlying directed graph and that of its quotient
graph induced with respect to a clustering partition to contain equal minimum
number of directed trees. This condition is further shown to be equivalent to
containing cluster spanning trees, a commonly used topology for the underlying
graph in the literature. Under a designed controller gain, lower bound of the
overall coupling strength for achieving group consensus is specified. Moreover,
the pattern of the multiple consensus states formed by all clusters is
characterized when the overall coupling strength is large enough.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:48:48 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 14:53:54 GMT""}]","2021-11-16"
"2102.02119","Joerg Osterrieder","Ali Hirsa, Joerg Osterrieder, Branka Hadji Misheva, Wenxin Cao, Yiwen
  Fu, Hanze Sun, Kin Wai Wong","The VIX index under scrutiny of machine learning techniques and neural
  networks",,,,,"q-fin.GN q-fin.TR","http://creativecommons.org/licenses/by/4.0/","  The CBOE Volatility Index, known by its ticker symbol VIX, is a popular
measure of the market's expected volatility on the SP 500 Index, calculated and
published by the Chicago Board Options Exchange (CBOE). It is also often
referred to as the fear index or the fear gauge. The current VIX index value
quotes the expected annualized change in the SP 500 index over the following 30
days, based on options-based theory and current options-market data. Despite
its theoretical foundation in option price theory, CBOE's Volatility Index is
prone to inadvertent and deliberate errors because it is weighted average of
out-of-the-money calls and puts which could be illiquid. Many claims of market
manipulation have been brought up against VIX in recent years.
  This paper discusses several approaches to replicate the VIX index as well as
VIX futures by using a subset of relevant options as well as neural networks
that are trained to automatically learn the underlying formula. Using subset
selection approaches on top of the original CBOE methodology, as well as
building machine learning and neural network models including Random Forests,
Support Vector Machines, feed-forward neural networks, and long short-term
memory (LSTM) models, we will show that a small number of options is sufficient
to replicate the VIX index. Once we are able to actually replicate the VIX
using a small number of SP options we will be able to exploit potential
arbitrage opportunities between the VIX index and its underlying derivatives.
The results are supposed to help investors to better understand the options
market, and more importantly, to give guidance to the US regulators and CBOE
that have been investigating those manipulation claims for several years.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:49:56 GMT""}]","2021-06-17"
"2102.02120","Ashley Montanaro","Ashley Montanaro and Stasja Stanisic","Error mitigation by training with fermionic linear optics","11 pages, 4 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noisy intermediate-scale quantum (NISQ) computers could solve
quantum-mechanical simulation problems that are beyond the capabilities of
classical computers. However, NISQ devices experience significant errors which,
if not corrected, can render physical quantities measured in these simulations
inaccurate or meaningless. Here we describe a method of reducing these errors
which is tailored to quantum algorithms for simulating fermionic systems. The
method is based on executing quantum circuits in the model of fermionic linear
optics, which are known to be efficiently simulable classically, to infer the
relationship between exact and noisy measurement outcomes, and hence undo the
effect of noise. We validated our method by applying it to the VQE algorithm
for estimating ground state energies of instances of the Fermi-Hubbard model.
In classical numerical simulations of 12-qubit examples with physically
realistic levels of depolarising noise, errors were reduced by a factor of
around 34 compared with the uncorrected case. Smaller experiments on quantum
hardware demonstrate an average reduction in errors by a factor of 10 or more.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:56:23 GMT""}]","2021-02-04"
"2102.02121","Daniele Petrone","Daniele Petrone, Neofytos Rodosthenous, Vito Latora","Artificial intelligence applied to bailout decisions in financial
  systemic risk management","12 pages, 6 figures","Nature Communications 13, 6815 (2022)","10.1038/s41467-022-34102-1",,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the bailout of banks by governments as a Markov Decision Process
(MDP) where the actions are equity investments. The underlying dynamics is
derived from the network of financial institutions linked by mutual exposures,
and the negative rewards are associated to the banks' default. Each node
represents a bank and is associated to a probability of default per unit time
(PD) that depends on its capital and is increased by the default of
neighbouring nodes. Governments can control the systemic risk of the network by
providing additional capital to the banks, lowering their PD at the expense of
an increased exposure in case of their failure. Considering the network of
European global systemically important institutions, we find the optimal
investment policy that solves the MDP, providing direct indications to
governments and regulators on the best way of action to limit the effects of
financial crises.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 15:56:47 GMT""}]","2022-12-27"
"2102.02204","Vahid Salari","Mina Abbaszadeh, S. Shahin Mousavi, Vahid Salari","Parametrized Quantum Circuits of Synonymous Sentences in Quantum Natural
  Language Processing",,,,,"quant-ph cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a compositional vector-based semantics of positive
transitive sentences in quantum natural language processing for a non-English
language, i.e. Persian, to compare the parametrized quantum circuits of two
synonymous sentences in two languages, English and Persian. By considering
grammar+meaning of a transitive sentence, we translate DisCoCat diagram via
ZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite
DisCoCat diagram and turn into quantum circuit in the semantic side.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:11:41 GMT""}]","2021-02-05"
"2102.02205","Heitor Ernandes","H. Ernandes, C. J. Evans, B. Barbuy, B. Castilho, G. Cescutti, N.
  Christlieb, S. Cristiani, G. Cupani, P. Di Marcantonio, M. Franchini, C.
  Hansen, A. Quirrenbach, R. Smiljanic","Stellar astrophysics in the near UV with VLT-CUBES",,"Proceedings of the SPIE, Volume 11447, id. 1144760 11 pp. (2020)","10.1117/12.2562497",,"astro-ph.IM astro-ph.GA astro-ph.SR physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alongside future observations with the new European Extremely Large Telescope
(ELT), optimised instruments on the 8-10m generation of telescopes will still
be competitive at 'ground UV' wavelengths (3000-4000 A). The near UV provides a
wealth of unique information on the nucleosynthesis of iron-peak elements,
molecules, and neutron-capture elements. In the context of development of the
near-UV CUBES spectrograph for ESO's Very Large Telescope (VLT), we are
investigating the impact of spectral resolution on the ability to estimate
chemical abundances for beryllium and more than 30 iron-peak and heavy
elements. From work ahead of the Phase A conceptual design of CUBES, here we
present a comparison of the elements observable at the notional resolving power
of CUBES (R~20,000) to those with VLT-UVES (R~40,000). For most of the
considered lines signal-to-noise is a more critical factor than resolution. We
summarise the elements accessible with CUBES, several of which (e.g. Be, Ge,
Hf) are now the focus of quantitative simulations as part of the ongoing Phase
A study.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 03:38:34 GMT""}]","2021-02-05"
"2102.02622","Kelly Widdicks","Charlotte Freitag, Mike Berners-Lee, Kelly Widdicks, Bran Knowles,
  Gordon Blair and Adrian Friday","The climate impact of ICT: A review of estimates, trends and regulations",,,,,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this report, we examine the available evidence regarding ICT's current and
projected climate impacts. We examine peer-reviewed studies which estimate
ICT's current share of global greenhouse gas (GHG) emissions to be 1.8-2.8% of
global GHG emissions. Our findings indicate that published estimates all
underestimate the carbon footprint of ICT, possibly by as much as 25%, by
failing to account for all of ICT's supply chains and full lifecycle (i.e.
emissions scopes 1, 2 and fully inclusive 3). Adjusting for truncation of
supply chain pathways, we estimate that ICT's share of emissions could actually
be as high as 2.1-3.9%.
  There are pronounced differences between available projections of ICT's
future emissions. These projections are dependent on underlying assumptions
that are sometimes, but not always, made explicit - and we explore these in the
report. Whatever assumptions analysts take, they agree that ICT will not reduce
its emissions without a major concerted effort involving broad political and
industrial action. We provide three reasons to believe ICT emissions are going
to increase barring a targeted intervention, and we note that in light of
these, it seems risky to assume that ICT will, by default, assist in the
attainment of climate targets.
  Based on our analysis, we find that not all carbon pledges in the ICT sector
are ambitious enough to meet climate targets. We explore the underdevelopment
of mechanisms for enforcing sector-wide compliance, and contend that without a
global carbon constraint, a new regulatory framework is required to keep the
ICT sector's carbon footprint in alignment with the Paris Agreement. We further
contend that a global carbon constraint should be viewed as a significant
opportunity for the ICT sector, as efficiencies within and enabled by ICT would
be even greater enablers of productivity and utility than they are today.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 14:26:04 GMT""}]","2021-02-05"
"2102.02624","Giorgio Camerani","Giorgio Camerani","The #ETH is False, #k-SAT is in Sub-Exponential Time","12 pages, 1 figure",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We orchestrate a randomized algorithm for #$k$-SAT which counts the exact
number of satisfying assignments in $2^{o(n)}$ time. The existence of such
algorithm signifies that the #ETH is hereby refuted, and so are $\oplus$ETH,
ETH, #SETH, $\oplus$SETH and SETH.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:41:47 GMT""}]","2021-02-05"
"2102.02634","Teboho Abram Moloi","Teboho Moloi","Spherical Bessel functions",,,,,"math.GM","http://creativecommons.org/licenses/by-sa/4.0/","  We examine indefinite integral involving of arbitrary power $x$, multiplied
by three spherical Bessel functions of the first kind $j_{h},j_{k}$, and
$j_{l}$ with integer order $h,k,l \geq 0$ and an exponential. Then we add some
conditions for smooth calculation in considering the general and elementary
exact evaluation. Thus, by measuring their equivalents, we can verify their
accuracy
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:06:22 GMT""},{""version"":""v2"",""created"":""Wed, 16 Nov 2022 12:22:16 GMT""}]","2022-11-17"
"2102.02638","Letian Zhang","Letian Zhang, Lixing Chen, Jie Xu","Autodidactic Neurosurgeon: Collaborative Deep Inference for Mobile Edge
  Intelligence via Online Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent breakthroughs in deep learning (DL) have led to the emergence of many
intelligent mobile applications and services, but in the meanwhile also pose
unprecedented computing challenges on resource-constrained mobile devices. This
paper builds a collaborative deep inference system between a
resource-constrained mobile device and a powerful edge server, aiming at
joining the power of both on-device processing and computation offloading. The
basic idea of this system is to partition a deep neural network (DNN) into a
front-end part running on the mobile device and a back-end part running on the
edge server, with the key challenge being how to locate the optimal partition
point to minimize the end-to-end inference delay. Unlike existing efforts on
DNN partitioning that rely heavily on a dedicated offline profiling stage to
search for the optimal partition point, our system has a built-in online
learning module, called Autodidactic Neurosurgeon (ANS), to automatically learn
the optimal partition point on-the-fly. Therefore, ANS is able to closely
follow the changes of the system environment by generating new knowledge for
adaptive decision making. The core of ANS is a novel contextual bandit learning
algorithm, called $\mu$LinUCB, which not only has provable theoretical learning
performance guarantee but also is ultra-lightweight for easy real-world
implementation. We implement our system on a video stream object detection
testbed to validate the design of ANS and evaluate its performance. The
experiments show that ANS significantly outperforms state-of-the-art benchmarks
in terms of tracking system changes and reducing the end-to-end inference
delay.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 18:50:06 GMT""}]","2021-02-05"
"2102.02649","Kleber Padovani","Kleber Padovani, Roberto Xavier, Andre Carvalho, Anna Reali, Annie
  Chateau, Ronnie Alves","A step towards a reinforcement learning de novo genome assembler",,,,,"q-bio.GN cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The use of reinforcement learning has proven to be very promising for solving
complex activities without human supervision during their learning process.
However, their successful applications are predominantly focused on fictional
and entertainment problems - such as games. Based on the above, this work aims
to shed light on the application of reinforcement learning to solve this
relevant real-world problem, the genome assembly. By expanding the only
approach found in the literature that addresses this problem, we carefully
explored the aspects of intelligent agent learning, performed by the Q-learning
algorithm, to understand its suitability to be applied in scenarios whose
characteristics are more similar to those faced by real genome projects. The
improvements proposed here include changing the previously proposed reward
system and including state space exploration optimization strategies based on
dynamic pruning and mutual collaboration with evolutionary computing. These
investigations were tried on 23 new environments with larger inputs than those
used previously. All these environments are freely available on the internet
for the evolution of this research by the scientific community. The results
suggest consistent performance progress using the proposed improvements,
however, they also demonstrate the limitations of them, especially related to
the high dimensionality of state and action spaces. We also present, later, the
paths that can be traced to tackle genome assembly efficiently in real
scenarios considering recent, successfully reinforcement learning applications
- including deep reinforcement learning - from other domains dealing with
high-dimensional inputs.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 23:43:42 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 23:16:39 GMT""},{""version"":""v3"",""created"":""Thu, 3 Nov 2022 17:23:25 GMT""}]","2022-11-04"
"2102.02661","Siddhant Das","Siddhant Das and Markus N\""oth","Times of Arrival and Gauge Invariance","9 pages, 1 figure",,"10.1098/rspa.2021.0101",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We revisit the arguments underlying two well-known arrival-time distributions
in quantum mechanics, viz., the Aharonov-Bohm and Kijowski (ABK) distribution,
applicable for freely moving particles, and the quantum flux (QF) distribution.
An inconsistency in the original axiomatic derivation of Kijowski's result is
pointed out, along with an inescapable consequence of the ""negative arrival
times"" inherent to this proposal (and generalizations thereof). The ABK
free-particle restriction is lifted in a discussion of an explicit arrival-time
setup featuring a charged particle moving in a constant magnetic field. A
natural generalization of the ABK distribution is in this case shown to be
critically gauge-dependent. A direct comparison to the QF distribution, which
does not exhibit this flaw, is drawn (its acknowledged drawback concerning the
quantum backflow effect notwithstanding).
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:44:40 GMT""}]","2021-07-07"
"2102.02662","Alexey Chernyavskiy","Elvira Zainulina, Alexey Chernyavskiy, Dmitry V. Dylov","No-reference denoising of low-dose CT projections","Accepted to ISBI 2021",,,,"eess.IV cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Low-dose computed tomography (LDCT) became a clear trend in radiology with an
aspiration to refrain from delivering excessive X-ray radiation to the
patients. The reduction of the radiation dose decreases the risks to the
patients but raises the noise level, affecting the quality of the images and
their ultimate diagnostic value. One mitigation option is to consider pairs of
low-dose and high-dose CT projections to train a denoising model using deep
learning algorithms; however, such pairs are rarely available in practice. In
this paper, we present a new self-supervised method for CT denoising. Unlike
existing self-supervised approaches, the proposed method requires only noisy CT
projections and exploits the connections between adjacent images. The
experiments carried out on an LDCT dataset demonstrate that our method is
almost as accurate as the supervised approach, while also outperforming the
considered self-supervised denoising methods.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:51:33 GMT""}]","2021-02-05"
"2102.02663","Richard Paris","R B Paris","Asymptotics of some integrals involving modified Bessel and hyper-Bessel
  functions","12 pages, 0 figures",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  We investigate the asymptotic expansion of integrals analogous to Ball's
integral \[\int_0^\infty
\left(\frac{\Gamma(1+\nu)|J_\nu(x)|}{(x/2)^\nu}\right)^{\!n}dx\] for large $n$
in which the Bessel function $J_\nu(x)$ is replaced by the modified Bessel
functions $I_\nu(x)$ and $K_\nu(x)$ together with appropriate exponential
factors $e^{\mp x}$, respectively.
  The above integral with $J_\nu(x)$ replaced by a hyper-Bessel function of the
type recently discussed in Aktas {\it et al.} [The Ramanujan J., 2019] and
taken over a finite interval determined by the first positive zero of the
function is also considered for $n\to\infty$. We give the leading asymptotic
behaviour of the hyper-Bessel function for $x\to+\infty$ in an appendix.
Numerical examples are given to illustrate the accuracy of the various
expansions obtained.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:10:02 GMT""}]","2021-02-05"
"2102.02664","C\'esar Quilodr\'an-Casas","C\'esar Quilodr\'an-Casas, Vinicius Santos Silva, Rossella Arcucci,
  Claire E. Heaney, Yike Guo, Christopher C. Pain","Digital twins based on bidirectional LSTM and GAN for modelling the
  COVID-19 pandemic","44 pages, 17 figures, 3 tables",,,,"cs.LG physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outbreak of the coronavirus disease 2019 (COVID-19) has now spread
throughout the globe infecting over 150 million people and causing the death of
over 3.2 million people. Thus, there is an urgent need to study the dynamics of
epidemiological models to gain a better understanding of how such diseases
spread. While epidemiological models can be computationally expensive, recent
advances in machine learning techniques have given rise to neural networks with
the ability to learn and predict complex dynamics at reduced computational
costs. Here we introduce two digital twins of a SEIRS model applied to an
idealised town. The SEIRS model has been modified to take account of spatial
variation and, where possible, the model parameters are based on official virus
spreading data from the UK. We compare predictions from a data-corrected
Bidirectional Long Short-Term Memory network and a predictive Generative
Adversarial Network. The predictions given by these two frameworks are accurate
when compared to the original SEIRS model data.
  Additionally, these frameworks are data-agnostic and could be applied to
towns, idealised or real, in the UK or in other countries. Also, more
compartments could be included in the SEIRS model, in order to study more
realistic epidemiological behaviour.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:54:24 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 11:33:07 GMT""}]","2021-05-10"
"2102.02665","Christian Schorr","Christian Schorr","Hybrid consistency and plausibility verification of product data
  according to FIC","42 pages, 6 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The labelling of food products in the EU is regulated by the Food Information
of Customers (FIC). Companies are required to provide the corresponding
information regarding nutrients and allergens among others. With the rise of
e-commerce more and more food products are sold online. There are often errors
in the online product descriptions regarding the FIC-relevant information due
to low data quality in the vendors' product data base. In this paper we propose
a hybrid approach of both rule-based and machine learning to verify nutrient
declaration and allergen labelling according to FIC requirements. Special focus
is given to the problem of false negatives in allergen prediction since this
poses a significant health risk to customers. Results show that a neural net
trained on a subset of the ingredients of a product is capable of predicting
the allergens contained with a high reliability.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:37:43 GMT""}]","2021-02-05"
"2102.02667","Farook Rahaman","Monimala Mondal, Farook Rahaman, Ksh. Newton Singh","Lyapunov exponent ISCO and Kolmogorov Senai entropy for Kerr Kiselev
  black hole","16 pages, 5 figures. Published in EPJC","Eur. Phys. J. C (2021) 81:84","10.1140/epjc/s10052-021-08888-1",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  Geodesic motion has significant characteristics of space-time. We calculate
the principle Lyapunov exponent (LE), which is the inverse of the instability
timescale associated with this geodesics and Kolmogorov-Senai (KS) entropy for
our rotating Kerr-Kiselev (KK) black hole. We have investigate the existence of
stable/unstable equatorial circular orbits via LE and KS entropy for time-like
and null circular geodesics. We have shown that both LE and KS entropy can be
written in terms of the radial equation of innermost stable circular orbit
(ISCO) for time-like circular orbit. Also, we computed the equation marginally
bound circular orbit, which gives the radius (smallest real root) of marginally
bound circular orbit (MBCO). We found that the null circular geodesics has
larger angular frequency than time-like circular geodesics ($Q_o >
Q_{\sigma}$). Thus, null-circular geodesics provides the fastest way to
circulate KK black holes. Further, it is also to be noted that null circular
geodesics has shortest orbital period $(T_{photon}< T_{ISCO})$ among the all
possible circular geodesics. Even null circular geodesics traverses fastest
than any stable time-like circular geodesics other than the ISCO.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:51:38 GMT""}]","2021-02-05"
"2102.02668","Qing Xu","Michael Shub, Qing Xu, Xiaohua (Michael) Xuan","Disease Prediction with a Maximum Entropy Method","15 pages",,,,"cs.LG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a maximum entropy method for predicting disease
risks. It is based on a patient's medical history with diseases coded in ICD-10
which can be used in various cases. The complete algorithm with strict
mathematical derivation is given. We also present experimental results on a
medical dataset, demonstrating that our method performs well in predicting
future disease risks and achieves an accuracy rate twice that of the
traditional method. We also perform a comorbidity analysis to reveal the
intrinsic relation of diseases.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:09:12 GMT""}]","2021-02-05"
"2102.02669","Xiaoyu Zhang","Xiaoyu Zhang, Yuting Xing, Kai Sun, Yike Guo","OmiEmbed: a unified multi-task deep learning framework for multi-omics
  data","14 pages, 8 figures, 7 tables","Cancers 2021, 13(12), 3047","10.3390/cancers13123047",,"q-bio.GN cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dimensional omics data contains intrinsic biomedical information that is
crucial for personalised medicine. Nevertheless, it is challenging to capture
them from the genome-wide data due to the large number of molecular features
and small number of available samples, which is also called 'the curse of
dimensionality' in machine learning. To tackle this problem and pave the way
for machine learning aided precision medicine, we proposed a unified multi-task
deep learning framework named OmiEmbed to capture biomedical information from
high-dimensional omics data with the deep embedding and downstream task
modules. The deep embedding module learnt an omics embedding that mapped
multiple omics data types into a latent space with lower dimensionality. Based
on the new representation of multi-omics data, different downstream task
modules were trained simultaneously and efficiently with the multi-task
strategy to predict the comprehensive phenotype profile of each sample.
OmiEmbed support multiple tasks for omics data including dimensionality
reduction, tumour type classification, multi-omics integration, demographic and
clinical feature reconstruction, and survival prediction. The framework
outperformed other methods on all three types of downstream tasks and achieved
better performance with the multi-task strategy comparing to training them
individually. OmiEmbed is a powerful and unified framework that can be widely
adapted to various application of high-dimensional omics data and has a great
potential to facilitate more accurate and personalised clinical decision
making.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:34:29 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 15:45:00 GMT""}]","2021-06-22"
"2102.02670","Huiyuan Deng","Huiyuan Deng, Xiangzhu Meng, Lin Feng","Multimodal-Aware Weakly Supervised Metric Learning with Self-weighting
  Triplet Loss",,,,,"cs.LG cs.AI cs.MM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, we have witnessed a surge of interests in learning a
suitable distance metric from weakly supervised data. Most existing methods aim
to pull all the similar samples closer while push the dissimilar ones as far as
possible. However, when some classes of the dataset exhibit multimodal
distribution, these goals conflict and thus can hardly be concurrently
satisfied. Additionally, to ensure a valid metric, many methods require a
repeated eigenvalue decomposition process, which is expensive and numerically
unstable. Therefore, how to learn an appropriate distance metric from weakly
supervised data remains an open but challenging problem. To address this issue,
in this paper, we propose a novel weakly supervised metric learning algorithm,
named MultimoDal Aware weakly supervised Metric Learning (MDaML). MDaML
partitions the data space into several clusters and allocates the local cluster
centers and weight for each sample. Then, combining it with the weighted
triplet loss can further enhance the local separability, which encourages the
local dissimilar samples to keep a large distance from the local similar
samples. Meanwhile, MDaML casts the metric learning problem into an
unconstrained optimization on the SPD manifold, which can be efficiently solved
by Riemannian Conjugate Gradient Descent (RCGD). Extensive experiments
conducted on 13 datasets validate the superiority of the proposed MDaML.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:27:05 GMT""}]","2021-02-05"
"2102.02671","Tim Miller","Ronal Singh, Paul Dourish, Piers Howe, Tim Miller, Liz Sonenberg,
  Eduardo Velloso and Frank Vetere","Directive Explanations for Actionable Explainability in Machine Learning
  Applications",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the prospects of using directive explanations to
assist people in achieving recourse of machine learning decisions. Directive
explanations list which specific actions an individual needs to take to achieve
their desired outcome. If a machine learning model makes a decision that is
detrimental to an individual (e.g. denying a loan application), then it needs
to both explain why it made that decision and also explain how the individual
could obtain their desired outcome (if possible). At present, this is often
done using counterfactual explanations, but such explanations generally do not
tell individuals how to act. We assert that counterfactual explanations can be
improved by explicitly providing people with actions they could use to achieve
their desired goal. This paper makes two contributions. First, we present the
results of an online study investigating people's perception of directive
explanations. Second, we propose a conceptual model to generate such
explanations. Our online study showed a significant preference for directive
explanations ($p<0.001$). However, the participants' preferred explanation type
was affected by multiple factors, such as individual preferences, social
factors, and the feasibility of the directives. Our findings highlight the need
for a human-centred and context-specific approach for creating directive
explanations.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 01:46:55 GMT""}]","2021-02-05"
"2102.02767","Lukas Bernreiter","Lukas Bernreiter, Lionel Ott, Juan Nieto, Roland Siegwart and Cesar
  Cadena","PHASER: a Robust and Correspondence-free Global Pointcloud Registration",,"IEEE Robotics and Automation Letters ( Volume: 6, Issue: 2, April
  2021)","10.1109/LRA.2021.3052418",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose PHASER, a correspondence-free global registration of
sensor-centric pointclouds that is robust to noise, sparsity, and partial
overlaps. Our method can seamlessly handle multimodal information and does not
rely on keypoint nor descriptor preprocessing modules. By exploiting properties
of Fourier analysis, PHASER operates directly on the sensor's signal, fusing
the spectra of multiple channels and computing the 6-DoF transformation based
on correlation. Our registration pipeline starts by finding the most likely
rotation followed by computing the most likely translation. Both estimates are
distributed according to a probability distribution that takes the underlying
manifold into account, i.e., a Bingham and Gaussian distribution, respectively.
This further allows our approach to consider the periodic-nature of rotations
and naturally represent its uncertainty. We extensively compare PHASER against
several well-known registration algorithms on both simulated datasets, and
real-world data acquired using different sensor configurations. Our results
show that PHASER can globally align pointclouds in less than 100ms with an
average accuracy of 2cm and 0.5deg, is resilient against noise, and can handle
partial overlap.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:07:37 GMT""}]","2021-02-05"
"2102.02768","Md Shahzamal","Md Shahzamal and Saeed Khan","A survey on modelling of infectious disease spread and control on social
  contact networks","Under submission. part of arXiv:1906.02856",,,,"physics.soc-ph cs.SI q-bio.PE","http://creativecommons.org/publicdomain/zero/1.0/","  Infectious diseases are a significant threat to human society which was over
sighted before the incidence of COVID-19, although according to the report of
the World Health Organisation (WHO) about 4.2 million people die annually due
to infectious disease. Due to recent COVID-19 pandemic, more than 2 million
people died during 2020 and 96.2 million people got affected by this
devastating disease. Recent research shows that applying individual
interactions and movements data could help managing the pandemic though
modelling the spread of infectious diseases on social contact networks.
Infectious disease spreading can be explained with the theories and methods of
diffusion processes where a dynamic phenomena evolves on networked systems. In
the modelling of diffusion process, it is assumed that contagious items spread
out in the networked system through the inter-node interactions. This resembles
spreading of infectious virus, e.g. spread of COVID-19, within a population
through individual social interactions. The evolution behaviours of the
diffusion process are strongly influenced by the characteristics of the
underlying system and the mechanism of the diffusion process itself. Thus,
spreading of infectious disease can be explained how people interact with each
other and by the characteristics of the disease itself. This paper presenters
the relevant theories and methodologies of diffusion process that can be used
to model the spread of infectious diseases.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 11:10:15 GMT""}]","2021-02-05"
"2102.02772","Abrar Faiyaz","Abrar Faiyaz, Marvin Doyley, Giovanni Schifitto, Jianhui Zhong, Md
  Nasir Uddin","Single-Shell NODDI Using Dictionary Learner Estimated Isotropic Volume
  Fraction","56 pages, 9 Figures, 2 Tables, Supplementary Document (attached)",,,,"physics.med-ph cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neurite orientation dispersion and density imaging (NODDI) enables the
assessment of intracellular, extracellular and free water signals from
multi-shell diffusion MRI data. It is an insightful approach to characterize
brain tissue microstructure. Single-shell reconstruction for NODDI parameters
has been discouraged in previous studies caused by failure when fitting,
especially for the neurite density index (NDI). Here, we investigated the
possibility of creating robust NODDI parameter maps with single-shell data,
using the isotropic volume fraction (fISO) as prior. Prior estimation was made
independent of the NODDI model constraint using a dictionary learning approach.
First, we used a stochastic sparse dictionary-based network (DictNet) in
predicting fISO which is trained with data obtained from in vivo and simulated
diffusion MRI data. In single-shell cases, the mean diffusivity (MD) and raw T2
signal with no diffusion weighting (S0) was incorporated in the dictionary for
the fISO estimation. Then, the NODDI framework was used with the known fISO to
estimate the NDI and orientation dispersion index (ODI). The fISO estimated by
our model was compared with other fISO estimators in the simulation. Further,
using both synthetic data simulation and human data collected on a 3T scanner,
we compared the performance of our dictionary-based learning prior NODDI (DLpN)
with the original NODDI for both single-shell and multi-shell data. Our results
suggest that DLpN derived NDI and ODI parameters for single-shell protocols are
comparable with original multi-shell NODDI, and protocol with b=2000 s/mm2
performs the best (error ~5% in white and grey matter). This may allow NODDI
evaluation of studies on single-shell data by multi-shell scanning of two
subjects for DictNet fISO training.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:43:09 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 23:37:17 GMT""}]","2021-04-06"
"2102.02775","Jamal Benbourenane","Jamal Benbourenane, Mohamed Benbourenane, Hichem Eleuch","Solvable Schrodinger Equations of Shape Invariant Potentials Having
  Superpotential W(x,A,B)=Atanh(px)+Btanh(6px)","16 pages, 2 figures, 1 table",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A new proposed one dimensional time independent Schr\""odinger equation is
solved completely using shape invariance method. The corresponding potential is
given by V_(x,A,B) =-A(sechpx)^2 - 6Bp(sech6px)^2+(tanhpx-6tanh6px)^2 with
superpotential W(x,A,B) = Atanh(px)+Btanh(6px). We derive the exact solutions
of the family of Schr\""odinger equations with the V_- potential partner using
supersymmetric quantum mechanics technique of a superpotential having shape
invariance property, and where the discrete spectrum and the corresponding
eigenfunctions are determined exactly and in closed form. It is well-known that
Schr\""odinger equations are challenging to solve in closed form, and only a few
of them are known. Finding new equations with exact solutions is crucial in
understanding the hidden physical properties near turning points where
numerical methods fail in these vicinities. This result has potential
applications in nuclear physics and chemistry where the antagonist forces have
a prominent presence.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 20:22:47 GMT""}]","2021-02-05"
"2102.03165","Mangilal Choudhary","Mangilal Choudhary","Perspective: The dusty plasma experiments a learning tool for physics
  graduate students","13,10",,"10.1088/1361-6404/abfdfb",,"physics.ed-ph physics.plasm-ph physics.pop-ph","http://creativecommons.org/licenses/by/4.0/","  The plasma is an ionized gas that responses collectively to any external (or
internal) perturbations. Introducing micron-sized solid dust grains into plasma
makes it more interesting. The solid grains acquire large negative charges on
their surface and exhibits collective behavior similar to the ambient plasma
medium. Some remarkable features of the charged dust grain medium (dusty
plasma) allow us to use it as a model system to understand some complex
phenomena at a microscopic level. In this perspective paper, the author
highlights the role of dusty plasma experiments as a learning tool at
undergraduate and post-graduate physics programs. The students could have great
opportunities to understand some basic physical phenomena as well as to learn
many advanced data analysis tools and techniques by performing dusty plasma
experiments. How a single dusty plasma experimental device at a physics
laboratory can help undergraduate and post-graduate students in the learning
process is discussed.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 12:36:31 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 06:05:01 GMT""}]","2021-07-07"
"2102.03379","Jayprakash Singh","Jay Prakash Singh, Sameer Kumar, and Shradha Mishra","Bond disorder enhances the information transfer in polar flock","7 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2005.03862","J. Stat. Mech. (2021) 083217","10.1088/1742-5468/ac1666",,"cond-mat.soft","http://creativecommons.org/publicdomain/zero/1.0/","  Collection of self-propelled particles (SPPs) exhibit coherent motion and
show true long-range order in two-dimensions. Inhomogeneity, in general
destroys the usual long-range order of the polar SPPs. We model a system of
polar self-propelled particles with inhomogeneous interaction strength or bond
disorder. The system is studied near the order-to-disorder transition for
different strengths of the disorder. The nature of phase transition changes
from discontinuous to continuous type by tuning the strength of the disorder.
The bond disorder also enhances the ordering near the transition due to the
formation of a homogeneous flock state for the large disorder. It leads to
faster information transfer in the system and enhances the system information
entropy. Our study gives a new understanding of the effect of intrinsic
inhomogeneity in the self-propelled particle system.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 16:38:33 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 18:56:14 GMT""}]","2021-10-08"
"2102.04250","Duc Kinh Le Tran","Duc Kinh Le Tran","Riiid! Answer Correctness Prediction Kaggle Challenge: 4th Place
  Solution Summary",,,,,"cs.CY cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper presents my solution to the challenge ""Riiid! Answer Correctness
Prediction"" on Kaggle hosted by Riiid Labs (2020), which scores 0.817 (AUC) and
ranks 4th on the final private leaderboard. It is a single transformer-based
model heavily inspired from previous works such as SAKT, SAINT and SAINT+.
Novel ingredients that I believed to have made a difference are the time-aware
attention mechanism, the concatenation of the embeddings of the input sequences
and the embedding of continuous features.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:55:51 GMT""}]","2021-02-09"
"2102.04253","Ryan Ogliore","Ryan Ogliore, Kazuhide Nagashima, Gary Huss, Pierre Haenecour","A Reassessment of the Quasi-Simultaneous Arrival Effect in Secondary Ion
  Mass Spectrometry","In press at Nuclear Inst. and Methods in Physics Research, B",,"10.1016/j.nimb.2021.01.007",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Quasi-simultaneous arrival (QSA) effects in secondary ion mass spectrometry
can create mass-indepedent inaccuracies in isotope measurements when using
electron multiplier detectors (EMs). The simple Poisson statistical model of
QSA does not explain most experimental data. We present pulse-height
distributions (PHDs) and time-series measurements to better study QSA. Our data
show that PHDs and the distribution of multiple arrivals on the EM are not
consistent with the Poisson model. Multiple arrivals are over-dispersed
compared to Poisson and are closer to a negative binomial distribution. Through
an emission-transmission-detection model we show that the QSA correction
depends on the non-Poisson emission of multiple secondary ions, the secondary
ion energy distribution, and other factors, making an analytical correction
impractical. A standards-based correction for QSA is the best approach, and we
show the proper way to calculate standards-normalized $\delta$ values to
minimize the effect of QSA.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:56:47 GMT""}]","2021-02-24"
"2102.04254","Sebastian Gonzalez","Sebastian Gonzalez, Davide Salvi, Daniel Baeza, Fabio Antonacci,
  Augusto Sarti","A Data-Driven Approach to Violin Making",,,,,"cs.CE cs.AI cs.LG cs.SD eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Of all the characteristics of a violin, those that concern its shape are
probably the most important ones, as the violin maker has complete control over
them. Contemporary violin making, however, is still based more on tradition
than understanding, and a definitive scientific study of the specific relations
that exist between shape and vibrational properties is yet to come and sorely
missed. In this article, using standard statistical learning tools, we show
that the modal frequencies of violin tops can, in fact, be predicted from
geometric parameters, and that artificial intelligence can be successfully
applied to traditional violin making. We also study how modal frequencies vary
with the thicknesses of the plate (a process often referred to as {\em plate
tuning}) and discuss the complexity of this dependency. Finally, we propose a
predictive tool for plate tuning, which takes into account material and
geometric parameters.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 00:42:08 GMT""}]","2021-02-09"
"2102.04552","Mathew Alex","Mathew Alex","Quantum Technologies: A Review of the Patent Landscape","25 pages",,,,"cs.DL quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum Technologies is a term that is getting broader with every passing
year. Nanotechnology and electronics operate in this realm. With the invention
of industry-disrupting algorithms like Shor's algorithm that can break RSA
encryption on a quantum computer and Quantum Key Distribution, which offers
unconditional security in theory, investment is pouring in. Here we taxonomize
and analyze 48,577 patents in this area from 2015 to present captured with a
comprehensive query in Relecura's patent database. The author's subject
experience, along with the company's AI-based tools and scholarly literature,
were utilized to make this highly subjective choice of taxonomy. Though most
Patent Landscape Analysis Reports consider a single technology, geography, or
company, we have tried to give a holistic overview of these technologies as a
whole due to their collaborative and intertwined nature. The physics of each
technology and its role in the industry is briefly explained where possible.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 07:26:24 GMT""}]","2021-02-10"
"2102.04854","Ashoke De","Santanu De, Ashoke De, Abhishek Jaiswal, Arpita Dash","Stabilization of lifted hydrogen jet diffusion flame in a vitiated
  co-flow: effects of jet and coflow velocities, coflow temperature and mixing",,"International Journal of Hydrogen Energy, 2016","10.1016/j.ijhydene.2016.06.052",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present paper reports on the numerical investigation of lifted turbulent
jet flames with H2/N2 fuel issuing into a vitiated coflow of lean combustion
products of H2/air using conditional moment closure method (CMC). A 2D
axisymmetric formulation has been used for the predictions of fluid flow, while
CMC equations are solved with detailed chemistry to represent the
turbulence-chemistry interaction. Simulations are carried out for different
coflow temperatures, jet and coflow velocities in order to investigate the
impact on the flame lift-off height as well as on the flame stabilization.
Furthermore, the role of conditional velocity models on the flame has also been
investigated. In addition, the effect of mixing is investigated over a range of
coflow temperatures and the stabilization mechanism is determined from the
analysis of the transport budgets. It is found that the lift-off height is
highly sensitive to the coflow temperature, while the predicted lift-off height
using the mixing model constant, i.e., C{\Phi}=4, is found to be the closest to
the experimental results. For all the coflow temperatures, the balance is found
between the chemical, axial convection and molecular diffusion terms while the
contribution from axial and radial diffusion is negligible, thus indicating
auto-ignition as the flame stabilization mechanism.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:06:49 GMT""}]","2021-02-10"
"2102.04855","Ashoke De","Ashoke De and Sumanta Acharya","Dynamics of upstream flame propagation in a hydrogen-enriched premixed
  flame","arXiv admin note: text overlap with arXiv:2101.09200","International Journal of Hydrogen Energy, 2012","10.1016/j.ijhydene.2012.08.019",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An unconfined strongly swirled flow is investigated to study the effect of
hydrogen addition on upstream flame propagation in a methane-air premixed flame
using Large Eddy Simulation (LES) with a Thickened Flame (TF) model. A
laboratory-scale swirled premixed combustor operated under atmospheric
conditions for which experimental data for validation is available has been
chosen for the numerical study. In the LES-TF approach, the flame front is
resolved on the computational grid through artificial thickening and the
individual species transport equations are directly solved with the reaction
rates specified using Arrhenius chemistry. Good agreement is found when
comparing predictions with the published experimental data including the
predicted RMS fluctuations. Also, the results show that the initiation of
upstream flame propagation is associated with balanced maintained between
hydrodynamics and reaction. This process is associated with the upstream
propagation of the center recirculation bubble, which pushes the flame front in
the upstream mixing tube. Once the upstream movement of the flame front is
initiated, the hydrogen-enriched mixture exhibits more unstable behavior; while
in contrast, the CH4 flame shows stable behavior.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 04:57:16 GMT""}]","2021-02-10"
"2102.04896","Dalton Sakthivadivel","Dalton A R Sakthivadivel","Formalising the Use of the Activation Function in Neural Inference","14+2 pages, two figures. TikZ code included in submission","Complex Systems, 31(4), 2022","10.25088/ComplexSystems.31.4.433",,"q-bio.NC cond-mat.dis-nn cond-mat.stat-mech stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate how the activation function can be used to describe neural
firing in an abstract way, and in turn, why it works well in artificial neural
networks. We discuss how a spike in a biological neurone belongs to a
particular universality class of phase transitions in statistical physics. We
then show that the artificial neurone is, mathematically, a mean field model of
biological neural membrane dynamics, which arises from modelling spiking as a
phase transition. This allows us to treat selective neural firing in an
abstract way, and formalise the role of the activation function in perceptron
learning. The resultant statistical physical model allows us to recover the
expressions for some known activation functions as various special cases. Along
with deriving this model and specifying the analogous neural case, we analyse
the phase transition to understand the physics of neural network learning.
Together, it is shown that there is not only a biological meaning, but a
physical justification, for the emergence and performance of typical activation
functions; implications for neural learning and inference are also discussed.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:42:21 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 16:55:31 GMT""},{""version"":""v3"",""created"":""Sun, 25 Dec 2022 04:16:51 GMT""}]","2022-12-27"
"2102.05183","Ashoke De","Ashoke De and Sumanta Acharya","Parametric study of upstream flame propagation in hydrogen-enriched
  premixed combustion: effects of swirl, geometry and premixedness","arXiv admin note: substantial text overlap with arXiv:2102.04855;
  text overlap with arXiv:2101.09200","International Journal of Hydrogen Energy, 2012","10.1016/j.ijhydene.2012.07.008",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effect of swirl, premixedness and geometry has been investigated for
hydrogen enriched premixed flame using Large Eddy Simulation (LES) with a
Thickened Flame (TF) model. Swirl strength has been varied to study the effects
of swirl on flame behavior in a laboratory-scale premixed combustor operated
under atmospheric conditions. In addition, the levels of premixedness and
geometry have also been changed to study the role of these quantities on flame
behavior. The turbulent flow field and the chemistry are coupled through TF
model. In the LES-TF approach, the flame front is resolved on the computational
grid through artificial thickening and the individual species transport
equations are directly solved with the reaction rates specified using Arrhenius
chemistry. Good agreement is found when comparing predictions with the
published experimental data including the predicted RMS fluctuations. Also, the
results show that higher swirl strength and increase in level of premixedness
make the system more susceptible to upstream flame movement due to higher
combustibility of hydrogen, which increases the reaction along the flame front,
thereby raises temperature in the reaction zone and leads to combustion induced
vortex breakdown (CIVB). Moreover, upstream flame movement is always observed
at higher swirl strength irrespective of level of premixedness and burner
geometry, whereas the premixed systems exhibit stable behavior while operating
at low swirl.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:02:07 GMT""}]","2021-02-11"
"2102.06145","Marina Speranskaya","Marina Speranskaya, Martin Schmitt, Benjamin Roth","Ranking vs. Classifying: Measuring Knowledge Base Completion Quality","AKBC 2020 accepted paper",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge base completion (KBC) methods aim at inferring missing facts from
the information present in a knowledge base (KB) by estimating the likelihood
of candidate facts. In the prevailing evaluation paradigm, models do not
actually decide whether a new fact should be accepted or not but are solely
judged on the position of true facts in a likelihood ranking with other
candidates. We argue that consideration of binary predictions is essential to
reflect the actual KBC quality, and propose a novel evaluation paradigm,
designed to provide more transparent model selection criteria for a realistic
scenario. We construct the data set FB14k-QAQ where instead of single facts, we
use KB queries, i.e., facts where one entity is replaced with a variable, and
construct corresponding sets of entities that are correct answers. We randomly
remove some of these correct answers from the data set, simulating the
realistic scenario of real-world entities missing from a KB. This way, we can
explicitly measure a model's ability to handle queries that have more correct
answers in the real world than in the KB, including the special case of queries
without any valid answer. The latter especially contrasts the ranking setting.
We evaluate a number of state-of-the-art KB embeddings models on our new
benchmark. The differences in relative performance between ranking-based and
classification-based evaluation that we observe in our experiments confirm our
hypothesis that good performance on the ranking task does not necessarily
translate to good performance on the actual completion task. Our results
motivate future work on KB embedding models with better prediction separability
and, as a first step in that direction, we propose a simple variant of TransE
that encourages thresholding and achieves a significant improvement in
classification F1 score relative to the original TransE.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 17:53:48 GMT""}]","2021-02-12"
"2102.07641","Weiming Li","Ruo Li, Weiming Li, Lingchao Zheng","Direct Flux Gradient Approximation to Close Moment Model for Kinetic
  Equations","23 pages, 0 figures",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To close the moment model deduced from kinetic equations, the canonical
approach is to provide an approximation to the flux function not able to be
depicted by the moments in the reduced model. In this paper, we propose a brand
new closure approach with remarkable advantages than the canonical approach.
Instead of approximating the flux function, the new approach close the moment
model by approximating the flux gradient. Precisely, we approximate the space
derivative of the distribution function by an ansatz which is a weighted
polynomial, and the derivative of the closing flux is computed by taking the
moments of the ansatz. Consequently, the method provides us an improved
framework to derive globally hyperbolic moment models, which preserve all those
conservative variables in the low order moments. It is shown that the
linearized system at the weight function, which is often the local equilibrium,
of the moment model deduced by our new approach is automatically coincided with
the system deduced from the classical perturbation theory, which can not be
satisfied by previous hyperbolic regularization framework. Taking the Boltzmann
equation as example, the linearlization of the moment model gives the correct
Navier-Stokes-Fourier law same as that the Chapman-Enskog expansion gives. Most
existing globally hyperbolic moment models are re-produced by our new approach,
and several new models are proposed based on this framework.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 13:08:31 GMT""}]","2021-02-16"
"2102.09047","Zachary Grey","Zachary J. Grey and Susanna Mosleh and Jacob D. Rezac and Yao Ma and
  Jason B. Coder and Andrew M. Dienstfrey","Optimizing Unlicensed Band Spectrum Sharing With Subspace-Based Pareto
  Tracing","7 pages, 2 figures, 1 table, to appear in IEEE ICC 2021 proceedings",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To meet the ever-growing demands of data throughput for forthcoming and
deployed wireless networks, new wireless technologies like Long-Term Evolution
License-Assisted Access (LTE-LAA) operate in shared and unlicensed bands.
However, the LAA network must co-exist with incumbent IEEE 802.11 Wi-Fi
systems. We consider a coexistence scenario where multiple LAA and Wi-Fi links
share an unlicensed band. We aim to improve this coexistence by maximizing the
key performance indicators (KPIs) of these networks simultaneously via
dimension reduction and multi-criteria optimization. These KPIs are network
throughputs as a function of medium access control protocols and physical layer
parameters. We perform an exploratory analysis of coexistence behavior by
approximating active subspaces to identify low-dimensional structure in the
optimization criteria, i.e., few linear combinations of parameters for
simultaneously maximizing KPIs. We leverage an aggregate low-dimensional
subspace parametrized by approximated active subspaces of throughputs to
facilitate multi-criteria optimization. The low-dimensional subspace
approximations inform visualizations revealing convex KPIs over mixed active
coordinates leading to an analytic Pareto trace of near-optimal solutions.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:25:12 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 00:37:31 GMT""}]","2021-02-25"
"2102.10997","Subhash Sagar Mr.","Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, and Wei Emma Zhang","Trust Computational Heuristic for Social Internet of Things: A Machine
  Learning-based Approach","6 pages",,,,"cs.CR cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Internet of Things (IoT) is an evolving network of billions of
interconnected physical objects, such as numerous sensors, smartphones,
wearables, and embedded devices. These physical objects, generally referred to
as the smart objects, when deployed in the real-world aggregates useful
information from their surrounding environment. As-of-late, this notion of IoT
has been extended to incorporate the social networking facets which have led to
the promising paradigm of the `Social Internet of Things' (SIoT). In SIoT, the
devices operate as an autonomous agent and provide an exchange of information
and service discovery in an intelligent manner by establishing social
relationships among them with respect to their owners. Trust plays an important
role in establishing trustworthy relationships among the physical objects and
reduces probable risks in the decision-making process. In this paper, a trust
computational model is proposed to extract individual trust features in a SIoT
environment. Furthermore, a machine learning-based heuristic is used to
aggregate all the trust features in order to ascertain an aggregate trust
score. Simulation results illustrate that the proposed trust-based model
isolates the trustworthy and untrustworthy nodes within the network in an
efficient manner.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:52:02 GMT""}]","2021-02-23"
"2102.10998","Subhash Sagar Mr.","Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, Munazza Zaib and Wei Emma
  Zhang","Towards a Machine Learning-driven Trust Evaluation Model for Social
  Internet of Things: A Time-aware Approach",,,,,"cs.CR cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The emerging paradigm of the Social Internet of Things (SIoT) has transformed
the traditional notion of the Internet of Things (IoT) into a social network of
billions of interconnected smart objects by integrating social networking
facets into the same. In SIoT, objects can establish social relationships in an
autonomous manner and interact with the other objects in the network based on
their social behaviour. A fundamental problem that needs attention is
establishing of these relationships in a reliable and trusted way, i.e.,
establishing trustworthy relationships and building trust amongst objects. In
addition, it is also indispensable to ascertain and predict an object's
behaviour in the SIoT network over a period of time. Accordingly, in this
paper, we have proposed an efficient time-aware machine learning-driven trust
evaluation model to address this particular issue. The envisaged model
deliberates social relationships in terms of friendship and community-interest,
and further takes into consideration the working relationships and
cooperativeness (object-object interactions) as trust parameters to quantify
the trustworthiness of an object. Subsequently, in contrast to the traditional
weighted sum heuristics, a machine learning-driven aggregation scheme is
delineated to synthesize these trust parameters to ascertain a single trust
score. The experimental results demonstrate that the proposed model can
efficiently segregates the trustworthy and untrustworthy objects within a
network, and further provides the insight on how the trust of an object varies
with time along with depicting the effect of each trust parameter on a trust
score.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 09:25:44 GMT""}]","2021-02-23"
"2102.11167","Adem Kilicman","Saadoune Brahimi, Ahcene Merad and Adem Kilicman","On Theoretical and Numerical Aspect of Fractional Differential Equations
  with Purely Integral Conditions","24 pages",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are interested in the study of a problem with fractional
derivatives having boundary conditions of integral types. The problem
represents a Caputo type advection-diffusion equation where the fractional
order derivative with respect to time with $1<\alpha <2$. The method of the
energy inequalities is used to prove the existence and the uniqueness of
solutions of the problem. The finite difference method is also introduced to
study the problem numerically in order to find an approximate solution of the
considered problem. Some numerical examples are presented to show satisfactory
results.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 05:46:34 GMT""}]","2021-02-23"
"2102.12359","Jake McCoy","Jake A. McCoy, Randall L. McEntaffer, Chad M. Eichfeld","Fabrication of astronomical x-ray reflection gratings using thermally
  activated selective topography equilibration","21 pages, 8 figures, from a special edition of JVST B for the 62nd
  International Conference on Electron, Ion, and Photon Beam Technology and
  Nanofabrication (EIPBN)","Journal of Vacuum Science and Technology B: Nanotechnology and
  Microelectronics, volume 36 (2018), p. 06JA01","10.1116/1.5048197",,"astro-ph.IM cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermally activated selective topography equilibration (TASTE) enables the
creation of 3D structures in resist using grayscale electron-beam lithography
followed by a thermal treatment to induce a selective polymer reflow. A blazed
grating topography can be created by reflowing repeating staircase patterns in
resist into wedge-like structures. Motivated by astronomical applications, such
patterns with periodicities 840 nm and 400 nm have been fabricated in 130
nm-thick PMMA using TASTE to provide a base for X-ray reflection gratings. A
path forward to integrate this alternative blazing technique into grating
fabrication recipes is discussed.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 19:30:48 GMT""}]","2021-02-25"
"2103.03683","Davide Ramaccia Dr.","Davide Ramaccia, Dimitrios L. Sounas, Angelica V. Marini, Alessandro
  Toscano, and Filiberto Bilotti","Electromagnetic Isolation Induced by Time-Varying Metasurfaces:
  Non-Reciprocal Bragg Grating",,"IEEE Antennas and Wireless Propagation Letters, vol. 19, no. 11,
  pp. 1886-1890, Nov. 2020","10.1109/LAWP.2020.2996275",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter, we propose a magnet-less non-reciprocal isolating system
based on time-varying metasurfaces. Two parallel time-varying metasurfaces, one
for frequency up-conversion and one for down-conversion by the same amount, are
used for realizing a region of space where incident waves from opposite
directions experience an opposite Doppler frequency shift. As a result, any
device within this region becomes sensitive to the illumination direction,
exhibiting a different scattering response from opposite directions and thus
breaking reciprocity. Very importantly, thanks to the opposite frequency shift
of the metasurfaces, the frequency of the transmitted electromagnetic field is
the same as for the incident one. Here, we demonstrate this general approach by
using a Bragg grating as the device between the time-varying metasurfaces. The
combined structure of the metasurfaces and the grating exhibits different
transmission and reflection properties for opposite illumination direction,
thereby realizing an isolator. More broadly, this letter presents a strategy
for converting any conventional electromagnetic device to a non-reciprocal one
by placing it between two time-varying metasurfaces. This approach opens the
door to several new non-reciprocal components based on thin and lightweight
metasurfaces, which are simpler to realize compared to their volumetric
counterparts.
","[{""version"":""v1"",""created"":""Wed, 3 Feb 2021 10:26:58 GMT""}]","2021-03-08"
"2103.03817","Abolfazl Zakeri","Amirhossein Shaghaghi, Abolfazl Zakeri, Nader Mokari, Mohammad Reza
  Javan, Mohammad Behdadfar and Eduard A Jorswieck","Proactive and AoI-aware Failure Recovery for Stateful NFV-enabled
  Zero-Touch 6G Networks: Model-Free DRL Approach","Accepted by IEEE TNSM for publication Code is available in
  https://github.com/wildsky95/ZT-PFR",,"10.1109/TNSM.2021.3113054",,"eess.SP cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a Zero-Touch, deep reinforcement learning
(DRL)-based Proactive Failure Recovery framework called ZT-PFR for stateful
network function virtualization (NFV)-enabled networks. To this end, we
formulate a resource-efficient optimization problem minimizing the network cost
function including resource cost and wrong decision penalty. As a solution, we
propose state-of-the-art DRL-based methods such as soft-actor-critic (SAC) and
proximal-policy-optimization (PPO). In addition, to train and test our DRL
agents, we propose a novel impending-failure model. Moreover, to keep network
status information at an acceptable freshness level for appropriate
decision-making, we apply the concept of age of information to strike a balance
between the event and scheduling based monitoring. Several key systems and DRL
algorithm design insights for ZT-PFR are drawn from our analysis and simulation
results. For example, we use a hybrid neural network, consisting long
short-term memory layers in the DRL agents structure, to capture
impending-failures time dependency.
","[{""version"":""v1"",""created"":""Tue, 2 Feb 2021 21:40:35 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 10:15:49 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 20:47:47 GMT""},{""version"":""v4"",""created"":""Sat, 11 Sep 2021 16:14:30 GMT""}]","2021-11-10"

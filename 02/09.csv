"2102.04295","Alfred Galichon","Raicho Bojilov and Alfred Galichon","Matching in Closed-Form: Equilibrium, Identification, and Comparative
  Statics","30 pages","Economic Theory 61 (2016) pp.587-609","10.1007/s00199-016-0961-8",,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper provides closed-form formulas for a multidimensional two-sided
matching problem with transferable utility and heterogeneity in tastes. When
the matching surplus is quadratic, the marginal distributions of the
characteristics are normal, and when the heterogeneity in tastes is of the
continuous logit type, as in Choo and Siow (J Polit Econ 114:172-201, 2006), we
show that the optimal matching distribution is also jointly normal and can be
computed in closed form from the model primitives. Conversely, the quadratic
surplus function can be identified from the optimal matching distribution, also
in closed-form. The closed-form formulas make it computationally easy to solve
problems with even a very large number of matches and allow for quantitative
predictions about the evolution of the solution as the technology and the
characteristics of the matching populations change.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:02:13 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 15:30:57 GMT""}]","2021-02-17"
"2102.04296","Jacob Bradley","Jacob R. Bradley and Timothy I. Cannings","Data-driven design of targeted gene panels for estimating immunotherapy
  biomarkers","21 pages, 10 figures",,,,"q-bio.GN stat.AP","http://creativecommons.org/licenses/by/4.0/","  We introduce a novel data-driven framework for the design of targeted gene
panels for estimating exome-wide biomarkers in cancer immunotherapy. Our first
goal is to develop a generative model for the profile of mutation across the
exome, which allows for gene- and variant type-dependent mutation rates. Based
on this model, we then propose a new procedure for estimating biomarkers such
as tumour mutation burden and tumour indel nurden. Our approach allows the
practitioner to select a targeted gene panel of a prespecified size, and then
construct an estimator that only depends on the selected genes. Alternatively,
the practitioner may apply our method to make predictions based on an existing
gene panel, or to augment a gene panel to a given size. We demonstrate the
excellent performance of our proposal using data from three non-small cell lung
cancer studies, as well as data from six other cancer types.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:03:05 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 13:48:47 GMT""},{""version"":""v3"",""created"":""Thu, 3 Feb 2022 18:50:48 GMT""}]","2022-02-04"
"2102.04297","Xingyu Wang","Xingyu Wang, Sewoong Oh, Chang-Han Rhee","Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise","Proceedings of 2022 International Conference on Learning
  Representations. 157 pages (12 pages for the main paper and 145 pages for the
  supplementary materials)",,,,"cs.LG math.OC math.PR stat.ML","http://creativecommons.org/licenses/by/4.0/","  The empirical success of deep learning is often attributed to SGD's
mysterious ability to avoid sharp local minima in the loss landscape, as sharp
minima are known to lead to poor generalization. Recently, empirical evidence
of heavy-tailed gradient noise was reported in many deep learning tasks, and it
was shown in \c{S}im\c{s}ekli (2019a,b) that SGD can escape sharp local minima
under the presence of such heavy-tailed gradient noise, providing a partial
solution to the mystery. In this work, we analyze a popular variant of SGD
where gradients are truncated above a fixed threshold. We show that it achieves
a stronger notion of avoiding sharp minima: it can effectively eliminate sharp
local minima entirely from its training trajectory. We characterize the
dynamics of truncated SGD driven by heavy-tailed noises. First, we show that
the truncation threshold and width of the attraction field dictate the order of
the first exit time from the associated local minimum. Moreover, when the
objective function satisfies appropriate structural conditions, we prove that
as the learning rate decreases, the dynamics of heavy-tailed truncated SGD
closely resemble those of a continuous-time Markov chain that never visits any
sharp minima. Real data experiments on deep learning confirm our theoretical
prediction that heavy-tailed SGD with gradient clipping finds a ""flatter"" local
minima and achieves better generalization.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:03:49 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 21:19:13 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 06:05:05 GMT""},{""version"":""v4"",""created"":""Tue, 10 May 2022 22:59:52 GMT""}]","2022-05-12"
"2102.04298","Luis Enrique Correa Rocha Prof","Luis E C Rocha and Jan Ryckebusch and Koen Schoors and Matthew Smith","The scaling of social interactions across animal species","To appear in Scientific Reports",,,,"physics.soc-ph cond-mat.stat-mech nlin.AO physics.pop-ph stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social animals self-organise to create groups to increase protection against
predators and productivity. One-to-one interactions are the building blocks of
these emergent social structures and may correspond to friendship, grooming,
communication, among other social relations. These structures should be robust
to failures and provide efficient communication to compensate the costs of
forming and maintaining the social contacts but the specific purpose of each
social interaction regulates the evolution of the respective social networks.
We collate 611 animal social networks and show that the number of social
contacts $E$ scales with group size $N$ as a super-linear power-law
$E=CN^{\beta}$ for various species of animals, including humans, other mammals
and non-mammals. We identify that the power-law exponent $\beta$ varies
according to the social function of the interactions as $\beta = 1+a/4$, with
$a \approx {1,2,3,4}$. By fitting a multi-layer model to our data, we observe
that the cost to cross social groups also varies according to social function.
Relatively low costs are observed for physical contact, grooming and group
membership which lead to small groups with high and constant social clustering.
Offline friendship has similar patterns while online friendship shows weak
social structures. The intermediate case of spatial proximity ($\beta=1.5$ and
clustering dependency on network size quantitatively similar to friendship)
suggests that proximity interactions may be as relevant for the spread of
infectious diseases as for social processes like friendship.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:03:58 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 14:10:26 GMT""}]","2021-06-02"
"2102.04299","Tapobrata Sarkar","Rajibul Shaikh, Kunal Pal, Kuntal Pal, Tapobrata Sarkar","Constraining alternatives to the Kerr black hole","16 Pages, LaTeX",,"10.1093/mnras/stab1779",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent observation of the shadow of the supermassive compact object
M87$^*$ by the Event Horizon Telescope (EHT) collaboration has opened up a new
window to probe the strong gravity regime. In this paper, we study shadows cast
by two viable alternatives to the Kerr black hole, and compare them with the
shadow of M87$^{*}$. The first alternative is a horizonless compact object
(HCO) having radius $r_0$ and exterior Kerr geometry. The second one is a
rotating generalisation of the recently obtained one parameter ($r_0$) static
metric by Simpson and Visser. This latter metric, constructed by using the
Newman-Janis algorithm, is a special case of a parametrised rotating non-Kerr
geometry obtained by Johannsen. Here, we constrain the parameter $r_0$ of these
alternatives using the results from M87$^{*}$ observation. We find that, for
the mass, inclination angle and the angular diameter of the shadow of M87$^{*}$
reported by the EHT collaboration, the maximum value of the parameter $r_0$
must be in the range $2.54r_{+}\leq r_{0,max}\leq 3.51r_{+}$ for the
dimensionless spin range $0.5\leq a_{*}\leq 0.94$, with $r_{+}$ being the outer
horizon radius of the Kerr black hole at the corresponding spin value. We
conclude that these black hole alternatives having $r_0$ below this maximum
range (i.e. $r_0\leq r_{0,max}$) is consistent with the size and deviation from
circularity of the observed shadow of M87$^{*}$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:04:18 GMT""}]","2021-07-07"
"2102.04302","Bruno Iannazzo","Dario A. Bini, Bruno Iannazzo, Jie Meng","Geometric means of quasi-Toeplitz matrices","33 pages, 4 figures",,,,"math.NA cs.NA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study means of geometric type of quasi-Toeplitz matrices, that are
semi-infinite matrices $A=(a_{i,j})_{i,j=1,2,\ldots}$ of the form $A=T(a)+E$,
where $E$ represents a compact operator, and $T(a)$ is a semi-infinite Toeplitz
matrix associated with the function $a$, with Fourier series
$\sum_{\ell=-\infty}^{\infty} a_\ell e^{\mathfrak i \ell t}$, in the sense that
$(T(a))_{i,j}=a_{j-i}$. If $a$ is \rv\ and essentially bounded, then these
matrices represent bounded self-adjoint operators on $\ell^2$. We consider the
case where $a$ is a continuous function, where quasi-Toeplitz matrices coincide
with a classical Toeplitz algebra, and the case where $a$ is in the Wiener
algebra, that is, has absolutely convergent Fourier series.
  We prove that if $a_1,\ldots,a_p$ are continuous and positive functions, or
are in the Wiener algebra with some further conditions, then means of geometric
type, such as the ALM, the NBMP and the Karcher mean of quasi-Toeplitz positive
definite matrices associated with $a_1,\ldots,a_p$, are quasi-Toeplitz matrices
associated with the geometric mean $(a_1\cdots a_p)^{1/p}$, which differ only
by the compact correction. We show by numerical tests that these operator means
can be practically approximated.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:07:10 GMT""}]","2021-02-09"
"2102.04303","Karla Pe\~na Ram\'irez","K. Pe\~na Ram\'irez, C. Gonz\'alez-Fern\'andez, A.-N. Chen\'e, S.
  Ram\'irez Alegr\'ia","The VVV Open Cluster Project. Near-infrared sequences of NGC6067,
  NGC6259, NGC4815, Pismis18, Trumpler23, and Trumpler20","13 pages, 7 figures, MNRAS accepted. v2: keywords and references
  updated at proof stage",,"10.1093/mnras/stab328",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open clusters are central elements of our understanding of the Galactic disk
evolution, as an accurate determination of their parameters leads to an
unbiased picture of our Galaxy's structure. Extending the analysis towards
fainter magnitudes in cluster sequences has a significant impact on the derived
fundamental parameters, such as extinction and total mass. We perform a
homogeneous analysis of six open stellar clusters in the Galactic disk using
kinematic and photometric information from the Gaia DR2 and VVV surveys:
NGC6067, NGC6259, NGC4815, Pismis18, Trumpler23, and Trumpler20. We implement
two coarse-to-fine characterization methods: first, we employ Gaussian mixture
models to tag fields around each open cluster in the proper motion space, and
then we apply an unsupervised machine learning method to make the membership
assignment to each cluster. For the studied clusters, with ages in the
$\sim$120-1900 Myr range, we report an increase of $\sim$45 % new member
candidates on average in our sample. The data-driven selection approach of
cluster members makes our catalog a valuable resource for testing stellar
evolutionary models and for assessing the cluster low-to-intermediate mass
populations. This study is the first of a series intended to homogeneously
reveal open cluster near-infrared sequences.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:07:29 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 13:52:41 GMT""}]","2021-02-22"
"2102.04305","Gert Heckman","Annegret Burtscher and Gert Heckman","Variations of Weyl's tube formula","Added reference and Section 8","The Journal of Geometric Analysis, Volume 31 (2021), Issue 12,
  11952-11970","10.1007/s12220-021-00707-z",,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In 1939 Weyl showed that the volume of spherical tubes around compact
submanifolds M of Euclidean space depends solely on the induced Riemannian
metric on M. Can this intrinsic nature of the tube volume be preserved for
tubes with more general cross sections D than the round ball? Under
sufficiently strong symmetry conditions on D the answer turns out to be yes.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:10:44 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 13:37:06 GMT""}]","2021-10-13"
"2102.04306","Jieneng Chen","Jieneng Chen, Yongyi Lu, Qihang Yu, Xiangde Luo, Ehsan Adeli, Yan
  Wang, Le Lu, Alan L. Yuille, Yuyin Zhou","TransUNet: Transformers Make Strong Encoders for Medical Image
  Segmentation","13 pages, 3 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Medical image segmentation is an essential prerequisite for developing
healthcare systems, especially for disease diagnosis and treatment planning. On
various medical image segmentation tasks, the u-shaped architecture, also known
as U-Net, has become the de-facto standard and achieved tremendous success.
However, due to the intrinsic locality of convolution operations, U-Net
generally demonstrates limitations in explicitly modeling long-range
dependency. Transformers, designed for sequence-to-sequence prediction, have
emerged as alternative architectures with innate global self-attention
mechanisms, but can result in limited localization abilities due to
insufficient low-level details. In this paper, we propose TransUNet, which
merits both Transformers and U-Net, as a strong alternative for medical image
segmentation. On one hand, the Transformer encodes tokenized image patches from
a convolution neural network (CNN) feature map as the input sequence for
extracting global contexts. On the other hand, the decoder upsamples the
encoded features which are then combined with the high-resolution CNN feature
maps to enable precise localization.
  We argue that Transformers can serve as strong encoders for medical image
segmentation tasks, with the combination of U-Net to enhance finer details by
recovering localized spatial information. TransUNet achieves superior
performances to various competing methods on different medical applications
including multi-organ segmentation and cardiac segmentation. Code and models
are available at https://github.com/Beckschen/TransUNet.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:10:50 GMT""}]","2021-02-09"
"2102.04307","Alper Kamil Bozkurt","Alper Kamil Bozkurt, Yu Wang, Michael M. Zavlanos, Miroslav Pajic","Learning Optimal Strategies for Temporal Tasks in Stochastic Games",,,,,"cs.AI cs.LG cs.LO cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synthesis from linear temporal logic (LTL) specifications provides assured
controllers for autonomous systems operating in stochastic and potentially
adversarial environments. Automatic synthesis tools, however, require a model
of the environment to construct controllers. In this work, we introduce a
model-free reinforcement learning (RL) approach that derives controllers from
given LTL specifications even when the environment is completely unknown. We
model the problem of satisfying the LTL specifications as a stochastic game
(SG) between the controller and the adversarial environment; we then learn
optimal controller strategies that maximize the probability of satisfying the
LTL specifications against the worst-case environment behavior. We first
construct a product game using the deterministic parity automaton (DPA)
translated from the given LTL specification. By deriving distinct rewards and
discount factors from the acceptance condition of the DPA, we reduce the
maximization of the worst-case probability of satisfying the LTL specification
into the maximization of a discounted reward objective in the product game;
this allows for the use of model-free RL algorithms to learn an optimal
controller strategy. To deal with the common scalability problems when the
number of colors defining the acceptance condition of the DPA is large, we
propose a lazy color generation method where distinct rewards and discount
factors are utilized only when needed, and an approximate method where the
controller eventually focuses on only one color. In several case studies, we
show that our approach is scalable to a wide range of LTL formulas,
significantly outperforming existing methods for learning controllers from LTL
specifications in SGs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:10:50 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 12:22:35 GMT""}]","2022-03-25"
"2102.04308","Ming Zhang","Ming Zhang, Chao-Ming Zhang, De-Cheng Zou, Rui-Hong Yue","$P-V$ criticality and Joule-Thomson Expansion of Hayward-AdS black holes
  in 4D Einstein-Gauss-Bonnet gravity","arXiv admin note: text overlap with arXiv:2009.03096",,"10.1016/j.nuclphysb.2021.115608",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the $P-V$ criticality and Joule-Thomson Expansion of
Hayward-AdS black holes in 4D Einstein-Gauss-Bonnet gravity are studied in the
extended phase space. We find the black hole always exhibits a phase transition
similar to that of the Van der Waals system for any arbitrary positive
parameters $\alpha$ and $g$. We also study the dependence of $\alpha$ and $g$
on the inversion curves and plot the inversion and isenthalpic curves in the
$T-P$ plane, which can determine the cooling-heating regions.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:10:57 GMT""}]","2021-12-08"
"2102.04309","Stefan Streif","Patrick Schmidt, Pavel Osinenko, Stefan Streif","On inf-convolution-based robust practical stabilization under
  computational uncertainty","Accepted for publication in IEEE TRANSACTIONS ON AUTOMATIC CONTROL; 8
  pages, 3 figures",,"10.1109/TAC.2021.3052747",,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This work is concerned with practical stabilization of nonlinear systems by
means of inf-convolution-based sample-and-hold control. It is a fairly general
stabilization technique based on a generic non-smooth control Lyapunov function
(CLF) and robust to actuator uncertainty, measurement noise, etc. The
stabilization technique itself involves computation of descent directions of
the CLF. It turns out that non-exact realization of this computation leads not
just to a quantitative, but also qualitative obstruction in the sense that the
result of the computation might fail to be a descent direction altogether and
there is also no straightforward way to relate it to a descent direction.
Disturbance, primarily measurement noise, complicate the described issue even
more. This work suggests a modified inf-convolution-based control that is
robust w. r. t. system and measurement noise, as well as computational
uncertainty. The assumptions on the CLF are mild, as, e. g., any piece-wise
smooth function, which often results from a numerical LF/CLF construction,
satisfies them. A computational study with a three-wheel robot with dynamical
steering and throttle under various tolerances w. r. t. computational
uncertainty demonstrates the relevance of the addressed issue and the necessity
of modifying the used stabilization technique. Similar analyses may be extended
to other methods which involve optimization, such as Dini aiming or steepest
descent.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:12:11 GMT""}]","2021-02-09"
"2102.04310","Magnus Sahlgren","Magnus Sahlgren, Fredrik Carlsson","The Singleton Fallacy: Why Current Critiques of Language Models Miss the
  Point",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper discusses the current critique against neural network-based
Natural Language Understanding (NLU) solutions known as language models. We
argue that much of the current debate rests on an argumentation error that we
will refer to as the singleton fallacy: the assumption that language, meaning,
and understanding are single and uniform phenomena that are unobtainable by
(current) language models. By contrast, we will argue that there are many
different types of language use, meaning and understanding, and that (current)
language models are build with the explicit purpose of acquiring and
representing one type of structural understanding of language. We will argue
that such structural understanding may cover several different modalities, and
as such can handle several different types of meaning. Our position is that we
currently see no theoretical reason why such structural knowledge would be
insufficient to count as ""real"" understanding.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:12:36 GMT""}]","2021-02-09"
"2102.04311","Markus Muhr","Markus Muhr, Vanja Nikoli\'c and Barbara Wohlmuth","A discontinuous Galerkin coupling for nonlinear elasto-acoustics","41 pages, 10 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by medical applications of high-intensity ultrasound, we study a
coupled elasto-acoustic problem with general acoustic nonlinearities of
quadratic type as they arise, for example, in the Westervelt and Kuznetsov
equations of nonlinear acoustics. We derive convergence rates in the energy
norm of a finite element approximation to the coupled problem in a setting that
involves different acoustic materials and hence jumps within material
parameters. A subdomain-based discontinuous Galerkin approach realizes the
acoustic-acoustic coupling of different materials. At the same time,
elasto-acoustic interface conditions are used for a mutual exchange of forces
between the different models. Numerical simulations back up the theoretical
findings in a three-dimensional setting with academic test cases as well as in
an application-oriented simulation, where the modeling of human tissue as an
elastic versus an acoustic medium is compared.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:13:52 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 10:29:23 GMT""}]","2021-08-09"
"2102.04312","Henrik Daniel Mettler","Henrik D. Mettler, Maximilian Schmidt, Walter Senn, Mihai A.
  Petrovici, Jakob Jordan","Evolving Neuronal Plasticity Rules using Cartesian Genetic Programming","2 pages, 1 figure",,,,"cs.NE q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  We formulate the search for phenomenological models of synaptic plasticity as
an optimization problem. We employ Cartesian genetic programming to evolve
biologically plausible human-interpretable plasticity rules that allow a given
network to successfully solve tasks from specific task families. While our
evolving-to-learn approach can be applied to various learning paradigms, here
we illustrate its power by evolving plasticity rules that allow a network to
efficiently determine the first principal component of its input distribution.
We demonstrate that the evolved rules perform competitively with known
hand-designed solutions. We explore how the statistical properties of the
datasets used during the evolutionary search influences the form of the
plasticity rules and discover new rules which are adapted to the structure of
the corresponding datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:17:15 GMT""}]","2021-02-09"
"2102.04313","Zoe Holmes","Joe Gibbs, Kaitlin Gili, Zo\""e Holmes, Benjamin Commeau, Andrew
  Arrasmith, Lukasz Cincio, Patrick J. Coles and Andrew Sornborger","Long-time simulations with high fidelity on quantum hardware","Main text: 14 pages, 11 Figures. Appendices: 10 pages, 1 Figure",,,"LA-UR-21-21053","quant-ph cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Moderate-size quantum computers are now publicly accessible over the cloud,
opening the exciting possibility of performing dynamical simulations of quantum
systems. However, while rapidly improving, these devices have short coherence
times, limiting the depth of algorithms that may be successfully implemented.
Here we demonstrate that, despite these limitations, it is possible to
implement long-time, high fidelity simulations on current hardware.
Specifically, we simulate an XY-model spin chain on the Rigetti and IBM quantum
computers, maintaining a fidelity of at least 0.9 for over 600 time steps. This
is a factor of 150 longer than is possible using the iterated Trotter method.
Our simulations are performed using a new algorithm that we call the fixed
state Variational Fast Forwarding (fsVFF) algorithm. This algorithm decreases
the circuit depth and width required for a quantum simulation by finding an
approximate diagonalization of a short time evolution unitary. Crucially, fsVFF
only requires finding a diagonalization on the subspace spanned by the initial
state, rather than on the total Hilbert space as with previous methods,
substantially reducing the required resources. We further demonstrate the
viability of fsVFF through large numerical implementations of the algorithm, as
well as an analysis of its noise resilience and the scaling of simulation
errors.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:18:50 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 11:49:55 GMT""}]","2021-07-15"
"2102.04314","Thomas Kirchartz","Zhifa Liu, Johanna Siekmann, Benjamin Klingebiel, Uwe Rau, and Thomas
  Kirchartz","Interface Optimization via Fullerene Blends Enables Open-Circuit
  Voltages of 1.35 V in CH3NH3Pb(I0.8Br0.2)3 Solar Cells",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Non-radiative recombination processes are the biggest hindrance to
approaching the radiative limit of the open-circuit voltage for wide-band gap
perovskite solar cells. In addition, to high bulk quality, good interfaces and
good energy level alignment for majority carriers at charge transport
layer-absorber interfaces are crucial to minimize non-radiative recombination
pathways. By tuning the lowest-unoccupied molecular-orbital of electron
transport layers via the use of different fullerenes and fullerene blends, we
demonstrate open-circuit voltages exceeding 1.35 V in CH3NH3Pb(I0.8Br0.2)3
device. Further optimization of mobility in binary fullerenes electron
transport layer can boost the power conversion efficiency as high as 18.6%. We
note in particular that the Voc-fill factor product is > 1.085 V, which is the
highest value reported for halide perovskites with this band gap.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:20:03 GMT""}]","2021-02-09"
"2102.04315","Paul-Hermann Balduf","Paul-Hermann Balduf","Propagator-cancelling scalar fields","46 pages, 21 figures",,,,"math-ph hep-th math.MP","http://creativecommons.org/licenses/by/4.0/","  We examine a large class of scalar quantum field theories where vertices are
able to cancel adjacent propagators. These theories are obtained as
diffeomorphisms of the field variable of a free field. Their connected
correlations functions can be computed efficiently with an algebraic procedure
dubbed connected perspective in earlier work. Specifically,
  (1) We compare the Feynman rules in momentum-space to their position-space
counterparts, they agree. This is a a-posteriori justification for the Feynman
rules of the connected perspective.
  (2) We extend the connected perspective to also incorporate counterterm
vertices.
  (3) We examine a specific choice of diffeomorphism that assumes the vertices
at different valence proportional to each other. We find that these relations
lead to various simplifications.
  (4) We perturbatively compute the connected 2-point function to all orders
for an arbitrary diffeomorphism of a massless field. We thereby give a
systematic perturbative derivation of the exponential superpropagator known
from the literature.
  (5) We compute a number of one- and two-loop counterterms. We find that for
the specific diffeomorphism, the one-loop counterterms arise from the bare
vertices by a non-linear redefinition of the momentum.
  (6) We show that every diffeomorphism fulfils a set of infinitely many
Slavnov-Taylor-like identities which express diffeomorphism-invariance of the
S-matrix at loop-level.
  Finally, we comment on surprising similarities between the structure of
propagator-cancelling scalar theories and gauge theories .
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:20:50 GMT""}]","2021-02-09"
"2102.04316","Yongseok Kwon","Yongseok Kwon, Javier Jimenez","An isolated logarithmic layer","Accepted in the journal of fluid mechanics","J. Fluid Mech. 916 (2021) A35","10.1017/jfm.2021.177",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To isolate the multiscale dynamics of the logarithmic layer of wall-bounded
turbulent flows, a novel numerical experiment is conducted in which the mean
tangential Reynolds stress is eliminated except in a subregion corresponding to
the typical location of the logarithmic layer in channels. Various statistical
comparisons against channel flow databases show that, despite some differences,
this modified flow system reproduces the kinematics and dynamics of natural
logarithmic layers well, even in the absence of a buffer and an outer zone.
This supports the previous idea that the logarithmic layer has its own
autonomous dynamics. In particular, the results suggest that the mean velocity
gradient and the wall-parallel scale of the largest eddies are determined by
the height of the tallest momentum-transferring motions, implying that the very
large-scale motions of wall-bounded flows are not an intrinsic part of
logarithmic-layer dynamics. Using a similar set-up, an isolated layer with a
constant total stress, representing the logarithmic layer without a driving
force, is simulated and examined.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:21:11 GMT""}]","2021-07-01"
"2102.04317","Shuquan Ye","Shuquan Ye, Dongdong Chen, Songfang Han, Ziyu Wan, Jing Liao","Meta-PU: An Arbitrary-Scale Upsampling Network for Point Cloud","To appear at TVCG",,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point cloud upsampling is vital for the quality of the mesh in
three-dimensional reconstruction. Recent research on point cloud upsampling has
achieved great success due to the development of deep learning. However, the
existing methods regard point cloud upsampling of different scale factors as
independent tasks. Thus, the methods need to train a specific model for each
scale factor, which is both inefficient and impractical for storage and
computation in real applications. To address this limitation, in this work, we
propose a novel method called ``Meta-PU"" to firstly support point cloud
upsampling of arbitrary scale factors with a single model. In the Meta-PU
method, besides the backbone network consisting of residual graph convolution
(RGC) blocks, a meta-subnetwork is learned to adjust the weights of the RGC
blocks dynamically, and a farthest sampling block is adopted to sample
different numbers of points. Together, these two blocks enable our Meta-PU to
continuously upsample the point cloud with arbitrary scale factors by using
only a single model. In addition, the experiments reveal that training on
multiple scales simultaneously is beneficial to each other. Thus, Meta-PU even
outperforms the existing methods trained for a specific scale factor only.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:21:48 GMT""}]","2021-02-09"
"2102.04318","Peng Lin","Peng Lin, Vignesh Vivekanandan, Kyle Starkey, Benjamin Anglin, Clint
  Geller, Anter El-Azab","On the computational solution of vector-density based continuum
  dislocation dynamics models: a comparison of two plastic distortion and
  stress update algorithms",,,"10.1016/j.ijplas.2021.102943",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuum dislocation dynamics models of mesoscale plasticity consist of
dislocation transport-reaction equations coupled with crystal mechanics
equations. The coupling between these two sets of equations is such that
dislocation transport gives rise to the evolution of plastic distortion
(strain), while the evolution of the latter fixes the stress from which the
dislocation velocity field is found via a mobility law. Earlier solutions of
these equations employed a staggered solution scheme for the two sets of
equations in which the plastic distortion was updated via time integration of
its rate, as found from Orowan's law. In this work, we show that such a direct
time integration scheme can suffer from accumulation of numerical errors. We
introduce an alternative scheme based on field dislocation mechanics that
ensures consistency between the plastic distortion and the dislocation content
in the crystal. The new scheme is based on calculating the compatible and
incompatible parts of the plastic distortion separately, and the incompatible
part is calculated from the current dislocation density field. Stress field and
dislocation transport calculations were implemented within a finite element
based discretization of the governing equations, with the crystal mechanics
part solved by a conventional Galerkin method and the dislocation transport
equations by the least squares method. A simple test is first performed to show
the accuracy of the two schemes for updating the plastic distortion, which
shows that the solution method based on field dislocation mechanics is more
accurate. This method then was used to simulate an austenitic steel crystal
under uniaxial loading and multiple slip conditions.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:23:23 GMT""}]","2021-02-09"
"2102.04319","Nils Bruin","Nils Bruin, E. Victor Flynn, Ari Shnidman","Genus two curves with full $\sqrt{3}$-level structure and
  Tate-Shafarevich groups","25 pages, small updates to presentation","Selecta Mathematica 29, 42 (2023)","10.1007/s00029-023-00839-w",,"math.NT math.AG","http://creativecommons.org/licenses/by/4.0/","  We give an explicit rational parameterization of the surface $\mathcal{H}_3$
over $\mathbb{Q}$ whose points parameterize genus 2 curves~$C$ with full
$\sqrt{3}$-level structure on their Jacobian $J$. We use this model to
construct abelian surfaces $A$ with the property that $\mathrm{Sha}(A_d)[3]
\neq 0$ for a positive proportion of quadratic twists $A_d$. In fact, for
$100\%$ of $x \in \mathcal{H}_3(\mathbb{Q})$, this holds for the surface $A =
\mathrm{Jac}(C_x)/\langle P \rangle$, where $P$ is the marked point of order
$3$. Our methods also give an explicit bound on the average rank of
$J_d(\mathbb{Q})$, as well as statistical results on the size of
$\#C_d(\mathbb{Q})$, as $d$ varies through squarefree integers.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:24:07 GMT""},{""version"":""v2"",""created"":""Fri, 21 Apr 2023 18:26:30 GMT""}]","2023-06-02"
"2102.04320","Yiping Cheng","Yiping Cheng","Derivation of the Backpropagation Algorithm Based on Derivative
  Amplification Coefficients","8 pages, 1 figure",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The backpropagation algorithm for neural networks is widely felt hard to
understand, despite the existence of some well-written explanations and/or
derivations. This paper provides a new derivation of this algorithm based on
the concept of derivative amplification coefficients. First proposed by this
author for fully connected cascade networks, this concept is found to well
carry over to conventional feedforward neural networks and it paves the way for
the use of mathematical induction in establishing a key result that enables
backpropagation for derivative amplification coefficients. Then we establish
the connection between derivative amplification coefficients and error
coefficients (commonly referred to as errors in the literature), and show that
the same backpropagation procedure can be used for error coefficients. The
entire derivation is thus rigorous, simple, and elegant.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:25:44 GMT""},{""version"":""v2"",""created"":""Sat, 30 Apr 2022 10:06:41 GMT""}]","2022-05-03"
"2102.04321","Rahul Meshram","Rahul Meshram and Kesav Kaza","Monte Carlo Rollout Policy for Recommendation Systems with Dynamic User
  Behavior","5 Pages, 4 figures, conference COMSNETS 2021",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model online recommendation systems using the hidden Markov multi-state
restless multi-armed bandit problem. To solve this we present Monte Carlo
rollout policy. We illustrate numerically that Monte Carlo rollout policy
performs better than myopic policy for arbitrary transition dynamics with no
specific structure. But, when some structure is imposed on the transition
dynamics, myopic policy performs better than Monte Carlo rollout policy.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:26:43 GMT""}]","2021-02-09"
"2102.04322","Pei Peng","Pei Peng, Moslem Noori, Emina Soljanin","Distributed Storage Allocations for Optimal Service Rates",,,,,"cs.IT cs.DC math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Redundant storage maintains the performance of distributed systems under
various forms of uncertainty. This paper considers the uncertainty in node
access and download service. We consider two access models under two download
service models. In one access model, a user can access each node with a fixed
probability, and in the other, a user can access a random fixed-size subset of
nodes. We consider two download service models. In the first (small file)
model, the randomness associated with the file size is negligible. In the
second (large file) model, randomness is associated with both the file size and
the system's operations. We focus on the service rate of the system. For a
fixed redundancy level, the systems' service rate is determined by the
allocation of coded chunks over the storage nodes. We consider quasi-uniform
allocations, where coded content is uniformly spread among a subset of nodes.
The question we address asks what the size of this subset (spreading) should
be. We show that in the small file model, concentrating the coded content to a
minimum-size subset is universally optimal. For the large file model, the
optimal spreading depends on the system parameters. These conclusions hold for
both access models.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:26:53 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 02:33:29 GMT""}]","2021-08-09"
"2102.04323","Tom Zahavy","Tom Zahavy, Andre Barreto, Daniel J Mankowitz, Shaobo Hou, Brendan
  O'Donoghue, Iurii Kemaev and Satinder Singh","Discovering a set of policies for the worst case reward",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of how to construct a set of policies that can be
composed together to solve a collection of reinforcement learning tasks. Each
task is a different reward function defined as a linear combination of known
features. We consider a specific class of policy compositions which we call set
improving policies (SIPs): given a set of policies and a set of tasks, a SIP is
any composition of the former whose performance is at least as good as that of
its constituents across all the tasks. We focus on the most conservative
instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any
SIP. This includes known policy-composition operators like generalized policy
improvement. Our main contribution is a policy iteration algorithm that builds
a set of policies in order to maximize the worst-case performance of the
resulting SMP on the set of tasks. The algorithm works by successively adding
new policies to the set. We show that the worst-case performance of the
resulting SMP strictly improves at each iteration, and the algorithm only stops
when there does not exist a policy that leads to improved performance. We
empirically evaluate our algorithm on a grid world and also on a set of domains
from the DeepMind control suite. We confirm our theoretical results regarding
the monotonically improving performance of our algorithm. Interestingly, we
also show empirically that the sets of policies computed by the algorithm are
diverse, leading to different trajectories in the grid world and very distinct
locomotion skills in the control suite.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:27:09 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 18:03:44 GMT""}]","2021-12-13"
"2102.04324","Dhruv Mauria Saxena","Dhruv Mauria Saxena, Muhammad Suhail Saleem, and Maxim Likhachev","Manipulation Planning Among Movable Obstacles Using Physics-Based
  Adaptive Motion Primitives","Published at IEEE International Conference on Robotics and Automation
  (ICRA), 2021",,"10.1109/ICRA48506.2021.9561221",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robot manipulation in cluttered scenes often requires contact-rich
interactions with objects. It can be more economical to interact via
non-prehensile actions, for example, push through other objects to get to the
desired grasp pose, instead of deliberate prehensile rearrangement of the
scene. For each object in a scene, depending on its properties, the robot may
or may not be allowed to make contact with, tilt, or topple it. To ensure that
these constraints are satisfied during non-prehensile interactions, a planner
can query a physics-based simulator to evaluate the complex multi-body
interactions caused by robot actions. Unfortunately, it is infeasible to query
the simulator for thousands of actions that need to be evaluated in a typical
planning problem as each simulation is time-consuming. In this work, we show
that (i) manipulation tasks (specifically pick-and-place style tasks from a
tabletop or a refrigerator) can often be solved by restricting robot-object
interactions to adaptive motion primitives in a plan, (ii) these actions can be
incorporated as subgoals within a multi-heuristic search framework, and (iii)
limiting interactions to these actions can help reduce the time spent querying
the simulator during planning by up to 40x in comparison to baseline
algorithms. Our algorithm is evaluated in simulation and in the real-world on a
PR2 robot using PyBullet as our physics-based simulator. Supplementary video:
\url{https://youtu.be/ABQc7JbeJPM}.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:29:45 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 15:33:30 GMT""}]","2023-03-24"
"2102.04325","Calum MacRury","Allan Borodin, Calum MacRury, Akash Rakheja","Prophet Matching Meets Probing with Commitment","Updated citations and improved presentation",,,,"cs.DM cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the online stochastic matching problem for bipartite graphs where
edges adjacent to an online node must be probed to determine if they exist,
based on known edge probabilities. Our algorithms respect commitment, in that
if a probed edge exists, it must be used in the matching. We study this
matching problem subject to a downward-closed constraint on each online node's
allowable edge probes. Our setting generalizes the commonly studied patience
(or time-out) constraint which limits the number of probes that can be made to
an online node's adjacent edges. We introduce a new LP that we prove is a
relaxation of an optimal offline probing algorithm (the adaptive benchmark) and
which overcomes the limitations of previous LP relaxations.
  (1) A tight $\frac{1}{2}$ ratio when the stochastic graph is generated from a
known stochastic type graph where the $t^{th}$ online node is drawn
independently from a known distribution $\scr{D}_{\pi(t)}$ and $\pi$ is chosen
adversarially. We refer to this setting as the known i.d. stochastic matching
problem with adversarial arrivals.
  (2) A $1-1/e$ ratio when the stochastic graph is generated from a known
stochastic type graph where the $t^{th}$ online node is drawn independently
from a known distribution $\scr{D}_{\pi(t)}$ and $\pi$ is a random permutation.
We refer to this setting as the known i.d. stochastic matching problem with
random order arrivals.
  Our results improve upon the previous best competitive ratio of $0.46$ in the
known i.i.d. setting against the standard adaptive benchmark. Moreover, we are
the first to study the prophet secretary matching problem in the context of
probing, where we match the best known classical result.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:29:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 17:06:03 GMT""},{""version"":""v3"",""created"":""Thu, 29 Jul 2021 21:59:41 GMT""}]","2021-08-02"
"2102.04326","Anurag Jain","Anurag Jain and Shoeb Siddiqui and Sujit Gujar","We might walk together, but I run faster: Network Fairness and
  Scalability in Blockchains","Full Version of the paper submitted to AAMAS as an Extended Abstract",,,,"cs.DC cs.NI","http://creativecommons.org/licenses/by/4.0/","  Blockchain-based Distributed Ledgers (DLs) promise to transform the existing
financial system by making it truly democratic. In the past decade, blockchain
technology has seen many novel applications ranging from the banking industry
to real estate. However, in order to be adopted universally, blockchain systems
must be scalable to support a high volume of transactions. As we increase the
throughput of the DL system, the underlying peer-to-peer network might face
multiple levels of challenges to keep up with the requirements. Due to varying
network capacities, the slower nodes would be at a relative disadvantage
compared to the faster ones, which could negatively impact their revenue. In
order to quantify their relative advantage or disadvantage, we introduce two
measures of network fairness, $p_f$, the probability of frontrunning and
$\alpha_f$, the publishing fairness. We show that as we scale the blockchain,
both these measures deteriorate, implying that the slower nodes face a
disadvantage at higher throughputs. It results in the faster nodes getting more
than their fair share of the reward while the slower nodes (slow in terms of
network quality) get less. Thus, fairness and scalability in blockchain systems
do not go hand in hand.
  In a setting with rational miners, lack of fairness causes miners to deviate
from the ""longest chain rule"" or undercut, which would reduce the blockchain's
resilience against byzantine adversaries. Hence, fairness is not only a
desirable property for a blockchain system but also essential for the security
of the blockchain and any scalable blockchain protocol proposed must ensure
fairness.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:30:04 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 17:22:28 GMT""}]","2021-02-22"
"2102.04327","Pallav Chanda","Pallav Chanda, Rajib Saha","An Unbiased Estimator of the Full-sky CMB Angular Power Spectrum at
  Large Scales using Neural Networks","10 pages, 11 figures; altered methodology, added links to references,
  updated analysis using latest available data, modified the write-up
  accordingly",,"10.1093/mnras/stab2753",,"astro-ph.CO cs.LG gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate estimation of the Cosmic Microwave Background (CMB) angular power
spectrum is enticing due to the prospect for precision cosmology it presents.
Galactic foreground emissions, however, contaminate the CMB signal and need to
be subtracted reliably in order to lessen systematic errors on the CMB
temperature estimates. Typically bright foregrounds in a region lead to further
uncertainty in temperature estimates in the area even after some foreground
removal technique is performed and hence determining the underlying full-sky
angular power spectrum poses a challenge. We explore the feasibility of
utilizing artificial neural networks to predict the angular power spectrum of
the full sky CMB temperature maps from the observed angular power spectrum of
the partial sky in which CMB temperatures in some bright foreground regions are
masked. We present our analysis at large angular scales with two different
masks. We produce unbiased predictions of the full-sky angular power spectrum
and recover the underlying theoretical power spectrum using neural networks.
Our predictions are also uncorrelated to a large extent. We further show that
the multipole-space covariances of the predictions of full-sky spectra made by
the ANNs are much smaller than those of the estimates obtained using the
pseudo-$C_\ell$ method.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:30:31 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 03:04:56 GMT""}]","2021-10-04"
"2102.04328","Artem Bohdan","Artem Bohdan, Martin Pohl, Jacek Niemiec, Paul J. Morris, Yosuke
  Matsumoto, Takanobu Amano, Masahiro Hoshino and Ali Sulaiman","Magnetic field amplification by the Weibel instability at planetary and
  astrophysical high-Mach-number shocks","Accepted to PRL. 7 pages, 4 figure",,"10.1103/PhysRevLett.126.095101",,"astro-ph.HE astro-ph.EP physics.comp-ph physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collisionless shocks are ubiquitous in the Universe and often associated with
strong magnetic field. Here we use large-scale particle-in-cell simulations of
non-relativistic perpendicular shocks in the high-Mach-number regime to study
the amplification of magnetic field within shocks. The magnetic field is
amplified at the shock transition due to the ion-ion two-stream Weibel
instability. The normalized magnetic-field strength strongly correlates with
the Alfv\'enic Mach number. Mock spacecraft measurements derived from PIC
simulations are fully consistent with those taken in-situ at Saturn's bow shock
by the Cassini spacecraft.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:33:39 GMT""}]","2021-03-17"
"2102.04329","Phiala Shanahan","W. Detmold and P. E. Shanahan","Few-nucleon matrix elements in pionless effective field theory in a
  finite volume",,"Phys. Rev. D 103, 074503 (2021)","10.1103/PhysRevD.103.074503","MIT-CTP/5275","nucl-th hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  Pionless effective field theory in a finite volume (FVEFT$_{\pi\!/}$) is
investigated as a framework for the analysis of multi-nucleon spectra and
matrix elements calculated in lattice QCD (LQCD). By combining FVEFT$_{\pi\!/}$
with the stochastic variational method, the spectra of nuclei with atomic
number $A\in\{2,3\}$ are matched to existing finite-volume LQCD calculations at
heavier-than-physical quark masses corresponding to a pion mass $m_\pi=806$
MeV, thereby enabling infinite-volume binding energies to be determined using
infinite-volume variational calculations. Based on the variational
wavefunctions that are constructed in this approach, the finite-volume matrix
elements of various local operators are computed in FVEFT$_{\pi\!/}$ and
matched to LQCD calculations of the corresponding QCD operators in the same
volume, thereby determining the relevant one and two-body EFT counterterms and
enabling an extrapolation of the LQCD matrix elements to infinite volume. As
examples, the scalar, tensor, and axial matrix elements are considered, as well
as the magnetic moments and the isovector longitudinal momentum fraction.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:34:00 GMT""}]","2021-04-21"
"2102.04330","Yuanyuan Xu","Kevin Schnelli, Yuanyuan Xu","Convergence rate to the Tracy-Widom laws for the largest eigenvalue of
  Wigner matrices","48 pages; minor revisions and updated references, final version",,"10.1007/s00220-022-04377-y",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the fluctuations of the largest eigenvalue of a real symmetric
or complex Hermitian Wigner matrix of size $N$ converge to the Tracy--Widom
laws at a rate $O(N^{-1/3+\omega})$, as $N$ tends to infinity. For Wigner
matrices this improves the previous rate $O(N^{-2/9+\omega})$ obtained by
Bourgade [5] for generalized Wigner matrices. Our result follows from a Green
function comparison theorem, originally introduced by Erd\H{o}s, Yau and Yin
[19] to prove edge universality, on a finer spectral parameter scale with
improved error estimates. The proof relies on the continuous Green function
flow induced by a matrix-valued Ornstein--Uhlenbeck process. Precise estimates
on leading contributions from the third and fourth order moments of the matrix
entries are obtained using iterative cumulant expansions and recursive
comparisons for correlation functions, along with uniform convergence estimates
for correlation kernels of the Gaussian invariant ensembles.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:36:00 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 15:09:10 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 21:00:11 GMT""}]","2022-05-04"
"2102.04331","Ali Karimi","Ali Karimi, Ramin Toosi, Mohammad Ali Akhaee","Soccer Event Detection Using Deep Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Event detection is an important step in extracting knowledge from the video.
In this paper, we propose a deep learning approach to detect events in a soccer
match emphasizing the distinction between images of red and yellow cards and
the correct detection of the images of selected events from other images. This
method includes the following three modules: i) the variational autoencoder
(VAE) module to differentiate between soccer images and others image, ii) the
image classification module to classify the images of events, and iii) the
fine-grain image classification module to classify the images of red and yellow
cards. Additionally, a new dataset was introduced for soccer images
classification that is employed to train the networks mentioned in the paper.
In the final section, 10 UEFA Champions League matches are used to evaluate the
networks' performance and precision in detecting the events. The experiments
demonstrate that the proposed method achieves better performance than
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:37:47 GMT""}]","2021-02-09"
"2102.04332","Alhun Aydin","Alhun Aydin","Quantum Shape Effects","PhD Thesis, Istanbul Technical University. 132 pages",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Can we change the shape of a domain without altering its sizes? By
introducing a size-invariant shape transformation, we propose the existence and
explore the consequences of a new type of physical effect appearing at the
quantum scales, which we call here as ""quantum shape effect"". By completely
separating the shape effects from size effects, we show that shape alone
becomes a control parameter on the thermodynamic state functions of confined
systems at nanoscale. We develop an overlapped quantum boundary layer method to
analytically predict the quantum shape effects, reducing a thermodynamic
problem into a geometric one and revealing the profound link between the
geometry and thermodynamics at the quantum scales. Furthermore, we introduce
the isoformal, shape preserving, process which opens up the possibility of a
new generation of thermodynamic cycles operating at nanoscale with unique
features. As a whole, this thesis constitutes the proposition and a
comprehensive investigation of the theory, construction of the methodology and
exploration of the applications of quantum shape effects in thermodynamics.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:39:27 GMT""}]","2021-02-09"
"2102.04333","Tan Guerpinar","Boris Duedder, Vladislav Fomin, Tan Guerpinar, Michael Henke, Philipp
  Asterios Ioannidis, Viktorija Janaviciene, Raimundas Matulevicius, Mubashar
  Iqbal, Natalia Straub","BlockNet Report: Exploring the Blockchain Skills Concept and Best
  Practice Use Cases","arXiv admin note: text overlap with arXiv:2102.03226",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  In order to explore the practical potential and needs of interdisciplinary
knowledge and competence requirements of Blockchain technology, the project
activity ""Development of Interdisciplinary Blockchain Skills Concept"" starts
with the literature review identifying the state of the art of Blockchain in
Supply Chain Management and Logistics, Business and Finance, as well as
Computer Science and IT-Security. The project activity further explores the
academic and industry landscape of existing initiatives in education which
offer Blockchain courses. Moreover, job descriptions and adverts are analyzed
in order to specify today's competence requirements from enterprises. To
discuss and define the future required competence, expert workshops are
organized to validate the findings by academic experts. Based on the research
outcome and validation, an interdisciplinary approach for Blockchain competence
is developed.
  A second part focuses on the development of the Blockchain Best Practices
activity while conducting qualitative empirical research based on case studies
with industry representatives. Therefore, company interviews, based on the
theoretical basis of Output 1, explore existing Blockchain use cases in
different sectors. Due to the interdisciplinary importance of Blockchain
technology, these skills will be defined by different perspectives of
Blockchain from across multiple mentioned disciplines. The use cases and
companies for the interviews will be selected based on various sampling
criteria to gain results valid for a broad scale. The analysis of the various
use cases will be conducted and defined in a standardized format to identify
the key drivers and competence requirements for Blockchain technology
applications and their adoption. On the one hand, this approach ensures
comparability, on the other hand, it facilitates the development of a
structured and systematic framework.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:40:09 GMT""}]","2021-02-09"
"2102.04337","Alfred Galichon","Federico Echenique and Alfred Galichon","Ordinal and cardinal solution concepts for two-sided matching","29 pages, 2 figures","Games and Economic Behavior 101 (2017) pp. 63-77","10.1016/j.geb.2015.10.002",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We characterize solutions for two-sided matching, both in the transferable
and in the nontransferable-utility frameworks, using a cardinal formulation.
Our approach makes the comparison of the matching models with and without
transfers particularly transparent. We introduce the concept of a no-trade
matching to study the role of transfers in matching. A no-trade matching is one
in which the availability of transfers do not affect the outcome.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:42:52 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 12:18:41 GMT""}]","2021-02-15"
"2102.04339","Peng Lin","Peng Lin, Vignesh Vivekanandan, Benjamin Anglin, Clint Geller, Anter
  El-Azab","Incorporating point defect generation due to jog formation into the
  vector density-based continuum dislocation dynamics approach",,,"10.1016/j.jmps.2021.104609",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During plastic deformation of crystalline materials, point defects such as
vacancies and interstitials are generated by jogs on moving dislocations. A
detailed model for jog formation and transport during plastic deformation was
developed within the vector density-based continuum dislocation dynamics
framework (Lin and El-Azab, 2020; Xia and El-Azab, 2015). As a part of this
model, point defect generation associated with jog transport was formulated in
terms of the volume change due to the non-conservative motion of jogs. Balance
equations for the vacancies and interstitials including their rate of
generation due to jog transport were also formulated. A two-way coupling
between point defects and dislocation dynamics was then completed by including
the stress contributed by the eigen-strain of point defects. A jog drag stress
was further introduced into the mobility law of dislocations to account for the
energy dissipation during point defects generation. A number of test problems
and a fully coupled simulation of dislocation dynamics and point defect
generation and diffusion were performed. The results show that there is an
asymmetry of vacancy and interstitial generation due to the different formation
energies of the two types of defects. The results also show that a higher
hardening rate and a higher dislocation density are obtained when the point
defect generation mechanism is coupled to dislocation dynamics.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:43:17 GMT""}]","2021-09-15"
"2102.04340","Radu Curticapean","Radu Curticapean","A full complexity dichotomy for immanant families","28 pages, to appear at STOC'21",,,,"cs.CC math.RT","http://creativecommons.org/licenses/by/4.0/","  Given an integer $n\geq 1$ and an irreducible character $\chi_{\lambda}$ of
$S_{n}$ for some partition $\lambda$ of $n$, the immanant
$\mathrm{imm}_{\lambda}:\mathbb{C}^{n\times n}\to\mathbb{C}$ maps matrices
$A\in\mathbb{C}^{n\times n}$ to $\mathrm{imm}_{\lambda}(A)=\sum_{\pi\in
S_{n}}\chi_{\lambda}(\pi)\prod_{i=1}^{n}A_{i,\pi(i)}$. Important special cases
include the determinant and permanent, which are the immanants associated with
the sign and trivial character, respectively.
  It is known that immanants can be evaluated in polynomial time for characters
that are close to the sign character: Given a partition $\lambda$ of $n$ with
$s$ parts, let $b(\lambda):=n-s$ count the boxes to the right of the first
column in the Young diagram of $\lambda$. For a family of partitions $\Lambda$,
let $b(\Lambda):=\max_{\lambda\in\Lambda}b(\lambda)$ and write Imm$(\Lambda)$
for the problem of evaluating $\mathrm{imm}_{\lambda}(A)$ on input $A$ and
$\lambda\in\Lambda$. If $b(\Lambda)<\infty$, then Imm$(\Lambda)$ is known to be
polynomial-time computable. This subsumes the case of the determinant. On the
other hand, if $b(\Lambda)=\infty$, then previously known hardness results
suggest that Imm$(\Lambda)$ cannot be solved in polynomial time. However, these
results only address certain restricted classes of families $\Lambda$.
  In this paper, we show that the parameterized complexity assumption FPT
$\neq$ #W[1] rules out polynomial-time algorithms for Imm$(\Lambda)$ for any
computationally reasonable family of partitions $\Lambda$ with
$b(\Lambda)=\infty$. We give an analogous result in algebraic complexity under
the assumption VFPT $\neq$ VW[1]. Furthermore, if $b(\lambda)$ even grows
polynomially in $\Lambda$, we show that Imm$(\Lambda)$ is hard for #P and VNP.
This concludes a series of partial results on the complexity of immanants
obtained over the last 35 years.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:43:33 GMT""}]","2021-02-09"
"2102.04341","Jonathan Kelly","Justin Tomasi, Brandon Wagstaff, Steven L. Waslander, Jonathan Kelly","Learned Camera Gain and Exposure Control for Improved Visual Feature
  Detection and Matching","In IEEE Robotics and Automation Letters (RA-L) and presented at the
  IEEE International Conference on Robotics and Automation (ICRA'21), Xi'an,
  China, May 30-Jun. 5, 2021","IEEE Robotics and Automation Letters (RA-L), Vol. 6, No. 2, pp.
  2028-2035, Apr. 2021","10.1109/LRA.2021.3058909",,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Successful visual navigation depends upon capturing images that contain
sufficient useful information. In this letter, we explore a data-driven
approach to account for environmental lighting changes, improving the quality
of images for use in visual odometry (VO) or visual simultaneous localization
and mapping (SLAM). We train a deep convolutional neural network model to
predictively adjust camera gain and exposure time parameters such that
consecutive images contain a maximal number of matchable features. The training
process is fully self-supervised: our training signal is derived from an
underlying VO or SLAM pipeline and, as a result, the model is optimized to
perform well with that specific pipeline. We demonstrate through extensive
real-world experiments that our network can anticipate and compensate for
dramatic lighting changes (e.g., transitions into and out of road tunnels),
maintaining a substantially higher number of inlier feature matches than
competing camera parameter control algorithms.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:46:09 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 17:52:10 GMT""},{""version"":""v3"",""created"":""Mon, 11 Jul 2022 05:00:57 GMT""}]","2022-07-12"
"2102.04342","Jesse Russell","Jesse Russell","The Limits of Computation in Solving Equity Trade-Offs in Machine
  Learning and Justice System Risk Assessment",,,,,"stat.ML cs.LG stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper explores how different ideas of racial equity in machine learning,
in justice settings in particular, can present trade-offs that are difficult to
solve computationally. Machine learning is often used in justice settings to
create risk assessments, which are used to determine interventions, resources,
and punitive actions. Overall aspects and performance of these machine
learning-based tools, such as distributions of scores, outcome rates by levels,
and the frequency of false positives and true positives, can be problematic
when examined by racial group. Models that produce different distributions of
scores or produce a different relationship between level and outcome are
problematic when those scores and levels are directly linked to the restriction
of individual liberty and to the broader context of racial inequity. While
computation can help highlight these aspects, data and computation are unlikely
to solve them. This paper explores where values and mission might have to fill
the spaces computation leaves.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:46:29 GMT""}]","2021-02-09"
"2102.04343","Franck Plunian","Franck Plunian and Thierry Alboussi\`ere","Axisymmetric dynamo action produced by differential rotation, with
  anisotropic electrical conductivity and anisotropic magnetic permeability","19 pages, 6 figures","Journal of Plasma Physics, 87(1), 905870110 (2021)","10.1017/S0022377820001634",,"physics.plasm-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The effect on dynamo action of an anisotropic electrical conductivity
conjugated to an anisotropic magnetic permeability is considered. Not only is
the dynamo fully axisymmetric, but it requires only a simple differential
rotation, which twice challenges the well-established dynamo theory. Stability
analysis is conducted entirely analytically, leading to an explicit expression
of the dynamo threshold. The results show a competition between the anisotropy
of electrical conductivity and that of magnetic permeability, the dynamo effect
becoming impossible if the two anisotropies are identical. For isotropic
electrical conductivity, Cowling's neutral point argument does imply the
absence of an azimuthal component of current density, but does not prevent the
dynamo effect as long as the magnetic permeability is anisotropic.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:47:31 GMT""}]","2021-02-09"
"2102.04344","Shotaro Shiba Funai","Shotaro Shiba Funai and Hirotaka Sugawara","Calculation of Hawking Radiation in Local Field Theory","22 pages, v2: minor typos corrected, v3: minor corrections",,,"KEK-TH-2297","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hawking radiation of the blackhole is calculated based on the principle of
local field theory. In our approach, the radiation is a unitary process,
therefore no information loss will be recorded. In fact, observers in different
regions of the space communicate using the Hawking radiation, when the systems
in the different regions are entangled with each other. The entanglement
entropy of the blackhole is also calculated in the local field theory. We found
that the entanglement entropy of the systems separated by the blackhole horizon
is closely connected to the Hawking radiation in our approach. Our calculation
shows that the entanglement entropy of the systems separated by the horizon of
a blackhole is just a pure number $\frac{\pi^3 + 270 \zeta(3)}{360 \pi^2}$,
independent of any parameter of the blackhole, and its relation to the Hawking
radiation is given by $S_{EE} = \frac{8 \pi}{3} \frac{\pi^3 + 270
\zeta(3)}{\pi^3 + 240 \zeta(3)} {\cal A} R_H$, where $S_{EE}$ is the
entanglement entropy, $\cal A$ is the area of the horizon, and $R_H$ is the
Hawking radiation.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:47:54 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 03:34:24 GMT""},{""version"":""v3"",""created"":""Wed, 1 Sep 2021 00:46:57 GMT""}]","2021-09-02"
"2102.04345","Haryanto Siahaan","Haryanto M. Siahaan","Magnetized Kerr-Taub-NUT spacetime and Kerr/CFT correspondence","18 pages, 1 figure",,"10.1016/j.physletb.2021.136568",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present a new solution in Einstein-Maxwell theory which can be considered
as the magnetized version of Kerr-Taub-NUT solution. Some properties of the
spacetime are discussed. We also compute the entropy of extremal black hole in
the spacetime by using the Kerr/CFT correspondence approach.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:48:07 GMT""}]","2021-08-11"
"2102.04346","Zhiqun Zou","Rui Yin, Zhiqun Zou, Celimuge Wu, Jiantao Yuan, Xianfu Chen and
  Guanding Yu","Learning-based WiFi Traffic Load Estimation in NR-U Systems",,,"10.1587/transfun.2020EAP1063",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unlicensed spectrum has been utilized to make up the shortage on
frequency spectrum in new radio (NR) systems. To fully exploit the advantages
brought by the unlicensed bands, one of the key issues is to guarantee the fair
coexistence with WiFi systems. To reach this goal, timely and accurate
estimation on the WiFi traffic loads is an important prerequisite. In this
paper, a machine learning (ML) based method is proposed to detect the number of
WiFi users on the unlicensed bands. An unsupervised Neural Network (NN)
structure is applied to filter the detected transmission collision probability
on the unlicensed spectrum, which enables the NR users to precisely rectify the
measurement error and estimate the number of active WiFi users. Moreover, NN is
trained online and the related parameters and learning rate of NN are jointly
optimized to estimate the number of WiFi users adaptively with high accuracy.
Simulation results demonstrate that compared with the conventional Kalman
Filter based detection mechanism, the proposed approach has lower complexity
and can achieve a more stable and accurate estimation.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:48:33 GMT""}]","2021-02-24"
"2102.04347","Riccardo Droghei PhD","Riccardo Droghei","On a solution of a fractional hyper-Bessel differential equation by
  means of a multi-index special function","12 pages","Fractional Calculus and Applied Analysis, 24 (2021), 1559-1570","10.1515/fca-2021-0065",,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a new multiple-parameters (multi-index) extension
of the Wright function that arises from an eigenvalue problem for a case of
hyper-Bessel operator involving Caputo fractional derivatives. We show that by
giving particular values to the parameters involved in this special function,
this leads to some known special functions (as the classical Wright function,
the $\alpha$-Mittag-Leffer function, the Tricomi function, etc.) that on their
turn appear as cases of the so-called multi-index Mittag-Leffer functions. As
an application, we mention that this new generalization Wright function is an
isochronous solution of a nonlinear fractional partial differential equation.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:48:52 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 11:54:17 GMT""}]","2021-12-07"
"2102.04348","Paritosh Garg","Paritosh Garg, Linus Jordan, Ola Svensson","Semi-Streaming Algorithms for Submodular Matroid Intersection",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  While the basic greedy algorithm gives a semi-streaming algorithm with an
approximation guarantee of $2$ for the \emph{unweighted} matching problem, it
was only recently that Paz and Schwartzman obtained an analogous result for
weighted instances. Their approach is based on the versatile local ratio
technique and also applies to generalizations such as weighted hypergraph
matchings. However, the framework for the analysis fails for the related
problem of weighted matroid intersection and as a result the approximation
guarantee for weighted instances did not match the factor $2$ achieved by the
greedy algorithm for unweighted instances. Our main result closes this gap by
developing a semi-streaming algorithm with an approximation guarantee of
$2+\epsilon$ for \emph{weighted} matroid intersection, improving upon the
previous best guarantee of $4+\epsilon$. Our techniques also allow us to
generalize recent results by Levin and Wajc on submodular maximization subject
to matching constraints to that of matroid-intersection constraints.
  While our algorithm is an adaptation of the local ratio technique used in
previous works, the analysis deviates significantly and relies on structural
properties of matroid intersection, called kernels. Finally, we also conjecture
that our algorithm gives a $(k+\epsilon)$ approximation for the intersection of
$k$ matroids but prove that new tools are needed in the analysis as the used
structural properties fail for $k\geq 3$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:50:51 GMT""}]","2021-02-09"
"2102.04349","Karthik Muralidhar Dr","Karthik Muralidhar","A Theoretical Answer to ""Does the IRC-SINR of an Interference Rejection
  Combiner always Increase with an Increase in Number of Receive Antennas?""",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Interference rejection combiners (IRCs) are very popular in 4G/5G systems. In
particular, they are often times used in co-ordinated multi-point (CoMP)
networks where the antennas of a neighboring cell's base station (BS) are used
in an IRC receiver, in conjunction with the antennas of the BS of a cell-edge
UE's own cell, to improve the IRC-SINR of a cell-edge user. But does the
IRC-SINR always increase with an increase in the number of antennas? In this
paper, we attempt to answer the question theoretically. We give a theoretical
derivation that quantifies the improvement in the IRC-SINR when the number of
antennas increases by unity. We show that this improvement in IRC-SINR is
always greater than or equal to zero. Thus we prove that increasing the number
of antennas even by unity will always improve the IRC-SINR. Selecting the extra
antennas of the neighbouring cell can be viewed as a special case of antenna
selection described in [1]. We also present the IRC-SINR improvement in an
uplink CoMP scenario by simulations and verify that it indeed matches with the
theoretical gains derived in this paper.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:51:22 GMT""}]","2021-02-09"
"2102.04350","Elan Markowitz","Elan Markowitz, Keshav Balasubramanian, Mehrnoosh Mirtaheri, Sami
  Abu-El-Haija, Bryan Perozzi, Greg Ver Steeg, Aram Galstyan","Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable
  Learning","To appear in ICLR 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Representation Learning (GRL) methods have impacted fields from
chemistry to social science. However, their algorithmic implementations are
specialized to specific use-cases e.g.message passing methods are run
differently from node embedding ones. Despite their apparent differences, all
these methods utilize the graph structure, and therefore, their learning can be
approximated with stochastic graph traversals. We propose Graph Traversal via
Tensor Functionals(GTTF), a unifying meta-algorithm framework for easing the
implementation of diverse graph algorithms and enabling transparent and
efficient scaling to large graphs. GTTF is founded upon a data structure
(stored as a sparse tensor) and a stochastic graph traversal algorithm
(described using tensor operations). The algorithm is a functional that accept
two functions, and can be specialized to obtain a variety of GRL models and
objectives, simply by changing those two functions. We show for a wide class of
methods, our algorithm learns in an unbiased fashion and, in expectation,
approximates the learning as if the specialized implementations were run
directly. With these capabilities, we scale otherwise non-scalable methods to
set state-of-the-art on large graph datasets while being more efficient than
existing GRL libraries - with only a handful of lines of code for each method
specialization. GTTF and its various GRL implementations are on:
https://github.com/isi-usc-edu/gttf.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:52:52 GMT""}]","2021-02-09"
"2102.04351","Sudip Mittal","Priyanka Ranade, Aritran Piplai, Sudip Mittal, Anupam Joshi, Tim Finin","Generating Fake Cyber Threat Intelligence Using Transformer-Based Models","In Proceedings of International Joint Conference on Neural Networks
  2021 (IJCNN 2021), July 2021",,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cyber-defense systems are being developed to automatically ingest Cyber
Threat Intelligence (CTI) that contains semi-structured data and/or text to
populate knowledge graphs. A potential risk is that fake CTI can be generated
and spread through Open-Source Intelligence (OSINT) communities or on the Web
to effect a data poisoning attack on these systems. Adversaries can use fake
CTI examples as training input to subvert cyber defense systems, forcing the
model to learn incorrect inputs to serve their malicious needs.
  In this paper, we automatically generate fake CTI text descriptions using
transformers. We show that given an initial prompt sentence, a public language
model like GPT-2 with fine-tuning, can generate plausible CTI text with the
ability of corrupting cyber-defense systems. We utilize the generated fake CTI
text to perform a data poisoning attack on a Cybersecurity Knowledge Graph
(CKG) and a cybersecurity corpus. The poisoning attack introduced adverse
impacts such as returning incorrect reasoning outputs, representation
poisoning, and corruption of other dependent AI-based cyber defense systems. We
evaluate with traditional approaches and conduct a human evaluation study with
cybersecurity professionals and threat hunters. Based on the study,
professional threat hunters were equally likely to consider our fake generated
CTI as true.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:54:35 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 14:36:16 GMT""},{""version"":""v3"",""created"":""Fri, 18 Jun 2021 18:00:10 GMT""}]","2021-06-22"
"2102.04352","Ad\'elie Gorce","Ad\'elie Gorce, Anne Hutter, Jonathan R. Pritchard","Using the sample variance of 21cm maps as a tracer of the ionisation
  topology","14 pages, 14 figures, published in A&A","A&A 653, A58 (2021)","10.1051/0004-6361/202140515",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Intensity mapping of the 21cm signal of neutral hydrogen will yield exciting
insights into the Epoch of Reionisation and the nature of the first galaxies.
However, the large amount of data that will be generated by the next generation
of radio telescopes, such as the Square Kilometre Array (SKA), as well as the
numerous observational obstacles to overcome, require analysis techniques tuned
to extract the reionisation history and morphology. In this context, we
introduce a one-point statistic, to which we refer as the local variance,
$\sigma_\mathrm{loc}$, that describes the distribution of the mean differential
21cm brightness temperatures measured in two-dimensional maps along the
frequency direction of a light-cone. The local variance takes advantage of what
is usually considered an observational bias, the sample variance. We find the
redshift-evolution of the local variance to not only probe the reionisation
history of the observed patches of the sky, but also trace the ionisation
morphology. This estimator provides a promising tool to constrain the midpoint
of reionisation as well as gaining insight into the ionising properties of
early galaxies.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:56:47 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 16:25:10 GMT""}]","2021-09-15"
"2102.04353","Krzysztof Choromanski","Krzysztof Marcin Choromanski, Deepali Jain, Wenhao Yu, Xingyou Song,
  Jack Parker-Holder, Tingnan Zhang, Valerii Likhosherstov, Aldo Pacchiano,
  Anirban Santara, Yunhao Tang, Jie Tan, Adrian Weller","Unlocking Pixels for Reinforcement Learning via Implicit Attention",,,,,"cs.LG cs.AI cs.CV cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  There has recently been significant interest in training reinforcement
learning (RL) agents in vision-based environments. This poses many challenges,
such as high dimensionality and the potential for observational overfitting
through spurious correlations. A promising approach to solve both of these
problems is an attention bottleneck, which provides a simple and effective
framework for learning high performing policies, even in the presence of
distractions. However, due to poor scalability of attention architectures,
these methods cannot be applied beyond low resolution visual inputs, using
large patches (thus small attention matrices). In this paper we make use of new
efficient attention algorithms, recently shown to be highly effective for
Transformers, and demonstrate that these techniques can be successfully adopted
for the RL setting. This allows our attention-based controllers to scale to
larger visual inputs, and facilitate the use of smaller patches, even
individual pixels, improving generalization. We show this on a range of tasks
from the Distracting Control Suite to vision-based quadruped robots locomotion.
We provide rigorous theoretical analysis of the proposed algorithm.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:00:26 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 16:07:52 GMT""},{""version"":""v3"",""created"":""Mon, 21 Jun 2021 15:53:45 GMT""},{""version"":""v4"",""created"":""Thu, 30 Sep 2021 17:51:39 GMT""},{""version"":""v5"",""created"":""Sat, 2 Oct 2021 01:56:30 GMT""}]","2021-10-05"
"2102.04354","Gabriel Dorfsman-Hopkins","Gabriel Dorfsman-Hopkins","Untilting Line Bundles on Perfectoid Spaces","16 pages. Final version. v2: Updated to correct and simplify the
  proof of the $p$-divisibility of $R^*/R^{\circ*}$ (Proposition 2.9). v3:
  Proposition 2.9 strengthened and section 3 greatly simplified. To appear in
  International Mathematics Research Notices",,,,"math.AG math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $X$ be a perfectoid space with tilt $X^\flat$. We construct a canonical
map $\theta:\operatorname{Pic} X^\flat\to\lim\operatorname{Pic} X$ where the
(inverse) limit is taken over the $p$-power map, and show that $\theta$ is an
isomorphism if $R = \Gamma(X,\mathscr{O}_X)$ is a perfectoid ring. As a
consequence we obtain a characterization of when the Picard groups of $X$ and
$X^\flat$ agree in terms of the $p$-divisibility of $\operatorname{Pic} X$. The
main technical ingredient is the vanishing of higher derived limits of the unit
group $R^*$, whence the main result follows from the Grothendieck spectral
sequence.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:00:46 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 17:41:52 GMT""},{""version"":""v3"",""created"":""Tue, 22 Feb 2022 22:13:33 GMT""}]","2022-02-24"
"2102.04355","Chunhua Geng","Chunhua Geng, Hua Sun, Syed A. Jafar","Multilevel Topological Interference Management: A TIM-TIN Perspective","This work will be submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The robust principles of treating interference as noise (TIN) when it is
sufficiently weak, and avoiding it when it is not, form the background of this
work. Combining TIN with the topological interference management (TIM)
framework that identifies optimal interference avoidance schemes, we formulate
a TIM-TIN problem for multilevel topological interference management, wherein
only a coarse knowledge of channel strengths and no knowledge of channel phases
is available to transmitters. To address the TIM-TIN problem, we first propose
an analytical baseline approach, which decomposes a network into TIN and TIM
components, allocates the signal power levels to each user in the TIN
component, allocates signal vector space dimensions to each user in the TIM
component, and guarantees that the product of the two is an achievable number
of signal dimensions available to each user in the original network. Next, a
distributed numerical algorithm called ZEST is developed. The convergence of
the algorithm is demonstrated, leading to the duality of the TIM-TIN problem
(in terms of GDoF). Numerical results are also provided to demonstrate the
superior sum-rate performance and fast convergence of ZEST.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:02:10 GMT""}]","2021-02-09"
"2102.04356","Abhinandan Bhattacharjee","Abhinandan Bhattacharjee, Nilakantha Meher, and Anand K. Jha","Measurement of two-photon position-momentum EPR correlations through
  single-photon intensity measurements",,"New Journal of Physics, Volume 24, May 2022","10.1088/1367-2630/ac6901",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The measurement of the position-momentum EPR correlations of a two-photon
state is important for many quantum information applications ranging from
quantum key distribution to coincidence imaging. However, all the existing
techniques for measuring the position-momentum EPR correlations involve
coincidence detection and thus suffer from issues that result in less accurate
measurements. In this letter, we propose and demonstrate an experimental scheme
that does not require coincidence detection for measuring the EPR correlations.
Our technique works for two-photon states that are pure, irrespective of
whether the state is separable or entangled. We theoretically show that if the
pure two-photon state satisfies a certain set of conditions then the
position-momentum EPR correlations can be obtained by doing the intensity
measurements on only one of the photons. We experimentally demonstrate this
technique for pure two-photon states produced by type-I spontaneous parametric
down-conversion, and to the best of our knowledge, we report the most accurate
measurement of position-momentum EPR correlations so far.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:02:26 GMT""}]","2022-09-28"
"2102.04357","Ekaterina Ponizovskaya-Devine","E. Ponizovskaya Devine","Mid-infrared photodetector based on 2D material metamaterial with
  negative index properties for a wide range of angles near vertical
  illumination","8 pages, 4 figures",,"10.1007/s00339-021-04364-5",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the vertically illuminated Si compatible mid-infrared
photodetectors based on graphene that forms negative-index metamaterial. The
coupling into a 2D layer at the angles near normal to the surface is negligible
without the help of a metamaterial. We propose a low loss metamaterial, the
dielectric structure with the nano/microholes through 2D materials that
supports a resonance and enhances quantum efficiency in a wide range of
incident angles.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:02:40 GMT""}]","2021-03-17"
"2102.04358","Xin Wang","Xin Wang, Shun Zhou","Explicit Perturbations to the Stabilizer $\tau = {\rm i}$ of Modular
  $A^\prime_5$ Symmetry and Leptonic CP Violation","33 pages, 5 figures. More discussions added, to be published in JHEP","JHEP 07 (2021) 093","10.1007/JHEP07(2021)093",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In a class of neutrino mass models with modular flavor symmetries, it has
been observed that CP symmetry is preserved at the fixed point (or stabilizer)
of the modulus parameter $\tau = {\rm i}$, whereas significant CP violation
emerges within the neighbourhood of this stabilizer. In this paper, we first
construct a viable model with the modular $A^\prime_5$ symmetry, and explore
the phenomenological implications for lepton masses and flavor mixing. Then, we
introduce explicit perturbations to the stabilizer at $\tau = {\rm i}$, and
present both numerical and analytical results to understand why a small
deviation from the stabilizer leads to large CP violation. As low-energy
observables are very sensitive to the perturbations to model parameters, we
further demonstrate that the renormalization-group running effects play an
important role in confronting theoretical predictions at the high-energy scale
with experimental measurements at the low-energy scale.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:03:45 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 01:55:40 GMT""}]","2021-07-26"
"2102.04359","Zhiqun Zou","Rui Yin, Zhiqun Zou, Celimuge Wu, Jiantao Yuan and Xianfu Chen","Distributed Spectrum and Power Allocation for D2D-U Networks: A Scheme
  based on NN and Federated Learning",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a Device-to-Device communication on unlicensed bands (D2D-U)
enabled network is studied. To improve the spectrum efficiency (SE) on the
unlicensed bands and fit its distributed structure while ensuring the fairness
among D2D-U links and the harmonious coexistence with WiFi networks, a
distributed joint power and spectrum scheme is proposed. In particular, a
parameter, named as price, is defined, which is updated at each D2D-U pair by a
online trained Neural network (NN) according to the channel state and traffic
load. In addition, the parameters used in the NN are updated by two ways,
unsupervised self-iteration and federated learning, to guarantee the fairness
and harmonious coexistence. Then, a non-convex optimization problem with
respect to the spectrum and power is formulated and solved on each D2D-U link
to maximize its own data rate. Numerical simulation results are demonstrated to
verify the effectiveness of the proposed scheme.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:08:53 GMT""}]","2021-02-09"
"2102.04360","Rapha\""el Bulle","Rapha\""el Bulle (1), Jack S. Hale (1), Alexei Lozinski (2), St\'ephane
  P. A. Bordas (1), Franz Chouly (2) ((1) University of Luxembourg, (2)
  Universit\'e de Bourgogne Franche-Comt\'e)","Hierarchical a posteriori error estimation of Bank-Weiser type in the
  FEniCS Project",,,,,"math.NA cs.CE cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the seminal paper of Bank and Weiser [Math. Comp., 44 (1985), pp.283-301]
a new a posteriori estimator was introduced. This estimator requires the
solution of a local Neumann problem on every cell of the finite element mesh.
Despite the promise of Bank-Weiser type estimators, namely locality,
computational efficiency, and asymptotic sharpness, they have seen little use
in practical computational problems. The focus of this contribution is to
describe a novel implementation of hierarchical estimators of the Bank-Weiser
type in a modern high-level finite element software with automatic code
generation capabilities. We show how to use the estimator to drive
(goal-oriented) adaptive mesh refinement and to mixed approximations of the
nearly-incompressible elasticity problems. We provide comparisons with various
other used estimators. An open-source implementation based on the FEniCS
Project finite element software is provided as supplementary material.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:09:15 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 10:56:19 GMT""}]","2022-02-08"
"2102.04361","Daniel Stan","Daniel Stan and Anthony Widjaja Lin","Regular Model Checking Approach to Knowledge Reasoning over
  Parameterized Systems (technical report)","Extended version, version of record accepted at the 20th
  International Conference on Autonomous Agents and Multiagent Systems
  (AAMAS-21)",,,,"cs.FL cs.LO cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general framework for modelling and verifying epistemic
properties over parameterized multi-agent systems that communicate by truthful
public announcements. In our framework, the number of agents or the amount of
certain resources are parameterized (i.e. not known a priori), and the
corresponding verification problem asks whether a given epistemic property is
true regardless of the instantiation of the parameters. For example, in a muddy
children puzzle, one could ask whether each child will eventually find out
whether (s)he is muddy, regardless of the number of children.
  Our framework is regular model checking (RMC)-based, wherein synchronous
finite-state automata (equivalently, monadic second-order logic over words) are
used to specify the systems. We propose an extension of public announcement
logic as specification language. Of special interests is the addition of the
so-called iterated public announcement operators, which are crucial for
reasoning about knowledge in parameterized systems. Although the operators make
the model checking problem undecidable, we show that this becomes decidable
when an appropriate ""disappearance relation"" is given. Further, we show how
Angluin's L*-algorithm for learning finite automata can be applied to find a
disappearance relation, which is guaranteed to terminate if it is regular. We
have implemented the algorithm and apply this to such examples as the Muddy
Children Puzzle, the Russian Card Problem, and Large Number Challenge.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:10:24 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 21:50:29 GMT""},{""version"":""v3"",""created"":""Mon, 8 Mar 2021 19:20:12 GMT""}]","2021-03-10"
"2102.04362","Chee Seng Chan","Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang","Protecting Intellectual Property of Generative Adversarial Networks from
  Ambiguity Attack","Accepted at CVPR2021",,,,"cs.CR cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Ever since Machine Learning as a Service (MLaaS) emerges as a viable business
that utilizes deep learning models to generate lucrative revenue, Intellectual
Property Right (IPR) has become a major concern because these deep learning
models can easily be replicated, shared, and re-distributed by any unauthorized
third parties. To the best of our knowledge, one of the prominent deep learning
models - Generative Adversarial Networks (GANs) which has been widely used to
create photorealistic image are totally unprotected despite the existence of
pioneering IPR protection methodology for Convolutional Neural Networks (CNNs).
This paper therefore presents a complete protection framework in both black-box
and white-box settings to enforce IPR protection on GANs. Empirically, we show
that the proposed method does not compromise the original GANs performance
(i.e. image generation, image super-resolution, style transfer), and at the
same time, it is able to withstand both removal and ambiguity attacks against
embedded watermarks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:12:20 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 03:31:03 GMT""}]","2021-03-02"
"2102.04363","Bart Paul Gerard Van Parys","Bart P.G. Van Parys","Efficient Data-Driven Optimization with Noisy Data",,,,,"math.OC cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Classical Kullback-Leibler or entropic distances have recently been shown to
enjoy certain desirable statistical properties in the context of
decision-making with noiseless data. However, a major criticism of such
distances is that they may result in fragile decisions in the presence of a
distributional shift between the training and out-of-sample data. Instead, we
study here data-driven prediction problems with data which is corrupted by
noise. We derive efficient data-driven formulations in this noisy regime and
indicate that they enjoy an entropic optimal transport interpretation. Finally,
we show that these efficient robust formulations are tractable in several
interesting settings by exploiting a classical representation result by
Strassen.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:12:30 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 00:41:02 GMT""}]","2022-03-14"
"2102.04364","Lo\""ick Le Guevel","L. Le Guevel, G. Billiot, S. De Franceschi, A. Morel, X. Jehl, A.G.M.
  Jansen, G. Pillonnet","Compact gate-based read-out of multiplexed quantum devices with a
  cryogenic CMOS active inductor","19 pages, 21 figures",,,,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  In the strive for scalable quantum processors, significant effort is being
devoted to the development of cryogenic classical hardware for the control and
readout of a growing number of qubits. Here we report on a cryogenic circuit
incorporating a CMOS-based active inductor enabling fast impedance measurements
with a sensitivity of 10 aF and an input-referred noise of 3.7 aF/sqrt(Hz).
This type of circuit is especially conceived for the readout of semiconductor
spin qubits. As opposed to commonly used schemes based on dispersive rf
reflectometry, which require mm-scale passive inductors, it allows for a
markedly reduced footprint (50$\mu$m $\times$ 60$\mu$m), facilitating its
integration in a scalable quantum-classical architecture. In addition, its
active inductor results in a resonant circuit with tunable frequency and
quality factor, enabling the optimization of readout sensitivity.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:13:53 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 16:05:16 GMT""}]","2021-02-10"
"2102.04365","Loic Anderegg","Lo\""ic Anderegg, Sean Burchesky, Yicheng Bao, Scarlett S. Yu, Tijs
  Karman, Eunmi Chae, Kang-Kuen Ni, Wolfgang Ketterle, John M. Doyle","Observation of Microwave Shielding of Ultracold Molecules",,,"10.1126/science.abg9502",,"physics.atom-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Harnessing the potential wide-ranging quantum science applications of
molecules will require control of their interactions. Here, we use microwave
radiation to directly engineer and tune the interaction potentials between
ultracold calcium monofluoride (CaF) molecules. By merging two optical
tweezers, each containing a single molecule, we probe collisions in three
dimensions. The correct combination of microwave frequency and power creates an
effective repulsive shield, which suppresses the inelastic loss rate by a
factor of six, in agreement with theoretical calculations. The demonstrated
microwave shielding shows a general route to the creation of long-lived, dense
samples of ultracold molecules and evaporative cooling.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:17:02 GMT""}]","2021-08-25"
"2102.04366","Lucas Prado Osco","Mauro dos Santos de Arruda, Lucas Prado Osco, Plabiany Rodrigo Acosta,
  Diogo Nunes Gon\c{c}alves, Jos\'e Marcato Junior, Ana Paula Marques Ramos,
  Edson Takashi Matsubara, Zhipeng Luo, Jonathan Li, Jonathan de Andrade Silva,
  Wesley Nunes Gon\c{c}alves","Counting and Locating High-Density Objects Using Convolutional Neural
  Network","15 pages, 10 figures, 8 tables","Expert Systems with Applications, 2022","10.1016/j.eswa.2022.116555",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a Convolutional Neural Network (CNN) approach for
counting and locating objects in high-density imagery. To the best of our
knowledge, this is the first object counting and locating method based on a
feature map enhancement and a Multi-Stage Refinement of the confidence map. The
proposed method was evaluated in two counting datasets: tree and car. For the
tree dataset, our method returned a mean absolute error (MAE) of 2.05, a
root-mean-squared error (RMSE) of 2.87 and a coefficient of determination
(R$^2$) of 0.986. For the car dataset (CARPK and PUCPR+), our method was
superior to state-of-the-art methods. In the these datasets, our approach
achieved an MAE of 4.45 and 3.16, an RMSE of 6.18 and 4.39, and an R$^2$ of
0.975 and 0.999, respectively. The proposed method is suitable for dealing with
high object-density, returning a state-of-the-art performance for counting and
locating objects.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:17:10 GMT""}]","2022-05-31"
"2102.04367","Bo Ning","Binlong Li, Jie Ma and Bo Ning","Extremal problems of Erd\H{o}s, Faudree, Schelp and Simonovits on paths
  and cycles","13 pages","J. Combin. Theory Ser. B 152 (2022), 399--414","10.1016/j.jctb.2021.10.007",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For positive integers $n>d\geq k$, let $\phi(n,d,k)$ denote the least integer
$\phi$ such that every $n$-vertex graph with at least $\phi$ vertices of degree
at least $d$ contains a path on $k+1$ vertices. Many years ago, Erd\H{o}s,
Faudree, Schelp and Simonovits proposed the study of the function
$\phi(n,d,k)$, and conjectured that for any positive integers $n>d\geq k$, it
holds that $\phi(n,d,k)\leq
\lfloor\frac{k-1}{2}\rfloor\lfloor\frac{n}{d+1}\rfloor+\epsilon$, where
$\epsilon=1$ if $k$ is odd and $\epsilon=2$ otherwise. In this paper we
determine the values of the function $\phi(n,d,k)$ exactly. This confirms the
above conjecture of Erd\H{o}s et al. for all positive integers $k\neq 4$ and in
a corrected form for the case $k=4$. Our proof utilizes, among others, a lemma
of Erd\H{o}s et al. \cite{EFSS89}, a theorem of Jackson \cite{J81}, and a
(slight) extension of a very recent theorem of Kostochka, Luo and Zirlin
\cite{KLZ}, where the latter two results concern maximum cycles in bipartite
graphs. Moreover, we construct examples to provide answers to two closely
related questions raised by Erd\H{o}s et al.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:20:24 GMT""},{""version"":""v2"",""created"":""Sun, 17 Oct 2021 10:00:03 GMT""},{""version"":""v3"",""created"":""Sun, 24 Oct 2021 13:49:44 GMT""}]","2022-07-19"
"2102.04368","Ralf T\""onjes","Ralf T\""onjes, Carlos E. Fiore and Tiago Pereira","Coherence resonance in influencer networks","this pdf includes supplementary notes","Nat.Commun. 12, 72 (2021)","10.1038/s41467-020-20441-4",,"nlin.AO cond-mat.dis-nn physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Complex networks are abundant in nature and many share an important
structural property: they contain a few nodes that are abnormally highly
connected (hubs). Some of these hubs are called influencers because they couple
strongly to the network and play fundamental dynamical and structural roles.
Strikingly, despite the abundance of networks with influencers, little is known
about their response to stochastic forcing. Here, for oscillatory dynamics on
influencer networks, we show that subjecting influencers to an optimal
intensity of noise can result in enhanced network synchronization. This new
network dynamical effect, which we call coherence resonance in influencer
networks, emerges from a synergy between network structure and stochasticity
and is highly nonlinear, vanishing when the noise is too weak or too strong.
Our results reveal that the influencer backbone can sharply increase the
dynamical response in complex systems of coupled oscillators.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:22:00 GMT""}]","2021-02-09"
"2102.04369","Michael Perlman","Michael Perlman","Mixed Hodge structure on local cohomology with support in determinantal
  varieties","17 pages, v2: Strengthened main theorem (Theorem 3.1) to include
  indecomposable summands of local cohomology. Corrected errors in Section 2
  and Section 3. To appear in IMRN",,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We employ the inductive structure of determinantal varieties to calculate the
mixed Hodge module structure of local cohomology modules with determinantal
support. We show that the weight of a simple composition factor is uniquely
determined by its support and cohomological degree. As a consequence, we obtain
the equivariant structure of the Hodge filtration on each local cohomology
module. Finally, as an application, we provide a formula for the generation
level of the Hodge filtration on these modules.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:22:05 GMT""},{""version"":""v2"",""created"":""Fri, 20 Jan 2023 15:33:33 GMT""}]","2023-01-23"
"2102.04370","Van Kien Nguyen","Dinh D\~ung and Van Kien Nguyen","High-dimensional nonlinear approximation by parametric manifolds in
  H\""older-Nikol'skii spaces of mixed smoothness","25 pages",,,,"math.NA cs.NA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study high-dimensional nonlinear approximation of functions in
H\""older-Nikol'skii spaces $H^\alpha_\infty(\mathbb{I}^d)$ on the unit cube
$\mathbb{I}^d:=[0,1]^d$ having mixed smoothness, by parametric manifolds. The
approximation error is measured in the $L_\infty$-norm. In this context, we
explicitly constructed methods of nonlinear approximation, and give
dimension-dependent estimates of the approximation error explicitly in
dimension $d$ and number $N$ measuring computation complexity of the parametric
manifold of approximants. For $d=2$, we derived a novel right asymptotic order
of noncontinuous manifold $N$-widths of the unit ball of
$H^\alpha_\infty(\mathbb{I}^2)$ in the space $L_\infty(\mathbb{I}^2)$. In
constructing approximation methods, the function decomposition by the tensor
product Faber series and special representations of its truncations on sparse
grids play a central role.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:23:36 GMT""}]","2021-02-09"
"2102.04371","Colin Rylands","Colin Rylands, Alireza Parhizkar, Anton A. Burkov and Victor Galitski","Chiral Anomaly in Interacting Condensed Matter Systems","4.5 pages","Phys. Rev. Lett. 126, 185303 (2021)","10.1103/PhysRevLett.126.185303",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The chiral anomaly is a fundamental quantum mechanical phenomenon which is of
great importance to both particle physics and condensed matter physics alike.
In the context of QED it manifests as the breaking of chiral symmetry in the
presence of electromagnetic fields. It is also known that anomalous chiral
symmetry breaking can occur through interactions alone, as is the case for
interacting one dimensional systems. In this paper we investigate the interplay
between these two modes of anomalous chiral symmetry breaking in the context of
interacting Weyl semimetals. Using Fujikawa's path integral method we show that
the chiral charge continuity equation is modified by the presence of
interactions which can be viewed as including the effect of the electric and
magnetic fields generated by the interacting quantum matter. This can be
understood further using dimensional reduction and a Luttinger liquid
description of the lowest Landau level. These effects manifest themselves in
the non-linear response of the system. In particular we find an interaction
dependent density response due to a change in the magnetic field as well as a
contribution to the non-equilibrium and inhomogeneous anomalous Hall response
while preserving its equilibrium value.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:24:17 GMT""}]","2021-05-12"
"2102.04372","Christophe Ritzenthaler","Reynald Lercier, Jeroen Sijsling, Christophe Ritzenthaler","Functionalities for genus $2$ and $3$ curves","13 pages",,,,"math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We gather and illustrate some functions that we wrote in the Magma computer
algebra system for curves of genus $2$ and $3$. In genus $3$, we furnish
functions both for non-hyperelliptic and for hyperelliptic curves. A fair bit
of the functionality in the latter case extends to hyperelliptic curves of
arbitrary genus.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:26:05 GMT""}]","2021-02-09"
"2102.04373","Calvin Tsay","Calvin Tsay and Jan Kronqvist and Alexander Thebelt and Ruth Misener","Partition-based formulations for mixed-integer optimization of trained
  ReLU neural networks","Conference on Neural Information Processing Systems (NeurIPS) 2021",,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a class of mixed-integer formulations for trained ReLU
neural networks. The approach balances model size and tightness by partitioning
node inputs into a number of groups and forming the convex hull over the
partitions via disjunctive programming. At one extreme, one partition per input
recovers the convex hull of a node, i.e., the tightest possible formulation for
each node. For fewer partitions, we develop smaller relaxations that
approximate the convex hull, and show that they outperform existing
formulations. Specifically, we propose strategies for partitioning variables
based on theoretical motivations and validate these strategies using extensive
computational experiments. Furthermore, the proposed scheme complements known
algorithmic approaches, e.g., optimization-based bound tightening captures
dependencies within a partition.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:27:34 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 10:46:33 GMT""}]","2021-10-22"
"2102.04374","Giuseppe Ughi","Jared Tanner and Giuseppe Ughi","Mutual Information of Neural Network Initialisations: Mean Field
  Approximations",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to train randomly initialised deep neural networks is known to
depend strongly on the variance of the weight matrices and biases as well as
the choice of nonlinear activation. Here we complement the existing geometric
analysis of this phenomenon with an information theoretic alternative. Lower
bounds are derived for the mutual information between an input and hidden layer
outputs. Using a mean field analysis we are able to provide analytic lower
bounds as functions of network weight and bias variances as well as the choice
of nonlinear activation. These results show that initialisations known to be
optimal from a training point of view are also superior from a mutual
information perspective.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:29:38 GMT""}]","2021-02-09"
"2102.04375","Natalia Jurga","Natalia Jurga","Non-existence of the box dimension for dynamically invariant sets","To appear in APDE",,,,"math.DS math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the key challenges in the dimension theory of smooth dynamical systems
is in establishing whether or not the Hausdorff, lower and upper box dimensions
coincide for invariant sets. For sets invariant under conformal dynamics, these
three dimensions always coincide. On the other hand, considerable attention has
been given to examples of sets invariant under non-conformal dynamics whose
Hausdorff and box dimensions do not coincide. These constructions exploit the
fact that the Hausdorff and box dimensions quantify size in fundamentally
different ways, the former in terms of covers by sets of varying diameters and
the latter in terms of covers by sets of fixed diameters. In this article we
construct the first example of a dynamically invariant set with distinct lower
and upper box dimensions. Heuristically, this describes that if size is
quantified in terms of covers by sets of equal diameters, a dynamically
invariant set can appear bigger when viewed at certain resolutions than at
others.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:30:12 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 00:11:43 GMT""}]","2022-05-24"
"2102.04376","Yannis Flet-Berliac","Yannis Flet-Berliac and Johan Ferret and Olivier Pietquin and Philippe
  Preux and Matthieu Geist","Adversarially Guided Actor-Critic","Accepted at ICLR 2021",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Despite definite success in deep reinforcement learning problems,
actor-critic algorithms are still confronted with sample inefficiency in
complex environments, particularly in tasks where efficient exploration is a
bottleneck. These methods consider a policy (the actor) and a value function
(the critic) whose respective losses are built using different motivations and
approaches. This paper introduces a third protagonist: the adversary. While the
adversary mimics the actor by minimizing the KL-divergence between their
respective action distributions, the actor, in addition to learning to solve
the task, tries to differentiate itself from the adversary predictions. This
novel objective stimulates the actor to follow strategies that could not have
been correctly predicted from previous trajectories, making its behavior
innovative in tasks where the reward is extremely rare. Our experimental
analysis shows that the resulting Adversarially Guided Actor-Critic (AGAC)
algorithm leads to more exhaustive exploration. Notably, AGAC outperforms
current state-of-the-art methods on a set of various hard-exploration and
procedurally-generated tasks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:31:13 GMT""}]","2021-02-09"
"2102.04377","Louie Corpe Dr","A. Buckley, J. M. Butterworth, L. Corpe, M. Habedank, D. Huang, D.
  Yallup, M. Altakach, G. Bassman, I. Lagwankar, J. Rocamonde, H. Saunders, B.
  Waugh, G. Zilgalvis","Testing new physics models with global comparisons to collider
  measurements: the Contur toolkit",,"SciPost Phys. Core 4, 013 (2021)","10.21468/SciPostPhysCore.4.2.013","MCnet-21","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements at particle collider experiments, even if primarily aimed at
understanding Standard Model processes, can have a high degree of model
independence, and implicitly contain information about potential contributions
from physics beyond the Standard Model. The Contur package allows users to
benefit from the hundreds of measurements preserved in the Rivet library to
test new models against the bank of LHC measurements to date. This method has
proven to be very effective in several recent publications from the Contur
team, but ultimately, for this approach to be successful, the authors believe
that the Contur tool needs to be accessible to the wider high energy physics
community. As such, this manual accompanies the first user-facing version:
Contur v2. It describes the design choices that have been made, as well as
detailing pitfalls and common issues to avoid. The authors hope that with the
help of this documentation, external groups will be able to run their own
Contur studies, for example when proposing a new model, or pitching a new
search.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:33:19 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 07:14:56 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 13:50:54 GMT""}]","2021-08-20"
"2102.04378","Shuting He","Shuting He, Hao Luo, Pichao Wang, Fan Wang, Hao Li, Wei Jiang","TransReID: Transformer-based Object Re-Identification","Code is available at https://github.com/heshuting555/TransReID",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extracting robust feature representation is one of the key challenges in
object re-identification (ReID). Although convolution neural network
(CNN)-based methods have achieved great success, they only process one local
neighborhood at a time and suffer from information loss on details caused by
convolution and downsampling operators (e.g. pooling and strided convolution).
To overcome these limitations, we propose a pure transformer-based object ReID
framework named TransReID. Specifically, we first encode an image as a sequence
of patches and build a transformer-based strong baseline with a few critical
improvements, which achieves competitive results on several ReID benchmarks
with CNN-based methods. To further enhance the robust feature learning in the
context of transformers, two novel modules are carefully designed. (i) The
jigsaw patch module (JPM) is proposed to rearrange the patch embeddings via
shift and patch shuffle operations which generates robust features with
improved discrimination ability and more diversified coverage. (ii) The side
information embeddings (SIE) is introduced to mitigate feature bias towards
camera/view variations by plugging in learnable embeddings to incorporate these
non-visual clues. To the best of our knowledge, this is the first work to adopt
a pure transformer for ReID research. Experimental results of TransReID are
superior promising, which achieve state-of-the-art performance on both person
and vehicle ReID benchmarks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:33:59 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 15:40:42 GMT""}]","2021-03-29"
"2102.04379","Georgios Chochlakis","Georgios Chochlakis, Efthymios Georgiou, Alexandros Potamianos","End-to-end Generative Zero-shot Learning via Few-shot Learning","12 pages, 3 figures, 6 tables",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Contemporary state-of-the-art approaches to Zero-Shot Learning (ZSL) train
generative nets to synthesize examples conditioned on the provided metadata.
Thereafter, classifiers are trained on these synthetic data in a supervised
manner. In this work, we introduce Z2FSL, an end-to-end generative ZSL
framework that uses such an approach as a backbone and feeds its synthesized
output to a Few-Shot Learning (FSL) algorithm. The two modules are trained
jointly. Z2FSL solves the ZSL problem with a FSL algorithm, reducing, in
effect, ZSL to FSL. A wide class of algorithms can be integrated within our
framework. Our experimental results show consistent improvement over several
baselines. The proposed method, evaluated across standard benchmarks, shows
state-of-the-art or competitive performance in ZSL and Generalized ZSL tasks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:35:37 GMT""}]","2021-02-09"
"2102.04380","Tatiana Dudnikova","T.V. Dudnikova","Space-time statistical solutions for an inhomogeneous chain of harmonic
  oscillators","27 pages",,,,"math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an one-dimensional inhomogeneous harmonic chain consisting of two
different semi-infinite chains of harmonic oscillators. We study the Cauchy
problem with random initial data. Under some restrictions on the interaction
between the oscillators of the chain and on the distribution of the initial
data, we prove the convergence of space-time statistical solutions to a
Gaussian measure.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:38:16 GMT""}]","2021-02-09"
"2102.04381","Ilija Zeljkovic","Zheng Ren, Hong Li, He Zhao, Shrinkhala Sharma, Ziqiang Wang and Ilija
  Zeljkovic","Nanoscale decoupling of electronic nematicity and structural anisotropy
  in FeSe thin films",,"Nature Communications 12, 10 (2021)","10.1038/s41467-020-20150-y",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  In a material prone to a nematic instability, anisotropic strain in principle
provides a preferred symmetry-breaking direction for the electronic nematic
state to follow. This is consistent with experimental observations, where
electronic nematicity and structural anisotropy typically appear hand-in-hand.
In this work, we discover that electronic nematicity can be locally decoupled
from the underlying structural anisotropy in strain-engineered iron-selenide
(FeSe) thin films. We use heteroepitaxial molecular beam epitaxy to grow FeSe
with a nanoscale network of modulations that give rise to spatially varying
strain. We map local anisotropic strain by analyzing scanning tunneling
microscopy topographs, and visualize electronic nematic domains from
concomitant spectroscopic maps. While the domains form so that the energy of
nemato-elastic coupling is minimized, we observe distinct regions where
electronic nematic ordering fails to flip direction, even though the underlying
structural anisotropy is locally reversed. The findings point towards a
nanometer-scale stiffness of the nematic order parameter.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:40:48 GMT""}]","2021-02-09"
"2102.04382","Falco J. Bargagli Stoffi","Falco J. Bargagli Stoffi, Kenneth De Beckker, Joana E. Maldonado,
  Kristof De Witte","Assessing Sensitivity of Machine Learning Predictions.A Novel Toolbox
  with an Application to Financial Literacy",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  Despite their popularity, machine learning predictions are sensitive to
potential unobserved predictors. This paper proposes a general algorithm that
assesses how the omission of an unobserved variable with high explanatory power
could affect the predictions of the model. Moreover, the algorithm extends the
usage of machine learning from pointwise predictions to inference and
sensitivity analysis. In the application, we show how the framework can be
applied to data with inherent uncertainty, such as students' scores in a
standardized assessment on financial literacy. First, using Bayesian Additive
Regression Trees (BART), we predict students' financial literacy scores (FLS)
for a subgroup of students with missing FLS. Then, we assess the sensitivity of
predictions by comparing the predictions and performance of models with and
without a highly explanatory synthetic predictor. We find no significant
difference in the predictions and performances of the augmented (i.e., the
model with the synthetic predictor) and original model. This evidence sheds a
light on the stability of the predictive model used in the application. The
proposed methodology can be used, above and beyond our motivating empirical
example, in a wide range of machine learning applications in social and health
sciences.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:42:10 GMT""}]","2021-02-09"
"2102.04383","Douglas Heggie","Philip G. Breen (1), Simon Rozier (2), Douglas C. Heggie (1), Anna
  Lisa Varri (3 and 1) ((1) School of Mathematics and Maxwell Institute for
  Mathematical Sciences, University of Edinburgh, Scotland, (2) Universit\'e de
  Strasbourg, CNRS UMR 7550, Observatoire astronomique de Strasbourg, France,
  (3) Institute for Astronomy, University of Edinburgh, Scotland)","The Kinematic Richness of Star Clusters - II. Stability of Spherical
  Anisotropic Models with Rotation","17 pages, 18 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab365",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the bar instability in collisionless, rotating, anisotropic, stellar
systems, using N-body simulations and also the matrix technique for calculation
of modes with the perturbed collisionless Boltzmann equation. These methods are
applied to spherical systems with an initial Plummer density distribution, but
modified kinematically in two ways: the velocity distribution is tangentially
anisotropic, using results of Dejonghe, and the system is set in rotation by
reversing the velocities of a fraction of stars in various regions of phase
space, a la Lynden-Bell. The aim of the N-body simulations is first to survey
the parameter space, and, using those results, to identify regions of phase
space (by radius and orbital inclination) which have the most important
influence on the bar instability. The matrix method is then used to identify
the resonant interactions in the system which have the greatest effect on the
growth rate of a bar. Complementary series of N-body simulations examine these
processes in relation to the evolving frequency distribution and the pattern
speed. Finally, the results are synthesised with an existing theoretical
framework, and used to consider the old question of constructing a stability
criterion.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:45:16 GMT""}]","2021-02-17"
"2102.04384","Haris Aziz","Haris Aziz and Florian Brandl","Efficient, Fair, and Incentive-Compatible Healthcare Rationing","The new version focusses on different rules and has new
  characterisation results",,,,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rationing of healthcare resources has emerged as an important issue, which
has been discussed by medical experts, policy-makers, and the general public.
We consider a rationing problem where medical units are to be allocated to
patients. Each unit is reserved for one of several categories and each category
has a priority ranking of the patients. We present an allocation rule that
respects the priorities, complies with the eligibility requirements, allocates
the largest feasible number of units, and does not incentivize agents to hide
that they qualify through a category. The rule characterizes all possible
allocations that satisfy the first three properties and is polynomial-time
computable.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:45:52 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 03:47:04 GMT""}]","2021-09-28"
"2102.04385","Markus Mugrauer","K.-U. Michel, M. Mugrauer","Search for (sub)stellar companions of exoplanet hosts by exploring the
  second ESA-Gaia data release","30 pages, 7 figures, 5 tables, accepted for publication in Frontiers
  in Astronomy and Space Sciences",,,,"astro-ph.EP astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the latest results of an ongoing multiplicity survey of exoplanet
hosts, which was initiated at the Astrophysical Institute and University
Observatory Jena, using data from the second data release of the ESA-Gaia
mission. In this study the multiplicity of 289 targets was investigated, all
located within a distance of about 500 pc from the Sun. In total, 41 binary,
and 5 hierarchical triple star systems with exoplanets were detected in the
course of this project, yielding a multiplicity rate of the exoplanet hosts of
about 16 %. A total of 61 companions (47 stars, a white dwarf, and 13 brown
dwarfs) were detected around the targets, whose equidistance and common proper
motion with the exoplanet hosts were proven with their precise Gaia DR2
astrometry, which also agrees with the gravitational stability of most of these
systems. The detected companions exhibit masses from about 0.016 up to 1.66
M$_\odot$ and projected separations in the range between about 52 and 9555 au.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:46:10 GMT""}]","2021-02-09"
"2102.04386","Cole Comfort","Cole Comfort","Distributive Laws, Spans and the ZX-Calculus",,,,,"math.CT cs.LO quant-ph","http://creativecommons.org/licenses/by/4.0/","  We modularly build increasingly larger fragments of the ZX-calculus by
modularly adding new generators and relations, at each point, giving some
concrete semantics in terms of some category of spans. This is performed using
Lack's technique of composing props via distributive laws, as well as the
technique of pushout cubes of Zanasi. We do this for the fragment of the
ZX-calculus with only the black $\pi$-phase (and no Hadamard gate) as well as
well as the fragment which additionally has the and gate as a generator (which
is equivalent to the natural number H-box fragment of the ZH-calculus). In the
former case, we show that this is equivalent to the full subcategory of spans
of (possibly empty) free, finite dimensional affine $\mathbb F_2$-vector
spaces, where the objects are the non-empty affine vector spaces. In the latter
case, we show that this is equivalent to the full subcategory of spans of
finite sets where the objects are powers of the two element set. Because these
fragments of the ZX-calculus have semantics in terms of full subcategories of
categories of spans, they can not be presented by distributive laws over
groupoids. Instead, we first construct their subcategories of partial
isomorphisms via distributive laws over all isomorphims with subobjects
adjoined. After which, the full subcategory of spans are obtained by freely
adjoining units and counits the the semi-Frobenius structures given by the
diagonal and codiagonal maps.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:47:28 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 01:26:59 GMT""},{""version"":""v3"",""created"":""Sat, 13 Mar 2021 00:32:42 GMT""}]","2021-03-16"
"2102.04387","Fengying Li","Fengying Li, Bingying Li, Shiqing Zhang","A Generalized Mountain Pass Lemma with a Closed Subset for Locally
  Lipschitz Functionals","arXiv admin note: text overlap with arXiv:1405.6004",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  The classical Mountain Pass Lemma of Ambrosetti-Rabinowitz has been studied,
extended and modified in several directions. Notable examples would certainly
include the generalization to locally Lipschitz functionals by K.C. Chang,
analyzing the structure of the critical set in the mountain pass theorem in the
works of Hofer, Pucci-Serrin and Tian, and the extension by Ghoussoub-Preiss to
closed subsets in a Banach space with recent variations. In this paper, we
utilize the generalized gradient of Clarke and Ekeland's variatonal principle
to generalize the Ghoussoub-Preiss's Theorem in the setting of locally
Lipschitz functionals. We give an application to periodic solutions of
Hamiltonian systems.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:47:46 GMT""}]","2021-02-09"
"2102.04388","Petr Baklanov","A. A. Nikiforova, P. V. Baklanov, S. I. Blinnikov, D. A. Blinov, T. S.
  Grishina, Yu. V. Troitskaya, D. A. Morozova, E. N. Kopatskaya, E. G.
  Larionova, I. S. Troitsky","Parameters of the type-IIP supernova SN 2012aw","7 pages, 8 figures, 3 tables. Accepted for publication in MNRAS",,"10.1093/mnras/stab1093",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results the photometric observations of the Type IIP supernova
SN 2012aw obtained for the time interval from 7 till 371 days after the
explosion. Using the previously published values of the photospheric velocities
we've computed the hydrodynamic model which simultaneously reproduced the
photometry observations and velocity measurements. The model was calculated
with the multi-energy group radiation hydrodynamics code STELLA. We found the
parameters of the pre-supernova: radius $R = 500 R_\odot$, nickel mass
$M(^{56}$Ni$)$ $\sim 0.06 M_\odot$, pre-supernova mass $25 M_\odot$, mass of
ejected envelope $23.6 M_\odot$, explosion energy $E \sim 2 \times 10^{51}$
erg. The model progenitor mass $M=25 M_\odot$ significantly exceeds the upper
limit mass $M=17 M_\odot$, obtained from analysis the pre-SNe observations.
This result confirms once more that the 'Red Supergiant Problem' must be
resolved by stellar evolution and supernova explosion theories in interaction
with observations.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:49:38 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 08:21:17 GMT""}]","2021-04-28"
"2102.04389","Andrew Treglown","Andrea Freschi, Joseph Hyde, Andrew Treglown","On deficiency problems for graphs","12 pages, author accepted manuscript, to appear in Combinatorics,
  Probability and Computing",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by analogous questions in the setting of Steiner triple systems and
Latin squares, Nenadov, Sudakov and Wagner [Completion and deficiency problems,
Journal of Combinatorial Theory Series B, 2020] recently introduced the notion
of graph deficiency. Given a global spanning property $\mathcal P$ and a graph
$G$, the deficiency $\text{def}(G)$ of the graph $G$ with respect to the
property $\mathcal P$ is the smallest non-negative integer $t$ such that the
join $G*K_t$ has property $\mathcal P$. In particular, Nenadov, Sudakov and
Wagner raised the question of determining how many edges an $n$-vertex graph
$G$ needs to ensure $G*K_t$ contains a $K_r$-factor (for any fixed $r\geq 3$).
In this paper we resolve their problem fully. We also give an analogous result
which forces $G*K_t$ to contain any fixed bipartite $(n+t)$-vertex graph of
bounded degree and small bandwidth.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:49:42 GMT""},{""version"":""v2"",""created"":""Sun, 15 Aug 2021 08:06:21 GMT""}]","2021-08-17"
"2102.04390","Jahmall Matteo Bersini","Oleg Antipin, Jahmall Bersini, Francesco Sannino, Zhi-Wei Wang, Chen
  Zhang","Untangling scaling dimensions of fixed charge operators in Higgs
  Theories","36 pages, 3 figures","Phys. Rev. D 103, 125024 (2021)","10.1103/PhysRevD.103.125024","RBI-ThPhys-2021-8, CP3-Origins-2021-01 DNRF90","hep-th cond-mat.stat-mech hep-lat hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We go beyond a systematic review of the semiclassical approaches for
determining the scaling dimensions of fixed-charge operators in $U(1)$ and
$O(N)$ models by introducing a general strategy apt at determining the relation
between a given charge configuration and the associated operators for more
involved symmetry groups such as the $U(N) \times U(M)$. We show how, varying
the charge configuration, it is possible to access anomalous dimensions of
different operators transforming according to a variety of irreducible
representations of the non-abelian symmetry group without the aid of
diagrammatical computations. We illustrate our computational strategy by
determining the anomalous dimensions of several composite operators to the
next-to-leading order in the semiclassical expansion for the $U(N) \times U(M)$
conformal field theory (CFT) in $4-\epsilon$ dimensions. Thanks to the powerful
interplay between semiclassical methods and group theory we can, for the first
time, extract scaling dimensions for a wide range of operators.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:51:44 GMT""}]","2021-06-30"
"2102.04391","Lisa Piccirillo","Ciprian Manolescu, Lisa Piccirillo","From zero surgeries to candidates for exotic definite four-manifolds","30 pages, 23 figures, 1 table, supporting files found at
  http://web.stanford.edu/~cm5/RBG.html",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One strategy for distinguishing smooth structures on closed $4$-manifolds is
to produce a knot $K$ in $S^3$ that is slice in one smooth filling $W$ of $S^3$
but not slice in some homeomorphic smooth filling $W'$. In this paper we
explore how $0$-surgery homeomorphisms can be used to potentially construct
exotic pairs of this form. In order to systematically generate a plethora of
candidates for exotic pairs, we give a fully general construction of pairs of
knots with the same zero surgeries. By computer experimentation, we find $5$
topologically slice knots such that, if any of them were slice, we would obtain
an exotic four-sphere. We also investigate the possibility of constructing
exotic smooth structures on $\#^n \mathbb{C}P^2$ in a similar fashion.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:51:52 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 20:35:16 GMT""}]","2021-03-02"
"2102.04392","Ana Bel\'en Gri\~n\'on Mar\'in","Ana Bel\'en Gri\~n\'on-Mar\'in, Adur Pastor Yabar, Rebecca Centeno and
  H\'ector Socas-Navarro","Long-Term Evolution of Three Light Bridges Developed on the Same Sunspot",,"A&A 647, A148 (2021)","10.1051/0004-6361/202039847",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One important feature of sunspots is the presence of light bridges. These
structures are elongated and bright (as compared to the umbra) features that
seem to be related to the formation and evolution of sunspots. In this work, we
studied the long-term evolution and the stratification of different atmospheric
parameters of three light bridges formed in the same host sunspot by different
mechanisms. To accomplish this, we used data taken with the GREGOR Infrared
Spectrograph installed at the GREGOR telescope. These data were inverted to
infer the physical parameters of the atmosphere where the observed spectral
profiles were formed of the three light bridges. We find that, in general, the
behaviour of the three light bridges is typical of this kind of structure with
the magnetic field strength, inclination, and temperature values between the
values at the umbra and the penumbra. We also find that they are of a
significantly non-magnetic character (particularly at the axis of the light
bridges) as it is deduced from the filling factor. In addition, within the
common behaviour of the physical properties of light bridges, we observe that
each one exhibits a particular behaviour. Another interesting result is that
the light bridge cools down, the magnetic field decreases, and the magnetic
field lines get more inclined higher in the atmosphere. Finally, we studied the
magnetic and non-magnetic line-of-sight velocities of the light bridges. The
former shows that the magnetic component is at rest and, interestingly, its
variation with optical depth shows a bi-modal behaviour. For the line-of-sight
velocity of the non-magnetic component, we see that the core of the light
bridge is at rest or with shallow upflows and clear downflows sinking through
the edges.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:52:01 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 08:50:44 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 22:51:58 GMT""}]","2021-03-24"
"2102.04393","Yang Zheng","Yang Zheng and Yujie Tang and Na Li","Analysis of the Optimization Landscape of Linear Quadratic Gaussian
  (LQG) Control","72 pages; 9 figures; Y. Zheng and Y. Tang contributed to this work
  equally",,,,"math.OC cs.SY eess.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper revisits the classical Linear Quadratic Gaussian (LQG) control
from a modern optimization perspective. We analyze two aspects of the
optimization landscape of the LQG problem: 1) connectivity of the set of
stabilizing controllers $\mathcal{C}_n$; and 2) structure of stationary points.
It is known that similarity transformations do not change the input-output
behavior of a dynamical controller or LQG cost. This inherent symmetry by
similarity transformations makes the landscape of LQG very rich. We show that
1) the set of stabilizing controllers $\mathcal{C}_n$ has at most two
path-connected components and they are diffeomorphic under a mapping defined by
a similarity transformation; 2) there might exist many \emph{strictly
suboptimal stationary points} of the LQG cost function over $\mathcal{C}_n$ and
these stationary points are always \emph{non-minimal}; 3) all \emph{minimal}
stationary points are globally optimal and they are identical up to a
similarity transformation. These results shed some light on the performance
analysis of direct policy gradient methods for solving the LQG problem.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:53:34 GMT""}]","2021-02-09"
"2102.04394","Fabio Gonzalez","Fabio A. Gonz\'alez, Alejandro Gallego, Santiago Toledo-Cort\'es,
  Vladimir Vargas-Calder\'on","Learning with Density Matrices and Random Features","Paper reorganized, classification experimental results updated","Quantum Mach. Intell. 4, 23 (2022)","10.1007/s42484-022-00079-9",,"cs.LG cs.AI quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  A density matrix describes the statistical state of a quantum system. It is a
powerful formalism to represent both the quantum and classical uncertainty of
quantum systems and to express different statistical operations such as
measurement, system combination and expectations as linear algebra operations.
This paper explores how density matrices can be used as a building block to
build machine learning models exploiting their ability to straightforwardly
combine linear algebra and probability. One of the main results of the paper is
to show that density matrices coupled with random Fourier features could
approximate arbitrary probability distributions over $\mathbb{R}^n$. Based on
this finding the paper builds different models for density estimation,
classification and regression. These models are differentiable, so it is
possible to integrate them with other differentiable components, such as deep
learning architectures and to learn their parameters using gradient-based
optimization. In addition, the paper presents optimization-less training
strategies based on estimation and model averaging. The models are evaluated in
benchmark tasks and the results are reported and discussed.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:54:59 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 14:40:04 GMT""},{""version"":""v3"",""created"":""Tue, 21 Sep 2021 01:40:47 GMT""},{""version"":""v4"",""created"":""Tue, 9 Nov 2021 04:05:52 GMT""}]","2022-08-30"
"2102.04395","Bruno Rizzuti","B. F. Rizzuti and G. F. Vasconcelos Jr","5-Dimensional $SO(1, 4)$-Invariant Action as an Origin to the
  Magueijo-Smolin Doubly Special Relativity Proposal","14 pages, 1 figure","Physics Letters B, 2021","10.1016/j.physletb.2021.136334",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we discuss how the Magueijo-Smolin Doubly Special Relativity
proposal may obtained from a singular Lagrangian action. The deformed
energy-momentum dispersion relation rises as a particular gauge, whose
covariance imposes the non-linear Lorentz group action. Moreover, the
additional invariant scale is present from the beginning as a coupling constant
to a gauge auxiliary variable. The geometrical meaning of the gauge fixing
procedure and its connection to the free relativistic particle are also
described.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:55:11 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 01:23:48 GMT""}]","2021-05-05"
"2102.04396","Kiwon Lee","Courtney Paquette, Kiwon Lee, Fabian Pedregosa and Elliot Paquette","SGD in the Large: Average-case Analysis, Asymptotics, and Stepsize
  Criticality",,,,,"math.OC cs.LG math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new framework, inspired by random matrix theory, for analyzing
the dynamics of stochastic gradient descent (SGD) when both number of samples
and dimensions are large. This framework applies to any fixed stepsize and the
finite sum setting. Using this new framework, we show that the dynamics of SGD
on a least squares problem with random data become deterministic in the large
sample and dimensional limit. Furthermore, the limiting dynamics are governed
by a Volterra integral equation. This model predicts that SGD undergoes a phase
transition at an explicitly given critical stepsize that ultimately affects its
convergence rate, which we also verify experimentally. Finally, when input data
is isotropic, we provide explicit expressions for the dynamics and average-case
convergence rates (i.e., the complexity of an algorithm averaged over all
possible inputs). These rates show significant improvement over the worst-case
complexities.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:00:13 GMT""}]","2021-02-09"
"2102.04397","Marcel Nutz","Espen Bernton, Promit Ghosal, Marcel Nutz","Entropic Optimal Transport: Geometry and Large Deviations","Forthcoming in 'Duke Mathematical Journal'",,,,"math.OC math.FA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the convergence of entropically regularized optimal transport to
optimal transport. The main result is concerned with the convergence of the
associated optimizers and takes the form of a large deviations principle
quantifying the local exponential convergence rate as the regularization
parameter vanishes. The exact rate function is determined in a general setting
and linked to the Kantorovich potential of optimal transport. Our arguments are
based on the geometry of the optimizers and inspired by the use of $c$-cyclical
monotonicity in classical transport theory. The results can also be phrased in
terms of Schr\""odinger bridges.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:01:54 GMT""},{""version"":""v2"",""created"":""Sun, 23 Jan 2022 14:14:00 GMT""}]","2022-01-25"
"2102.04398","Sathish Kumar","A. Sathish Kumar, Prashant Kumar and P. Devaraj","Approximation of discontinuous functions by Kantorovich exponential
  sampling series",,,,,"math.FA cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The Kantorovich exponential sampling series at jump discontinuities of the
bounded measurable signal f has been analysed. A representation lemma for the
series is established and using this lemma certain approximation theorems for
discontinuous signals are proved. The degree of approximation in terms of
logarithmic modulus of smoothness for the series is studied. Further a linear
prediction of signals based on past sample values has been obtained. Some
numerical simulations are performed to validate the approximation of
discontinuous signals f by the sampling series.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:02:07 GMT""}]","2021-02-09"
"2102.04399","Augustine Mavor-Parker","Augustine N. Mavor-Parker, Kimberly A. Young, Caswell Barry, Lewis D.
  Griffin","Escaping Stochastic Traps with Aleatoric Mapping Agents","Previously Presented at the NeurIPS (2020) Biological and Artificial
  Reinforcement Learning Workshop",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Exploration in environments with sparse rewards is difficult for artificial
agents. Curiosity driven learning -- using feed-forward prediction errors as
intrinsic rewards -- has achieved some success in these scenarios, but fails
when faced with action-dependent noise sources. We present aleatoric mapping
agents (AMAs), a neuroscience inspired solution modeled on the cholinergic
system of the mammalian brain. AMAs aim to explicitly ascertain which dynamics
of the environment are unpredictable, regardless of whether those dynamics are
induced by the actions of the agent. This is achieved by generating separate
forward predictions for the mean and variance of future states and reducing
intrinsic rewards for those transitions with high aleatoric variance. We show
AMAs are able to effectively circumvent action-dependent stochastic traps that
immobilise conventional curiosity driven agents. The code for all experiments
presented in this paper is open sourced:
http://github.com/self-supervisor/Escaping-Stochastic-Traps-With-Aleatoric-Mapping-Agents.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:05:08 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 15:13:27 GMT""}]","2021-10-11"
"2102.04400","Vasudevan Lakshminarayanan","Hardit Singh, Simarjeet Saini, Vasudevan Lakshminarayanan","Rapid Classification of Glaucomatous Fundus Images","Submitted for publication in JOSA A: Optics and Image Science,
  currently under revision",,"10.1364/JOSAA.415395",,"eess.IV cs.CV cs.LG q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  We propose a new method for training convolutional neural networks which
integrates reinforcement learning along with supervised learning and use ti for
transfer learning for classification of glaucoma from colored fundus images.
The training method uses hill climbing techniques via two different climber
types, viz ""random movment"" and ""random detection"" integrated with supervised
learning model though stochastic gradient descent with momentum (SGDM) model.
The model was trained and tested using the Drishti GS and RIM-ONE-r2 datasets
having glaucomatous and normal fundus images. The performance metrics for
prediction was tested by transfer learning on five CNN architectures, namely
GoogLenet, DesnseNet-201, NASNet, VGG-19 and Inception-resnet-v2. A fivefold
classification was used for evaluating the perfroamnace and high sensitivities
while high maintaining high accuracies were achieved. Of the models tested, the
denseNet-201 architecture performed the best in terms of sensitivity and area
under the curve (AUC). This method of training allows transfer learning on
small datasets and can be applied for tele-ophthalmology applications including
training with local datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:06:25 GMT""}]","2021-05-19"
"2102.04401","Nikos Zarifis","Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis","The Optimality of Polynomial Regression for Agnostic Learning under
  Gaussian Marginals",,,,,"cs.LG cs.DS math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of agnostic learning under the Gaussian distribution. We
develop a method for finding hard families of examples for a wide class of
problems by using LP duality. For Boolean-valued concept classes, we show that
the $L^1$-regression algorithm is essentially best possible, and therefore that
the computational difficulty of agnostically learning a concept class is
closely related to the polynomial degree required to approximate any function
from the class in $L^1$-norm. Using this characterization along with additional
analytic tools, we obtain optimal SQ lower bounds for agnostically learning
linear threshold functions and the first non-trivial SQ lower bounds for
polynomial threshold functions and intersections of halfspaces. We also develop
an analogous theory for agnostically learning real-valued functions, and as an
application prove near-optimal SQ lower bounds for agnostically learning ReLUs
and sigmoids.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:06:32 GMT""}]","2021-02-09"
"2102.04402","Xueguang Lyu","Xueguang Lyu, Yuchen Xiao, Brett Daley, Christopher Amato","Contrasting Centralized and Decentralized Critics in Multi-Agent
  Reinforcement Learning",,"Proceedings of the 20th International Conference on Autonomous
  Agents and MultiAgent Systems (AAMAS). 2021",,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Centralized Training for Decentralized Execution, where agents are trained
offline using centralized information but execute in a decentralized manner
online, has gained popularity in the multi-agent reinforcement learning
community. In particular, actor-critic methods with a centralized critic and
decentralized actors are a common instance of this idea. However, the
implications of using a centralized critic in this context are not fully
discussed and understood even though it is the standard choice of many
algorithms. We therefore formally analyze centralized and decentralized critic
approaches, providing a deeper understanding of the implications of critic
choice. Because our theory makes unrealistic assumptions, we also empirically
compare the centralized and decentralized critic methods over a wide set of
environments to validate our theories and to provide practical advice. We show
that there exist misconceptions regarding centralized critics in the current
literature and show that the centralized critic design is not strictly
beneficial, but rather both centralized and decentralized critics have
different pros and cons that should be taken into account by algorithm
designers.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:08:11 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 21:33:13 GMT""}]","2021-12-06"
"2102.04403","Andrew Nelson","A. O. Nelson, F. M. Laggner, A. Diallo, Z. A. Xing, D. R. Smith, E.
  Kolemen","Perturbative Determination of Plasma Microinstabilities in Tokamaks","8 pages, 5 figures",,,,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, theoretical analysis has identified plasma microinstabilities as
the primary mechanism responsible for anomalous heat transport in tokamaks. In
particular, the microtearing mode (MTM) has been credited with the production
of intense electron heat fluxes, most notably through a thin self-organized
boundary layer called the pedestal. Here we exploit a novel, time-dependent
analysis to compile explicit experimental evidence that MTMs are active in the
pedestal region. The expected frequency of pedestal MTMs, calculated as a
function of time from plasma profile measurements, is shown in a dedicated
experiment to be in excellent agreement with observed magnetic turbulence
fluctuations. Further, fast perturbations of the plasma equilibrium are
introduced to decouple the instability drive and resonant location, providing a
compelling validation of the analytical model. This analysis offers strong
evidence of edge MTMs, validating the existing theoretical work and
highlighting the important role of MTMs in regulating electron heat flow in
tokamaks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:08:38 GMT""}]","2021-02-09"
"2102.04404","Vincent Humiliere","Dan Cristofaro-Gardiner, Vincent Humili\`ere, Sobhan Seyfaddini","PFH spectral invariants on the two-sphere and the large scale geometry
  of Hofer's metric","v2: new result on area preserving diffeomorphisms of the open disc
  added. v3: minor corrections, this version to appear in JEMS",,,,"math.SG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We resolve three longstanding questions related to the large scale geometry
of the group of Hamiltonian diffeomorphisms of the two-sphere, equipped with
Hofer's metric. Namely: (1) we resolve the Kapovich-Polterovich question by
showing that this group is not quasi-isometric to the real line; (2) more
generally, we show that the kernel of Calabi over any proper open subset is
unbounded; and (3) we show that the group of area and orientation preserving
homeomorphisms of the two-sphere is not a simple group. We also obtain, as a
corollary, that the group of area-preserving diffeomorphisms of the open disc,
equipped with an area-form of finite area, is not perfect. Central to all of
our proofs are new sequences of spectral invariants over the two-sphere,
defined via periodic Floer homology.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:09:12 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 20:59:16 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 21:48:43 GMT""}]","2021-12-07"
"2102.04405","Fei Hu","Fei Hu and Tuyen Trung Truong","A dynamical approach to generalized Weil's Riemann hypothesis and
  semisimplicity","36 pages; Title changed; this article is extracted from the last
  longer version with a focus on Conjecture $G_r$, the norm comparison
  conjecture, and the dynamical degree comparison conjecture; new results on
  generalized semisimplicity (for polarized endomorphisms) added; comments very
  welcome!",,,,"math.AG math.DS math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a smooth projective variety over an algebraically closed field of
arbitrary characteristic, and $f$ a dynamical correspondence of $X$. In 2016,
the second author conjectured that the dynamical degrees of $f$ defined by the
pullback actions on \'etale cohomology groups and on numerical cycle class
groups are equivalent, which we call the dynamical degree comparison (DDC)
conjecture. It contains the generalized Weil's Riemann hypothesis (for
polarized endomorphisms) as a special case.
  To proceed, we introduce the so-called Conjecture $G_r$, which is a
quantitative strengthening of the standard conjecture $C$ and holds on abelian
varieties and Kummer surfaces. We prove that for arbitrary varieties,
Conjecture $G_r$ yields the generalized Weil's Riemann hypothesis. Moreover,
Conjecture $G_r$ plus the standard conjecture $D$ imply the so-called norm
comparison (NC) conjecture, whose consequences include the DDC conjecture and
the generalized semisimplicity conjecture (for polarized endomorphisms). As an
application, we obtain new results on the DDC conjecture for abelian varieties
and Kummer surfaces, and the generalized semisimplicity conjecture for Kummer
surfaces. Finally, we also obtain a similar comparison result for effective
finite correspondences of abelian varieties.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:09:33 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 13:21:03 GMT""},{""version"":""v3"",""created"":""Tue, 30 Nov 2021 00:05:30 GMT""}]","2021-12-01"
"2102.04406","Ninad Gaikwad","Ninad Gaikwad, Naren Srivaths Raman, Prabir Barooah","Increasing Energy Resiliency to Hurricanes with Battery and Rooftop
  Solar Through Intelligent Control","9 pages, 9 figures. arXiv admin note: substantial text overlap with
  arXiv:2003.05570",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rooftop solar photovoltaic (PV) panels together with batteries can provide
resiliency to blackouts during natural disasters such as hurricanes. Without
intelligent and automated decision making that can trade off conflicting
requirements, a large PV system and a large battery is needed to provide
meaningful resiliency. By utilizing the flexibility of various household
demands, an intelligent system can ensure that critical loads are serviced
longer than a non-intelligent system. As a result a smaller (and thus lower
cost) system can provide the same energy resilience that a much larger system
will be needed otherwise.
  In this paper we propose such an intelligent control system that uses a model
predictive control (MPC) architecture. The optimization problem is formulated
as a MILP (mixed integer linear program) due to the on/off decisions for the
loads. Performance is compared with two rule based controllers, a simple
all-or-none controller that mimics what is available now commercially, and a
Rule-Based controller that uses the same information that the MPC controller
uses. The controllers are tested through simulation on a PV-battery system
chosen carefully for a small single family house in Florida. Simulations are
conducted for a one week period during hurricane Irma in 2017. Simulations show
that the size of the PV+battery system to provide a certain resiliency
performance can be halved by the proposed control system.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:12:36 GMT""}]","2021-02-09"
"2102.04407","Pramod Sangi Reddy","Amin Reihani, Shen Yan, Yuxuan Luan, Rohith Mittapally, Edgar
  Meyhofer, Pramod Reddy","Quantifying the Temperature of Heated Microdevices Using Scanning
  Thermal Probes","Manuscript submitted to Applied Physics Letters",,"10.1063/5.0046789",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantifying the temperature of microdevices is critical for probing nanoscale
energy transport.Such quantification is often accomplished by integrating
resistance thermometers into microdevices. However, such thermometers
frequently become structurally unstable and fail due to thermal stresses at
elevated temperatures. Here, we show that custom-fabricated scanning thermal
probes (STPs) with a sharp tip and an integrated heater/thermometer can
accurately measure the temperature of microdevices held at elevated
temperatures. This measurement is accomplished by introducing a modulated heat
input to the STP after contacting the microdevice with the STP's tip, and
characterizing the DC and AC components of the STP's temperature.From these
measured temperature components, the tip-to-sample thermal resistance and the
microdevice surface temperature are deduced via a simple lumped-capacitance
model. The advances presented here can greatly facilitate temperature
measurements of a variety of heated microdevices.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:14:27 GMT""}]","2021-05-05"
"2102.04408","Hernan Calvo","Federico D. Ribetto, Ra\'ul A. Bustos-Mar\'un, Hernan L. Calvo","Role of coherence in quantum-dot-based nanomachines within the Coulomb
  blockade regime","18 pages, 7 figures","Phys. Rev. B 103, 155435 (2021)","10.1103/PhysRevB.103.155435",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the last decades, quantum dots within the Coulomb blockade regime of
transport have been proposed as essential building blocks for a wide variety of
nanomachines. This includes thermoelectric devices, quantum shuttles, quantum
pumps, and even quantum motors. However, in this regime, the role of quantum
mechanics is commonly limited to provide energy quantization while the working
principle of the devices is ultimately the same as their classic counterparts.
Here, we study quantum-dot-based nanomachines in the Coulomb blockade regime,
but in a configuration where the coherent superpositions of the dots' states
plays a crucial role. We show that the studied system can be used as the basis
for different forms of ""true"" quantum machines that should only work in the
presence of these coherent superpositions. We analyze the efficiency of these
machines against different nonequilibrium sources (bias voltage, temperature
gradient, and external driving) and the factors that limit it, including
decoherence and the role of the different orders appearing in the adiabatic
expansion of the charge/heat currents.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:15:03 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 20:28:08 GMT""}]","2021-05-03"
"2102.04409","Dennis Bonatsos","Andriana Martinou, Dennis Bonatsos, K.E. Karakatsanis, S.
  Sarantopoulou, I.E. Assimakis, S.K. Peroulis, and N. Minkov","Why nuclear forces favor the highest weight irreducible representations
  of the fermionic SU(3) symmetry","16 pages, 1 figure, 10 tables","Eur. Phys. J A 57 (2021) 83","10.1140/epja/s10050-021-00395-x",,"nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The consequences of the attractive, short-range nucleon-nucleon (NN)
interaction on the wave functions of the Elliott SU(3) and the proxy-SU(3)
symmetry are discussed. The NN interaction favors the most symmetric spatial
SU(3) irreducible representation, which corresponds to the maximal spatial
overlap among the fermions. The percentage of the symmetric components out of
the total in an SU(3) wave function is introduced, through which it is found,
that no SU(3) irrep is more symmetric than the highest weight irrep for a
certain number of valence particles in a three dimensional, isotropic, harmonic
oscillator shell. The consideration of the highest weight irreps in nuclei and
in alkali metal clusters, leads to the prediction of a prolate to oblate shape
transition beyond the mid-shell region.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:15:05 GMT""}]","2021-03-09"
"2102.04410","Valeriano Aiello","Valeriano Aiello, Stefano Rossi","On the entropy and index of the winding endomorphisms of p-adic ring
  C$^*$-algebras",,"Studia Mathematica 262 (3) (2022), 305-326","10.4064/sm201125-9-2",,"math.OA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $p\geq 2$, the $p$-adic ring $C^*$-algebra $\mathcal{Q}_p$ is the
universal $C^*$-algebra generated by a unitary $U$ and an isometry $S_p$ such
that $S_pU=U^pS_p$ and $\sum_{l=0}^{p-1}U^lS_pS_p^*U^{-l}=1$. For any $k$
coprime with $p$ we define an endomorphism $\chi_k\in{\rm End}(\mathcal{Q}_p)$
by setting $\chi_k(U):=U^k$ and $\chi_k(S_p):=S_p$. We then compute the entropy
of $\chi_k$, which turns out to be $\log |k|$. Finally, for selected values of
$k$ we also compute the Watatani index of $\chi_k$ showing that the entropy is
the natural logarithm of the index.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:17:44 GMT""},{""version"":""v2"",""created"":""Thu, 23 Dec 2021 22:01:17 GMT""}]","2021-12-28"
"2102.04411","Jinfeng Lin","Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, Jane Cleland-Huang","Traceability Transformed: Generating more Accurate Links with
  Pre-Trained BERT Models",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Software traceability establishes and leverages associations between diverse
development artifacts. Researchers have proposed the use of deep learning trace
models to link natural language artifacts, such as requirements and issue
descriptions, to source code; however, their effectiveness has been restricted
by availability of labeled data and efficiency at runtime. In this study, we
propose a novel framework called Trace BERT (T-BERT) to generate trace links
between source code and natural language artifacts. To address data sparsity,
we leverage a three-step training strategy to enable trace models to transfer
knowledge from a closely related Software Engineering challenge, which has a
rich dataset, to produce trace links with much higher accuracy than has
previously been achieved. We then apply the T-BERT framework to recover links
between issues and commits in Open Source Projects. We comparatively evaluated
accuracy and efficiency of three BERT architectures. Results show that a
Single-BERT architecture generated the most accurate links, while a
Siamese-BERT architecture produced comparable results with significantly less
execution time. Furthermore, by learning and transferring knowledge, all three
models in the framework outperform classical IR trace models. On the three
evaluated real-word OSS projects, the best T-BERT stably outperformed the VSM
model with average improvements of 60.31% measured using Mean Average Precision
(MAP). RNN severely underperformed on these projects due to insufficient
training data, while T-BERT overcame this problem by using pretrained language
models and transfer learning.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:18:07 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 20:43:18 GMT""}]","2021-02-24"
"2102.04412","Ryan Pfeifle","Ryan W. Pfeifle, Claudio Ricci, Peter G. Boorman, Marko Stalevski,
  Daniel Asmus, Benny Trakhtenbrot, Michael J. Koss, Daniel Stern, Federica
  Ricci, Shobita Satyapal, Kohei Ichikawa, David J. Rosario, Turgay Caglar,
  Ezequiel Treister, Meredith Powell, Kyuseok Oh, C. Megan Urry, and Fiona
  Harrison","BAT AGN Spectroscopic Survey-XXIII. A New Mid-Infrared Diagnostic for
  Absorption in Active Galactic Nuclei","28 pages: 1-19 main text, 20-28 appendix and references. 15 figures.
  Accepted for publication in ApJS; part of BASS DR2 special issue",,"10.3847/1538-4365/ac5b65",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  In this study, we use the SWIFT/BAT AGN sample, which has received extensive
multiwavelength follow-up analysis as a result of the BAT AGN Spectroscopic
Survey (BASS), to develop a diagnostic for nuclear obscuration by examining the
relationship between the line-of-sight column densities ($N_{\rm{H}}$), the
2-10 keV-to-$12\,\rm{\mu m}$ luminosity ratio, and WISE mid-infrared colors. We
demonstrate that heavily obscured AGNs tend to exhibit both preferentially
''redder'' mid-infrared colors and lower values of
$L_{\rm{X,\,Obs.}}$/$L_{12\,\rm{\mu m}}$ than less obscured AGNs, and we derive
expressions relating $N_{\rm{H}}$ to the $L_{\rm{X,\,Obs.}}$/$L_{12\,\rm{\mu
m}}$ and $L_{22\,\rm{\mu m}}$/$L_{4.6\,\rm{\mu m}}$ luminosity ratios as well
as develop diagnostic criteria using these ratios. Our diagnostic regions yield
samples that are $\gtrsim80$% complete and $\gtrsim60$% pure for AGNs with
log($N_{\rm{H}})\geq24$, as well as $\gtrsim85$% pure for AGNs with
$\rm{log}(N_{\rm{H}})\gtrsim23.5$. We find that these diagnostics cannot be
used to differentiate between optically star forming galaxies and active
galaxies. Further, mid-IR contributions from host galaxies that dominate the
observed $12~\rm{\mu m}$ emission can lead to larger apparent X-ray deficits
and redder mid-IR colors than the AGNs would intrinsically exhibit, though this
effect helps to better separate less obscured and more obscured AGNs. Finally,
we test our diagnostics on two catalogs of AGNs and infrared galaxies,
including the XMM-Newton XXL-N field, and we identify several known
Compton-thick AGNs as well as a handful of candidate heavily obscured AGNs
based upon our proposed obscuration diagnostics.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:18:23 GMT""}]","2022-07-27"
"2102.04413","Wuchen Li","Wuchen Li","Transport information Hessian distances",,,,,"math.MG cs.IT math.DS math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate closed-form Hessian distances of information entropies in
one-dimensional probability density space embedded with the L2-Wasserstein
metric.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:18:59 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 16:33:44 GMT""}]","2021-02-23"
"2102.04414","Ajit C. Balram","Ajit C. Balram","Abelian parton state for the $\nu=4/11$ fractional quantum Hall effect","7 pages and 1 figure, published version","Phys. Rev. B 103, 155103 (2021)","10.1103/PhysRevB.103.155103",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the fractional quantum Hall effect at the filling factor
$\nu=4/11$, where two independent experiments have observed a well-developed
and quantized Hall plateau. We examine the Abelian state described by the
""$4\bar{2}1^{3}$"" parton wave function and numerically demonstrate it to be a
plausible candidate for the ground state at $\nu=4/11$. We work out the
low-energy effective theory of the $4\bar{2}1^{3}$ edge and make predictions
for experimentally measurable properties of the state.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:21:04 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 14:51:35 GMT""}]","2021-04-02"
"2102.04415","Angelica Osorno","Evan E. Franchere, Kyle Ormsby, Ang\'elica M Osorno, Weihang Qin,
  Riley Waugh","Self-duality of the lattice of transfer systems via weak factorization
  systems","19 pages. To appear in Homology, Homotopy, and Applications",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  For a finite group $G$, $G$-transfer systems are combinatorial objects which
encode the homotopy category of $G$-$N_\infty$ operads, whose algebras in
$G$-spectra are $E_\infty$ $G$-spectra with a specified collection of
multiplicative norms. For $G$ finite Abelian, we demonstrate a correspondence
between $G$-transfer systems and weak factorization systems on the poset
category of subgroups of $G$. This induces a self-duality on the lattice of
$G$-transfer systems.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:21:37 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 16:35:19 GMT""}]","2021-06-22"
"2102.04416","Luis MacDowell G.","Juan Luengo-M\'arquez and Luis G. MacDowell","Lifshitz theory of wetting films at three phase coexistence: The case of
  ice nucleation on Silver Iodide (AgI)","Accepted Manuscript","Journal of Colloid and Interface Science, 590, 527-538 (2021)","10.1016/j.jcis.2021.01.060",,"physics.chem-ph cond-mat.mtrl-sci cond-mat.soft cond-mat.stat-mech physics.ao-ph physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hypothesis: As a fluid approaches three phase coexistence, adsorption may
take place by the successive formation of two intervening wetting films. The
equilibrium thickness of these wetting layers is the result of a delicate
balance of intermolecular forces, as dictated by an underlying interface
potential. The van der Waals forces for the two variable adsorption layers may
be formulated exactly from Dzyaloshinskii-Lifshitz-Pitaevskii theory, and
analytical approximations may be derived that extent well beyond the validity
of conventional Hamaker theory.
  Calculations: We consider the adsorption equilibrium of water vapor on Silver
Iodide where both ice and a water layers can form simultaneously and compete
for the vapor as the triple point is approached. We perform numerical
calculations of Lifshitz theory for this complex system and work out analytical
approximations which provide quantitative agreement with the numerical results.
  Findings: At the three phase contact line between AgI/water/air, surface
forces promote growth of ice both on the AgI/air and the water/vapor
interfaces, lending support to a contact nucleation mode of AgI in the
atmosphere. Our approach provides a framework for the description of adsorption
at three phase coexistence, and allows for the study of ice nucleation
efficiency on atmospheric aerosols.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:22:51 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 23:12:35 GMT""}]","2021-03-11"
"2102.04417","Clare Spinner","Patrick Chan, Katherine Johnston, Anne Shiu, Aleksandra Sobieska,
  Clare Spinner","Identifiability of Linear Compartmental Models: The Impact of Removing
  Leaks and Edges","15 pages, 6 figures. Updated paper in light of conjecture now solved",,,,"math.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A mathematical model is identifiable if its parameters can be recovered from
data. Here, we focus on a particular class of model, linear compartmental
models, which are used to represent the transfer of substances in a system. We
analyze what happens to identifiability when operations are performed on a
model, specifically, adding or deleting a leak or an edge. We first consider
the conjecture of Gross et al. that states that removing a leak from an
identifiable model yields a model that is again identifiable. We prove a
special case of this conjecture, and also show that the conjecture is
equivalent to asserting that leak terms do not divide the so-called
singular-locus equation. As for edge terms that do divide this equation, we
conjecture that removing any one of these edges makes the model become
unidentifiable,and then prove a case of this somewhat surprising conjecture.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:24:20 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 17:02:26 GMT""}]","2021-06-22"
"2102.04418","Nino Ba\v{s}i\'c","Nino Ba\v{s}i\'c and Martin Knor and Riste \v{S}krekovski","On $12$-regular nut graphs","12 pages, 20 references",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A nut graph is a simple graph whose adjacency matrix is singular with
$1$-dimensional kernel such that the corresponding eigenvector has no zero
entries. In 2020, Fowler et al. characterised for each $d \in
\{3,4,\ldots,11\}$ all values $n$ such that there exists a $d$-regular nut
graph of order $n$. In the present paper, we determine all values $n$ for which
a $12$-regular nut graph of order $n$ exists. We also present a result by which
there are infinitely many circulant nut graphs of degree $d \equiv 0 \pmod 4$
and no circulant nut graph of degree $d \equiv 2 \pmod 4$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:26:14 GMT""}]","2021-02-09"
"2102.04419","Ali Lafzi","Ali Lafzi, Miad Boodaghi, Siavash Zamani, Niyousha Mohammadshafie, and
  Veeraraghava Raju Hasti","Analysis of the Effectiveness of Face-Coverings on the Death Ratio of
  COVID-19 Using Machine Learning",,"Lafzi, A., Boodaghi, M., Zamani, S. et al. Analysis of the
  effectiveness of face-coverings on the death ratio of COVID-19 using machine
  learning. Sci Rep 11, 21675 (2021)","10.1038/s41598-021-01005-y",,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  The recent outbreak of the COVID-19 led to the death of millions of people
worldwide. To stave off the spread of the virus, the authorities in the US
employed different strategies, including the mask mandate order issued by the
states' governors. In the current work, we defined a parameter called the
average death ratio as the monthly average of the number of daily deaths to the
monthly average number of daily cases. We utilized survey data to quantify
people's abidance by the mask mandate order. Additionally, we implicitly
addressed the extent to which people abide by the mask mandate order that may
depend on some parameters like population, income, and education level. Using
different machine learning classification algorithms, we investigated how the
decrease or increase in death ratio for the counties in the US West Coast
correlates with the input parameters. The results showed that for most counties
there, the mask mandate order decreased the death ratio reflecting the
effectiveness of this preventive measure on the West Coast. Additionally, the
changes in the death ratio demonstrated a noticeable correlation with the
socio-economic condition of each county. Moreover, the results showed a
promising classification accuracy score as high as around 90%.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:26:30 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 00:34:55 GMT""}]","2021-11-09"
"2102.04420","Adam Van Etten","Adam Van Etten, Daniel Hogan, Jesus Martinez-Manso, Jacob Shermeyer,
  Nicholas Weir, Ryan Lewis","The Multi-Temporal Urban Development SpaceNet Dataset","8 pages, 10 figures, 3 tables",,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Satellite imagery analytics have numerous human development and disaster
response applications, particularly when time series methods are involved. For
example, quantifying population statistics is fundamental to 67 of the 231
United Nations Sustainable Development Goals Indicators, but the World Bank
estimates that over 100 countries currently lack effective Civil Registration
systems. To help address this deficit and develop novel computer vision methods
for time series data, we present the Multi-Temporal Urban Development SpaceNet
(MUDS, also known as SpaceNet 7) dataset. This open source dataset consists of
medium resolution (4.0m) satellite imagery mosaics, which includes 24 images
(one per month) covering >100 unique geographies, and comprises >40,000 km2 of
imagery and exhaustive polygon labels of building footprints therein, totaling
over 11M individual annotations. Each building is assigned a unique identifier
(i.e. address), which permits tracking of individual objects over time. Label
fidelity exceeds image resolution; this ""omniscient labeling"" is a unique
feature of the dataset, and enables surprisingly precise algorithmic models to
be crafted. We demonstrate methods to track building footprint construction (or
demolition) over time, thereby directly assessing urbanization. Performance is
measured with the newly developed SpaceNet Change and Object Tracking (SCOT)
metric, which quantifies both object tracking as well as change detection. We
demonstrate that despite the moderate resolution of the data, we are able to
track individual building identifiers over time. This task has broad
implications for disaster preparedness, the environment, infrastructure
development, and epidemic prevention.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:28:52 GMT""}]","2021-02-09"
"2102.04421","Younous Mofenjou Peuriekeu","Younous Mofenjou Peuriekeu, Victoire Djimna Noyum, Cyrille Feudjio,
  Alkan Goktug and Ernest Fokoue","A Text Mining Discovery of Similarities and Dissimilarities Among Sacred
  Scriptures",,,,,"stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The careful examination of sacred texts gives valuable insights into human
psychology, different ideas regarding the organization of societies as well as
into terms like truth and God. To improve and deepen our understanding of
sacred texts, their comparison, and their separation is crucial. For this
purpose, we use our data set has nine sacred scriptures. This work deals with
the separation of the Quran, the Asian scriptures Tao-Te-Ching, the Buddhism,
the Yogasutras, and the Upanishads as well as the four books from the Bible,
namely the Book of Proverbs, the Book of Ecclesiastes, the Book of
Ecclesiasticus, and the Book of Wisdom. These scriptures are analyzed based on
the natural language processing NLP creating the mathematical representation of
the corpus in terms of frequencies called document term matrix (DTM). After
this analysis, machine learning methods like supervised and unsupervised
learning are applied to perform classification. Here we use the Multinomial
Naive Bayes (MNB), the Super Vector Machine (SVM), the Random Forest (RF), and
the K-nearest Neighbors (KNN). We obtain that among these methods MNB is able
to predict the class of a sacred text with an accuracy of about 85.84 %.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:32:50 GMT""}]","2021-02-09"
"2102.04422","Ahmed Bou-Rabee","Ahmed Bou-Rabee","A shape theorem for exploding sandpiles","31 pages, 5 figures, 1 table; some minor revisions",,,,"math.PR math.AP math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study scaling limits of exploding Abelian sandpiles using ideas from
percolation and front propagation in random media. We establish sufficient
conditions under which a limit shape exists and show via a family of
counterexamples that convergence may not occur in general. A corollary of our
proof is a simple criteria for determining if a sandpile is explosive; this
strengthens a result of Fey, Levine, and Peres (2010).
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:34:45 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 01:51:40 GMT""}]","2023-05-03"
"2102.04423","Colin Fogarty","Colin B. Fogarty","Prepivoted permutation tests",,,,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general approach to constructing permutation tests that are both
exact for the null hypothesis of equality of distributions and asymptotically
correct for testing equality of parameters of distributions while allowing the
distributions themselves to differ. These robust permutation tests transform a
given test statistic by a consistent estimator of its limiting distribution
function before enumerating its permutation distribution. This transformation,
known as prepivoting, aligns the unconditional limiting distribution for the
test statistic with the probability limit of its permutation distribution.
Through prepivoting, the tests permute one minus an asymptotically valid
$p$-value for testing the null of equality of parameters. We describe two
approaches for prepivoting within permutation tests, one directly using
asymptotic normality and the other using the bootstrap. We further illustrate
that permutation tests using bootstrap prepivoting can provide improvements to
the order of the error in rejection probability relative to competing
transformations when testing equality of parameters, while maintaining
exactness under equality of distributions. Simulation studies highlight the
versatility of the proposal, illustrating the restoration of asymptotic
validity to a wide range of permutation tests conducted when only the
parameters of distributions are equal.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:35:08 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 19:29:28 GMT""}]","2021-07-12"
"2102.04424","Paolo Valtancoli","P. Valtancoli","On the area of the sphere in a Snyder geometry","7 pages, no figures",,,,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We compute the area of a generic d-sphere in a Snyder geometry.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:36:02 GMT""}]","2021-02-09"
"2102.04425","Habib Rostami","Habib Rostami, Mikhail I. Katsnelson, Giovanni Vignale and Marco
  Polini","Gauge invariance and Ward identities in nonlinear response theory","44 pages, 5 figures",,"10.1016/j.aop.2021.168523",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a formal analysis of nonlinear response functions in terms of
correlation functions in real- and imaginary-time domains. In particular, we
show that causal nonlinear response functions, expressed in terms of nested
commutators in real time, can be obtained from the analytic continuation of
time-ordered response functions, which are more easily amenable to diagrammatic
calculation. This generalizes the well-known result of linear response theory.
We then use gauge invariance arguments to derive exact relations between
second-order response functions in density and current channels. These
identities, which are non-perturbative in the strength of inter-particle
interactions, allow us to establish exact connections between nonlinear optics
calculations done in different electromagnetic gauges.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:36:21 GMT""}]","2021-07-07"
"2102.04426","Ryan Strauss","Ryan R. Strauss, Junier B. Oliva","Arbitrary Conditional Distributions with Energy","Accepted at NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modeling distributions of covariates, or density estimation, is a core
challenge in unsupervised learning. However, the majority of work only
considers the joint distribution, which has limited utility in practical
situations. A more general and useful problem is arbitrary conditional density
estimation, which aims to model any possible conditional distribution over a
set of covariates, reflecting the more realistic setting of inference based on
prior knowledge. We propose a novel method, Arbitrary Conditioning with Energy
(ACE), that can simultaneously estimate the distribution $p(\mathbf{x}_u \mid
\mathbf{x}_o)$ for all possible subsets of unobserved features $\mathbf{x}_u$
and observed features $\mathbf{x}_o$. ACE is designed to avoid unnecessary bias
and complexity -- we specify densities with a highly expressive energy function
and reduce the problem to only learning one-dimensional conditionals (from
which more complex distributions can be recovered during inference). This
results in an approach that is both simpler and higher-performing than prior
methods. We show that ACE achieves state-of-the-art for arbitrary conditional
likelihood estimation and data imputation on standard benchmarks.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:36:26 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 14:01:36 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 19:16:49 GMT""}]","2021-10-28"
"2102.04427","Austin Wright","Austin P Wright, Omar Shaikh, Haekyu Park, Will Epperson, Muhammed
  Ahmed, Stephane Pinel, Duen Horng Chau, Diyi Yang","RECAST: Enabling User Recourse and Interpretability of Toxicity
  Detection Models with Interactive Visualization","26 pages, 5 figures, CSCW '21",,"10.1145/3449280",,"cs.HC cs.CL cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the widespread use of toxic language online, platforms are increasingly
using automated systems that leverage advances in natural language processing
to automatically flag and remove toxic comments. However, most automated
systems -- when detecting and moderating toxic language -- do not provide
feedback to their users, let alone provide an avenue of recourse for these
users to make actionable changes. We present our work, RECAST, an interactive,
open-sourced web tool for visualizing these models' toxic predictions, while
providing alternative suggestions for flagged toxic language. Our work also
provides users with a new path of recourse when using these automated
moderation tools. RECAST highlights text responsible for classifying toxicity,
and allows users to interactively substitute potentially toxic phrases with
neutral alternatives. We examined the effect of RECAST via two large-scale user
evaluations, and found that RECAST was highly effective at helping users reduce
toxicity as detected through the model. Users also gained a stronger
understanding of the underlying toxicity criterion used by black-box models,
enabling transparency and recourse. In addition, we found that when users focus
on optimizing language for these models instead of their own judgement (which
is the implied incentive and goal of deploying automated models), these models
cease to be effective classifiers of toxicity compared to human annotations.
This opens a discussion for how toxicity detection models work and should work,
and their effect on the future of online discourse.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:37:50 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 14:42:17 GMT""}]","2021-02-11"
"2102.04428","Christopher Duffy","C. Duffy, G. Ramsay, D. Steeghs, V. Dhillon, Mark R. Kennedy, D. Mata
  S\'anchez, K. Ackley, M. Dyer, J. Lyman, K. Ulaczyk, D. K. Galloway, P.
  O'Brien, K. Noysena, L. Nuttall, D. Pollacco","Evidence that short period AM CVn systems are diverse in outburst
  behaviour","11 Pages, 7 Figures, 2 Tables. Accepted for publication in MNRAS.
  Author's final submitted version",,"10.1093/mnras/stab389",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present results of our analysis of up to 15 years of photometric data from
eight AM CVn systems with orbital periods between 22.5 and 26.8 min. Our data
has been collected from the GOTO, ZTF, Pan-STARRS, ASAS-SN and Catalina all-sky
surveys and amateur observations collated by the AAVSO. We find evidence that
these interacting ultra-compact binaries show a similar diversity of long term
optical properties as the hydrogen accreting dwarf novae. We found that AM CVn
systems in the previously identified accretion disc instability region are not
a homogenous group. Various members of the analysed sample exhibit behaviour
reminiscent of Z Cam systems with long super outbursts and standstills, SU UMa
systems with regular, shorter super outbursts, and nova-like systems which
appear only in a high state. The addition of TESS full frame images of one of
these systems, KL Dra, reveals the first evidence for normal outbursts
appearing as a precursor to super outbursts in an AM CVn system. Our results
will inform theoretical modelling of the outbursts of hydrogen deficient
systems.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:38:14 GMT""}]","2021-02-17"
"2102.04429","Xiaodong Cui","Xiaodong Cui, Songtao Lu and Brian Kingsbury","Federated Acoustic Modeling For Automatic Speech Recognition","Accepted by ICASSP 2021",,,,"cs.SD cs.DC eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data privacy and protection is a crucial issue for any automatic speech
recognition (ASR) service provider when dealing with clients. In this paper, we
investigate federated acoustic modeling using data from multiple clients. A
client's data is stored on a local data server and the clients communicate only
model parameters with a central server, and not their data. The communication
happens infrequently to reduce the communication cost. To mitigate the non-iid
issue, client adaptive federated training (CAFT) is proposed to canonicalize
data across clients. The experiments are carried out on 1,150 hours of speech
data from multiple domains. Hybrid LSTM acoustic models are trained via
federated learning and their performance is compared to traditional centralized
acoustic model training. The experimental results demonstrate the effectiveness
of the proposed federated acoustic modeling strategy. We also show that CAFT
can further improve the performance of the federated acoustic model.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:39:36 GMT""}]","2021-02-09"
"2102.04430","Mohammad Reza Ghoreyshi","Mohammad R. Ghoreyshi, Alex C. Carciofi, Carol E. Jones, Daniel M.
  Faes, Dietrich Baade, Thomas Rivinius","A Multi-observing-technique Study of the Dynamical Evolution of the
  Viscous Disk around the Be Star $\omega$ CMa","25 pages, 19 figures",,"10.3847/1538-4357/abdd1e",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The observed emission lines of Be stars originate from a circumstellar
Keplerian disk that are generally well explained by the Viscous Decretion Disk
model. In an earlier work we performed the modeling of the full light curve of
the bright Be star $\omega$ CMa (Ghoreyshi et al. 2018) with the 1-D
time-dependent hydrodynamics code SINGLEBE and the Monte Carlo
radiative-transfer code HDUST.
  We used the V -band light curve that probes the inner disk through four disk
formation and dissipation cycles. This new study compares predictions of the
same set of model parameters with time-resolved photometry from the near UV
through the mid-infrared, comprehensive series of optical spectra, and optical
broad-band polarimetry, that overall represent a larger volume of the disk.
Qualitatively, the models reproduce the trends in the observed data due to the
growth and decay of the disk. However, quantitative differences exist, e.g., an
overprediction of the flux increasing with wavelength, too slow decreases in
Balmer emission-line strength that are too slow during disk dissipation, and
the discrepancy between the range of polarimetric data and the model. We find
that a larger value of the viscosity parameter alone, or a truncated disk by a
companion star, reduces these discrepancies by increasing the dissipation rate
in the outer regions of the disk.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:39:40 GMT""}]","2021-03-24"
"2102.04431","Angelo Felice Lopez","Angelo Felice Lopez (with an appendix by Thomas Dedieu)","On the extendability of projective varieties: a survey","v2: added some references; v3: added more references, classical and
  recent; v4: minor modifications in the main text following referee's remarks;
  appendix substantially improved thanks to result pointed out by an anonymous
  referee; v5: added one more reference; v6: added another reference",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a survey of the incredibly beautiful amount of geometry involved with
the problem of realizing a projective variety as hyperplane section of another
variety.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:40:58 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 20:18:55 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 17:31:11 GMT""},{""version"":""v4"",""created"":""Sat, 6 Mar 2021 17:59:49 GMT""},{""version"":""v5"",""created"":""Wed, 17 Mar 2021 20:19:07 GMT""},{""version"":""v6"",""created"":""Mon, 27 Sep 2021 13:51:17 GMT""}]","2021-09-28"
"2102.04432","Manoj Kumar","Manoj Kumar, Dirk Weissenborn, Nal Kalchbrenner","Colorization Transformer","ICLR 2021 Camera Ready. See
  https://openreview.net/forum?id=5NA1PinlGFu for more details",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Colorization Transformer, a novel approach for diverse high
fidelity image colorization based on self-attention. Given a grayscale image,
the colorization proceeds in three steps. We first use a conditional
autoregressive transformer to produce a low resolution coarse coloring of the
grayscale image. Our architecture adopts conditional transformer layers to
effectively condition grayscale input. Two subsequent fully parallel networks
upsample the coarse colored low resolution image into a finely colored high
resolution image. Sampling from the Colorization Transformer produces diverse
colorings whose fidelity outperforms the previous state-of-the-art on
colorising ImageNet based on FID results and based on a human evaluation in a
Mechanical Turk test. Remarkably, in more than 60% of cases human evaluators
prefer the highest rated among three generated colorings over the ground truth.
The code and pre-trained checkpoints for Colorization Transformer are publicly
available at
https://github.com/google-research/google-research/tree/master/coltran
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:45:06 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 08:38:49 GMT""}]","2021-03-09"
"2102.04433","Steven Duplij","Steven Duplij (University of M\""unster, Germany)","Higher braid groups and regular semigroups from polyadic-binary
  correspondence","17 pages, amslatex","Mathematics, 2021, 9(9), 972","10.3390/math9090972",,"math.GR hep-th math-ph math.MP math.QA math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we first consider a ternary matrix group related to the von
Neumann regular semigroups and to the Artin braid group (in an algebraic way).
The product of a special kind of ternary matrices (idempotent and of finite
order) reproduces the regular semigroups and braid groups with their binary
multiplication of components. We then generalize the construction to the higher
arity case, which allows us to obtain some higher degree versions (in our
sense) of the regular semigroups and braid groups. The latter are connected
with the generalized polyadic braid equation and $R$-matrix introduced by the
author, which differ from any version of the well-known tetrahedron equation
and higher-dimensional analogs of the Yang-Baxter equation, $n$-simplex
equations. The higher degree (in our sense) Coxeter group and symmetry groups
are then defined, and it is shown that these are connected only in the
non-higher case.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:47:03 GMT""}]","2021-04-28"
"2102.04434","Li Gao","Li Gao, Marius Junge, Haojian Li","Geometric Approach Towards Complete Logarithmic Sobolev Inequalities","12 pages. A preliminary version. Comments are welcome!",,,,"quant-ph math.OA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we use the Carnot-Caratheodory distance from sub-Riemanian
geometry to prove entropy decay estimates for all finite dimensional symmetric
quantum Markov semigroups. This estimate is independent of the environment size
and hence stable under tensorization. Our approach relies on the transference
principle, the existence of $t$-designs, and the sub-Riemannian diameter of
compact Lie groups and implies estimates for the spectral gap.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:48:15 GMT""}]","2021-02-09"
"2102.04435","Ling Zou","Ling Zou","Understand Slope Limiter -- Graphically",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this article, we illustrate how the concept of slope limiter can be
interpreted graphically, i.e., how the slope of reconstructed piecewise linear
function is limited by four bounding lines that connect cell-averaged data and
its neighboring cell-averaged data. It is then conjectured that the same
graphical rule can be generalized from uniform mesh to non-uniform mesh, such
that the high-resolution total variance diminishing (TVD) region of slope
limiter for non-uniform meshes can be obtained.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:48:58 GMT""}]","2021-02-09"
"2102.04436","Ivan L. Andronov","L.S. Kudashkina, I.L.Andronov","R Scuti: Close Alternating Pulsation Periods or Chaos in the RV Tau --
  Type Star?","""Annales Astronomiae Novae"", 2021, vol.2,
  http://astronomianova.org/publikacje.php (to appear)","Annales Astronomiae Novae, 2021, vol. 2, p. 301-312;
  2021AANv....2..301K",,,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results of analysis of 60010 data photometric observations from the AAVSO
international database are presented, which span 120 years of monitoring. The
periodogram analysis shows the best fit period of 70.74d, a half of typically
published periods for smaller intervals. Contrary to expectation for
deep/shallow minima, the changes between them are not so regular. There may be
series of deep (or shallow) minima without alternations. There may be two
acting periods of 138.5 days and 70.74, so the beat modulation may be expected.
The dependence of the phases of deep minima argue for two alternating periods
with a characteristic life-time of a mode of 30years. These phenomenological
results better explain the variability than the model of chaos.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:53:11 GMT""}]","2021-03-22"
"2102.04437","Toshiyuki Gogami","T. Gogami, C. Chen, D. Kawama, P. Achenbach, A. Ahmidouch, I.
  Albayrak, D. Androic, A. Asaturyan, R. Asaturyan, O. Ates, P. Baturin, R.
  Badui, W. Boeglin, J. Bono, E. Brash, P. Carter, A. Chiba, E. Christy, S.
  Danagoulian, R. De Leo, D. Doi, M. Elaasar, R. Ent, Y. Fujii, M. Fujita, M.
  Furic, M. Gabrielyan, L. Gan, F. Garibaldi, D. Gaskell, A. Gasparian, Y. Han,
  O. Hashimoto, T. Horn, B. Hu, Ed.V. Hungerford, M. Jones, H. Kanda, M.
  Kaneta, S. Kato, M. Kawai, H. Khanal, M. Kohl, A. Liyanage, W. Luo, K. Maeda,
  A. Margaryan, P. Markowitz, T. Maruta, A. Matsumura, V. Maxwell, D. Meekins,
  A. Mkrtchyan, H. Mkrtchyan, S. Nagao, S.N. Nakamura, A. Narayan, C. Neville,
  G. Niculescu, M.I. Niculescu, A. Nunez, Nuruzzaman, Y. Okayasu, T. Petkovic,
  J. Pochodzalla, X. Qiu, J. Reinhold, V.M. Rodriguez, C. Samanta, B. Sawatzky,
  T. Seva, A. Shichijo, V. Tadevosyan, L. Tang, N. Taniya, K. Tsukada, M.
  Veilleux, W. Vulcan, F.R. Wesselmann, S.A. Wood, T. Yamamoto, L. Ya, Z. Ye,
  K. Yokota, L. Yuan, S. Zhamkochyan, L. Zhu (HKS (JLab E05-115) Collaboration)","Spectroscopy of $A=9$ hyperlithium by the $(e,e^{\prime}K^{+})$ reaction","5 pages, 3 figures","Phys. Rev. C 103, 041301 (2021)","10.1103/PhysRevC.103.L041301",,"nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Missing mass spectroscopy with the $(e,e^{\prime}K^{+})$ reaction was
performed at Jefferson Laboratory's Hall C for the neutron rich $\Lambda$
hypernucleus $^{9}_{\Lambda}{\rm Li}$. The ground state energy was obtained to
be $B_{\Lambda}^{\rm g.s.}=8.84\pm0.17^{\rm stat.}\pm0.15^{\rm sys.}~{\rm MeV}$
by using shell model calculations of a cross section ratio and an energy
separation of the spin doublet states ($3/2^{+}_1$ and $5/2^{+}_1$). In
addition, peaks that are considered to be states of [$^{8}{\rm
Li}(3^{+})\otimes s_{\Lambda}=3/2^{+}_{2}, 1/2^{+}$] and [$^{8}{\rm
Li}(1^{+})\otimes s_{\Lambda}=5/2^{+}_{2}, 7/2^{+}$] were observed at
$E_{\Lambda}({\rm no.~2})=1.74\pm0.27^{\rm stat.}\pm0.11^{\rm sys.}~{\rm MeV}$
and $E_{\Lambda}({\rm no.~3})=3.30\pm0.24^{\rm stat.}\pm0.11^{\rm sys.}~{\rm
MeV}$, respectively. The $E_{\Lambda}({\rm no.~3})$ is larger than shell model
predictions by a few hundred keV, and the difference would indicate that a
${\rm ^{5}He}+t$ structure is more developed for the $3^{+}$ state than those
for the $2^{+}$ and $1^{+}$ states in a core nucleus $^{8}{\rm Li}$ as a
cluster model calculation suggests.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:53:42 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 08:36:37 GMT""}]","2021-04-14"
"2102.04438","Umang Gupta","Umang Gupta, Pradeep K. Lam, Greg Ver Steeg, Paul M. Thompson","Improved Brain Age Estimation with Slice-based Set Networks","To appear at IEEE International Symposium on Biomedical Imaging 2021
  (ISBI 2021). Code is available at https://git.io/JtazG",,,,"eess.IV cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Learning for neuroimaging data is a promising but challenging direction.
The high dimensionality of 3D MRI scans makes this endeavor compute and
data-intensive. Most conventional 3D neuroimaging methods use 3D-CNN-based
architectures with a large number of parameters and require more time and data
to train. Recently, 2D-slice-based models have received increasing attention as
they have fewer parameters and may require fewer samples to achieve comparable
performance. In this paper, we propose a new architecture for BrainAGE
prediction. The proposed architecture works by encoding each 2D slice in an MRI
with a deep 2D-CNN model. Next, it combines the information from these 2D-slice
encodings using set networks or permutation invariant layers. Experiments on
the BrainAGE prediction problem, using the UK Biobank dataset, showed that the
model with the permutation invariant layers trains faster and provides better
predictions compared to other state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:54:15 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 16:15:45 GMT""}]","2021-02-10"
"2102.04439","Mohammad Esmaeili","Mohammad Esmaeili and Aria Nosratinia","Community Detection: Exact Recovery in Weighted Graphs",,,,,"cs.SI cs.IT eess.SP math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In community detection, the exact recovery of communities (clusters) has been
mainly investigated under the general stochastic block model with edges drawn
from Bernoulli distributions. This paper considers the exact recovery of
communities in a complete graph in which the graph edges are drawn from either
a set of Gaussian distributions with community-dependent means and variances,
or a set of exponential distributions with community-dependent means. For each
case, we introduce a new semi-metric that describes sufficient and necessary
conditions of exact recovery. The necessary and sufficient conditions are
asymptotically tight. The analysis is also extended to incomplete, fully
connected weighted graphs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:54:29 GMT""}]","2021-02-09"
"2102.04440","Fangzhou Zhao","Fangzhou Zhao, Ting Cao, and Steven G. Louie","Electric Field Tunable Topological Phases in Graphene Nanoribbons",,"Phys. Rev. Lett. 127, 166401 (2021)","10.1103/PhysRevLett.127.166401",,"cond-mat.mes-hall cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphene nanoribbons (GNRs) possess distinct symmetry-protected topological
phases. We show, through first-principles calculations, that by applying an
experimentally accessible transverse electric field (TEF), certain boron and
nitrogen periodically co-doped GNRs have tunable topological phases. The
tunability arises from a field-induced band inversion due to an opposite
response of the conduction- and valance-band states to the electric field. With
a spatially-varying applied field, segments of GNRs of distinct topological
phases are created, resulting in a field-programmable array of topological
junction states, each may be occupied with charge or spin. Our findings not
only show that electric field may be used as an easy tuning knob for
topological phases in quasi-one-dimensional systems, but also provide new
design principles for future GNR-based quantum electronic devices through their
topological characters.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:54:30 GMT""}]","2021-10-25"
"2102.04441","Felix Marc P\""otzl","F. M. P\""otzl, A. P. Lobanov, E. Ros, J. L. G\'omez, G. Bruni, U.
  Bach, A. Fuentes, L. I. Gurvits, D. L. Jauncey, Y. Y. Kovalev, E. V.
  Kravchenko, M. M. Lisakov, T. Savolainen, K. V. Sokolovsky, and J. A. Zensus","Probing the innermost regions of AGN jets and their magnetic fields with
  RadioAstron IV. The quasar 3C 345 at 18 cm: Magnetic field structure and
  brightness temperature","10 pages, 9 figures. Accepted for publication in Astronomy &
  Astrophysics","A&A 648, A82 (2021)","10.1051/0004-6361/202039493",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. Supermassive black holes in the centres of radio-loud active
galactic nuclei (AGN) can produce collimated relativistic outflows (jets).
Magnetic fields are thought to play a key role in the formation and collimation
of these jets, but the details are much debated. Aims. We study the innermost
jet morphology and magnetic field strength in the AGN 3C 345 with an
unprecedented resolution using images obtained within the framework of the key
science programme on AGN polarisation of the Space VLBI mission RadioAstron.
Methods. We observed the flat spectrum radio quasar 3C 345 at 1.6 GHz on 2016
March 30 with RadioAstron and 18 ground-based radio telescopes in full
polarisation mode. Results. Our images, in both total intensity and linear
polarisation, reveal a complex jet structure at 300 $\mu$as angular resolution,
corresponding to a projected linear scale of about 2 pc or a few thousand
gravitational radii. We identify the synchrotron self-absorbed core at the jet
base and find the brightest feature in the jet 1.5 mas downstream of the core.
Several polarised components appear in the Space VLBI images that cannot be
seen from ground array-only images. Except for the core, the electric vector
position angles follow the local jet direction, suggesting a magnetic field
perpendicular to the jet. This indicates the presence of plane perpendicular
shocks in these regions. Additionally, we infer a minimum brightness
temperature at the largest $(u,v)$-distances of $1.1\times 10^{12}$ K in the
source frame, which is above the inverse Compton limit and an order of
magnitude larger than the equipartition value. This indicates locally efficient
injection or re-acceleration of particles in the jet to counter the inverse
Compton cooling or the geometry of the jet creates significant changes in the
Doppler factor, which has to be $>11$ to explain the high brightness
temperatures.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:56:24 GMT""}]","2021-04-14"
"2102.04442","Adrian Bulat","Adrian Bulat and Enrique S\'anchez-Lozano and Georgios Tzimiropoulos","Improving memory banks for unsupervised learning with large mini-batch,
  consistency and hard negative mining","Accepted at ICASSP 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important component of unsupervised learning by instance-based
discrimination is a memory bank for storing a feature representation for each
training sample in the dataset. In this paper, we introduce 3 improvements to
the vanilla memory bank-based formulation which brings massive accuracy gains:
(a) Large mini-batch: we pull multiple augmentations for each sample within the
same batch and show that this leads to better models and enhanced memory bank
updates. (b) Consistency: we enforce the logits obtained by different
augmentations of the same sample to be close without trying to enforce
discrimination with respect to negative samples as proposed by previous
approaches. (c) Hard negative mining: since instance discrimination is not
meaningful for samples that are too visually similar, we devise a novel nearest
neighbour approach for improving the memory bank that gradually merges
extremely similar data samples that were previously forced to be apart by the
instance level classification loss. Overall, our approach greatly improves the
vanilla memory-bank based instance discrimination and outperforms all existing
methods for both seen and unseen testing categories with cosine similarity.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:56:33 GMT""}]","2021-02-09"
"2102.04443","Benjamin Sambale","Nguyen Ngoc Hung, Benjamin Sambale and Pham Huu Tiep","Bounding p-Brauer characters in finite groups with two conjugacy classes
  of p-elements","24 pages, incorporated valuable comments by Gunter Malle",,,,"math.RT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let k(B_0) and l(B_0) respectively denote the number of ordinary and p-Brauer
irreducible characters in the principal block B_0 of a finite group G. We prove
that, if k(B_0)-l(B_0)=1, then l(B_0)\geq p-1 or else p=11 and l(B_0)=9. This
follows from a more general result that for every finite group G in which all
non-trivial p-elements are conjugate, l(B_0)\geq p-1 or else p = 11 and
G/O_{p'}(G) =11^2:SL(2,5). These results are useful in the study of principal
blocks with a few characters.
  We propose that, in every finite group G of order divisible by p, the number
of irreducible Brauer characters in the principal p-block of G is always at
least 2\sqrt{p-1}+1-k_p(G), where k_p(G) is the number of conjugacy classes of
p-elements of G. This indeed is a consequence of the celebrated Alperin weight
conjecture and known results on bounding the number of p-regular classes in
finite groups.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:57:09 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 04:39:10 GMT""}]","2021-02-17"
"2102.04444","Yi-Ming Wu","Yi-Ming Wu, Shang-Shun Zhang, Artem Abanov and Andrey V. Chubukov","Interplay between superconductivity and non-Fermi liquid at a
  quantum-critical point in a metal: V. The $\gamma$ model and its phase
  diagram. The case $\gamma =2$","62 pages, 21 figs. The continuation of arXiv:2004.13220,
  arXiv:2006.02968, arXiv:2007.14540 and arXiv:2009.10911",,"10.1103/PhysRevB.103.184508",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  This paper is a continuation and a partial summary of our analysis of the
pairing at a quantum-critical point (QCP) in a metal for a set of
quantum-critical systems, whose low-energy physics is described by an effective
model with dynamical electron-electron interaction $V(\Omega_m) = ({\bar
g}/|\Omega_m|)^\gamma$ (the $\gamma$-model). Examples include pairing at the
onset of various spin and charge density-wave and nematic orders and pairing in
SYK-type models. In previous papers, we analyzed the physics for $\gamma <2$.
We have shown that the onset temperature for the pairing $T_p$ is finite, of
order ${\bar g}$, yet the gap equation at $T=0$ has an infinite set of
solutions within the same spatial symmetry. As the consequence, the
condensation energy $E_c$ has an infinite number of minima. The spectrum of
$E_c$ is discrete, but becomes more dense as $\gamma$ increases. Here we
consider the case $\gamma =2$. The $\gamma=2$ model attracted special interest
in the past as it describes the pairing by an Einstein phonon in the limit when
the dressed phonon mass $\omega_D$ vanishes. We show that for $\gamma =2$, the
spectrum of $E_c$ becomes continuous. We argue that the associated gapless
""longitudinal"" fluctuations destroy superconducting phase coherence at a finite
$T$, such that at $0<T< T_p$ the system displays pseudogap behavior. We show
that for each gap function from the continuum spectrum, there is an infinite
array of dynamical vortices in the upper half-plane of frequency. For the
electron-phonon case, our results show that $T_p =0.1827 {\bar g}$, obtained in
earlier studies, marks the onset of the pseudogap behavior of preformed pairs,
while the actual superconducting $T_c$vanishes at $\omega_D \to 0$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:57:16 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 20:51:15 GMT""}]","2021-06-03"
"2102.04445","Edmilson Roque Dos Santos","Jaap Eldering, Jeroen S.W. Lamb, Tiago Pereira and Edmilson Roque dos
  Santos","Chimera states through invariant manifold theory","32 pages, 8 figures",,"10.1088/1361-6544/ac0613",,"math.DS nlin.AO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We establish the existence of chimera states, simultaneously supporting
synchronous and asynchronous dynamics, in a network consisting of two
symmetrically linked star subnetworks consisting of identical oscillators with
shear and Kuramoto--Sakaguchi coupling. We show that the chimera states may be
metastable or asymptotically stable. If the intra-star coupling strength is of
order $\varepsilon$, the chimera states persist on time scales at least of
order $1/\varepsilon$ in general, and on time-scales at least of order
$1/\varepsilon^2$ if the intra-star coupling is of Kuramoto--Sakaguchi type. If
the intra-star coupling configuration is sparse, the chimeras are
asymptotically stable. The analysis relies on a combination of dimensional
reduction using a M\""obius symmetry group and techniques from averaging theory
and normal hyperbolicity.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:57:52 GMT""}]","2021-08-11"
"2102.04446","Justin Gould","Justin Gould","A Framework for Auditing Data Center Energy Usage and Mitigating
  Environmental Footprint","9 pages, 2 figures",,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  As the Data Science field continues to mature, and we collect more data, the
demand to store and analyze them will continue to increase. This increase in
data availability and demand for analytics will put a strain on data centers
and compute clusters-with implications for both energy costs and emissions. As
the world battles a climate crisis, it is prudent for organizations with data
centers to have a framework for combating increasing energy costs and emissions
to meet demand for analytics work. In this paper, I present a generalized
framework for organizations to audit data centers energy efficiency to
understand the resources required to operate a given data center and effective
steps organizations can take to improve data center efficiency and lower the
environmental impact.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:58:41 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 13:29:11 GMT""}]","2021-02-10"
"2102.04447","John Leung","John Kalung Leung and Igor Griva and William G. Kennedy","Applying the Affective Aware Pseudo Association Method to Enhance the
  Top-N Recommendations Distribution to Users in Group Emotion Recommender
  Systems","19 pages, 9 tables","International Journal on Natural Language Computing (IJNLC) Vol.
  10, No. 1, February 2021","10.5121/ijnlc.2021.10101",,"cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recommender Systems are a subclass of information retrieval systems, or more
succinctly, a class of information filtering systems that seeks to predict how
close is the match of the user's preference to a recommended item. A common
approach for making recommendations for a user group is to extend Personalized
Recommender Systems' capability. This approach gives the impression that group
recommendations are retrofits of the Personalized Recommender Systems.
Moreover, such an approach not taken the dynamics of group emotion and
individual emotion into the consideration in making top_N recommendations.
Recommending items to a group of two or more users has certainly raised unique
challenges in group behaviors that influence group decision-making that
researchers only partially understand. This study applies the Affective Aware
Pseudo Association Method in studying group formation and dynamics in group
decision-making. The method shows its adaptability to group's moods change when
making recommendations.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:59:20 GMT""}]","2021-03-09"
"2102.04448","Valentin Khrulkov","Valentin Khrulkov, Artem Babenko, Ivan Oseledets","Functional Space Analysis of Local GAN Convergence",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work demonstrated the benefits of studying continuous-time dynamics
governing the GAN training. However, this dynamics is analyzed in the model
parameter space, which results in finite-dimensional dynamical systems. We
propose a novel perspective where we study the local dynamics of adversarial
training in the general functional space and show how it can be represented as
a system of partial differential equations. Thus, the convergence properties
can be inferred from the eigenvalues of the resulting differential operator. We
show that these eigenvalues can be efficiently estimated from the target
dataset before training. Our perspective reveals several insights on the
practical tricks commonly used to stabilize GANs, such as gradient penalty,
data augmentation, and advanced integration schemes. As an immediate practical
benefit, we demonstrate how one can a priori select an optimal data
augmentation strategy for a particular generation task.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:59:46 GMT""}]","2021-02-09"
"2102.04458","Myung Suh Choi","Alim Al Ayub Ahmed, Ayman Aljabouh, Praveen Kumar Donepudi, Myung Suh
  Choi","Detecting Fake News Using Machine Learning : A Systematic Literature
  Review","8 pages, 2 figures",,,,"cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Internet is one of the important inventions and a large number of persons are
its users. These persons use this for different purposes. There are different
social media platforms that are accessible to these users. Any user can make a
post or spread the news through the online platforms. These platforms do not
verify the users or their posts. So some of the users try to spread fake news
through these platforms. These news can be propaganda against an individual,
society, organization or political party. A human being is unable to detect all
these fake news. So there is a need for machine learning classifiers that can
detect these fake news automatically. Use of machine learning classifiers for
detecting fake news is described in this systematic literature review.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:36:00 GMT""}]","2021-02-10"
"2102.04460","Iuliana Marin","Iuliana Marin, Nicolae Goga","Securing the Network for a Smart Bracelet System",,"2018 22nd International Conference on System Theory, Control and
  Computing (ICSTCC)","10.1109/ICSTCC.2018.8540704",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital instruments play a vital role in our daily life. It is a routine to
produce business papers, watch the news program, write articles and blogs,
manage healthcare systems, to purchase online, to send messages and all this is
processed by making observations and then manipulating, receiving and availing
the diverse data. This electronic data provides the foundation of real time
data. All this transmission of data needs to be secured. Security is essential
for healthcare systems as the present one where the blood pressure recordings
provided by the smart bracelet are sent to the user's mobile phone via
Bluetooth. The bracelet monitors the pregnant women, but also other users who
wish to have their blood pressure under control. The system's server analyses
the recordings and announces the user, as well as the associated persons to the
user in case of an emergency. The doctors, the medical staff, user and user's
family and caregivers have access to the health recordings belonging to the
monitored user. Security is a main feature of the electronic healthcare system
based on the smart bracelet.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:50:02 GMT""}]","2021-02-10"
"2102.04462","Stefano Favaro","Emanuele Dolera, Stefano Favaro, Stefano Peluchetti","Learning-augmented count-min sketches via Bayesian nonparametrics","47 pages",,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  The count-min sketch (CMS) is a time and memory efficient randomized data
structure that provides estimates of tokens' frequencies in a data stream of
tokens, i.e. point queries, based on random hashed data. A learning-augmented
version of the CMS, referred to as CMS-DP, has been proposed by Cai,
Mitzenmacher and Adams (\textit{NeurIPS} 2018), and it relies on Bayesian
nonparametric (BNP) modeling of the data stream of tokens via a Dirichlet
process (DP) prior, with estimates of a point query being obtained as suitable
mean functionals of the posterior distribution of the point query, given the
hashed data. While the CMS-DP has proved to improve on some aspects of CMS, it
has the major drawback of arising from a ``constructive"" proof that builds upon
arguments tailored to the DP prior, namely arguments that are not usable for
other nonparametric priors. In this paper, we present a ``Bayesian"" proof of
the CMS-DP that has the main advantage of building upon arguments that are
usable, in principle, within a broad class of nonparametric priors arising from
normalized completely random measures. This result leads to develop a novel
learning-augmented CMS under power-law data streams, referred to as CMS-PYP,
which relies on BNP modeling of the data stream of tokens via a Pitman-Yor
process (PYP) prior. Under this more general framework, we apply the arguments
of the ``Bayesian"" proof of the CMS-DP, suitably adapted to the PYP prior, in
order to compute the posterior distribution of a point query, given the hashed
data. Applications to synthetic data and real textual data show that the
CMS-PYP outperforms the CMS and the CMS-DP in estimating low-frequency tokens,
which are known to be of critical interest in textual data, and it is
competitive with respect to a variation of the CMS designed for low-frequency
tokens. An extension of our BNP approach to more general queries is also
discussed.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:02:30 GMT""},{""version"":""v2"",""created"":""Sun, 13 Mar 2022 23:41:00 GMT""},{""version"":""v3"",""created"":""Tue, 13 Sep 2022 15:03:37 GMT""}]","2022-09-14"
"2102.04463","Ankit Pandey","Ankit Pandey, Bill Poirier, Luis Grave-de-Peralta","Viewing quantum mechanics through the prism of electromagnetism","5 pages, 4 figures",,,,"quant-ph physics.pop-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we demonstrate novel relationships between quantum mechanics
and the electromagnetic wave equation. In our approach, an invariant
interference-dependent electromagnetic quantity, which we call ""quantum rest
mass"", replaces the conventional role of the inertial rest mass. In the ensuing
results, photons, during interference, move slower than the speed of light in
vacuum, and possess de Broglie wavelength. Further, we use our electromagnetic
approach to examine double-slit photon trajectories, and to arrive at the
Schrodinger equation's results for a particle in an infinite square well
potential.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:15:08 GMT""}]","2021-02-10"
"2102.04464","Arka Majumdar","Albert Ryou, James Whitehead, Maksym Zhelyeznyakov, Paul Anderson, Cem
  Keskin, Michal Bajcsy, and Arka Majumdar","Free-space optical neural network based on thermal atomic nonlinearity",,,"10.1364/PRJ.415964",,"cs.ET physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As artificial neural networks (ANNs) continue to make strides in wide-ranging
and diverse fields of technology, the search for more efficient hardware
implementations beyond conventional electronics is gaining traction. In
particular, optical implementations potentially offer extraordinary gains in
terms of speed and reduced energy consumption due to intrinsic parallelism of
free-space optics. At the same time, a physical nonlinearity, a crucial
ingredient of an ANN, is not easy to realize in free-space optics, which
restricts the potential of this platform. This problem is further exacerbated
by the need to perform the nonlinear activation also in parallel for each data
point to preserve the benefit of linear free-space optics. Here, we present a
free-space optical ANN with diffraction-based linear weight summation and
nonlinear activation enabled by the saturable absorption of thermal atoms. We
demonstrate, via both simulation and experiment, image classification of
handwritten digits using only a single layer and observed 6-percent improvement
in classification accuracy due to the optical nonlinearity compared to a linear
model. Our platform preserves the massive parallelism of free-space optics even
with physical nonlinearity, and thus opens the way for novel designs and wider
deployment of optical ANNs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:52:00 GMT""}]","2021-07-01"
"2102.04465","Jacob Hamer","Jacob H. Hamer","Coadded Spectroscopic Stellar Parameters and Abundances from the LAMOST
  Low Resolution Survey","2 pages, data available at https://doi.org/10.7281/T1/QISGRU","2021 Res. Notes AAS 5 24","10.3847/2515-5172/abe1b3",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  I combine duplicate spectroscopic stellar parameter estimates in the Large
Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) Data Release 6 Low
Resolution Spectral Survey A, F, G, and K Type stellar parameter catalog.
Combining repeat measurements results in a factor of two improvement in the
precision of the spectroscopic stellar parameter estimates. Moreover, this
trivializes the process of performing coordinate-based cross-matching with
other catalogs. Similarly, I combine duplicate stellar abundance estimates for
the Xiang et al. catalog which was produced using LAMOST Data Release 5 Low
Resolution Spectral Survey data. These data have numerous applications in
stellar, galactic, and exoplanet astronomy. The catalogs I produce are
available as machine-readable tables at https://doi.org/10.7281/T1/QISGRU .
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:00 GMT""}]","2021-02-10"
"2102.04466","Guy Nir","Guy Nir, Eran O. Ofek, Avishay Gal-Yam","The GN-z11-Flash Event Can be a Satellite Glint",,,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Recently Jiang et al. reported the discovery of a possible short duration
transient, detected in a single image, spatially associated with a z~11 galaxy.
Jiang et al. and Kahn et al. suggested the transient originates from a
Gamma-Ray Burst (GRB), while Padmanabhan & Loeb argued the flash is consistent
with a supernova shock breakout event of a 300 M_sun population III star. Jiang
et al. argued against the possibility that this event originated from light
reflected off a satellite. Here we show that reflection of sunlight from a
high-orbit satellite or a piece of space debris is a valid and reasonable
explanation. As shown in recent works, the rate of point-like satellite
reflections, brighter than 11th magnitude, is >10 deg^{-2} day^-1 near the
equatorial plane. At higher declinations the rate is 5--50 times lower, but
still significant: about four orders of magnitudes higher than the rate
estimated for GRBs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:01 GMT""}]","2021-02-10"
"2102.04467","Sho Fujibayashi","Sho Fujibayashi, Koh Takahashi, Yuichiro Sekiguchi, Masaru Shibata","Ultra-delayed neutrino-driven explosion of rotating massive-star
  collapse","12 pages, 5 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac10cb",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Long-term neutrino-radiation hydrodynamics simulations in full general
relativity are performed for the collapse of rotating massive stars that are
evolved from He-stars with their initial mass of $20$ and $32M_\odot$. It is
shown that if the collapsing stellar core has sufficient angular momentum, the
rotationally-supported proto-neutron star (PNS) survives for seconds
accompanying the formation of a massive torus of mass larger than $1\,M_\odot$.
Subsequent mass accretion onto the central region produces a massive and
compact central object, and eventually enhances the neutrino luminosity beyond
$10^{53}$\,erg/s, resulting in a very delayed neutrino-driven explosion in
particular toward the polar direction. The kinetic energy of the explosion can
be appreciably higher than $10^{52}$ erg for a massive progenitor star and
compatible with that of energetic supernovae like broad-line type-Ic
supernovae. By the subsequent accretion, the massive PNS collapses eventually
into a rapidly spinning black hole, which could be a central engine for
gamma-ray bursts if a massive torus surrounds it.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 07:37:24 GMT""}]","2021-10-04"
"2102.04468","Abhijeet Alase","Abhijeet Alase and David L. Feder","Generating and detecting topological phases with higher Chern number","12 pages, 4 figures","Phys. Rev. A 103, 053305 (2021)","10.1103/PhysRevA.103.053305",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological phases with broken time-reversal symmetry and Chern number |C|>=2
are of fundamental interest, but it remains unclear how to engineer the desired
topological Hamiltonian within the paradigm of spin-orbit-coupled particles
hopping only between nearest neighbours of a static lattice. We show that
phases with higher Chern number arise when the spin-orbit coupling satisfies a
combination of spin and spatial rotation symmetries. We leverage this result
both to construct minimal two-band tight binding Hamiltonians that exhibit
|C|=2,3 phases, and to show that the Chern number of one of the energy bands
can be inferred from the particle spin polarization at the high-symmetry
crystal momenta in the Brillouin zone. Using these insights, we provide a
detailed experimental scheme for the specific realization of a
time-reversal-breaking topological phase with |C|=2 for ultracold atomic gases
on a triangular lattice subject to spin-orbit coupling. The Chern number can be
directly measured using Zeeman spectroscopy; for fermions the spin amplitudes
can be measured directly via time of flight, while for bosons this is preceded
by a short Bloch oscillation. Our results provide a pathway to the realization
and detection of novel topological phases with higher Chern number in ultracold
atomic gases.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 23:33:27 GMT""}]","2021-06-09"
"2102.04469","Guido Roberts-Borsani","Guido Roberts-Borsani, Tommaso Treu, Charlotte Mason, Kasper B.
  Schmidt, Tucker Jones and Adriano Fontana","Improving $z\sim7-11$ Galaxy Property Estimates with JWST/NIRCam
  Medium-Band Photometry","13 pages, 7 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/abe45b",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The past decade has seen impressive progress in the detection of $z>7$
galaxies with the Hubble Space Telescope, however little is known about their
properties. The James Webb Space Telescope will revolutionise the high-$z$
field by providing NIR (i.e., rest-frame optical) data of unprecedented depth
and spatial resolution. Measuring galaxy quantities such as resolved stellar
ages or gas metallicity gradients traditionally requires spectroscopy, as
broad-band imaging filters are generally too coarse to fully isolate
diagnostics such as the 4000 \r{A} (rest-frame) break, continuum emission from
aged stars, and key emission lines (e.g., [OII], [OIII], H$\beta$). However, in
this paper, we show that adding NIRCam images through a strategically chosen
medium-band filter to common wide-band filters sets adopted by ERS and GTO
programs delivers tighter constraints on these galactic properties. To
constrain the choice of filter, we perform a systematic investigation of which
combinations of wide-band filters from ERS and GTO programs and single
medium-band filters offer the tightest constraints on several galaxy properties
at redshifts $z\sim7-11$. We employ the JAGUAR extragalactic catalogs to
construct statistical samples of physically-motivated mock photometry and
conduct SED-fitting procedures to evaluate the accuracy of galaxy property (and
photo-$z$) recovery with a simple star-formation history model. We find that
adding $>4.1 \mu$m medium filters at comparable depth to the broad-band filters
can significantly improve photo-$z$s and yield close to order-of-magnitude
improvements in the determination of quantities such as stellar ages,
metallicities, SF-related quantities and emission line fluxes at $z\sim8$. For
resolved sources, the proposed approach enables spatially-resolved
determination of these quantities that would be prohibitive with slit
spectroscopy.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:01 GMT""}]","2021-04-07"
"2102.04470","Yu-Ping Lin","Yu-Ping Lin and Wei-Han Hsiao","Band geometry from position-momentum duality at topological band
  crossings","8 pages, 2 figures. v3: Published version","Phys. Rev. B 105, 075127 (2022)","10.1103/PhysRevB.105.075127",,"cond-mat.mes-hall cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the position-momentum duality offers a transparent
interpretation of the band geometry at the topological band crossings. Under
this duality, the band geometry with Berry connection is dual to the
free-electron motion under gauge field. This identifies the trace of quantum
metric as the dual energy in momentum space. The band crossings with Berry
defects thus induce the dual energy quantization in the trace of quantum
metric. For the $\mathbb Z$ nodal-point and nodal-surface semimetals in three
dimensions, the dual Landau level quantization occurs owing to the Berry
charges. Meanwhile, the two-dimensional (2D) Dirac points exhibit the Berry
vortices, leading to the quantized dual axial rotational energies. Such a
quantization naturally generalizes to the three-dimensional (3D) nodal-loop
semimetals, where the nodal loops host the Berry vortex lines. The $\mathbb
Z_2$ monopoles bring about additional dual axial rotational energies, which
originate from the links with additional nodal lines. Nontrivial band geometry
generically induces finite spread in the Wannier functions. While the spread
manifest quantized lower bounds from the Berry charges, logarithmic divergences
occur from the Berry vortices. The band geometry at the band crossings may be
probed experimentally by a periodic-drive measurement.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 14:04:41 GMT""},{""version"":""v3"",""created"":""Fri, 18 Feb 2022 18:55:02 GMT""}]","2022-02-21"
"2102.04471","Matteo Pompili","Matteo Pompili, Sophie L. N. Hermans, Simon Baier, Hans K. C. Beukers,
  Peter C. Humphreys, Raymond N. Schouten, Raymond F. L. Vermeulen, Marijn J.
  Tiggelman, Laura dos Santos Martins, Bas Dirkse, Stephanie Wehner, Ronald
  Hanson","Realization of a multi-node quantum network of remote solid-state qubits","9 pages, 5 figures, supplementary materials","Science, 372, 259-264 (2021)","10.1126/science.abg1919",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distribution of entangled states across the nodes of a future quantum
internet will unlock fundamentally new technologies. Here we report on the
experimental realization of a three-node entanglement-based quantum network. We
combine remote quantum nodes based on diamond communication qubits into a
scalable phase-stabilized architecture, supplemented with a robust memory qubit
and local quantum logic. In addition, we achieve real-time communication and
feed-forward gate operations across the network. We capitalize on the novel
capabilities of this network to realize two canonical protocols without
post-selection: the distribution of genuine multipartite entangled states
across the three nodes and entanglement swapping through an intermediary node.
Our work establishes a key platform for exploring, testing and developing
multi-node quantum network protocols and a quantum network control stack.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""}]","2021-04-19"
"2102.04472","James Nightingale","James. W. Nightingale, Richard G. Hayes, Matthew Griffiths","PyAutoFit: A Classy Probabilistic Programming Language for Model
  Composition and Fitting","Published in the Journal of Open Source Software","Journal of Open Source Software, 6(58), 2550 (2021)","10.21105/joss.02550",,"astro-ph.IM cs.PL physics.data-an physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  A major trend in academia and data science is the rapid adoption of Bayesian
statistics for data analysis and modeling, leading to the development of
probabilistic programming languages (PPL). A PPL provides a framework that
allows users to easily specify a probabilistic model and perform inference
automatically. PyAutoFit is a Python-based PPL which interfaces with all
aspects of the modeling (e.g., the model, data, fitting procedure,
visualization, results) and therefore provides complete management of every
aspect of modeling. This includes composing high-dimensionality models from
individual model components, customizing the fitting procedure and performing
data augmentation before a model-fit. Advanced features include database tools
for analysing large suites of modeling results and exploiting domain-specific
knowledge of a problem via non-linear search chaining. Accompanying PyAutoFit
is the autofit workspace (see https://github.com/Jammy2211/autofit_workspace),
which includes example scripts and the HowToFit lecture series which introduces
non-experts to model-fitting and provides a guide on how to begin a project
using PyAutoFit. Readers can try PyAutoFit right now by going to the
introduction Jupyter notebook on Binder (see
https://mybinder.org/v2/gh/Jammy2211/autofit_workspace/HEAD) or checkout our
readthedocs(see https://pyautofit.readthedocs.io/en/latest/) for a complete
overview of PyAutoFit's features.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""}]","2021-02-15"
"2102.04473","Tobias Donner","Farokh Mivehvar and Francesco Piazza and Tobias Donner and Helmut
  Ritsch","Cavity QED with Quantum Gases: New Paradigms in Many-Body Physics","Review paper with 170 pages, 67 figures, and 2 tables. Revised
  version","Advances in Physics, 70, 1 (2021)","10.1080/00018732.2021.1969727",,"cond-mat.quant-gas physics.atom-ph physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  We review the recent developments and the current status in the field of
quantum-gas cavity QED. Since the first experimental demonstration of atomic
self-ordering in a system composed of a Bose-Einstein condensate coupled to a
quantized electromagnetic mode of a high-$Q$ optical cavity, the field has
rapidly evolved over the past decade. The composite quantum-gas--cavity systems
offer the opportunity to implement, simulate, and experimentally test
fundamental solid-state Hamiltonians, as well as to realize non-equilibrium
many-body phenomena beyond conventional condensed-matter scenarios. This hinges
on the unique possibility to design and control in open quantum environments
photon-induced tunable-range interaction potentials for the atoms using
tailored pump lasers and dynamic cavity fields. Notable examples range from
Hubbard-like models with long-range interactions exhibiting a
lattice-supersolid phase, over emergent magnetic orderings and quasicrystalline
symmetries, to the appearance of dynamic gauge potentials and non-equilibrium
topological phases. Experiments have managed to load spin-polarized as well as
spinful quantum gases into various cavity geometries and engineer versatile
tunable-range atomic interactions. This led to the experimental observation of
spontaneous discrete and continuous symmetry breaking with the appearance of
soft-modes as well as supersolidity, density and spin self-ordering, dynamic
spin-orbit coupling, and non-equilibrium dynamical self-ordered phases among
others. In addition, quantum-gas--cavity setups offer new platforms for
quantum-enhanced measurements. In this review, starting from an introduction to
basic models, we pedagogically summarize a broad range of theoretical
developments and put them in perspective with the current and near future
state-of-art experiments.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 08:42:42 GMT""}]","2021-10-27"
"2102.04474","Vazha Loladze","Sabyasachi Chakraborty, Manfred Kraus, Vazha Loladze, Takemichi Okui,
  Kohsaku Tobioka","Heavy QCD Axion in $b\to s$ transition: Enhanced Limits and Projections","9 pages, 4 figures; Two Typos are corrected; one in equation (B7) and
  the second in the y-axis scale of Fig. 3. No conclusions and final results
  changed","Phys. Rev. D 104, 055036 (2021)","10.1103/PhysRevD.104.055036","KEK-TH-2295","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a ""heavy"" QCD axion whose coupling to the standard model is
dominated by $a G \widetilde{G}$ but with $m_a \gg m_\pi f_\pi / f_a$. This is
well motivated as it can solve the strong CP problem while evading the axion
quality problem. It also poses interesting challenges for its experimental
search due to its suppressed couplings to photons and leptons. Such axion with
mass around a GeV is kinematically inaccessible or poorly constrained by most
experimental probes except B-factories. We study $B \to K a$ transitions as a
powerful probe of the heavy QCD axion by performing necessary 2-loop
calculations for the first time, together with some improvement on the existing
analysis strategy. We find some of the existing limits are enhanced by at least
an order of magnitude. We also demonstrate that the bounds are robust against
unknown UV physics. For forthcoming data sets of the Belle II experiment, we
provide a projection that $f_a$ of a few TeV is within its future reach, which
is relevant to the quality problem.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 19:58:18 GMT""},{""version"":""v3"",""created"":""Fri, 30 Jul 2021 09:11:41 GMT""},{""version"":""v4"",""created"":""Mon, 22 May 2023 14:31:48 GMT""}]","2023-05-23"
"2102.04475","Ali Kheirandish","Ali Kheirandish, Kohta Murase, Shigeo S. Kimura","High-Energy Neutrinos from Magnetized Coronae of Active Galactic Nuclei
  and Prospects for Identification of Seyfert Galaxies and Quasars in Neutrino
  Telescopes","23 pages, 16 figures, accepted for publication in ApJ. Discussion is
  extended, results and conclusions remain unchanged","Astrophys.J. 922 (2021) 45","10.3847/1538-4357/ac1c77",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particles may be accelerated in magnetized coronae via magnetic reconnections
and/or plasma turbulence, leading to high-energy neutrinos and soft gamma rays.
We evaluate the detectability of neutrinos from nearby bright Seyfert galaxies
identified by X-ray measurements. In the disk-corona model, we find that NGC
1068 is the most promising Seyfert galaxy in the Northern sky, where IceCube is
the most sensitive, and show prospects for the identification of aggregated
neutrino signals from Seyfert galaxies bright in X-rays. Moreover, we
demonstrate that nearby Seyfert galaxies are promising targets for the next
generation of neutrino telescopes such as KM3NeT and IceCube-Gen2. For KM3NeT,
Cen A can be the most promising source in the Southern sky if a significant
fraction of the observed X-rays come from the corona, and it could be
identified in few years of KM3NeT operation. Our results reinforce the idea
that hidden cores of supermassive black holes are the dominant sources of the
high-energy neutrino emission and underlines the necessity of better
sensitivity to medium-energy ranges in future neutrino detectors for
identifying the origin of high-energy cosmic neutrinos.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 20:33:56 GMT""}]","2021-11-25"
"2102.04476","Alejandro Ruiperez","Pablo A. Cano, \'Angel Murcia, Pedro F. Ram\'irez and Alejandro
  Ruip\'erez","On small black holes, KK monopoles and solitonic 5-branes","56 pages, 1 figure; v2: minor changes to match published version",,"10.1007/JHEP05(2021)272",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review and extend results on higher-curvature corrections to different
configurations describing a superposition of heterotic strings, KK monopoles,
solitonic 5-branes and momentum waves. Depending on which sources are present,
the low-energy fields describe a black hole, a soliton or a naked singularity.
We show that this property is unaltered when perturbative higher-curvature
corrections are included, provided the sources are fixed. On the other hand,
this character may be changed by appropriate introduction (or removal) of
sources regardless of the presence of curvature corrections, which constitutes
a non-perturbative modification of the departing system. The general system of
multicenter KK monopoles and their 5-brane charge induced by higher-curvature
corrections is discussed in some detail, with special attention paid to the
possibility of merging monopoles. Our results are particularly relevant for
small black holes (Dabholkar-Harvey states, DH), which remain singular after
quadratic curvature corrections are taken into account. When there are four
non-compact dimensions, we notice the existence of a black hole with regular
horizon whose entropy coincides with that of the DH states, but the charges and
supersymmetry preserved by both configurations are different. A similar
construction with five non-compact dimensions is possible, in this case with
the same charges as DH, although it fails to reproduce the DH entropy and
supersymmetry. No such configuration exists if $d>5$, which we interpret as
reflecting the necessity of having a 5-brane wrapping the compact space.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 10:33:47 GMT""}]","2021-07-28"
"2102.04477","Ilya Khrykin","Ilya S. Khrykin, Joseph F. Hennawi, Gabor Worseck, Frederick B. Davies","The first measurement of the quasar lifetime distribution","14 pages, 10 figures, submitted to MNRAS",,"10.1093/mnras/stab1288",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the growth of the supermassive black holes powering luminous
quasars, their co-evolution with host galaxies, and impact on the surrounding
intergalactic medium depends sensitively on the duration of quasar accretion
episodes. Unfortunately, this time-scale, known as the quasar lifetime, $t_{\rm
Q}$, is still uncertain by orders of magnitude ($t_{\rm Q}\simeq 0.01~{\rm
Myr}-1~{\rm Gyr}$). However, the extent of the He II Ly$\alpha$ proximity zones
in the absorption spectra of $z_{\rm qso}\sim3-4$ quasars constitutes a unique
probe, providing sensitivity to lifetimes up to $\sim 30$ Myr. Our recent
analysis of $22$ archival He II proximity zone spectra reveals a surprisingly
broad range of emission timescales, indicating that some quasars turned on
$\lesssim 1$ Myr ago, whereas others have been shining for $\gtrsim 30$ Myr.
Determining the underlying quasar lifetime distribution (QLD) from proximity
zone measurements is a challenging task owing to: 1) the limited sensitivity of
individual measurements; 2) random sampling of the quasar light curves; 3)
density fluctuations in the quasar environment; and 4) the inhomogeneous
ionization state of He II in a reionizing IGM. We combine a semi-numerical He
II reionization model, hydrodynamical simulations post-processed with ionizing
radiative transfer, and a novel statistical framework to infer the QLD from an
ensemble of proximity zone measurements. Assuming a log-normal QLD, we infer a
mean $\langle {\rm log}_{10}\left(t_{\rm Q}/{\rm
Myr}\right)\rangle=0.22^{+0.22}_{-0.25}$ and standard deviation $\sigma_{{\rm
log}_{10}t_{\rm Q}}=0.80^{+0.37}_{-0.27}$. Our results allow us to estimate the
probability of detecting young quasars with $t_{\rm Q}\leq0.1$ Myr from their
proximity zone sizes yielding $p\left(\leq 0.1~{\rm
Myr}\right)=0.19^{+0.11}_{-0.09}$, which is broadly consistent with recent
determination at $z\sim 6$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""}]","2021-05-12"
"2102.04478","Marion Wienen","M. Wienen, F. Wyrowski, C. M. Walmsley, T. Csengeri, T. Pillai, A.
  Giannetti and K. M. Menten","ATLASGAL -- selected massive clumps in the inner Galaxy. IX. Deuteration
  of ammonia",,"A&A 649, A21 (2021)","10.1051/0004-6361/201731208",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deuteration has been used as a tracer of the evolutionary phases of low- and
high-mass star formation. The APEX Telescope Large Area Survey (ATLASGAL)
provides an important repository for a detailed statistical study of massive
star-forming clumps in the inner Galactic disc at different evolutionary
phases. We study the amount of deuteration using NH2D in a representative
sample of high-mass clumps discovered by the ATLASGAL survey covering various
evolutionary phases of massive star formation. Unbiased spectral line surveys
at 3 mm were thus conducted towards ATLASGAL clumps between 85 and 93 GHz with
the Mopra telescope and from 84 to 115 GHz using the IRAM 30m telescope. A
subsample was followed up in the NH2D transition at 74 GHz with the IRAM 30m
telescope. We determined the deuterium fractionation from the column density
ratio of NH2D and NH3 and measured the NH2D excitation temperature for the
first time from the simultaneous modelling of the 74 and 110 GHz line using
MCWeeds. We find a large range of the NH2D to NH3 column density ratio up to
1.6+/-0.7 indicating a high degree of NH3 deuteration in a subsample of the
clumps. Our analysis yields a clear difference between NH3 and NH2D rotational
temperatures for a fraction of the sources. We therefore advocate observation
of the NH2D transitions at 74 and 110 GHz simultaneously to determine the NH2D
temperature directly. We determine a median ortho-to-para column density ratio
of 3.7+/-1.2. The high detection rate of NH2D confirms a high deuteration
previously found in massive star-forming clumps. Using the excitation
temperature of NH2D instead of NH3 is needed to avoid an overestimation of
deuteration. We measure a higher detection rate of NH2D in sources at early
evolutionary stages. The deuterium fractionation shows no correlation with
evolutionary tracers such as the NH3 (1,1) line width, or rotational
temperature.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:03 GMT""}]","2021-05-05"
"2102.04479","Biao Lian","Biao Lian and Fang Xie and B. Andrei Bernevig","Open Momentum Space Method for Hofstadter Butterfly and the Quantized
  Lorentz Susceptibility","5+30 pages, 3+4 figures","Phys. Rev. B 103, 161405 (2021)","10.1103/PhysRevB.103.L161405",,"cond-mat.mes-hall math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a generic $\mathbf{k}\cdot \mathbf{p}$ open momentum space method
for calculating the Hofstadter butterfly of both continuum (Moir\'e) models and
tight-binding models, where the quasimomentum is directly substituted by the
Landau level (LL) operators. By taking a LL cutoff (and a reciprocal lattice
cutoff for continuum models), one obtains the Hofstadter butterfly with in-gap
spectral flows. For continuum models such as the Moir\'e model for twisted
bilayer graphene, our method gives a sparse Hamiltonian, making it much more
efficient than existing methods. The spectral flows in the Hofstadter gaps can
be understood as edge states on a momentum space boundary, from which one can
determine the two integers ($t_\nu,s_\nu$) of a gap $\nu$ satisfying the
Diophantine equation. The spectral flows can also be removed to obtain a clear
Hofstadter butterfly. While $t_\nu$ is known as the Chern number, our theory
identifies $s_\nu$ as a dual Chern number for the momentum space, which
corresponds to a quantized Lorentz susceptibility $\gamma_{xy}=eBs_\nu$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 16:22:44 GMT""}]","2021-04-28"
"2102.04480","Yixuan Li","Yixuan Li","Black Holes and the Swampland: the Deep Throat revelations","29 pages, 2 figures. V2: reference added. V3: revised version
  accepted for publication in JHEP. V4: Added funding information",,"10.1007/JHEP06(2021)065","JHEP06(2021)065","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-centered bubbling solutions are black hole microstate geometries that
arise as smooth solutions of 5-dimensional $\mathcal{N}=2$ Supergravity. When
these solutions reach the scaling limit, their resulting geometries develop an
infinitely deep throat and look arbitrarily close to a black hole geometry. We
depict a connection between the scaling limit in the moduli space of Microstate
Geometries and the Swampland Distance Conjecture. The naive extension of the
Distance Conjecture implies that the distance in moduli space between a
reference point and a point approaching the scaling limit is set by the proper
length of the throat as it approaches the scaling limit. Independently, we also
compute a distance in the moduli space of 3-centre solutions, from the K\""ahler
structure of its phase space using quiver quantum mechanics. We show that the
two computations of the distance in moduli space do not agree and comment on
the physical implications of this mismatch.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:00:07 GMT""},{""version"":""v2"",""created"":""Sat, 13 Mar 2021 15:42:51 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 08:59:30 GMT""},{""version"":""v4"",""created"":""Mon, 19 Jul 2021 16:27:28 GMT""}]","2021-07-20"
"2102.04481","Marzieh Shahmandi","Marzieh Shahmandi, Paul Wilson, and Mike Thelwall","A Bayesian Hurdle Quantile Regression Model for Citation Analysis with
  Mass Points at Lower Values","Accepted in Quantitative Science Studies",,,,"stat.ME cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantile regression presents a complete picture of the effects on the
location, scale, and shape of the dependent variable at all points, not just
the mean. We focus on two challenges for citation count analysis by quantile
regression: discontinuity and substantial mass points at lower counts. A
Bayesian hurdle quantile regression model for count data with a substantial
mass point at zero was proposed by King and Song (2019). It uses quantile
regression for modeling the nonzero data and logistic regression for modeling
the probability of zeros versus nonzeros. We show that substantial mass points
for low citation counts will nearly certainly also affect parameter estimation
in the quantile regression part of the model, similar to a mass point at zero.
We update the King and Song model by shifting the hurdle point past the main
mass points. This model delivers more accurate quantile regression for
moderately to highly cited articles, especially at quantiles corresponding to
values just beyond the mass points, and enables estimates of the extent to
which factors influence the chances that an article will be low cited. To
illustrate the potential of this method, it is applied to simulated citation
counts and data from Scopus.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:03:35 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 09:44:06 GMT""}]","2021-07-14"
"2102.04482","Zhaofu Zhang","Jiaqi Chen, Zhaofu Zhang, Yuzheng Guo, and John Robertson","Schottky Barrier Heights of Defect-free Metal/ZnO, CdO, MgO and SrO
  Interfaces","13 pages, 6 figures",,"10.1063/5.0047447",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The Schottky barrier heights (SBHs) of defect-free interfaces of ZnO, CdO,
MgO and SrO with various metals and different terminations are investigated by
density functional supercell calculations. The oxide bands are corrected for
their density functional band gap error by applying U-type treatment to their
metal-d and O-p states where necessary. The p-type SBHs are found to decrease
linearly with increasing metal work function. The pinning factor S of the
non-polar and polar interfaces are similar for each oxide. S is found to be
0.26, 0.56, 0.74 and 0.96 for CdO, ZnO, MgO and SrO, respectively, with S
increasing for increased oxide ionicity. The calculated pinning factors are
generally consistent with the metal-induced gap states (MIGS) model in terms of
variation with ionicity and dielectric constant. A significant shift of SBHs
from the non-polar to the polar interfaces of 0.4 eV, 1 eV and 0.5 eV for ZnO,
MgO and SrO, respectively, can be explained by an interfacial dipole. Our
results are also useful to describe Co,Fe|MgO interfaces in magnetic tunnel
junctions.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:04:26 GMT""}]","2021-05-19"
"2102.04483","Matthew Pearce","M. J. Pearce, K. G\""otze, A. Szab\'o, T. S. Sikkenk, M. R. Lees, A. T.
  Boothroyd, D. Prabhakaran, C. Castelnovo, P. A. Goddard","Monopole density and antiferromagnetic domain control in spin-ice
  iridates","29 pages, 11 figures",,"10.1038/s41467-022-27964-y",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Frustration in magnetic systems is fertile ground for complex behaviour,
including unconventional ground states with emergent symmetries, topological
properties, and exotic excitations. A canonical example is the emergence of
magnetic-charge-carrying quasiparticles in spin-ice compounds. Despite
extensive work, a reliable experimental indicator of the density of these
magnetic monopoles in spin-ice systems is yet to be found. Here, using
measurements on single crystals of Ho$_{2}$Ir$_{2}$O$_{7}$ in combination with
dipolar Monte Carlo simulations, we show that the magnetoresistance is highly
sensitive to the density of monopoles. Moreover, we find that for the
orientations of magnetic field in which the monopole density is enhanced, a
strong coupling emerges between the magnetic charges on the holmium sublattice
and the antiferromagnetically ordered iridium ions, leading to an ability to
manipulate the antiferromagnetic domains via a uniform external field. Our
results pave the way to a quantitative experimental measure of monopole density
and provide a powerful illustration of the interplay between the various
magnetic and electronic degrees of freedom in the frustrated pyrochlore
iridates. This interdependence holds promise for potential functional
properties arising from the link between magnetic and electric charges, as well
as for the control of antiferromagnetic domain walls, a key goal in the design
of next-generation spintronic devices.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:07:00 GMT""}]","2022-03-02"
"2102.04484","Gongjun Choi","Gongjun Choi, Tsutomu T. Yanagida, Norimi Yokozaki","Charms of Strongly Interacting Conformal Gauge Mediation","8 pages, 2 figures, 1 table","JHEP05(2021)113","10.1007/JHEP05(2021)113",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By extending a previously proposed conformal gauge mediation model, we
construct a gauge-mediated SUSY breaking (GMSB) model where a SUSY-breaking
scale, a messenger mass, the $\mu$-parameter and the gravitino mass in a
minimal supersymmetric (SUSY) Standard Model (MSSM) are all explained by a
single mass scale, a R-symmetry breaking scale. We focus on a low scale
SUSY-breaking scenario with the gravitino mass $m_{3/2}=\mathcal{O}(1){\rm
eV}$, which is free from the cosmological gravitino problem and relaxes the
fine-tuning of the cosmological constant. Both the messenger and SUSY-breaking
sectors are subject to a hidden strong dynamics with the conformality above the
messenger mass threshold (and hence the name of the model ""strongly interacting
conformal gauge mediation""). In our model, the Higgs B-term is suppressed and a
large $\tan\beta$ is predicted, resulting in the relatively light second
CP-even Higgs and the CP-odd Higgs with a sizable production cross section.
These Higgs bosons can be tested at future LHC experiments.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:07:24 GMT""}]","2021-05-18"
"2102.04485","Karen Mulleners","S\'ebastien Le Fouest, Julien Deparday, Karen Mulleners","The dynamics and timescales of static stall",,,"10.1016/j.jfluidstructs.2021.103304",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Airfoil stall plays a central role in the design of safe and efficient
lifting surfaces. We typically distinguish between static and dynamic stall
based on the unsteady rate of change of an airfoil's angle of attack. Despite
the somewhat misleading denotation, the force and flow development of an
airfoil undergoing static stall are highly unsteady and the boundary with
dynamic stall is not clearly defined. We experimentally investigate the forces
acting on a two-dimensional airfoil that is subjected to two manoeuvres leading
to static stall: a slow continuous increase in angle of attack with a reduced
pitch rate of 1.3e-4 and a step-wise increase in angle of attack from
14.2{\deg} to 14.8{\deg} within 0.04 convective times. We systematically
quantify the stall reaction delay for many repetitions of these two manoeuvres.
The onset of flow stall is marked by the distinct drop in the lift coefficient.
The reaction delay for the slow continuous ramp-up manoeuvre is not influenced
by the blade kinematics and its occurrence histogram is normally distributed
around 32 convective times. The static reaction delay is compared with dynamic
stall delays for dynamic ramp-up motions with reduced pitch rates ranging from
9e-4 to 0.14 and for dynamic sinusoidal pitching motions of different airfoils
at higher Reynolds numbers up to 1e6. The stall delays for all conditions
follows the same power law decrease from 32 convective times for the most
steady case down to an asymptotic value of 3 for reduced pitch rates above
0.04. Static stall is not phenomenologically different than dynamic stall and
is merely a typical case of stall for low pitch rates. Based on our results, we
suggest that conventional measurements of the static stall angle and the static
load curves should be conducted using a continuous and uniform ramp-up motion
at a reduced frequency around 1e-4.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:12:13 GMT""}]","2021-06-04"
"2102.04486","Raul Jimenez","David Valcin, Raul Jimenez, Licia Verde, Jose Luis Bernal, Benjamin D.
  Wandelt","The Age of the Universe with Globular Clusters: Reducing Systematic
  Uncertainties","Matches accepted version to JCAP. New version includes a new appendix
  comparing our independently determined distances to GC to those of GAIA DR3;
  we find excellent agreement","JCAP. JCAP08(2021)017","10.1088/1475-7516/2021/08/017",,"astro-ph.GA astro-ph.CO astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dominant systematic uncertainty in the age determination of galactic
globular clusters is the depth of the convection envelope of the stars. This
parameter is partially degenerate with metallicity which is in turn degenerate
with age. However, if the metal content, distance and extinction are known, the
position and morphology of the red giant branch in a color-magnitude diagram
are mostly sensitive to the value of the depth of the convective envelope.
Therefore, using external, precise metallicity determinations this degeneracy
and thus the systematic error in age, can be reduced. Alternatively, the
morphology of the red giant branch of globular clusters color magnitude diagram
can also be used to achieve the same. We demonstrate that globular cluster red
giant branches are well fitted by values of the depth of the convection
envelope consistent with those obtained for the Sun and this finding is robust
to the adopted treatment of the stellar physics. With these findings, the
uncertainty in the depth of the convection envelope is no longer the dominant
contribution to the systematic error in the age determination of the oldest
globular clusters, reducing it from $0.5$ to $0.23$ or $0.33$ Gyr, depending on
the methodology adopted: i.e., whether resorting to external data
(spectroscopic metallicity determinations) or relying solely on the morphology
of the clusters's color-magnitude diagrams. This results in an age of the
Universe $t_{\rm U}=13.5^{+0.16}_{-0.14} {\rm (stat.)} \pm 0.23(0.33) ({\rm
sys.})$ at 68\% confidence level, accounting for the formation time of globular
clusters and its uncertainty. An uncertainty of 0.27(0.36) Gyr if added in
quadrature. This agrees well with $13.8 \pm 0.02$ Gyr, the cosmological
model-dependent value inferred by the Planck mission assuming the $\Lambda$CDM
model.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:13:06 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 12:05:59 GMT""}]","2022-01-24"
"2102.04487","Divyansh Jhunjhunwala","Divyansh Jhunjhunwala, Advait Gadhikar, Gauri Joshi, Yonina C. Eldar","Adaptive Quantization of Model Updates for Communication-Efficient
  Federated Learning","Accepted to ICASSP 2021",,,,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communication of model updates between client nodes and the central
aggregating server is a major bottleneck in federated learning, especially in
bandwidth-limited settings and high-dimensional models. Gradient quantization
is an effective way of reducing the number of bits required to communicate each
model update, albeit at the cost of having a higher error floor due to the
higher variance of the stochastic gradients. In this work, we propose an
adaptive quantization strategy called AdaQuantFL that aims to achieve
communication efficiency as well as a low error floor by changing the number of
quantization levels during the course of training. Experiments on training deep
neural networks show that our method can converge in much fewer communicated
bits as compared to fixed quantization level setups, with little or no impact
on training and test accuracy.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:14:21 GMT""}]","2021-02-10"
"2102.04488","Yiming Wang","Yiming Wang, Hang Lv, Daniel Povey, Lei Xie, Sanjeev Khudanpur","Wake Word Detection with Streaming Transformers","Accepted at IEEE ICASSP 2021. 5 pages, 3 figures",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern wake word detection systems usually rely on neural networks for
acoustic modeling. Transformers has recently shown superior performance over
LSTM and convolutional networks in various sequence modeling tasks with their
better temporal modeling power. However it is not clear whether this advantage
still holds for short-range temporal modeling like wake word detection.
Besides, the vanilla Transformer is not directly applicable to the task due to
its non-streaming nature and the quadratic time and space complexity. In this
paper we explore the performance of several variants of chunk-wise streaming
Transformers tailored for wake word detection in a recently proposed LF-MMI
system, including looking-ahead to the next chunk, gradient stopping, different
positional embedding methods and adding same-layer dependency between chunks.
Our experiments on the Mobvoi wake word dataset demonstrate that our proposed
Transformer model outperforms the baseline convolution network by 25% on
average in false rejection rate at the same false alarm rate with a comparable
model size, while still maintaining linear complexity w.r.t. the sequence
length.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:14:32 GMT""}]","2021-02-10"
"2102.04491","Farhan Rana","Arjan Singh, Okan Koksal, Nicholas Tanen, Jonathan McCandless, Debdeep
  Jena, Huili (Grace) Xing, Hartwin Peelaers, Farhan Rana","Ultrafast Dynamics of Gallium Vacancy Charge States in
  $\beta$-Ga$_2$O$_3$","8 pages, 6 figures","Phys. Rev. Research 3, 023154 (2021)","10.1103/PhysRevResearch.3.023154",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point defects in crystalline materials often occur in multiple charge states.
Although many experimental methods to study and explore point defects are
available, techniques to explore the non-equilibrium dynamics of the charge
states of these defects at ultrafast (sub-nanosecond) time scales have not been
discussed before. We present results from ultrafast optical-pump
supercontinuum-probe spectroscopy measurements on $\beta$-Ga$_2$O$_3$. The
study of point defects in $\beta$-Ga$_2$O$_3$ is essential for its
establishment as a material platform for high-power electronics and deep-UV
optoelectronics. Use of a supercontinuum probe allows us to obtain the
time-resolved absorption spectra of material defects under non-equilibrium
conditions with picosecond time resolution. The probe absorption spectra shows
defect absorption peaks at two energies, $\sim$2.2 eV and $\sim$1.63 eV, within
the 1.3-2.5 eV probe energy bandwidth. The strength of the absorption
associated with each peak is time-dependent and the spectral weight shifts from
the lower energy peak to the higher energy peak with pump-probe delay. Further,
maximum defect absorption is seen for probe polarized along the crystal c-axis.
The time-dependent probe absorption spectra and the observed dynamics for all
probe wavelengths at all pump-probe delays can be fit with a set of rate
equations for a single multi-level defect. Based on first-principles
calculations within hybrid density functional theory we attribute the observed
absorption features to optical transitions from the valence band to different
charge states of Gallium vacancies. Our results demonstrate that broadband
ultrafast supercontinuum spectroscopy can be a useful tool to explore charge
states of defects and defect dynamics in semiconductors.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:18:07 GMT""}]","2021-06-02"
"2102.04492","Judah Unmuth-Yockey","Mingwei Dai, Jack Laiho, Marc Schiffer, Judah Unmuth-Yockey","Newtonian Binding from Lattice Quantum Gravity","15 pages, 18 figures, one table, includes appendix","Phys. Rev. D 103, 114511 (2021)","10.1103/PhysRevD.103.114511","FERMILAB-PUB-21-037-QIS-T","hep-lat gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study scalar fields propagating on Euclidean dynamical triangulations
(EDT). In this work we study the interaction of two scalar particles, and we
show that in the appropriate limit we recover an interaction compatible with
Newton's gravitational potential in four dimensions. Working in the quenched
approximation, we calculate the binding energy of a two-particle bound state,
and we study its dependence on the constituent particle mass in the
non-relativistic limit. We find a binding energy compatible with what one
expects for the ground state energy by solving the Schr\""{o}dinger equation for
Newton's potential. Agreement with this expectation is obtained in the
infinite-volume, continuum limit of the lattice calculation, providing
non-trivial evidence that EDT is in fact a theory of gravity in four
dimensions. Furthermore, this result allows us to determine the lattice spacing
within an EDT calculation for the first time, and we find that the various
lattice spacings are smaller than the Planck length, suggesting that we can
achieve a separation of scales and that there is no obstacle to taking a
continuum limit. This lends further support to the asymptotic safety scenario
for gravity.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:18:12 GMT""}]","2021-06-30"
"2102.04493","Miguel D. Bustamante","Miguel D. Bustamante, Pauline Mellon, M. Victoria Velasco","Determining when an algebra is an evolution algebra",,"Mathematics 2020, 8, 1349","10.3390/math8081349",,"math.RA","http://creativecommons.org/licenses/by/4.0/","  Evolution algebras are non-associative algebras that describe non-Mendelian
hereditary processes and have connections with many other areas. In this paper
we obtain necessary and sufficient conditions for a given algebra $A$ to be an
evolution algebra. We prove that the problem is equivalent to the so-called
$SDC$ $problem$, that is, the $simultaneous$ $diagonalisation$ $via$
$congruence$ of a given set of matrices. More precisely we show that an
$n$-dimensional algebra $A$ is an evolution algebra if, and only if, a certain
set of $n$ symmetric $n\times n$ matrices $\{M_{1}, \ldots, M_{n}\}$ describing
the product of $A$ are $SDC$. We apply this characterisation to show that while
certain classical genetic algebras (representing Mendelian and auto-tetraploid
inheritance) are not themselves evolution algebras, arbitrarily small
perturbations of these are evolution algebras. This is intriguing as evolution
algebras model asexual reproduction unlike the classical ones.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:22:02 GMT""}]","2021-02-10"
"2102.04494","Ananya Mukherjee","Ujjal Kumar Dey, Tapoja Jha, Ananya Mukherjee, Nirakar Sahoo","Leptogenesis in an extended seesaw model with $U(1)_{B-L}$ symmetry","32 pages, 13 figures, 4 tables; updated references; new discussions
  added; matches published version","J. Phys. G: Nucl. Part. Phys. 50 (2023)015004","10.1088/1361-6471/ac9fe5",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have explored an extended seesaw model accommodating a keV sterile
neutrino adopting $U(1)_{B-L}$ symmetry. This model provides a natural platform
for achieving resonant leptogenesis to account for the observed baryon
asymmetry of the Universe. The required lepton asymmetry is sourced by the CP
violating decay of the lightest heavy right handed neutrino to Standard Model
leptons and Higgs. The presence of the light sterile neutrino in the model
brings out an enhancement in the final lepton asymmetry through an additional
self-energy contribution. Adopting a proper treatment for all the washout
processes this framework strictly favors a strong washout regime thereby
protecting the low energy neutrino mass parameters in agreement with the
present neutrino and cosmology data. This framework of extended seesaw scheme
offers the source of matter-antimatter asymmetry without any severe fine tuning
of the Yukawa couplings governing the tiny neutrino mass. We also comment on
the half-life period for the neutrino less double beta decay process in the
background of having a keV sterile neutrino satisfying all the constraints
which guide the explanation for the observed baryon asymmetry of the Universe.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:23:07 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 03:46:42 GMT""},{""version"":""v3"",""created"":""Tue, 6 Dec 2022 19:43:24 GMT""}]","2022-12-08"
"2102.04495","Sergey Zagorodnyuk","Sergey M. Zagorodnyuk","On the truncated multidimensional moment problems in $\mathbb{C}^n$","Corollary 1 was corrected",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of finding a (non-negative) measure $\mu$ on
$\mathfrak{B}(\mathbb{C}^n)$ such that $\int_{\mathbb{C}^n}
\mathbf{z}^{\mathbf{k}} d\mu(\mathbf{z}) = s_{\mathbf{k}}$, $\forall
\mathbf{k}\in\mathcal{K}$. Here $\mathcal{K}$ is an arbitrary finite subset of
$\mathbb{Z}^n_+$, which contains $(0,...,0)$, and $s_{\mathbf{k}}$ are
prescribed complex numbers (we use the usual notations for multi-indices).
There are two possible interpretations of this problem. At first, one may
consider this problem as an extension of the truncated multidimensional moment
problem on $\mathbb{R}^n$, where the support of the measure $\mu$ is allowed to
lie in $\mathbb{C}^n$. Secondly, the moment problem is a particular case of the
truncated moment problem in $\mathbb{C}^n$, with special truncations. We give
simple conditions for the solvability of the above moment problem. As a
corollary, we have an integral representation with a non-negative measure for
linear functionals on some linear subspaces of polynomials.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:32:05 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 13:10:51 GMT""}]","2021-02-12"
"2102.04496","Sanjib Sharma","Sanjib Sharma, Ben Seiyon Lee, Robert E. Nicholas, Klaus Keller","A safety factor approach to designing urban infrastructure for dynamic
  conditions",,,"10.1029/2021EF002118",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Current approaches to design flood-sensitive infrastructure typically assume
a stationary rainfall distribution and neglect many uncertainties. These
assumptions are inconsistent with observations that suggest intensifying
extreme precipitation events and the uncertainties surrounding projections of
the coupled natural-human systems. Here we demonstrate a safety factor approach
to designing urban infrastructure in a changing climate. Our results show that
assuming climate stationarity and neglecting deep uncertainties can drastically
underestimate flood risks and lead to poor infrastructure design choices. We
find that climate uncertainty dominates the socioeconomic and engineering
uncertainties that impact the hydraulic reliability in stormwater drainage
systems. We quantify the upfront costs needed to achieve higher hydraulic
reliability and robustness against the deep uncertainties surrounding
projections of rainfall, surface runoff characteristics, and infrastructure
lifetime. Depending on the location, we find that adding safety factors of 1.4
to 1.7 to the standard stormwater pipe design guidance produces robust
performance to the considered deep uncertainties. The insights gained from this
study highlight the need for updating traditional engineering design strategies
to improve infrastructure reliability under socioeconomic and environmental
changes.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:35:25 GMT""},{""version"":""v2"",""created"":""Sun, 28 Mar 2021 16:20:38 GMT""},{""version"":""v3"",""created"":""Tue, 30 Mar 2021 01:26:23 GMT""},{""version"":""v4"",""created"":""Sun, 29 Aug 2021 16:08:51 GMT""}]","2022-01-11"
"2102.04497","Alessandro Geraldini","Alessandro Geraldini, Matt Landreman, Elizabeth Paul","An adjoint method for determining the sensitivity of island size to
  magnetic field variations","41 pages, 8 figures",,"10.1017/S0022377821000428",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An adjoint method to calculate the gradient of island width in stellarators
is presented and applied to a set of magnetic field configurations. The
underlying method of calculation of the island width is that of Cary & Hanson
(1991) (with a minor modification), and requires that the residue of the island
centre be small. Therefore, the gradient of the residue is calculated in
addition. Both the island width and the gradient calculations are verified
using an analytical magnetic field configuration introduced in Reiman &
Greenside (1986). The method is also applied to the calculation of the shape
gradient of the width of a magnetic island in an NCSX vacuum configuration with
respect to positions on a coil. A gradient-based optimization is applied to a
magnetic field configuration studied in Hanson & Cary (1984) to minimize
stochasticity by adding perturbations to a pair of helical coils. Although only
vacuum magnetic fields and an analytical magnetic field model are considered in
this work, the adjoint calculation of the island width gradient could also be
applied to a magnetohydrodynamic (MHD) equilibrium if the derivative of the
magnetic field with respect to the equilibrium parameters was known. Using the
island width gradient calculation presented here, more general gradient-based
optimization methods can be applied to design stellarators with small magnetic
islands. Moreoever, the sensitivity of the island size may itself be optimized
to ensure that coil tolerances with respect to island size are kept as high as
possible.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:44:19 GMT""}]","2021-05-19"
"2102.04498","Sibylle Driezen","Riccardo Borsato and Sibylle Driezen","Supergravity solution-generating techniques and canonical
  transformations of $\sigma$-models from $O(D,D)$","58 pages, 1 figure, 6 appendices; v2: published version, references
  and minor clarifications added, notational fixes",,"10.1007/JHEP05(2021)180",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of the flux formulation of Double Field Theory (DFT) we
employ a generalised Scherk-Schwarz ansatz and discuss the classification of
the twists that in the presence of the strong constraint give rise to constant
generalised fluxes interpreted as gaugings. We analyse the various
possibilities of turning on the fluxes $H_{ijk}, F_{ij}{}^k, Q_i{}^{jk}$ and
$R^{ijk}$, and the solutions for the twists allowed in each case. While we do
not impose the DFT (or equivalently supergravity) equations of motion, our
results provide solution-generating techniques in supergravity when applied to
a background that does solve the DFT equations. At the same time, our results
give rise also to canonical transformations of 2-dimensional $\sigma$-models, a
fact which is interesting especially because these are integrability-preserving
transformations on the worldsheet. Both the solution-generating techniques of
supergravity and the canonical transformations of 2-dimensional $\sigma$-models
arise as maps that leave the generalised fluxes of DFT and their flat
derivatives invariant. These maps include the known
abelian/non-abelian/Poisson-Lie T-duality transformations, Yang-Baxter
deformations, as well as novel generalisations of them.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:44:54 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 08:49:45 GMT""}]","2023-01-11"
"2102.04499","Emmanuel Dartois","E. Dartois, M. Chabot, T. Id Barkach, H. Rothard, P. Boduch, B.
  Aug\'e, A.N. Agnihotri","Cosmic ray sputtering yield of interstellar ice mantles: CO and CO2 ice
  thickness dependence","To appear in Astronomy & Astrophysics",,"10.1051/0004-6361/202039535",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cosmic-ray-induced sputtering is one of the important desorption mechanisms
at work in astrophysical environments. The chemical evolution observed in
high-density regions, from dense clouds to protoplanetary disks, and the
release of species condensed on dust grains, is one key parameter to be taken
into account in interpretations of both observations and models. This study is
part of an ongoing systematic experimental determination of the parameters to
consider in astrophysical cosmic ray sputtering. As was already done for water
ice, we investigated the sputtering yield as a function of ice mantle thickness
for the two next most abundant species of ice mantles, carbon monoxide and
carbon dioxide, which were exposed to several ion beams to explore the
dependence with deposited energy. These ice sputtering yields are constant for
thick films. It decreases rapidly for thin ice films when reaching the
impinging ion sputtering desorption depth. An ice mantle thickness dependence
constraint can be implemented in the astrophysical modelling of the sputtering
process, in particular close to the onset of ice mantle formation at low visual
extinctions.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:46:27 GMT""}]","2021-04-07"
"2102.04500","Jiawang Nie","Bingni Guo, Jiawang Nie, Zi Yang","Learning Diagonal Gaussian Mixture Models and Incomplete Tensor
  Decompositions","24 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies how to learn parameters in diagonal Gaussian mixture
models. The problem can be formulated as computing incomplete symmetric tensor
decompositions. We use generating polynomials to compute incomplete symmetric
tensor decompositions and approximations. Then the tensor approximation method
is used to learn diagonal Gaussian mixture models. We also do the stability
analysis. When the first and third order moments are sufficiently accurate, we
show that the obtained parameters for the Gaussian mixture models are also
highly accurate. Numerical experiments are also provided.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:49:32 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 21:58:10 GMT""}]","2021-06-10"
"2102.04501","Abhimanyu Singareddy","Abhimanyu Singareddy, Uday Kiran Reddy Sadula and Pradeep R. Nair","Is more Phase Segregation better for mixed halide perovskite devices:
  Spatial randomness, Ion migration, and Non-radiative recombination",,,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase segregation is a critical phenomenon that influences the stability and
performance of mixed halide perovskite based opto-electronic devices. In
addition to the underlying physical mechanisms, the spatial pattern and
randomness associated with the nanoscale morphology of phase segregation
significantly influence performance degradation a topic which, along with the
multitude of parameter combinations, has remained too complex to address so
far. Given this, with MAPbI1.5Br1.5 as a model system, here we address the
influence of critical factors like the spatial randomness of phase segregation,
influence of ion migration, and the effect of increased non radiative
recombination at material interfaces. Interestingly, our analytical model and
detailed statistical simulations indicate a unique trend morphology evolution
with increased phase segregation results, surprisingly, in a recovery in
efficiency while non-radiative recombination at grain/domain boundaries results
in efficiency degradation. Further, our quantitative and predictive estimates
identify critical parameters for interface states beyond which device
variability could be an important system level bottleneck. Indeed, these
estimates are broadly applicable to systems which undergo phase segregation and
have interesting implications to perovskite based optoelectronic devices from
stability concerns to engineering approaches that attempt to arrest phase
segregation.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:52:35 GMT""},{""version"":""v2"",""created"":""Sat, 5 Jun 2021 06:20:33 GMT""}]","2021-06-08"
"2102.04502","Mareike Fischer","Mareike Fischer and Michael Hendriksen","Refinement-stable Consensus Methods",,,,,"q-bio.PE math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent study, Bryant, Francis and Steel investigated the concept of
\enquote{future-proofing} consensus methods in phylogenetics. That is, they
investigated if such methods can be robust against the introduction of
additional data like extra trees or new species. In the present manuscript, we
analyze consensus methods under a different aspect of introducing new data,
namely concerning the discovery of new clades. In evolutionary biology, often
formerly unresolved clades get resolved by refined reconstruction methods or
new genetic data analyses. In our manuscript we investigate which properties of
consensus methods can guarantee that such new insights do not disagree with
previously found consensus trees but merely refine them. We call consensus
methods with this property \emph{refinement-stable}. Along these lines, we also
study two famous super tree methods, namely Matrix Representation with
Parsimony (MRP) and Matrix Representation with Compatibility (MRC), which have
also been suggested as consensus methods in the literature. While we (just like
Bryant, Francis and Steel in their recent study) unfortunately have to conclude
some negative answers concerning general consensus methods, we also state some
relevant and positive results concerning the majority rule (MR) and strict
consensus methods, which are amongst the most frequently used consensus
methods. Moreover, we show that there exist infinitely many consensus methods
which are refinement-stable and have some other desirable properties.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:52:46 GMT""}]","2021-02-10"
"2102.04503","Steve Dai","Steve Dai, Rangharajan Venkatesan, Haoxing Ren, Brian Zimmer, William
  J. Dally, Brucek Khailany","VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision
  Neural Network Inference",,,,,"cs.LG cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantization enables efficient acceleration of deep neural networks by
reducing model memory footprint and exploiting low-cost integer math hardware
units. Quantization maps floating-point weights and activations in a trained
model to low-bitwidth integer values using scale factors. Excessive
quantization, reducing precision too aggressively, results in accuracy
degradation. When scale factors are shared at a coarse granularity across many
dimensions of each tensor, effective precision of individual elements within
the tensor are limited. To reduce quantization-related accuracy loss, we
propose using a separate scale factor for each small vector of ($\approx$16-64)
elements within a single dimension of a tensor. To achieve an efficient
hardware implementation, the per-vector scale factors can be implemented with
low-bitwidth integers when calibrated using a two-level quantization scheme. We
find that per-vector scaling consistently achieves better inference accuracy at
low precision compared to conventional scaling techniques for popular neural
networks without requiring retraining. We also modify a deep learning
accelerator hardware design to study the area and energy overheads of
per-vector scaling support. Our evaluation demonstrates that per-vector scaled
quantization with 4-bit weights and activations achieves 37% area saving and
24% energy saving while maintaining over 75% accuracy for ResNet50 on ImageNet.
4-bit weights and 8-bit activations achieve near-full-precision accuracy for
both BERT-base and BERT-large on SQuAD while reducing area by 26% compared to
an 8-bit baseline.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:56:04 GMT""}]","2021-02-11"
"2102.04504","Nicole Reindl Dr.","Nicole Reindl, Veronika Schaffenroth, Semih Filiz, Stephan Geier,
  Ingrid Pelisoli and S. O. Kepler","Mysterious, Variable, and Extremely Hot: White Dwarfs Showing Ultra-High
  Excitation Lines I. Photometric Variability","24 pages, accepted for publication in A&A","A&A 647, A184 (2021)","10.1051/0004-6361/202140289",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  About 10% of all stars exhibit absorption lines of ultra-high excited (UHE)
metals (e.g. OVIII) in their optical spectra when entering the white dwarf
cooling sequence. The recent discovery of a both spectroscopic and photometric
variable UHE white dwarf led to the speculation that the UHE lines might be
created in a shock-heated circumstellar magnetosphere. We investigate
(multi-band) light curves from several ground- and space-based surveys of all
16 currently known UHE white dwarfs (including one newly discovered) and eight
white dwarfs that show only the HeII line problem, as both phenomena are
believed to be connected. We find that $75^{+8}_{-13}$% of the UHE white
dwarfs, and $75^{+9}_{-19}$% of the HeII line problem white dwarfs are
significantly photometrically variable, with periods ranging from 0.22d to
2.93d and amplitudes from a few tenth to a few hundredth mag. The high
variability rate is in stark contrast to the variability rate amongst normal
hot white dwarfs (we find $9^{+4}_{-2}$%), marking UHE and HeII line problem
white dwarfs as a new class of variable stars. The period distribution of our
sample agrees with both the orbital period distribution of post-common envelope
binaries and the rotational period distribution of magnetic white dwarfs if we
assume that the objects in our sample will spin-up as a consequence of further
contraction. The lack of increasing photometric amplitudes towards longer
wavelengths, as well as the non-detection of optical emission lines arising
from the highly irradiated face of a hypothetical secondary in the optical
spectra of our stars, makes it seem unlikely that an irradiated late type
companion is the origin of the photometric variability. Instead, we believe
that spots on the surfaces of these stars and/or geometrical effects of
circumstellar material might be responsible. (abridged)
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 19:56:52 GMT""}]","2021-04-07"
"2102.04505","Fabio Coppini","Fabio Coppini","A note on Fokker-Planck equations and graphons","Clarify role of initial conditions and better section division,
  update bibliography",,"10.1007/s10955-022-02905-7",,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Fokker-Planck equations represent a suitable description of the finite-time
behavior for a large class of particle systems as the size of the population
tends to infinity. Recently, the theory of graph limits has been introduced in
the classical mean-field framework to account for heterogeneous interactions
among particles. In many instances, such network heterogeneity is preserved in
the limit which turns from being a single Fokker-Planck equation (also known as
McKean-Vlasov) to an infinite system of non-linear partial differential
equations (PDE) coupled by means of a graphon. While appealing from an applied
viewpoint, few rigorous results exist on the graphon particle system. This note
addresses such limit system focusing on the relation between interaction
network and initial conditions: if the system initial datum and the graphon
degrees satisfy a suitable condition, a significantly simpler representation of
the solution is available. Interesting conclusions can be drawn from this
result: substantially different graphons can give rise to exactly the same
particle behavior, e.g., if the initial condition is independent of the
graphon, the particle behavior is indistinguishable from the well-known
mean-field limit as long as the graphon has constant degree; step-kernels, a
building block of graph limit theory, can be used to approximate the graphon
particle system with a finite system of Fokker-Planck equations and an explicit
rate of convergence.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:00:21 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 17:51:08 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 08:08:57 GMT""}]","2022-03-24"
"2102.04506","Boliang Zhang","Boliang Zhang, Ying Lyu, Ning Ding, Tianhao Shen, Zhaoyang Jia, Kun
  Han, Kevin Knight","A Hybrid Task-Oriented Dialog System with Domain and Task Adaptive
  Pretraining",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper describes our submission for the End-to-end Multi-domain Task
Completion Dialog shared task at the 9th Dialog System Technology Challenge
(DSTC-9). Participants in the shared task build an end-to-end task completion
dialog system which is evaluated by human evaluation and a user simulator based
automatic evaluation. Different from traditional pipelined approaches where
modules are optimized individually and suffer from cascading failure, we
propose an end-to-end dialog system that 1) uses Generative Pretraining 2
(GPT-2) as the backbone to jointly solve Natural Language Understanding, Dialog
State Tracking, and Natural Language Generation tasks, 2) adopts Domain and
Task Adaptive Pretraining to tailor GPT-2 to the dialog domain before
finetuning, 3) utilizes heuristic pre/post-processing rules that greatly
simplify the prediction tasks and improve generalizability, and 4) equips a
fault tolerance module to correct errors and inappropriate responses. Our
proposed method significantly outperforms baselines and ties for first place in
the official evaluation. We make our source code publicly available.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:02:30 GMT""}]","2021-02-10"
"2102.04507","Charles-Antoine Gu\'erin","Charles-Antoine Gu\'erin, Dylan Dumas, Anne Molcard, C\'eline Quentin,
  Bruno Zakardjian, Anthony Gramoull\'e, and Maristella Berta","High-Frequency radar measurements with CODARs in the region of Nice:
  improved calibration and performance","14 pages, 11 figures, 4 tables",,"10.1175/JTECH-D-21-0058.1",,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  We report on the installation and first results of one compact oceanographic
radar in the region of Nice for a long-term observation of the coastal surface
currents in the North-West Mediterranean Sea. We describe the specific
processing and calibration techniques which were developed at the laboratory to
produce high-quality radial surface current maps. In particular, we propose an
original self-calibration technique of the antenna patterns, which is based on
the sole analysis of the databasis and does not require any shipborne
transponder or other external transmitters. The relevance of the
self-calibration technique and the accuracy of inverted surface currents have
been assessed with the launch of 40 drifters that remained under the radar
coverage for about 10 days.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:04:14 GMT""},{""version"":""v2"",""created"":""Sat, 2 Oct 2021 15:15:24 GMT""}]","2022-01-05"
"2102.04508","Felix Werner","K. Van Houcke, E. Kozik, R. Rossi, Y. Deng, F. Werner","Physical and unphysical regimes of self-consistent many-body
  perturbation theory",,,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the standard framework of self-consistent many-body perturbation theory,
the skeleton series for the self-energy is truncated at a finite order $N$ and
plugged into the Dyson equation, which is then solved for the propagator $G_N$.
For two simple examples of fermionic models -- the Hubbard atom at half filling
and its zero space-time dimensional simplified version -- we find that $G_N$
converges when $N\to\infty$ to a limit $G_\infty\,$, which coincides with the
exact physical propagator $G_{\rm exact}\ \,$ at small enough coupling, while
$G_\infty \neq G_{\rm exact}\ \,$ at strong coupling. We also demonstrate that
it is possible to discriminate between these two regimes thanks to a criterion
which does not require the knowledge of $G_{\rm exact}\ \,$, as proposed in
[Rossi et al., PRB 93, 161102(R) (2016)].
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:06:48 GMT""}]","2021-02-10"
"2102.04509","Will Grathwohl","Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, Chris J.
  Maddison","Oops I Took A Gradient: Scalable Sampling for Discrete Distributions","Energy-Based Models, Deep generative models, MCMC sampling",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose a general and scalable approximate sampling strategy for
probabilistic models with discrete variables. Our approach uses gradients of
the likelihood function with respect to its discrete inputs to propose updates
in a Metropolis-Hastings sampler. We show empirically that this approach
outperforms generic samplers in a number of difficult settings including Ising
models, Potts models, restricted Boltzmann machines, and factorial hidden
Markov models. We also demonstrate the use of our improved sampler for training
deep energy-based models on high dimensional discrete data. This approach
outperforms variational auto-encoders and existing energy-based models.
Finally, we give bounds showing that our approach is near-optimal in the class
of samplers which propose local updates.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:08:50 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 20:36:42 GMT""}]","2021-06-08"
"2102.04510","Pavlo Sukhachov","P. O. Sukhachov, L. I. Glazman","Anomalous sound attenuation in Weyl semimetals in magnetic and
  pseudomagnetic fields","21 pages, 4 multi-panel figures; published version","Phys. Rev. B 103, 214310 (2021)","10.1103/PhysRevB.103.214310",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We evaluate the sound attenuation in a Weyl semimetal subject to a magnetic
field or a pseudomagnetic field associated with a strain. Due to the interplay
of intra- and inter-node scattering processes as well as screening, the fields
generically reduce the sound absorption. A nontrivial dependence on the
relative direction of the magnetic field and the sound wave vector, i.e., the
magnetic sound dichroism, can occur in materials with nonsymmetric Weyl nodes
(e.g., different Fermi velocities and/or relaxation times). It is found that
the sound dichroism in Weyl materials can also be activated by an external
strain-induced pseudomagnetic field. In view of the dependence on the field
direction, the dichroism may lead to a weak enhancement of the sound
attenuation compared with its value at vanishing fields.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:09:08 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 21:15:51 GMT""}]","2021-06-30"
"2102.04511","Rohini Giles","Rohini S. Giles, Thomas K. Greathouse, Joshua A. Kammer, G. Randall
  Gladstone, Bertrand Bonfond, Vincent Hue, Denis C. Grodent, Jean-Claude
  G\'erard, Maarten H. Versteeg, Scott J. Bolton, John E. P. Connerney, Steven
  M. Levin","Detection of a bolide in Jupiter's atmosphere with Juno UVS","Accepted in GRL. 21 pages, 3 figures",,"10.1029/2020GL091797",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The UVS instrument on the Juno mission recorded transient bright emission
from a point source in Jupiter's atmosphere. The spectrum shows that the
emission is consistent with a 9600-K blackbody located 225 km above the 1-bar
level and the duration of the emission was between 17 ms and 150 s. These
characteristics are consistent with a bolide in Jupiter's atmosphere. Based on
the energy emitted, we estimate that the impactor had a mass of 250-5000 kg,
which corresponds to a diameter of 1-4 m. By considering all observations made
with Juno UVS over the first 27 perijoves of the mission, we estimate an impact
flux rate of 24,000 per year for impactors with masses greater than 250-5000
kg.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:14:32 GMT""}]","2021-04-07"
"2102.04512","Akarsh Venkatasubramanian","Aryan Mahindra, Anshuman Sharma, Priyanshi Katiyar, Rohan Sukumaran,
  Ishaan Singh, Albert Johnson, Kasia Jakimowicz, Akarsh Venkatasubramanian,
  Chandan CV, Shailesh Advani, Rohan Iyer, Sheshank Shankar, Saurish
  Srivastava, Sethuraman TV, Abhishek Singh, Ramesh Raskar","Paper card-based vs application-based vaccine credentials: a comparison","10 pages, 4 figures",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  In this early draft, we provide an overview on similarities and differences
in the implementation of a paper card-based vaccine credential system and an
app-based vaccine credential system. A vaccine credential's primary goal is to
regulate entry and ensure safety of individuals within densely packed public
locations and workspaces. This is critical for containing the rapid spread of
Covid-19 in densely packed public locations since a single individual can
infect a large majority of people in a crowd. A vaccine credential can also
provide information such as an individual's Covid-19 vaccination history and
adverse symptom reaction history to judge their potential impact on the overall
health of individuals within densely packed public locations and workspaces.
After completing the comparisons, we believe a card-based implementation will
benefit regions with less socioeconomic mobility, limited resources, and
stagnant administrations. An app-based implementation on the other hand will
benefit regions with equitable internet access and lower technological divide.
We also believe an interoperable system of both credential systems will work
best for regions with enormous working-class populations and dense housing
clusters.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:14:53 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 03:36:01 GMT""},{""version"":""v3"",""created"":""Fri, 26 Mar 2021 21:47:02 GMT""},{""version"":""v4"",""created"":""Thu, 29 Apr 2021 22:37:03 GMT""},{""version"":""v5"",""created"":""Tue, 25 Jan 2022 07:32:34 GMT""}]","2022-01-26"
"2102.04513","Mima Stanojkovski","Delaram Kahrobaei and Mima Stanojkovski","Cryptographic multilinear maps using pro-p groups","To appear in Advances in Mathematics of Communications",,,,"cs.CR math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To any nilpotent group of class n, one can associate a non-interactive key
exchange protocol between n+1 users. The multilinear commutator maps associated
to nilpotent groups play a key role in this protocol. In the present paper, we
discuss the security of this key exchange when applied to finite p-groups and
explore some alternative platforms, such as pro-p groups.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:23:55 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 13:19:50 GMT""}]","2021-07-20"
"2102.04514","Jocelyn Thiebaut","St\'ephane Bessy, Jocelyn Thiebaut","Complementary cycles of any length in regular bipartite tournaments","22 pages, 5 figures",,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $D$ be a $k$-regular bipartite tournament on $n$ vertices. We show that,
for every $p$ with $2 \le p \le n/2-2$, $D$ has a cycle $C$ of length $2p$ such
that $D \setminus C$ is hamiltonian unless $D$ is isomorphic to the special
digraph $F_{4k}$. This statement was conjectured by Manoussakis, Song and Zhang
[K. Zhang, Y. Manoussakis, and Z. Song. Complementary cycles containing a fixed
arc in diregular bipartite tournaments. Discrete Mathematics,
133(1-3):325--328,1994]. In the same paper, the conjecture was proved for $p=2$
and more recently Bai, Li and He gave a proof for $p=3$ [Y. Bai, H. Li, and W.
He. Complementary cycles in regular bipartite tournaments. Discrete
Mathematics, 333:14--27, 2014].
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:27:24 GMT""}]","2021-02-10"
"2102.04515","Gulshan Saleem","Nisar Ahmed, Hafiz Muhammad Shahzad Asif, Gulshan Saleem","Leaf Image-based Plant Disease Identification using Color and Texture
  Features",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Identification of plant disease is usually done through visual inspection or
during laboratory examination which causes delays resulting in yield loss by
the time identification is complete. On the other hand, complex deep learning
models perform the task with reasonable performance but due to their large size
and high computational requirements, they are not suited to mobile and handheld
devices. Our proposed approach contributes automated identification of plant
diseases which follows a sequence of steps involving pre-processing,
segmentation of diseased leaf area, calculation of features based on the
Gray-Level Co-occurrence Matrix (GLCM), feature selection and classification.
In this study, six color features and twenty-two texture features have been
calculated. Support vector machines is used to perform one-vs-one
classification of plant disease. The proposed model of disease identification
provides an accuracy of 98.79% with a standard deviation of 0.57 on 10-fold
cross-validation. The accuracy on a self-collected dataset is 82.47% for
disease identification and 91.40% for healthy and diseased classification. The
reported performance measures are better or comparable to the existing
approaches and highest among the feature-based methods, presenting it as the
most suitable method to automated leaf-based plant disease identification. This
prototype system can be extended by adding more disease categories or targeting
specific crop or disease categories.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:32:56 GMT""}]","2021-02-10"
"2102.04516","Alice Minelli","A. Minelli, A. Mucciarelli, D. Romano, M. Bellazzini, L. Origlia, F.
  R. Ferraro","A homogeneous comparison between the chemical composition of the Large
  Magellanic Cloud and the Sagittarius dwarf galaxy","21 pages, 8 figures, Accepted for publication by ApJ",,"10.3847/1538-4357/abe3f9",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Similarities in the chemical composition of two of the closest Milky Way
satellites, namely the Large Magellanic Cloud (LMC) and the Sagittarius (Sgr)
dwarf galaxy, have been proposed in the literature, suggesting similar chemical
enrichment histories between the two galaxies. This proposition, however, rests
on different abundance analyses, which likely introduce various systematics
that hamper a fair comparison among the different data sets. In order to bypass
this issue (and highlight real similarities and differences between their
abundance patterns), we present a homogeneous chemical analysis of 30 giant
stars in LMC, 14 giant stars in Sgr and 14 giants in the Milky Way, based on
high-resolution spectra taken with the spectrograph UVES-FLAMES. The LMC and
Sgr stars, in the considered metallicity range ([Fe/H]>-1.1 dex), show very
similar abundance ratios for almost all the elements, with differences only in
the heavy s-process elements Ba, La and Nd, suggesting a different contribution
by asymptotic giant branch stars. On the other hand, the two galaxies have
chemical patterns clearly different from those measured in the Galactic stars,
especially for the elements produced by massive stars. This finding suggests
the massive stars contributed less to the chemical enrichment of these galaxies
with respect to the Milky Way. The derived abundances support similar chemical
enrichment histories for the LMC and Sgr.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:33:41 GMT""}]","2021-04-14"
"2102.04517","Alex Lu","Alex Lu, Aleksandr Lukatskiy, Zhiqi Zhong, and John G. Allen","Power Off! Challenges in Planning and Executing Power Isolations on
  Shared-Use Electrified Railways","26 pages, 6 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Electric railways are fast, clean, and safe, but complex to operate and
maintain. Electric traction infrastructure includes signal power and feeder
lines that remain live during isolations and complicate maintenance processes.
Stakeholders involved in power outage planning include contractors, linemen,
groundmen, power directors, dispatchers, conductor-flag, and support personnel.
Weekly planning processes for track time requires many contingencies due to
large number of moving parts and factors not known in advance, like personnel
availability. Electrical and mechanical environments faced by crews working in
adjacent areas may be entirely different and require a ""bespoke"" circuit
configuration to de-energize catenary, which must be planned meticulously.
Although recent automation improved real-time ""plate order"" communications
between power directors and dispatchers, each outage still requires many manual
switching operations. Net impact of this isolation process reduces available
construction work windows nightly from a nominal 7 hours to 2 hrs 39 mins. We
recommend joint design of electrical and civil infrastructure, cross-training
between disciplines, limiting maximum number of concurrent outages, formal
study of maintenance outage capacity, and further automation in power
switching.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:34:40 GMT""}]","2021-02-10"
"2102.04518","Forest Agostinelli","Forest Agostinelli, Alexander Shmakov, Stephen McAleer, Roy Fox,
  Pierre Baldi","A* Search Without Expansions: Learning Heuristic Functions with Deep
  Q-Networks","Added theoretical results to show that Q* search is an admissible
  search algorithm. Added comparisons to deferred heuristic evaluation. Added
  experiments with Lights Out and the 35-Pancake puzzle",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Efficiently solving problems with large action spaces using A* search has
been of importance to the artificial intelligence community for decades. This
is because the computation and memory requirements of A* search grow linearly
with the size of the action space. This burden becomes even more apparent when
A* search uses a heuristic function learned by computationally expensive
function approximators, such as deep neural networks. To address this problem,
we introduce Q* search, a search algorithm that uses deep Q-networks to guide
search in order to take advantage of the fact that the sum of the transition
costs and heuristic values of the children of a node can be computed with a
single forward pass through a deep Q-network without explicitly generating
those children. This significantly reduces computation time and requires only
one node to be generated per iteration. We use Q* search to solve the Rubik's
cube when formulated with a large action space that includes 1872 meta-actions
and find that this 157-fold increase in the size of the action space incurs
less than a 4-fold increase in computation time and less than a 3-fold increase
in number of nodes generated when performing Q* search. Furthermore, Q* search
is up to 129 times faster and generates up to 1288 times fewer nodes than A*
search. Finally, although obtaining admissible heuristic functions from deep
neural networks is an ongoing area of research, we prove that Q* search is
guaranteed to find a shortest path given a heuristic function that neither
overestimates the cost of a shortest path nor underestimates the transition
cost.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:36:41 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 17:38:09 GMT""}]","2023-03-24"
"2102.04519","Ryan Gabrys","Mahdi Cheraghchi, Ryan Gabrys, Olgica Milenkovic","Semiquantitative Group Testing in at Most Two Rounds",,,,,"cs.IT cs.DM math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semiquantitative group testing (SQGT) is a pooling method in which the test
outcomes represent bounded intervals for the number of defectives.
Alternatively, it may be viewed as an adder channel with quantized outputs.
SQGT represents a natural choice for Covid-19 group testing as it allows for a
straightforward interpretation of the cycle threshold values produced by
polymerase chain reactions (PCR). Prior work on SQGT did not address the need
for adaptive testing with a small number of rounds as required in practice. We
propose conceptually simple methods for 2-round and nonadaptive SQGT that
significantly improve upon existing schemes by using ideas on nonbinary
measurement matrices based on expander graphs and list-disjunct matrices.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:36:49 GMT""}]","2021-02-10"
"2102.04520","Yvette Perrott","Yvette C. Perrott (1 and 2), Marcos L\'opez-Caniego (3), Ricardo T.
  G\'enova-Santos (4 and 5), Jose Alberto Rubi\~no-Mart\'in (4 and 5), Mark
  Ashdown (1 and 6), Diego Herranz (7), Anne L\""ahteenm\""aki (8 and 9), Anthony
  N. Lasenby (1 and 6), Carlos H. L\'opez-Caraballo (4 and 5 and 10),
  Fr\'ed\'erick Poidevin (4 and 5), Merja Tornikoski (8) ((1) Astrophysics
  Group, Cavendish Laboratory, (2) School of Chemical and Physical Sciences,
  Victoria University of Wellington, (3) European Space Agency, ESAC, (4)
  Instituto de Astrof\'isica de Canarias (IAC), (5) Universidad de La Laguna,
  Dpto. Astrof\'isica, (6) Kavli Institute for Cosmology, University of
  Cambridge, (7) Instituto de F\'isica de Cantabria (CSIC-Universidad de
  Cantabria), (8) Aalto University Mets\""ahovi Radio Observatory, (9) Aalto
  University Department of Electronics and Nanoengineering, (10) INFN Sezione
  di Milano)","28 -- 40 GHz variability and polarimetry of bright compact sources in
  the QUIJOTE cosmological fields","17 pages, 14 figures, accepted to MNRAS",,"10.1093/mnras/stab400",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observed 51 sources in the Q-U-I JOint TEnerife (QUIJOTE) cosmological
fields which were brighter than 1 Jy at 30 GHz in the Planck Point Source
Catalogue (version 1), with the Very Large Array at 28 -- 40 GHz, in order to
characterise their high-radio-frequency variability and polarization
properties. We find a roughly log-normal distribution of polarization fractions
with a median of 2%, in agreement with previous studies, and a median rotation
measure (RM) of $\approx$ 1110 rad m$^{-2}$ with one outlier up to $\approx$
64000 rad m$^{-2}$ which is among the highest RMs measured in quasar cores. We
find hints of a correlation between the total intensity flux density and median
polarization fraction. We find 59% of sources are variable in total intensity,
and 100% in polarization at $3\sigma$ level, with no apparent correlation
between total intensity variability and polarization variability. This
indicates that it will be difficult to model these sources without simultaneous
polarimetric monitoring observations and they will need to be masked for
cosmological analysis.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:39:06 GMT""}]","2021-02-24"
"2102.04521","Chrysoula Themeli","Chrysoula Themeli, George Giannakopoulos and Nikiforos Pittaras","A study of text representations in Hate Speech Detection","14 pages, CICLing2019",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The pervasiveness of the Internet and social media have enabled the rapid and
anonymous spread of Hate Speech content on microblogging platforms such as
Twitter. Current EU and US legislation against hateful language, in conjunction
with the large amount of data produced in these platforms has led to automatic
tools being a necessary component of the Hate Speech detection task and
pipeline. In this study, we examine the performance of several, diverse text
representation techniques paired with multiple classification algorithms, on
the automatic Hate Speech detection and abusive language discrimination task.
We perform an experimental evaluation on binary and multiclass datasets, paired
with significance testing. Our results show that simple hate-keyword frequency
features (BoW) work best, followed by pre-trained word embeddings (GLoVe) as
well as N-gram graphs (NGGs): a graph-based representation which proved to
produce efficient, very low-dimensional but rich features for this task. A
combination of these representations paired with Logistic Regression or 3-layer
neural network classifiers achieved the best detection performance, in terms of
micro and macro F-measure.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:39:17 GMT""}]","2021-02-10"
"2102.04522","Konstantin Loginov","Konstantin Loginov","A note on 3-subgroups in the space Cremona group",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove that a finite $3$-group in the Cremona group
$\mathrm{Cr}_3(\mathbb{C})$ can be generated by at most $4$ elements. This
provides the last missing piece in bounding the ranks of finite $p$-subgroups
in the space Cremona group.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:40:29 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 14:09:38 GMT""}]","2021-05-05"
"2102.04523","Timo Deist","Timo M. Deist, Monika Grewal, Frank J.W.M. Dankers, Tanja
  Alderliesten, Peter A.N. Bosman","Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume
  Maximization","T.M.D. and M.G. contributed equally. Changes in new version (v2):
  improved method, added comparison to method described in old manuscript (v1),
  added experiments, added appendix, revised text",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world problems are often multi-objective with decision-makers unable to
specify a priori which trade-off between the conflicting objectives is
preferable. Intuitively, building machine learning solutions in such cases
would entail providing multiple predictions that span and uniformly cover the
Pareto front of all optimal trade-off solutions. We propose a novel approach
for multi-objective training of neural networks to approximate the Pareto front
during inference. In our approach, the neural networks are trained
multi-objectively using a dynamic loss function, wherein each network's losses
(corresponding to multiple objectives) are weighted by their hypervolume
maximizing gradients. We discuss and illustrate why training processes to
approximate Pareto fronts need to optimize on fronts of individual training
samples instead of on only the front of average losses. Experiments on three
multi-objective problems show that our approach returns outputs that are
well-spread across different trade-offs on the approximated Pareto front
without requiring the trade-off vectors to be specified a priori. Further,
results of comparisons with the state-of-the-art approaches highlight the added
value of our proposed approach, especially in asymmetric Pareto fronts.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:41:21 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 17:50:29 GMT""}]","2021-10-20"
"2102.04524","The CMS Collaboration","CMS Collaboration","Observation of a new excited beauty strange baryon decaying to
  $\Xi^-_\mathrm{b} \pi^+ \pi^-$","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/BPH-20-004
  (CMS Public Pages)","Phys. Rev. Lett. 126, 252003 (2021)","10.1103/PhysRevLett.126.252003","CMS-BPH-20-004, CERN-EP-2021-020","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The $\Xi^-_\mathrm{b} \pi^+ \pi^-$ invariant mass spectrum is investigated
with an event sample of proton-proton collisions at $\sqrt{s} = $ 13 TeV,
collected by the CMS experiment at the LHC in 2016-2018 and corresponding to an
integrated luminosity of 140 fb$^{-1}$. The ground state $\Xi^-_\mathrm{b}$ is
reconstructed via its decays to J$/\psi$ $\Xi^-$ and J$/\psi$ $\Xi^-$ $\Lambda$
K$^-$. A narrow resonance, labeled $\Xi_\mathrm{b}$(6100)$^-$, is observed at a
$\Xi^-_\mathrm{b} \pi^+ \pi^-$ invariant mass of 6100.3 $\pm$ 0.2 (stat) $\pm$
0.1 (syst) $\pm$ 0.6 ($\Xi^-_\mathrm{b}$) MeV, where the last uncertainty
reflects the precision of the $\Xi^-_\mathrm{b}$ baryon mass. The upper limit
on the $\Xi_\mathrm{b}$(6100)$^-$ natural width is determined to be 1.9 MeV at
95% confidence level. Following analogies with the established excited
$\Xi_\mathrm{c}$ baryon states, the new $\Xi_\mathrm{b}$(6100)$^-$ resonance
and its decay sequence are consistent with the orbitally excited
$\Xi^-_\mathrm{b}$ baryon, with spin and parity quantum numbers $J^P$ $=$
3/2$^-$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:42:30 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 20:32:20 GMT""}]","2021-06-30"
"2102.04525","Michael Yeung","Michael Yeung, Evis Sala, Carola-Bibiane Sch\""onlieb, Leonardo Rundo","Unified Focal loss: Generalising Dice and cross entropy-based losses to
  handle class imbalanced medical image segmentation",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic segmentation methods are an important advancement in medical image
analysis. Machine learning techniques, and deep neural networks in particular,
are the state-of-the-art for most medical image segmentation tasks. Issues with
class imbalance pose a significant challenge in medical datasets, with lesions
often occupying a considerably smaller volume relative to the background. Loss
functions used in the training of deep learning algorithms differ in their
robustness to class imbalance, with direct consequences for model convergence.
The most commonly used loss functions for segmentation are based on either the
cross entropy loss, Dice loss or a combination of the two. We propose the
Unified Focal loss, a new hierarchical framework that generalises Dice and
cross entropy-based losses for handling class imbalance. We evaluate our
proposed loss function on five publicly available, class imbalanced medical
imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction
(DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020
(BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss
function performance against six Dice or cross entropy-based loss functions,
across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating
that our proposed loss function is robust to class imbalance and consistently
outperforms the other loss functions. Source code is available at:
https://github.com/mlyg/unified-focal-loss
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:47:38 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 08:49:30 GMT""},{""version"":""v3"",""created"":""Mon, 24 May 2021 14:06:06 GMT""},{""version"":""v4"",""created"":""Wed, 24 Nov 2021 15:12:27 GMT""}]","2021-11-25"
"2102.04526","Dan Wilson","Dan Wilson","Data-Driven Inference of High-Accuracy Isostable-Based Dynamical Models
  in Response to External Inputs",,,"10.1063/5.0042874",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Isostable reduction is a powerful technique that can be used to characterize
behaviors of nonlinear dynamical systems in a basis of slowly decaying
eigenfunctions of the Koopman operator. When the underlying dynamical equations
are known, previously developed numerical techniques allow for high-order
accuracy computation of isostable reduced models. However, in situations where
the dynamical equations are unknown, few general techniques are available that
provide reliable estimates of the isostable reduced equations, especially in
applications where large magnitude inputs are considered. In this work, a
purely data-driven inference strategy yielding high-accuracy isostable reduced
models is developed for dynamical systems with a fixed point attractor. By
analyzing steady state outputs of nonlinear systems in response to sinusoidal
forcing, both isostable response functions and isostable-to-output
relationships can be estimated to arbitrary accuracy in an expansion performed
in the isostable coordinates. Detailed examples are considered for a population
of synaptically coupled neurons and for the one-dimensional Burgers' equation.
While linear estimates of the isostable response functions are sufficient to
characterize the dynamical behavior when small magnitude inputs are considered,
the high-accuracy reduced order model inference strategy proposed here is
essential when considering large magnitude inputs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:52:13 GMT""}]","2021-07-28"
"2102.04527","Michael Stuart","Markus Kneer and Michael T. Stuart","Playing the Blame Game with Robots","5 pages, 2 figures, 2 tables, HRI'21",,"10.1145/3434074.3447202",,"cs.HC cs.AI cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent research shows -- somewhat astonishingly -- that people are willing to
ascribe moral blame to AI-driven systems when they cause harm [1]-[4]. In this
paper, we explore the moral-psychological underpinnings of these findings. Our
hypothesis was that the reason why people ascribe moral blame to AI systems is
that they consider them capable of entertaining inculpating mental states (what
is called mens rea in the law). To explore this hypothesis, we created a
scenario in which an AI system runs a risk of poisoning people by using a novel
type of fertilizer. Manipulating the computational (or quasi-cognitive)
abilities of the AI system in a between-subjects design, we tested whether
people's willingness to ascribe knowledge of a substantial risk of harm (i.e.,
recklessness) and blame to the AI system. Furthermore, we investigated whether
the ascription of recklessness and blame to the AI system would influence the
perceived blameworthiness of the system's user (or owner). In an experiment
with 347 participants, we found (i) that people are willing to ascribe blame to
AI systems in contexts of recklessness, (ii) that blame ascriptions depend
strongly on the willingness to attribute recklessness and (iii) that the
latter, in turn, depends on the perceived ""cognitive"" capacities of the system.
Furthermore, our results suggest (iv) that the higher the computational
sophistication of the AI system, the more blame is shifted from the human user
to the AI system.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:53:42 GMT""}]","2021-02-10"
"2102.04528","Daniel Frisch","Daniel Frisch and Uwe D. Hanebeck","Deterministic Sampling on the Circle using Projected Cumulative
  Distributions","11 pages, 5 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  We propose a method for deterministic sampling of arbitrary continuous
angular density functions. With deterministic sampling, good estimation results
can typically be achieved with much smaller numbers of samples compared to the
commonly used random sampling. While the Unscented Kalman Filter uses
deterministic sampling as well, it only takes the absolute minimum number of
samples. Our method can draw arbitrary numbers of deterministic samples and
therefore improve the quality of state estimation. Conformity between the
continuous density function (reference) and the Dirac mixture density, i.e.,
sample locations (approximation) is established by minimizing the difference of
the cumulatives of many univariate projections. In other words, we compare
cumulatives of probability densities in the Radon space.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:59:23 GMT""}]","2021-02-10"
"2102.04529","Habiba Kalantarova","H. Kalantarova and V. Kalantarov and O. Vantzos","Chevron pattern equations: exponential attractor and global
  stabilization",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The initial boundary value problem for a nonlinear system of equations
modeling the chevron patterns is studied in one and two spatial dimensions. The
existence of an exponential attractor and the stabilization of the zero steady
state solution through application of a finite-dimensional feedback control is
proved in two spatial dimensions. The stabilization of an arbitrary fixed
solution is shown in one spatial dimension along with relevant numerical
results.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:59:24 GMT""}]","2021-02-10"
"2102.04530","Ran Cheng","Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, Bingbing Liu","(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection
  for Sparse Semantic Segmentation Network","10 pages, 6 figures, 4 tables",,,,"cs.CV cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Autonomous robotic systems and self driving cars rely on accurate perception
of their surroundings as the safety of the passengers and pedestrians is the
top priority. Semantic segmentation is one the essential components of
environmental perception that provides semantic information of the scene.
Recently, several methods have been introduced for 3D LiDAR semantic
segmentation. While, they can lead to improved performance, they are either
afflicted by high computational complexity, therefore are inefficient, or lack
fine details of smaller instances. To alleviate this problem, we propose
AF2-S3Net, an end-to-end encoder-decoder CNN network for 3D LiDAR semantic
segmentation. We present a novel multi-branch attentive feature fusion module
in the encoder and a unique adaptive feature selection module with feature map
re-weighting in the decoder. Our AF2-S3Net fuses the voxel based learning and
point-based learning into a single framework to effectively process the large
3D scene. Our experimental results show that the proposed method outperforms
the state-of-the-art approaches on the large-scale SemanticKITTI benchmark,
ranking 1st on the competitive public leaderboard competition upon publication.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:04:21 GMT""}]","2021-02-10"
"2102.04531","Francesco Ticozzi","Giacomo Baggio, Francesco Ticozzi, Peter D. Johnson, Lorenza Viola","Dissipative Encoding of Quantum Information","29 pages, 4 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We formalize the problem of dissipative quantum encoding, and explore the
advantages of using Markovian evolution to prepare a quantum code in the
desired logical space, with emphasis on discrete-time dynamics and the
possibility of exact finite-time convergence. In particular, we investigate
robustness of the encoding dynamics and their ability to tolerate
initialization errors, thanks to the existence of non-trivial basins of
attraction. As a key application, we show that for stabilizer quantum codes on
qubits, a finite-time dissipative encoder may always be constructed, by using
at most a number of quantum maps determined by the number of stabilizer
generators. We find that even in situations where the target code lacks gauge
degrees of freedom in its subsystem form, dissipative encoders afford
nontrivial robustness against initialization errors, thus overcoming a
limitation of purely unitary encoding procedures. Our general results are
illustrated in a number of relevant examples, including Kitaev's toric code.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:07:08 GMT""}]","2021-02-10"
"2102.04532","Sandhya Devi","Sandhya Devi","Asymmetric Tsallis distributions for modelling financial market dynamics","13 figures, 28 pages",,"10.1016/j.physa.2021.126109",,"q-fin.ST","http://creativecommons.org/licenses/by/4.0/","  Financial markets are highly non-linear and non-equilibrium systems. Earlier
works have suggested that the behavior of market returns can be well described
within the framework of non-extensive Tsallis statistics or superstatistics.
For small time scales (delays), a good fit to the distributions of stock
returns is obtained with q-Gaussian distributions, which can be derived either
from Tsallis statistics or superstatistics. These distributions are symmetric.
However, as the time lag increases, the distributions become increasingly
non-symmetric. In this work, we address this problem by considering the data
distribution as a linear combination of two independent normalized
distributions - one for negative returns and one for positive returns. Each of
these two independent distributions are half q-Gaussians with different
non-extensivity parameter q and temperature parameter beta. Using this model,
we investigate the behavior of stock market returns over time scales from 1 to
80 days. The data covers both the .com bubble and the 2008 crash periods. These
investigations show that for all the time lags, the fits to the data
distributions are better using asymmetric distributions than symmetric
q-Gaussian distributions. The behaviors of the q parameter are quite different
for positive and negative returns. For positive returns, q approaches a
constant value of 1 after a certain lag, indicating the distributions have
reached equilibrium. On the other hand, for negative returns, the q values do
not reach a stationary value over the time scales studied. In the present
model, the markets show a transition from normal to superdiffusive behavior (a
possible phase transition) during the 2008 crash period. Such behavior is not
observed with a symmetric q-Gaussian distribution model with q independent of
time lag.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:07:56 GMT""}]","2021-06-30"
"2102.04533","Yuting Yang","Yuting Yang, Connelly Barnes, Adam Finkelstein","Learning from Shader Program Traces",,,,,"cs.LG cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning for image processing typically treats input imagery as pixels
in some color space. This paper proposes instead to learn from program traces
of procedural fragment shaders -- programs that generate images. At each pixel,
we collect the intermediate values computed at program execution, and these
data form the input to the learned model. We investigate this learning task for
a variety of applications: our model can learn to predict a low-noise output
image from shader programs that exhibit sampling noise; this model can also
learn from a simplified shader program that approximates the reference solution
with less computation, as well as learn the output of postprocessing filters
like defocus blur and edge-aware sharpening. Finally we show that the idea of
learning from program traces can even be applied to non-imagery simulations of
flocks of boids. Our experiments on a variety of shaders show quantitatively
and qualitatively that models learned from program traces outperform baseline
models learned from RGB color augmented with hand-picked shader-specific
features like normals, depth, and diffuse and specular color.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:08:14 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 00:59:28 GMT""}]","2022-04-26"
"2102.04535","Dan Wilson","Dan Wilson","Optimal Control of Oscillation Timing and Entrainment Using Large
  Magnitude Inputs: An Adaptive Phase-Amplitude-Coordinate-Based Approach",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the high dimensionality and underlying complexity of many oscillatory
dynamical systems, phase reduction is often an imperative first step in control
applications where oscillation timing and entrainment are of interest.
Unfortunately, most phase reduction frameworks place restrictive limitations on
the magnitude of allowable inputs, limiting the practical utility of the
resulting phase reduced models in many situations. In this work, motivated by
the search for control strategies to hasten recovery from jet-lag caused by
rapid travel through multiple time zones, the efficacy of the recently
developed adaptive phase-amplitude reduction is considered for manipulating
oscillation timing in the presence of a large magnitude entraining stimulus.
The adaptive phase-amplitude reduced equations allow for a numerically
tractable optimal control formulation and the associated optimal stimuli
significantly outperform those resulting from from previously proposed optimal
control formulations. Additionally, a data-driven technique to identify the
necessary terms of the adaptive phase-amplitude reduction is proposed and
validated using a model describing the aggregate oscillations of a large
population of coupled limit cycle oscillators. Such data-driven model reduction
algorithms are essential in situations where the underlying model equations are
either unreliable or unavailable.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:14:05 GMT""}]","2021-02-10"
"2102.04536","Chris Pinner","Bishnu Paudel, Chris Pinner","Minimal Group Determinants For Dicyclic Groups",,"Moscow J. Comb. Number Th. 10 (2021) 235-248","10.2140/moscow.2021.10.235",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the minimal non-trivial integer group determinant for the
dicyclic group of order $4n$ when $n$ is odd. We also discuss the set of all
integer group determinants for the dicyclic groups of order $4p$.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:17:19 GMT""}]","2021-09-22"
"2102.04537","Elizabeth Burroughs","Elizabeth G. Arnold, Elizabeth A. Burroughs, Elizabeth W. Fulton,
  James A. Mendoza \'Alvarez","Applications of Teaching Secondary Mathematics in Undergraduate
  Mathematics Courses","To be published in 14th International Congress on Mathematical
  Education",,,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  Robust preparation of future secondary mathematics teachers requires
attention to the acquisition of mathematical knowledge for teaching. Many
future teachers learn mathematics content primarily through mathematics major
courses that are taught by mathematicians who do not specialize in teacher
preparation. How can mathematics education researchers assist mathematicians in
making explicit connections between the content of undergraduate mathematics
courses and the content of secondary mathematics? We present an articulation of
five types of connections that can be used in secondary mathematics teacher
preparation and give examples of question prompts that mathematicians can use
as applications of teaching secondary mathematics in undergraduate mathematics
courses.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:17:53 GMT""}]","2021-02-10"
"2102.04538","Mario Hern\'an Casta\~neda Garc\'ia","Mario H. Casta\~neda Garcia, Alejandro Molina-Galan, Mate Boban,
  Javier Gozalvez, Baldomero Coll-Perales, Taylan \c{S}ahin and Apostolos
  Kousaridas","A Tutorial on 5G NR V2X Communications","This tutorial paper has been accepted for publication as open access
  in the IEEE Communications Surveys & Tutorials journal. Citation information:
  DOI 10.1109/COMST.2021.3057017",,"10.1109/COMST.2021.3057017",,"eess.SP cs.IT cs.NI math.IT","http://creativecommons.org/licenses/by/4.0/","  The Third Generation Partnership Project (3GPP) has recently published its
Release 16 that includes the first Vehicle to-Everything (V2X) standard based
on the 5G New Radio (NR) air interface. 5G NR V2X introduces advanced
functionalities on top of the 5G NR air interface to support connected and
automated driving use cases with stringent requirements. This paper presents an
in-depth tutorial of the 3GPP Release 16 5G NR V2X standard for V2X
communications, with a particular focus on the sidelink, since it is the most
significant part of 5G NR V2X. The main part of the paper is an in-depth
treatment of the key aspects of 5G NR V2X: the physical layer, the resource
allocation, the quality of service management, the enhancements introduced to
the Uu interface and the mobility management for V2N (Vehicle to Network)
communications, as well as the co-existence mechanisms between 5G NR V2X and
LTE V2X. We also review the use cases, the system architecture, and describe
the evaluation methodology and simulation assumptions for 5G NR V2X. Finally,
we provide an outlook on possible 5G NR V2X enhancements, including those
identified within Release 17.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:26:58 GMT""}]","2021-02-12"
"2102.04539","Leon Kellerhals","Till Fluschnik and Leon Kellerhals","Placing Green Bridges Optimally, with a Multivariate Analysis","An extended abstract of this work appeared at CiE '21",,,,"cs.CC cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of placing wildlife crossings, such as green bridges,
over human-made obstacles to challenge habitat fragmentation. The main task
herein is, given a graph describing habitats or routes of wildlife animals and
possibilities of building green bridges, to find a low-cost placement of green
bridges that connects the habitats. We develop different problem models for
this task and study them from a computational complexity and parameterized
algorithmics perspective.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:30:33 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 13:45:14 GMT""}]","2022-08-18"
"2102.04540","Chen-Yu Wei","Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo","Last-iterate Convergence of Decentralized Optimistic Gradient
  Descent/Ascent in Infinite-horizon Competitive Markov Games",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  We study infinite-horizon discounted two-player zero-sum Markov games, and
develop a decentralized algorithm that provably converges to the set of Nash
equilibria under self-play. Our algorithm is based on running an Optimistic
Gradient Descent Ascent algorithm on each state to learn the policies, with a
critic that slowly learns the value of each state. To the best of our
knowledge, this is the first algorithm in this setting that is simultaneously
rational (converging to the opponent's best response when it uses a stationary
policy), convergent (converging to the set of Nash equilibria under self-play),
agnostic (no need to know the actions played by the opponent), symmetric
(players taking symmetric roles in the algorithm), and enjoying a finite-time
last-iterate convergence guarantee, all of which are desirable properties of
decentralized algorithms.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:45:56 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 17:16:37 GMT""}]","2021-07-08"
"2102.04541","Tobias Hofmann","Tobias Hofmann and Uwe Schwerdtfeger","Edge-connectivity matrices and their spectra",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The edge-connectivity matrix of a weighted graph is the matrix whose
off-diagonal $v$-$w$ entry is the weight of a minimum edge cut separating
vertices $v$ and $w$. Its computation is a classical topic of combinatorial
optimization since at least the seminal work of Gomory and Hu. In this article,
we investigate spectral properties of these matrices. In particular, we provide
tight bounds on the smallest eigenvalue and the energy. Moreover, we study the
eigenvector structure and show in which cases eigenvectors can be easily
obtained from matrix entries. These results in turn rely on a new
characterization of those nonnegative matrices that can actually occur as
edge-connectivity matrices.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:46:05 GMT""}]","2021-02-10"
"2102.04542","Rahul Chandan","Rahul Chandan, Dario Paccagnan and Jason R. Marden","Tractable mechanisms for computing near-optimal utility functions","13 pages, 3 figures, to appear in Proceedings of the 20th
  International Conference on Autonomous Agents and Multiagent Systems (AAMAS
  2021)",,,,"cs.GT cs.MA cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large scale multiagent systems must rely on distributed decision making, as
centralized coordination is either impractical or impossible. Recent works
approach this problem under a game theoretic lens, whereby utility functions
are assigned to each of the agents with the hope that their local optimization
approximates the centralized optimal solution. Yet, formal guarantees on the
resulting performance cannot be obtained for broad classes of problems without
compromising on their accuracy. In this work, we address this concern relative
to the well-studied problem of resource allocation with nondecreasing concave
welfare functions. We show that optimally designed local utilities achieve an
approximation ratio (price of anarchy) of 1-c/e, where c is the function's
curvature and e is Euler's constant. The upshot of our contributions is the
design of approximation algorithms that are distributed and efficient, and
whose performance matches that of the best existing polynomial-time (and
centralized) schemes.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:46:56 GMT""}]","2021-02-10"
"2102.04543","Jacob Dorn","Jacob Dorn and Kevin Guo","Sharp Sensitivity Analysis for Inverse Propensity Weighting via Quantile
  Balancing",,,,,"math.ST econ.EM stat.ME stat.TH","http://creativecommons.org/licenses/by/4.0/","  Inverse propensity weighting (IPW) is a popular method for estimating
treatment effects from observational data. However, its correctness relies on
the untestable (and frequently implausible) assumption that all confounders
have been measured. This paper introduces a robust sensitivity analysis for IPW
that estimates the range of treatment effects compatible with a given amount of
unobserved confounding. The estimated range converges to the narrowest possible
interval (under the given assumptions) that must contain the true treatment
effect. Our proposal is a refinement of the influential sensitivity analysis by
Zhao, Small, and Bhattacharya (2019), which we show gives bounds that are too
wide even asymptotically. This analysis is based on new partial identification
results for Tan (2006)'s marginal sensitivity model.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:47:23 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 18:27:27 GMT""}]","2021-04-12"
"2102.04544","David Kline","David Kline, Ayaz Hyder, Enhao Liu, Michael Rayo, Samuel Malloy,
  Elisabeth Root","A Bayesian spatio-temporal nowcasting model for public health
  decision-making and surveillance",,"American Journal of Epidemiology. 2022;191(6):1107-1115","10.1093/aje/kwac034",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  As COVID-19 spread through the United States in 2020, states began to set up
alert systems to inform policy decisions and serve as risk communication tools
for the general public. Many of these systems, like in Ohio, included
indicators based on an assessment of trends in reported cases. However, when
cases are indexed by date of disease onset, reporting delays complicate the
interpretation of trends. Despite a foundation of statistical literature to
address this problem, these methods have not been widely applied in practice.
In this paper, we develop a Bayesian spatio-temporal nowcasting model for
assessing trends in county-level COVID-19 cases in Ohio. We compare the
performance of our model to the current approach used in Ohio and the approach
that was recommended by the Centers for Disease Control and Prevention. We
demonstrate gains in performance while still retaining interpretability using
our model. In addition, we are able to fully account for uncertainty in both
the time series of cases and in the reporting process. While we cannot
eliminate all of the uncertainty in public health surveillance and subsequent
decision-making, we must use approaches that embrace these challenges and
deliver more accurate and honest assessments to policymakers.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:47:24 GMT""}]","2023-05-12"
"2102.04545","Oleg Antropov","Vladimir Ignatenko, Pekka Laurila, Andrea Radius, Leszek Lamentowski,
  Oleg Antropov, Darren Muff","ICEYE microsatellite SAR constellation status update: Evaluation of
  first commercial imaging modes",,,,,"eess.IV eess.SP physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ICEYE constellation features the first operational microsatellite based
X-band SAR sensors suitable for all weather day-and-night Earth Observation. In
this paper, we report on the status of the ICEYE Constellation and describe the
characteristics of the first operational imaging modes.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:49:19 GMT""}]","2021-02-10"
"2102.04546","Alexandre Nolin","Magn\'us M. Halld\'orsson, Alexandre Nolin","Superfast Coloring in CONGEST via Efficient Color Sampling",,,,,"cs.DC cs.DS","http://creativecommons.org/licenses/by-sa/4.0/","  We present a procedure for efficiently sampling colors in the {\congest}
model. It allows nodes whose number of colors exceeds their number of neighbors
by a constant fraction to sample up to $\Theta(\log n)$ semi-random colors
unused by their neighbors in $O(1)$ rounds, even in the distance-2 setting.
This yields algorithms with $O(\log^* \Delta)$ complexity for different
edge-coloring, vertex coloring, and distance-2 coloring problems, matching the
best possible. In particular, we obtain an $O(\log^* \Delta)$-round CONGEST
algorithm for $(1+\epsilon)\Delta$-edge coloring when $\Delta \ge
\log^{1+1/\log^*n} n$, and a poly($\log\log n$)-round algorithm for
$(2\Delta-1)$-edge coloring in general. The sampling procedure is inspired by a
seminal result of Newman in communication complexity.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:49:26 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 14:29:37 GMT""}]","2021-03-04"
"2102.04547","Kasra Yazdani","Kasra Yazdani and Matthew Hale","Asynchronous Parallel Nonconvex Optimization Under the
  Polyak-Lojasiewicz Condition","6 pages, 1 figure",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communication delays and synchronization are major bottlenecks for parallel
computing, and tolerating asynchrony is therefore crucial for accelerating
parallel computation. Motivated by optimization problems that do not satisfy
convexity assumptions, we present an asynchronous block coordinate descent
algorithm for nonconvex optimization problems whose objective functions satisfy
the Polyak-Lojasiewicz condition. This condition is a generalization of strong
convexity to nonconvex problems and requires neither convexity nor uniqueness
of minimizers. Under only assumptions of mild smoothness of objective functions
and bounded delays, we prove that a linear convergence rate is obtained.
Numerical experiments for logistic regression problems are presented to
illustrate the impact of asynchrony upon convergence.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:56:10 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 23:01:08 GMT""}]","2021-05-25"
"2102.04548","Bonny Banerjee","Bonny Banerjee, Masoumeh Heidari Kapourchali, Murchana Baruah, Mousumi
  Deb, Kenneth Sakauye, Mette Olufsen","Synthesizing Skeletal Motion and Physiological Signals as a Function of
  a Virtual Human's Actions and Emotions",,,,,"eess.SP cs.AI cs.LG q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Round-the-clock monitoring of human behavior and emotions is required in many
healthcare applications which is very expensive but can be automated using
machine learning (ML) and sensor technologies. Unfortunately, the lack of
infrastructure for collection and sharing of such data is a bottleneck for ML
research applied to healthcare. Our goal is to circumvent this bottleneck by
simulating a human body in virtual environment. This will allow generation of
potentially infinite amounts of shareable data from an individual as a function
of his actions, interactions and emotions in a care facility or at home, with
no risk of confidentiality breach or privacy invasion. In this paper, we
develop for the first time a system consisting of computational models for
synchronously synthesizing skeletal motion, electrocardiogram, blood pressure,
respiration, and skin conductance signals as a function of an open-ended set of
actions and emotions. Our experimental evaluations, involving user studies,
benchmark datasets and comparison to findings in the literature, show that our
models can generate skeletal motion and physiological signals with high
fidelity. The proposed framework is modular and allows the flexibility to
experiment with different models. In addition to facilitating ML research for
round-the-clock monitoring at a reduced cost, the proposed framework will allow
reusability of code and data, and may be used as a training tool for ML
practitioners and healthcare professionals.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 21:56:15 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 23:58:07 GMT""}]","2021-02-17"
"2102.04549","Wolfgang Lueck","Wolfgang Lueck","Survey on L^2-invariants and 3-manifolds","38 pages. This is the final version and has been accepted for
  publication in the Bulletin of the London Mathematical Society",,"10.1112/blms.12536",,"math.GT","http://creativecommons.org/licenses/by/4.0/","  In this paper give a survey about L^2-invariants focusing on 3-manifolds.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:00:18 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 07:51:45 GMT""}]","2021-09-17"
"2102.04550","Angeliki Katsenou Dr","Angeliki V. Katsenou, Joel Sole and David R. Bull","Efficient Bitrate Ladder Construction for Content-Optimized Adaptive
  Video Streaming",,,"10.1109/OJSP.2021.3086691",,"eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One of the challenges faced by many video providers is the heterogeneity of
network specifications, user requirements, and content compression performance.
The universal solution of a fixed bitrate ladder is inadequate in ensuring a
high quality of user experience without re-buffering or introducing annoying
compression artifacts. However, a content-tailored solution, based on
extensively encoding across all resolutions and over a wide quality range is
highly expensive in terms of computational, financial, and energy costs.
Inspired by this, we propose an approach that exploits machine learning to
predict a content-optimized bitrate ladder. The method extracts spatio-temporal
features from the uncompressed content, trains machine-learning models to
predict the Pareto front parameters, and, based on that, builds the ladder
within a defined bitrate range. The method has the benefit of significantly
reducing the number of encodes required per sequence. The presented results,
based on 100 HEVC-encoded sequences, demonstrate a reduction in the number of
encodes required when compared to an exhaustive search and an
interpolation-based method, by 89.06% and 61.46%, respectively, at the cost of
an average Bj{\o}ntegaard Delta Rate difference of 1.78% compared to the
exhaustive approach. Finally, a hybrid method is introduced that selects either
the proposed or the interpolation-based method depending on the sequence
features. This results in an overall 83.83% reduction of required encodings at
the cost of an average Bj{\o}ntegaard Delta Rate difference of 1.26%.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:02:06 GMT""}]","2021-11-02"
"2102.04551","Stephane Sabourau","Ivan Babenko, St\'ephane Sabourau","Minimal volume entropy and fiber growth","This paper corresponds to a corrected and extended version of the
  first part of our preprint entitled ""Minimal volume entropy of simplicial
  complexes"". arXiv admin note: substantial text overlap with arXiv:2002.11069",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article deals with topological assumptions under which the minimal
volume entropy of a closed manifold~$M$, and more generally of a finite
simplicial complex~$X$, vanishes or is positive. These topological conditions
are expressed in terms of the growth of the fundamental group of the fibers of
maps from a given finite simplicial complex~$X$ to lower dimensional simplicial
complexes~$P$. We also give examples of finite simplicial complexes with zero
simplicial volume and arbitrarily large minimal volume entropy.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:03:46 GMT""}]","2021-02-10"
"2102.04553","Maksim Buzikov","Maksim Buzikov and Andrey Galyaev","Minimum-time lateral interception of a moving target by a Dubins car","16 pages, 19 figures",,"10.1016/j.automatica.2021.109968",,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents the problem of lateral interception by a Dubins car of a
target that moves along an a priori known trajectory. This trajectory is given
by two coordinates of a planar location and one angle of a heading orientation,
every one of them is a continuous function of time. The optimal trajectory
planning problem of constructing minimum-time trajectories for a Dubins car in
the presence of a priory known time-dependent wind vector field is a special
case of the presented problem. Using the properties of the three-dimensional
reachable set of a Dubins car, it is proved that the optimal interception point
belongs to a part of an analytically described surface in the three-dimensional
space. The analytical description of the surface makes it possible to obtain 10
algebraic equations for calculating parameters of the optimal control that
implements the minimum-time lateral interception. These equations are generally
transcendental and can be simplified for particular cases of target motion
(e.g. resting target, straight-line uniform target motion). Finally, some
particular cases of the optimal lateral interception validate developments of
the paper and highlight the necessity to consider each of 10 algebraic
equations in general case.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:09:14 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 10:33:49 GMT""}]","2023-04-14"
"2102.04554","Debjit Pal","Debjit Pal, Shobha Vasudevan","Feature Engineering for Scalable Application-Level Post-Silicon
  Debugging","15 pages, 13 figures, 9 tables",,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present systematic and efficient solutions for both observability
enhancement and root-cause diagnosis of post-silicon System-on-Chips (SoCs)
validation with diverse usage scenarios. We model specification of interacting
flows in typical applications for message selection. Our method for message
selection optimizes flow specification coverage and trace buffer utilization.
We define the diagnosis problem as identifying buggy traces as outliers and
bug-free traces as inliers/normal behaviors, for which we use unsupervised
learning algorithms for outlier detection. Instead of direct application of
machine learning algorithms over trace data using the signals as raw features,
we use feature engineering to transform raw features into more sophisticated
features using domain specific operations. The engineered features are highly
relevant to the diagnosis task and are generic to be applied across any
hardware designs. We present debugging and root cause analysis of subtle
post-silicon bugs in industry-scale OpenSPARC T2 SoC. We achieve a trace buffer
utilization of 98.96\% with a flow specification coverage of 94.3\% (average).
Our diagnosis method was able to diagnose up to 66.7\% more bugs and took up to
847$\times$ less diagnosis time as compared to the manual debugging with a
diagnosis precision of 0.769.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:11:59 GMT""}]","2021-02-10"
"2102.04555","Ryan Magee","Ryan Magee, Deep Chatterjee, Leo P. Singer, Surabhi Sachdev, Manoj
  Kovalam, Geoffrey Mo, Stuart Anderson, Patrick Brady, Patrick Brockill, Kipp
  Cannon, Tito Dal Canton, Qi Chu, Patrick Clearwater, Alex Codoreanu, Marco
  Drago, Patrick Godwin, Shaon Ghosh, Giuseppe Greco, Chad Hanna, Shasvath J.
  Kapadia, Erik Katsavounidis, Victor Oloworaran, Alexander E. Pace, Fiona
  Panther, Anwarul Patwary, Roberto De Pietri, Brandon Piotrzkowski, Tanner
  Prestegard, Luca Rei, Anala K. Sreekumar, Marek J. Szczepa\'nczyk, Vinaya
  Valsan, Aaron Viets, Madeline Wade, Linqing Wen, John Zweizig","First demonstration of early warning gravitational wave alerts",,,"10.3847/2041-8213/abed54",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational-wave observations became commonplace in Advanced LIGO-Virgo's
recently concluded third observing run. 56 non-retracted candidates were
identified and publicly announced in near real time. Gravitational waves from
binary neutron star mergers, however, remain of special interest since they can
be precursors to high-energy astrophysical phenomena like $\gamma$-ray bursts
and kilonovae. While late-time electromagnetic emissions provide important
information about the astrophysical processes within, the prompt emission along
with gravitational waves uniquely reveals the extreme matter and gravity during
- and in the seconds following - merger. Rapid communication of source location
and properties from the gravitational-wave data is crucial to facilitate
multi-messenger follow-up of such sources. This is especially enabled if the
partner facilities are forewarned via an early-warning (pre-merger) alert. Here
we describe the commissioning and performance of such a low-latency
infrastructure within LIGO-Virgo. We present results from an end-to-end mock
data challenge that detects binary neutron star mergers and alerts partner
facilities before merger. We set expectations for these alerts in future
observing runs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:14:35 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 14:43:39 GMT""}]","2021-04-14"
"2102.04556","Stephan Schlamminger","Lorenz Keck, Gordon Shaw, Ren\'e Theska, Stephan Schlamminger","Design of an electrostatic balance mechanism to measure optical power of
  100 kW","11 pages, 9 figures, accepted for publication in IEEE Transactions on
  Instrumentation and Measurement",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  A new instrument is required to accommodate the need for increased
portability and accuracy in laser power measurement above 100 W. Reflection and
absorption of laser light provide a measurable force from photon momentum
exchange that is directly proportional to laser power, which can be measured
with an electrostatic balance traceable to the SI. We aim for a relative
uncertainty of $10^{-3}$ with coverage factor $k=2$. For this purpose, we have
designed a monolithic parallelogram 4-bar linkage incorporating elastic
circular notch flexure hinges. The design is optimized to address the main
factors driving force measurement uncertainty from the balance mechanism:
corner loading errors, balance stiffness, stress in the flexure hinges,
sensitivity to vibration, and sensitivity to thermal gradients. Parasitic
rotations in the free end of the 4-bar linkage during arcuate motion are
constrained by machining tolerances. An analytical model shows this affects the
force measurement less than 0.01 percent. Incorporating an inverted pendulum
reduces the stiffness of the system without unduly increasing tilt sensitivity.
Finite element modeling of the flexures is used to determine the hinge
orientation that minimizes stress which is therefore expected to minimize
hysteresis. Thermal effects are mitigated using an external enclosure to
minimize temperature gradients, although a quantitative analysis of this effect
is not carried out. These analyses show the optimized mechanism is expected to
contribute less than $10^{-3}$ relative uncertainty in the final laser power
measurement.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:16:59 GMT""}]","2021-02-10"
"2102.04557","Yan Ru Pei","Yan Ru Pei, Massimiliano Di Ventra","Non-equilibrium criticality and efficient exploration of glassy
  landscapes with memory dynamics","21 pages, 9 figures",,"10.1016/j.physa.2021.126727",,"cond-mat.dis-nn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Spin glasses are notoriously difficult to study both analytically and
numerically due to the presence of frustration and metastability. Their highly
non-convex landscapes require collective updates to explore efficiently.
Currently, most state-of-the-art algorithms rely on stochastic spin clusters to
perform non-local updates, but such ""cluster algorithms"" lack general
efficiency. Here, we introduce a non-equilibrium approach for simulating spin
glasses based on classical dynamics with memory. By simulating various classes
of 3d spin glasses (Edwards-Anderson, partially-frustrated, and
fully-frustrated models), we find that memory dynamically promotes critical
spin clusters during time evolution, in a self-organizing manner. This
facilitates an efficient exploration of the low-temperature phases of spin
glasses.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:18:57 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 16:01:16 GMT""},{""version"":""v3"",""created"":""Sat, 27 Mar 2021 21:03:20 GMT""}]","2022-01-03"
"2102.04558","Muhammad Anshari","Muhammad Anshari","E-Health Management Services in Supporting Empowerment","4 tables",,,,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  The Web technology provides healthcare providers the ability to broaden their
services beyond the usual practices, and thus provides a particular
advantageous environment to achieve complex e-health goals. This paper
discusses how a Web 2.0 application will help healthcare provider to extend and
enhance their services by involving and empowering their customers.Web 2.0
referes to the next generations of Web technology that empowers users to
generate contents over Internet. The Web 2.0 also refers to the Web as a
platform to perform any task online. The Web 2.0 allows customers to have
greater control of information flow from interactions between healthcare
providers with its customers and among customers themselves. The study employed
quantitative methods to depict expectations of customers in Indonesia towards
healthcare services that can offer empowerment and social media and sharing.
The questionnaires were fairly distributed to the groups of healthcare staffs
and customers (patients) who regularly visit healthcare centres. The survey
revealed that features of Web 2.0 in e-health services such as consultation
online, sharing in social networks, empowerment in detailing personal health
records are highly appreciated by customers. Regardless of the limitations of
the survey, the public has responded with a great support for the capabilities
of Web 2.0 listed from the questionnaires. The findings provide initial ideas
and recommendation for a future direction of prototype of social networks in
e-health services.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:21:35 GMT""}]","2021-02-10"
"2102.04559","Henrietta Lyons","Henrietta Lyons, Eduardo Velloso, Tim Miller","Designing for Contestation: Insights from Administrative Law",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A paper presented at the Workshop on Contestability in Algorithmic Systems at
CSCW 2019. Challenging algorithmic decisions is important to decision subjects,
yet numerous factors can limit a person's ability to contest such decisions. We
propose that administrative law systems, which were created to ensure that
governments are kept accountable for their actions and decision making in
relation to individuals, can provide guidance on how to design contestation
systems for algorithmic decision-making.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:24:40 GMT""}]","2021-02-10"
"2102.04560","Jakob Sauer J{\o}rgensen","Jakob S. J{\o}rgensen, Evelina Ametova, Genoveva Burca, Gemma Fardell,
  Evangelos Papoutsellis, Edoardo Pasca, Kris Thielemans, Martin Turner, Ryan
  Warr, William R. B. Lionheart and Philip J. Withers","Core Imaging Library -- Part I: a versatile Python framework for
  tomographic imaging","22 pages, 11 figures",,"10.1098/rsta.2020.0192",,"math.OC cs.MS","http://creativecommons.org/licenses/by/4.0/","  We present the Core Imaging Library (CIL), an open-source Python framework
for tomographic imaging with particular emphasis on reconstruction of
challenging datasets. Conventional filtered back-projection reconstruction
tends to be insufficient for highly noisy, incomplete, non-standard or
multi-channel data arising for example in dynamic, spectral and in situ
tomography. CIL provides an extensive modular optimisation framework for
prototyping reconstruction methods including sparsity and total variation
regularisation, as well as tools for loading, preprocessing and visualising
tomographic data. The capabilities of CIL are demonstrated on a synchrotron
example dataset and three challenging cases spanning golden-ratio neutron
tomography, cone-beam X-ray laminography and positron emission tomography.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:26:37 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 21:00:21 GMT""}]","2021-08-04"
"2102.04561","Andrea Gebek","Andrea Gebek and Jorryt Matthee","On the variation in stellar $\alpha$-enhancements of star-forming
  galaxies in the EAGLE simulation","21 pages, 12 figures, 4 tables. Accepted to ApJ",,"10.3847/1538-4357/ac350b",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ratio of $\alpha$-elements to iron in galaxies holds valuable information
about the star formation history since their enrichment occurs on different
timescales. The fossil record of stars in galaxies has mostly been excavated
for passive galaxies, since the light of star-forming galaxies is dominated by
young stars which have much weaker atmospheric absorption features. Here we use
the largest reference cosmological simulation of the EAGLE project to
investigate the origin of variations in stellar $\alpha$-enhancement among
star-forming galaxies at $z=0$, and their impact on integrated spectra. The
definition of $\alpha$-enhancement in a composite stellar population is
ambiguous. We elucidate two definitions - termed `mean' and `galactic'
$\alpha$-enhancement - in more detail. While a star-forming galaxy has a high
`mean' $\alpha$-enhancement when its stars formed rapidly, a galaxy with a
large `galactic' $\alpha$-enhancement generally had a delayed star formation
history. We find that absorption-line strengths of Mg and Fe correlate with
variations in $\alpha$-enhancement. These correlations are strongest for the
`galactic' $\alpha$-enhancement. However, we show that these are mostly caused
by other effects which are cross-correlated with $\alpha$-enhancement, such as
variations in the light-weighted age. This severely complicates the retrieval
of $\alpha$-enhancements in star-forming galaxies. The ambiguity is not severe
for passive galaxies and we confirm that spectral variations in these galaxies
are caused by measurable variations in $\alpha$-enhancements. We suggest that
this more complex coupling between $\alpha$-enhancement and star formation
histories can guide the interpretation of new observations of star-forming
galaxies.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:28:03 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 15:04:50 GMT""}]","2022-01-19"
"2102.04562","Yasuyuki Kawahigashi","Yasuyuki Kawahigashi","Projector Matrix Product Operators, Anyons and Higher Relative
  Commutants of Subfactors","17 pages, improved exposition",,"10.1007/s00208-022-02519-0",,"math.OA cond-mat.str-el math-ph math.MP math.QA","http://creativecommons.org/licenses/by/4.0/","  A bi-unitary connection in subfactor theory of Jones producing a subfactor of
finite depth gives a 4-tensor appearing in a recent work of
Bultinck-Mariena-Williamson-Sahinoglu-Haegemana-Verstraete on 2-dimensional
topological order and anyons. In their work, they have a special projection
called a projector matrix product operator. We prove that the range of this
projection of length k is naturally identified with the k-th higher relative
commutant of the subfactor arising from the bi-unitary connection. This gives a
further connection between 2-dimensional topological order and subfactor
theory.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:42:49 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 04:15:12 GMT""},{""version"":""v3"",""created"":""Mon, 19 Apr 2021 13:18:14 GMT""},{""version"":""v4"",""created"":""Fri, 4 Jun 2021 12:06:45 GMT""},{""version"":""v5"",""created"":""Thu, 19 Aug 2021 08:21:24 GMT""}]","2022-11-22"
"2102.04563","Mikhail Lisakov M","M. M. Lisakov (1 and 2), E. V. Kravchenko (3, 2 and 4), A. B.
  Pushkarev (5, 2 and 3), Y. Y. Kovalev (2, 3 and 1), T. K. Savolainen (6, 7
  and 1), and M. L. Lister (8) ((1) Max-Planck-Institut f\""ur Radioastronomie,
  (2) Astro Space Center, Lebedev Physical Institute, Russian Academy of
  Sciences, (3) Moscow Institute of Physics and Technology, (4) INAF Istituto
  di Radioastronomia, (5) Crimean Astrophysical Observatory, (6) Aalto
  University Department of Electronics and Nanoengineering, (7) alto University
  Mets\""ahovi Radio Observatory, (8) Department of Physics and Astronomy,
  Purdue University)","An oversized magnetic sheath wrapping around the parsec-scale jet in 3C
  273","10 pages, 9 figures. Accepted to the Astrophysical Journal","ApJ 910 (2021) 35","10.3847/1538-4357/abe1bd",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent studies, several AGN have exhibited gradients of the Faraday
Rotation Measure (RM) transverse to their parsec-scale jet direction. Faraday
rotation likely occurs as a result of a magnetized sheath wrapped around the
jet. In the case of 3C 273, using Very Long Baseline Array multi-epoch
observations at 5, 8 and 15 GHz in 2009--2010, we observe that the jet RM has
changed significantly towards negative values compared with that previously
observed. These changes could be explained by a swing of the parsec-scale jet
direction which causes synchrotron emission to pass through different portions
of the Faraday screen. We develop a model for the jet-sheath system in 3C 273
where the sheath is wider than the single-epoch narrow relativistic jet. We
present our oversized sheath model together with a derived wide jet full
intrinsic opening angle $\alpha_\mathrm{int}=2.1^\circ$ and magnetic field
strength $B_{||}=3$ $\mu$G and thermal particle density
$N_\mathrm{e}=125~\mathrm{cm}^{-3}$ at the wide jet--sheath boundary 230 pc
downstream (deprojected) from its beginning. Most of the Faraday rotation
occurs within the innermost layers of the sheath. The model brings together the
jet direction swing and long-term RM evolution and may be applicable to other
AGN jets that exhibit changes of their apparent jet direction.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:43:21 GMT""}]","2021-03-26"
"2102.04564","Thomas Scott","T. C. Scott, Chandreyee Sengupta, P. Lagos, Aeree Chung and O. Ivy
  Wong","Resolved HI in two ultra-diffuse galaxies from contrasting non-cluster
  environments","13 pages , 8 Figures",,"10.1093/mnras/stab390",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report on the first resolved HI observations of two blue ultra-diffuse
galaxies (UDGs)using the Giant Metrewave Radio Telescope (GMRT). These
observations add to the sofar limited number of UDGs with resolved HI data. The
targets are from contrasting non-cluster environments: UDG-B1 is projected in
the outskirts of Hickson Compact Group 25 and Secco-dI-2 (SdI-2) is an isolated
UDG. These UDGs also have contrasting effective radii with Re of 3.7 kpc
(similar to the Milky Way) and 1.3 kpc respectively. SdI-2 has an unusually
large MHI/M* ratio =28.9, confirming a previous single dish HI observation.
Both galaxies display HI morphological and kinematic signatures consistent with
a recent tidal interaction, which is also supported by observations from other
wavelengths, including optical spectroscopy. Within the limits of the
observations' resolution, our analysis indicates that SdI-2 is dark
matter-dominated within its HI radius and this is also likely to be the case
for UDG-B1. Our study highlights the importance of high spatial and spectral
resolution HI observations for the study of the dark matter properties of UDGs.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:45:04 GMT""}]","2021-02-17"
"2102.04565","Jakob Schoeffer","Jakob Schoeffer, Niklas Kuehl, Isabel Valera","A Ranking Approach to Fair Classification","ACM SIGCAS Conference on Computing and Sustainable Societies
  (COMPASS), June 28--July 2, 2021, Virtual Event, Australia",,"10.1145/3460112.3471950",,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Algorithmic decision systems are increasingly used in areas such as hiring,
school admission, or loan approval. Typically, these systems rely on labeled
data for training a classification model. However, in many scenarios,
ground-truth labels are unavailable, and instead we have only access to
imperfect labels as the result of (potentially biased) human-made decisions.
Despite being imperfect, historical decisions often contain some useful
information on the unobserved true labels. In this paper, we focus on scenarios
where only imperfect labels are available and propose a new fair ranking-based
decision system based on monotonic relationships between legitimate features
and the outcome. Our approach is both intuitive and easy to implement, and thus
particularly suitable for adoption in real-world settings. More in detail, we
introduce a distance-based decision criterion, which incorporates useful
information from historical decisions and accounts for unwanted correlation
between protected and legitimate features. Through extensive experiments on
synthetic and real-world data, we show that our method is fair in the sense
that a) it assigns the desirable outcome to the most qualified individuals, and
b) it removes the effect of stereotypes in decision-making, thereby
outperforming traditional classification algorithms. Additionally, we are able
to show theoretically that our method is consistent with a prominent concept of
individual fairness which states that ""similar individuals should be treated
similarly.""
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:51:12 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 05:19:56 GMT""}]","2021-07-19"
"2102.04566","Lucas Prado Osco","Patrik Ol\~a Bressan, Jos\'e Marcato Junior, Jos\'e Augusto Correa
  Martins, Diogo Nunes Gon\c{c}alves, Daniel Matte Freitas, Lucas Prado Osco,
  Jonathan de Andrade Silva, Zhipeng Luo, Jonathan Li, Raymundo Cordero Garcia,
  Wesley Nunes Gon\c{c}alves","Semantic Segmentation with Labeling Uncertainty and Class Imbalance","15 pages, 9 figures, 3 tables","International Journal of Applied Earth Observation and
  Geoinformation, 2022","10.1016/j.jag.2022.102690",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, methods based on Convolutional Neural Networks (CNN) achieved
impressive success in semantic segmentation tasks. However, challenges such as
the class imbalance and the uncertainty in the pixel-labeling process are not
completely addressed. As such, we present a new approach that calculates a
weight for each pixel considering its class and uncertainty during the labeling
process. The pixel-wise weights are used during training to increase or
decrease the importance of the pixels. Experimental results show that the
proposed approach leads to significant improvements in three challenging
segmentation tasks in comparison to baseline methods. It was also proved to be
more invariant to noise. The approach presented here may be used within a wide
range of semantic segmentation methods to improve their robustness.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:53:33 GMT""}]","2022-05-31"
"2102.04567","Maur\'icio Gruppi","Maur\'icio Gruppi, Benjamin D. Horne and Sibel Adal{\i}","NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of
  Misinformation in News Articles","6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2003.08444",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present an updated version of the NELA-GT-2019 dataset,
entitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519
sources collected between January 1st, 2020 and December 31st, 2020. Just as
with NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of
mainstream news sources and alternative news sources. Included in the dataset
are source-level ground truth labels from Media Bias/Fact Check (MBFC) covering
multiple dimensions of veracity. Additionally, new in the 2020 dataset are the
Tweets embedded in the collected news articles, adding an extra layer of
information to the data. The NELA-GT-2020 dataset can be found at
https://doi.org/10.7910/DVN/CHMUYZ.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:55:37 GMT""}]","2021-02-10"
"2102.04568","Chris Kennedy","Chris J. Kennedy, Julia Vassey, Ho-Chun Herbert Chang, Jennifer B.
  Unger, Emilio Ferrara","Tracking e-cigarette warning label compliance on Instagram with deep
  learning","9 pages, 3 figures",,,,"cs.SI cs.CV","http://creativecommons.org/licenses/by/4.0/","  The U.S. Food & Drug Administration (FDA) requires that e-cigarette
advertisements include a prominent warning label that reminds consumers that
nicotine is addictive. However, the high volume of vaping-related posts on
social media makes compliance auditing expensive and time-consuming, suggesting
that an automated, scalable method is needed. We sought to develop and evaluate
a deep learning system designed to automatically determine if an Instagram post
promotes vaping, and if so, if an FDA-compliant warning label was included or
if a non-compliant warning label was visible in the image. We compiled and
labeled a dataset of 4,363 Instagram images, of which 44% were vaping-related,
3% contained FDA-compliant warning labels, and 4% contained non-compliant
labels. Using a 20% test set for evaluation, we tested multiple neural network
variations: image processing backbone model (Inceptionv3, ResNet50,
EfficientNet), data augmentation, progressive layer unfreezing, output bias
initialization designed for class imbalance, and multitask learning. Our final
model achieved an area under the curve (AUC) and [accuracy] of 0.97 [92%] on
vaping classification, 0.99 [99%] on FDA-compliant warning labels, and 0.94
[97%] on non-compliant warning labels. We conclude that deep learning models
can effectively identify vaping posts on Instagram and track compliance with
FDA warning label requirements.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 22:56:21 GMT""}]","2021-02-10"
"2102.04569","Hyesung Kang","Sunjung Kim, Ji-Hoon Ha, Dongsu Ryu, and Hyesung Kang","Microinstabilities in the Transition Region of Weak Quasi-Perpendicular
  Intracluster Shocks","15 pages, 7 figures",,"10.3847/1538-4357/abf1e1",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microinstabilities play important roles in both entropy generation and
particle acceleration in collisionless shocks. Recent studies have suggested
that in the transition zone of quasi-perpendicular ($Q_{\perp}$) shocks in the
high-beta ($\beta=P_{\rm gas}/P_{\rm B}$) intracluster medium (ICM), the ion
temperature anisotropy due to the reflected-gyrating ions could trigger the
Alfv\'en ion cyclotron (AIC) instability and the ion-mirror instability, while
the electron temperature anisotropy induced by magnetic field compression could
excite the whistler instability and the electron-mirror instability. Adopting
the numerical estimates for ion and electron temperature anisotropies found in
particle-in-cell (PIC) simulations of $Q_{\perp}$-shocks with sonic Mach
numbers, $M_{\rm s}=2-3$, we carry out a linear stability analysis for these
microinstabilities. The kinetic properties of the microinstabilities and the
ensuing plasma waves on both ion and electron scales are described for wide
ranges of parameters, including the dependence on $\beta$ and the
ion-to-electron mass ratio. In addition, the nonlinear evolution of induced
plasma waves are examined by performing 2D PIC simulations with periodic
boundary conditions. We find that for $\beta\approx 20-100$, the AIC
instability could induce ion-scale waves and generate shock surface ripples in
supercritical shocks above the AIC critical Mach number, $M_{\rm AIC}^{*}
\approx 2.3$. Also electron-scale waves are generated primarily by the whistler
instability in these high-$\beta$ shocks. The resulting multi-scale waves from
electron to ion scales are thought to be essential in electron injection to the
diffusive shock acceleration mechanism in $Q_{\perp}$-shocks in the ICM.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:00:05 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 12:47:26 GMT""},{""version"":""v3"",""created"":""Wed, 24 Mar 2021 01:24:17 GMT""}]","2021-06-02"
"2102.04570","Fabian Menezes MSc","Fabian Menezes, Caius L. Selhorst, Carlos Guillermo Gim\'enez de
  Castro, and Adriana Valio","The subterahertz solar cycle: Polar and equatorial radii derived from
  SST and ALMA","10 pages, 5 figure, 3 tables, 1 equation",,"10.3847/1538-4357/abe41c",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  At subterahertz frequencies -- i.e., millimeter and submillimeter wavelengths
-- there is a gap of measurements of the solar radius as well as other
parameters of the solar atmosphere. As the observational wavelength changes,
the radius varies because the altitude of the dominant electromagnetic
radiation is produced at different heights in the solar atmosphere. Moreover,
radius variations throughout long time series are indicative of changes in the
solar atmosphere that may be related to the solar cycle. Therefore, the solar
radius is an important parameter for the calibration of solar atmospheric
models enabling a better understanding of the atmospheric structure. In this
work we use data from the Solar Submillimeter-wave Telescope (SST) and from the
Atacama Large Millimeter/submillimeter Array (ALMA), at the frequencies of 100,
212, 230, and 405 GHz, to measure the equatorial and polar radii of the Sun.
The radii measured with extensive data from the SST agree with the
radius-vs-frequency trend present in the literature. The radii derived from
ALMA maps at 230 GHz also agree with the radius-vs-frequency trend, whereas the
100-GHz radii are slightly above the values reported by other authors. In
addition, we analyze the equatorial and polar radius behavior over the years,
by determining the correlation coefficient between solar activity and
subterahertz radii time series at 212 and 405 GHz (SST). The variation of the
SST-derived radii over 13 years are correlated to the solar activity when
considering equatorial regions of the solar atmosphere, and anticorrelated when
considering polar regions. The ALMA derived radii time series for 100 and 230
GHz show very similar behaviors with those of SST.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:03:00 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 21:07:13 GMT""}]","2021-04-07"
"2102.04571","Yernat Assylbekov","Yernat M. Assylbekov, Franklin T. Rea","The attenuated ray transforms on Gaussian thermostats with negative
  curvature","23 pages",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper we consider a Gaussian thermostat on a compact
Riemannian surface with negative thermostat curvature. In the case of surfaces
with boundary, we show that the thermostat ray transform with attenuation given
by a general connection and Higgs field is injective, modulo the natural
obstruction, for tensors. We also prove that the connection and Higgs field can
be determined, up to a gauge transformation, from the knowledge of the parallel
transport between boundary points along all possible thermostat geodesics. In
the case of closed surfaces, we obtain similar results for the ray transform
with some additional conditions on the connection. Under the same condition, we
study connections and Higgs fields whose parallel transport along periodic
thermostat geodesics coincides with the ones for the flat connection.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:06:33 GMT""}]","2021-02-10"
"2102.04572","Aaron Melman","Aaron Melman","An octagon containing the numerical range of a bounded linear operator","8 pages, 3 figures",,,,"math.FA cs.NA math.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A polygon is derived that contains the numerical range of a bounded linear
operator on a complex Hilbert space, using only norms. In its most general
form, the polygon is an octagon, symmetric with respect to the origin, and
tangent to the closure of the numerical range in at least four points when the
spectral norm is used.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:08:11 GMT""}]","2021-02-10"
"2102.04573","Victor Ribeiro","Victor Vidigal Ribeiro, Daniela Soares Cruzes, Guilherme Horta
  Travassos","Moderator Factors of Software Security and Performance Verification",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Context: Security and performance (S&P) are critical non-functional
requirements on software systems. Therefore, verification activities should be
included in the development process to identify related defects and avoiding
S&P failures after deployment. However, the state of the practice of S&P
verification is unclear, challenging academia to offer solutions for real-world
problems faced by the S&P verification practitioners. Thus, identifying factors
moderating the S&P verification helps software development organizations
improve the S&P verification, releasing software that meets security and
performance requirements. Objective: To present moderator factors influencing
S&P verification activities and actions to promote S&P moderator factors.
Method: Multiple case study using qualitative analysis of observational data to
identify S&P moderators factors. Literature Rapid Reviews with Snowballing to
strengthen confidence in the identified S&P moderators factors. Practitioners
Survey to classify the S&P moderator factors regarding their relevance.
Results: Identification of eight S&P moderator factors regarding organizational
awareness, crossfunctional team, S&P requirements, support tools, verification
environment, verification methodology, verification planning, and reuse
practices. The literature reviews allowed us to confirm the identified S&P
moderator factors and identify a set of actions to promote each of them. A
survey with 37 valid participants allowed us to classify the identified S&P
moderators factors and their actions relevant to S&P verification activities.
Conclusions: The S&P moderator factors can be considered key points in which
software development organizations should invest to implement or improve S&P
verification activities.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:21:34 GMT""},{""version"":""v2"",""created"":""Sun, 25 Jul 2021 17:32:03 GMT""}]","2021-07-27"
"2102.04574","Bruno Kimura DSc","Gabriel Francisco Loren\c{c}on Ribeiro Bernardes, Rog\'erio Ishibashi,
  Andr\'e Aparecido de Souza Ivo, Val\'erio Rosset, Bruno Yuji Lino Kimura","Prototyping Low-Cost Automatic Weather Stations for Natural Disaster
  Monitoring",,,,,"cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Weather events put human lives at risk mostly when people might reside in
areas susceptible to natural disasters. Weather monitoring is a pivotal task
that is accomplished in vulnerable areas with the support of reliable weather
stations. Such stations are front-end equipment typically mounted on a fixed
mast structure with a set of digital and magnetic weather sensors connected to
a datalogger. While remote sensing from a number of stations is paramount, the
cost of professional weather instruments is extremely high. This imposes a
challenge for large-scale deployment and maintenance of weather stations for
broad natural disaster monitoring. To address this problem, in this paper, we
validate the hypothesis that a Low-Cost Automatic Weather Station system
(LCAWS) entirely developed from commercial-off-the-shelf and open-source IoT
technologies is able to provide data as reliable as a Professional Weather
Station (PWS) of reference for natural disaster monitoring. To achieve data
reliability, we propose an intelligent sensor calibration method to correct
weather parameters. From the experimental results of a 30-day uninterrupted
observation period, we show that the results of the calibrated LCAWS sensors
have no statistically significant differences with the PWS's results. Together
with The Brazilian National Center for Monitoring and Early Warning of Natural
Disasters (Cemaden), LCAWS has opened new opportunities towards reducing
maintenance cost of its weather observational network.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:28:49 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 20:47:48 GMT""}]","2021-05-05"
"2102.04575","Mathieu Francoeur","Takuro Tokunaga, Amun Jarzembski, Takuma Shiga, Keunhan Park and
  Mathieu Francoeur","Extreme Near-Field Heat Transfer Between Gold Surfaces","27 pages, 4 figures, 2 supplementary figures","Physical Review B 104, 125404, 2021","10.1103/PhysRevB.104.125404",,"cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Extreme near-field heat transfer between metallic surfaces is a subject of
debate as the state-of-the-art theory and experiments are in disagreement on
the energy carriers driving heat transport. In an effort to elucidate the
physics of extreme near-field heat transfer between metallic surfaces, this
Letter presents a comprehensive model combining radiation, acoustic phonon and
electron transport across sub-10-nm vacuum gaps. The results obtained for gold
surfaces show that in the absence of bias voltage, acoustic phonon transport is
dominant for vacuum gaps smaller than ~2 nm. The application of a bias voltage
significantly affects the dominant energy carriers as it increases the phonon
contribution mediated by the long-range Coulomb force and the electron
contribution due to a lower potential barrier. For a bias voltage of 0.6 V,
acoustic phonon transport becomes dominant at a vacuum gap of 5 nm, whereas
electron tunneling dominates at sub-1-nm vacuum gaps. The comparison of the
theory against experimental data from the literature suggests that
well-controlled measurements between metallic surfaces are needed to quantify
the contributions of acoustic phonon and electron as a function of the bias
voltage.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:30:56 GMT""}]","2022-01-19"
"2102.04576","Mackenzie Simper","Persi Diaconis, Mackenzie Simper","Statistical Enumeration of Groups by Double Cosets","46 pages, 1 figure; minor edits",,,,"math.PR math.CO math.GR","http://creativecommons.org/licenses/by/4.0/","  Let $H$ and $K$ be subgroups of a finite group $G$. Pick $g \in G$ uniformly
at random. We study the distribution induced on double cosets. Three examples
are treated in detail: 1) $H = K = $ the Borel subgroup in
$GL_n(\mathbb{F}_q)$. This leads to new theorems for Mallows measure on
permutations and new insights into the LU matrix factorization. 2) The double
cosets of the hyperoctahedral group inside $S_{2n}$, which leads to new
applications of the Ewens's sampling formula of mathematical genetics. 3)
Finally, if $H$ and $K$ are parabolic subgroups of $S_n$, the double cosets are
`contingency tables', studied by statisticians for the past 100 years.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:31:02 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 19:49:44 GMT""}]","2021-03-09"
"2102.04577","Amal Alghamdi","Amal Alghamdi, Marc Hesse, Jingyi Chen, Umberto Villa, Omar Ghattas","Bayesian Poroelastic Aquifer Characterization from InSAR Surface
  Deformation Data Part II: Quantifying the Uncertainty",,,"10.1029/2021WR029775",,"physics.geo-ph cs.CE","http://creativecommons.org/licenses/by/4.0/","  Uncertainty quantification of groundwater (GW) aquifer parameters is critical
for efficient management and sustainable extraction of GW resources. These
uncertainties are introduced by the data, model, and prior information on the
parameters. Here we develop a Bayesian inversion framework that uses
Interferometric Synthetic Aperture Radar (InSAR) surface deformation data to
infer the laterally heterogeneous permeability of a transient linear
poroelastic model of a confined GW aquifer. The Bayesian solution of this
inverse problem takes the form of a posterior probability density of the
permeability. Exploring this posterior using classical Markov chain Monte Carlo
(MCMC) methods is computationally prohibitive due to the large dimension of the
discretized permeability field and the expense of solving the poroelastic
forward problem. However, in many partial differential equation (PDE)-based
Bayesian inversion problems, the data are only informative in a few directions
in parameter space. For the poroelasticity problem, we prove this property
theoretically for a one-dimensional problem and demonstrate it numerically for
a three-dimensional aquifer model. We design a generalized preconditioned
Crank--Nicolson (gpCN) MCMC method that exploits this intrinsic low
dimensionality by using a low-rank based Laplace approximation of the posterior
as a proposal, which we build scalably. The feasibility of our approach is
demonstrated through a real GW aquifer test in Nevada. The inherently two
dimensional nature of InSAR surface deformation data informs a sufficient
number of modes of the permeability field to allow detection of major
structures within the aquifer, significantly reducing the uncertainty in the
pressure and the displacement quantities of interest.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:47:34 GMT""}]","2021-12-08"
"2102.04578","Daikichi Seki","Daikichi Seki, Kenichi Otsuji, Takako T. Ishii, Ayumi Asai, Kiyoshi
  Ichimoto","Relationship between three-dimensional velocity of filament eruptions
  and CME association","accepted for publication in Earth, Planets and Space",,"10.1186/s40623-021-01378-4",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  It is widely recognised that filament disappearances or eruptions are
frequently associated with Coronal Mass Ejections (CMEs). Since CMEs are a
major source of disturbances of the space environment surrounding the Earth, it
is important to investigate these associations in detail for the better
prediction of CME occurrence. However, the proportion of filament
disappearances associated with CMEs is under debate. The estimates range from
$\sim$10% to $\sim$90% and could be affected by the manners to select the
events. In this study, we aim to reveal what parameters control the association
between filament eruptions and CMEs. We analysed the relationships between CME
associations and the physical parameters of filaments including their length,
maximum ascending velocity, and direction of eruptions using 28 events of
filament eruptions observed in H$\alpha$. We found that the product of the
maximum radial velocity and the filament length is well correlated with the CME
occurrence. If the product is larger than 8.0$\times$10$^{6}$ km$^{2}$
s$^{-1}$, the filament will become a CME with a probability of 93%, and if the
product is smaller than this value, it will not become a CME with a probability
of 100%. We suggest a kinetic-energy threshold above which filament eruptions
are associated with CMEs. Our findings also suggest the importance of measuring
the velocity vector of filament eruption in three-dimensional space for the
better prediction of CME occurrence.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:53:32 GMT""}]","2021-03-10"
"2102.04579","Ulysse Chabaud","Ulysse Chabaud, Damian Markham, and Adel Sohbi","Quantum machine learning with adaptive linear optics","16 + 5 pages, presented at AQIS2020, accepted in Quantum","Quantum 5, 496 (2021)","10.22331/q-2021-07-05-496",,"quant-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  We study supervised learning algorithms in which a quantum device is used to
perform a computational subroutine - either for prediction via probability
estimation, or to compute a kernel via estimation of quantum states overlap. We
design implementations of these quantum subroutines using Boson Sampling
architectures in linear optics, supplemented by adaptive measurements. We then
challenge these quantum algorithms by deriving classical simulation algorithms
for the tasks of output probability estimation and overlap estimation. We
obtain different classical simulability regimes for these two computational
tasks in terms of the number of adaptive measurements and input photons. In
both cases, our results set explicit limits to the range of parameters for
which a quantum advantage can be envisaged with adaptive linear optics compared
to classical machine learning algorithms: we show that the number of input
photons and the number of adaptive measurements cannot be simultaneously small
compared to the number of modes. Interestingly, our analysis leaves open the
possibility of a near-term quantum advantage with a single adaptive
measurement.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:56:49 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 08:29:45 GMT""}]","2021-07-07"
"2102.04580","Bernhard von Stengel","Bernhard von Stengel","Finding Nash Equilibria of Two-Player Games",,,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  This paper is an exposition of algorithms for finding one or all equilibria
of a bimatrix game (a two-player game in strategic form) in the style of a
chapter in a graduate textbook. Using labeled ""best-response polytopes"", we
present the Lemke-Howson algorithm that finds one equilibrium. We show that the
path followed by this algorithm has a direction, and that the endpoints of the
path have opposite index, in a canonical way using determinants. For reference,
we prove that a number of notions of nondegeneracy of a bimatrix game are
equivalent. The computation of all equilibria of a general bimatrix game, via a
description of the maximal Nash subsets of the game, is canonically described
using ""complementary pairs"" of faces of the best-response polytopes.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 23:58:47 GMT""}]","2021-02-10"
"2102.04581","Madhav Pathak","Madhav Pathak and Ratnesh Kumar","Synchronous Inductor Switched Energy Extraction Circuits for
  Triboelectric Nanogenerator",,"IEEE Access Volume 9, 2021","10.1109/ACCESS.2021.3082499",,"physics.app-ph cs.SY eess.SP eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Triboelectric nanogenerator (TENG), a class of mechanical to electrical
energy transducers, has emerged as a promising solution to self-power Internet
of Things (IoT) sensors, wearable electronics, etc. The use of synchronous
switched energy extraction circuits (EECs) as an interface between TENG and
battery load can deliver multi-fold energy gain over simple minded Full Wave
Rectification (FWR). This paper presents a detailed analysis of Parallel and
Series Synchronous Switched Harvesting on Inductor (P-SSHI and S-SSHI) EECs to
derive the energy delivered to the battery load and compare it with the
standard FWR (a 3rd circuit) in a common analytical framework, under both
realistic conditions, and also ideal conditions. Further, the optimal value of
battery load to maximize output and upper bound beyond which charging is not
feasible are derived for all the three considered circuits. These closed-form
results derived with general TENG electrical parameters and first-order circuit
non-idealities shed light on the physics of the modeling and guide the choice
and design of EECs for any given TENG. The derived analytical results are
verified against PSpice based simulation results as well as the experimentally
measured values.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:01:11 GMT""}]","2021-05-26"
"2102.04582","Abdallah Chehade","Mayuresh Savargaonkar, Abdallah Chehade and Samir Rawashdeh","RMOPP: Robust Multi-Objective Post-Processing for Effective Object
  Detection",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last few decades, many architectures have been developed that
harness the power of neural networks to detect objects in near real-time.
Training such systems requires substantial time across multiple GPUs and
massive labeled training datasets. Although the goal of these systems is
generalizability, they are often impractical in real-life applications due to
flexibility, robustness, or speed issues. This paper proposes RMOPP: A robust
multi-objective post-processing algorithm to boost the performance of fast
pre-trained object detectors with a negligible impact on their speed.
Specifically, RMOPP is a statistically driven, post-processing algorithm that
allows for simultaneous optimization of precision and recall. A unique feature
of RMOPP is the Pareto frontier that identifies dominant possible
post-processed detectors to optimize for both precision and recall. RMOPP
explores the full potential of a pre-trained object detector and is deployable
for near real-time predictions. We also provide a compelling test case on
YOLOv2 using the MS-COCO dataset.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:02:38 GMT""}]","2021-02-10"
"2102.04583","Jie Chen","Jie Chen and Daniel R. Chavas","Can Existing Theory Predict the Response of Tropical Cyclone Intensity
  to Idealized Landfall?",,,"10.1175/JAS-D-21-0037.1",,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tropical cyclones cause significant inland hazards, including wind damage and
freshwater flooding, that depend strongly on how storm intensity evolves at and
after landfall. Existing theoretical predictions for the time-dependent and
equilibrium response of storm intensity have been tested over the open ocean
but not yet to be applied to storms after landfall. Recent work examined the
transient response of the tropical cyclone low-level wind field to
instantaneous surface roughening or drying in idealized axisymmetric f-plane
simulations. Here, experiments testing combined surface roughening and drying
with varying magnitudes of each are used to test theoretical predictions for
the intensity response. The transient response to combined surface forcings can
be reproduced by the product of their individual responses, in line with
traditional potential intensity theory. Existing intensification theory is
generalized to weakening and found capable of reproducing the time-dependent
inland intensity decay. The initial (0-10min) rapid decay of near-surface wind
caused by surface roughening is not captured by existing theory but can be
reproduced by a simple frictional spin-down model, where the decay rate is a
function of surface roughness. Finally, the theory is shown to compare well
with the prevailing empirical decay model for real-world storms. Overall,
results indicate the potential for existing theory to predict how tropical
cyclone intensity evolves after landfall.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:07:47 GMT""}]","2021-10-27"
"2102.04584","Eduardo Marcos N.","Edson R. Alvares, Eduardo N. Marcos and Hagen Meltzer","The braid group action on exceptional sequences for weighted projective
  lines",,,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a new and intrinsic proof of the transitivity of the braid group
action on the set of full exceptional sequences of coherent sheaves on a
weighted projective line. We do not use here the corresponding result of
Crawley-Boevey for modules over hereditary algebras. As an application we prove
that the strongest global dimension of the category of coherent sheaves on a
weighted projective line $\XX$ does not depend on the parameters of $\XX$.
Finally we prove that the determinant of the matrix obtained by taking the
values of $n$ $\ZZ$-linear functions defined on the Grothendieck group
$K_0(\XX) \simeq \ZZ^n $ of the elements of a full exceptional sequence is an
invariant, up to sign.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:08:34 GMT""}]","2021-02-10"
"2102.04585","Jordan Hanson PhD","Jordan C. Hanson","Broadband RF Phased Array Design with MEEP: Comparisons to Array Theory
  in Two and Three Dimensions",,"Electronics 2021, 10(4), 415","10.3390/electronics10040415",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Phased array radar systems have a wide variety of applications in engineering
and physics research. Phased array design usually requires numerical modeling
with expensive commercial computational packages. Using the open-source MIT
Electrogmagnetic Equation Propagation (MEEP) package, a set of phased array
designs is presented. Specifically, one and two-dimensional arrays of Yagi-Uda
and horn antennas were modeled in the bandwidth [0.1 - 5] GHz, and compared to
theoretical expectations in the far-field. Precise matches between MEEP
simulation and radiation pattern predictions at different frequencies and beam
angles are demonstrated. Given that the computations match the theory, the
effect of embedding a phased array within a medium of varying index of
refraction is then computed. Understanding the effect of varying index on
phased arrays is critical for proposed ultra-high energy neutrino observatories
which rely on phased array detectors embedded in natural ice. Future work will
develop the phased array concepts with parallel MEEP, in order to increase the
detail, complexity, and speed of the computations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:15:56 GMT""}]","2021-02-10"
"2102.04586","Ruichen Jiang","Ruichen Jiang, Ya-Feng Liu, Chenglong Bao, and Bo Jiang","Tightness and Equivalence of Semidefinite Relaxations for MIMO Detection","25 pages, 3 figures, submitted for possible publication",,,,"math.OC cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multiple-input multiple-output (MIMO) detection problem, a fundamental
problem in modern digital communications, is to detect a vector of transmitted
symbols from the noisy outputs of a fading MIMO channel. The maximum likelihood
detector can be formulated as a complex least-squares problem with discrete
variables, which is NP-hard in general. Various semidefinite relaxation (SDR)
methods have been proposed in the literature to solve the problem due to their
polynomial-time worst-case complexity and good detection error rate
performance. In this paper, we consider two popular classes of SDR-based
detectors and study the conditions under which the SDRs are tight and the
relationship between different SDR models. For the enhanced complex and real
SDRs proposed recently by Lu et al., we refine their analysis and derive the
necessary and sufficient condition for the complex SDR to be tight, as well as
a necessary condition for the real SDR to be tight. In contrast, we also show
that another SDR proposed by Mobasher et al. is not tight with high probability
under mild conditions. Moreover, we establish a general theorem that shows the
equivalence between two subsets of positive semidefinite matrices in different
dimensions by exploiting a special ""separable"" structure in the constraints.
Our theorem recovers two existing equivalence results of SDRs defined in
different settings and has the potential to find other applications due to its
generality.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:23:49 GMT""}]","2021-02-10"
"2102.04587","Ryan Cole","Ryan K. Cole, Anthony D. Draper, Paul J. Schroeder, Cameron M. Casby,
  Amanda S. Makowiecki, Sean C. Coburn, Julie E. Steinbrenner, Nazanin
  Hoghooghi, Gregory B. Rieker","Demonstration of a uniform, high-pressure, high-temperature gas cell
  with a dual frequency comb absorption spectrometer",,,"10.1016/j.jqsrt.2021.107640",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Accurate absorption models for gases at high pressure and temperature support
advanced optical combustion diagnostics and aid in the study of harsh planetary
atmospheres. Developing and validating absorption models for these applications
requires recreating the extreme temperature and pressure conditions of these
environments in static, uniform, well-known conditions in the laboratory. Here,
we present the design of a new gas cell to enable reference-quality absorption
spectroscopy at high pressure and temperature. The design centers on a
carefully controlled quartz sample cell housed at the core of a pressurized
ceramic furnace. The half-meter sample cell is relatively long compared to past
high- pressure and temperature absorption cells, and is surrounded by a
molybdenum heat spreader that enables high temperature uniformity over the full
length of the absorbing gas. We measure the temperature distribution of the
sample gas using in situ thermocouples, and fully characterize the temperature
uniformity across a full matrix of conditions up to 1000 K and 50 bar. The
results demonstrate that the new design enables highly uniform and precisely
known conditions across the full absorbing path length. Uniquely, we test the
new gas cell with a broadband, high-resolution dual frequency comb spectrometer
that enables highly resolved absorption spectroscopy across a wide range of
temperature and pressure conditions. With this system, we measure the spectrum
of CO$_2$ between 6800 and 7000 cm$^{-1}$ at pressures between 0.2 and 20 bar,
and temperatures up to 1000 K. The measurements reveal discrepancies from
spectra predicted by the HITRAN2016 database with a Voigt line shape at both
low- and high-pressure conditions. These results motivate future work to expand
absorption models and databases to accurately model high-pressure and
-temperature spectra in combustion and planetary science research.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:37:13 GMT""}]","2021-04-07"
"2102.04588","Debasish Mohapatra","Debasish Ray Mohapatra, Victor Zappi, Sidney Fels","A comparative study of two-dimensional vocal tract acoustic modeling
  based on Finite-Difference Time-Domain methods","4 pages, 3 figures",,,,"cs.SD cs.CL eess.AS","http://creativecommons.org/licenses/by/4.0/","  The two-dimensional (2D) numerical approaches for vocal tract (VT) modelling
can afford a better balance between the low computational cost and accurate
rendering of acoustic wave propagation. However, they require a high
spatio-temporal resolution in the numerical scheme for a precise estimation of
acoustic formants at the simulation run-time expense. We have recently proposed
a new VT acoustic modelling technique, known as the 2.5D Finite-Difference
Time-Domain (2.5D FDTD), which extends the existing 2D FDTD approach by adding
tube depth to its acoustic wave solver. In this work, first, the simulated
acoustic outputs of our new model are shown to be comparable with the 2D FDTD
and a realistic 3D FEM VT model at a low spatio-temporal resolution. Next, a
radiation model is developed by including a circular baffle around the VT as
head geometry. The transfer functions of the radiation model are analyzed using
five different vocal tract shapes for vowel sounds /a/, /e/, /i/, /o/ and /u/.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:40:52 GMT""}]","2021-02-10"
"2102.04589","Naoyuki Itagaki","Naoyuki Itagaki, Tokuro Fukui, Junki Tanaka, and Yuma Kikuchi","Two $^9$Li clusters connected with two valence neutrons in $^{20}$C","arXiv admin note: text overlap with arXiv:2011.12642",,,,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Many preceding works have shown in $^{11}$Li the presence of the halo
structure comprised of the weakly bound two neutrons around $^9$Li, and it is
intriguing to see how this halo structure changes when another $^9$Li
approaches. In this study, we introduce a four-body model for $^{20}$C with two
$^9$Li clusters and two valence neutrons. The recent development of the
antisymmetrized quasi cluster model (AQCM) makes it possible to generate
$jj$-coupling shell-model wave functions from $\alpha$ cluster models. Here,
$jj$-coupling shell model wave function of $^9$Li is regarded as a cluster,
which corresponds to the subclosure configuration of $p_{3/2}$ for the
neutrons, and we discuss how the two neutrons connect two $^9$Li clusters.
Until now, most of the clusters in the conventional models have been limited to
the closures of the three-dimensional harmonic oscillators, such as $^4$He,
$^{16}$O, and $^{40}$Ca; however, owing to AQCM, it is feasible to utilize the
$jj$-coupling shell model wave functions as plural subsystems quite easily. The
appearance of a rotational band structure with a cluster structure around the
four-body threshold energy is discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:47:04 GMT""}]","2021-02-10"
"2102.04590","Mona Zehni","Mona Zehni, Zhizhen Zhao","UVTomo-GAN: An adversarial learning based approach for unknown view
  X-ray tomographic reconstruction",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tomographic reconstruction recovers an unknown image given its projections
from different angles. State-of-the-art methods addressing this problem assume
the angles associated with the projections are known a-priori. Given this
knowledge, the reconstruction process is straightforward as it can be
formulated as a convex problem. Here, we tackle a more challenging setting: 1)
the projection angles are unknown, 2) they are drawn from an unknown
probability distribution. In this set-up our goal is to recover the image and
the projection angle distribution using an unsupervised adversarial learning
approach. For this purpose, we formulate the problem as a distribution matching
between the real projection lines and the generated ones from the estimated
image and projection distribution. This is then solved by reaching the
equilibrium in a min-max game between a generator and a discriminator. Our
novel contribution is to recover the unknown projection distribution and the
image simultaneously using adversarial learning. To accommodate this, we use
Gumbel-softmax approximation of samples from categorical distribution to
approximate the generator's loss as a function of the unknown image and the
projection distribution. Our approach can be generalized to different inverse
problems. Our simulation results reveal the ability of our method in
successfully recovering the image and the projection distribution in various
settings.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:51:25 GMT""}]","2021-02-10"
"2102.04591","Zhiyong Cheng","Zhiyong Cheng, Jun Deng, Tianyi Wang, Mei Yu","Liquidation, Leverage and Optimal Margin in Bitcoin Futures Markets","21 pages, 5 fugures",,,,"q-fin.TR","http://creativecommons.org/licenses/by/4.0/","  Using the generalized extreme value theory to characterize tail
distributions, we address liquidation, leverage, and optimal margins for
bitcoin long and short futures positions. The empirical analysis of perpetual
bitcoin futures on BitMEX shows that (1) daily forced liquidations to out-
standing futures are substantial at 3.51%, and 1.89% for long and short; (2)
investors got forced liquidation do trade aggressively with average leverage of
60X; and (3) exchanges should elevate current 1% margin requirement to 33% (3X
leverage) for long and 20% (5X leverage) for short to reduce the daily margin
call probability to 1%. Our results further suggest normality assumption on
return significantly underestimates optimal margins. Policy implications are
also discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:54:07 GMT""}]","2021-02-10"
"2102.04592","Mateo Diaz","David Applegate, Mateo D\'iaz, Haihao Lu, Miles Lubin","Infeasibility detection with primal-dual hybrid gradient for large-scale
  linear programming","32 pages, 3 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of detecting infeasibility of large-scale linear
programming problems using the primal-dual hybrid gradient method (PDHG) of
Chambolle and Pock (2011). The literature on PDHG has mostly focused on
settings where the problem at hand is assumed to be feasible. When the problem
is not feasible, the iterates of the algorithm do not converge. In this
scenario, we show that the iterates diverge at a controlled rate towards a
well-defined ray. The direction of this ray is known as the infimal
displacement vector $v$. The first contribution of our work is to prove that
this vector recovers certificates of primal and dual infeasibility whenever
they exist. Based on this fact, we propose a simple way to extract approximate
infeasibility certificates from the iterates of PDHG. We study three different
sequences that converge to the infimal displacement vector: the difference of
iterates, the normalized iterates, and the normalized average. All of them are
easy to compute, and thus the approach is suitable for large-scale problems.
Our second contribution is to establish tight convergence rates for these
sequences. We demonstrate that the normalized iterates and the normalized
average achieve a convergence rate of $O(1/k)$, improving over the known rate
of $O(1/\sqrt{k})$. This rate is general and applies to any fixed-point
iteration of a nonexpansive operator. Thus, it is a result of independent
interest since it covers a broad family of algorithms, including, for example,
ADMM, and can be applied settings beyond linear programming, such as quadratic
and semidefinite programming. Further, in the case of linear programming we
show that, under nondegeneracy assumptions, the iterates of PDHG identify the
active set of an auxiliary feasible problem in finite time, which ensures that
the difference of iterates exhibits eventual linear convergence to the infimal
displacement vector.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:08:51 GMT""}]","2021-02-10"
"2102.04593","Gabriele Di Cerbo","Gabriele Di Cerbo, Ali Hirsa, Ahmad Shayaan","Regularized Generative Adversarial Network","18 pages. Comments are welcome!",,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a framework for generating samples from a probability distribution
that differs from the probability distribution of the training set. We use an
adversarial process that simultaneously trains three networks, a generator and
two discriminators. We refer to this new model as regularized generative
adversarial network (RegGAN). We evaluate RegGAN on a synthetic dataset
composed of gray scale images and we further show that it can be used to learn
some pre-specified notions in topology (basic topology properties). The work is
motivated by practical problems encountered while using generative methods in
the art world.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:13:36 GMT""}]","2021-02-10"
"2102.04594","Vikram Krishnamurthy","Kunal Pattanayak and Vikram Krishnamurthy","Rationally Inattentive Utility Maximization for Interpretable Deep Image
  Classification",,,,,"cs.LG econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Are deep convolutional neural networks (CNNs) for image classification
explainable by utility maximization with information acquisition costs? We
demonstrate that deep CNNs behave equivalently (in terms of necessary and
sufficient conditions) to rationally inattentive utility maximizers, a
generative model used extensively in economics for human decision making. Our
claim is based by extensive experiments on 200 deep CNNs from 5 popular
architectures. The parameters of our interpretable model are computed
efficiently via convex feasibility algorithms. As an application, we show that
our economics-based interpretable model can predict the classification
performance of deep CNNs trained with arbitrary parameters with accuracy
exceeding 94% . This eliminates the need to re-train the deep CNNs for image
classification. The theoretical foundation of our approach lies in Bayesian
revealed preference studied in micro-economics. All our results are on GitHub
and completely reproducible.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:14:24 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 22:08:39 GMT""},{""version"":""v3"",""created"":""Sat, 31 Jul 2021 02:48:03 GMT""}]","2021-08-03"
"2102.04595","Jorge Bellorin","Jorge Bellorin and Byron Droguett","BFV quantization of the nonprojectable 2+1 Horava theory",,"Phys. Rev. D 103, 064039 (2021)","10.1103/PhysRevD.103.064039",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We show that the BFV quantization scheme can be implemented in the
nonprojectable 2+1 Horava theory. This opens the possibility of imposing more
general gauge conditions in the quantization of this theory. The BFV
quantization is based on the canonical formalism, which is suitable to
incorporate the measure associated to the second-class constraints that the
theory has. Special features of the Hamiltonian density and the matrix of
second-class constraints allow that the system be involutive in terms of Dirac
brackets, which is a nontrivial requisite for implementing the BFV formalism.
We present the BRST symmetry transformations in the canonical variables. The
theory is of rank one, in the classification introduced by Fradkin and
Fradkina. The originally called relativistic gauge-fixing conditions of the BFV
formalism can be implemented in the nonprojectable Horava theory, extended to
nonrelativistic forms. We show that the nonlocal gauge condition introduced in
the projectable theory can be included among these gauges.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:17:30 GMT""}]","2021-03-23"
"2102.04596","Ciaran O'Hare","Sven E. Vahsen, Ciaran A. J. O'Hare, Dinesh Loomba","Directional recoil detection","41 pages, 8 figures. Invited review for Annual Review of Nuclear and
  Particle Science. v2 has minor corrections and is slightly shorter","Annu. Rev. Nucl. Part. Sci. 2021. 71 189-224","10.1146/annurev-nucl-020821-035016",,"physics.ins-det astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searches for dark matter-induced recoils have made impressive advances in the
last few years. Yet the field is confronted by several outstanding problems.
First, the inevitable background of solar neutrinos will soon inhibit the
conclusive identification of many dark matter models. Second, and more
fundamentally, current experiments have no practical way of confirming a
detected signal's galactic origin. The concept of directional detection
addresses both of these issues while offering opportunities to study novel dark
matter and neutrino-related physics. The concept remains experimentally
challenging, but gas time projection chambers are an increasingly attractive
option, and when properly configured, would allow directional measurements of
both nuclear and electron recoils. In this review, we reassess the required
detector performance and survey relevant technologies. Fortuitously, the
highly-segmented detectors required to achieve good directionality also enable
several fundamental and applied physics measurements. We comment on near-term
challenges and how the field could be advanced.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:24:11 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 00:46:26 GMT""}]","2021-06-23"
"2102.04597","Prasoon Kumar Shandilya","Prasoon K Shandilya, David P Lake, Matthew J Mitchell, Denis D
  Sukachev, Paul E Barclay","Optomechanical interface between telecom photons and spin quantum memory","8 pages, 5 figures","Nature Physics (2021)","10.1038/s41567-021-01364-3",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum networks enable a broad range of practical and fundamental
applications spanning distributed quantum computing to sensing and metrology. A
cornerstone of such networks is an interface between telecom photons and
quantum memories. Here we demonstrate a novel approach based on cavity
optomechanics that utilizes the susceptibility of spin qubits to strain. We use
it to control electron spins of nitrogen-vacancy centers in diamond with
photons in the 1550 nm telecommunications wavelength band. This method does not
involve qubit optical transitions and is insensitive to spectral diffusion.
Furthermore, our approach can be applied to solid-state qubits in a wide
variety of materials, expanding the toolbox for quantum information processing.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:28:35 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 21:05:01 GMT""}]","2021-11-29"
"2102.04598","Marius T\u{a}rn\u{a}uceanu","Marius T\u{a}rn\u{a}uceanu","Isolated subgroups of finite abelian groups",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  We say that a subgroup $H$ is isolated in a group $G$ if for every $x\in G$
we have either $x\in H$ or $\langle x\rangle\cap H=1$. In this short note, we
describe the set of isolated subgroups of a finite abelian group. The technique
used is based on an interesting connection between isolated subgroups and the
function sum of element orders of a finite group.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:35:40 GMT""}]","2021-02-10"
"2102.04599","Guanyang Wang","Weibo Fu, Guanyang Wang, Jun Yan","On the Minimax Spherical Designs","24 pages, 5 figures. To appear in Random Structures & Algorithms",,,,"math.CO cs.NA math.MG math.NA math.PR","http://creativecommons.org/licenses/by/4.0/","  Distributing points on a (possibly high-dimensional) sphere with minimal
energy is a long-standing problem in and outside the field of mathematics. This
paper considers a novel energy function that arises naturally from statistics
and combinatorial optimization, and studies its theoretical properties. Our
result solves both the exact optimal spherical point configurations in certain
cases and the minimal energy asymptotics under general assumptions. Connections
between our results and the L1-Principal Component analysis and Quasi-Monte
Carlo methods are also discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:45:25 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 20:03:09 GMT""}]","2022-03-21"
"2102.04600","Ryuichiro Hataya","Ryuichiro Hataya, Hideki Nakayama, Kazuki Yoshizoe","Graph Energy-based Model for Substructure Preserving Molecular Design","preprint",,,,"physics.chem-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is common practice for chemists to search chemical databases based on
substructures of compounds for finding molecules with desired properties. The
purpose of de novo molecular generation is to generate instead of search.
Existing machine learning based molecular design methods have no or limited
ability in generating novel molecules that preserves a target substructure. Our
Graph Energy-based Model, or GEM, can fix substructures and generate the rest.
The experimental results show that the GEMs trained from chemistry datasets
successfully generate novel molecules while preserving the target
substructures. This method would provide a new way of incorporating the domain
knowledge of chemists in molecular design.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:46:12 GMT""}]","2021-02-10"
"2102.04601","Allan Sung","Allan Sung, Gang Guo, Meng-Ru Wu","Supernova Constraint on Self-Interacting Dark Sector Particles","24 pages, 6 figures","Phys. Rev. D 103, 103005 (2021)","10.1103/PhysRevD.103.103005",,"hep-ph astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We examine the constraints on sub-GeV dark sector particles set by the
proto-neutron star cooling associated with the core-collapse supernova event
SN1987a. Considering explicitly a dark photon portal dark sector model, we
compute the relevant interaction rates of dark photon ($A'$) and dark fermion
($\chi$) with the Standard Model particles as well as their self-interaction
inside the dark sector. We find that even with a small dark sector fine
structure constant $\alpha_D\ll 1$, dark sector self-interactions can easily
lead to their own self-trapping. This effect strongly limits the energy
luminosity carried away by dark sector particles from the supernova core and
thus drastically affects the parameter space that can be constrained by
SN1987a. We consider specifically two mass ratios $m_{A'}=3m_\chi$ and
$3m_{A'}=m_\chi$ which represent scenarios where the decay of $A'$ to
$\chi\bar\chi$ is allowed or not. We show that SN1987a can only place bounds on
the dark sector when $\alpha_D\lesssim 10^{-15}$ ($10^{-7}$) for the former
(latter) for $m_\chi\lesssim 20$ MeV. Furthermore, this evades the supernova
bounds on the widely-examined dark photon parameter space completely if
$\alpha_D\lesssim 10^{-7}$ for the former, while lifts the bounds when
$\alpha_D\lesssim 10^{-7}$ if $m_\chi\lesssim 100$ MeV. Our findings thus imply
that the existing supernova bounds on light dark particles can be generally
evaded by a similar self-trapping mechanism. This also implies that
non-standard strongly self-interacting neutrino is not consistent with the
SN1987a observation. Same effects can also take place for other known stellar
bounds on dark sector particles.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:47:56 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 01:09:27 GMT""}]","2021-05-14"
"2102.04602","Marcin Bownik","Marcin Bownik, Baode Li, Tal Weissblat","A characterization of spaces of homogeneous type induced by continuous
  ellipsoid covers of $\mathbb R^n$",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relationship between the concept of a continuous ellipsoid
$\Theta$ cover of $\mathbb{R}^n$, which was introduced by Dahmen, Dekel, and
Petrushev, and the space of homogeneous type induced by $\Theta$. We
characterize the class of quasi-distances on $\mathbb{R}^n$ (up to equivalence)
which correspond to continuous ellipsoid covers. This places firmly continuous
ellipsoid covers as a subclass of spaces of homogeneous type on $\mathbb{R}^n$
satisfying quasi-convexity and $1$-Ahlfors-regularity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:02:04 GMT""}]","2021-02-10"
"2102.04603","Wei Hong","Hanwen Feng, Yuchen Huang, Wei Hong and Jun Tao","Charged torus-like black holes as heat engines","16 pages, 8 figures, accepted by Communications in Theoretical
  Physics",,"10.1088/1572-9494/abe3ef",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the thermodynamical properties of charged torus-like black
holes and take it as the working substance to study the heat engines. In the
extended phase space, by interpreting the cosmological constant as the
thermodynamic pressure, we derive the thermodynamical quantities by the first
law of black hole thermodynamics and obtain the equation of state. Then, we
calculate the efficiency of the heat engine in Carnot cycle as well as
rectangular cycle, and investigate how the efficiency changes with respect to
volume. In addition, to avoid a negative temperature, we emphasize that the
charge of this black hole can not be arbitrary. Last, we check the calculation
accuracy of a benchmark scheme and discuss the upper bound and lower bound for
charged torus-like black hole in the scheme.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:04:47 GMT""}]","2021-02-10"
"2102.04604","Haochen Wang","Haochen Wang, Xiaolong Jiang, Haibing Ren, Yao Hu, Song Bai","SwiftNet: Real-time Video Object Segmentation",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this work we present SwiftNet for real-time semisupervised video object
segmentation (one-shot VOS), which reports 77.8% J &F and 70 FPS on DAVIS 2017
validation dataset, leading all present solutions in overall accuracy and speed
performance. We achieve this by elaborately compressing spatiotemporal
redundancy in matching-based VOS via Pixel-Adaptive Memory (PAM). Temporally,
PAM adaptively triggers memory updates on frames where objects display
noteworthy inter-frame variations. Spatially, PAM selectively performs memory
update and match on dynamic pixels while ignoring the static ones,
significantly reducing redundant computations wasted on segmentation-irrelevant
pixels. To promote efficient reference encoding, light-aggregation encoder is
also introduced in SwiftNet deploying reversed sub-pixel. We hope SwiftNet
could set a strong and efficient baseline for real-time VOS and facilitate its
application in mobile vision. The source code of SwiftNet can be found at
https://github.com/haochenheheda/SwiftNet.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:22:48 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 01:52:30 GMT""}]","2021-04-22"
"2102.04605","Leping Li","Leping Li, Hardi Peter, Lakshmi Pradeep Chitta, Hongqiang Song","On-disk solar coronal condensations facilitated by magnetic reconnection
  between open and closed magnetic structures","17 pages, 2 tables, 8 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abe537",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronal condensation and rain are a crucial part of the mass cycle between
the corona and chromosphere. In some cases, condensation and subsequent rain
originate in the magnetic dips formed during magnetic reconnection. This
provides a new and alternative formation mechanism for coronal rain. Until now,
only off-limb, rather than on-disk, condensation events during reconnection
have been reported. In this paper, employing extreme-ultraviolet (EUV) images
of the Solar Terrestrial Relations Observatory (STEREO) and Solar Dynamics
Observatory (SDO), we investigate the condensations facilitated by reconnection
from 2011 July 14 to 15, when STEREO was in quadrature with respect to the
Sun-Earth line. Above the limb, in STEREO/EUV Imager (EUVI) 171 \AA~images,
higher-lying open structures move downward, reconnect with the lower-lying
closed loops, and form dips. Two sets of newly reconnected structures then
form. In the dips, bright condensations occur in EUVI 304 \AA~images repeatedly
which then flow downward to the surface. In the on-disk observations by
SDO/Atmospheric Imaging Assembly (AIA) in the 171 \AA~channel, these magnetic
structures are difficult to identify. Dark condensations appear in AIA 304
\AA~images, and then move to the surface as on-disk coronal rain. The cooling
and condensation of coronal plasma is revealed by the EUV light curves. If only
the on-disk observations would be available, the relation between the
condensations and reconnection, shown clearly by the off-limb observations,
would not be identified. Thus, we suggest that some on-disk condensation events
seen in transition region and chromospheric lines may be facilitated by
reconnection.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:25:54 GMT""}]","2021-04-07"
"2102.04606","Shanette De La Motte","S.A. De La Motte, H.M. Wakeling, M.Barrett, K.Kinoshita","Diversity + Inclusion at Belle II: Where We Are, What We've Done and
  Where We Want To Be","3 pages, 1 figure Originally published at
  https://pos.sissa.it/390/977/pdf . Corresponding 3 slide presentation
  available at
  https://indico.cern.ch/event/868940/contributions/3801009/attachments/2082517/3498118/Diversity_and_Inclusion_at_Belle_II_ICHEP_2020_Shanette_De_La_Motte.pdf
  . See also companion conference note at arXiv:2102.04195v1",,,"BELLE2-CONF-PROC-2020-018 PoS(ICHEP2020)977","physics.ed-ph hep-ex hep-ph physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Belle II Collaboration comprises over 1000 international high energy
physicists, who investigate the properties of $b$-quarks and other particles at
the luminosity frontier. In order to achieve our aim of a successful physics
program, it is essential that we emphasise contributions from a diverse
community. Belle II has thus far focused on diversity in gender and sexuality,
among other efforts within our collaboration. These efforts are led by our two
Diversity Officers, elected to the newly created positions in 2018. Their role
has been to promote an inclusive atmosphere, raising awareness of diversity and
being a safe first point of call for issues of discrimination and harassment.
These proceedings accompany the short talk delivered during ICHEP 2020, marking
the first conference the Belle II Collaboration has presented in the diversity
and inclusion stream. It details the efforts described above, as well as
examining the evolving gender demographics of our community, since membership
began in 2011.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:31:14 GMT""}]","2021-02-10"
"2102.04607","Shunsuke Furuya","Shunsuke C. Furuya, Kazuaki Takasan, Masahiro Sato","Control of superexchange interactions with DC electric fields",,"Phys. Rev. Research 3, 033066 (2021)","10.1103/PhysRevResearch.3.033066",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss DC electric-field controls of superexchange interactions. We first
present generic results about antiferromagnetic and ferromagnetic superexchange
interactions valid in a broad class of Mott insulators, where we also estimate
typical field strength to observe DC electric-field effects: $\sim
1~\mathrm{MV/cm}$ for inorganic Mott insulators such as transition-metal oxides
and $\sim 0.1~\mathrm{MV/cm}$ for organic ones. Next, we apply these results to
geometrically frustrated quantum spin systems. Our theory widely applies to
(quasi-)two-dimensional and thin-film systems and one-dimensional quantum spin
systems on various lattices such as square, honeycomb, triangular, and kagome
ones. In this paper, we give our attention to those on the square lattice and
on the chain. For the square lattice, we show that DC electric fields can
control a ratio of the nearest-neighbor and next-nearest-neighbor exchange
interactions. In some realistic cases, DC electric fields make the two
next-nearest-neighbor interactions nonequivalent and eventually turns the
square-lattice quantum spin system into a deformed triangular-lattice one. For
the chain, DC electric fields can induce singlet-dimer and Haldane-dimer
orders. We show that the DC electric-field-induced spin gap $\propto
|\boldsymbol E|^{2/3}$ in the Heisenberg antiferromagnetic chain will reach
$\sim 10~\%$ of the dominant superexchange interaction in the case of a
spin-chain compound $\mathrm{KCuMoO_4(OH)}$ when the DC electric field of $\sim
1~\mathrm{MV/cm}$ is applied.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:31:23 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 15:53:03 GMT""}]","2021-07-20"
"2102.04608","Adel Sohbi","Adel Sohbi, Damian Markham, Jaewan Kim, and Marco T\'ulio Quintino","Certifying dimension of quantum systems by sequential projective
  measurements",,"Quantum 5, 472 (2021)","10.22331/q-2021-06-10-472",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  This work analyzes correlations arising from quantum systems subject to
sequential projective measurements to certify that the system in question has a
quantum dimension greater than some $d$. We refine previous known methods and
show that dimension greater than two can be certified in scenarios which are
considerably simpler than the ones presented before and, for the first time in
this sequential projective scenario, we certify quantum systems with dimension
strictly greater than three. We also perform a systematic numerical analysis in
terms of robustness and conclude that performing random projective measurements
on random pure qutrit states allows a robust certification of quantum
dimensions with very high probability.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:31:47 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 02:06:30 GMT""}]","2021-06-16"
"2102.04609","Shuai Yin","Yu-Rong Shu, Shao-Kai Jian, Shuai Yin","Nonequilibrium dynamics in deconfined quantum critical point revealed by
  imaginary-time evolution","19 pages, 14 figures","PhysRevLett.128.020601 (2022)","10.1103/PhysRevLett.128.020601",,"cond-mat.str-el cond-mat.stat-mech hep-lat","http://creativecommons.org/licenses/by/4.0/","  As proposed to describe putative continuous phase transitions between two
ordered phases, the deconfined quantum critical point (DQCP) goes beyond the
prevalent Landau-Ginzburg-Wilson (LGW) paradigm since its critical theory is
not expressed in terms of the order parameters characterizing either state, but
involves fractionalized degrees of freedom and an emergent symmetry. So far,
great efforts have been spent on its equilibrium properties, but the
nonequilibrium properties therein are largely unknown. Here we study the
nonequilibrium dynamics of the DQCP via the imaginary-time evolution in the
two-dimensional (2D) J-Q$_3$ model. We discover fascinating nonequilibrium
scaling behaviors hinging on the process of fractionization and the dynamics of
emergent symmetry associated with two length scales. Our findings not only
constitute a new realm of nonequilibrium criticality in DQCP, but also offer a
controllable knob by which to investigate the dynamics in strongly correlated
systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:31:58 GMT""}]","2022-01-14"
"2102.04610","Pengfei Wei","Pengfei Wei, Bi Zeng and Wenxiong Liao","Joint Intent Detection and Slot Filling with Wheel-Graph Attention
  Networks",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intent detection and slot filling are two fundamental tasks for building a
spoken language understanding (SLU) system. Multiple deep learning-based joint
models have demonstrated excellent results on the two tasks. In this paper, we
propose a new joint model with a wheel-graph attention network (Wheel-GAT)
which is able to model interrelated connections directly for intent detection
and slot filling. To construct a graph structure for utterances, we create
intent nodes, slot nodes, and directed edges. Intent nodes can provide
utterance-level semantic information for slot filling, while slot nodes can
also provide local keyword information for intent. Experiments show that our
model outperforms multiple baselines on two public datasets. Besides, we also
demonstrate that using Bidirectional Encoder Representation from Transformer
(BERT) model further boosts the performance in the SLU task.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:37:56 GMT""}]","2021-02-10"
"2102.04611","Lingzhong Zeng","Lingzhong Zeng","Eigenvalues for the Clamped Plate Problem of $\mathfrak{L}^{2}_{\nu}$
  Operator on Complete Riemannian manifolds","26pages. arXiv admin note: substantial text overlap with
  arXiv:2101.07989, arXiv:2101.07992",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  $\mathfrak{L}_{\nu}$ operator is an important extrinsic differential operator
of divergence type and has profound geometric settings. In this paper, we
consider the clamped plate problem of $\mathfrak{L}^{2}_{\nu}$ operator on a
bounded domain of the complete Riemannian manifolds. A general formula of
eigenvalues of $\mathfrak{L}^{2}_{\nu}$ operator is established. Applying this
general formula, we obtain some estimates for the eigenvalues with higer order
on the complete Riemannian manifolds. As several fascinating applications, we
discuss this eigenvalue problem on the complete translating solitons, minimal
submanifolds on the Euclidean space, submanifolds on the unit sphere and
projective spaces. In particular, we get a universal inequality with respect to
the $\mathcal{L}_{II}$ operator on the translating solitons. Usually, it is
very difficult to get universal inequalities for weighted Laplacian and even
Laplacian on the complete Riemannian manifolds. Therefore, this work can be
viewed as a new contribution to universal inequality.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:38:03 GMT""}]","2021-02-10"
"2102.04612","Kazuto Akiba","Kazuto Akiba, Hiroaki Nishimori, Nobuaki Umeshita, and Tatsuo C.
  Kobayashi","Successive destruction of charge density wave states by pressure in
  LaAgSb$_2$","15pages, 13 figures","Phys. Rev. B 103, 085134 (2021)","10.1103/PhysRevB.103.085134",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We comprehensively studied the magnetotransport properties of LaAgSb$_2$
under high pressure up to 4 GPa, which showed unique successive charge density
wave (CDW) transitions at $T_{CDW1}\sim 210$ K and $T_{CDW2}\sim 190$ K at
ambient pressure. With the application of pressure, both $T_{CDW1}$ and
$T_{CDW2}$ were suppressed and disappeared at the critical pressures of
$P_{CDW1}=3.0$--3.4 GPa and $P_{CDW2}=1.5$--1.9 GPa, respectively. At
$P_{CDW1}$, the Hall conductivity showed a step-like increase, which is
consistently understood by the emergence of two-dimensional hollow Fermi
surface at $P_{CDW1}$. We also observed a significant negative
magnetoresistance effect when the magnetic field and current were applied
parallel to the $c$ axis. Shubnikov--de Haas (SdH) oscillation measurements
under pressure directly showed the changes in the Fermi surface across the CDW
phase boundaries. In $P<P_{CDW2}$, three major oscillation components,
$\alpha$, $\beta$, and $\gamma$, were identified, whose frequencies were
increased by application of pressure. The increment rate of these frequencies
was considerably larger than that expected from the shrinkage of lattice
constant, indicating the unignorable band modification under pressure. In the
normal metallic phase above $P>P_{CDW1}$, we observed a single frequency of
$\sim 48$ T with a cyclotron effective mass of 0.066 $m_0$, whose cross section
in the reciprocal space corresponded to only 0.22\% of the first Brillouin
zone. Besides, we observed another oscillation component with frequency of
$\sim 9.2$ T, which is significantly enhanced in the limited pressure range of
$P_{CDW2}<P<P_{CDW1}$. The amplitude of this oscillation was anomalously
suppressed in the high-field and low-temperature region, which cannot be
explained by the conventional Lifshitz--Kosevich formula.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:40:19 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 00:45:15 GMT""}]","2021-02-25"
"2102.04613","Zhengmian Hu","Zhengmian Hu, Feihu Huang, Heng Huang","A New Framework for Variance-Reduced Hamiltonian Monte Carlo",,,,,"cs.LG math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new framework of variance-reduced Hamiltonian Monte Carlo (HMC)
methods for sampling from an $L$-smooth and $m$-strongly log-concave
distribution, based on a unified formulation of biased and unbiased variance
reduction methods. We study the convergence properties for HMC with gradient
estimators which satisfy the Mean-Squared-Error-Bias (MSEB) property. We show
that the unbiased gradient estimators, including SAGA and SVRG, based HMC
methods achieve highest gradient efficiency with small batch size under high
precision regime, and require $\tilde{O}(N + \kappa^2 d^{\frac{1}{2}}
\varepsilon^{-1} + N^{\frac{2}{3}} \kappa^{\frac{4}{3}} d^{\frac{1}{3}}
\varepsilon^{-\frac{2}{3}} )$ gradient complexity to achieve
$\epsilon$-accuracy in 2-Wasserstein distance. Moreover, our HMC methods with
biased gradient estimators, such as SARAH and SARGE, require
$\tilde{O}(N+\sqrt{N} \kappa^2 d^{\frac{1}{2}} \varepsilon^{-1})$ gradient
complexity, which has the same dependency on condition number $\kappa$ and
dimension $d$ as full gradient method, but improves the dependency of sample
size $N$ for a factor of $N^\frac{1}{2}$. Experimental results on both
synthetic and real-world benchmark data show that our new framework
significantly outperforms the full gradient and stochastic gradient HMC
approaches. The earliest version of this paper was submitted to ICML 2020 with
three weak accept but was not finally accepted.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:44:24 GMT""}]","2021-02-10"
"2102.04614","Jianrun Hu","Daya Bay collaboration: F. P. An, A. B. Balantekin, H. R. Band, M.
  Bishai, S. Blyth, G. F. Cao, J. Cao, J. F. Chang, Y. Chang, H. S. Chen, S. M.
  Chen, Y. Chen, Y. X. Chen, J. Cheng, Z. K. Cheng, J. J. Cherwinka, M. C. Chu,
  J. P. Cummings, O. Dalager, F. S. Deng, Y. Y. Ding, M. V. Diwan, T. Dohnal,
  J. Dove, M. Dvorak, D. A. Dwyer, J. P. Gallo, M. Gonchar, G. H. Gong, H.
  Gong, W. Q. Gu, J. Y. Guo, L. Guo, X. H. Guo, Y. H. Guo, Z. Guo, R. W.
  Hackenburg, S. Hans, M. He, K. M. Heeger, Y. K. Heng, A. Higuera, Y. K. Hor,
  Y. B. Hsiung, B. Z. Hu, J. R. Hu, T. Hu, Z. J. Hu, H. X. Huang, X. T. Huang,
  Y. B. Huang, P. Huber, D. E. Jaffe, K. L. Jen, X. L. Ji, X. P. Ji, R. A.
  Johnson, D. Jones, L. Kang, S. H. Kettell, S. Kohn, M. Kramer, T. J.
  Langford, J. Lee, J. H. C. Lee, R. T. Lei, R. Leitner, J. K. C. Leung, F. Li,
  J. J. Li, Q. J. Li, S. Li, S. C. Li, W. D. Li, X. N. Li, X. Q. Li, Y. F. Li,
  Z. B. Li, H. Liang, C. J. Lin, G. L. Lin, S. Lin, J. J. Ling, J. M. Link, L.
  Littenberg, B. R. Littlejohn, J. C. Liu, J. L. Liu, C. Lu, H. Q. Lu, J. S.
  Lu, K. B. Luk, X. B. Ma, X. Y. Ma, Y. Q. Ma, C. Marshall, D. A. Martinez
  Caicedo, K. T. McDonald, R. D. McKeown, Y. Meng, J. Napolitano, D. Naumov, E.
  Naumova, J. P. Ochoa-Ricoux, A. Olshevskiy, H.-R. Pan, J. Park, S. Patton, J.
  C. Peng, C. S. J. Pun, F. Z. Qi, M. Qi, X. Qian, N. Raper, J. Ren, C. Morales
  Reveco, R. Rosero, B. Roskovec, X. C. Ruan, H. Steiner, J. L. Sun, T. Tmej,
  K. Treskov, W.-H. Tse, C. E. Tull, B. Viren, V. Vorobel, C. H. Wang, J. Wang,
  M. Wang, N. Y. Wang, R. G. Wang, W. Wang, W. Wang, X. Wang, Y. Wang, Y. F.
  Wang, Z. Wang, Z. Wang, Z. M. Wang, H. Y. Wei, L. H. Wei, L. J. Wen, K.
  Whisnant, C. G. White, H. L. H. Wong, E. Worcester, D. R. Wu, F. L. Wu, Q.
  Wu, W. J. Wu, D. M. Xia, Z. Q. Xie, Z. Z. Xing, J. L. Xu, T. Xu, T. Xue, C.
  G. Yang, L. Yang, Y. Z. Yang, H. F. Yao, M. Ye, M. Yeh, B. L. Young, H. Z.
  Yu, Z. Y. Yu, B. B. Yue, S. Zeng, Y. Zeng, L. Zhan, C. Zhang, F. Y. Zhang, H.
  H. Zhang, J. W. Zhang, Q. M. Zhang, X. T. Zhang, Y. M. Zhang, Y. X. Zhang, Y.
  Y. Zhang, Z. J. Zhang, Z. P. Zhang, Z. Y. Zhang, J. Zhao, L. Zhou, H. L.
  Zhuang, J. H. Zou","Antineutrino Energy Spectrum Unfolding Based on the Daya Bay Measurement
  and Its Applications","22 pages, 10 figures, 6 supplemental materials","Chinese Physics C, Volume 45, Number 7, 2021","10.1088/1674-1137/abfc38",,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The prediction of reactor antineutrino spectra will play a crucial role as
reactor experiments enter the precision era. The positron energy spectrum of
3.5 million antineutrino inverse beta decay reactions observed by the Daya Bay
experiment, in combination with the fission rates of fissile isotopes in the
reactor, is used to extract the positron energy spectra resulting from the
fission of specific isotopes. This information can be used to produce a
precise, data-based prediction of the antineutrino energy spectrum in other
reactor antineutrino experiments with different fission fractions than Daya
Bay. The positron energy spectra are unfolded to obtain the antineutrino energy
spectra by removing the contribution from detector response with the Wiener-SVD
unfolding method. Consistent results are obtained with other unfolding methods.
A technique to construct a data-based prediction of the reactor antineutrino
energy spectrum is proposed and investigated. Given the reactor fission
fractions, the technique can predict the energy spectrum to a 2% precision. In
addition, we illustrate how to perform a rigorous comparison between the
unfolded antineutrino spectrum and a theoretical model prediction that avoids
the input model bias of the unfolding method.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:46:17 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 07:15:10 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 07:59:33 GMT""}]","2021-07-07"
"2102.04615","Jo\~ao Gabriel Zago","Jo\~ao G. Zago, Fabio L. Baldissera, Eric A. Antonelo and Rodrigo T.
  Saad","Benford's law: what does it say on adversarial images?",,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks (CNNs) are fragile to small perturbations in
the input images. These networks are thus prone to malicious attacks that
perturb the inputs to force a misclassification. Such slightly manipulated
images aimed at deceiving the classifier are known as adversarial images. In
this work, we investigate statistical differences between natural images and
adversarial ones. More precisely, we show that employing a proper image
transformation and for a class of adversarial attacks, the distribution of the
leading digit of the pixels in adversarial images deviates from Benford's law.
The stronger the attack, the more distant the resulting distribution is from
Benford's law. Our analysis provides a detailed investigation of this new
approach that can serve as a basis for alternative adversarial example
detection methods that do not need to modify the original CNN classifier
neither work on the raw high-dimensional pixels as features to defend against
attacks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:50:29 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 00:29:14 GMT""}]","2023-03-07"
"2102.04616","Yakub Sebastian","Yakub Sebastian and Chaomei Chen","The Boundary-Spanning Mechanisms of Nobel Prize Winning Papers","27 pages, 8 figures, 9 tables. Submitted to Frontiers in Research
  Metrics and Analytics","PLoS ONE 16(8) (2021): e0254744","10.1371/journal.pone.0254744",,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  The breakthrough potentials of research papers can be explained by their
boundary-spanning qualities. Here, for the first time, we apply the structural
variation analysis (SVA) model and its affiliated metrics to investigate the
extent to which such qualities characterize a group of Nobel Prize winning
papers. We find that these papers share remarkable boundary-spanning traits,
marked by exceptional abilities to connect disparate and topically-diverse
clusters of research papers. Further, their publications exert structural
variations on the scale that significantly alters the betweenness centrality
distributions of existing intellectual space. Overall, SVA not only provides a
set of leading indicators for describing future Nobel Prize winning papers, but
also broadens our understanding of the similar prize-winning properties that
may have been overlooked among other regular publications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:55:41 GMT""}]","2021-09-01"
"2102.04617","Kiyoharu Kawana","Yuta Hamada, Hikaru Kawai, Kiyoharu Kawana, Kin-ya Oda, and Kei Yagyu","Minimal scenario of Criticality for Electroweak scale, Neutrino Masses,
  Dark Matter, and Inflation","30 pages, 7 figures; Version accepted in EPJC (v2)",,"10.1140/epjc/s10052-021-09735-z","OU-HET-1087","hep-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  We propose a minimal model that can explain the electroweak scale, neutrino
masses, Dark Matter (DM), and successful inflation all at once based on the
multicritical-point principle (MPP). The model has two singlet scalar fields
that realize an analogue of the Coleman-Weinberg mechanism, in addition to the
Standard Model with heavy Majorana right-handed neutrinos. By assuming a $Z_2 $
symmetry, one of the scalars becomes a DM candidate whose property is almost
the same as the minimal Higgs-portal scalar DM. In this model, the MPP can
naturally realize a saddle point in the Higgs potential at high energy scales.
By the renormalization-group analysis, we study the critical Higgs inflation
with non-minimal coupling $\xi |H|^2 R$ that utilizes the saddle point of the
Higgs potential. We find that it is possible to realize successful inflation
even for $\xi=25$ and that the heaviest right-handed neutrino is predicted to
have a mass around $10^{14}$ GeV to meet the current cosmological observations.
Such a small value of $\xi$ can be realized by the Higgs-portal coupling
$\lambda_{SH}\simeq 0.32$ and the vacuum expectation value of the additional
neutral scalar $\langle\phi\rangle\simeq 2.7$ TeV, which correspond to the dark
matter mass 2.0 TeV, its spin-independent cross section $1.8\times10^{-9}$ pb,
and the mass of additional neutral scalar 190 GeV.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:55:54 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 06:08:00 GMT""}]","2022-01-06"
"2102.04618","Kotaro Hisa","Kotaro Hisa, Jin Takahashi","Optimal singularities of initial data for solvability of the Hardy
  parabolic equation",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Cauchy problem for the Hardy parabolic equation $\partial_t
u-\Delta u=|x|^{-\gamma}u^p$ with initial data $u_0$ singular at some point
$z$. Our main results show that, if $z\neq 0$, then the optimal strength of the
singularity of $u_0$ at $z$ for the solvability of the equation is the same as
that of the Fujita equation $\partial_t u-\Delta u=u^p$. Moreover, if $z=0$,
then the optimal singularity for the Hardy parabolic equation is weaker than
that of the Fujita equation. We also obtain analogous results for a fractional
case $\partial_t u+(-\Delta)^{\theta/2} u=|x|^{-\gamma}u^p$ with $0<\theta<2$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:57:58 GMT""}]","2021-02-10"
"2102.04619","Alexander Williamson","A. Williamson, C. W. James, S. J. Tingay, S. J. McSweeney, S. M. Ord","An Ultra-High Time Resolution Cosmic Ray Detection Mode for the
  Murchison Widefield Array","9 pages, 8 figures. To be published in the Journal of Astronomical
  Instrumentation","Journal of Astronomical Instrumentation, Vol. 10, No. 1 (2021),
  page 2150003","10.1142/S2251171721500033",,"astro-ph.IM","http://creativecommons.org/licenses/by-sa/4.0/","  The radio-wavelength detection of extensive air showers (EAS) initiated by
cosmic-ray interactions in the Earth's atmosphere is a promising technique for
investigating the origin of these particles and the physics of their
interactions. The Low Frequency Array (LOFAR) and the Owens Valley Long
Wavelength Array (OVRO-LWA) have both demonstrated that the dense cores of low
frequency radio telescope arrays yield detailed information on the radiation
ground pattern, which can be used to reconstruct key EAS properties and infer
the primary cosmic-ray composition. Here, we demonstrate a new observation mode
of the Murchison Widefield Array (MWA), tailored to the observation of the
sub-microsecond coherent bursts of radiation produced by EAS. We first show how
an aggregate 30.72 MHz bandwidth (3072x 10 kHz frequency channels) recorded at
0.1 ms resolution with the MWA's voltage capture system (VCS) can be
synthesised back to the full bandwidth Nyquist resolution of 16.3 ns. This
process, which involves `inverting' two sets of polyphase filterbanks, retains
90.5% of the signal-to-noise of a cosmic ray signal. We then demonstrate the
timing and positional accuracy of this mode by resolving the location of a
calibrator pulse to within 5 m. Finally, preliminary observations show that the
rate of nanosecond radio-frequency interference (RFI) events is 0.1 Hz, much
lower than that found at the sites of other radio telescopes that study cosmic
rays. We conclude that the identification of cosmic rays at the MWA, and hence
with the low-frequency component of the Square Kilometre Array, is feasible
with minimal loss of efficiency due to RFI.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 02:59:35 GMT""}]","2021-03-29"
"2102.04620","Yoshiki Toba","Yoshiki Toba, Yoshihiro Ueda, Poshak Gandhi, Claudio Ricci, Denis
  Burgarella, Veronique Buat, Tohru Nagao, Shinki Oyabu, Hideo Matsuhara,
  Bau-Ching Hsieh","How does the Polar Dust affect the Correlation between Dust Covering
  Factor and Eddington Ratio in Type 1 Quasars Selected from the Sloan Digital
  Sky Survey Data Release 16?","20 pages, 14 figures, and 4 tables, accepted for publication in ApJ.
  Physical properties (e.g., BH mass, Eddington ratio, IR luminosity) of 37,181
  quasars at z < 0.7 selected from the SDSS DR16 will be available as a
  Machine-readable table",,"10.3847/1538-4357/abe94a",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We revisit the dependence of covering factor (CF) of dust torus on physical
properties of active galactic nuclei (AGNs) by taking into account an AGN polar
dust emission. The CF is converted from a ratio of infrared (IR) luminosity
contributed from AGN dust torus ($L_{\rm IR}^{\rm torus}$) and AGN bolometric
luminosity ($L_{\rm bol}$), by assuming a non-linear relation between
luminosity ratio and intrinsic CF. We select 37,181 type 1 quasars at $z < 0.7$
from the Sloan Digital Sky Survey Data Release 16 quasar catalog. Their $L_{\rm
bol}$, black hole mass ($M_{\rm BH}$), and Eddington ratio ($\lambda_{\rm
Edd}$) are derived by spectral fitting with QSFit. We conduct spectral energy
distribution decomposition by using X-CIGALE with clumpy torus and polar dust
model to estimate $L_{\rm IR}^{\rm torus}$ without being affected by the
contribution of stellar and AGN polar dust to IR emission. For 5720 quasars
whose physical quantities are securely determined, we perform a correlation
analysis on CF and (i) $L_{\rm bol}$, (ii) $M_{\rm BH}$, and (iii)
$\lambda_{\rm Edd}$. As a result, anti-correlations for CF-$L_{\rm bol}$,
CF-$M_{\rm BH}$, and CF-$\lambda_{\rm Edd}$ are confirmed. We find that
incorporating the AGN polar dust emission makes those anti-correlations
stronger which are compared to those without considering it. This indicates
that polar dust wind provably driven by AGN radiative pressure is one of the
key components to regulate obscuring material of AGNs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:03:43 GMT""}]","2021-05-19"
"2102.04621","Xinchen Liu","Jinkai Zheng, Xinchen Liu, Chenggang Yan, Jiyong Zhang, Wu Liu,
  Xiaoping Zhang, Tao Mei","TraND: Transferable Neighborhood Discovery for Unsupervised Cross-domain
  Gait Recognition","Accepted by ISCAS 2021. 5 pages, 2 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gait, i.e., the movement pattern of human limbs during locomotion, is a
promising biometric for the identification of persons. Despite significant
improvement in gait recognition with deep learning, existing studies still
neglect a more practical but challenging scenario -- unsupervised cross-domain
gait recognition which aims to learn a model on a labeled dataset then adapts
it to an unlabeled dataset. Due to the domain shift and class gap, directly
applying a model trained on one source dataset to other target datasets usually
obtains very poor results. Therefore, this paper proposes a Transferable
Neighborhood Discovery (TraND) framework to bridge the domain gap for
unsupervised cross-domain gait recognition. To learn effective prior knowledge
for gait representation, we first adopt a backbone network pre-trained on the
labeled source data in a supervised manner. Then we design an end-to-end
trainable approach to automatically discover the confident neighborhoods of
unlabeled samples in the latent space. During training, the class consistency
indicator is adopted to select confident neighborhoods of samples based on
their entropy measurements. Moreover, we explore a high-entropy-first neighbor
selection strategy, which can effectively transfer prior knowledge to the
target domain. Our method achieves state-of-the-art results on two public
datasets, i.e., CASIA-B and OU-LP.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:07:07 GMT""}]","2021-02-10"
"2102.04622","Raphael M. Albuquerque","R.M. Albuquerque, S. Narison, D. Rabetiarivony and G. Randriamanatrika","The New Charm-Strange Resonances in the D^- K^+ Channel","Talk given at 23rd High-Energy Physics International Conference in
  Quantum Chromodynamics (QCD 20, 35th anniversary), 27-30 October 2020,
  Montpellier-France (v2: typos corrected, results unchanged)",,,,"hep-ph hep-ex hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We evaluate the masses and decay constants of the $0^+$ and $1^-$ open-charm
$(\bar{c}\bar{d})(us)$ tetraquarks and molecular states from QCD spectral sum
rules (QSSR) by using QCD Laplace sum rule (LSR). This method takes into
account the stability criteria where the factorized perturbative NLO
corrections and the contributions of quark and gluon condensates up to
dimension-6 in the OPE are included. We confront our results with the $D^- K^+$
invariant mass recently reported by LHCb from $B^+ \to D^+(D^- K^+)$ decays. We
expect that the resonance near the $D^- K^+$ threshold can be originated from
the $0^{+}(D^-K^+)$ molecule and/or $D^- K^+$ scattering. The $X_0(2900)$
scalar state and the resonance $X_J(3150)$ (if $J = 0$) can emerge from a
minimal mixing model, with a tiny mixing angle $\theta_0 \simeq (5.2 \pm
1.9)^0$, between a scalar Tetramole $({\cal T}_{\!\!{\cal M}0})$ (superposition
of nearly degenerated hypothetical molecules and compact tetraquarks states
with the same quantum numbers), having a mass $M_{{\cal T}_{\!\!{\cal M}0}} =
2743(18)$ MeV, and the first radial excitation of the $D^- K^+$ molecule with
mass $M_{(DK)_1} = 3678(310)$ MeV. In an analogous way, the $X_1(2900)$ and the
$X_J(3350)$ (if $J = 1$) could be a mixture between the vector Tetramole
$({\cal T}_{\!\!{\cal M}1})$, with a mass $M_{{\cal T}_{\!\!{\cal M}1}} =
2656(20)$ MeV, and its first radial excitation having a mass $M_{{\cal
T}_{\!\!{\cal M}1}} = 4592(141)$ MeV with an angle $\theta_0 \simeq (9.1 \pm
0.6)^0$. A (non)-confirmation of these statements requires experimental
findings of the quantum numbers of the resonances at $3150$ and $3350$ MeV.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:08:18 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 05:18:38 GMT""}]","2021-02-22"
"2102.04623","Alexander Turbiner","A.V. Turbiner and E. Shuryak","On connection between perturbation theory and semiclassical expansion in
  quantum mechanics","17 pages, 2 figures, 11 references; several typos fixed, to be
  published at Nuclear Physics B","Nuclear Physics B 989 (2023) 116117",,,"quant-ph hep-lat hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that for the one-dimensional anharmonic oscillator with potential
$V(x)= a x^2 + b g x^3 +\ldots=\frac{1}{g^2}\,\hat{V}(gx)$, as well as for the
radial oscillator $V(r)=\frac{1}{g^2}\,\hat{V}(gr)$ and for the perturbed
Coulomb problem $V(r)=\frac{\alpha}{r}+ \beta g r + \ldots = g\,\tilde{V}(gr)$,
the Perturbation Theory in powers of the coupling constant $g$ (weak coupling
regime) and the semiclassical expansion in powers of $\hbar^{1/2}$ for the
energies coincide. This is related to the fact that the dynamics developed in
two spaces: $x\ (r)$-space and $gx\ (gr)$-space, lead to the same energy
spectra. The equations which govern dynamics in these two spaces, the
Riccati-Bloch equation and the Generalized Bloch equation, respectively, are
presented. It is shown that the perturbation theory for the logarithmic
derivative of the wavefunction in $gx\ (gr)$- space leads to (true)
semiclassical expansion in powers of $\hbar^{1/2}$; for the one-dimensional
case this corresponds to the flucton calculus for the density matrix in the
path integral formalism in Euclidean (imaginary) time proposed by one of the
authors, Shuryak(1988). Matching the perturbation theory in powers of $g$ and
the semiclassical expansion in powers of $\hbar^{1/2}$ for the wavefunction
leads to a highly accurate local approximation in the entire coordinate space,
its expectation value for the Hamiltonian provides a prescription for the
summation of the perturbative (trans)-series.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:13:56 GMT""},{""version"":""v2"",""created"":""Sun, 19 Sep 2021 10:49:19 GMT""},{""version"":""v3"",""created"":""Thu, 2 Feb 2023 09:12:49 GMT""}]","2023-03-07"
"2102.04624","Yan He","Yan He and Min Ru","Nevanlinna Pair and Algebraic Hyperbolicity",,,,,"math.AG math.CV","http://creativecommons.org/licenses/by/4.0/","  We introduce the notion of the $\textit{Nevanlinna pair}$ for a pair $(X,
D)$, where $X$ is a projective variety and $D$ is an effective Cartier divisor
on $X$. This notion links and unifies the Nevanlinna theory, the complex
hyperbolicity (Brody and Kobayashi hyperbolicity), the big Picard type
extension theorem (more generally the Borel hyperbolicity), as well as the
algebraic hyperbolicity. The key is to use the Nevanlinna theory on parabolic
Riemann surfaces recently developed by P\v{a}un and Sibony.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:15:07 GMT""}]","2021-02-10"
"2102.04625","Yu Wang","Yu Wang, Ke Wang, Linzhang Wang","WheaCha: A Method for Explaining the Predictions of Models of Code",,,,,"cs.LG cs.PL cs.SE","http://creativecommons.org/licenses/by/4.0/","  Attribution methods have emerged as a popular approach to interpreting model
predictions based on the relevance of input features. Although the feature
importance ranking can provide insights of how models arrive at a prediction
from a raw input, they do not give a clear-cut definition of the key features
models use for the prediction. In this paper, we present a new method, called
WheaCha, for explaining the predictions of code models. Although WheaCha
employs the same mechanism of tracing model predictions back to the input
features, it differs from all existing attribution methods in crucial ways.
Specifically, WheaCha divides an input program into ""wheat"" (i.e., the defining
features that are the reason for which models predict the label that they
predict) and the rest ""chaff"" for any prediction of a learned code model. We
realize WheaCha in a tool, HuoYan, and use it to explain four prominent code
models: code2vec, seq-GNN, GGNN, and CodeBERT. Results show (1) HuoYan is
efficient - taking on average under twenty seconds to compute the wheat for an
input program in an end-to-end fashion (i.e., including model prediction time);
(2) the wheat that all models use to predict input programs is made of simple
syntactic or even lexical properties (i.e., identifier names); (3) Based on
wheat, we present a novel approach to explaining the predictions of code models
through the lens of training data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:17:46 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 01:48:28 GMT""},{""version"":""v3"",""created"":""Tue, 12 Jul 2022 06:32:27 GMT""}]","2022-07-13"
"2102.04626","Lu Lu","Lu Lu, Raphael Pestourie, Wenjie Yao, Zhicheng Wang, Francesc Verdugo,
  Steven G. Johnson","Physics-informed neural networks with hard constraints for inverse
  design",,,,,"physics.comp-ph cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Inverse design arises in a variety of areas in engineering such as acoustic,
mechanics, thermal/electronic transport, electromagnetism, and optics. Topology
optimization is a major form of inverse design, where we optimize a designed
geometry to achieve targeted properties and the geometry is parameterized by a
density function. This optimization is challenging, because it has a very high
dimensionality and is usually constrained by partial differential equations
(PDEs) and additional inequalities. Here, we propose a new deep learning method
-- physics-informed neural networks with hard constraints (hPINNs) -- for
solving topology optimization. hPINN leverages the recent development of PINNs
for solving PDEs, and thus does not rely on any numerical PDE solver. However,
all the constraints in PINNs are soft constraints, and hence we impose hard
constraints by using the penalty method and the augmented Lagrangian method. We
demonstrate the effectiveness of hPINN for a holography problem in optics and a
fluid problem of Stokes flow. We achieve the same objective as conventional
PDE-constrained optimization methods based on adjoint methods and numerical PDE
solvers, but find that the design obtained from hPINN is often simpler and
smoother for problems whose solution is not unique. Moreover, the
implementation of inverse design with hPINN can be easier than that of
conventional methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:18:15 GMT""}]","2022-01-19"
"2102.04627","Bhavtosh Rath","Bhavtosh Rath, Xavier Morales, Jaideep Srivastava","SCARLET: Explainable Attention based Graph Neural Network for Fake News
  spreader prediction","Accepted to the Pacific-Asia Conference on Knowledge Discovery and
  Data Mining (PAKDD, 2021)",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  False information and true information fact checking it, often co-exist in
social networks, each competing to influence people in their spread paths. An
efficient strategy here to contain false information is to proactively identify
if nodes in the spread path are likely to endorse false information (i.e.
further spread it) or refutation information (thereby help contain false
information spreading). In this paper, we propose SCARLET (truSt and
Credibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely
action of nodes in the spread path. We aggregate trust and credibility features
from a node's neighborhood using historical behavioral data and network
structure and explain how features of a spreader's neighborhood vary. Using
real world Twitter datasets, we show that the model is able to predict false
information spreaders with an accuracy of over 87%.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:25:57 GMT""}]","2021-02-10"
"2102.04628","Youming Li","Youming Li and Da-Quan Jiang and Chen Jia","Steady-state joint distribution for first-order stochastic reaction
  kinetics","33 pages, 6 figures","Phys. Rev. E 104, 024408 (2021)","10.1103/PhysRevE.104.024402",,"q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the analytical solution for the marginal distribution of a stochastic
chemical reaction network has been extensively studied, its joint distribution,
i.e. the solution of a high-dimensional chemical master equation, has received
much less attention. Here we develop a novel method of computing the exact
joint distributions of a wide class of first-order stochastic reaction systems
in steady-state conditions. The effectiveness of our method is validated by
applying it to four gene expression models of biological significance,
including models with 2A peptides, nascent mRNA, gene regulation, translational
bursting, and alternative splicing.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:34:43 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 05:16:19 GMT""},{""version"":""v3"",""created"":""Sat, 13 Nov 2021 13:12:07 GMT""}]","2021-11-16"
"2102.04629","Qinglong Li","Qinglong Li, Fei Gao, Haixin Guan and Kaichi Ma","Real-time Monaural Speech Enhancement With Short-time Discrete Cosine
  Transform","5 pages, 2 figures, Journal submitted",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech enhancement algorithms based on deep learning have been improved in
terms of speech intelligibility and perceptual quality greatly. Many methods
focus on enhancing the amplitude spectrum while reconstructing speech using the
mixture phase. Since the clean phase is very important and difficult to
predict, the performance of these methods will be limited. Some researchers
attempted to estimate the phase spectrum directly or indirectly, but the effect
is not ideal. Recently, some studies proposed the complex-valued model and
achieved state-of-the-art performance, such as deep complex convolution
recurrent network (DCCRN). However, the computation of the model is huge. To
reduce the complexity and further improve the performance, we propose a novel
method using discrete cosine transform as the input in this paper, called deep
cosine transform convolutional recurrent network (DCTCRN). Experimental results
show that DCTCRN achieves state-of-the-art performance both on objective and
subjective metrics. Compared with noisy mixtures, the mean opinion score (MOS)
increased by 0.46 (2.86 to 3.32) absolute processed by the proposed model with
only 2.86M parameters.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:34:58 GMT""}]","2021-02-10"
"2102.04630","Enrico Valdinoci","Serena Dipierro, Giorgio Poggesi, and Enrico Valdinoci","A quantitative rigidity result for a two-dimensional Frenkel-Kontorova
  model",,,"10.1016/j.physd.2021.132871",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a Frenkel-Kontorova system of harmonic oscillators in a
two-dimensional Euclidean lattice and we obtain a quantitative estimate on the
angular function of the equilibria. The proof relies on a PDE method related to
a classical conjecture by E. De Giorgi, also in view of an elegant technique
based on complex variables that was introduced by A. Farina.
  In the discrete setting, a careful analysis of the reminders is needed to
exploit this type of methodologies inspired by continuum models.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:34:58 GMT""}]","2021-03-17"
"2102.04631","Yue Zhao","Peijun Li, Xiaohua Yao, Yue Zhao","Stability for an inverse source problem of the biharmonic operator",,,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we study for the first time the stability of the inverse
source problem for the biharmonic operator with a compactly supported potential
in $\mathbb R^3$. Firstly, to connect the boundary data with the unknown
source, we shall consider an eigenvalue problem for the bi-Schr$\ddot{\rm
o}$dinger operator $\Delta^2 + V(x)$ on a ball which contains the support of
the potential $V$. We prove a Weyl-type law for the upper bounds of spherical
normal derivatives of both the eigenfunctions $\phi$ and their Laplacian
$\Delta\phi$ corresponding to the bi-Schr$\ddot{\rm o}$dinger operator. This
type of upper bounds was proved by Hassell and Tao for the Schr$\ddot{\rm
o}$dinger operator. Secondly, we investigate the meromorphic continuation of
the resolvent of the bi-Schr$\ddot{\rm o}$dinger operator and prove the
existence of a resonance-free region and an estimate of $L^2_{\rm comp} -
L^2_{\rm loc}$ type for the resolvent. As an application, we prove a bound of
the analytic continuation of the data from the given data to the higher
frequency data. Finally, we derive the stability estimate which consists of the
Lipschitz type data discrepancy and the high frequency tail of the source
function, where the latter decreases as the upper bound of the frequency
increases.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:44:54 GMT""}]","2021-02-10"
"2102.04632","Shanshan Huang","Shanshan Huang and Kenny Q. Zhu","Statistically Profiling Biases in Natural Language Reasoning Datasets
  and Models",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recent work has indicated that many natural language understanding and
reasoning datasets contain statistical cues that may be taken advantaged of by
NLP models whose capability may thus be grossly overestimated. To discover the
potential weakness in the models, some human-designed stress tests have been
proposed but they are expensive to create and do not generalize to arbitrary
models. We propose a light-weight and general statistical profiling framework,
ICQ (I-See-Cue), which automatically identifies possible biases in any
multiple-choice NLU datasets without the need to create any additional test
cases, and further evaluates through blackbox testing the extent to which
models may exploit these biases.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:51:53 GMT""}]","2021-02-10"
"2102.04633","Daniel Selsam","Daniel Selsam and Jesse Michael Han","$k$-Equivalence Relations and Associated Algorithms",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lines and circles pose significant scalability challenges in synthetic
geometry. A line with $n$ points implies ${n \choose 3}$ collinearity atoms, or
alternatively, when lines are represented as functions, equality among ${n
\choose 2}$ different lines. Similarly, a circle with $n$ points implies ${n
\choose 4}$ cocyclicity atoms or equality among ${n \choose 3}$ circumcircles.
We introduce a new mathematical concept of $k$-equivalence relations, which
generalizes equality ($k=1$) and includes both lines ($k=2$) and circles
($k=3$), and present an efficient proof-producing procedure to compute the
closure of a $k$-equivalence relation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:55:09 GMT""}]","2021-02-10"
"2102.04634","Saeed Nasseh","Saeed Nasseh, Maiko Ono, and Yuji Yoshino","Naive liftings of DG modules","19 pages","Mathematische Zeitschrift, 2022","10.1007/s00209-021-02951-z",,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let n be a positive integer, and let A be a strongly commutative differential
graded (DG) algebra over a commutative ring R. Assume that
  (a) B=A[X_1,...,X_n] is a polynomial extension of A, where X_1,...,X_n are
variables of positive degrees; or
  (b) A is a divided power DG R-algebra and B=A<X_1,...,X_n> is a free
extension of A obtained by adjunction of variables X_1,...,X_n of positive
degrees.
  In this paper, we study naive liftability of DG modules along the natural
injection A-->B using the notions of diagonal ideals and homotopy limits. We
prove that if N is a bounded below semifree DG B-module such that Ext_B^i(N,
N)=0 for all i>0, then N is naively liftable to A. This implies that N is a
direct summand of a DG B-module that is liftable to A. Also, the relation
between naive liftability of DG modules and the Auslander-Reiten Conjecture has
been described.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:04:27 GMT""}]","2022-01-28"
"2102.04635","Zhishuai Guo","Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, Tianbao Yang","Federated Deep AUC Maximization for Heterogeneous Data with a Constant
  Communication Complexity","Accepted by ICML2021. Code is available in
  https://github.com/Optimization-AI/ICML2021_FedDeepAUC_CODASCA, which is a
  part of our open-sourced library LibAUC (www.libauc.org)","International Conference on Machine Learning (ICML 2021)",,,"cs.LG cs.DC math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep AUC (area under the ROC curve) Maximization (DAM) has attracted much
attention recently due to its great potential for imbalanced data
classification. However, the research on Federated Deep AUC Maximization (FDAM)
is still limited. Compared with standard federated learning (FL) approaches
that focus on decomposable minimization objectives, FDAM is more complicated
due to its minimization objective is non-decomposable over individual examples.
In this paper, we propose improved FDAM algorithms for heterogeneous data by
solving the popular non-convex strongly-concave min-max formulation of DAM in a
distributed fashion, which can also be applied to a class of non-convex
strongly-concave min-max problems. A striking result of this paper is that the
communication complexity of the proposed algorithm is a constant independent of
the number of machines and also independent of the accuracy level, which
improves an existing result by orders of magnitude. The experiments have
demonstrated the effectiveness of our FDAM algorithm on benchmark datasets, and
on medical chest X-ray images from different organizations. Our experiment
shows that the performance of FDAM using data from multiple hospitals can
improve the AUC score on testing data from a single hospital for detecting
life-threatening diseases based on chest radiographs. The proposed method is
implemented in our open-sourced library LibAUC (www.libauc.org) whose github
address is https://github.com/Optimization-AI/ICML2021_FedDeepAUC_CODASCA.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:05:19 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 19:14:09 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 16:55:35 GMT""}]","2021-09-14"
"2102.04636","Nicole Kirchner-Hall","Nicole E. Kirchner-Hall, Wayne Zhao, Yihuang Xiong, Iurii Timrov, and
  Ismaila Dabo","Extensive Benchmarking of DFT+U Calculations for Predicting Band Gaps","22 pages, 5 figures, 6 tables","Appl. Sci. 2021, 11, 2395","10.3390/app11052395",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate computational predictions of band gaps are of practical importance
to the modeling and development of semiconductor technologies, such as
(opto)electronic devices and photoelectrochemical cells. Among available
electronic-structure methods, density-functional theory (DFT) with the Hubbard
U correction (DFT+U) applied to band edge states is a computationally tractable
approach to improve the accuracy of band gap predictions beyond that of DFT
calculations based on (semi)local functionals. At variance with DFT
approximations, which are not intended to describe optical band gaps and other
excited-state properties, DFT+U can be interpreted as an approximate
spectral-potential method when U is determined by imposing the piecewise
linearity of the total energy with respect to electronic occupations in the
Hubbard manifold (thus removing self-interaction errors in this subspace),
thereby providing a (heuristic) justification for using DFT+U to predict band
gaps. However, it is still frequent in the literature to determine the Hubbard
U parameters semiempirically by tuning their values to reproduce experimental
band gaps, which ultimately alters the description of other total-energy
characteristics. Here, we present an extensive assessment of DFT+U band gaps
computed using self-consistent ab initio U parameters obtained from
density-functional perturbation theory to impose the aforementioned piecewise
linearity of the total energy. The study is carried out on 20 compounds
containing transition-metal or p-block (group III-IV) elements, including
oxides, nitrides, sulfides, oxynitrides, and oxysulfides...
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:07:22 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 00:37:07 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 21:39:31 GMT""}]","2021-03-16"
"2102.04637","Jakub Sowa","Jakub K. Sowa, Rudolph A. Marcus","On the theory of charge transport and entropic effects in solvated
  molecular junctions",,"J. Chem. Phys. 154, 034110 (2021)","10.1063/5.0034782",,"physics.chem-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Experimental studies on single-molecule junctions are typically in need of a
simple theoretical approach that can reproduce or be fitted to experimentally
measured transport data. In this context, the single-level variant of the
Landauer approach is most commonly used but methods based on Marcus theory are
also gaining in popularity. Recently, a generalized theory unifying these two
approaches has also been developed. In the present work, we extend this theory
so that it includes entropic effects (which can be important when polar
solvents are involved, but are likely minor for solid-state systems). We
investigate the temperature-dependence of the electric current and compare it
to the behavior predicted by the Landauer and the conventional Marcus theory.
We argue that this generalized theory provides a simple yet effective framework
for understanding charge transport through molecular junctions. Furthermore, we
explore the role of the entropic effects in different transport regimes and
suggest experimental criteria for detecting them in solvated molecular
junctions. Lastly, in order to account for nuclear tunnelling effects, we also
demonstrate how lifetime broadening can be introduced into the
Marcus-Levich-Dogonadze-Jortner-type description of electron transport.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:09:59 GMT""}]","2021-02-10"
"2102.04638","Liping Li","Wee Liang Gan and Liping Li","Adjoint functors on the representation category of $\mathscr{OI}$",,,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study adjunction relations between some natural functors on
the representation category of the category of finite linearly ordered sets and
order-preserving injections. We also prove that the Nakayama functor induces an
equivalence from the Serre quotient of the category of finitely generated
modules by the category of finitely generated torsion modules to the category
of finite dimensional modules.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:10:03 GMT""}]","2021-02-10"
"2102.04639","Jie Mei","Jie Mei, Jenq-Neng Hwang, Suzanne Romain, Craig Rose, Braden Moore,
  Kelsey Magrane","Absolute 3D Pose Estimation and Length Measurement of Severely Deformed
  Fish from Monocular Videos in Longline Fishing","Accepted to ICASSP2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monocular absolute 3D fish pose estimation allows for efficient fish length
measurement in the longline fisheries, where fishes are under severe
deformation during the catching process. This task is challenging since it
requires locating absolute 3D fish keypoints based on a short monocular video
clip. Unlike related works, which either require expensive 3D ground-truth data
and/or multiple-view images to provide depth information, or are limited to
rigid objects, we propose a novel frame-based method to estimate the absolute
3D fish pose and fish length from a single-view 2D segmentation mask. We first
introduce a relative 3D fish template. By minimizing an objective function, our
method systematically estimates the relative 3D pose of the target fish and
fish 2D keypoints in the image. Finally, with a closed-form solution, the
relative 3D fish pose can help locate absolute 3D keypoints, resulting in the
frame-based absolute fish length measurement, which is further refined based on
the statistical temporal inference for the optimal fish length measurement from
the video clip. Our experiments show that this method can accurately estimate
the absolute 3D fish pose and further measure the absolute length, even
outperforming the state-of-the-art multi-view method.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:15:51 GMT""}]","2021-02-10"
"2102.04640","Zhuo Li","Zhuo Li, Weiqing Min, Jiajun Song, Yaohui Zhu, Liping Kang, Xiaoming
  Wei, Xiaolin Wei, Shuqiang Jiang","Rethinking the Optimization of Average Precision: Only Penalizing
  Negative Instances before Positive Ones is Enough",,,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by/4.0/","  Optimizing the approximation of Average Precision (AP) has been widely
studied for image retrieval. Limited by the definition of AP, such methods
consider both negative and positive instances ranking before each positive
instance. However, we claim that only penalizing negative instances before
positive ones is enough, because the loss only comes from these negative
instances. To this end, we propose a novel loss, namely Penalizing Negative
instances before Positive ones (PNP), which can directly minimize the number of
negative instances before each positive one. In addition, AP-based methods
adopt a fixed and sub-optimal gradient assignment strategy. Therefore, we
systematically investigate different gradient assignment solutions via
constructing derivative functions of the loss, resulting in PNP-I with
increasing derivative functions and PNP-D with decreasing ones. PNP-I focuses
more on the hard positive instances by assigning larger gradients to them and
tries to make all relevant instances closer. In contrast, PNP-D pays less
attention to such instances and slowly corrects them. For most real-world data,
one class usually contains several local clusters. PNP-I blindly gathers these
clusters while PNP-D keeps them as they were. Therefore, PNP-D is more
superior. Experiments on three standard retrieval datasets show consistent
results with the above analysis. Extensive evaluations demonstrate that PNP-D
achieves the state-of-the-art performance. Code is available at
https://github.com/interestingzhuo/PNPloss
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:30:15 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 06:05:32 GMT""},{""version"":""v3"",""created"":""Wed, 8 Dec 2021 08:03:07 GMT""},{""version"":""v4"",""created"":""Sat, 7 May 2022 09:18:33 GMT""}]","2022-05-10"
"2102.04641","Kosuke Nomura","K. Nomura, R. Rodr\'iguez-Guzm\'an, L. M. Robledo, J. E.
  Garc\'ia-Ramos","Quadrupole-octupole coupling and the onset of octupole deformation in
  actinides","12 pages, 12 figures","Phys. Rev. C 103, 044311 (2021)","10.1103/PhysRevC.103.044311",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evolution of quadrupole and octupole collectivity and their coupling is
investigated in a series of even-even isotopes of the actinide Ra, Th, U, Pu,
Cm, and Cf with neutron number in the interval $130\leqslant N\leqslant 150$.
The Hartree-Fock-Bogoliubov approximation, based on the parametrization D1M of
the Gogny energy density functional, is employed to generate potential energy
surfaces depending upon the axially-symmetric quadrupole and octupole shape
degrees of freedom. The mean-field energy surface is then mapped onto the
expectation value of the $sdf$ interacting-boson-model Hamiltonian in the boson
condensate state as to determine the strength parameters of the boson
Hamiltonian. Spectroscopic properties related to the octupole degree of freedom
are produced by diagonalizing the mapped Hamiltonian. Calculated low-energy
negative-parity spectra, $B(E3;3^{-}_{1}\to 0^{+}_{1})$ reduced transition
rates, and effective octupole deformation suggest that the transition from
nearly spherical to stable octupole-deformed, and to octupole vibrational
states occurs systematically in the actinide region.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:38:43 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 03:16:37 GMT""}]","2021-04-21"
"2102.04642","Ha Nguyen","Muhammad Hanif and Ha H. Nguyen","Frequency-Shift Chirp Spread Spectrum Communications with Index
  Modulation","The first version of this paper was submitted to IEEE Internet of
  Things Journal on July 14, 2020. The revised version was submitted on October
  28, 2020, accepted May 15, 2021. The main idea and results of this work are
  documented in United States Patent #10,778,282, Sept. 2020.
  (https://researchers.usask.ca/ha-nguyen/documents/patents/us10778282b1-hanif.pdf)",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel frequency-shift chirp spread spectrum (FSCSS)
system with index modulation (IM). By using combinations of orthogonal chirp
signals for message representation, the proposed FSCSS-IM system is very
flexible to design and can achieve much higher data rates than the conventional
FSCSS system under the same bandwidth. The paper presents optimal detection
algorithms, both coherently and non-coherently, for the proposed FSCSS-IM
system. Furthermore, a low-complexity non-coherent detection algorithm is also
developed to reduce the computational complexity of the receiver, which is
shown to achieve near-optimal performance. Results are presented to demonstrate
that the proposed system, while enabling much higher data rates, enjoys similar
bit-error performance as that of the conventional FSCSS system.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:47:25 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 16:36:05 GMT""}]","2021-05-20"
"2102.04643","David Thulke","David Thulke, Nico Daheim, Christian Dugast, Hermann Ney","Efficient Retrieval Augmented Generation from Unstructured Knowledge for
  Task-Oriented Dialog","Accepted by DSTC9 Workshop at AAAI-2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper summarizes our work on the first track of the ninth Dialog System
Technology Challenge (DSTC 9), ""Beyond Domain APIs: Task-oriented
Conversational Modeling with Unstructured Knowledge Access"". The goal of the
task is to generate responses to user turns in a task-oriented dialog that
require knowledge from unstructured documents. The task is divided into three
subtasks: detection, selection and generation. In order to be compute
efficient, we formulate the selection problem in terms of hierarchical
classification steps. We achieve our best results with this model.
Alternatively, we employ siamese sequence embedding models, referred to as
Dense Knowledge Retrieval, to retrieve relevant documents. This method further
reduces the computation time by a factor of more than 100x at the cost of
degradation in R@1 of 5-6% compared to the first model. Then for either
approach, we use Retrieval Augmented Generation to generate responses based on
multiple selected snippets and we show how the method can be used to fine-tune
trained embeddings.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:50:35 GMT""}]","2021-02-10"
"2102.04644","Tao Zhou","Honglin Liao, Tao Tang and Tao Zhou","A new discrete energy technique for multi-step backward difference
  formulas",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The backward differentiation formula (BDF) is a useful family of implicit
methods for the numerical integration of stiff differential equations. It is
well noticed that the stability and convergence of the $A$-stable BDF1 and BDF2
schemes for parabolic equations can be directly established by using the
standard discrete energy analysis. However, such classical analysis technique
seems not directly applicable to the BDF-$\mathbf{k}$ schemes for $3\leq
\mathbf{k}\leq 5$. To overcome the difficulty, a powerful analysis tool based
on the Nevanlinna-Odeh multiplier technique [Numer. Funct. Anal. Optim.,
3:377-423, 1981] was developed by Lubich et al. [IMA J. Numer. Anal.,
33:1365-1385, 2013]. In this work, by using the so-called discrete orthogonal
convolution kernels technique, we will recover the classical energy analysis so
that the stability and convergence of the BDF-$\mathbf{k}$ schemes for $3\leq
\mathbf{k}\leq 5$ can be established. One of the theoretical advantages of our
analysis technique is that less spacial regularity requirement is needed on the
initial data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:53:37 GMT""}]","2021-02-10"
"2102.04645","Tanmoy Das","Arpit Raj, Nepal Banerjee, and Tanmoy Das","Rigidity of topological invariants to symmetry breakings","17 pages, two column. Accepted in PRB","Phys. Rev. B 103, 075139 (2021)","10.1103/PhysRevB.103.075139",,"cond-mat.str-el cond-mat.mes-hall hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetry plays an important role in the topological band theory to remedy the
eigenstates' gauge obstruction at the cost of a symmetry anomaly and
zero-energy boundary modes. One can also make use of the symmetry to enumerate
the topological invariants - giving a symmetry classification table. Here we
consider various topological phases protected by different symmetries, and
examine how the corresponding topological invariants evolve once the protecting
symmetry is spontaneously lost. To our surprise, we find that the topological
invariants and edge states can sometimes be robust to symmetry breaking quantum
orders. This topological robustness persists as long as the mean-field
Hamiltonian in a symmetry breaking ordered phase maintains its adiabatic
continuity to the non-interacting Hamiltonian. For example, for a time-reversal
symmetric topological phase in 2+1D, we show that the Z_2 time-reversal
polarization continues to be a good topological invariant even after including
distinct time-reversal breaking order parameters. Similar conclusions are drawn
for various other symmetry breaking cases. Finally, we discuss that the change
in the internal symmetry associated with the spontaneous symmetry breaking has
to be accounted for to reinstate the topological invariants into the expected
classification table.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:55:02 GMT""}]","2021-02-25"
"2102.04646","Tao Zhou","Shu-Lin Wu, Tao Zhou and Zhi Zhou","Stability implies robust convergence of a class of preconditioned
  parallel-in-time iterative algorithms",,,,,"math.NA cs.NA","http://creativecommons.org/publicdomain/zero/1.0/","  Solving evolutionary equations in a parallel-in-time manner is an attractive
topic and many algorithms are proposed in recent two decades. The algorithm
based on the block $\alpha$-circulant preconditioning technique has shown
promising advantages, especially for wave propagation problems. By fast Fourier
transform for factorizing the involved circulant matrices, the preconditioned
iteration can be computed efficiently via the so-called diagonalization
technique, which yields a direct parallel implementation across all time
levels. In recent years, considerable efforts have been devoted to exploring
the convergence of the preconditioned iteration by studying the spectral radius
of the iteration matrix, and this leads to many case-by-case studies depending
on the used time-integrator. In this paper, we propose a unified convergence
analysis for the algorithm applied to $u'+Au=f$, where
$\sigma(A)\subset\mathbb{C}^+$ with $\sigma(A)$ being the spectrum of
$A\in\mathbb{C}^{m\times m}$. For any one-step method (such as the Runge-Kutta
methods) with stability function $\mathcal{R}(z)$, we prove that the decay rate
of the global error is bounded by $\alpha/(1-\alpha)$, provided the method is
stable, i.e., $\max_{\lambda\in\sigma(A)}|\mathcal{R}(\Delta t\lambda)|\leq1$.
For any linear multistep method, such a bound becomes $c\alpha/(1-c\alpha)$,
where $c\geq1$ is a constant specified by the multistep method itself. Our
proof only relies on the stability of the time-integrator and the estimate is
independent of the step size $\Delta t$ and the spectrum $\sigma(A)$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:56:11 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 01:14:04 GMT""}]","2021-04-15"
"2102.04647","Sheikh Ziauddin Ahmed","Sheikh Z. Ahmed, Samiran Ganguly, Yuan Yuan, Jiyuan Zheng, Yaohua Tan,
  Joe C. Campbell and Avik W. Ghosh","A Physics Based Multiscale Compact Model of p-i-n Avalanche Photodiodes","8 pages, 11 figures",,"10.1109/JLT.2021.3068265",,"physics.ins-det cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  III-V material based digital alloy Avalanche Photodiodes (APDs) have recently
been found to exhibit low noise similar to Silicon APDs. The III-V materials
can be chosen to operate at any wavelength in the infrared spectrum. In this
work, we present a physics-based SPICE compatible compact model for APDs built
from parameters extracted from an Environment-Dependent Tight Binding (EDTB)
model calibrated to ab-initio Density Functional Theory (DFT) and Monte Carlo
(MC) methods. Using this approach, we can accurately capture the physical
characteristics of these APDs in integrated photonics circuit simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:00:43 GMT""}]","2021-06-09"
"2102.04648","Enrique Macias","Enrique Macias, Osmar Guerra-Alvarado, Carlos Carrasco-Gonzalez,
  Alvaro Ribas, Catherine C. Espaillat, Jane Huang, Sean M. Andrews","Characterizing the dust content of disk substructures in TW Hya","22 pages, 17 figures, accepted for publication in A&A. Language
  edited version","A&A 648, A33 (2021)","10.1051/0004-6361/202039812",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Atacama Large Millimeter Array (ALMA) observations of TW Hya at
3.1 mm with $\sim50$ milliarcsecond resolution. These new data were combined
with archival high angular resolution ALMA observations at 0.87 mm, 1.3 mm, and
2.1 mm. We analyze these multi-wavelength data to infer a disk radial profile
of the dust surface density, maximum particle size, and slope of the particle
size distribution. Most previously known annular substructures in the disk of
TW Hya are resolved at the four wavelengths. Inside the inner 3 au cavity, the
2.1 mm and 3.1 mm images show a compact source of free-free emission, likely
associated with an ionized jet. Our multi-wavelength analysis of the dust
emission shows that the maximum particle size in the disk of TW Hya is $>1$ mm.
The inner 20 au are completely optically thick at all four bands, which results
in the data tracing different disk heights at different wavelengths. Coupled
with the effects of dust settling, this prevents the derivation of accurate
density and grain size estimates in these regions. At $r>20$ au, we find
evidence of the accumulation of large dust particle at the position of the
bright rings, indicating that these are working as dust traps. The total dust
mass in the disk is between 250 and 330 $M_{\oplus}$, which represents a
gas-to-dust mass ratio between 50 and 70. Our mass measurement is a factor of
4.5-5.9 higher than the mass that one would estimate using the typical
assumptions of large demographic surveys. Our results indicate that the ring
substructures in TW Hya are ideal locations to trigger the streaming
instability and form new generations of planetesimals.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:09:13 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 19:16:32 GMT""}]","2021-04-14"
"2102.04649","Zilu Ma","Richard Bamler, Bennett Chow, Yuxing Deng, Zilu Ma, Yongjia Zhang","Four-Dimensional Steady Gradient Ricci Solitons with $3$-Cylindrical
  Tangent Flows at Infinity","13 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider $4$-dimensional steady soliton singularity models,
i.e., complete steady gradient Ricci solitons that arise as the rescaled limit
of a finite time singular solution of the Ricci flow on a closed $4$-manifold.
In particular, we study the geometry at infinity of such Ricci solitons under
the assumption that their tangent flow at infinity is the product of
$\mathbb{R}$ with a $3$-dimensional spherical space form. We also classify the
tangent flows at infinity of $4$-dimensional steady soliton singularity models
in general.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:11:11 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 02:25:14 GMT""}]","2022-03-21"
"2102.04650","Mahadev Pandge Dr.","M. B. Pandge, Biny Sebastian, Ruchika Seth, Somak Raychaudhury","A detailed study of X-ray cavities in the intracluster environment of
  the cool core cluster Abell 3017","13 pages, 13 figures, 7 Tables, Accepted for publication in MNRAS",,"10.1093/mnras/stab384",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed analysis of a cool-core galaxy cluster Abell 3017, at a
redshift of z=0.219, which has been identified to be merging with its companion
cluster Abell 3016. This study has made use of X-ray Chandra, UV (GALEX),
optical (ESO/VLT), mid-infrared (WISE), and radio uGMRT observations of this
cluster. Using various image processing techniques, such as unsharp masking,
2-d fits using Beta models, contour binning and the use of surface brightness
profiles, we show the existence of a pair of X-ray cavities, at a projected
distance of $\sim$20'' (70 kpc) and $\sim$16'' (57 kpc), respectively from the
core of Abell~3017. We also detect an excess of X-ray emission located at 25''
$\sim$(88 kpc) south of the centre of Abell 3017, is likely due to the bulk
motions in the ICM either by gas sloshing or ram-pressure striping due to a
merger. We find that the radio lobes are responsible for the observed X-ray
cavities detected in this system. The lower values of the mid-IR WISE colour
[W1-W2] and [W2-W3] imply that the central BCG of Abell~3017 is a star-forming
galaxy. The current star formation rate of the central BCG, estimated from the
${\rm H\alpha}$ and GALEX FUV luminosities, are equal to be $\sim 5.06\pm 0.78$
Msun yr$^{-1}$ and $\sim 9.20\pm 0.81$ Msun yr$^{-1}$, respectively. We detect,
for the first time, a radio phoenix $\sim$150 kpc away from the radio core,
with a spectral index of ($\alpha \!\leq\! -1.8$). We also report the detection
of $\rm~Pa_\alpha$ emission in this cluster using ESO VLT SINFONI imaging data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:15:00 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 09:44:58 GMT""},{""version"":""v3"",""created"":""Mon, 1 Mar 2021 17:27:50 GMT""}]","2021-03-17"
"2102.04651","Marcelo Sales","Vojtech R\""odl and Marcelo Sales","A blurred view of Van der Waerden type theorems","20 pages. Comments are welcome",,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $AP_k=\{a,a+d,\ldots,a+(k-1)d\}$ be an arithmetic progression. For
$\epsilon>0$ we call a set $AP_k(\epsilon)=\{x_0,\ldots,x_{k-1}\}$ an
$\epsilon$-approximate arithmetic progression if for some $a$ and $d$,
$|x_i-(a+id)|<\epsilon d$ holds for all $i\in\{0,1\ldots,k-1\}$. Complementing
earlier results of Dumitrescu, in this paper we study numerical aspects of Van
der Waerden, Szemeredi and Furstenberg-Katznelson like results in which
arithmetic progressions and their higher dimensional extensions are replaced by
their $\epsilon$-approximation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:16:37 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 00:08:28 GMT""}]","2021-09-15"
"2102.04652","Xiangzeng Zhou","Xiangzeng Zhou and Pan Pan and Yun Zheng and Yinghui Xu and Rong Jin","Large Scale Long-tailed Product Recognition System at Alibaba","Acccepted by CIKM 2020","In Proceedings of the 29th ACM International Conference on
  Information and Knowledge Management (CIKM20), 3353-3356 (2020)","10.1145/3340531.3417445",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A practical large scale product recognition system suffers from the
phenomenon of long-tailed imbalanced training data under the E-commercial
circumstance at Alibaba. Besides product images at Alibaba, plenty of image
related side information (e.g. title, tags) reveal rich semantic information
about images. Prior works mainly focus on addressing the long tail problem in
visual perspective only, but lack of consideration of leveraging the side
information. In this paper, we present a novel side information based large
scale visual recognition co-training~(SICoT) system to deal with the long tail
problem by leveraging the image related side information. In the proposed
co-training system, we firstly introduce a bilinear word attention module
aiming to construct a semantic embedding over the noisy side information. A
visual feature and semantic embedding co-training scheme is then designed to
transfer knowledge from classes with abundant training data (head classes) to
classes with few training data (tail classes) in an end-to-end fashion.
Extensive experiments on four challenging large scale datasets, whose numbers
of classes range from one thousand to one million, demonstrate the scalable
effectiveness of the proposed SICoT system in alleviating the long tail
problem. In the visual search platform
Pailitao\footnote{http://www.pailitao.com} at Alibaba, we settle a practical
large scale product recognition application driven by the proposed SICoT
system, and achieve a significant gain of unique visitor~(UV) conversion rate.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:34:30 GMT""}]","2021-02-10"
"2102.04653","Ziyi Chen","Ziyi Chen, Yi Zhou, Tengyu Xu, Yingbin Liang","Proximal Gradient Descent-Ascent: Variable Convergence under K{\L}
  Geometry","To appear in ICLR 2021",,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The gradient descent-ascent (GDA) algorithm has been widely applied to solve
minimax optimization problems. In order to achieve convergent policy parameters
for minimax optimization, it is important that GDA generates convergent
variable sequences rather than convergent sequences of function values or
gradient norms. However, the variable convergence of GDA has been proved only
under convexity geometries, and there lacks understanding for general nonconvex
minimax optimization. This paper fills such a gap by studying the convergence
of a more general proximal-GDA for regularized nonconvex-strongly-concave
minimax optimization. Specifically, we show that proximal-GDA admits a novel
Lyapunov function, which monotonically decreases in the minimax optimization
process and drives the variable sequence to a critical point. By leveraging
this Lyapunov function and the K{\L} geometry that parameterizes the local
geometries of general nonconvex functions, we formally establish the variable
convergence of proximal-GDA to a critical point $x^*$, i.e., $x_t\to x^*,
y_t\to y^*(x^*)$. Furthermore, over the full spectrum of the
K{\L}-parameterized geometry, we show that proximal-GDA achieves different
types of convergence rates ranging from sublinear convergence up to finite-step
convergence, depending on the geometry associated with the K{\L} parameter.
This is the first theoretical result on the variable convergence for nonconvex
minimax optimization.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:35:53 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 16:51:36 GMT""}]","2021-02-18"
"2102.04654","Michael Holst","Benjamin Faktor and Michael Holst","A Note On Determining Projections for Non-Homogeneous Incompressible
  Fluids","20 pages, no figures",,,,"math.AP cs.NA math-ph math.MP math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we consider a viscous incompressible fluid in a finite domain
in both two and three dimensions, and examine the question of determining
degrees of freedom (projections, functionals, and nodes). Our particular
interest is the case of non-constant viscosity, representing either a fluid
with viscosity that changes over time (such as an oil that loses viscosity as
it degrades), or a fluid with viscosity varying spatially (as in the case of
two-phase or multi-phase fluid models). Our goal is to apply the determining
projection framework developed by the second author in previous work for weak
solutions to the Navier-Stokes equations, in order to establish bounds on the
number of determining functionals for this case, or equivalently, the dimension
of a determining set, based on the approximation properties of an underlying
determining projection. The results for the case of time-varying viscosity
mirror those for weak solutions established in earlier work for constant
viscosity. The case of space-varying viscosity, treated within a single-fluid
Navier-Stokes model, is quite challenging to analyze, but we explore some
preliminary ideas for understanding this case.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:42:57 GMT""}]","2021-02-10"
"2102.04655","Qi Chang","Yikai Zhang, Hui Qu, Qi Chang, Huidong Liu, Dimitris Metaxas and Chao
  Chen","Training Federated GANs with Theoretical Guarantees: A Universal
  Aggregation Approach",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recently, Generative Adversarial Networks (GANs) have demonstrated their
potential in federated learning, i.e., learning a centralized model from data
privately hosted by multiple sites. A federatedGAN jointly trains a centralized
generator and multiple private discriminators hosted at different sites. A
major theoretical challenge for the federated GAN is the heterogeneity of the
local data distributions. Traditional approaches cannot guarantee to learn the
target distribution, which isa mixture of the highly different local
distributions. This paper tackles this theoretical challenge, and for the first
time, provides a provably correct framework for federated GAN. We propose a new
approach called Universal Aggregation, which simulates a centralized
discriminator via carefully aggregating the mixture of all private
discriminators. We prove that a generator trained with this simulated
centralized discriminator can learn the desired target distribution. Through
synthetic and real datasets, we show that our method can learn the mixture of
largely different distributions where existing federated GAN methods fail.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:44:46 GMT""}]","2021-02-10"
"2102.04656","Kang Zhao","Kang Zhao, Pan Pan, Yun Zheng, Yanhao Zhang, Changxu Wang, Yingya
  Zhang, Yinghui Xu, Rong Jin","Large-Scale Visual Search with Binary Distributed Graph at Alibaba","This paper has been accepted by CIKM2019. Proceedings of the 28th ACM
  International Conference on Information and Knowledge Management. 2019",,"10.1145/3357384.3357834",,"cs.IR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph-based approximate nearest neighbor search has attracted more and more
attentions due to its online search advantages. Numbers of methods studying the
enhancement of speed and recall have been put forward. However, few of them
focus on the efficiency and scale of offline graph-construction. For a deployed
visual search system with several billions of online images in total, building
a billion-scale offline graph in hours is essential, which is almost
unachievable by most existing methods. In this paper, we propose a novel
algorithm called Binary Distributed Graph to solve this problem. Specifically,
we combine binary codes with graph structure to speedup online and offline
procedures, and achieve comparable performance with the ones in real-value
based scenarios by recalling more binary candidates. Furthermore, the
graph-construction is optimized to completely distributed implementation, which
significantly accelerates the offline process and gets rid of the limitation of
memory and disk within a single machine. Experimental comparisons on Alibaba
Commodity Data Set (more than three billion images) show that the proposed
method outperforms the state-of-the-art with respect to the online/offline
trade-off.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:51:34 GMT""}]","2021-02-10"
"2102.04657","Guy Moshkovitz","Alex Cohen and Guy Moshkovitz","Structure vs. Randomness for Bilinear Maps","Published version for Discrete Analysis",,,,"math.CO cs.CC math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove that the slice rank of a 3-tensor (a combinatorial notion introduced
by Tao in the context of the cap-set problem), the analytic rank (a
Fourier-theoretic notion introduced by Gowers and Wolf), and the geometric rank
(an algebro-geometric notion introduced by Kopparty, Moshkovitz, and Zuiddam)
are all equal up to an absolute constant. As a corollary, we obtain strong
trade-offs on the arithmetic complexity of a biased bilinear map, and on the
separation between computing a bilinear map exactly and on average. Our result
settles open questions of Haramaty and Shpilka [STOC 2010], and of Lovett
[Discrete Anal. 2019] for 3-tensors.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:56:38 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 16:08:00 GMT""}]","2022-10-04"
"2102.04658","Eiji Yamamura","Eiji Yamamura","View about consumption tax and grandchildren",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Japan, the increase in the consumption tax rate, a measure of balanced
public finance, reduces the inequality of fiscal burden between the present and
future generations. This study estimates the effect of grandchildren on an
older person's view of consumption tax, using independently collected data. The
results show that having grandchildren is positively associated with supporting
an increase in consumption tax. Further, this association is observed strongly
between granddaughters and grandparents. However, the association between
grandsons and grandparents depends on the sub-sample. This implies that people
of the old generation are likely to accept the tax burden to reduce the burden
on their grandchildren, especially granddaughters. In other words, grandparents
show intergenerational altruism.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:57:58 GMT""}]","2021-02-10"
"2102.04659","Byoung Ham","Byoung S. Ham","Macroscopically entangled light fields: A quantum laser","6 pages, 2 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  A novel method of macroscopically entangled light-pair generation is
presented for a quantum laser using randomness-based deterministic phase
control of coherent light in a Mach-Zehnder interferometer (MZI). Unlike the
particle nature-based quantum correlation in conventional quantum mechanics,
the wave nature of photons is applied for collective phase control of coherent
fields, resulting in a deterministically controllable nonclassical phenomenon.
For the proof of principle, the entanglement between output light fields from
an MZI is examined using the Hong-Ou-Mandel-type anticorrelation technique,
where the anticorrelation is a direct evidence of the nonclassical features in
an interferometric scheme. For the generation of random phase bases between two
bipartite input coherent fields, a deterministic control of opposite frequency
shifts results in phase sensitive anticorrelation, which is a macroscopic
quantum feature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:02:11 GMT""}]","2021-02-10"
"2102.04660","Drew Stone","Drew Stone","Trustless, privacy-preserving blockchain bridges",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a protocol for facilitating trust-less cross-chain
cryptocurrency transfers that preserve privacy of bridge withdrawals. We
leverage zero-knowledge primitives that are commonly used to design
cryptocurrency mixing protocols to provide similar functionality but across two
or more blockchains. To that end, we receive cryptocurrency mixing for free
through the bridge operations and de-scribe how to extend these protocols to
incentivise bridge transfers using past ideas. We describe how resulting
protocols lead to similar vampire style attacks coined in the Uniswap vs.
Sushiswap saga but across chains.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:05:10 GMT""}]","2021-02-10"
"2102.04661","Ayodeji Oseni","Ayodeji Oseni, Nour Moustafa, Helge Janicke, Peng Liu, Zahir Tari and
  Athanasios Vasilakos","Security and Privacy for Artificial Intelligence: Opportunities and
  Challenges",,,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increased adoption of Artificial Intelligence (AI) presents an
opportunity to solve many socio-economic and environmental challenges; however,
this cannot happen without securing AI-enabled technologies. In recent years,
most AI models are vulnerable to advanced and sophisticated hacking techniques.
This challenge has motivated concerted research efforts into adversarial AI,
with the aim of developing robust machine and deep learning models that are
resilient to different types of adversarial scenarios. In this paper, we
present a holistic cyber security review that demonstrates adversarial attacks
against AI applications, including aspects such as adversarial knowledge and
capabilities, as well as existing methods for generating adversarial examples
and existing cyber defence models. We explain mathematical AI models,
especially new variants of reinforcement and federated learning, to demonstrate
how attack vectors would exploit vulnerabilities of AI models. We also propose
a systematic framework for demonstrating attack techniques against AI
applications and reviewed several cyber defences that would protect AI
applications against those attacks. We also highlight the importance of
understanding the adversarial goals and their capabilities, especially the
recent attacks against industry applications, to develop adaptive defences that
assess to secure AI applications. Finally, we describe the main challenges and
future research directions in the domain of security and privacy of AI
technologies.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:06:13 GMT""}]","2021-02-10"
"2102.04662","P Shalima","Subhashree Swain, P. Shalima, K.V.P. Latha and Krishna B. S. Swamy","Hot graphite dust in the inner regime of NGC 4151","21 pages, 24 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab372",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model the near infrared SED of NGC 4151 with a 3-D radiative transfer
SKIRT code, using which torus only (TO) and Ring And Torus (RAT) scenarios are
studied. In the RAT models, a graphite ring-like structure (clumpy or smooth),
is incorporated between the torus and the accretion disk. We vary the
inclination angle $(i)$, inner radius (of the torus and the ring, $R_{\rm in,
t}$ and $R_{\rm in, r}$ respectively), torus half-opening angle ($\sigma $),
optical depth ($\tau_{9.7, \rm t} $ of the torus and $\tau_{9.7, \rm r} $ of
the ring ) and the dust clump size ($R_{\rm clump}$). We perform a statistical
analysis of the parameter space and find that all the models are able to
explain the flat NIR SED of NGC 4151 with minor differences in the derived
parameters. For the TO model, we get, $R_{\rm in, t}=0.1$ pc, $\sigma =
30^\circ $, $i = 53^\circ $, $\tau_{9.7, \rm t}=10$ and the clumpsize, $R_{\rm
clump}$ =0.4 pc. For the smooth RAT model, $R_{\rm in, \rm r}=0.04$ pc,
$\tau_{9.7, \rm total}$ = 11 and for the clumpy RAT model, $R_{\rm in, r} =
0.04$ pc/0.06 pc and $\tau_{9.7, \rm total}=20$. The $R_{\rm in, t}$ from the
TO model does not agree with the NIR observations ($\sim 0.04$ pc). Hence, the
most likely scenario is that a hot graphite ring is located at a distance 0.04
pc from the centre, composed of a smooth distribution of dust followed by a
dusty torus at 0.1 pc with ISM type of grains.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:09:59 GMT""}]","2021-02-17"
"2102.04663","Peng-Jie Wong","Elchin Hasanalizade, Quanli Shen, Peng-Jie Wong","Counting zeros of Dedekind zeta functions","Accepted by Math. Comp",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a number field $K$ of degree $n_K$ and with absolute discriminant
$d_K$, we obtain an explicit bound for the number $N_K(T)$ of non-trivial zeros
(counted with multiplicity), with height at most $T$, of the Dedekind zeta
function $\zeta_K(s)$ of $K$. More precisely, we show that for $T \geq 1$, $$
\Big| N_K (T) - \frac{T}{\pi} \log \Big( d_K \Big( \frac{T}{2\pi
e}\Big)^{n_K}\Big)\Big|
  \le 0.228 (\log d_K + n_K \log T) + 23.108 n_K + 4.520, $$ which improves
previous results of Kadiri and Ng, and Trudgian. The improvement is based on
ideas from the recent work of Bennett $et$ $al.$ on counting zeros of Dirichlet
$L$-functions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:12:24 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 06:31:44 GMT""},{""version"":""v3"",""created"":""Mon, 3 May 2021 02:36:05 GMT""}]","2021-05-04"
"2102.04664","Shuai Lu","Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
  Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li,
  Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou,
  Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, Shujie Liu","CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding
  and Generation","14 pages; Revise CodeBLEU scores for all models on text-to-code task",,,,"cs.SE cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benchmark datasets have a significant impact on accelerating research in
programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark
dataset to foster machine learning research for program understanding and
generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and
a platform for model evaluation and comparison. CodeXGLUE also features three
baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder
models, to make it easy for researchers to use the platform. The availability
of such data and baselines can help the development and validation of new
methods that can be applied to various program understanding and generation
problems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:16:25 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 08:28:37 GMT""}]","2021-03-17"
"2102.04665","Takahiro Misawa","Takahiro Misawa and Youhei Yamaji","Zeros of Green Functions in Topological Insulators","21 pages, 1 table, 14 figures",,"10.1103/PhysRevResearch.4.023177","Phys. Rev. Research 4, 023177","cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study demonstrates that the zeros of the diagonal components of Green
functions are key quantities that can detect non-interacting topological
insulators. We show that zeros of the Green functions traverse the band gap in
the topological phases. The traverses induce the crosses of zeros, and the
zeros' surface in the band gap, analogous to the Fermi surface of metals. By
calculating the zeros of the microscopic models, we show the traverses of the
zeros universally appear in all six classes of conventional non-interacting
topological insulators. By utilizing the eigenvector-eigenvalue identity, which
is a recently rediscovered relation in linear algebra, we prove that the
traverses of the zeros in the bulk Green functions are guaranteed by the band
inversions, which occur in the topological phases. The relevance of the zeros
to detecting the exotic topological insulators such as the higher-order
topological insulators is also discussed. For the Hamiltonians with the
nearest-neighbor hoppings, we also show that the gapless edge state guarantees
the zeros' surfaces in the band gap. The analysis demonstrates that the zeros
can be used to detect a wide range of topological insulators and thus useful
for searching new topological materials.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:25:07 GMT""},{""version"":""v2"",""created"":""Tue, 8 Mar 2022 10:21:59 GMT""},{""version"":""v3"",""created"":""Mon, 29 Aug 2022 13:46:21 GMT""}]","2022-08-30"
"2102.04666","Sihe Chen","Sihe Chen, Eliot F. Young, Leslie A. Young, Tanguy Bertrand,
  Fran\c{c}ois Forget, Yuk L. Yung","Global Climate Model Occultation Lightcurves Tested by August 2018
  Ground-Based Stellar Occultation",,"Volume 356, Icarus (2021)","10.1016/j.icarus.2020.113976",,"astro-ph.EP physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pluto's atmospheric profiles (temperature and pressure) have been studied for
decades from stellar occultation lightcurves. In this paper, we look at recent
Pluto Global Climate Model (GCM) results (3D temperature, pressure, and density
fields) from Bertrand et al. (2020) and use the results to generate model
observer's plane intensity fields (OPIF) and lightcurves by using a Fourier
optics scheme to model light passing through Pluto's atmosphere (Young, 2012).
This approach can accommodate arbitrary atmospheric structures and 3D
distributions of haze. We compared the GCM model lightcurves with the
lightcurves observed during the 15-AUG-2018 Pluto stellar occultation. We find
that the climate scenario which best reproduces the observed data includes an
N2 ice mid-latitude band in the southern hemisphere. We have also studied
different haze and P/T ratio profiles: the haze effectively reduces the central
flash strength, and a lower P/T ratio both reduces the central flash strength
and incurs anomalies in the shoulders of the central flash.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:28:50 GMT""}]","2021-02-10"
"2102.04667","Yanhao Zhang","Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Jianmin Wu, Yinghui Xu,
  Rong Jin","Virtual ID Discovery from E-commerce Media at Alibaba: Exploiting
  Richness of User Click Behavior for Visual Search Relevance","accepted by CIKM 2019","CIKM 2019: 2489-2497","10.1145/3357384.3357800",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual search plays an essential role for E-commerce. To meet the search
demands of users and promote shopping experience at Alibaba, visual search
relevance of real-shot images is becoming the bottleneck. Traditional visual
search paradigm is usually based upon supervised learning with labeled data.
However, large-scale categorical labels are required with expensive human
annotations, which limits its applicability and also usually fails in
distinguishing the real-shot images. In this paper, we propose to discover
Virtual ID from user click behavior to improve visual search relevance at
Alibaba. As a totally click-data driven approach, we collect various types of
click data for training deep networks without any human annotations at all. In
particular, Virtual ID are learned as classification supervision with co-click
embedding, which explores image relationship from user co-click behaviors to
guide category prediction and feature learning. Concretely, we deploy Virtual
ID Category Network by integrating first-clicks and switch-clicks as
regularizer. Incorporating triplets and list constraints, Virtual ID Feature
Network is trained in a joint classification and ranking manner. Benefiting
from exploration of user click data, our networks are more effective to encode
richer supervision and better distinguish real-shot images in terms of category
and feature. To validate our method for visual search relevance, we conduct an
extensive set of offline and online experiments on the collected real-shot
images. We consistently achieve better experimental results across all
components, compared with alternative and state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:31:20 GMT""}]","2021-02-10"
"2102.04668","Juntang Zhuang","Juntang Zhuang, Nicha C. Dvornek, Sekhar Tatikonda, James S. Duncan","MALI: A memory efficient and reverse accurate integrator for Neural ODEs","https://openreview.net/forum?id=blfSjHeFM_e","International Conference on Learning Representation, ICLR 2021",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural ordinary differential equations (Neural ODEs) are a new family of
deep-learning models with continuous depth. However, the numerical estimation
of the gradient in the continuous case is not well solved: existing
implementations of the adjoint method suffer from inaccuracy in reverse-time
trajectory, while the naive method and the adaptive checkpoint adjoint method
(ACA) have a memory cost that grows with integration time. In this project,
based on the asynchronous leapfrog (ALF) solver, we propose the
Memory-efficient ALF Integrator (MALI), which has a constant memory cost
\textit{w.r.t} number of solver steps in integration similar to the adjoint
method, and guarantees accuracy in reverse-time trajectory (hence accuracy in
gradient estimation). We validate MALI in various tasks: on image recognition
tasks, to our knowledge, MALI is the first to enable feasible training of a
Neural ODE on ImageNet and outperform a well-tuned ResNet, while existing
methods fail due to either heavy memory burden or inaccuracy; for time series
modeling, MALI significantly outperforms the adjoint method; and for continuous
generative models, MALI achieves new state-of-the-art performance. We provide a
pypi package at \url{https://jzkay12.github.io/TorchDiffEqPack/}
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:33:47 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 20:11:32 GMT""}]","2021-03-05"
"2102.04669","Zihang Wang","Zihang Wang and Lijing Shao","Axion induced spin effective couplings","11 pages, 3 figures","Phys. Rev. D 103, 116021 (2021)","10.1103/PhysRevD.103.116021",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting axionic dark matter induced electron or nucleon oscillating
electric dipole moment (OEDM) has become a new way for dark matter searches. We
re-examine such axion-spin couplings in external electromagnetic fields. We
point out that axion-photon interaction induces an electron spin effective
coupling, which is different from an OEDM. In particular, the axion-spin
effective coupling is directly related to magnetic field rather than electric
field. For axion-electron or axion-nucleon couplings, an OEDM of fermion is
introduced, whose effect in ultralight axion cases depends on whether axion
shift symmetry is manifest. Specifically, ultralight axionic dark matter
interactions that do not obey the shift symmetry will be strongly constrained.
We also extend the results to the case where axion has a finite velocity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:34:15 GMT""}]","2021-06-30"
"2102.04670","Tom Allison","Jay Rutledge, Anthony Catanese, Daniel D. Hickstein, Scott A. Diddams,
  Thomas K. Allison, Abijith S. Kowligy","Broadband ultraviolet-visible frequency combs from cascaded
  high-harmonic generation in quasi-phase-matched waveguides","10 pages, 7 figures",,"10.1364/JOSAB.427086",,"physics.optics physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-harmonic generation (HHG) provides short-wavelength light that is useful
for precision spectroscopy and probing ultrafast dynamics. We report efficient,
phase-coherent harmonic generation up to 9th-order (333 nm) in chirped
periodically poled lithium niobate waveguides driven by phase-stable
$\leq$12-nJ, 100 fs pulses at 3 $\mu$m with 100 MHz repetition rate. A
mid-infrared to ultraviolet-visible conversion efficiency as high as 10% is
observed, amongst an overall 23% conversion of the fundamental to all
harmonics. We verify the coherence of the harmonic frequency combs despite the
complex highly nonlinear process. Numerical simulations based on a single
broadband envelope equation with quadratic nonlinearity give estimates for the
conversion efficiency within approximately 1 order of magnitude over a wide
range of experimental parameters. From this comparison we identify a
dimensionless parameter capturing the competition between three-wave mixing and
group-velocity walk-off of the harmonics that governs the cascaded HHG physics.
These results can inform cascaded HHG in a range of different platforms.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:34:57 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 21:54:00 GMT""}]","2021-07-28"
"2102.04671","Quan Xiao","Tianyi Chen, Yuejiao Sun, Quan Xiao, Wotao Yin","A Single-Timescale Method for Stochastic Bilevel Optimization","Minor edits in Table 1",,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic bilevel optimization generalizes the classic stochastic
optimization from the minimization of a single objective to the minimization of
an objective function that depends the solution of another optimization
problem. Recently, stochastic bilevel optimization is regaining popularity in
emerging machine learning applications such as hyper-parameter optimization and
model-agnostic meta learning. To solve this class of stochastic optimization
problems, existing methods require either double-loop or two-timescale updates,
which are sometimes less efficient. This paper develops a new optimization
method for a class of stochastic bilevel problems that we term Single-Timescale
stochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop
fashion, and uses a single-timescale update with a fixed batch size. To achieve
an $\epsilon$-stationary point of the bilevel problem, STABLE requires ${\cal
O}(\epsilon^{-2})$ samples in total; and to achieve an $\epsilon$-optimal
solution in the strongly convex case, STABLE requires ${\cal O}(\epsilon^{-1})$
samples. To the best of our knowledge, this is the first bilevel optimization
algorithm achieving the same order of sample complexity as the stochastic
gradient descent method for the single-level stochastic optimization.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:35:30 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 06:27:44 GMT""},{""version"":""v3"",""created"":""Fri, 11 Feb 2022 04:24:09 GMT""},{""version"":""v4"",""created"":""Thu, 31 Mar 2022 02:39:25 GMT""}]","2022-04-01"
"2102.04672","EPTCS","Christian Williams (University of California, Riverside), Michael Stay
  (Pyrofex Corporation, Utah)","Native Type Theory","In Proceedings ACT 2021, arXiv:2211.01102","EPTCS 372, 2022, pp. 116-132","10.4204/EPTCS.372.9",,"cs.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  Native type systems are those in which type constructors are derived from
term constructors, as well as the constructors of predicate logic and
intuitionistic type theory. We present a method to construct native type
systems for a broad class of languages, lambda-theories with equality, by
embedding such a theory into the internal language of its topos of presheaves.
Native types provide total specification of the structure of terms; and by
internalizing transition systems, native type systems serve to reason about
structure and behavior simultaneously. The construction is functorial, thereby
providing a shared framework of higher-order reasoning for many languages,
including programming languages.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:44:13 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 18:59:41 GMT""},{""version"":""v3"",""created"":""Thu, 3 Nov 2022 14:16:58 GMT""}]","2022-11-04"
"2102.04673","Kirill Glavatskiy","Kirill S. Glavatskiy","Symmetry and dissipation as the basic mechanism of social mobility,
  explaining distance scaling of migration patterns","11 pages, 3 figures, 1 table",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Models of social mobility inspired by the Newton's law of gravity have been
used for several decades to describe migrations of people, goods, and
information. Despite an eminent reference and widespread use, these models lack
the background theory, being often viewed as a collection of empirical recipes
which rely on adjustable parameters. Here we propose a tractable and
fundamental mechanism of social mobility, which explains distance scaling of
migration flows and predicts the value of the scaling exponent. The mechanism
reveals two key aspects framing social flows, which have direct analogy in
physics: symmetry and dissipation. In particular, we identify the conditions
for the social gravity scaling, when the power law exponent equals 2, and
explain deviations from this behaviour, including saturation transitions. The
resulting flow distribution is determined by the spatial structure of the
underlying social network, rather than by distance explicitly. The theory is
verified for residential migration in suburb networks of major Australian
cities with diverse structure, population and size. The mechanism is directly
translatable to other social contexts, such as flows of goods or information,
and provides a universal understanding of how dynamic patterns of social
mobility emerge from structural network properties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:46:39 GMT""}]","2021-02-10"
"2102.04674","Yanhao Zhang","Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Yingya Zhang, Xiaofeng
  Ren, Rong Jin","Visual Search at Alibaba","accepted by KDD 2018","KDD 2018: 993-1001","10.1145/3219819.3219820",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the large scale visual search algorithm and system
infrastructure at Alibaba. The following challenges are discussed under the
E-commercial circumstance at Alibaba (a) how to handle heterogeneous image data
and bridge the gap between real-shot images from user query and the online
images. (b) how to deal with large scale indexing for massive updating data.
(c) how to train deep models for effective feature representation without huge
human annotations. (d) how to improve the user engagement by considering the
quality of the content. We take advantage of large image collection of Alibaba
and state-of-the-art deep learning techniques to perform visual search at
scale. We present solutions and implementation details to overcome those
problems and also share our learnings from building such a large scale
commercial visual search engine. Specifically, model and search-based fusion
approach is introduced to effectively predict categories. Also, we propose a
deep CNN model for joint detection and feature learning by mining user click
behavior. The binary index engine is designed to scale up indexing without
compromising recall and precision. Finally, we apply all the stages into an
end-to-end system architecture, which can simultaneously achieve highly
efficient and scalable performance adapting to real-shot images. Extensive
experiments demonstrate the advancement of each module in our system. We hope
visual search at Alibaba becomes more widely incorporated into today's
commercial applications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:46:50 GMT""}]","2021-02-10"
"2102.04675","Vivekanand Maddali Dr.","M. Vivekanand","Phase resolved spectrum of the Crab pulsar from NICER","Accepted for publication in A&A","A&A 649, A140 (2021)","10.1051/0004-6361/202140358",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Context{The high energy emission regions of rotation powered pulsars are
studied using folded light curve (FLCs) and phase resolved spectra (PRS).}
aims{This work uses the NICER observatory to obtain the highest resolution FLC
and PRS of the Crab pulsar at soft X-ray energies.} methods{NICER has
accumulated about 347 ksec of data on the Crab pulsar. The data are processed
using the standard analysis pipeline. Stringent filtering is done for spectral
analysis. The individual detectors are calibrated in terms of long time light
curve (LTLC), raw spectrum and deadtime. The arrival times of the photons are
referred to the solar system's barycenter and the rotation frequency $\nu$ and
its time derivative $\dot \nu$ are used to derive the rotation phase of each
photon.} results{The LTLCs, raw spectra and deadtimes of the individual
detectors are statistically similar; the latter two show no evolution with
epoch; detector deadtime is independent of photon energy. The deadtime for the
Crab pulsar, taking into account the two types of deadtime, is only approx 7%
to 8% larger than that obtained using the cleaned events. Detector 00 behaves
slightly differently from the rest, but can be used for spectral work. The PRS
of the two peaks of the Crab pulsar are obtained at a resolution of better than
1/512 in rotation phase. The FLC very close to the first peak rises slowly and
falls faster. The spectral index of the PRS is almost constant very close to
the first peak.} conclusions{The high resolution FLC and PRS of the {{peaks}}
of the Crab pulsar provide important constraints for the formation of caustics
in the emission zone.}
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:53:31 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 12:16:21 GMT""}]","2021-06-04"
"2102.04676","Mattia Scomparin","Mattia Scomparin","Cosmic structures in Ricci-inverse theories of gravity","11 pages, 0 figures",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We discuss a no-go theorem for the novel Ricci-inverse theory of gravity.
Referring to a static spherically symmetric matter distribution embedded in a
de Sitter cosmology, we prove that it is impossible to have a stable
Sub-Horizon non-relativistic Weak-Field limit in any model proposed in previous
works to avoid some cosmological and inflationary instabilities. We discuss
possible ways to circumvent the issue, and point out a machinery to build new
stable models under Sub-Horizon non-relativistic Weak-Field limit. Such models
exhibit full consistency with predictions of General Relativity on small
scales.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:53:45 GMT""}]","2021-02-10"
"2102.04677","Gabriel Goldberg","Gabriel Goldberg","On products of ultrafilters","15 pages",,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  Assuming the Generalized Continuum Hypothesis, this paper answers the
question: when is the tensor product of two ultrafilters equal to their
Cartesian product? It is necessary and sufficient that their Cartesian product
is an ultrafilter; that the two ultrafilters commute in the tensor product;
that for all cardinals $\lambda$, one of the ultrafilters is both
$\lambda$-indecomposable and $\lambda^+$-indecomposable; that the ultrapower
embedding associated to each ultrafilter restricts to a definable embedding of
the ultrapower of the universe associated to the other.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:02:23 GMT""}]","2021-02-10"
"2102.04678","Hansol Park Dr","Hansol Park","Generalization of the Winfree model to the high-dimensional sphere and
  its emergent dynamics",,,,,"math-ph math.DS math.MP","http://creativecommons.org/licenses/by/4.0/","  We present a high-dimensional Winfree model in this paper. The Winfree model
is the first mathematical model for synchronization on the circle. We
generalize this model to the high-dimensional sphere and we call it ""the
Winfree sphere model."" We restricted the support of the influence function in
the neighborhood of the attraction point with a small diameter to mimic the
influence function as the Dirac-delta distribution. Restricting the support of
the influence function allows several new conditions of the complete
phase-locking states for the identical Winfree sphere model compare to previous
results. We also provide the exponential $\ell^1$-stability and the existence
of the equilibrium solution to obtain the complete oscillator death state of
the Winfree sphere model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:03:51 GMT""}]","2021-02-10"
"2102.04679","Ryota Nakai","Ryota Nakai, Kentaro Nomura, Yukio Tanaka","Edge-induced pairing states in a Josephson junction through a
  spin-polarized quantum anomalous Hall insulator","13 pages, 9 figures","Phys. Rev. B 103, 184509 (2021)","10.1103/PhysRevB.103.184509",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the robustness of the chiral edge modes of quantum Hall systems
against the superconducting proximity effect, Cooper pairs can penetrate into
the chiral edge channels and carry the Josephson current in an appropriate
setup. In our work, the Josephson junction of a spin-polarized quantum
anomalous Hall insulator (QAHI) with a Chern number $\nu=1$ connecting
conventional superconductors is studied from the perspective of pairing
symmetry consistent with the chiral edge mode. Induced pairing states are
equal-spin triplet, a combination of the even- and odd-frequency components,
nonlocally extended, and have a finite momentum $2k_F$. The signature of the
equal-spin triplet pairings is confirmed via the dependence on the
interface-magnetization direction, and that of the finite-momentum pairing
states via the spatial profile of the anomalous Green's function. In the
presence of disorder, the robustness of the chiral edge mode leads to high
sensitivity of the critical current and the equilibrium phase difference to
disorder configurations, which is resulting from the interference of
current-carrying channels. The numerical calculations on a lattice model are
also examined by a simplified analytical model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:03:57 GMT""}]","2021-05-26"
"2102.04680","Dasaem Jeong","Dasaem Jeong and Seungheon Doh and Taegyun Kwon","Tr\""aumerAI: Dreaming Music with StyleGAN","presented in NeurIPS Workshop 2020: Machine Learning for Creativity
  and Design",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  The goal of this paper to generate a visually appealing video that responds
to music with a neural network so that each frame of the video reflects the
musical characteristics of the corresponding audio clip. To achieve the goal,
we propose a neural music visualizer directly mapping deep music embeddings to
style embeddings of StyleGAN, named Tr\""aumerAI, which consists of a music
auto-tagging model using short-chunk CNN and StyleGAN2 pre-trained on WikiArt
dataset. Rather than establishing an objective metric between musical and
visual semantics, we manually labeled the pairs in a subjective manner. An
annotator listened to 100 music clips of 10 seconds long and selected an image
that suits the music among the 200 StyleGAN-generated examples. Based on the
collected data, we trained a simple transfer function that converts an audio
embedding to a style embedding. The generated examples show that the mapping
between audio and video makes a certain level of intra-segment similarity and
inter-segment dissimilarity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:04:22 GMT""}]","2021-02-10"
"2102.04681","Dennis Bautembach","Dennis Bautembach, Iason Oikonomidis, Antonis Argyros","Multi-GPU SNN Simulation with Static Load Balancing","Camera-ready version, accepted to IJCNN 2021",,"10.1109/IJCNN52387.2021.9533921",,"cs.NE cs.DC cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a SNN simulator which scales to millions of neurons, billions of
synapses, and 8 GPUs. This is made possible by 1) a novel, cache-aware spike
transmission algorithm 2) a model parallel multi-GPU distribution scheme and 3)
a static, yet very effective load balancing strategy. The simulator further
features an easy to use API and the ability to create custom models. We compare
the proposed simulator against two state of the art ones on a series of
benchmarks using three well-established models. We find that our simulator is
faster, consumes less memory, and scales linearly with the number of GPUs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:07:34 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 18:50:23 GMT""}]","2021-09-23"
"2102.04682","Yao Ge","Yao Ge, Qinwen Deng, P. C. Ching, Zhi Ding","OTFS Signaling for Uplink NOMA of Heterogeneous Mobility Users","31 pages, 10 figures, accepted by IEEE Transactions on Communications",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a coded uplink non-orthogonal multiple access (NOMA)
configuration in which groups of co-channel users are modulated in accordance
with orthogonal time frequency space (OTFS). We take advantage of OTFS
characteristics to achieve NOMA spectrum sharing in the delay-Doppler domain
between stationary and mobile users. We develop an efficient iterative turbo
receiver based on the principle of successive interference cancellation (SIC)
to overcome the co-channel interference (CCI). We propose two turbo detector
algorithms: orthogonal approximate message passing with linear minimum mean
squared error (OAMP-LMMSE) and Gaussian approximate message passing with
expectation propagation (GAMP-EP). The interactive OAMP-LMMSE detector and
GAMP-EP detector are respectively assigned for the reception of the stationary
and mobile users. We analyze the convergence performance of our proposed
iterative SIC turbo receiver by utilizing a customized extrinsic information
transfer (EXIT) chart and simplify the corresponding detector algorithms to
further reduce receiver complexity. Our proposed iterative SIC turbo receiver
demonstrates performance improvement over existing receivers and robustness
against imperfect SIC process and channel state information uncertainty.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:08:08 GMT""}]","2021-02-10"
"2102.04683","Tomoharu Iwata","Tomoharu Iwata and Yoshinobu Kawahara","Meta-Learning for Koopman Spectral Analysis with Short Time-series",,,,,"stat.ML cs.LG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Koopman spectral analysis has attracted attention for nonlinear dynamical
systems since we can analyze nonlinear dynamics with a linear regime by
embedding data into a Koopman space by a nonlinear function. For the analysis,
we need to find appropriate embedding functions. Although several neural
network-based methods have been proposed for learning embedding functions,
existing methods require long time-series for training neural networks. This
limitation prohibits performing Koopman spectral analysis in applications where
only short time-series are available. In this paper, we propose a meta-learning
method for estimating embedding functions from unseen short time-series by
exploiting knowledge learned from related but different time-series. With the
proposed method, a representation of a given short time-series is obtained by a
bidirectional LSTM for extracting its properties. The embedding function of the
short time-series is modeled by a neural network that depends on the
time-series representation. By sharing the LSTM and neural networks across
multiple time-series, we can learn common knowledge from different time-series
while modeling time-series-specific embedding functions with the time-series
representation. Our model is trained such that the expected test prediction
error is minimized with the episodic training framework. We experimentally
demonstrate that the proposed method achieves better performance in terms of
eigenvalue estimation and future prediction than existing methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:19:19 GMT""}]","2021-02-10"
"2102.04684","Yehyun Kwon","Seongyeon Kim, Yehyun Kwon, Sanghyuk Lee and Ihyeok Seo","Strichartz and uniform Sobolev inequalities for the elastic wave
  equation","to appear in Proc. Amer. Math. Soc",,,,"math.AP math.CA","http://creativecommons.org/licenses/by/4.0/","  We prove dispersive estimate for the elastic wave equation by which we extend
the known Strichartz estimates for the classical wave equation to those for the
elastic wave equation. In particular, the endpoint Strichartz estimates are
deduced. For the purpose we diagonalize the symbols of the Lam\'e operator and
its semigroup, which also gives an alternative and simpler proofs of the
previous results on perturbed elastic wave equations. Furthermore, we obtain
uniform Sobolev inequalities for the elastic wave operator.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:21:19 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 05:25:13 GMT""}]","2022-08-31"
"2102.04685","Songlin He","Songlin He, Yuan Lu, Qiang Tang, Guiling Wang, Chase Qishi Wu","Fair Peer-to-Peer Content Delivery via Blockchain","Accepted for publication at the 26th European Symposium on Research
  in Computer Security (ESORICS) 2021",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peer-to-peer (p2p) content delivery is promising to provide benefits like
cost-saving and scalable peak-demand handling in comparison with conventional
content delivery networks (CDNs) and complement the decentralized storage
networks such as Filecoin. However, reliable p2p delivery requires proper
enforcement of delivery fairness, i.e., the deliverers should be rewarded
according to their in-time delivery. Unfortunately, most existing studies on
delivery fairness are based on non-cooperative game-theoretic assumptions that
are arguably unrealistic in the ad-hoc p2p setting. We for the first time put
forth the expressive yet still minimalist securities for p2p content delivery,
and give two efficient solutions FairDownload and FairStream via the blockchain
for p2p downloading and p2p streaming scenarios, respectively. Our designs not
only guarantee delivery fairness to ensure deliverers be paid (nearly)
proportional to his in-time delivery, but also ensure the content consumers and
content providers to be fairly treated. The fairness of each party can be
guaranteed when the other two parties collude to arbitrarily misbehave.
Moreover, the systems are efficient in the sense of attaining asymptotically
optimal on-chain costs and optimal deliverer communication. We implement the
protocols to build the prototype systems atop the Ethereum Ropsten network.
Extensive experiments done in LAN and WAN settings showcase their high
practicality.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:22:48 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 13:58:06 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 22:39:21 GMT""},{""version"":""v4"",""created"":""Sun, 26 Sep 2021 19:20:41 GMT""}]","2021-09-28"
"2102.04686","Abdur Rahim Mohammad Forkan","Abdur Rahim Mohammad Forkan, Yong-Bin Kang, Prem Prakash Jayaraman,
  Kewen Liao, Rohit Kaul, Graham Morgan, Rajiv Ranjan, Samir Sinha","CorrDetector: A Framework for Structural Corrosion Detection from Drone
  Images using Ensemble Deep Learning",,,"10.1016/j.eswa.2021.116461",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new technique that applies automated image
analysis in the area of structural corrosion monitoring and demonstrate
improved efficacy compared to existing approaches. Structural corrosion
monitoring is the initial step of the risk-based maintenance philosophy and
depends on an engineer's assessment regarding the risk of building failure
balanced against the fiscal cost of maintenance. This introduces the
opportunity for human error which is further complicated when restricted to
assessment using drone captured images for those areas not reachable by humans
due to many background noises. The importance of this problem has promoted an
active research community aiming to support the engineer through the use of
artificial intelligence (AI) image analysis for corrosion detection. In this
paper, we advance this area of research with the development of a framework,
CorrDetector. CorrDetector uses a novel ensemble deep learning approach
underpinned by convolutional neural networks (CNNs) for structural
identification and corrosion feature extraction. We provide an empirical
evaluation using real-world images of a complicated structure (e.g.
telecommunication tower) captured by drones, a typical scenario for engineers.
Our study demonstrates that the ensemble approach of \model significantly
outperforms the state-of-the-art in terms of classification accuracy.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:27:16 GMT""}]","2022-01-12"
"2102.04687","Sudeep Bapat","Sudeep R. Bapat and Rohit Bhardwaj","On an Inflated Unit-Lindley Distribution",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modeling fractional data in various real life scenarios is a challenging
task. This paper consider situations where fractional data is observed on the
interval [0,1]. The unit-Lindley distribution has been discussed in the
literature where its support lies between 0 and 1. In this paper, we focus on
an inflated variant of the unit-Lindley distribution, where the inflation
occurs at both 0 and 1. Various properties of the inflated unit-Lindley
distribution are discussed and examined, including point estimation based on
the maximum likelihood method and interval estimation. Finally, extensive Monte
Carlo simulation and real-data analyses are carried out to compare the fit of
our proposed distribution along with some of the existing ones such as the
inflated beta and the inflated Kumaraswamy distributions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:30:07 GMT""}]","2021-02-10"
"2102.04688","Xuda Ye","Xuda Ye, Zhennan Zhou","Efficient Sampling of Thermal Averages of Interacting Quantum Particle
  Systems with Random Batches",,,"10.1063/5.0047437",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An efficient sampling method, the pmmLang+RBM, is proposed to compute the
quantum thermal average in the interacting quantum particle system. Benefiting
from the random batch method (RBM), the pmmLang+RBM reduces the complexity due
to the interaction forces per timestep from $O(NP^2)$ to $O(NP)$, where $N$ is
the number of beads and $P$ is the number of particles. Although the RBM
introduces a random perturbation of the interaction forces at each timestep,
the long time effects of the random perturbations along the sampling process
only result in a small bias in the empirical measure of the pmmLang+RBM from
the target distribution, which also implies a small error in the thermal
average calculation. We numerically study the convergence of the pmmLang+RBM,
and quantitatively investigate the dependence of the error in computing the
thermal average on the parameters including the batch size, the timestep, etc.
We also propose an extension of the pmmLang+RBM, which is based on the
splitting Monte Carlo method and is applicable when the interacting potential
contains a singular part.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:35:38 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 02:19:27 GMT""},{""version"":""v3"",""created"":""Sat, 13 Feb 2021 12:12:03 GMT""},{""version"":""v4"",""created"":""Sun, 4 Apr 2021 10:13:23 GMT""}]","2021-06-16"
"2102.04689","Tom\'a\v{s} Vina\v{r}","Bro\v{n}a Brejov\'a, Vikt\'oria Hodorov\'a, Krist\'ina Bor\v{s}ov\'a,
  Vikt\'oria \v{C}abanov\'a, Lenka Reizigov\'a, Evan D. Paul, Pavol \v{C}ekan,
  Boris Klempa, Jozef Nosek, Tom\'a\v{s} Vina\v{r}","B.1.258$\Delta$, a SARS-CoV-2 variant with $\Delta$H69/$\Delta$V70 in
  the Spike protein circulating in the Czech Republic and Slovakia",,,"10.1007/s11262-021-01866-5",,"q-bio.OT","http://creativecommons.org/licenses/by/4.0/","  SARS-CoV-2 mutants carrying the $\Delta$H69/$\Delta$V70 deletion in the amino
terminal domain of the Spike protein emerged independently in at least six
lineages of the virus (namely, B.1.1.7, B.1.1.298, B.1.160, B.1.177, B.1.258,
B.1.375). Routine RT-qPCR tests including TaqPath or similar assays based on a
drop-out of the Spike gene target are incapable of distinguishing among these
lineages and often lead to the false conclusion that clinical samples contain
the B.1.1.7 variant, which recently emerged in the United Kingdom and is
quickly spreading through the human population. We analyzed SARS-CoV-2 samples
collected from various regions of Slovakia between November and December 2020
that were presumed to contain the B.1.1.7 variant due to traveling history of
the virus carriers or their contacts. Sequencing of these isolates revealed
that although in some cases the samples were indeed confirmed as B.1.1.7, a
substantial fraction of isolates contained another $\Delta$H69/$\Delta$V70
carrying mutant belonging to the lineage B.1.258, which has been circulating in
Central Europe since August 2020, long before the import of B.1.1.7.
Phylogenetic analysis shows that the early sublineage of B.1.258 acquired the
N439K substitution in the receptor binding domain (RBD) of the Spike protein
and, later on, also the deletion $\Delta$H69/$\Delta$V70 in the Spike
N-terminal domain (NTD). This variant is particularly common in several
European countries including Czech Republic and Slovakia, and we propose to
name it B.1.258$\Delta$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:36:46 GMT""}]","2021-10-04"
"2102.04690","Pouya M Ghari","Pouya M Ghari, Yanning Shen","Graph-Aided Online Multi-Kernel Learning","Preliminary results of this work have been presented in ""Online
  Multi-Kernel Learning with Graph-Structured Feedback."" P. M. Ghari, and Y.
  Shen, International Conference on Machine Learning (ICML), pp. 3474-3483.
  PMLR, July 2020",,,,"cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Multi-kernel learning (MKL) has been widely used in function approximation
tasks. The key problem of MKL is to combine kernels in a prescribed dictionary.
Inclusion of irrelevant kernels in the dictionary can deteriorate accuracy of
MKL, and increase the computational complexity. To improve the accuracy of
function approximation and reduce the computational complexity, the present
paper studies data-driven selection of kernels from the dictionary that provide
satisfactory function approximations. Specifically, based on the similarities
among kernels, the novel framework constructs and refines a graph to assist
choosing a subset of kernels. In addition, random feature approximation is
utilized to enable online implementation for sequentially obtained data.
Theoretical analysis shows that our proposed algorithms enjoy tighter
sub-linear regret bound compared with state-of-art graph-based online MKL
alternatives. Experiments on a number of real datasets also showcase the
advantages of our novel graph-aided framework.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:43:29 GMT""}]","2021-02-10"
"2102.04691","Shan Cheng","Jian Chai, Shan Cheng, and Wen-Fei Wang","The role of $D_{(s)}^\ast$ and their contributions in $B_{(s)}\to
  D_{(s)} h h^\prime$ decays","24 pages, 3 figures, 6 tables, minor correction, typos removed","Phys. Rev. D 103, 096016 (2021)","10.1103/PhysRevD.103.096016",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate the roles of $D_{(s)}^\ast$ and their contributions in the
quasi-two-body decays $B_{(s)} \to D_{(s)} h h^\prime$ ($h, h^\prime = \{\pi,
K\}$) in the perturbative QCD approach, stemming from the quark flavour
changing $\bar{b} \to \bar{c} \, q_2 \, \bar{q}_1$ and $\bar{b} \to c \,
\bar{q_1} \, \bar{q_2}$ with $q_1, q_2 = \{s/d, u\}$. The main motivation of
this study is the measurements of significant derivations from the simple
phase-space model in the channels $B_{(s)} \to D_{(s)} h h^\prime$ at $B$
factories and LHC, which is now clarified as the Breit-Wigner-tail effects from
the corresponding intermediate resonant states $D_{(s)}^\ast$. We confirm that
these effect from $D^\ast$ is small ($\sim 5\%$) in the quasi-two-body $B_{(s)}
\to D \pi \pi (K)$ decaying channels, and predict the tiny ($< 1 \%$)
contributions from $D^\ast$ in the $B_{(s)} \to D_s K \pi (K)$ decaying
channels, our result for the $B_s \to D K \pi (K)$ decaying channels
contributed only from the Breit-Wigner-tail effect of $D_s^\ast$ is in
agreement with the current LHCb measurement. We recommend the Belle-II and the
LHCb collaborations to restudy the processes $B^+\to \bar D^{\ast 0}\pi^+(K^+)
\to D^-\pi^+\pi^+(K^+)$ to reveal the structure of $D^{\ast 0}$ and the strong
decay $D^{\ast 0} \to D^+ \pi^-$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:46:04 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 04:04:48 GMT""}]","2021-05-26"
"2102.04692","Haike Xu","Haike Xu, Tengyu Ma, Simon S. Du","Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive
  Multi-Step Bootstrap","Accepted for presentation at the Conference on Learning Theory (COLT)
  2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a new model-free algorithm for episodic finite-horizon
Markov Decision Processes (MDP), Adaptive Multi-step Bootstrap (AMB), which
enjoys a stronger gap-dependent regret bound. The first innovation is to
estimate the optimal $Q$-function by combining an optimistic bootstrap with an
adaptive multi-step Monte Carlo rollout. The second innovation is to select the
action with the largest confidence interval length among admissible actions
that are not dominated by any other actions. We show when each state has a
unique optimal action, AMB achieves a gap-dependent regret bound that only
scales with the sum of the inverse of the sub-optimality gaps. In contrast,
Simchowitz and Jamieson (2019) showed all upper-confidence-bound (UCB)
algorithms suffer an additional $\Omega\left(\frac{S}{\Delta_{min}}\right)$
regret due to over-exploration where $\Delta_{min}$ is the minimum
sub-optimality gap and $S$ is the number of states. We further show that for
general MDPs, AMB suffers an additional $\frac{|Z_{mul}|}{\Delta_{min}}$
regret, where $Z_{mul}$ is the set of state-action pairs $(s,a)$'s satisfying
$a$ is a non-unique optimal action for $s$. We complement our upper bound with
a lower bound showing the dependency on $\frac{|Z_{mul}|}{\Delta_{min}}$ is
unavoidable for any consistent algorithm. This lower bound also implies a
separation between reinforcement learning and contextual bandits.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:46:34 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 10:06:50 GMT""}]","2021-07-05"
"2102.04693","Anton Golovanov","A. A. Golovanov, I. Yu. Kostyukov, L. Reichwein, J. Thomas, A. Pukhov","Excitation of strongly nonlinear plasma wakefield by electron bunches",,,"10.1088/1361-6587/ac0352",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new method for analytical self-consistent description of the
excitation of a strongly nonlinear wakefield (a bubble) excited by an electron
bunch. This method makes it possible to calculate the shape of the bubble and
the distribution of the electric field in it based only on the properties of
the driver, without relying on any additional parameters. The analytical
results are verified by particle-in-cell simulations and show good
correspondence. A complete analytical solution for cylindrical drivers and
scaling laws for the properties of the bubble and other plasma accelerator
parameters depending on the bunch charge and length are derived.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:54:41 GMT""}]","2021-07-07"
"2102.04694","Mazhar Ali","Mazhar Ali","Genuinely entangling uncorrelated atoms via Jaynes-Cummings interactions","12 pages, 3 figures, comments welcome","Quantum Info Process 20, 311 (2021)",,,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We study three independent pairs of Jaynes-Cummings systems such that two
atoms might be correlated with each other but the third atom is uncorrelated
with rest. We investigate the conditions under which these uncorrelated three
atoms may become genuinely entangled. We find that this task is impossible if
the cavity interacting with uncorrelated atom share classical correlations with
any other cavity. We observe that atomic state can become genuine multipartite
entangled, at least if the cavity with uncorrelated atom, is highly entangled
with any other cavity. This is an interesting and non-trivial observation and
may serve as another technique to generate multipartite entangled atoms via
JC-interactions. The findings can be realized with available experimental
setups.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:06:39 GMT""}]","2021-09-21"
"2102.04695","Cosimo Bambi","Ashutosh Tripathi, Askar B. Abdikamalov, Dimitry Ayzenberg, Cosimo
  Bambi, Honghui Liu","Impact of the disk thickness on X-ray reflection spectroscopy
  measurements","16 pages, 9 figures. v2: refereed version","Astrophys.J. 913: 129 (2021)","10.3847/1538-4357/abf6c5",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a previous paper, we presented an extension of our reflection model
RELXILL_NK to include the finite thickness of the accretion disk following the
prescription in Taylor & Reynolds (2018). In this paper, we apply our model to
fit the 2013 simultaneous observations by NuSTAR and XMM-Newton of the
supermassive black hole in MCG-06-30-15 and the 2019 NuSTAR observation of the
Galactic black hole in EXO 1846-031. The high-quality data of these spectra had
previously led to precise black hole spin measurements and very stringent
constraints on possible deviations from the Kerr metric. We find that the disk
thickness does not change previous spin results found with a model employing an
infinitesimally thin disk, which confirms the robustness of spin measurements
in high radiative efficiency disks, where the impact of disk thickness is
minimal. Similar analysis on lower accretion rate systems will be an important
test for measuring the effect of disk thickness on black hole spin
measurements.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:07:54 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 23:24:50 GMT""}]","2021-06-07"
"2102.04696","Rintaro Ikeshita","Rintaro Ikeshita, Tomohiro Nakatani","Independent Vector Extraction for Fast Joint Blind Source Separation and
  Dereverberation","Accepted to IEEE Signal Processing Letters",,"10.1109/LSP.2021.3074321",,"eess.AS cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address a blind source separation (BSS) problem in a noisy reverberant
environment in which the number of microphones $M$ is greater than the number
of sources of interest, and the other noise components can be approximated as
stationary and Gaussian distributed. Conventional BSS algorithms for the
optimization of a multi-input multi-output convolutional beamformer have
suffered from a huge computational cost when $M$ is large. We here propose a
computationally efficient method that integrates a weighted prediction error
(WPE) dereverberation method and a fast BSS method called independent vector
extraction (IVE), which has been developed for less reverberant environments.
We show that, given the power spectrum for each source, the optimization
problem of the new method can be reduced to that of IVE by exploiting the
stationary condition, which makes the optimization easy to handle and
computationally efficient. An experiment of speech signal separation shows
that, compared to a conventional method that integrates WPE and independent
vector analysis, our proposed method achieves much faster convergence while
maintaining its separation performance.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:18:10 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 02:01:12 GMT""}]","2021-04-23"
"2102.04697","Shucong Zhang","Shucong Zhang, Cong-Thanh Do, Rama Doddipatla, Erfan Loweimi, Peter
  Bell and Steve Renals","Train your classifier first: Cascade Neural Networks Training from upper
  layers to lower layers","Accepted by ICASSP 2021",,,,"eess.AS cs.AI cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although the lower layers of a deep neural network learn features which are
transferable across datasets, these layers are not transferable within the same
dataset. That is, in general, freezing the trained feature extractor (the lower
layers) and retraining the classifier (the upper layers) on the same dataset
leads to worse performance. In this paper, for the first time, we show that the
frozen classifier is transferable within the same dataset. We develop a novel
top-down training method which can be viewed as an algorithm for searching for
high-quality classifiers. We tested this method on automatic speech recognition
(ASR) tasks and language modelling tasks. The proposed method consistently
improves recurrent neural network ASR models on Wall Street Journal,
self-attention ASR models on Switchboard, and AWD-LSTM language models on
WikiText-2.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:19:49 GMT""}]","2021-02-10"
"2102.04698","Joakim Arnlind","Joakim Arnlind","Levi-Civita connections for a class of noncommutative minimal surfaces",,,,,"math.QA math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study connections on hermitian modules, and show that metric connections
exist on regular hermitian modules; i.e finitely generated projective modules
together with a non-singular hermitian form. In addition, we develop an index
calculus for such modules, and provide a characterization in terms of the
existence of a pseudo-inverse of the matrix representing the hermitian form
with respect to a set of generators. As a first illustration of the above
concepts, we find metric connections on the fuzzy sphere. Finally, the
framework is applied to a class of noncommutative minimal surfaces, for which
there is a natural concept of torsion, and we prove that there exist metric and
torsion-free connections for every minimal surface in this class.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:21:26 GMT""}]","2021-02-10"
"2102.04699","Rajiv Kumar V","Rajiv Kumar, Rishabh Dabral, G. Sivakumar","Learning Unsupervised Cross-domain Image-to-Image Translation Using a
  Shared Discriminator",,,"10.5220/0010184102560264",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised image-to-image translation is used to transform images from a
source domain to generate images in a target domain without using source-target
image pairs. Promising results have been obtained for this problem in an
adversarial setting using two independent GANs and attention mechanisms. We
propose a new method that uses a single shared discriminator between the two
GANs, which improves the overall efficacy. We assess the qualitative and
quantitative results on image transfiguration, a cross-domain translation task,
in a setting where the target domain shares similar semantics to the source
domain. Our results indicate that even without adding attention mechanisms, our
method performs at par with attention-based methods and generates images of
comparable quality.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:26:23 GMT""}]","2023-03-09"
"2102.04700","Peidong Liu","Peidong Liu, Gengwei Zhang, Bochao Wang, Hang Xu, Xiaodan Liang, Yong
  Jiang, Zhenguo Li","Loss Function Discovery for Object Detection via Convergence-Simulation
  Driven Search","Accepted by ICLR2021 Poster",,,,"cs.CV cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Designing proper loss functions for vision tasks has been a long-standing
research direction to advance the capability of existing models. For object
detection, the well-established classification and regression loss functions
have been carefully designed by considering diverse learning challenges.
Inspired by the recent progress in network architecture search, it is
interesting to explore the possibility of discovering new loss function
formulations via directly searching the primitive operation combinations. So
that the learned losses not only fit for diverse object detection challenges to
alleviate huge human efforts, but also have better alignment with evaluation
metric and good mathematical convergence property. Beyond the previous
auto-loss works on face recognition and image classification, our work makes
the first attempt to discover new loss functions for the challenging object
detection from primitive operation levels. We propose an effective
convergence-simulation driven evolutionary search algorithm, called
CSE-Autoloss, for speeding up the search progress by regularizing the
mathematical rationality of loss candidates via convergence property
verification and model optimization simulation. CSE-Autoloss involves the
search space that cover a wide range of the possible variants of existing
losses and discovers best-searched loss function combination within a short
time (around 1.5 wall-clock days). We conduct extensive evaluations of loss
function search on popular detectors and validate the good generalization
capability of searched losses across diverse architectures and datasets. Our
experiments show that the best-discovered loss function combinations outperform
default combinations by 1.1% and 0.8% in terms of mAP for two-stage and
one-stage detectors on COCO respectively. Our searched losses are available at
https://github.com/PerdonLiu/CSE-Autoloss.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:34:52 GMT""}]","2021-02-10"
"2102.04701","Linda Gesenhues","Linda Gesenhues, Marek Behr","Simulating dense granular flow using the $\mu$($I$)-rheology within a
  space-time framework",,,"10.1002/fld.5014",,"cs.CE cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A space-time framework is applied to simulate dense granular flow. Two
different numerical experiments are performed: a column collapse and a dam
break on an inclined plane. The experiments are modeled as two-phase flows. The
dense granular material is represented by a constitutive model, the
$\mu$($I$)-rheology, that is based on the Coulomb's friction law, such that the
normal stress applied by the pressure is related to the tangential stress. The
model represents a complex shear thinning viscoplastic material behavior. The
interface between the dense granular material and the surrounding light fluid
is captured with a level set function. Due to discontinuities close to the the
interface, the mesh requires a sufficient resolution. The space-time approach
allows unstructured meshes in time and, therefore a well refined mesh in the
temporal direction around the interface. In this study, results and performance
of a flat and a simplex space time discretization are verified and analyzed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:36:21 GMT""}]","2021-09-01"
"2102.04702","Yilmazcan \""Ozyurt","Yilmazcan \""Ozyurt, Mathias Kraus, Tobias Hatt, Stefan Feuerriegel","AttDMM: An Attentive Deep Markov Model for Risk Scoring in Intensive
  Care Units",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinical practice in intensive care units (ICUs) requires early warnings when
a patient's condition is about to deteriorate so that preventive measures can
be undertaken. To this end, prediction algorithms have been developed that
estimate the risk of mortality in ICUs. In this work, we propose a novel
generative deep probabilistic model for real-time risk scoring in ICUs.
Specifically, we develop an attentive deep Markov model called AttDMM. To the
best of our knowledge, AttDMM is the first ICU prediction model that jointly
learns both long-term disease dynamics (via attention) and different disease
states in health trajectory (via a latent variable model). Our evaluations were
based on an established baseline dataset (MIMIC-III) with 53,423 ICU stays. The
results confirm that compared to state-of-the-art baselines, our AttDMM was
superior: AttDMM achieved an area under the receiver operating characteristic
curve (AUROC) of 0.876, which yielded an improvement over the state-of-the-art
method by 2.2%. In addition, the risk score from the AttDMM provided warnings
several hours earlier. Thereby, our model shows a path towards identifying
patients at risk so that health practitioners can intervene early and save
patient lives.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:44:31 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 08:46:30 GMT""}]","2021-02-18"
"2102.04703","Bjoern Andres","David Stein and Bjoern Andres","Inapproximability of a Pair of Forms Defining a Partial Boolean Function",,,,,"cs.LG cs.CC cs.DM math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of jointly minimizing forms of two Boolean functions
$f, g \colon \{0,1\}^J \to \{0,1\}$ such that $f + g \leq 1$ and so as to
separate disjoint sets $A \cup B \subseteq \{0,1\}^J$ such that $f(A) = \{1\}$
and $g(B) = \{1\}$. We hypothesize that this problem is easier to solve or
approximate than the well-understood problem of minimizing the form of one
Boolean function $h: \{0,1\}^J \to \{0,1\}$ such that $h(A) = \{1\}$ and $h(B)
= \{0\}$. For a large class of forms, including binary decision trees and
ordered binary decision diagrams, we refute this hypothesis. For disjunctive
normal forms, we show that the problem is at least as hard as MIN-SET-COVER.
For all these forms, we establish that no $o(\ln (|A| + |B| -1))$-approximation
algorithm exists unless P$=$NP.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:46:50 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 16:23:32 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jul 2022 12:53:44 GMT""},{""version"":""v4"",""created"":""Thu, 8 Sep 2022 07:39:02 GMT""}]","2022-09-09"
"2102.04704","Andrew Lowy","Andrew Lowy and Meisam Razaviyayn","Output Perturbation for Differentially Private Convex Optimization with
  Improved Population Loss Bounds, Runtimes and Applications to Private
  Adversarial Training",,,,,"cs.LG cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding efficient, easily implementable differentially private (DP)
algorithms that offer strong excess risk bounds is an important problem in
modern machine learning. To date, most work has focused on private empirical
risk minimization (ERM) or private population loss minimization. However, there
are often other objectives--such as fairness, adversarial robustness, or
sensitivity to outliers--besides average performance that are not captured in
the classical ERM setup. To this end, we study a completely general family of
convex, Lipschitz loss functions and establish the first known DP excess risk
and runtime bounds for optimizing this broad class. We provide similar bounds
under additional assumptions of smoothness and/or strong convexity. We also
address private stochastic convex optimization (SCO). While $(\epsilon,
\delta)$-DP ($\delta > 0$) has been the focus of much recent work in private
SCO, proving tight population loss bounds and runtime bounds for $(\epsilon,
0)$-DP remains a challenging open problem. We provide the tightest known
$(\epsilon, 0)$-DP population loss bounds and fastest runtimes under the
presence of (or lack of) smoothness and strong convexity. Our methods extend to
the $\delta > 0$ setting, where we offer the unique benefit of ensuring
differential privacy for arbitrary $\epsilon > 0$ by incorporating a new form
of Gaussian noise. Finally, we apply our theory to two learning frameworks:
tilted ERM and adversarial learning. In particular, our theory quantifies
tradeoffs between adversarial robustness, privacy, and runtime. Our results are
achieved using perhaps the simplest DP algorithm: output perturbation. Although
this method is not novel conceptually, our novel implementation scheme and
analysis show that the power of this method to achieve strong privacy, utility,
and runtime guarantees has not been fully appreciated in prior works.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:47:06 GMT""}]","2021-02-10"
"2102.04705","Myrron Albert Aguila","Myrron Albert Callera Aguila, Joshoua Condicion Esmenda, Jyh-Yang
  Wang, Teik-Hui Lee, Chi-Yuan Yang, Kung-Hsuan Lin, Kuei-Shu Chang-Liao,
  Sergey Kafanov, Yuri A. Pashkin, Chii-Dong Chen","Fabry-Perot Interferometric Calibration of 2D Nanomechanical Plate
  Resonators","15 pages, 4 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Displacement calibration of nanomechanical plate resonators presents a
challenging task. Large nanomechanical resonator thickness reduces the
amplitude of the resonator motion due to its increased spring constant and
mass, and its unique reflectance. Here, we show that the plate thickness,
resonator gap height, and motional amplitude of circular and elliptical drum
resonators, can be determined in-situ by exploiting the fundamental
interference phenomenon in Fabry-Perot cavities. The proposed calibration
scheme uses optical contrasts to uncover thickness and spacer height profiles,
and reuse the results to convert the photodetector signal to the displacement
of drumheads that are electromotively driven in their linear regime. Calibrated
frequency response and spatial mode maps enable extraction of the modal radius,
effective mass, effective driving force, and Young's elastic modulus of the
drumhead material. This scheme is applicable to any configuration of
Fabry-Perot cavities, including plate and membrane resonators.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:48:11 GMT""}]","2021-02-10"
"2102.04706","Xincheng He","Xincheng He, Lei Xu, Xiangyu Zhang, Rui Hao, Yang Feng and Baowen Xu","PyART: Python API Recommendation in Real-Time","12 pages",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  API recommendation in real-time is challenging for dynamic languages like
Python. Many existing API recommendation techniques are highly effective, but
they mainly support static languages. A few Python IDEs provide API
recommendation functionalities based on type inference and training on a large
corpus of Python libraries and third-party libraries. As such, they may fail to
recommend or make poor recommendations when type information is missing or
target APIs are project-specific. In this paper, we propose a novel approach,
PyART, to recommend APIs for Python programs in real-time. It features a
light-weight analysis to derives so-called optimistic data-flow, which is
neither sound nor complete, but simulates the local data-flow information
humans can derive. It extracts three kinds of features: data-flow, token
similarity, and token co-occurrence, in the context of the program point where
a recommendation is solicited. A predictive model is trained on these features
using the Random Forest algorithm. Evaluation on 8 popular Python projects
demonstrates that PyART can provide effective API recommendations. When
historic commits can be leveraged, which is the target scenario of a
state-of-the-art tool ARIREC, our average top-1 accuracy is over 50% and
average top-10 accuracy over 70%, outperforming APIREC and Intellicode (i.e.,
the recommendation component in Visual Studio) by 28.48%-39.05% for top-1
accuracy and 24.41%-30.49% for top-10 accuracy. In other applications such as
when historic comments are not available and cross-project recommendation,
PyART also shows better overall performance. The time to make a recommendation
is less than a second on average, satisfying the real-time requirement.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:50:02 GMT""}]","2021-02-10"
"2102.04707","Nikolas M\""ahlmann","Nikolas M\""ahlmann, Sebastian Siebertz, Alexandre Vigny","Recursive Backdoors for SAT",,,,,"cs.DS cs.DM cs.LO","http://creativecommons.org/licenses/by/4.0/","  A strong backdoor in a formula $\phi$ of propositional logic to a tractable
class $\mathcal{C}$ of formulas is a set $B$ of variables of $\phi$ such that
every assignment of the variables in $B$ results in a formula from
$\mathcal{C}$. Strong backdoors of small size or with a good structure, e.g.
with small backdoor treewidth, lead to efficient solutions for the
propositional satisfiability problem SAT. In this paper we propose the new
notion of recursive backdoors, which is inspired by the observation that in
order to solve SAT we can independently recurse into the components that are
created by partial assignments of variables. The quality of a recursive
backdoor is measured by its recursive backdoor depth. Similar to the concept of
backdoor treewidth, recursive backdoors of bounded depth include backdoors of
unbounded size that have a certain treelike structure. However, the two
concepts are incomparable and our results yield new tractability results for
SAT.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:53:57 GMT""}]","2021-02-10"
"2102.04708","Hang Liu","Hang Liu, Meng Chen, Youzheng Wu, Xiaodong He, Bowen Zhou","Conversational Query Rewriting with Self-supervised Learning","Accepted by ICASSP 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context modeling plays a critical role in building multi-turn dialogue
systems. Conversational Query Rewriting (CQR) aims to simplify the multi-turn
dialogue modeling into a single-turn problem by explicitly rewriting the
conversational query into a self-contained utterance. However, existing
approaches rely on massive supervised training data, which is labor-intensive
to annotate. And the detection of the omitted important information from
context can be further improved. Besides, intent consistency constraint between
contextual query and rewritten query is also ignored. To tackle these issues,
we first propose to construct a large-scale CQR dataset automatically via
self-supervised learning, which does not need human annotation. Then we
introduce a novel CQR model Teresa based on Transformer, which is enhanced by
self-attentive keywords detection and intent consistency constraint. Finally,
we conduct extensive experiments on two public datasets. Experimental results
demonstrate that our proposed model outperforms existing CQR baselines
significantly, and also prove the effectiveness of self-supervised learning on
improving the CQR performance.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 08:57:53 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 07:05:08 GMT""}]","2021-02-22"
"2102.04709","Sheng Li","Sheng Li, Yang Lu, Fei Jiang, Haihu Liu","Lattice Boltzmann simulation of three-phase flows with moving contact
  lines on curved surfaces",,"Phys. Rev. E 104, 015310 (2021)","10.1103/PhysRevE.104.015310",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A numerical method for simulating three-phase flows with moving contact lines
on arbitrarily complex surfaces is developed in the framework of lattice
Boltzmann method. In this method, the immiscible three-phase flow is modeled
through a multiple-relaxation-time color-gradient model, which not only allows
for a full range of interfacial tensions but also produces stable outcomes for
a wide range of viscosity ratios. A characteristic line model is introduced to
implement the wetting boundary condition, which is not only easy to implement
but also able to handle arbitrarily complex boundaries with prescribed contact
angles. The developed method is first validated by the simulation of a Janus
droplet resting on a flat surface, a perfect Janus droplet deposited on a
cylinder, and the capillary intrusion of ternary fluids for various viscosity
ratios. It is then used to study a compound droplet subject to a uniform
incoming flow passing through a multi-pillar structure, where three different
values of surface wettability are considered. The simulated results show that
the surface wettability has significant impact on the droplet dynamic behavior
and final fluid distribution.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:03:19 GMT""}]","2021-07-28"
"2102.04710","Cezar Sas","Cezar Sas and Andrea Capiluppi","Using Structural and Semantic Information to Identify Software
  Components","5 pages, 4 figures, 1 table. Accepted at SANER 2021 ERA Track",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Component Based Software Engineering (CBSE) seeks to promote the reuse of
software by using existing software modules into the development process.
However, the availability of such a reusable component is not immediate and is
costly and time consuming. As an alternative, the extraction from pre-existing
OO software can be considered.
  In this work, we evaluate two community detection algorithms for the task of
software components identification. Considering `components' as `communities',
the aim is to evaluate how independent, yet cohesive, the components are when
extracted by structurally informed algorithms.
  We analyze 412 Java systems and evaluate the cohesion of the extracted
communities using four document representation techniques. The evaluation aims
to find which algorithm extracts the most semantically cohesive, yet separated
communities.
  The results show a good performance in both algorithms, however, each has its
own strengths. Leiden extracts less cohesive, but better separated, and better
clustered components that depend more on similar ones. Infomap, on the other
side, creates more cohesive, slightly overlapping clusters that are less likely
to depend on other semantically similar components.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:03:46 GMT""}]","2021-02-10"
"2102.04711","Reza Nikandish","M. J. Nikmehr, R. Nikandish, A. Yassine","Integral closures, Primary Hyperideals and Hypervaluation Hyperideals of
  Kranser Hyperrings",,,,,"math.AC math.CO","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, the notions of integral closure of hyperrings and hyperideals
in a Krasner hyperring $(R, +, \cdot)$ are defined and some basics properties
of them are studied. We define also the notion of hypervaluation hyperideals
and then a relations between hypervaluations, integral closure of hyperideals
and primary hyperideals are studied. In fact it is shown that the integral
closure of a hyperideal is determined by the hypervaluation Krasner hyperrings.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:05:18 GMT""}]","2021-02-10"
"2102.04712","Oliver Stockdale","Oliver R. Stockdale, Matthew T. Reeves, Matthew J. Davis","Dynamical mechanisms of vortex pinning in superfluid thin films","5+4 pages, 4+5 figures, supplemental videos:
  https://www.youtube.com/watch?v=l8E8RdydaY0","Phys. Rev. Lett. 127, 255304 (2021)","10.1103/PhysRevLett.127.255302",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize the mechanisms of vortex pinning in a superfluid thin film
described by the two-dimensional Gross-Pitaevskii equation. We consider a
vortex ""scattering experiment"" whereby a single vortex in a superfluid flow
interacts with a circular, uniform pinning potential. By an analogy with linear
dielectrics, we develop an analytical hydrodynamic approximation that predicts
vortex trajectories, the vortex fixed point and the unpinning velocity. We then
solve the Gross-Pitaevskii equation to validate this model, and build a phase
portrait of vortex pinning. We identify two different dynamical pinning
mechanisms marked by distinctive phonon emission signatures: one enabled by
acoustic radiation and another mediated by vortex dipoles nucleated within the
pin. Relative to obstacle size, we find that pinning potentials on the order of
the healing length are more effective for vortex capture. Our results could be
useful in mitigating the negative effects of drag due to vortices in superfluid
channels, in analogy to maximising supercurrents in type-II superconductors.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:08:35 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 07:24:36 GMT""}]","2021-12-15"
"2102.04713","Sergey Finashin","Sergey Finashin, Viatcheslav Kharlamov","Two kinds of real lines on real del Pezzo surfaces of degree 1","19 pages, 5 figures",,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how the real lines on a real del Pezzo surface of degree 1 can be
split into two species, elliptic and hyperbolic, via a certain distinguished,
intrinsically defined, Pin-structure on the real locus of the surface. We prove
that this splitting is invariant under real automorphisms and real deformations
of the surface, and that the difference between the total numbers of hyperbolic
and elliptic lines is always equal to 16.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:13:36 GMT""}]","2021-02-10"
"2102.04714","Andrea Aler Tubella","Andrea Aler Tubella, Andreas Theodorou and Juan Carlos Nieves","Interrogating the Black Box: Transparency through Information-Seeking
  Dialogues","Accepted at AAMAS 2021",,,,"cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is preoccupied with the following question: given a (possibly
opaque) learning system, how can we understand whether its behaviour adheres to
governance constraints? The answer can be quite simple: we just need to ""ask""
the system about it. We propose to construct an investigator agent to query a
learning agent -- the suspect agent -- to investigate its adherence to a given
ethical policy in the context of an information-seeking dialogue, modeled in
formal argumentation settings. This formal dialogue framework is the main
contribution of this paper. Through it, we break down compliance checking
mechanisms into three modular components, each of which can be tailored to
various needs in a vast amount of ways: an investigator agent, a suspect agent,
and an acceptance protocol determining whether the responses of the suspect
agent comply with the policy. This acceptance protocol presents a fundamentally
different approach to aggregation: rather than using quantitative methods to
deal with the non-determinism of a learning system, we leverage the use of
argumentation semantics to investigate the notion of properties holding
consistently. Overall, we argue that the introduced formal dialogue framework
opens many avenues both in the area of compliance checking and in the analysis
of properties of opaque systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:14:04 GMT""}]","2021-02-10"
"2102.04715","Pau Clusella Cober\'o","Pau Clusella and Romualdo Pastor-Satorras","Phase transitions on a class of generalized Vicsek-like models of
  collective motion",,,"10.1063/5.0046926",,"nlin.AO cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Systems composed of interacting self-propelled particles (SPPs) display
different forms of order-disorder phase transitions relevant to collective
motion. In this paper we propose a generalization of the Vicsek model
characterized by an angular noise term following an arbitrary probability
density function, which might depend on the state of the system and thus have a
multiplicative character. We show that the well established vectorial Vicsek
model can be expressed in this general formalism by deriving the corresponding
angular probability density function, as well as we propose two new
multiplicative models consisting on a bivariate Gaussian and a wrapped Gaussian
distributions. With the proposed formalism, the mean-field system can be solved
using the mean resultant length of the angular stochastic term. Accordingly,
when the SPPs interact globally, the character of the phase transition depends
on the choice of the noise distribution, being first-order with an hybrid
scaling for the vectorial and wrapped Gaussian distributions, and second order
for the bivariate Gaussian distribution. Numerical simulations reveal that this
scenario also holds when the interactions among SPPs are given by a static
complex network. On the other hand, using spatial short-range interactions
displays, in all the considered instances, a discontinuous transition with a
coexistence region, consistent with the original formulation of the Vicsek
model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:16:36 GMT""}]","2021-04-14"
"2102.04716","Lue Tao","Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, Songcan Chen","Better Safe Than Sorry: Preventing Delusive Adversaries with Adversarial
  Training","NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Delusive attacks aim to substantially deteriorate the test accuracy of the
learning model by slightly perturbing the features of correctly labeled
training examples. By formalizing this malicious attack as finding the
worst-case training data within a specific $\infty$-Wasserstein ball, we show
that minimizing adversarial risk on the perturbed data is equivalent to
optimizing an upper bound of natural risk on the original data. This implies
that adversarial training can serve as a principled defense against delusive
attacks. Thus, the test accuracy decreased by delusive attacks can be largely
recovered by adversarial training. To further understand the internal mechanism
of the defense, we disclose that adversarial training can resist the delusive
perturbations by preventing the learner from overly relying on non-robust
features in a natural setting. Finally, we complement our theoretical findings
with a set of experiments on popular benchmark datasets, which show that the
defense withstands six different practical attacks. Both theoretical and
empirical results vote for adversarial training when confronted with delusive
adversaries.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:19:47 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 15:05:32 GMT""},{""version"":""v3"",""created"":""Mon, 8 Nov 2021 15:32:58 GMT""},{""version"":""v4"",""created"":""Mon, 13 Dec 2021 17:46:58 GMT""}]","2021-12-14"
"2102.04717","Mirjana Povi\'c","Mirjana Povi\'c","Development of astronomy research and education in Africa and Ethiopia","Proceedings paper of the International Astronomical Union Symposium
  367: Education and Heritage in the Era of Big Data in Astronomy",,"10.1017/S1743921321001009",,"astro-ph.IM physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Africa has amazing potential due to natural (such as dark sky) and human
resources for scientific research in astronomy and space science. At the same
time, the continent is still facing many difficulties, and its countries are
now recognising the importance of astronomy, space science and satellite
technologies for improving some of their principal socio-economic challenges.
The development of astronomy in Africa (including Ethiopia) has grown
significantly over the past few years, and never before it was more possible to
use astronomy for education, outreach, and development as it is now. However,
much still remains to be done. This paper will summarise the recent
developments in astronomy research and education in Africa and Ethiopia and
will focus on how working together on the development of science and education
can we fight poverty in the long term and increase our possibilities of
attaining the United Nations Sustainable Development Goals in future for
benefit of all.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:23:32 GMT""}]","2022-01-05"
"2102.04718","Prof. Surajit Dhara","Muhammed Rasi M, Ravi Kumar Pujala, Sathyanarayana Paladugu and
  Surajit Dhara","Interactions of charged microrods in chiral nematic liquid crystals","9 pages, 10 figures","Phys. Rev. E 104, 014706 (2021)","10.1103/PhysRevE.104.014706",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We study the pair interaction of charged silica microrods in chiral nematic
liquid crystals and show that the microrods with homeotropic surface anchoring
form a bound state due to the competing effect of electrostatic (Coulomb) and
elastic interactions. The robustness of the bound state is demonstrated by
applying external electrical and mechanical forces that perturbs their
equilibrium position as well as orientation. In the bound state we have
measured the correlated thermal fluctuations of the position, using
two-particle cross-correlation spectroscopy that uncovers their hydrodynamic
interaction. These findings reveal unexplored aspects of liquid-crystal
dispersions which are important for understanding the assembly and dynamics of
nano and microparticles in chiral nematic liquid crystals.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:26:10 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 10:21:51 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 10:05:54 GMT""},{""version"":""v4"",""created"":""Sat, 12 Nov 2022 16:15:56 GMT""}]","2022-11-15"
"2102.04719","Kristofer Bj\""ornson","K.Bj\""ornson, J.M.Wills, M.Alouani, O.Gr{\aa}n\""as, P.Thunstr\""om,
  Chin Shen Ong, O.Eriksson","\textit{In-situ} pseudopotentials for electronic structure theory","13 pages, 3 figures",,,,"cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general method of constructing \textit{in-situ} pseodopotentials
from first principles, all-electron, full-potential electronic structure
calculations of a solid. The method is applied to bcc Na, at equilibrium
volume. The essential steps of the method involve (i) calculating an
all-electron Kohn-Sham eigenstate. (ii) Replacing the oscillating part of the
wavefunction (inside the muffin-tin spheres) of this state, with a smooth
function. (iii) Representing the smooth wavefunction in a Fourier series, and
(iv) inverting the Kohn-Sham equation, to extract the pseudopotential that
produces the state generated in steps (i)-(iii). It is shown that an
\textit{in-situ} pseudopotential can reproduce an all-electron, full-potential
eigenvalue up to the sixth significant digit. A comparison of the all-electron
theory, \textit{in-situ} pseudopotential theory and the standard nonlocal
pseudopotential theory demonstrates good agreement, e.g., in the energy
dispersion of the 3$s$ band state of bcc Na.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:31:25 GMT""}]","2021-02-10"
"2102.04720","Brian Mathias","Brian Mathias, Christian Andrae, Anika Schwager, Manuela Macedonia,
  Katharina von Kriegstein","Twelve- and fourteen-year-old school children differentially benefit
  from sensorimotor- and multisensory-enriched vocabulary training",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Both children and adults have been shown to benefit from the integration of
multisensory and sensorimotor enrichment into pedagogy. For example,
integrating pictures or gestures into foreign language (L2) vocabulary learning
can improve learning outcomes relative to unisensory learning. However, whereas
adults seem to benefit to a greater extent from sensorimotor enrichment such as
the performance of gestures in contrast to multisensory enrichment with
pictures, this is not the case in elementary school children. Here, we compared
multisensory- and sensorimotor-enriched learning in an intermediate age group
that falls between the age groups tested in previous studies (elementary school
children and young adults), in an attempt to determine the developmental time
point at which children's responses to enrichment mature from a child-like
pattern into an adult-like pattern. Twelve-year-old and fourteen-year-old
German children were trained over 5 consecutive days on auditorily-presented,
concrete and abstract, Spanish vocabulary. The vocabulary was learned under
picture-enriched, gesture-enriched, and non-enriched (auditory-only)
conditions. The children performed vocabulary recall and translation tests at 3
days, 2 months, and 6 months post-learning. Both picture and gesture enrichment
interventions were found to benefit children's L2 learning relative to
non-enriched learning up to 6 months post-training. Interestingly,
gesture-enriched learning was even more beneficial than picture-enriched
learning for the fourteen-year-olds, while the twelve-year-olds benefitted
equivalently from learning enriched with pictures and gestures. These findings
provide evidence for opting to integrate gestures rather than pictures into L2
pedagogy starting at fourteen years of age.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:32:12 GMT""}]","2021-02-10"
"2102.04721","Xiaofan Liu","Xiaofan Liua, Zuoquan Zhanga, Di Wanga","Classification of Imbalanced Credit scoring data sets Based on Ensemble
  Method with the Weighted-Hybrid-Sampling","Credit scoring, Imbalanced data, Data sampling, Boosting algorithm",,,"A20210209","stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the era of big data, the utilization of credit-scoring models to determine
the credit risk of applicants accurately becomes a trend in the future. The
conventional machine learning on credit scoring data sets tends to have poor
classification for the minority class, which may bring huge commercial harm to
banks. In order to classify imbalanced data sets, we propose a new ensemble
algorithm, namely, Weighted-Hybrid-Sampling-Boost (WHSBoost). In data sampling,
we process the imbalanced data sets with weights by the Weighted-SMOTE method
and the Weighted-Under-Sampling method, and thus obtain a balanced training
sample data set with equal weight. In ensemble algorithm, each time we train
the base classifier, the balanced data set is given by the method above. In
order to verify the applicability and robustness of the WHSBoost algorithm, we
performed experiments on the simulation data sets, real benchmark data sets and
real credit scoring data sets, comparing WHSBoost with SMOTE, SMOTEBoost and
HSBoost based on SVM, BPNN, DT and KNN.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:32:50 GMT""}]","2021-02-10"
"2102.04722","Sebastian Peitz","Sebastian Peitz and Katharina Bieker","On the Universal Transformation of Data-Driven Models to Control Systems",,,"10.1016/j.automatica.2022.110840",,"math.OC cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The advances in data science and machine learning have resulted in
significant improvements regarding the modeling and simulation of nonlinear
dynamical systems. It is nowadays possible to make accurate predictions of
complex systems such as the weather, disease models or the stock market.
Predictive methods are often advertised to be useful for control, but the
specifics are frequently left unanswered due to the higher system complexity,
the requirement of larger data sets and an increased modeling effort. In other
words, surrogate modeling for autonomous systems is much easier than for
control systems. In this paper we present the framework QuaSiModO
(Quantization-Simulation-Modeling-Optimization) to transform arbitrary
predictive models into control systems and thus render the tremendous advances
in data-driven surrogate modeling accessible for control. Our main contribution
is that we trade control efficiency by autonomizing the dynamics - which yields
mixed-integer control problems - to gain access to arbitrary, ready-to-use
autonomous surrogate modeling techniques. We then recover the complexity of the
original problem by leveraging recent results from mixed-integer optimization.
The advantages of QuaSiModO are a linear increase in data requirements with
respect to the control dimension, performance guarantees that rely exclusively
on the accuracy of the predictive model in use, and little prior knowledge
requirements in control theory to solve complex control problems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:33:03 GMT""},{""version"":""v2"",""created"":""Sun, 28 Aug 2022 13:35:21 GMT""}]","2023-01-24"
"2102.04723","Gregor Decristoforo M.Sc.","Gregor Decristoforo, Audun Theodorsen, John Omotani, Thomas Nicholas
  and Odd Erik Garcia","Numerical turbulence simulations of intermittent fluctuations in the
  scrape-off layer of magnetized plasmas","27 pages, 20 figures",,"10.1063/5.0047566",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intermittent fluctuations in the boundary of magnetically confined plasmas
are investigated by numerical turbulence simulations of a reduced fluid model
describing the evolution of the plasma density and electric drift vorticity in
the two-dimensional plane perpendicular to the magnetic field. Two different
cases are considered, one describing resistive drift waves in the edge region
and another including only the interchange instability due to unfavorable
magnetic field curvature in the scrape-off layer. Analysis of long data time
series obtained by single-point recordings are compared to predictions of a
stochastic model describing the plasma fluctuations as a super-position of
uncorrelated pulses. For both cases investigated, the radial particle density
profile in the scrape-off layer is exponential with a radially constant scale
length. The probability density function for the particle density fluctuations
in the far scrape-off layer has an exponential tail. Radial motion of blob-like
structures leads to large-amplitude bursts with an exponential distribution of
peak amplitudes and the waiting times between them. The average burst shape is
well described by a two-sided exponential function. The frequency power
spectral density of the particle density is simply that of the average burst
shape and is the same for all radial positions in the scrape-off layer. The
fluctuation statistics obtained from the numerical simulations are in excellent
agreement with recent experimental measurements on magnetically confined
plasmas. The statistical framework defines a new validation metric for boundary
turbulence simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:33:04 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 08:07:21 GMT""}]","2021-07-28"
"2102.04724","Ibrahima N'Doye","Ibrahima N'Doye and Ding Zhang and Mohamed-Slim Alouini and
  Taous-Meriem Laleg-Kirati","Establishing and Maintaining a Reliable Optical Wireless Communication
  in Underwater Environment",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes the trajectory tracking problem between an autonomous
underwater vehicle (AUV) and a mobile surface ship, both equipped with optical
communication transceivers. The challenging issue is to maintain stable
connectivity between the two autonomous vehicles within an optical
communication range. We define a directed optical line-of-sight (LoS) link
between the two-vehicle systems. The transmitter is mounted on the AUV while
the surface ship is equipped with an optical receiver. However, this optical
communication channel needs to preserve a stable transmitter-receiver position
to reinforce service quality, which typically includes a bit rate and bit error
rates. A cone-shaped beam region of the optical receiver is approximated based
on the channel model; then, a minimum bit rate is ensured if the AUV
transmitter remains inside of this region. Additionally, we design two control
algorithms for the transmitter to drive the AUV and maintain it in the
cone-shaped beam region under an uncertain oceanic environment. Lyapunov
function-based analysis that ensures asymptotic stability of the resulting
closed-loop tracking error is used to design the proposed NLPD controller.
Numerical simulations are performed using MATLAB/Simulink to show the
controllers' ability to achieve favorable tracking in the presence of the solar
background noise within competitive times. Finally, results demonstrate the
proposed NLPD controller improves the tracking error performance more than
$70\%$ under nominal conditions and $35\%$ with model uncertainties and
disturbances compared to the original PD strategy.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:33:07 GMT""}]","2021-02-10"
"2102.04725","Sebastien Callens","Sebastien J.P. Callens, Christoph H. Arns, Alina Kuliesh, Amir A.
  Zadpoor","Decoupling minimal surface metamaterial properties through
  multi-material hyperbolic tilings","25 pages, 6 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Rapid advances in additive manufacturing over the past decade have kindled
widespread interest in the rational design of metamaterials with unique
properties. However, many applications require multi-physics metamaterials,
where multiple properties are simultaneously optimized. This is challenging,
since different properties, such as mechanical and mass transport properties,
typically impose competing requirements on the nano-/micro-/meso-architecture
of metamaterials. Here, we propose a parametric metamaterial design strategy
that enables independent tuning of the effective permeability and elastic
properties. We apply hyperbolic tiling theory to devise simple templates based
on which triply periodic minimal surfaces (TPMS) are partitioned into hard and
soft regions. Through computational analyses, we demonstrate how the decoration
of hard, soft, and void phases within the TPMS substantially enhances their
permeability-elasticity property space and offers high tunability in the
elastic properties and anisotropy, at constant permeability. We also show that
this permeability-elasticity balance is well captured using simple scaling
laws. We then proceed to demonstrate the proposed concept through
multi-material additive manufacturing of representative specimens. Our
approach, which is generalizable to other designs, offers a route towards
multi-physics metamaterials that need to simultaneously carry a load and enable
mass transport, such as load-bearing heat exchangers or architected
tissue-substituting meta-biomaterials.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:44:23 GMT""}]","2021-02-10"
"2102.04726","Felix von Oppen","Sergio Acero Gonzalez, Larissa Melischek, Olof Peters, Karsten
  Flensberg, Katharina J. Franke, and Felix von Oppen","Photon-assisted resonant Andreev reflections: Yu-Shiba-Rusinov and
  Majorana states","20 pages, 8 figures","Phys. Rev. B 102, 045413 (2020)","10.1103/PhysRevB.102.045413",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photon-assisted tunneling frequently provides detailed information on the
underlying charge-transfer process. In particular, the Tien-Gordon approach and
its extensions predict that the sideband spacing in bias voltage is a direct
fingerprint of the number of electrons transferred in a single tunneling event.
Here, we analyze photon-assisted tunneling into subgap states in
superconductors in the limit of small temperatures and bias voltages where
tunneling is dominated by resonant Andreev processes and does not conform to
the predictions of simple Tien-Gordon theory. Our analysis is based on a
systematic Keldysh calculation of the subgap conductance and provides a
detailed analytical understanding of photon-assisted tunneling into subgap
states, in excellent agreement with a recent experiment. We focus on tunneling
from superconducting electrodes and into Yu-Shiba-Rusinov states associated
with magnetic impurities or adatoms, but we also explicitly extend our results
to include normal-metal electrodes or other types of subgap states in
superconductors. In particular, we argue that photon-assisted Andreev
reflections provide a high-accuracy method to measure small, but nonzero
energies of subgap states which can be important for distinguishing
conventional subgap states from Majorana bound states.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:44:54 GMT""}]","2022-04-01"
"2102.04727","Yanhao Zhang","Yanhao Zhang, Qiang Wang, Pan Pan, Yun Zheng, Cheng Da, Siyang Sun and
  Yinghui Xu","Fashion Focus: Multi-modal Retrieval System for Video Commodity
  Localization in E-commerce","accepted by AAAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, live-stream and short video shopping in E-commerce have grown
exponentially. However, the sellers are required to manually match images of
the selling products to the timestamp of exhibition in the untrimmed video,
resulting in a complicated process. To solve the problem, we present an
innovative demonstration of multi-modal retrieval system called ""Fashion
Focus"", which enables to exactly localize the product images in the online
video as the focuses. Different modality contributes to the community
localization, including visual content, linguistic features and interaction
context are jointly investigated via presented multi-modal learning. Our system
employs two procedures for analysis, including video content structuring and
multi-modal retrieval, to automatically achieve accurate video-to-shop
matching. Fashion Focus presents a unified framework that can orientate the
consumers towards relevant product exhibitions during watching videos and help
the sellers to effectively deliver the products over search and recommendation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:45:04 GMT""}]","2021-02-10"
"2102.04728","Tiberiu Harko","Tiberiu Harko, Haidar Sheikhahmadi","Warm inflation with non-comoving scalar field and radiation fluid","25 pages, 8 figures, accepted for publication in EPJC","Eur. Phys. J. C (2021) 81: 165","10.1140/epjc/s10052-021-08964-6",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a warm inflationary scenario in which the two dominant matter
components present in the early Universe, the scalar field, and the radiation
fluid, evolve with different four-velocities. This cosmological system is
mathematically equivalent to a single anisotropic fluid, evolving with a
four-velocity that is a function of the two independent fluid four-velocities.
Due to the presence of the anisotropic physical parameters, the overall
cosmological evolution is also anisotropic. We derive the gravitational field
equations of the noncomoving scalar field-radiation mixture for a Bianchi type
I geometry. By considering that the decay of the scalar field is accompanied by
a corresponding radiation generation, we formulate the basic equations of the
warm inflationary model in the presence of two noncomoving components. By
adopting the slow roll approximation, we perform a detailed comparison of the
theoretical predictions of the warm inflationary scenario with noncomoving
scalar field and radiation fluid with the observational data obtained by the
Planck satellite, by investigating both the weak dissipation and strong
dissipation limits. Constraints on the free parameters of the model are
obtained in both cases. The functional forms of the scalar field potentials
compatible with the noncomoving nature of warm inflation are also derived.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:45:54 GMT""}]","2021-03-15"
"2102.04729","Aly El Gamal","Teng-Hui Huang, Aly El Gamal","A Provably Convergent Information Bottleneck Solution via ADMM","8 pages, 1 figure",,,,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Information bottleneck (IB) method enables optimizing over the trade-off
between compression of data and prediction accuracy of learned representations,
and has successfully and robustly been applied to both supervised and
unsupervised representation learning problems. However, IB has several
limitations. First, the IB problem is hard to optimize. The IB Lagrangian
$\mathcal{L}_{IB}:=I(X;Z)-\beta I(Y;Z)$ is non-convex and existing solutions
guarantee only local convergence. As a result, the obtained solutions depend on
initialization. Second, the evaluation of a solution is also a challenging
task. Conventionally, it resorts to characterizing the information plane, that
is, plotting $I(Y;Z)$ versus $I(X;Z)$ for all solutions obtained from different
initial points. Furthermore, the IB Lagrangian has phase transitions while
varying the multiplier $\beta$. At phase transitions, both $I(X;Z)$ and
$I(Y;Z)$ increase abruptly and the rate of convergence becomes significantly
slow for existing solutions. Recent works with IB adopt variational surrogate
bounds to the IB Lagrangian. Although allowing efficient optimization, how
close are these surrogates to the IB Lagrangian is not clear. In this work, we
solve the IB Lagrangian using augmented Lagrangian methods. With augmented
variables, we show that the IB objective can be solved with the alternating
direction method of multipliers (ADMM). Different from prior works, we prove
that the proposed algorithm is consistently convergent, regardless of the value
of $\beta$. Empirically, our gradient-descent-based method results in
information plane points that are comparable to those obtained through the
conventional Blahut-Arimoto-based solvers and is convergent for a wider range
of the penalty coefficient than previous ADMM solvers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:47:18 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 22:19:53 GMT""}]","2021-05-25"
"2102.04730","Kuan Hsieh","Kuan Hsieh, Cynthia Rush, Ramji Venkataramanan","Near-Optimal Coding for Many-user Multiple Access Channels","15 pages, 4 figures. To appear in IEEE Journal on Selected Areas in
  Information Theory","IEEE Journal on Selected Areas in Information Theory, vol. 3, no.
  1, pp. 21-36, March 2022","10.1109/JSAIT.2022.3158827",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the Gaussian multiple-access channel (MAC) in the
asymptotic regime where the number of users grows linearly with the code
length. We propose efficient coding schemes based on random linear models with
approximate message passing (AMP) decoding and derive the asymptotic error rate
achieved for a given user density, user payload (in bits), and user energy. The
tradeoff between energy-per-bit and achievable user density (for a fixed user
payload and target error rate) is studied, and it is demonstrated that in the
large system limit, a spatially coupled coding scheme with AMP decoding
achieves near-optimal tradeoffs for a wide range of user densities.
Furthermore, in the regime where the user payload is large, we also study the
tradeoff between energy-per-bit and spectral efficiency and discuss methods to
reduce decoding complexity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:51:23 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 21:43:52 GMT""},{""version"":""v3"",""created"":""Wed, 9 Mar 2022 16:29:51 GMT""}]","2022-05-04"
"2102.04731","Marco Carbone","Marco Carbone, Sonia Marin, Carsten Sch\""urmann","Synchronous Forwarders",,,,,"cs.PL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Session types are types for specifying protocols that processes must follow
when communicating with each other. Session types are in a
propositions-as-types correspondence with linear logic. Previous work has shown
that a multiparty session type, a generalisation of session types to protocols
of two or more parties, can be modelled as a proof of coherence, a
generalisation of linear logic duality. And, protocols expressed as coherence
can be simulated by arbiters, processes that act as a middleware by forwarding
messages according to the given protocol. In this paper, we generalise the
concept of arbiter to that of synchronous forwarder, that is a processes that
implements the behaviour of an arbiter in several different ways. In a
propositions-as-types fashion, synchronous forwarders form a logic equipped
with cut elimination which is a special restriction of classical linear logic.
Our main result shows that synchronous forwarders are a characterisation of
coherence, i.e., coherence proofs can be transformed into synchronous
forwarders and, viceversa, every synchronous forwarder corresponds to a
coherence proofs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:51:59 GMT""}]","2021-02-10"
"2102.04732","Fabio Tanania","Fabio Tanania","Cellular objects in isotropic motivic categories","To appear in Geometry and Topology",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main purpose of this paper is to describe the category of isotropic
cellular spectra over flexible fields. Guided by [9], we show that it is
equivalent as a stable $\infty$-category equipped with a $t$-structure to the
derived category of left comodules over the dual of the classical topological
Steenrod algebra. In order to obtain this result, the category of isotropic
cellular modules over the motivic Brown-Peterson spectrum is also studied and
isotropic Adams and Adams-Novikov spectral sequences are developed. As a
consequence, we also compute hom-sets in the category of isotropic Tate motives
between motives of isotropic cellular spectra.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:53:47 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 16:00:33 GMT""}]","2022-08-08"
"2102.04733","Sonia L Rueda","Sonia L. Rueda and Maria-Angeles Zurro","Factoring Third Order Ordinary Differential Operators over Spectral
  Curves",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the classical factorization problem of a third order ordinary
differential operator $L-\lambda$, for a spectral parameter $\lambda$. It is
assumed that $L$ is an algebro-geometric operator, that it has a nontrivial
centralizer, which can be seen as the affine ring of curve, the famous
""spectral curve"" $\Gamma$. In this work we explicitly describe the ring
structure of the centralizer of $L$ and, as a consequence, we prove that
$\Gamma$ is a space curve. In this context, the first computed example of a
non-planar spectral curve arises, for an operator of this type. Based on the
structure of the centralizer, we give a symbolic algorithm, using differential
subresultants, to factor $L-\lambda_0$ for all but a finite number of points
$P=(\lambda_0 , \mu_0 , \gamma_0)$ of the spectral curve .
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:55:47 GMT""}]","2021-02-10"
"2102.04734","Rishabh Bhalavi","Rishabh Kumar Bhalavi and Rakesh Kumar Singh","Phase-space interpretation of spatial stationarity for coherence
  holography","7 pages, 2 figures (gray-scale)",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the wide-sense spatial stationarity concept of coherence holography
in the regime of phase-space using the wigner distribution function. We focus
mainly on the incoherent light source and the Fourier and Fresnel propagation
kernels for the optical-field transformation rule (inputoutput relation) and
derive the same analogy in WDF. We further show that in phase-space the WDF
obtained from the ensemble-averaged and space-averaged coherence functions are
the same. Finally, we interpret behaviour of these results through numerical
simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:58:29 GMT""}]","2021-02-10"
"2102.04735","Mark Sadgrove","Mark Sadgrove, Takaaki Yoshino, Masakazu Sugawara, Yasuyoshi
  Mitsumori, and Keiichi Edamatsu","Optically induced sieve effect for nanoparticles near a nanofiber taper","V2: Typos in text and figures corrected, title and abstract edited to
  emphasize novel content. Text edited for brevity in some places",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate size selective optical trapping and transport for
nanoparticles near an optical nanofiber taper. Using a two-wavelength,
counter-propagating mode configuration, we show that 100 nm diameter and 150 nm
diameter gold nanospheres (GNSs) are trapped by the evanescent field in the
taper region at different optical powers. Conversely, when one nanoparticle
species is trapped the other may be transported, leading to a sieve-like
effect. Our results show that sophisticated optical manipulation can be
achieved in a passive configuration by taking advantage of mode behavior in
nanophotonics devices.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:02:47 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 04:08:27 GMT""}]","2021-03-17"
"2102.04736","Gabriel Barth-Maron","Albin Cassirer, Gabriel Barth-Maron, Eugene Brevdo, Sabela Ramos, Toby
  Boyd, Thibault Sottiaux, Manuel Kroiss","Reverb: A Framework For Experience Replay","11 pages",,,,"cs.LG cs.AI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A central component of training in Reinforcement Learning (RL) is Experience:
the data used for training. The mechanisms used to generate and consume this
data have an important effect on the performance of RL algorithms.
  In this paper, we introduce Reverb: an efficient, extensible, and easy to use
system designed specifically for experience replay in RL. Reverb is designed to
work efficiently in distributed configurations with up to thousands of
concurrent clients.
  The flexible API provides users with the tools to easily and accurately
configure the replay buffer. It includes strategies for selecting and removing
elements from the buffer, as well as options for controlling the ratio between
sampled and inserted elements. This paper presents the core design of Reverb,
gives examples of how it can be applied, and provides empirical results of
Reverb's performance characteristics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:03:17 GMT""}]","2021-02-10"
"2102.04737","Onur G\""unl\""u Dr.-Ing.","Muah Kim, Onur G\""unl\""u, and Rafael F. Schaefer","Federated Learning with Local Differential Privacy: Trade-offs between
  Privacy, Utility, and Communication","To appear in IEEE International Conference on Acoustics, Speech, and
  Signal Processing 2021",,,,"cs.LG cs.CR cs.DC cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Federated learning (FL) allows to train a massive amount of data privately
due to its decentralized structure. Stochastic gradient descent (SGD) is
commonly used for FL due to its good empirical performance, but sensitive user
information can still be inferred from weight updates shared during FL
iterations. We consider Gaussian mechanisms to preserve local differential
privacy (LDP) of user data in the FL model with SGD. The trade-offs between
user privacy, global utility, and transmission rate are proved by defining
appropriate metrics for FL with LDP. Compared to existing results, the query
sensitivity used in LDP is defined as a variable and a tighter privacy
accounting method is applied. The proposed utility bound allows heterogeneous
parameters over all users. Our bounds characterize how much utility decreases
and transmission rate increases if a stronger privacy regime is targeted.
Furthermore, given a target privacy level, our results guarantee a
significantly larger utility and a smaller transmission rate as compared to
existing privacy accounting methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:04:18 GMT""}]","2021-02-10"
"2102.04738","Jinn-Liang Liu","Der-Hau Lee and Jinn-Liang Liu","End-to-End Deep Learning of Lane Detection and Path Prediction for
  Real-Time Autonomous Driving","6 pages, 4 figures",,,,"cs.CV cs.AI cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the UNet architecture of semantic image segmentation, we propose
a lightweight UNet using depthwise separable convolutions (DSUNet) for
end-to-end learning of lane detection and path prediction (PP) in autonomous
driving. We also design and integrate a PP algorithm with convolutional neural
network (CNN) to form a simulation model (CNN-PP) that can be used to assess
CNN's performance qualitatively, quantitatively, and dynamically in a host
agent car driving along with other agents all in a real-time autonomous manner.
DSUNet is 5.16x lighter in model size and 1.61x faster in inference than UNet.
DSUNet-PP outperforms UNet-PP in mean average errors of predicted curvature and
lateral offset for path planning in dynamic simulation. DSUNet-PP outperforms a
modified UNet in lateral error, which is tested in a real car on real road.
These results show that DSUNet is efficient and effective for lane detection
and path prediction in autonomous driving.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:04:39 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 02:40:18 GMT""}]","2021-12-10"
"2102.04739","Supriyo Ghosh","Supriyo Ghosh, Soumen Mondal, Ramkrishna Das, and Somnath Dutta","Spectroscopic and photometric monitoring of a poorly known high-luminous
  OH/IR star: IRAS 18278+0931","14 pages, 7 figures, 5 tables. Accepted for publication in AJ",,"10.3847/1538-3881/abe544",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the time-dependent properties of a poorly known OH/IR star $-$
IRAS 18278+0931 (hereafter, IRAS 18+09) towards the Ophiuchus constellation. We
have carried out long-term optical/near-infrared (NIR) photometric and
spectroscopic observations to study the object. From optical $R$- and $I$-band
light curves, the period of IRAS 18+09 is estimated to be 575 $\pm$ 30 days and
the variability amplitudes range from $\Delta$R $\sim$ 4.0 mag to $\Delta$I
$\sim$ 3.5 mag. From the standard Period-Luminosity (PL) relations, the
distance ($D$) to the object, 4.0 $\pm$ 1.3 kpc, is estimated. Applying this
distance in the radiative transfer model, the spectral energy distribution
(SED) are constructed from multi-wavelength photometric and IRAS-LRS spectral
data which provides the luminosity, optical depth, and gas mass-loss rate (MLR)
of the object to be 9600 $\pm$ 500 $L_{\odot}$, 9.1 $\pm$ 0.6 at 0.55 $\mu$m
and 1.0$\times$10$^{-6}$ M$_\odot$ yr$^{-1}$, respectively. The current mass of
the object infers in the range 1.0 $-$ 1.5 $M_\odot$ assuming solar
metallicity. Notably, the temporal variation of atomic and molecular features
(e.g., TiO, Na I, Ca I, CO, H$_2$O) over the pulsation cycle of the OH/IR star
illustrates the sensitivity of the spectral features to the dynamical
atmosphere as observed in pulsating AGB stars.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:05:31 GMT""}]","2021-03-31"
"2102.04740","Christopher Carignan","Christopher Carignan and Ander Egurtzegi","Principal components variable importance reconstruction (PC-VIR):
  Exploring predictive importance in multicollinear acoustic speech data","10 pages, 3 figures, GitHub repository",,,,"stat.ME cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  This paper presents a method of exploring the relative predictive importance
of individual variables in multicollinear data sets at three levels of
significance: strong importance, moderate importance, and no importance.
Implementation of Bonferroni adjustment to control for Type I error in the
method is described, and results with and without the correction are compared.
An example of the method in binary logistic modeling is demonstrated by using a
set of 20 acoustic features to discriminate vocalic nasality in the speech of
six speakers of the Mixean variety of Low Navarrese Basque. Validation of the
method is presented by comparing the direction of significant effects to those
observed in separate logistic mixed effects models, as well as goodness of fit
and prediction accuracy compared to partial least squares logistic regression.
The results show that the proposed method yields: (1) similar, but more
conservative estimates in comparison to separate logistic regression models,
(2) models that fit data as well as partial least squares methods, and (3)
predictions for new data that are as accurate as partial least squares methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:06:43 GMT""}]","2021-02-10"
"2102.04741","Fan Zhou","Fan Zhou, Arini Fitri, Khoirul Anwar, Brian M. Kurkoski","Encoding and Decoding Construction D' Lattices for Power-Constrained
  Communications",,"Proc. 2021 IEEE International Symposium on Information Theory
  (ISIT), pp. 1005-1010","10.1109/ISIT45174.2021.9518122",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the encoding and decoding of Construction D' coding
lattices that can be used with shaping lattices for power-constrained channels.
Two encoding methods and a decoding algorithm for Construction D' lattices are
given. A design of quasi-cyclic low-density parity-check (QC-LDPC) codes to
form Construction D' lattices is presented. This allows construction of nested
lattice codes which are good for coding, good for shaping, and have low
complexity encoding and decoding. Numerical results of using $E_8$, $BW_{16}$
and Leech lattices for shaping a Construction D' lattice indicate that the
shaping gains 0.65 dB, 0.86 dB and 1.03 dB are preserved, respectively.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:09:27 GMT""}]","2021-09-14"
"2102.04742","Yunhe Sheng","Jifeng Liu, Yunhe Sheng, Chengming Bai","Maurer-Cartan characterizations and cohomologies of compatible Lie
  algebras","24 pages","Science China Mathematics (2022)","10.1007/s11425-021-2014-5",,"math-ph math.MP math.RA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we give Maurer-Cartan characterizations as well as a
cohomology theory for compatible Lie algebras. Explicitly, we first introduce
the notion of a bidifferential graded Lie algebra and thus give Maurer-Cartan
characterizations of compatible Lie algebras. Then we introduce a cohomology
theory of compatible Lie algebras and use it to classify infinitesimal
deformations and abelian extensions of compatible Lie algebras. In particular,
we introduce the reduced cohomology of a compatible Lie algebra and establish
the relation between the reduced cohomology of a compatible Lie algebra and the
cohomology of the corresponding compatible linear Poisson structures introduced
by Dubrovin and Zhang in their study of bi-Hamiltonian structures. Finally, we
use the Maurer-Cartan approach to classify nonabelian extensions of compatible
Lie algebras.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:17:07 GMT""}]","2022-08-24"
"2102.04743","Eddie Ross","Eddie Ross, William J. Chaplin, Steven J. Hale, Rachel Howe, Yvonne P.
  Elsworth, Guy R. Davies and Martin Bo Nielsen","Lifetimes and Rotation within the Solar Mean Magnetic Field","Accepted for publication in MNRAS; 9 pages, 7 figures, 1 table",,"10.1093/mnras/stab405",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have used very high-cadence (sub-minute) observations of the solar mean
magnetic field (SMMF) from the Birmingham Solar Oscillations Network (BiSON) to
investigate the morphology of the SMMF. The observations span a period from
1992--2012, and the high-cadence observations allowed the exploration of the
power spectrum up to frequencies in the mHz range. The power spectrum contains
several broad peaks from a rotationally-modulated (RM) component, whose
linewidths allowed us to measure, for the first time, the lifetime of the RM
source. There is an additional broadband, background component in the power
spectrum which we have shown is an artefact of power aliasing due to the low
fill of the data. The sidereal rotation period of the RM component was measured
as $25.23 \pm 0.11$ days and suggests that the signal is sensitive to a
time-averaged latitude of $\sim 12^{\circ}$. We have also shown the RM lifetime
to be $139.6 \pm 18.5$ days. This provides evidence to suggest the RM component
of the SMMF is connected to magnetic flux concentrations (MFCs) and active
regions (ARs) of magnetic flux, based both on its lifetime and location on the
solar disc.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:17:29 GMT""}]","2021-03-03"
"2102.04744","Jibitesh Dutta","Wompherdeiki Khyllep and Jibitesh Dutta","Cosmological dynamics and bifurcation analysis of the general
  non-minimally coupled scalar field models","17 pages and 14 figs","Eur. Phys. J. C 81, 774 (2021)","10.1140/epjc/s10052-021-09559-x",,"gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-minimally coupled scalar field models are well-known for providing
interesting cosmological features. These include a late time dark energy
behavior, a phantom dark energy evolution without singularity, an early time
inflationary universe, scaling solutions, convergence to the standard
$\Lambda$CDM, etc. While the usual stability analysis helps us determine the
evolution of a model geometrically, bifurcation theory allows us to precisely
locate the parameters' values describing the global dynamics without a
fine-tuning of initial conditions. Using the center manifold theory and
bifurcation analysis, we show that the general model undergoes a transcritical
bifurcation, which predicts us to tune our models to have certain desired
dynamics. We obtained a class of models and a range of parameters capable of
describing a cosmic evolution from an early radiation era towards a late time
dark energy era over a wide range of initial conditions. There is also a
possible scenario of crossing the phantom divide line. We also find a class of
models where the late time attractor mechanism is indistinguishable from that
of a structurally stable general relativity based model; thus, we can elude the
big rip singularity generically. Therefore, bifurcation theory allows us to
select models that are viable with cosmological observations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:18:05 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 08:43:55 GMT""}]","2021-09-03"
"2102.04745","Lorenzo Piroli","Denis Bernard, Lorenzo Piroli","Entanglement distribution in the Quantum Symmetric Simple Exclusion
  Process","6 pages, 3 figures; v2: minor revision","Phys. Rev. E 104, 014146 (2021)","10.1103/PhysRevE.104.014146",,"cond-mat.stat-mech math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the probability distribution of entanglement in the Quantum
Symmetric Simple Exclusion Process, a model of fermions hopping with random
Brownian amplitudes between neighboring sites. We consider a protocol where the
system is initialized in a pure product state of $M$ particles, and focus on
the late-time distribution of R\'enyi-$q$ entropies for a subsystem of size
$\ell$. By means of a Coulomb gas approach from Random Matrix Theory, we
compute analytically the large-deviation function of the entropy in the
thermodynamic limit. For $q>1$, we show that, depending on the value of the
ratio $\ell/M$, the entropy distribution displays either two or three distinct
regimes, ranging from low- to high-entanglement. These are connected by points
where the probability density features singularities in its third derivative,
which can be understood in terms of a transition in the corresponding charge
density of the Coulomb gas. Our analytic results are supported by numerical
Monte Carlo simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:25:04 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 13:04:54 GMT""}]","2021-07-30"
"2102.04746","Mats Brun PhD","Mats K. Brun, Elyes Ahmed, Jan Martin Nordbotten, Nils Christian
  Stenseth","Modeling the process of speciation using a multi-scale framework
  including error estimates","27 pages, 27 figures",,,,"q-bio.PE math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper concerns the modeling and numerical simulation of the process of
speciation. In particular, given conditions for which one or more speciation
events within an ecosystem occur, our aim is to develop the necessary modeling
and simulation tools. Care is also taken to establish a solid mathematical
foundation on which our modeling framework is built. This is the subject of the
first half of the paper. The second half is devoted to developing a multi-scale
framework for eco-evolutionary modeling, where the relevant scales are that of
species and individual/population, respectively. Hence, a system of interacting
species can be described at the species level, while for branching species a
population level description is necessary. Our multi-scale framework thus
consists of coupling the species and population level models where speciation
events are detected in advance and then resolved at the population scale until
the branching is complete. Moreover, since the population level model is
formulated as a PDE, we first establish the well-posedness in the time-discrete
setting, and then derive the a posteriori error estimates which provides a
fully computable upper bound on an energy-type error, including also for the
case of general smooth distributions (which will be useful for the detection of
speciation events). Several numerical tests validate our framework in practice.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:26:16 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 16:17:05 GMT""}]","2021-10-08"
"2102.04747","Elena R. Loubenets","Elena R. Loubenets and Min Namkung","Conclusive discrimination by $N$ sequential receivers between $r\geq2$
  arbitrary quantum states","Improved and extended version, 29 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present article, we develop a general framework for the description of
discrimination between $r\geq2$ quantum states by $N\geq1$ sequential receivers
in the case where each receiver obtains a conclusive result. This type of
discrimination constitutes an $N$-sequential extension of the minimum-error
discrimination by one receiver. The developed general framework, which is valid
for a conclusive discrimination between any number $r\geq2$ of arbitrary
quantum states, pure or mixed, of an arbitrary dimension and any number
$N\geq1$ of sequential receivers, is based on the notion of a quantum state
instrument and this allows us to derive the new important general results. We,
in particular, find a general condition on $r\geq2$ quantum states, under
which, within the strategy where all types of receivers' quantum measurements
are allowed, the optimal success probability is equal to that of the first
receiver for any number $N\geq2$ of further sequential receivers. Furthermore,
we extend our general framework to include an $N$-sequential conclusive
discrimination between $r\geq2$ arbitrary quantum states under a noisy
communication. As an example, we analyze analytically and numerically a
two-sequential conclusive discrimination between two qubit states via
depolarizing quantum channels. The derived new general results are important
both from the theoretical point of view and for the development of a successful
multipartite quantum communication via noisy quantum channels.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:32:23 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 13:59:32 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 07:55:43 GMT""},{""version"":""v4"",""created"":""Wed, 11 Jan 2023 07:23:36 GMT""}]","2023-01-12"
"2102.04748","Oscar Dominguez","Oscar Dom\'inguez, Sergey Tikhonov","New estimates for the maximal functions and applications","47 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study sharp pointwise inequalities for maximal operators. In
particular, we strengthen DeVore's inequality for the moduli of smoothness and
a logarithmic variant of Bennett--DeVore--Sharpley's inequality for
rearrangements. As a consequence, we improve the classical Stein--Zygmund
embedding deriving $\dot{B}^{d/p}_\infty L_{p,\infty}(\mathbb{R}^d)
\hookrightarrow \text{BMO}(\mathbb{R}^d)$ for $1 < p < \infty$. Moreover, these
results are also applied to establish new Fefferman--Stein inequalities,
Calder\'on--Scott type inequalities, and extrapolation estimates. Our approach
is based on the limiting interpolation techniques.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:34:13 GMT""}]","2021-02-10"
"2102.04749","Roy Zektzer","Roy Zektzer, Eliran Talker, Yefim Barash, Noa Mazurski and Uriel Levy","Chiral light-matter interactions in hot vapor cladded waveguides",,,"10.1364/OPTICA.6.000015",,"physics.optics physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, there is growing interest in integrating alkali vapors with
nanoscale photonic structures, such as nano-waveguides, resonators and
nanoantennas. Nanoscale confinement of electromagnetic fields may introduce a
longitudinal electric field component, giving rise to circularly polarized
modes which are essential for diverse applications involving vapor and light,
such as chirality and non-reciprocity. Hereby, we have designed, fabricated and
characterized a miniaturized vapor cell that is integrated with optical
waveguides that are designed to generate a peculiar circular-like polarization.
Taking advantage of this phenomenon, we demonstrate a spectral shift in the
atomic absorption signatures at varying magnetic fields, and significant
isolation between forward and backward propagating waves in our atomic-cladded
waveguide. Our results pave the way for the utilization of chip-scale
integrated atomic devices in applications such as optical isolation and high
spatial resolution magnetometry.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:34:14 GMT""}]","2021-02-10"
"2102.04750","Pedro Vicente","Alexandre Almeida, Pedro Vicente, Alexandre Bernardino","Where is my hand? Deep hand segmentation for visual self-recognition in
  humanoid robots","13 pages, 12 figures, Submitted to Journal of Robotics and Autonomous
  Systems",,,,"cs.RO cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to distinguish between the self and the background is of
paramount importance for robotic tasks. The particular case of hands, as the
end effectors of a robotic system that more often enter into contact with other
elements of the environment, must be perceived and tracked with precision to
execute the intended tasks with dexterity and without colliding with obstacles.
They are fundamental for several applications, from Human-Robot Interaction
tasks to object manipulation. Modern humanoid robots are characterized by high
number of degrees of freedom which makes their forward kinematics models very
sensitive to uncertainty. Thus, resorting to vision sensing can be the only
solution to endow these robots with a good perception of the self, being able
to localize their body parts with precision. In this paper, we propose the use
of a Convolution Neural Network (CNN) to segment the robot hand from an image
in an egocentric view. It is known that CNNs require a huge amount of data to
be trained. To overcome the challenge of labeling real-world images, we propose
the use of simulated datasets exploiting domain randomization techniques. We
fine-tuned the Mask-RCNN network for the specific task of segmenting the hand
of the humanoid robot Vizzy. We focus our attention on developing a methodology
that requires low amounts of data to achieve reasonable performance while
giving detailed insight on how to properly generate variability in the training
dataset. Moreover, we analyze the fine-tuning process within the complex model
of Mask-RCNN, understanding which weights should be transferred to the new task
of segmenting robot hands. Our final model was trained solely on synthetic
images and achieves an average IoU of 82% on synthetic validation data and
56.3% on real test data. These results were achieved with only 1000 training
images and 3 hours of training time using a single GPU.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:34:32 GMT""}]","2021-02-10"
"2102.04751","Joseph Callingham Dr","J. R. Callingham, B. J. S. Pope, A. D. Feinstein, H. K. Vedantham, T.
  W. Shimwell, P. Zarka, C. Tasse, L. Lamy, K. Veken, S. Toet, J. Sabater, P.
  N. Best, R. J. van Weeren, H. J. A. R\""ottgering, T. P. Ray","Low-frequency monitoring of flare star binary CR Draconis: Long-term
  electron-cyclotron maser emission","Accepted for publication in A&A, 16 pages, 7 figures, 2 tables","A&A 648, A13 (2021)","10.1051/0004-6361/202039144",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Recently detected coherent low-frequency radio emission from M dwarf systems
shares phenomenological similarities with emission produced by magnetospheric
processes from the gas giant planets of our Solar System. Such beamed
electron-cyclotron maser emission can be driven by a star-planet interaction or
a breakdown in co-rotation between a rotating plasma disk and a stellar
magnetosphere. Both models suggest that the radio emission could be periodic.
Here we present the longest low-frequency interferometric monitoring campaign
of an M dwarf system, composed of twenty-one $\approx$8 hour epochs taken in
two series of observing blocks separated by a year. We achieved a total
on-source time of 6.5 days. We show that the M dwarf binary CR Draconis has a
low-frequency 3$\sigma$ detection rate of 90$^{+5}_{-8}$% when a noise floor of
$\approx$0.1 mJy is reached, with a median flux density of 0.92 mJy, consistent
circularly polarised handedness, and a median circularly polarised fraction of
66%. We resolve three bright radio bursts in dynamic spectra, revealing the
brightest is elliptically polarised, confined to 4 MHz of bandwidth centred on
170 MHz, and reaches a flux density of 205 mJy. The burst structure is mottled,
indicating it consists of unresolved sub-bursts. Such a structure shares a
striking resemblance with the low-frequency emission from Jupiter. We suggest
the near-constant detection of high brightness temperature,
highly-circularly-polarised radiation that has a consistent circular
polarisation handedness implies the emission is produced via the
electron-cyclotron maser instability. Optical photometric data reveal the
system has a rotation period of 1.984$\pm$0.003 days. We observe no periodicity
in the radio data, but the sampling of our radio observations produces a window
function that would hide the near two-day signal.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:38:38 GMT""}]","2021-04-07"
"2102.04752","Bogdan Zavyalov","Bogdan Zavyalov","Altered Local Uniformization Of Rigid-Analytic Spaces","Updated. Comments are welcome!",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a version of Temkin's local altered uniformization theorem. We show
that for any rig-smooth, quasi-compact and quasi-separated admissible formal
$\mathcal{O}_K$-model $\mathfrak{X}$, there is a finite extension $K'/K$ such
that $\mathfrak{X}_{\mathcal{O}_{K'}}$ locally admits a rig-\'etale morphism
$g\colon \mathfrak{X}' \to \mathfrak{X}_{\mathcal{O}_{K'}}$ and a
rig-isomorphism $h\colon \mathfrak{X}"" \to \mathfrak{X}'$ with $\mathfrak{X}'$
being a successive semi-stable curve fibration over $\mathcal{O}_{K'}$ and
$\mathfrak{X}""$ being a poly-stable formal $\mathcal{O}_{K'}$-scheme. Moreover,
$\mathfrak{X}'$ admits an action of a finite group $G$ such that $g\colon
\mathfrak{X}' \to \mathfrak{X}_{\mathcal{O}_{K'}}$ is $G$-invariant, and the
adic generic fiber $\mathfrak{X}'_{K'}$ becomes a $G$-torsor over its
quasi-compact open image $U=g_{K'}(\mathfrak{X}'_{K'})$. Also, we study
properties of the quotient map $\mathfrak{X}'/G \to
\mathfrak{X}_{\mathcal{O}_{K'}}$ and show that it can be obtained as a
composition of open immersions and rig-isomorphisms.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:40:13 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 11:43:14 GMT""}]","2022-06-14"
"2102.04753","Yuri Makeenko","Yuri Makeenko","Private life of the Liouville field that causes new anomalies in the
  Nambu-Goto string","21 pages, 5 figures; v2: slightly polished",,"10.1016/j.nuclphysb.2021.115398","ITEP-TH-05/21","hep-th","http://creativecommons.org/licenses/by/4.0/","  I consider higher-order terms of the Seeley expansion of the heat kernel,
which for smooth metrics are suppressed as inverse powers of the UV cutoff
$\Lambda$, and demonstrate how they result in an anomalous contribution to the
string effective action after doing uncertainties $\Lambda^{-2}\times
\Lambda^2$. For the Polyakov string these anomalies precisely reproduce at one
loop the result of KPZ-DDK obtained for the Liouville theory by the conformal
field theory technique. For the Nambu-Goto string I find a deviation from this
result which shows that the two string formulations may differ.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:47:54 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 09:04:04 GMT""}]","2021-05-05"
"2102.04754","Boyang Xue","Boyang Xue, Jianwei Yu, Junhao Xu, Shansong Liu, Shoukang Hu, Zi Ye,
  Mengzhe Geng, Xunying Liu, Helen Meng","Bayesian Transformer Language Models for Speech Recognition",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art neural language models (LMs) represented by Transformers are
highly complex. Their use of fixed, deterministic parameter estimates fail to
account for model uncertainty and lead to over-fitting and poor generalization
when given limited training data. In order to address these issues, this paper
proposes a full Bayesian learning framework for Transformer LM estimation.
Efficient variational inference based approaches are used to estimate the
latent parameter posterior distributions associated with different parts of the
Transformer model architecture including multi-head self-attention, feed
forward and embedding layers. Statistically significant word error rate (WER)
reductions up to 0.5\% absolute (3.18\% relative) and consistent perplexity
gains were obtained over the baseline Transformer LMs on state-of-the-art
Switchboard corpus trained LF-MMI factored TDNN systems with i-Vector speaker
adaptation. Performance improvements were also obtained on a cross domain LM
adaptation task requiring porting a Transformer LM trained on the Switchboard
and Fisher data to a low-resource DementiaBank elderly speech corpus.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:55:27 GMT""}]","2021-02-10"
"2102.04755","Alessandro Laneve","Alessandro Laneve, Farzam Nosrati, Andrea Geraldi, Kobra Mahdavipour,
  Federico Pegoraro, Mahshid Khazaei Shadfar, Rosario Lo Franco, Paolo Mataloni","Enhancing nonclassical bosonic correlations in a Quantum Walk network
  through experimental control of disorder","11 pages, 12 figures","Phys. Rev. Research 3, 033235 (2021)","10.1103/PhysRevResearch.3.033235",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The presence of disorder and inhomogeneities in quantum networks has often
been unexpectedly beneficial for both quantum and classical resources. Here, we
experimentally realize a controllable inhomogenous Quantum Walk dynamics, which
can be exploited to investigate the effect of coherent disorder on the quantum
correlations between two indistinguishable photons. Through the imposition of
suitable disorder configurations, we observe two photon states which exhibit an
enhancement in the quantum correlations between two modes of the network,
compared to the case of an ordered Quantum Walk. Different configurations of
disorder can steer the system towards different realizations of such an
enhancement, thus allowing spatial and temporal manipulation of quantum
correlations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 10:57:00 GMT""}]","2021-09-15"
"2102.04756","Evgeny Plekhanov","Evgeny Plekhanov, Nicola Bonini, Cedric Weber","Calculating DMFT forces in ab-initio ultrasoft pseudopotential formalism","12 pages, 3 figures","Phys. Rev. B 104 235131 (2021)","10.1103/PhysRevB.104.235131",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show how to calculate analytical atomic forces within
self-consistent density functional theory + dynamical mean-field theory
(DFT+DMFT) approach in the case when ultra-soft or norm-conserving
pseudopotentials are used. We show how to treat the non-local projection terms
arising within the pseudopotential formalism and circumvent the problem of
non-orthogonality of the Kohn-Sham eigenvectors. Our approach is, in principle,
independent of the DMFT solver employed, and here was tested with the Hubbard I
solver. We benchmark our formalism by comparing against the forces calculated
in Ce$_{2}$O$_{3}$ and PrO$_2$ by numerical differentiation of the total free
energy, as well as by comparing the energy profiles against the numerically
integrated analytical forces.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:00:21 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 22:35:41 GMT""}]","2021-12-20"
"2102.04757","Samuel Cohen","Samuel N. Cohen and Derek Snow and Lukasz Szpruch","Black-box model risk in finance",,,,,"q-fin.CP econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning models are increasingly used in a wide variety of financial
settings. The difficulty of understanding the inner workings of these systems,
combined with their wide applicability, has the potential to lead to
significant new risks for users; these risks need to be understood and
quantified. In this sub-chapter, we will focus on a well studied application of
machine learning techniques, to pricing and hedging of financial options. Our
aim will be to highlight the various sources of risk that the introduction of
machine learning emphasises or de-emphasises, and the possible risk mitigation
and management strategies that are available.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:10:51 GMT""}]","2021-02-10"
"2102.04758","Jacob Janssen","Jacob Janssen and Yaneer Bar-Yam","Lowest-cost virus suppression","6 pages",,,,"econ.GN econ.TH q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Analysis of policies for managing epidemics require simultaneously an
economic and epidemiological perspective. We adopt a cost-of-policy framework
to model both the virus spread and the cost of handling the pandemic. Because
it is harder and more costly to fight the pandemic when the circulation is
higher, we find that the optimal policy is to go to zero or near-zero case
numbers. Without imported cases, if a region is willing to implement measures
to prevent spread at one level in number of cases, it must also be willing to
prevent the spread with at a lower level, since it will be cheaper to do so and
has only positive other effects. With imported cases, if a region is not
coordinating with other regions, we show the cheapest policy is continually low
but nonzero cases due to decreasing cost of halting imported cases. When it is
coordinating, zero is cost-optimal. Our analysis indicates that within Europe
cooperation targeting a reduction of both within country transmission, and
between country importation risk, should help achieve lower transmission and
reduced costs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:18:30 GMT""}]","2021-02-10"
"2102.04759","Staszek Zola","K. D. Gazeas, G. A. Loukaidou, P. G. Niarchos, S. Palafouta, D.
  Athanasopoulos, A. Liakos, S. Zola, A. Essam and P. Hakala","CoBiToM Project -- I. Contact Binaries Towards Merging","16 pages, 10 figure, 2 tables",,"10.1093/mnras/stab234",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Binary and multiple stellar systems are numerous in our solar neighborhood
with 80 per cent of the solar-type stars being members of systems with high
order multiplicity. The Contact Binaries Towards Merging (CoBiToM) Project is a
programme that focuses on contact binaries and multiple stellar systems, as a
key for understanding stellar nature. The goal is to investigate stellar
coalescence and merging processes, as the final state of stellar evolution of
low-mass contact binary systems. Obtaining observational data of approximately
100 eclipsing binaries and multiple systems and more than 400 archival systems,
the programme aspires to give insights for their physical and orbital
parameters and their temporal variations, e.g. the orbital period modulation,
spot activity etc. Gravitational phenomena in multiple-star environments will
be linked with stellar evolution. A comprehensive analysis will be conducted,
in order to investigate the possibility of contact binaries to host planets, as
well as the link between inflated hot Jupiters and stellar mergers. The
innovation of CoBiToM Project is based on a multi-method approach and a
detailed investigation, that will shed light for the first time on the origin
of stellar mergers and rapidly rotating stars. In this work we describe the
scientific rationale, the observing facilities to be used and the methods that
will be followed to achieve the goals of CoBiToM Project and we present the
first results as an example of the current research on evolution of contact
binary systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:19:57 GMT""}]","2021-02-10"
"2102.04760","Sahand Sharifzadeh","Sahand Sharifzadeh, Sina Moayed Baharlou, Martin Schmitt, Hinrich
  Sch\""utze, Volker Tresp","Improving Scene Graph Classification by Exploiting Knowledge from Texts",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training scene graph classification models requires a large amount of
annotated image data. Meanwhile, scene graphs represent relational knowledge
that can be modeled with symbolic data from texts or knowledge graphs. While
image annotation demands extensive labor, collecting textual descriptions of
natural scenes requires less effort. In this work, we investigate whether
textual scene descriptions can substitute for annotated image data. To this
end, we employ a scene graph classification framework that is trained not only
from annotated images but also from symbolic data. In our architecture, the
symbolic entities are first mapped to their correspondent image-grounded
representations and then fed into the relational reasoning pipeline. Even
though a structured form of knowledge, such as the form in knowledge graphs, is
not always available, we can generate it from unstructured texts using a
transformer-based language model. We show that by fine-tuning the
classification pipeline with the extracted knowledge from texts, we can achieve
~8x more accurate results in scene graph classification, ~3x in object
classification, and ~1.5x in predicate classification, compared to the
supervised baselines with only 1% of the annotated images.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:21:44 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 13:11:16 GMT""}]","2021-10-11"
"2102.04761","Tao Lin","Tao Lin, Sai Praneeth Karimireddy, Sebastian U. Stich, Martin Jaggi","Quasi-Global Momentum: Accelerating Decentralized Deep Learning on
  Heterogeneous Data",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Decentralized training of deep learning models is a key element for enabling
data privacy and on-device learning over networks. In realistic learning
scenarios, the presence of heterogeneity across different clients' local
datasets poses an optimization challenge and may severely deteriorate the
generalization performance. In this paper, we investigate and identify the
limitation of several decentralized optimization algorithms for different
degrees of data heterogeneity. We propose a novel momentum-based method to
mitigate this decentralized training difficulty. We show in extensive empirical
experiments on various CV/NLP datasets (CIFAR-10, ImageNet, and AG News) and
several network topologies (Ring and Social Network) that our method is much
more robust to the heterogeneity of clients' data than other existing methods,
by a significant improvement in test performance ($1\% \!-\! 20\%$). Our code
is publicly available.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:27:14 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 14:11:08 GMT""}]","2021-06-21"
"2102.04762","Linwei Ye","Linwei Ye, Mrigank Rochan, Zhi Liu, Xiaoqin Zhang and Yang Wang","Referring Segmentation in Images and Videos with Cross-Modal
  Self-Attention Network","14 pages, 8 figures. arXiv admin note: substantial text overlap with
  arXiv:1904.04745",,"10.1109/TPAMI.2021.3054384",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of referring segmentation in images and videos with
natural language. Given an input image (or video) and a referring expression,
the goal is to segment the entity referred by the expression in the image or
video. In this paper, we propose a cross-modal self-attention (CMSA) module to
utilize fine details of individual words and the input image or video, which
effectively captures the long-range dependencies between linguistic and visual
features. Our model can adaptively focus on informative words in the referring
expression and important regions in the visual input. We further propose a
gated multi-level fusion (GMLF) module to selectively integrate self-attentive
cross-modal features corresponding to different levels of visual features. This
module controls the feature fusion of information flow of features at different
levels with high-level and low-level semantic information related to different
attentive words. Besides, we introduce cross-frame self-attention (CFSA) module
to effectively integrate temporal information in consecutive frames which
extends our method in the case of referring segmentation in videos. Experiments
on benchmark datasets of four referring image datasets and two actor and action
video segmentation datasets consistently demonstrate that our proposed approach
outperforms existing state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:27:59 GMT""}]","2021-02-10"
"2102.04763","Lukas Daniel Klausner","Djordje Slijep\v{c}evi\'c, Maximilian Henzl, Lukas Daniel Klausner,
  Tobias Dam, Peter Kieseberg, Matthias Zeppelzauer","$k$-Anonymity in Practice: How Generalisation and Suppression Affect
  Machine Learning Classifiers","48 pages, 38 figures","Comput. Secur. 111, 2021","10.1016/j.cose.2021.102488",,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The protection of private information is a crucial issue in data-driven
research and business contexts. Typically, techniques like anonymisation or
(selective) deletion are introduced in order to allow data sharing, e. g. in
the case of collaborative research endeavours. For use with anonymisation
techniques, the $k$-anonymity criterion is one of the most popular, with
numerous scientific publications on different algorithms and metrics.
Anonymisation techniques often require changing the data and thus necessarily
affect the results of machine learning models trained on the underlying data.
In this work, we conduct a systematic comparison and detailed investigation
into the effects of different $k$-anonymisation algorithms on the results of
machine learning models. We investigate a set of popular $k$-anonymisation
algorithms with different classifiers and evaluate them on different real-world
datasets. Our systematic evaluation shows that with an increasingly strong
$k$-anonymity constraint, the classification performance generally degrades,
but to varying degrees and strongly depending on the dataset and anonymisation
method. Furthermore, Mondrian can be considered as the method with the most
appealing properties for subsequent classification.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:28:20 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 07:13:36 GMT""}]","2022-06-23"
"2102.04764","Cagatay Yildiz","\c{C}a\u{g}atay Y{\i}ld{\i}z, Markus Heinonen, and Harri
  L\""ahdesm\""aki","Continuous-Time Model-Based Reinforcement Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-based reinforcement learning (MBRL) approaches rely on discrete-time
state transition models whereas physical systems and the vast majority of
control tasks operate in continuous-time. To avoid time-discretization
approximation of the underlying process, we propose a continuous-time MBRL
framework based on a novel actor-critic method. Our approach also infers the
unknown state evolution differentials with Bayesian neural ordinary
differential equations (ODE) to account for epistemic uncertainty. We implement
and test our method on a new ODE-RL suite that explicitly solves
continuous-time control systems. Our experiments illustrate that the model is
robust against irregular and noisy data, is sample-efficient, and can solve
control problems which pose challenges to discrete-time MBRL methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:30:19 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 08:46:17 GMT""},{""version"":""v3"",""created"":""Fri, 11 Jun 2021 07:21:29 GMT""}]","2021-06-14"
"2102.04765","Xianghui Zhong","Xianghui Zhong","Lower Bounds on the Integraliy Ratio of the Subtour LP for the Traveling
  Salesman Problem",,,,,"cs.DM cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we investigate instances with high integrality ratio of the
subtour LP. We develop a procedure to generate families of Euclidean TSP
instances whose integrality ratios converge to $\frac{4}{3}$ and may have a
different structure than the instances currently known from the literature.
Moreover, we compute the instances maximizing the integrality ratio for
Rectilinear TSP with up to 10 vertices. Based on these instances we give
families of instances whose integrality ratio converge to $\frac{4}{3}$ for
Rectilinear, Multidimensional Rectilinear and Euclidean TSP that have similar
structures. We show that our instances for Multidimensional Rectilinear TSP and
the known instances for Metric TSP maximize the integrality ratio under certain
assumptions. We also investigate the concept of local optimality with respect
to integrality ratio and develop several algorithms to find instances with high
integrality ratio. Furthermore, we describe a family of instances that are hard
to solve in practice. The currently fastest TSP solver Concorde needs more than
two days to solve an instance from the family with 52 vertices.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:30:39 GMT""}]","2021-02-10"
"2102.04766","Erika Michela Dematteis","Erika Michela Dematteis, Nicola Berti, Fermin Cuevas, Michel Latroche,
  and Marcello Baricco","Substitutional effects in TiFe for hydrogen storage: a comprehensive
  review","76 pages, 7 Figures, 5 Tables",,"10.1039/D1MA00101A",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The search for suitable materials for solid-state stationary storage of green
hydrogen is pushing the implementation of efficient renewable energy systems.
This involves rational design and modification of cheap alloys for effective
storage in mild conditions of temperature and pressure. Among many
intermetallic compounds described in the literature, TiFe-based systems have
recently regained vivid interest as materials for practical applications since
they are low-cost and they can be tuned to match required pressure and
operation conditions. This work aims to provide a comprehensive review of
publications involving chemical substitution in TiFe-based compounds for
guiding compound design and materials selection in current and future hydrogen
storage applications. Mono- and multi-substituted compounds modify TiFe
thermodynamics and are beneficial for many hydrogenation properties. They will
be reviewed and deeply discussed, with a focus on manganese substitution.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:30:59 GMT""}]","2021-04-23"
"2102.04767","Takuya Tsuchiya","Hiroki Ishizaka, Kenta Kobayashi, Ryo Suzuki, Takuya Tsuchiya","A new geometric condition equivalent to the maximum angle condition for
  tetrahedrons","to appear in Computers & Mathematics with Applications","Computers & Mathematics with Applications, 99 (2021) 323-328","10.1016/j.camwa.2021.08.017",,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For a tetrahedron, suppose that all internal angles of faces and all dihedral
angles are less than a fixed constant $C$ that is smaller than $\pi$. Then, it
is said to satisfy the maximum angle condition with the constant $C$. The
maximum angle condition is important in the error analysis of Lagrange
interpolation on tetrahedrons. This condition ensures that we can obtain an
error estimation, even on certain kinds of anisotropic tetrahedrons. In this
paper, using two quantities that represent the geometry of tetrahedrons, we
present an equivalent geometric condition to the maximum angle condition for
tetrahedrons.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:33:44 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 10:39:46 GMT""}]","2021-09-06"
"2102.04768","Satoshi Yamaguchi","Satoshi Yamaguchi","Supersymmetric quantum field theory with exotic symmetry in 3+1
  dimensions and fermionic fracton phases","16 pages, no figures. v2: typos corrected, references added. v3:typos
  corrected, comments added",,,"OU-HET 1090","hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a supersymmetric quantum field theory with exotic symmetry related
to fracton phases. We use superfield formalism and write down the action of a
supersymmetric version of the $\varphi$ theory in 3+1 dimensions. It contains a
large number of ground states due to the fermionic higher pole subsystem
symmetry. Its residual entropy is proportional to the area instead of the
volume. This theory has a self-duality similar to that of the $\varphi$ theory.
We also write down the action of a supersymmetric version of a tensor gauge
theory, and discuss BPS fractons.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:37:29 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 06:58:39 GMT""},{""version"":""v3"",""created"":""Fri, 19 Mar 2021 03:37:59 GMT""}]","2021-03-22"
"2102.04769","Bingkai Lin","Bingkai Lin","Constant Approximating k-Clique is W[1]-hard",,,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For every graph $G$, let $\omega(G)$ be the largest size of complete subgraph
in $G$. This paper presents a simple algorithm which, on input a graph $G$, a
positive integer $k$ and a small constant $\epsilon>0$, outputs a graph $G'$
and an integer $k'$ in $2^{\Theta(k^5)}\cdot |G|^{O(1)}$-time such that (1)
$k'\le 2^{\Theta(k^5)}$, (2) if $\omega(G)\ge k$, then $\omega(G')\ge k'$, (3)
if $\omega(G)<k$, then $\omega(G')< (1-\epsilon)k'$. This implies that no
$f(k)\cdot |G|^{O(1)}$-time algorithm can distinguish between the cases
$\omega(G)\ge k$ and $\omega(G)<k/c$ for any constant $c\ge 1$ and computable
function $f$, unless $FPT= W[1]$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:38:43 GMT""}]","2021-02-10"
"2102.04770","Konstantin Kutzkov","Konstantin Kutzkov","COLOGNE: Coordinated Local Graph Neighborhood Sampling",,,,,"cs.LG cs.AI cs.DS","http://creativecommons.org/licenses/by/4.0/","  Representation learning for graphs enables the application of standard
machine learning algorithms and data analysis tools to graph data. Replacing
discrete unordered objects such as graph nodes by real-valued vectors is at the
heart of many approaches to learning from graph data. Such vector
representations, or embeddings, capture the discrete relationships in the
original data by representing nodes as vectors in a high-dimensional space.
  In most applications graphs model the relationship between real-life objects
and often nodes contain valuable meta-information about the original objects.
While being a powerful machine learning tool, embeddings are not able to
preserve such node attributes. We address this shortcoming and consider the
problem of learning discrete node embeddings such that the coordinates of the
node vector representations are graph nodes. This opens the door to designing
interpretable machine learning algorithms for graphs as all attributes
originally present in the nodes are preserved.
  We present a framework for coordinated local graph neighborhood sampling
(COLOGNE) such that each node is represented by a fixed number of graph nodes,
together with their attributes. Individual samples are coordinated and they
preserve the similarity between node neighborhoods. We consider different
notions of similarity for which we design scalable algorithms. We show
theoretical results for all proposed algorithms. Experiments on benchmark
graphs evaluate the quality of the designed embeddings and demonstrate how the
proposed embeddings can be used in training interpretable machine learning
algorithms for graph data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:39:06 GMT""}]","2021-02-10"
"2102.04771","Florimond Gueniat","Florimond Gueniat and Sahdia Maryam","Forecasting the Evolution of Hydrogen Vehicle Fleet in the UK
  usingGrowth and Lotka-Volterra Models",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Road vehicles play an important role in the UK's energy systems and are a
critical component in reducing the reliance on fossil fuels and mitigating
emissions. A dynamic model of vehicle fleet, based on predator-prey concepts,
is presented. It allows to predict the evolution of the hydrogen based
vehicle's role in the UK's vehicle fleet and the sensitivity of this growth to
the supply chain. In addition to this, this model is used to predict the demand
of hydrogen for the passenger vehicle fleet for various scenarios. A key result
is that the amount of hydrogen required to support a huge network of hydrogen
based vehicles is currently not practical, regarding the infrastructure
required and the cost to build such an infrastructure. In order to mitigate
that, the policy focus should move primarily from hydrogen based vehicles to
first encompass range extenders in the transport energy system.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:41:15 GMT""}]","2021-02-10"
"2102.04772","Joanna Barstow (Eberhardt) Dr","Joanna K. Barstow","The curse of clouds","Invited review article for Astronomy & Geophysics, author's own
  version. Version of record:
  https://academic.oup.com/astrogeo/article/62/1/1.36/6102751","Astronomy & Geophysics, Volume 62, Issue 1, February 2021, Pages
  1.36 - 1.42","10.1093/astrogeo/atab044",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, a vast increase in spectroscopic observations of transiting
exoplanets has for the first time allowed us to search for broad trends in
their atmospheric properties. Analysis of these observations has revealed that,
even for the highly irradiated hot Jupiters, aerosol is a common presence and
must be accounted for in modelling efforts. An additional challenge for hot
Jupiters is the large variation in temperature across the planet, which is
likely to result in partial or patchy cloud cover. As our observational
capability is due to increase further with the launch of the James Webb Space
Telescope, anticipated in autumn 2021, community efforts are underway to
prepare modelling and analysis tools capable of recovering information about
variable and patchy cloud coverage on hot exoplanets
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:42:40 GMT""}]","2021-02-10"
"2102.04773","Floriane Cangemi","F. Cangemi, T. Beuchert, T. Siegert, J. Rodriguez, V. Grinberg, R.
  Belmont, C. Gouiff\`es, I. Kreykenbohm, P. Laurent, K. Pottschmidt, J. Wilms","Potential origin of the state-dependent high-energy tail in the black
  hole microquasar Cygnus X-1 as seen with INTEGRAL","14 pages, 8 figures. Accepted for a publication in A&A",,"10.1051/0004-6361/202038604",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  0.1-10 MeV observations of the black hole microquasar Cygnus X-1 have shown
the presence of a spectral feature in the form of a power law in addition to
the standard black body and Comptonization components observed by INTEGRAL.
This so-called ""high-energy tail"" has recently been shown to be strong in its
hard spectral state and interpreted as high-energy part of the emission from a
compact jet. This result was, however, obtained from a data set dominated by
hard state observations. In the soft state, only upper limits on the presence
and hence the potential parameters of a high-energy tail could be derived.
Using an extended data set we aim at obtaining better constraints on the
properties of this spectral component in both states. We make use of data
obtained from 15 years of observations with the INTEGRAL satellite. The data
set is separated into the different states and we analyse stacked
state-resolved spectra obtained from the X-ray monitors, the gamma-ray imager,
and the gamma-ray spectrometer onboard. A high-energy component is detected in
both states confirming its earlier detection in the hard state and its
suspected presence in the soft state with INTEGRAL. We first characterize the
high-energy tail components in the two states through a model-independent,
phenomenological analysis. We then apply physical models based on hybrid
Comptonization. The spectra are well modeled in all cases, with a similar
goodness of the fits. While in the phenomenological approach the high-enery
tail has similar indices in both states, the fits with the physical models seem
to indicate different properties. We discuss the potential origins of the
high-energy components in both states, and favor an interpretation where the
part of the high-energy component is due to a compact jet in the hard state and
hybrid Comptonization in either a magnetised or non-magnetised corona in the
soft state.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:44:25 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 15:09:38 GMT""},{""version"":""v3"",""created"":""Fri, 9 Apr 2021 13:32:31 GMT""}]","2021-06-23"
"2102.04774","Guram Adamashvili","G. T. Adamashvili","Two-component nonlinear wave of the Hirota equation",,,,,"cond-mat.mes-hall nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the generalized perturbation reduction method the Hirota equation is
transformed to the coupled nonlinear Schr\""odinger equations for auxiliary
functions. A solution in the form of a two-component vector nonlinear pulse is
obtained. The components of the pulse oscillate with the sum and difference of
the frequencies and the wave numbers. Explicit analytical expressions for the
shape and parameters of the two-component nonlinear pulse are presented.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:45:44 GMT""}]","2021-02-10"
"2102.04775","Wenhao Li","Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Yun Hua and Hongyuan
  Zha","Structured Diversification Emergence via Reinforced Organization Control
  and Hierarchical Consensus Learning","AAMAS 2021 camera-ready",,,,"cs.LG cs.AI cs.GT cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When solving a complex task, humans will spontaneously form teams and to
complete different parts of the whole task, respectively. Meanwhile, the
cooperation between teammates will improve efficiency. However, for current
cooperative MARL methods, the cooperation team is constructed through either
heuristics or end-to-end blackbox optimization. In order to improve the
efficiency of cooperation and exploration, we propose a structured
diversification emergence MARL framework named {\sc{Rochico}} based on
reinforced organization control and hierarchical consensus learning.
{\sc{Rochico}} first learns an adaptive grouping policy through the
organization control module, which is established by independent multi-agent
reinforcement learning. Further, the hierarchical consensus module based on the
hierarchical intentions with consensus constraint is introduced after team
formation. Simultaneously, utilizing the hierarchical consensus module and a
self-supervised intrinsic reward enhanced decision module, the proposed
cooperative MARL algorithm {\sc{Rochico}} can output the final diversified
multi-agent cooperative policy. All three modules are organically combined to
promote the structured diversification emergence. Comparative experiments on
four large-scale cooperation tasks show that {\sc{Rochico}} is significantly
better than the current SOTA algorithms in terms of exploration efficiency and
cooperation strength.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:46:12 GMT""}]","2021-02-10"
"2102.04776","Emilien Dupont","Emilien Dupont, Yee Whye Teh, Arnaud Doucet","Generative Models as Distributions of Functions","AISTATS 2022 Oral camera ready. Incorporated reviewer feedback",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative models are typically trained on grid-like data such as images. As
a result, the size of these models usually scales directly with the underlying
grid resolution. In this paper, we abandon discretized grids and instead
parameterize individual data points by continuous functions. We then build
generative models by learning distributions over such functions. By treating
data points as functions, we can abstract away from the specific type of data
we train on and construct models that are agnostic to discretization. To train
our model, we use an adversarial approach with a discriminator that acts on
continuous signals. Through experiments on a wide variety of data modalities
including images, 3D shapes and climate data, we demonstrate that our model can
learn rich distributions of functions independently of data type and
resolution.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:47:55 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 18:04:08 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 10:48:57 GMT""},{""version"":""v4"",""created"":""Thu, 17 Feb 2022 16:18:12 GMT""}]","2022-02-18"
"2102.04777","Daniel Karrasch","Daniel Karrasch, Nathanael Schilling","A Lagrangian perspective on nonautonomous advection-diffusion processes
  in the low-diffusivity limit","38 pages, submitted",,,,"math.AP math-ph math.DG math.DS math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study mass preserving transport of passive tracers in the low-diffusivity
limit using Lagrangian coordinates. Over finite-time intervals, the
solution-operator of the nonautonomous diffusion equation is approximated by
that of a time-averaged diffusion equation. We show that leading order
asymptotics that hold for functions [Krol, 1991] extend to the dominant
nontrivial singular value. This answers questions raised in [Karrasch & Keller,
2020]. The generator of the time-averaged diffusion/heat semigroup is a Laplace
operator associated to a weighted manifold structure on the material manifold.
We show how geometrical properties of this weighted manifold directly lead to
physical transport quantities of the nonautonomous equation in the
low-diffusivity limit.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:50:13 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 10:26:37 GMT""}]","2021-03-22"
"2102.04778","Robert Hughes","Robert R. Hughes and Bruce W. Drinkwater","Exploring high-frequency eddy-current testing for sub-aperture defect
  characterisation using parametric-manifold mapping","14 pages, 8 figures, research paper",,"10.1016/j.ndteint.2021.102534",,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Accurate characterisation of small defects remains a challenge in
non-destructive testing (NDT). In this paper, a principle-component
parametric-manifold mapping approach is applied to single-frequency
eddy-current defect characterisation problems for surface breaking defects in a
planar half-space. A broad 1-8 MHz frequency-range FE-circuit model &
calibration approach is developed & validated to simulate eddy-current scans of
surface-breaking notch defects. This model is used to generate parametric
defect databases for surface breaking defects in an aluminium planar half-space
and defect characterisation of experimental measurements performed.
Parametric-manifold mapping was conducted in N-dimensional principle component
space, reducing the dimensionality of the characterisation problem. In a study
characterising slot depth, the model & characterisation approach is shown to
accurately invert the depth with greater accuracy than a simple amplitude
inversion method with normalised percentage characterisation errors of 38% and
17% respectively measured at 2.0 MHz across 5 slot depths between 0.26 - 2.15
mm. The approach is used to characterise the depth of a sloped slot
demonstrating good accuracy up to ~2.0 mm in depth over a broad range of
sub-resonance frequencies, indicating applications in geometric feature
inversion. Finally the technique is applied to finite rectangular notch defects
of surface extents smaller than the diameter of the inspection coil
(sub-aperture) over a range of frequencies. The results highlight the
limitations in characterising these defects and indicate how the inherent
instabilities in resonance can severely limit characterisation at these
frequencies.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:51:51 GMT""}]","2021-10-27"
"2102.04779","Andreas Koehn","Jan Schnabel, Tobias Kampschulte, Simon Rupp, Johannes Hecker
  Denschlag, Andreas K\""ohn","Towards photoassociation processes of ultracold rubidium trimers","15 pages, 8 figures, 3 tables; supporting info and underlying data as
  supplemental files",,"10.1103/PhysRevA.103.022820",,"physics.chem-ph cond-mat.quant-gas physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate the prospects for photoassociation (PA) of
Rb$_3$, in particular at close range. We provide an overview of accessible
states and possible transitions. The major focus is placed on the calculation
of equilibrium structures, the survey of spin-orbit effects and the
investigation of transition dipole moments. Furthermore we discuss
Franck-Condon overlaps and special aspects of trimers including the (pseudo)
Jahn-Teller effect and the resulting topology of adiabatic potential-energy
surfaces. With this we identify concrete and suitable PA transitions to
potentially produce long-lived trimer bound states. Calculations are performed
using the multireference configuration-interaction method together with a
large-core effective core potential and a core-polarization potential with a
large uncontracted even-tempered basis set.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:52:42 GMT""}]","2021-02-24"
"2102.04780","Sutharsan Mahendren Mr","Sutharsan Mahendren, Chamira Edussooriya, Ranga Rodrigo","Diverse Single Image Generation with Controllable Global Structure","Published in the Neurocomputing Journal","Neurocomputing 528(2023)97-112","10.1016/j.neucom.2023.01.011",,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image generation from a single image using generative adversarial networks is
quite interesting due to the realism of generated images. However, recent
approaches need improvement for such realistic and diverse image generation,
when the global context of the image is important such as in face, animal, and
architectural image generation. This is mainly due to the use of fewer
convolutional layers for mainly capturing the patch statistics and, thereby,
not being able to capture global statistics very well. We solve this problem by
using attention blocks at selected scales and feeding a random Gaussian blurred
image to the discriminator for training. Our results are visually better than
the state-of-the-art particularly in generating images that require global
context. The diversity of our image generation, measured using the average
standard deviation of pixels, is also better.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:52:48 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 05:22:34 GMT""},{""version"":""v3"",""created"":""Thu, 20 Jan 2022 05:25:10 GMT""},{""version"":""v4"",""created"":""Wed, 25 Jan 2023 13:10:39 GMT""}]","2023-01-26"
"2102.04781","Vania Bogorny","Tarlis Portela, Jonata Tyska, Vania Bogorny","Fast discovery of multidimensional subsequences for robust trajectory
  classification",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trajectory classification tasks became more complex as large volumes of
mobility data are being generated every day and enriched with new sources of
information, such as social networks and IoT sensors. Fast classification
algorithms are essential for discovering knowledge in trajectory data for real
applications. In this work we propose a method for fast discovery of
subtrajectories with the reduction of the search space and the optimization of
the MASTERMovelets method, which has proven to be effective for discovering
interpretable patterns in classification problems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:54:33 GMT""}]","2021-02-10"
"2102.04782","Kang Zhao","Kang Zhao, Sida Huang, Pan Pan, Yinghan Li, Yingya Zhang, Zhenyu Gu,
  Yinghui Xu","Distribution Adaptive INT8 Quantization for Training CNNs","This paper has been accepted by AAAI 2021",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researches have demonstrated that low bit-width (e.g., INT8) quantization can
be employed to accelerate the inference process. It makes the gradient
quantization very promising since the backward propagation requires
approximately twice more computation than forward one. Due to the variability
and uncertainty of gradient distribution, a lot of methods have been proposed
to attain training stability. However, most of them ignore the channel-wise
gradient distributions and the impact of gradients with different magnitudes,
resulting in the degradation of final accuracy. In this paper, we propose a
novel INT8 quantization training framework for convolutional neural network to
address the above issues. Specifically, we adopt Gradient Vectorized
Quantization to quantize the gradient, based on the observation that layer-wise
gradients contain multiple distributions along the channel dimension. Then,
Magnitude-aware Clipping Strategy is introduced by taking the magnitudes of
gradients into consideration when minimizing the quantization error, and we
present a theoretical derivation to solve the quantization parameters of
different distributions. Experimental results on broad range of computer vision
tasks, such as image classification, object detection and video classification,
demonstrate that the proposed Distribution Adaptive INT8 Quantization training
method has achieved almost lossless training accuracy for different backbones,
including ResNet, MobileNetV2, InceptionV3, VGG and AlexNet, which is superior
to the state-of-the-art techniques. Moreover, we further implement the INT8
kernel that can accelerate the training iteration more than 200% under the
latest Turing architecture, i.e., our method excels on both training accuracy
and speed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:58:10 GMT""}]","2021-02-10"
"2102.04783","Ieng-Wai Un","Ieng Wai Un and Yonatan Sivan","The role of heat generation and fluid flow in plasmon-enhanced
  reduction-oxidation reactions",,,"10.1021/acsphotonics.1c00113",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, we have shown that thermal effects play a crucial role in speeding
up the rate of bond-dissociation reactions. This was done by applying a simple
temperature-shifted Arrhenius Law to the experimental data, corroborated with
detailed account of the heat diffusion occurring within the relevant samples
and identification of errors in the temperature measurements. Here, we provide
three important extensions of our previous studies. First, we analyze thermal
effects in reduction-oxidation (redox) reactions, where charge transfer is an
integral part of the reaction. Second, we analyze not only the spatial
distribution of the temperature, but also its temporal dynamics. Third, we also
model the fluid convection and stirring. An analysis of two exemplary
experimental studies allows us to show that thermal effects can explain the
experimental data in one of experiments (Baumberg and coworkers), but not in
the other (Jain and coworkers), showing that redox reactions are not
necessarily driven by non-thermal charge carriers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:59:56 GMT""}]","2023-03-31"
"2102.04784","Abdellah Laaroussi","Wolfram Bauer, Abdellah Laaroussi","Trivializable and quaternionic subriemannian structure on $\mathbb{S}^7$
  and subelliptic heat kernel",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On the seven dimensional Euclidean sphere $\mathbb{S}^7$ we compare two
subriemannian structures with regards to various geometric and analytical
properties. The first structure is called trivializable and the underlying
distribution $\mathcal{H}_T$ is induced by a Clifford module structure of
$\mathbb{R}^8$. More precisely, $\mathcal{H}_T$ is rank $4$, bracket generating
of step two and generated by globally defined vector fields. The distribution
$\mathcal{H}_{Q}$ of the second structure is of rank 4 and step two as well and
obtained as the horizontal distribution in the quaternionic Hopf fibration
$\mathbb{S}^3\hookrightarrow\mathbb{S}^7\rightarrow\mathbb{S}^4$. Answering a
question in arXiv:0901.1406 we first show that $\mathcal{H}_{Q}$ does not admit
a global nowhere vanishing smooth section. In both cases we determine the Popp
measures, the intrinsic sublaplacians $\Delta_{sub}^T$ and $\Delta_{sub}^{Q}$
and the nilpotent approximations. We conclude that both subriemannian
structures are not locally isometric and we discuss properties of the isometry
group. By determining the first heat invariant of the sublaplacians it is shown
that both structures are also not isospectral in the subriemannian sense.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:02:29 GMT""}]","2021-02-10"
"2102.04785","Michael Nicklas","M. O. Ajeesh, Thomas Gruner, Christoph Geibel and Michael Nicklas","Possible Pressure-Induced Charge-Density Wave Quantum Critical Point in
  LuPd2In","2 figures","J. Phys. Soc. Jpn. 90, 035001 (2021)","10.7566/JPSJ.90.035001",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the effect of application of hydrostatic pressure on the
charge-density wave (CDW) state in Lu(Pt$_{1-x}$Pd$_x$)$_2$In by
electrical-resistivity measurements. In Lu(Pt$_{0.7}$Pd$_{0.3}$)$_{2}$In we
find an increase of the CDW transition temperature upon application of
pressure, which is not expected based on simple volume arguments, but in line
with results of a theoretical work by Kim et al. [Phys. Rev. Lett. 125, 157001
(2020).]. Combining experimental and theoretical results suggests the existence
of a CDW quantum critical point in stoichiometric LuPd$_2$In around
$p\approx20$ GPa.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:02:33 GMT""}]","2021-02-10"
"2102.04786","Jaka Cimpric","Jaka Cimpri\v{c}","Prime and semiprime submodules of $R^n$ and a related Nullstellensatz
  for $M_n(R)$","11 pages",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  Let $R$ be a commutative ring with $1$ and $n$ a natural number. We say that
a submodule $N$ of $R^n$ is semiprime if for every $f=(f_1,\ldots,f_n) \in R^n$
such that $f_i f \in N$ for $i=1,\ldots,n$ we have $f \in N$. Our main result
is that every semiprime submodule of $R^n$ is equal to the intersection of all
prime submodules containing it. It follows that every semiprime left ideal of
$M_n(R)$ is equal to the intersection of all prime left ideals that contain it.
For $R=k[x_1,\ldots,x_d]$ where $k$ is an algebraically closed field we can
rephrase this result as a Nullstellensatz for $M_n(R)$: For every
$G_1,\ldots,G_m,F \in M_n(R)$, $F$ belongs to the smallest semiprime left ideal
of $M_n(R)$ that contains $G_1,\ldots,G_m$ iff for every $a \in k^d$ and $v \in
k^n$ such that $G_1(a)v=\ldots=G_m(a)v=0$ we have $F(a)v=0$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:03:17 GMT""}]","2021-02-10"
"2102.04787","Sam Sanders","Dag Normann and Sam Sanders","On robust theorems due to Bolzano, Weierstrass, Cantor, and Jordan","44 pages + technical appendix, to appear in Journal of Symbolic Logic",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reverse Mathematics (RM hereafter) is a program in the foundations of
mathematics where the aim is to identify the minimal axioms needed to prove a
given theorem from ordinary, i.e. non-set theoretic, mathematics. This program
has unveiled surprising regularities: the minimal axioms are very often
equivalent to the theorem over the base theory, a weak system of 'computable
mathematics', while most theorems are either provable in this base theory, or
equivalent to one of only four logical systems. The latter plus the base theory
are called the 'Big Five' and the associated equivalences are robust following
Montalban, i.e. stable under small variations of the theorems at hand. Working
in Kohlenbach's higher-order RM, we obtain two long series of equivalences
based on theorems due to Bolzano, Weierstrass, Jordan, and Cantor; these
equivalences are extremely robust and have no counterpart among the Big Five
systems, as they are strictly between the base theory and the higher-order
counterpart of weak Koenig's lemma. Thus, higher-order RM is much richer than
its second-order cousin, boasting (at least) two extra 'Big' systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:03:28 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 19:17:48 GMT""},{""version"":""v3"",""created"":""Wed, 20 Apr 2022 20:58:52 GMT""},{""version"":""v4"",""created"":""Mon, 9 May 2022 17:41:01 GMT""},{""version"":""v5"",""created"":""Wed, 28 Sep 2022 18:51:02 GMT""}]","2022-09-30"
"2102.04788","Stratos Pateloudis","Fabio M. Mele, Johannes M\""unch, Stratos Pateloudis","Quantum Corrected Polymer Black Hole Thermodynamics: Mass Relations and
  Logarithmic Entropy Correction","Published version, 33 pages, 7 figures. References and minor
  clarifications added","JCAP02(2022)011","10.1088/1475-7516/2022/02/011",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we continue the analysis of the effective model of quantum
Schwarzschild black holes recently proposed by some of the authors in [1,2]. In
the resulting spacetime the central singularity is resolved by a black-to-white
hole bounce, quantum effects become relevant at a unique mass independent
curvature scale, while they become negligible in the low curvature region near
the horizon and classical geometry is approached asymptotically. This is the
case independently of the relation between the black and white hole masses,
which are thus freely specifiable independent observables. A natural question
then arises about the phenomenological implications of the resulting
non-singular effective spacetime and whether some specific relation between the
masses can be singled out from a phenomenological perspective. Here we focus on
the thermodynamic properties of the effective polymer black hole and analyse
the corresponding quantum corrections as functions of black and white hole
masses. The study of the relevant thermodynamic quantities such as temperature,
specific heat and horizon entropy reveals that the effective spacetime
generically admits an extremal minimal-sized configuration of
quantum-gravitational nature characterised by vanishing temperature and
entropy. For large masses, the classically expected results are recovered at
leading order and quantum corrections are negligible, thus providing us with a
further consistency check of the model. The explicit form of the corrections
depends on the specific relation among the masses. In particular, a first-order
logarithmic correction to the entropy is obtained for a quadratic mass
relation. The latter corresponds to the case of proper finite length effects
which turn out to be compatible with a minimal length generalised uncertainty
principle associated with an extremal Planck-sized black hole.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:04:45 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 07:44:18 GMT""}]","2022-02-28"
"2102.04789","Najko Jahn","Najko Jahn, Lisa Matthias, Mikael Laakso","Transparency to hybrid open access through publisher-provided metadata:
  An article-level study of Elsevier","31 pages, 8 figures, 7 tables, preprint",,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  With the growth of open access (OA), the financial flows in scholarly journal
publishing have become increasingly complex, but comprehensive data and
transparency into these flows are still lacking. The opaqueness is especially
concerning for hybrid OA, where subscription-based journals publish individual
articles as OA if an optional fee is paid. This study addresses the lack of
transparency by leveraging Elsevier article metadata and provides the first
publisher-level study of hybrid OA uptake and invoicing. Our results show that
Elsevier's hybrid OA uptake has grown steadily but slowly from 2015-2019,
doubling the number of hybrid OA articles published per year and increasing the
share of OA articles in Elsevier's hybrid journals from 2.6% to 3.7% of all
articles. Further, we find that most hybrid OA articles were invoiced directly
to authors, followed by articles invoiced through agreements with research
funders, institutions, or consortia, with only a few funding bodies driving
hybrid OA uptake. As such, our findings point to the role of publishing
agreements and OA policies in hybrid OA publishing. Our results further
demonstrate the value of publisher-provided metadata to improve the
transparency in scholarly publishing by linking invoicing data to
bibliometrics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:05:13 GMT""}]","2021-02-10"
"2102.04790","The CMS Collaboration","CMS Collaboration","Performance of the CMS muon trigger system in proton-proton collisions
  at $\sqrt{s} =$ 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/MUO-19-001
  (CMS Public Pages)","JINST 16 (2021) P07001","10.1088/1748-0221/16/07/P07001","CMS-MUO-19-001, CERN-EP-2021-013","hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The muon trigger system of the CMS experiment uses a combination of hardware
and software to identify events containing a muon. During Run 2 (covering
2015-2018) the LHC achieved instantaneous luminosities as high as 2 $\times$
10$^{34}$cm$^{-2}$s$^{-1}$ while delivering proton-proton collisions at
$\sqrt{s} =$ 13 TeV. The challenge for the trigger system of the CMS experiment
is to reduce the registered event rate from about 40 MHz to about 1 kHz.
Significant improvements important for the success of the CMS physics program
have been made to the muon trigger system via improved muon reconstruction and
identification algorithms since the end of Run 1 and throughout the Run 2
data-taking period. The new algorithms maintain the acceptance of the muon
triggers at the same or even lower rate throughout the data-taking period
despite the increasing number of additional proton-proton interactions in each
LHC bunch crossing. In this paper, the algorithms used in 2015 and 2016 and
their improvements throughout 2017 and 2018 are described. Measurements of the
CMS muon trigger performance for this data-taking period are presented,
including efficiencies, transverse momentum resolution, trigger rates, and the
purity of the selected muon sample. This paper focuses on the single- and
double-muon triggers with the lowest sustainable transverse momentum thresholds
used by CMS. The efficiency is measured in a transverse momentum range from 8
to several hundred GeV.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:12:33 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2021 12:06:24 GMT""}]","2021-07-06"
"2102.04791","Linda Nab","Linda Nab, Maarten van Smeden, Ruth H. Keogh, Rolf H.H. Groenwold","mecor: An R package for measurement error correction in linear
  regression models with a continuous outcome","34 pages (including appendix), software package",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Measurement error in a covariate or the outcome of regression models is
common, but is often ignored, even though measurement error can lead to
substantial bias in the estimated covariate-outcome association. While several
texts on measurement error correction methods are available, these methods
remain seldomly applied. To improve the use of measurement error correction
methodology, we developed mecor, an R package that implements measurement error
correction methods for regression models with continuous outcomes. Measurement
error correction requires information about the measurement error model and its
parameters. This information can be obtained from four types of studies, used
to estimate the parameters of the measurement error model: an internal
validation study, a replicates study, a calibration study and an external
validation study. In the package mecor, regression calibration methods and a
maximum likelihood method are implemented to correct for measurement error in a
continuous covariate in regression analyses. Additionally, methods of moments
methods are implemented to correct for measurement error in the continuous
outcome in regression analyses. Variance estimation of the corrected estimators
is provided in closed form and using the bootstrap.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:22:12 GMT""}]","2021-02-10"
"2102.04792","Sylvain Bertaina","M. Orio, J.K. Bindra, J. vanTol, M. Giorgi, N. Dalal, S. Bertaina","Quantum dynamics of Mn$^{2+}$ in dimethylammonium magnesium formate",,"J. Chem. Phys. 154, 154201 (2021)","10.1063/5.0046984",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Dimethylammonium magnesium formate, [(CH$_3$)$_2$NH$_2$][Mg(HCOO)$_3$] or
DMAMgF, is a model to study high temperature hybrid perovskite-like
dielectrics. This compound displays a phase transition from para to
ferroelectric at about 260~K. Using multifrequency electron spin resonance in
continuous wave and pulsed modes, we herein present the quantum dynamic of
Mn$^{2+}$ ion probe in DMAMgF. In the high temperature paraelectric phase, we
observe a large distribution of the zero field splitting that is attributed to
high local disorder and further supported by DFT computations. In the low
temperature ferroelectric phase, a single structure phase is detected and shown
to contain two magnetic structures. The complex EPR signals were identifed by
the means of Rabi oscillation method combined to crystal fields kernel density
estimation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:24:21 GMT""}]","2021-04-23"
"2102.04793","Natan T'Joens","Natan T'Joens, Jasper De Bock","Average Behaviour in Discrete-Time Imprecise Markov Chains: A Study of
  Weak Ergodicity","arXiv admin note: substantial text overlap with arXiv:2002.05661",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the limit behaviour of upper and lower bounds on expected time
averages in imprecise Markov chains; a generalised type of Markov chain where
the local dynamics, traditionally characterised by transition probabilities,
are now represented by sets of `plausible' transition probabilities. Our first
main result is a necessary and sufficient condition under which these upper and
lower bounds, called upper and lower expected time averages, will converge as
time progresses towards infinity to limit values that do not depend on the
process' initial state. Our condition is considerably weaker than that needed
for ergodic behaviour; a similar notion which demands that marginal upper and
lower expectations of functions at a single time instant converge to so-called
limit-or steady state-upper and lower expectations. For this reason, we refer
to our notion as `weak ergodicity'. Our second main result shows that, as far
as this weakly ergodic behaviour is concerned, one should not worry about which
type of independence assumption to adopt-epistemic irrelevance, complete
independence or repetition independence. The characterisation of weak
ergodicity as well as the limit values of upper and lower expected time
averages do not depend on such a choice. Notably, this type of robustness is
not exhibited by the notion of ergodicity and the related inferences of limit
upper and lower expectations. Finally, though limit upper and lower
expectations are often used to provide approximate information about the limit
behaviour of time averages, we show that such an approximation is sub-optimal
and that it can be significantly improved by directly using upper and lower
expected time averages.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:24:42 GMT""}]","2021-02-10"
"2102.04794","Alexander Pchelintsev","Alexander N. Pchelintsev","A Numerical-Analytical Method for Constructing Periodic Solutions of the
  Lorenz System","Differential Equations & Control Processes, 4 (2020), 59-75","https://diffjournal.spbu.ru/EN/numbers/2020.4/article.1.3.html",,"The reported study was funded by RFBR according to the research
  project 20-01-00347","math.NA cs.NA math.DS nlin.CD","http://creativecommons.org/licenses/by/4.0/","  This article describes a method for constructing approximations to periodic
solutions of dynamic Lorenz system with classical values of the system
parameters. The author obtained a system of nonlinear algebraic equations in
general form concerning of the cyclic frequency, constant terms and amplitudes
of harmonics that make up harmonic approximations to the desired solutions. The
initial approximation for the Newton method is selected, which converges to a
solution describing a periodic solution different from the equilibrium
position. The results of a computational experiment are presented. The results
are verified using high-precision calculations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:28:47 GMT""}]","2021-02-10"
"2102.04795","Jie Zhang","Jie Zhang, Menquan Liu, Zhie Liu and Shuzheng Yang","An Improvement for Quantum Tunneling Radiation of Fermions in a
  Stationary Kerr-Newman Black Hole Spacetime",,,"10.1016/j.cjph.2022.08.009",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  By introducing a specific etheric-like vector in the Dirac equation with
Lorentz Invariance Violation (LIV) in the curved spacetime, an improved method
for quantum tunneling radiation of fermions is proposed. As an example, we
apply this new method to a charged axisymmetric Kerr-Newman black hole.
Firstly, considering LIV theory, we derive a modified dynamical equation of
fermion with spin 1/2 in the Kerr-Newman black hole spacetime. Then we solve
the equation and find the increase or decrease of black hole's Hawking
temperature and entropy are related to constants $a$ and $c$ of the Dirac
equation with LIV in the curved spacetime. As $c$ is positive, the new Hawking
temperature is about $ \frac{\sqrt{1+2a+2cmk_r^2}}{\sqrt{1+2a}}$ times higher
than that without modification, but the entropy will decrease. We also make a
brief discussion for the case of high spin fermions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:30:32 GMT""}]","2022-10-12"
"2102.04796","Javier Yuste","Javier Yuste, Sergio Pastrana","Avaddon ransomware: an in-depth analysis and decryption of infected
  systems",,"Computers & Security 109 (2021) 102388","10.1016/j.cose.2021.102388",,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The commoditization of Malware-as-a-Service (MaaS) allows criminals to obtain
financial benefits at a low risk and with little technical background. One such
popular product in the underground economy is ransomware. In ransomware
attacks, data from infected systems is held hostage (encrypted) until a fee is
paid to the criminals. This modus operandi disrupts legitimate businesses,
which may become unavailable until the data is restored. A recent blackmailing
strategy adopted by criminals is to leak data online from the infected systems
if the ransom is not paid. Besides reputational damage, data leakage might
produce further economical losses due to fines imposed by data protection laws.
Thus, research on prevention and recovery measures to mitigate the impact of
such attacks is needed to adapt existing countermeasures to new strains.
  In this work, we perform an in-depth analysis of Avaddon, a ransomware
offered in the underground economy as an affiliate program business. This has
infected and leaked data from at least 23 organizations. Additionally, it runs
Distributed Denial-of-Service (DDoS) attacks against victims that do not pay
the ransom. We first provide an analysis of the criminal business model from
the underground economy. Then, we identify and describe its technical
capabilities. We provide empirical evidence of links between this variant and a
previous family, suggesting that the same group was behind the development and,
possibly, the operation of both campaigns.
  Finally, we describe a method to decrypt files encrypted with Avaddon in real
time. We implement and test the decryptor in a tool that can recover the
encrypted data from an infected system, thus mitigating the damage caused by
the ransomware. The tool is released open-source so it can be incorporated in
existing Antivirus engines.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:31:49 GMT""}]","2021-07-09"
"2102.04797","Vijith Kumar Kizhakke Purakkal","Vijith Kumar K P, Brijesh Kumar Rai, and Tony Jacob","The Exact Rate Memory Tradeoff for Small Caches with Coded Placement","arXiv admin note: substantial text overlap with arXiv:2101.09785",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The idea of coded caching was introduced by Maddah-Ali and Niesen who
demonstrated the advantages of coding in caching problems. To capture the
essence of the problem, they introduced the $(N, K)$ canonical cache network in
which $K$ users with independent caches of size $M$ request files from a server
that has $N$ files. Among other results, the caching scheme and lower bounds
proposed by them led to a characterization of the exact rate memory tradeoff
when $M\geq \frac{N}{K}(K-1)$. These lower bounds along with the caching scheme
proposed by Chen et al. led to a characterization of the exact rate memory
tradeoff when $M\leq \frac{1}{K}$. In this paper we focus on small caches where
$M\in \left[0,\frac{N}{K}\right]$ and derive new lower bounds. For the case
when $\big\lceil\frac{K+1}{2}\big\rceil\leq N \leq K$ and $M\in
\big[\frac{1}{K},\frac{N}{K(N-1)}\big]$, our lower bounds demonstrate that the
caching scheme introduced by G{\'o}mez-Vilardeb{\'o} is optimal and thus extend
the characterization of the exact rate memory tradeoff. For the case $1\leq
N\leq \big\lceil\frac{K+1}{2}\big\rceil$, we show that the new lower bounds
improve upon the previously known lower bounds.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:35:23 GMT""}]","2021-02-10"
"2102.04798","Kateryna Chumachenko","Kateryna Chumachenko, Jenni Raitoharju, Alexandros Iosifidis, Moncef
  Gabbouj","Ensembling object detectors for image and video data analysis","Accepted to ICASSP 2021.(C)2021 IEEE.Personal use of this material is
  permitted.Permission from IEEE must be obtained for all other uses,in any
  current or future media,including reprinting/republishing this material for
  advertising or promotional purposes,creating new collective works,for resale
  or redistribution to servers or lists,or reuse of any copyrighted component
  of this work in other works",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a method for ensembling the outputs of multiple
object detectors for improving detection performance and precision of bounding
boxes on image data. We further extend it to video data by proposing a
two-stage tracking-based scheme for detection refinement. The proposed method
can be used as a standalone approach for improving object detection
performance, or as a part of a framework for faster bounding box annotation in
unseen datasets, assuming that the objects of interest are those present in
some common public datasets.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:38:16 GMT""}]","2021-02-10"
"2102.04799","Yuye Ling","Jiaxuan Li, Peiyao Jin, Jianfeng Zhu, Haidong Zou, Xun Xu, Min Tang,
  Minwen Zhou, Yu Gan, Jiangnan He, Yuye Ling and Yikai Su","Multi-scale GCN-assisted two-stage network for joint segmentation of
  retinal layers and disc in peripapillary OCT images",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An accurate and automated tissue segmentation algorithm for retinal optical
coherence tomography (OCT) images is crucial for the diagnosis of glaucoma.
However, due to the presence of the optic disc, the anatomical structure of the
peripapillary region of the retina is complicated and is challenging for
segmentation. To address this issue, we developed a novel graph convolutional
network (GCN)-assisted two-stage framework to simultaneously label the nine
retinal layers and the optic disc. Specifically, a multi-scale global reasoning
module is inserted between the encoder and decoder of a U-shape neural network
to exploit anatomical prior knowledge and perform spatial reasoning. We
conducted experiments on human peripapillary retinal OCT images. The Dice score
of the proposed segmentation network is 0.820$\pm$0.001 and the pixel accuracy
is 0.830$\pm$0.002, both of which outperform those from other state-of-the-art
techniques.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:38:42 GMT""}]","2021-02-10"
"2102.04800","Yifan Jin","S.Bacher, G.Bassi, L.Bosisio, G.Cautero, P.Cristaudo, M.Dorigo,
  A.Gabrielli, D.Giuressi, K.Hara, Y.Jin, C.La Licata, L.Lanceri, R. Manfredi,
  H.Nakayama, K.R.Nakamura, A.Natochii, A.Paladino, G.Rizzo, L.Vitale, H.Yin","Performance of the diamond-based beam-loss monitor system of Belle II",,,"10.1016/j.nima.2021.165157",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We designed, constructed and have been operating a system based on
single-crystal synthetic diamond sensors, to monitor the beam losses at the
interaction region of the SuperKEKB asymmetric-energy electron-positron
collider. The system records the radiation dose-rates in positions close to the
inner detectors of the Belle II experiment, and protects both the detector and
accelerator components against destructive beam losses, by participating in the
beam-abort system. It also provides complementary information for the dedicated
studies of beam-related backgrounds. We describe the performance of the system
during the commissioning of the accelerator and during the first physics data
taking.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:39:59 GMT""}]","2021-02-26"
"2102.04801","Luca Ambrogioni","Luca Ambrogioni, Gianluigi Silvestri and Marcel van Gerven","Automatic variational inference with cascading flows",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automation of probabilistic reasoning is one of the primary aims of
machine learning. Recently, the confluence of variational inference and deep
learning has led to powerful and flexible automatic inference methods that can
be trained by stochastic gradient descent. In particular, normalizing flows are
highly parameterized deep models that can fit arbitrarily complex posterior
densities. However, normalizing flows struggle in highly structured
probabilistic programs as they need to relearn the forward-pass of the program.
Automatic structured variational inference (ASVI) remedies this problem by
constructing variational programs that embed the forward-pass. Here, we combine
the flexibility of normalizing flows and the prior-embedding property of ASVI
in a new family of variational programs, which we named cascading flows. A
cascading flows program interposes a newly designed highway flow architecture
in between the conditional distributions of the prior program such as to steer
it toward the observed data. These programs can be constructed automatically
from an input probabilistic program and can also be amortized automatically. We
evaluate the performance of the new variational programs in a series of
structured inference problems. We find that cascading flows have much higher
performance than both normalizing flows and ASVI in a large set of structured
inference problems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:44:39 GMT""}]","2021-02-10"
"2102.04802","Yufei Zhang","Yufei Zhang and Wenjuan Fang","Geometrical constraints on curvature from galaxy-lensing
  cross-correlations","13 pages, 4 figures, 3 tables, minor modifications reflect PRD
  accepted version","Phys. Rev. D 103, 043539(2021)","10.1103/PhysRevD.103.043539",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Accurate constraints on curvature provide a powerful probe of inflation.
However, curvature constraints based on specific assumptions of dark energy may
lead to unreliable conclusions when used to test inflation models. To avoid
this, it is important to obtain constraints that are independent on assumptions
for dark energy. In this paper, we investigate such constraints on curvature
from the geometrical probe constructed from galaxy-lensing cross-correlations.
We study comprehensively the cross-correlations of galaxy with magnification,
measured from type Ia supernovae's brightnesses (""$g\kappa^{\rm SN}$""), with
shear (""$g\kappa^{\rm g}$""), and with CMB lensing (""$g\kappa^{\rm CMB}$""). We
find for the LSST and Stage IV CMB surveys, ""$g\kappa^{\rm SN}$"" ,
""$g\kappa^{\rm g}$"" and ""$g\kappa^{\rm CMB}$"" can be detected with
signal-to-noise ratio $S/N=104,\ 2291,\ 1842$ respectively. When combined with
supernovae Hubble diagram (""SN"") to constrain curvature, we find galaxy-lensing
cross-correlation becomes increasingly important with more degrees of freedom
allowed in dark energy. Without any priors, we obtain error on $\Omega_K$ of
$0.723$ from ""SN + $g\kappa^{\rm SN}$"", $0.0417$ from ""SN + $g\kappa^{\rm g}$"",
and $0.04$ from ""SN + $g\kappa^{\rm g}$ + $g\kappa^{\rm CMB}$"" for the LSST and
Stage IV CMB surveys. The last one is more competitive than a Stage IV BAO
survey (""BAO""). When galaxy-lensing cross-correlations are added to the
combined probe of ""SN + BAO + CMB"", where ""CMB"" stands for Planck measurement
for the CMB acoustic scale, we obtain constraint on $\Omega_K$ of $0.0013$,
which is a factor of 7 improvement from ""SN + BAO + CMB"". We study improvements
in these results from increasing the high redshift extension of supernovae.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:47:01 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 08:19:58 GMT""}]","2021-03-02"
"2102.04803","Enze Xie","Enze Xie, Jian Ding, Wenhai Wang, Xiaohang Zhan, Hang Xu, Peize Sun,
  Zhenguo Li, Ping Luo","DetCo: Unsupervised Contrastive Learning for Object Detection","ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised contrastive learning achieves great success in learning image
representations with CNN. Unlike most recent methods that focused on improving
accuracy of image classification, we present a novel contrastive learning
approach, named DetCo, which fully explores the contrasts between global image
and local image patches to learn discriminative representations for object
detection. DetCo has several appealing benefits. (1) It is carefully designed
by investigating the weaknesses of current self-supervised methods, which
discard important representations for object detection. (2) DetCo builds
hierarchical intermediate contrastive losses between global image and local
patches to improve object detection, while maintaining global representations
for image recognition. Theoretical analysis shows that the local patches
actually remove the contextual information of an image, improving the lower
bound of mutual information for better contrastive learning. (3) Extensive
experiments on PASCAL VOC, COCO and Cityscapes demonstrate that DetCo not only
outperforms state-of-the-art methods on object detection, but also on
segmentation, pose estimation, and 3D shape prediction, while it is still
competitive on image classification. For example, on PASCAL VOC, DetCo-100ep
achieves 57.4 mAP, which is on par with the result of MoCov2-800ep. Moreover,
DetCo consistently outperforms supervised method by 1.6/1.2/1.0 AP on Mask
RCNN-C4/FPN/RetinaNet with 1x schedule. Code will be released at
\href{https://github.com/xieenze/DetCo}{\color{blue}{\tt
github.com/xieenze/DetCo}}.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:47:20 GMT""},{""version"":""v2"",""created"":""Fri, 23 Jul 2021 07:54:34 GMT""}]","2021-07-26"
"2102.04804","Han Wang","Linfeng Zhang, Han Wang, Roberto Car, Weinan E","The Phase Diagram of a Deep Potential Water Model",,"Phys. Rev. Lett. 126, 236001 (2021)","10.1103/PhysRevLett.126.236001",,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Using the Deep Potential methodology, we construct a model that reproduces
accurately the potential energy surface of the SCAN approximation of density
functional theory for water, from low temperature and pressure to about 2400 K
and 50 GPa, excluding the vapor stability region. The computational efficiency
of the model makes it possible to predict its phase diagram using molecular
dynamics. Satisfactory overall agreement with experimental results is obtained.
The fluid phases, molecular and ionic, and all the stable ice polymorphs,
ordered and disordered, are predicted correctly, with the exception of ice III
and XV that are stable in experiments, but metastable in the model. The
evolution of the atomic dynamics upon heating, as ice VII transforms first into
ice VII$''$ and then into an ionic fluid, reveals that molecular dissociation
and breaking of the ice rules coexist with strong covalent fluctuations,
explaining why only partial ionization was inferred in experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:49:39 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 03:29:18 GMT""},{""version"":""v3"",""created"":""Thu, 11 Feb 2021 07:15:44 GMT""}]","2021-06-16"
"2102.04805","Gr\'egoire Menguy","Gr\'egoire Menguy, S\'ebastien Bardin, Richard Bonichon, Cauim de
  Souza Lima","AI-based Blackbox Code Deobfuscation: Understand, Improve and Mitigate",,,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Code obfuscation aims at protecting Intellectual Property and other secrets
embedded into software from being retrieved. Recent works leverage advances in
artificial intelligence with the hope of getting blackbox deobfuscators
completely immune to standard (whitebox) protection mechanisms. While
promising, this new field of AI-based blackbox deobfuscation is still in its
infancy. In this article we deepen the state of AI-based blackbox deobfuscation
in three key directions: understand the current state-of-the-art, improve over
it and design dedicated protection mechanisms. In particular, we define a novel
generic framework for AI-based blackbox deobfuscation encompassing prior work
and highlighting key components; we are the first to point out that the search
space underlying code deobfuscation is too unstable for simulation-based
methods (e.g., Monte Carlo Tres Search used in prior work) and advocate the use
of robust methods such as S-metaheuritics; we propose the new optimized
AI-based blackbox deobfuscator Xyntia which significantly outperforms prior
work in terms of success rate (especially with small time budget) while being
completely immune to the most recent anti-analysis code obfuscation methods;
and finally we propose two novel protections against AI-based blackbox
deobfuscation, allowing to counter Xyntia's powerful attacks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:52:24 GMT""}]","2021-02-10"
"2102.04806","Matthew Crowe","Matthew N. Crowe and Edward R. Johnson","The propagation and decay of a coastal vortex on a shelf",,,"10.1017/jfm.2021.790",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A coastal eddy is modelled as a barotropic vortex propagating along a coastal
shelf. If the vortex speed matches the phase speed of any coastal trapped shelf
wave modes, a shelf wave wake is generated leading to a flux of energy from the
vortex into the wave field. Using a simply shelf geometry, we determine
analytic expressions for the wave wake and the leading order flux of wave
energy. By considering the balance of energy between the vortex and wave field,
this energy flux is then used to make analytic predictions for the evolution of
the vortex speed and radius under the assumption that the vortex structure
remains self similar. These predictions are examined in the asymptotic limit of
small rotation rate and shelf slope and tested against numerical simulations.
  If the vortex speed does not match the phase speed of any shelf wave, steady
vortex solutions are expected to exist. We present a numerical approach for
finding these nonlinear solutions and examine the parameter dependence of their
structure.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:53:38 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 14:43:12 GMT""}]","2021-10-13"
"2102.04807","Haoshu Li","Haoshu Li and Shaolong Wan","Homotopy invariant in time-reversal and twofold rotation symmetric
  systems","19 pages, 10 figures","Phys. Rev. B 104, 045150 (2021)","10.1103/PhysRevB.104.045150",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The primary goal of this paper is to study topological invariants in two
dimensional twofold rotation and time-reversal symmetric spinful systems. In
this paper, firstly we build a new homotopy invariant based on the lifting of
the Wilson loop to the universal covering group of the special orthogonal
group. Furthermore, we prove that the invariant we built agrees with the K
theory invariant. We go beyond the previous understanding of the Wilson loop
unwinding in more than two occupied bands by finding an obstruction of such
unwinding. Then, within this formalism, we show two examples that have the same
Wilson loop spectrum but belong to different topological classes. Finally, we
present a tight binding model realizing the non-trivial phase.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:04:15 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 07:15:06 GMT""},{""version"":""v3"",""created"":""Fri, 30 Jul 2021 06:43:35 GMT""}]","2021-08-02"
"2102.04808","Yassine Himeur","Yassine Himeur and Abdullah Alsalemi and Faycal Bensaali and Abbes
  Amira","Smart non-intrusive appliance identification using a novel local power
  histogramming descriptor with an improved k-nearest neighbors classifier","20 pages, 5 tables, 7 figures","Sustainable Cities and Society Volume 67, 102764, 2021","10.1016/j.scs.2021.102764",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Non-intrusive load monitoring (NILM) is a key cost-effective technology for
monitoring power consumption and contributing to several challenges encountered
when transiting to an efficient, sustainable, and competitive energy efficiency
environment. This paper proposes a smart NILM system based on a novel local
power histogramming (LPH) descriptor, in which appliance power signals are
transformed into 2D space and short histograms are extracted to represent each
device. Specifically, short local histograms are drawn to represent individual
appliance consumption signatures and robustly extract appliance-level data from
the aggregated power signal. Furthermore, an improved k-nearest neighbors
(IKNN) algorithm is presented to reduce the learning computation time and
improve the classification performance. This results in highly improving the
discrimination ability between appliances belonging to distinct categories. A
deep evaluation of the proposed LPH-IKNN based solution is investigated under
different data sets, in which the proposed scheme leads to promising
performance. An accuracy of up to 99.65% and 98.51% has been achieved on GREEND
and UK-DALE data sets, respectively. While an accuracy of more than 96% has
been attained on both WHITED and PLAID data sets. This proves the validity of
using 2D descriptors to accurately identify appliances and create new
perspectives for the NILM problem.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:12:20 GMT""}]","2021-02-10"
"2102.04809","Muhammad Zakwan","Muhammad Zakwan","Stability Analysis and State-Feedback Stabilization of LPV Time-Delay
  Systems with Piecewise Constant Parameters subject to Spontaneous Poissonian
  Jumps",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper discusses the stability analysis of linear parameter varying
systems with a parameter-dependent delay where the parameters are assumed to be
stochastic piecewise constants under spontaneous Poissonian jumps. Based on
stochastic Lyapunov-Krasovskii functionals, we also provide sufficient
synthesis conditions for the gain-scheduled state-feedback controller with
memory in terms of parameter-dependent linear matrix inequalities (LMIs). Such
synthesis conditions are computationally intractable due to the presence of
integral terms. However, we show that these LMIs can be equivalently
represented by integral-free LMIs, which are computationally tractable.
Finally, we illustrate the applicability of the results through examples.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:20:00 GMT""}]","2021-02-10"
"2102.04810","Ivan Nourdin","Soukaina Douissi and Khalifa Es-Sebaiy and George Kerchev and Ivan
  Nourdin","Berry-Esseen bounds of second moment estimators for Gaussian processes
  observed at high frequency",,,,,"math.ST math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $Z:=\{Z_t,t\geq0\}$ be a stationary Gaussian process. We study two
estimators of $\mathbb{E}[Z_0^2]$, namely $\widehat{f}_T(Z):= \frac{1}{T}
\int_{0}^{T} Z_{t}^{2}dt$, and $\widetilde{f}_n(Z) :=\frac{1}{n} \sum_{i
=1}^{n} Z_{t_{i}}^{2}$, where $ t_{i} = i \Delta_{n}$, $ i=0,1,\ldots, n $,
$\Delta_{n}\rightarrow 0$ and $ T_{n} := n \Delta_{n}\rightarrow \infty$. We
prove that the two estimators are strongly consistent and establish
Berry-Esseen bounds for a central limit theorem involving $\widehat{f}_T(Z)$
and $\widetilde{f}_n(Z)$. We apply these results to asymptotically stationary
Gaussian processes and estimate the drift parameter for Gaussian
Ornstein-Uhlenbeck processes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:26:54 GMT""}]","2021-02-10"
"2102.04811","Rog\'erio Duarte","Rog\'erio Duarte, \^Angela Lacerda Nobre, Fernando Pimentel, Marc
  Jacquinet","Broader terms curriculum mapping: Using natural language processing and
  visual-supported communication to create representative program planning
  experiences","v3 removed date and undertitle",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Accreditation bodies call for curriculum development processes open to all
stakeholders, reflecting viewpoints of students, industry, university faculty
and society. However, communication difficulties between faculty and
non-faculty groups leave unexplored an immense collaboration potential. Using
classification of learning objectives, natural language processing, and data
visualization, this paper presents a method to deliver program plan
representations that are universal, self-explanatory, and empowering. A simple
example shows how the method contributes to representative program planning
experiences and a case study is used to confirm the method's accuracy and
utility.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:27:04 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 09:05:48 GMT""},{""version"":""v3"",""created"":""Thu, 16 Jun 2022 17:20:54 GMT""}]","2022-06-17"
"2102.04812","Pedro Pires Ferreira","Lucas E. Correa, Pedro P. Ferreira, Leandro R. de Faria, Thiago T.
  Dorini, M\'ario S. da Luz, Zachary Fisk, Milton S. Torikachvili, Luiz T. F.
  Eleno, Antonio J. S. Machado","Evidence for multiband superconductivity and charge density waves in
  Ni-doped ZrTe$_2$",,,"10.1016/j.jallcom.2022.164477",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We carried out a comprehensive study of the electronic, magnetic, and
thermodynamic properties of Ni-doped ZrTe$_2$. High quality
Ni$_{0.04}$ZrTe$_{1.89}$ single crystals show a possible coexistence of charge
density waves (CDW, T$_{CDW}\approx287$\,K) with superconductivity (T$_c\approx
4.1$\,K), which we report here for the first time. The temperature dependence
of the lower (H$_{c_1}$) and upper (H$_{c_2}$) critical magnetic fields both
deviate significantly from the behaviors expected in conventional single-gap
s-wave superconductors. However, the behaviors of the normalized superfluid
density $\rho_s(T)$ and H$_{c_2}(T)$ can be described well using a two-gap
model for the Fermi surface, in a manner consistent with conventional multiband
superconductivity. Electrical resistivity and specific heat measurements show
clear anomalies centered near 287\,K consistent with a CDW phase transition.
Additionally, electronic-structure calculations support the coexistence of
electron-phonon multiband superconductivity and CDW order due to the
compensated disconnected nature of the electron- and hole-pockets at the Fermi
surface. Our electronic structure calculations also suggest that ZrTe$_2$ could
reach a non-trivial topological type-II Dirac semimetallic state. These
findings highlight that Ni-doped ZrTe2 can be uniquely important for probing
the coexistence of superconducting and CDW ground states in an electronic
system with non-trivial topology.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:31:08 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 17:23:24 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 17:10:56 GMT""}]","2022-03-25"
"2102.04813","Thomas Nikas","Thomas Nikas, Evangelos Pikasis, Sotiris Karabetsos, Dimitris Syvridis","Compensation of Multicore Fiber Skew Effects for Radio over Fiber mmWave
  Antenna Beamforming",,"Journal of Lightwave Technology, 38(7), 1644-1650 (2019)","10.1109/JLT.2019.2961557",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In 5G networks, a Radio over Fiber architecture utilizing multicore fibers
can be adopted for the transmission of mmwave signals feeding phased array
antennas. The mmwave signals undergo phase shifts imposed by optical true time
delay networks, to provide squint free beams. Multicore fibers are used to
transfer the phase shifted optical signals. However, the intercore static skew
of these fibers, if not compensated, distorts the radiation pattern. We propose
an efficient method to compensate the differential delays, without full
equalization of the transmission path lengths, reducing the power loss and
complexity. Statistical analysis shows that regardless of the skew
distribution, the frequency response can be estimated with respect to the rms
skew delays. Simulation analysis of the complete Radio over Fiber and RF link
validates the method.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:32:35 GMT""}]","2021-02-10"
"2102.04814","Liang Kong","Liang Kong and Hao Zheng","Categorical computation","11 pages, comments are welcome","Front. Phys. 18(2), 21302 (2023)",,,"quant-ph cond-mat.str-el math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quantum computing, the computation is achieved by linear operators in or
between Hilbert spaces. In this work, we explore a new computation scheme, in
which the linear operators in quantum computing are replaced by (higher)
functors between two (higher) categories. If from Turing computing to quantum
computing is the first quantization of computation, then this new scheme can be
viewed as the second quantization of computation. The fundamental problem in
realizing this idea is how to realize a (higher) functor physically. We provide
a theoretical idea of realizing (higher) functors physically based on the
physics of topological orders.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:32:58 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 12:20:46 GMT""}]","2023-02-07"
"2102.04815","Andrei Polyanin","Alexander V. Aksenov, Andrei D. Polyanin","Construction of complex solutions to nonlinear partial differential
  equations using simpler solutions",,,,,"nlin.SI math-ph math.AP math.MP","http://creativecommons.org/licenses/by/4.0/","  The paper describes a number of simple but quite effective methods for
constructing exact solutions of PDEs, that involve a relatively small amount of
intermediate calculations. The methods employ two main ideas: (i) simple exact
solutions can serve to construct more complex solutions of the equations under
consideration and (ii) exact solutions of some equations can serve to construct
solutions of other, more complex equations. In particular, we propose a method
for constructing complex solutions from simple solutions using translation and
scaling. We show that in some cases, rather complex solutions can be obtained
by adding one or more terms to simpler solutions. There are situations where
nonlinear superposition allows us to construct a complex composite solution
using similar simple solutions. We also propose a few methods for constructing
complex exact solutions to linear and nonlinear PDEs by introducing
complex-valued parameters into simpler solutions. The effectiveness of the
methods is illustrated by a large number of specific examples (over 30 in
total). These include nonlinear heat/diffusion equations, wave type equations,
Klein--Gordon type equations, hydrodynamic boundary layer equations,
Navier--Stokes equations, and some other PDEs. Apart from exact solutions to
`ordinary' PDEs, we also describe some exact solutions to more complex
nonlinear delay PDEs. Along with the unknown function at the current time,
$u=u(x,t)$, these equations contain the same function at a past time,
$w=u(x,t-\tau)$, where $\tau>0$ is the delay time. Furthermore, we look at
nonlinear partial functional-differential equations of the pantograph type,
which in addition to the unknown $u=u(x,t)$, also contain the same functions
with dilated or contracted arguments, $w=u(px,qt)$, where $p$ and $q$ are
scaling parameters.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:33:47 GMT""}]","2021-02-10"
"2102.04816","Abdelrahman Abdallah","Daniyar Nurseitov, Kairat Bostanbekov, Maksat Kanatov, Anel Alimova,
  Abdelrahman Abdallah, Galymzhan Abdimanap","Classification of Handwritten Names of Cities and Handwritten Text
  Recognition using Various Deep Learning Models",,"Advances in Science, Technology and Engineering Systems. 5,
  934-943 (2020)","10.25046/aj0505114",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This article discusses the problem of handwriting recognition in Kazakh and
Russian languages. This area is poorly studied since in the literature there
are almost no works in this direction. We have tried to describe various
approaches and achievements of recent years in the development of handwritten
recognition models in relation to Cyrillic graphics. The first model uses deep
convolutional neural networks (CNNs) for feature extraction and a fully
connected multilayer perceptron neural network (MLP) for word classification.
The second model, called SimpleHTR, uses CNN and recurrent neural network (RNN)
layers to extract information from images. We also proposed the Bluechet and
Puchserver models to compare the results. Due to the lack of available open
datasets in Russian and Kazakh languages, we carried out work to collect data
that included handwritten names of countries and cities from 42 different
Cyrillic words, written more than 500 times in different handwriting. We also
used a handwritten database of Kazakh and Russian languages (HKR). This is a
new database of Cyrillic words (not only countries and cities) for the Russian
and Kazakh languages, created by the authors of this work.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:34:16 GMT""}]","2021-02-10"
"2102.04817","Wencai Yi","Tao Yang, Xingang Jiang, Wencai Yi, Xiaomin Cheng, Xiaobing Liu","g-SiC6 Monolayer: A New Graphene-like Dirac Cone Material with a High
  Fermi Velocity",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional (2D) materials with Dirac cones have been intrigued by many
unique properties, i.e., the effective masses of carriers close to zero and
Fermi velocity of ultrahigh, which yields a great possibility in
high-performance electronic devices. In this work, using first-principles
calculations, we have predicted a new Dirac cone material of silicon carbide
with the new stoichiometries, named g-SiC6 monolayer, which is composed of sp2
hybridized with a graphene-like structure. The detailed calculations have
revealed that g-SiC6 has outstanding dynamical, thermal, and mechanical
stabilities, and the mechanical and electronic properties are still isotropic.
Of great interest is that the Fermi velocity of g-SiC6 monolayer is the highest
in silicon carbide Dirac materials until now. The Dirac cone of the g-SiC6 is
controllable by an in-plane uniaxial strain and shear strain, which is promised
to realize a direct application in electronics and optoelectronics. Moreover,
we found that new stoichiometries AB6 (A, B = C, Si, and Ge) compounds with the
similar SiC6 monolayer structure are both dynamics stable and possess Dirac
cones, and their Fermi velocity was also calculated in this paper. Given the
outstanding properties of those new types of silicon carbide monolayer, which
is a promising 2D material for further exploring the potential applications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:35:22 GMT""}]","2021-02-10"
"2102.04818","Jan \v{Z}emli\v{c}ka","Josef Dvo\v{r}\'ak, Jan \v{Z}emli\v{c}ka","Autocompact objects of Ab5 categories",,,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of the paper is to describe autocompact objects in Ab5-categories,
i.e. objects in cocomplete abelian categories with exactness preserving
filtered colimits of exact sequences, whose covariant Hom-functor commutes with
copowers of the object itself. A characterization of non-autocompact object is
given, a general criterion of autocompactness of an object via the structure of
its endomorphism ring is presented and a criterion of autocompactness of
products is proven.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:39:53 GMT""}]","2021-02-10"
"2102.04819","Viktor Skoup\'y","Viktor Skoup\'y and Georgios Lukes-Gerakopoulos","Spinning test body orbiting around a Kerr black hole: Eccentric
  equatorial orbits and their asymptotic gravitational-wave fluxes","24 pages, 10 figures","Phys. Rev. D 103, 104045 (2021)","10.1103/PhysRevD.103.104045",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the frequency and time domain Teukolsky formalism to calculate
gravitational-wave fluxes from a spinning body on a bound eccentric equatorial
orbit around a Kerr black hole. The spinning body is represented as a point
particle following the pole-dipole approximation of the
Mathisson-Papapetrou-Dixon equations. Reformulating these equations we are not
only able to find the trajectory of a spinning particle in terms of its
constants of motion, but also to provide a method to calculate the azimuthal
and the radial frequency of this trajectory. Using these orbital quantities, we
introduce the machinery to calculate through the frequency domain Teukolsky
formalism the energy and the angular momentum fluxes at infinity, and at the
horizon, along with the gravitational strain at infinity. We crosscheck the
results obtained from the frequency domain approach with the results obtained
from a time domain Teukolsky equation solver called Teukode.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:40:04 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 11:56:52 GMT""}]","2021-06-02"
"2102.04820","Rebecca Bellovin","Rebecca Bellovin","Cohomology of $(\varphi,\Gamma)$-modules over pseudorigid spaces","To appear in IMRN. Revision; added section A.2",,"10.1093/imrn/rnad093",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the cohomology of families of $(\varphi,\Gamma)$-modules with
coefficients in pseudoaffinoid algebras. We prove that they have finite
cohomology, and we deduce an Euler characteristic formula and Tate local
duality. We classify rank-$1$ $(\varphi, \Gamma)$-modules and deduce that
triangulations of pseudorigid families of $(\varphi,\Gamma)$-modules can be
interpolated, extending a result of [KPX14]. We then apply this to study
extended eigenvarieties at the boundary of weight space, proving in particular
that the eigencurve is proper at the boundary and that Galois representations
attached to certain characteristic $p$ points are trianguline.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:41:43 GMT""},{""version"":""v2"",""created"":""Sun, 25 Jul 2021 15:28:54 GMT""},{""version"":""v3"",""created"":""Fri, 2 Sep 2022 11:08:27 GMT""},{""version"":""v4"",""created"":""Sat, 1 Apr 2023 17:55:42 GMT""}]","2023-04-04"
"2102.04821","Nenad Lazarevi\'c","S. {\DJ}ur{\dj}i\'c Mijin, A. Baum, J. Bekaert, A. \v{S}olaji\'c, J.
  Pe\v{s}i\'c, Y. Liu, Ge He, M. V. Milo\v{s}evi\'c, C. Petrovic and Z. V.
  Popovi\'c, R. Hackl and N. Lazarevi\'c","Probing charge density wave phases and the Mott transition in
  $1T$-TaS$_2$ by inelastic light scattering",,"Phys. Rev. B 103, 245133 (2021)","10.1103/PhysRevB.103.245133",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a polarization-resolved, high-resolution Raman scattering study of
the three consecutive charge density wave (CDW) regimes in $1T$-TaS$_2$ single
crystals, supported by \textit{ab initio} calculations. Our analysis of the
spectra within the low-temperature commensurate (C-CDW) regime shows
$\mathrm{P3}$ symmetry of the system, thus excluding the previously proposed
triclinic stacking of the ""star-of-David"" structure, and promoting trigonal or
hexagonal stacking instead. The spectra of the high-temperature incommensurate
(IC-CDW) phase directly project the phonon density of states due to the
breaking of the translational invariance, supplemented by sizeable
electron-phonon coupling. Between 200 and 352\,K, our Raman spectra show
contributions from both the IC-CDW and the C-CDW phase, indicating their
coexistence in the so-called nearly-commensurate (NC-CDW) phase. The
temperature-dependence of the symmetry-resolved Raman conductivity indicates
the stepwise reduction of the density of states in the CDW phases, followed by
a Mott transition within the C-CDW phase. We determine the size of the Mott gap
to be $\Omega_{\rm gap}\approx 170-190$ meV, and track its temperature
dependence.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:42:59 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 12:52:27 GMT""}]","2021-06-30"
"2102.04822","Gregory Gay","Hussein Almulla and Gregory Gay","Learning How to Search: Generating Effective Test Cases Through Adaptive
  Fitness Function Selection","Accepted, to appear in Empirical Software Engineering Journal",,,,"cs.SE cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Search-based test generation is guided by feedback from one or more fitness
functions - scoring functions that judge solution optimality. Choosing
informative fitness functions is crucial to meeting the goals of a tester.
Unfortunately, many goals - such as forcing the class-under-test to throw
exceptions, increasing test suite diversity, and attaining Strong Mutation
Coverage - do not have effective fitness function formulations. We propose that
meeting such goals requires treating fitness function identification as a
secondary optimization step. An adaptive algorithm that can vary the selection
of fitness functions could adjust its selection throughout the generation
process to maximize goal attainment, based on the current population of test
suites. To test this hypothesis, we have implemented two reinforcement learning
algorithms in the EvoSuite unit test generation framework, and used these
algorithms to dynamically set the fitness functions used during generation for
the three goals identified above.
  We have evaluated our framework, EvoSuiteFIT, on a set of Java case examples.
EvoSuiteFIT techniques attain significant improvements for two of the three
goals, and show limited improvements on the third when the number of
generations of evolution is fixed. Additionally, for two of the three goals,
EvoSuiteFIT detects faults missed by the other techniques. The ability to
adjust fitness functions allows strategic choices that efficiently produce more
effective test suites, and examining these choices offers insight into how to
attain our testing goals. We find that adaptive fitness function selection is a
powerful technique to apply when an effective fitness function does not already
exist for achieving a testing goal.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:44:37 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 08:08:40 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 12:07:41 GMT""}]","2021-08-31"
"2102.04823","Alessandra Di Pierro","Riccardo Mengoni, Massimiliano Incudini, Alessandra Di Pierro","Facial Expression Recognition on a Quantum Computer",,,,,"quant-ph cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of facial expression recognition and show a possible
solution using a quantum machine learning approach. In order to define an
efficient classifier for a given dataset, our approach substantially exploits
quantum interference. By representing face expressions via graphs, we define a
classifier as a quantum circuit that manipulates the graphs adjacency matrices
encoded into the amplitudes of some appropriately defined quantum states. We
discuss the accuracy of the quantum classifier evaluated on the quantum
simulator available on the IBM Quantum Experience cloud platform, and compare
it with the accuracy of one of the best classical classifier.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:48:00 GMT""}]","2021-02-10"
"2102.04824","Kumar Abhishek","Ayush Deva, Kumar Abhishek, Sujit Gujar","A Multi-Arm Bandit Approach To Subset Selection Under Constraints","Accepted in AAMAS 2021 as Extended Abstract",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We explore the class of problems where a central planner needs to select a
subset of agents, each with different quality and cost. The planner wants to
maximize its utility while ensuring that the average quality of the selected
agents is above a certain threshold. When the agents' quality is known, we
formulate our problem as an integer linear program (ILP) and propose a
deterministic algorithm, namely \dpss\ that provides an exact solution to our
ILP.
  We then consider the setting when the qualities of the agents are unknown. We
model this as a Multi-Arm Bandit (MAB) problem and propose \newalgo\ to learn
the qualities over multiple rounds. We show that after a certain number of
rounds, $\tau$, \newalgo\ outputs a subset of agents that satisfy the average
quality constraint with a high probability. Next, we provide bounds on $\tau$
and prove that after $\tau$ rounds, the algorithm incurs a regret of $O(\ln
T)$, where $T$ is the total number of rounds. We further illustrate the
efficacy of \newalgo\ through simulations.
  To overcome the computational limitations of \dpss, we propose a
polynomial-time greedy algorithm, namely \greedy, that provides an approximate
solution to our ILP. We also compare the performance of \dpss\ and \greedy\
through experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:48:57 GMT""}]","2021-02-10"
"2102.04825","Carolina Tamborini","Alessandro Ghigi, Carolina Tamborini","Bergman kernel and period map for curves",,,,,"math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As for any symmetric space the tangent space to Siegel upper-half space is
endowed with an operation coming from the Lie bracket on the Lie algebra. We
consider the pull-back of this operation to the moduli space of curves via the
Torelli map. We characterize it in terms of the geometry of the curve, using
the Bergman kernel form associated to the curve. It is known that the second
fundamental form of the Torelli map outside the hyperelliptic locus can be seen
as the multiplication by a certain meromorphic form. Our second result says
that the Bergman kernel form is the harmonic representative - in a suitable
sense - of this meromorphic form.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:50:52 GMT""}]","2021-02-10"
"2102.04826","Armelle Perret du Cray","Pascal Giorgi, Bruno Grenet, Armelle Perret du Cray","On exact division and divisibility testing for sparse polynomials",,"Proceedings of ISSAC 2021","10.1145/3452143.3465539",,"cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  No polynomial-time algorithm is known to test whether a sparse polynomial G
divides another sparse polynomial $F$. While computing the quotient Q=F quo G
can be done in polynomial time with respect to the sparsities of F, G and Q,
this is not yet sufficient to get a polynomial-time divisibility test in
general. Indeed, the sparsity of the quotient Q can be exponentially larger
than the ones of F and G. In the favorable case where the sparsity #Q of the
quotient is polynomial, the best known algorithm to compute Q has a non-linear
factor #G#Q in the complexity, which is not optimal.
  In this work, we are interested in the two aspects of this problem. First, we
propose a new randomized algorithm that computes the quotient of two sparse
polynomials when the division is exact. Its complexity is quasi-linear in the
sparsities of F, G and Q. Our approach relies on sparse interpolation and it
works over any finite field or the ring of integers. Then, as a step toward
faster divisibility testing, we provide a new polynomial-time algorithm when
the divisor has a specific shape. More precisely, we reduce the problem to
finding a polynomial S such that QS is sparse and testing divisibility by S can
be done in polynomial time. We identify some structure patterns in the divisor
G for which we can efficiently compute such a polynomial~S.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:54:38 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 19:45:10 GMT""}]","2021-07-21"
"2102.04827","Benjamin J. Stone Mr","Evgeny I. Buchbinder and Benjamin J. Stone","Mixed three-point functions of conserved currents in three-dimensional
  superconformal field theory","54 pages, v2: minor typos corrected, references added, v3: section 7
  added, published version","Phys. Rev. D 103, 086023 (2021)","10.1103/PhysRevD.103.086023",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider mixed three-point correlation functions of the supercurrent and
flavour current in three-dimensional $1 \leq \mathcal{N} \leq 4$ superconformal
field theories. Our method is based on the decomposition of the relevant
tensors into irreducible components to guarantee that all possible tensor
structures are systematically taken into account. We show that only parity even
structures appear in the correlation functions. In addition to the previous
results obtained in arXiv:1503.04961, it follows that supersymmetry forbids
parity odd structures in three-point functions involving the supercurrent and
flavour current multiplets.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:58:14 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 09:58:22 GMT""},{""version"":""v3"",""created"":""Thu, 29 Apr 2021 03:27:46 GMT""}]","2021-05-05"
"2102.04828","Sebastian U. Stich","Lingjing Kong, Tao Lin, Anastasia Koloskova, Martin Jaggi, Sebastian
  U. Stich","Consensus Control for Decentralized Deep Learning","LK and TL contribute equally - ICML 2021","Proceedings of the 38th International Conference on Machine
  Learning (ICML), PMLR 139, 2021",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decentralized training of deep learning models enables on-device learning
over networks, as well as efficient scaling to large compute clusters.
Experiments in earlier works reveal that, even in a data-center setup,
decentralized training often suffers from the degradation in the quality of the
model: the training and test performance of models trained in a decentralized
fashion is in general worse than that of models trained in a centralized
fashion, and this performance drop is impacted by parameters such as network
size, communication topology and data partitioning. We identify the changing
consensus distance between devices as a key parameter to explain the gap
between centralized and decentralized training.
  We show in theory that when the training consensus distance is lower than a
critical quantity, decentralized training converges as fast as the centralized
counterpart. We empirically validate that the relation between generalization
performance and consensus distance is consistent with this theoretical
observation. Our empirical insights allow the principled design of better
decentralized training schemes that mitigate the performance drop. To this end,
we provide practical training guidelines and exemplify its effectiveness on the
data-center setup as the important first step.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:58:33 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 08:15:00 GMT""}]","2021-06-21"
"2102.04829","Oleksandra Ivanova","Oleksandra Ivanova, Yury Skorov, Pavlo Korsun, Viktor Afanasiev,
  J\""urgen Blum","Observations of the long-lasting activity of the distant Comets 29P
  Schwassmann-Wachmann 1, C/2003 WT42 (LINEAR) and C/2002 VQ94 (LINEAR)","9 pages, 4 figures, 2 tables",,"10.1016/j.icarus.2010.10.026",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated three comets, which are active at large heliocentric
distances, using observations obtained at the 6-m BTA telescope (SAO RAS,
Russia) in the photometric mode of the focal reducer SCORPIO. The three comets,
29P/Schwassmann-Wachmann 1, C/2003 WT42 (LINEAR), and C/2002 VQ94 (LINEAR),
were observed after their perihelion passages at heliocentric distances between
5.5 and 7.08 AU. The dust production rates in terms of Afrho was measured for
these comets. Using the retrieved values, an average dust production rate was
derived under different model assumptions. A tentative calculation of the total
mass loss of the comet nucleus within a certain observation period was
executed. We calculated the corresponding thickness of the depleted uppermost
layer where high-volatile ices completely sublimated. The results obtained in
our study strongly support the idea that the observed activity of Comet SW1
requires a permanent demolition of the upper surface layers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:59:55 GMT""}]","2021-02-10"
"2102.04830","Wenmeng Yu","Wenmeng Yu, Hua Xu, Ziqi Yuan, Jiele Wu","Learning Modality-Specific Representations with Self-Supervised
  Multi-Task Learning for Multimodal Sentiment Analysis","Accepted by AAAI2021",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Representation Learning is a significant and challenging task in multimodal
learning. Effective modality representations should contain two parts of
characteristics: the consistency and the difference. Due to the unified
multimodal annotation, existing methods are restricted in capturing
differentiated information. However, additional uni-modal annotations are high
time- and labor-cost. In this paper, we design a label generation module based
on the self-supervised learning strategy to acquire independent unimodal
supervisions. Then, joint training the multi-modal and uni-modal tasks to learn
the consistency and difference, respectively. Moreover, during the training
stage, we design a weight-adjustment strategy to balance the learning progress
among different subtasks. That is to guide the subtasks to focus on samples
with a larger difference between modality supervisions. Last, we conduct
extensive experiments on three public multimodal baseline datasets. The
experimental results validate the reliability and stability of auto-generated
unimodal supervisions. On MOSI and MOSEI datasets, our method surpasses the
current state-of-the-art methods. On the SIMS dataset, our method achieves
comparable performance than human-annotated unimodal labels. The full codes are
available at https://github.com/thuiar/Self-MM.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:05:02 GMT""}]","2021-02-10"
"2102.04831","Ismael Ribeiro de Assis","I. R. de Assis, R. Raimondi, G. J. Ferreira","Spin drift-diffusion for two-subband quantum wells","16 pages, 10 figures","Phys. Rev. B 103, 165304 (2021)","10.1103/PhysRevB.103.165304",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controlling the spin dynamics and spin lifetimes is one of the main
challenges in spintronics. To this end, the study of the spin diffusion in
two-dimensional electron gases (2DEGs) shows that when the Rashba and
Dresselhaus spin-orbit couplings (SOC) are balanced, a persistent spin helix
regime arises. There, a striped spin pattern shows a long lifetime, limited
only by the cubic Dresselhaus SOC, and its dynamics can be controlled by
in-plane drift fields. Here, we derive a spin diffusion equation for
non-degenerate two-subbands 2DEGs. We show that the intersubband scattering
rate, which is defined by the overlap of the subband densities, enters as a new
nob to control the spin dynamics, and can be controlled by electric fields,
being maximum for symmetric quantum wells. We find that for large intersubband
couplings the dynamics follow an effective diffusion matrix given by
approximately half of the subband-averaged matrices. This extra 1/2 factor
arises from Matthiessen's rule summing over the intra- and intersubband
scattering rates, and leads to a reduced diffusion constant and larger spin
lifetimes. We illustrate our findings with numerical solutions of the diffusion
equation with parameters extracted from realistic Schr\""odinger-Poisson
calculations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:05:54 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 13:54:53 GMT""}]","2021-04-14"
"2102.04832","Mantas Gabrielaitis","Mantas Gabrielaitis","Fast and Accurate Amplitude Demodulation of Wideband Signals","Accepted for publication in IEEE Transactions on Signal Processing",,"10.1121/10.0004762",,"eess.SP cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Amplitude demodulation is a classical operation used in signal processing.
For a long time, its effective applications in practice have been limited to
narrowband signals. In this work, we generalize amplitude demodulation to
wideband signals. We pose demodulation as a recovery problem of an oversampled
corrupted signal and introduce special iterative schemes belonging to the
family of alternating projection algorithms to solve it. Sensibly chosen
structural assumptions on the demodulation outputs allow us to reveal the high
inferential accuracy of the method over a rich set of relevant signals. This
new approach surpasses current state-of-the-art demodulation techniques apt to
wideband signals in computational efficiency by up to many orders of magnitude
with no sacrifice in quality. Such performance opens the door for applications
of the amplitude demodulation procedure in new contexts. In particular, the new
method makes online and large-scale offline data processing feasible, including
the calculation of modulator-carrier pairs in higher dimensions and poor
sampling conditions, independent of the signal bandwidth. We illustrate the
utility and specifics of applications of the new method in practice by using
natural speech and synthetic signals.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:06:29 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 17:07:10 GMT""}]","2021-06-16"
"2102.04833","Bu\u{g}ra T\""uzemen","Piotr Magierski, Bu\u{g}ra T\""uzemen, Gabriel Wlaz{\l}owski","Dynamics of spin-polarized impurity in ultracold Fermi gas",,"Phys. Rev. A 104, 033304 (2021)","10.1103/PhysRevA.104.033304",,"cond-mat.quant-gas cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the motion of spin-polarized impurity (ferron) in ultracold
atomic gas is characterized by a certain critical velocity which can be traced
back to the amount of spin imbalance inside the impurity. We have calculated
the effective mass of ferron in two dimensions. We show that the effective mass
scales with the surface of the ferron. We discuss the impact of these findings;
in particular, we demonstrate that ferrons become unstable in the vicinity of a
vortex.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:11:15 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 19:56:25 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 11:01:40 GMT""}]","2021-09-15"
"2102.04834","Antonela Trbovic","Antonela Trbovi\'c","Tamagawa numbers of elliptic curves with prescribed torsion subgroup or
  isogeny",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Tamagawa numbers of elliptic curves with torsion
$\mathbb{Z}/2\mathbb{Z}\oplus \mathbb{Z}/14\mathbb{Z}$ over cubic fields and of
elliptic curves with an $n-$isogeny over $\mathbb{Q}$, for
$n\in\{6,8,10,12,14,16,17,18,19,37,43,67,163\}$. Bruin and Najman proved that
every elliptic curve with torsion $\mathbb{Z}/2\mathbb{Z}\oplus
\mathbb{Z}/14\mathbb{Z}$ over a cubic field is a base change of an elliptic
curve defined over $\mathbb{Q}$. We find that Tamagawa numbers of elliptic
curves defined over $\mathbb{Q}$ with torsion $\mathbb{Z}/2\mathbb{Z}\oplus
\mathbb{Z}/14\mathbb{Z}$ over a cubic field are always divisible by $14^2$,
with each factor $14$ coming from a rational prime with split multiplicative
reduction of type $I_{14k},$ one of which is always $p=2.$ The only exception
is the curve 1922.e2, with $c_E=c_2=14.$ The same curves defined over cubic
fields over which they have torsion subgroup $\mathbb{Z}/2\mathbb{Z}\oplus
\mathbb{Z}/14\mathbb{Z}$ turn out to have the Tamagawa number divisible by
$14^3$. As for $n-$isogenies, Tamagawa numbers of elliptic curves with an
$18-$isogeny must be divisible by 4, while elliptic curves with an $n-$isogeny
for the remaining $n$ from the mentioned set must have Tamagawa numbers
divisible by 2, except for finite sets of specified curves.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:13:04 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 08:03:50 GMT""}]","2021-06-09"
"2102.04835","Florent Baboux","F. Appas, F. Baboux, M. I. Amanti, A. Lema\^itre, F. Boitier, E.
  Diamanti, S. Ducci","Flexible entanglement-distribution network with an AlGaAs chip for
  secure communications","12 pages, 8 figures","npj Quantum Information 7, 118 (2021)","10.1038/s41534-021-00454-7",,"quant-ph cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum communication networks enable applications ranging from highly secure
communication to clock synchronization and distributed quantum computing.
Miniaturized, flexible, and cost-efficient resources will be key elements for
ensuring the scalability of such networks as they progress towards large-scale
deployed infrastructures. Here, we bring these elements together by combining
an on-chip, telecom-wavelength, broadband entangled photon source with
industry-grade flexible-grid wavelength division multiplexing techniques, to
demonstrate reconfigurable entanglement distribution between up to 8 users in a
resource-optimized quantum network topology. As a benchmark application we use
quantum key distribution, and show low error and high secret key generation
rates across several frequency channels, over both symmetric and asymmetric
metropolitan-distance optical fibered links and including finite-size effects.
By adapting the bandwidth allocation to specific network constraints, we also
illustrate the flexible networking capability of our configuration. Together
with the potential of our semiconductor source for distributing secret keys
over a 60 nm bandwidth with commercial multiplexing technology, these results
offer a promising route to the deployment of scalable quantum network
architectures.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:13:07 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 17:58:50 GMT""}]","2021-08-17"
"2102.04836","Blerta Lindqvist","Blerta Lindqvist","Target Training Does Adversarial Training Without Adversarial Samples","arXiv admin note: text overlap with arXiv:2006.04504",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network classifiers are vulnerable to misclassification of adversarial
samples, for which the current best defense trains classifiers with adversarial
samples. However, adversarial samples are not optimal for steering attack
convergence, based on the minimization at the core of adversarial attacks. The
minimization perturbation term can be minimized towards $0$ by replacing
adversarial samples in training with duplicated original samples, labeled
differently only for training. Using only original samples, Target Training
eliminates the need to generate adversarial samples for training against all
attacks that minimize perturbation. In low-capacity classifiers and without
using adversarial samples, Target Training exceeds both default CIFAR10
accuracy ($84.3$%) and current best defense accuracy (below $25$%) with $84.8$%
against CW-L$_2$($\kappa=0$) attack, and $86.6$% against DeepFool. Using
adversarial samples against attacks that do not minimize perturbation, Target
Training exceeds current best defense ($69.1$%) with $76.4$% against
CW-L$_2$($\kappa=40$) in CIFAR10.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:17:57 GMT""}]","2021-02-10"
"2102.04837","Rafael Leon Greenblatt","Rafael Leon Greenblatt","Discrete and zeta-regularized determinants of the Laplacian on polygonal
  domains with Dirichlet boundary conditions","43 pages, 6 figures. Moderate revisions including restatement of the
  main result","J. Math. Phys. 64, 043301 (2023)","10.1063/5.0062138",,"math-ph math.FA math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $\Pi \subset \mathbb{R}^2$ a connected, open, bounded set whose boundary
is a finite union of disjoint polygons whose vertices have integer coordinates,
the logarithm of the discrete Laplacian on $L\Pi \cap \mathbb{Z}^2$ with
Dirichlet boundary conditions has an asymptotic expansion for large $L$
involving the zeta-regularized determinant of the associated continuum
Laplacian.
  When $\Pi$ is not simply connected, this result extends to Laplacians acting
on two-valued functions with a specified monodromy class.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:26:36 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 09:32:27 GMT""},{""version"":""v3"",""created"":""Thu, 1 Sep 2022 09:33:07 GMT""},{""version"":""v4"",""created"":""Fri, 10 Mar 2023 14:17:52 GMT""}]","2023-04-19"
"2102.04839","Lei Liu","Yanjie Hu, Jiaqi Feng, Xiangping Zhang, Hongshuai Gao, Saimeng Jin,
  Lei Liu, Weifeng Shen","Efficient electrochemical reduction of CO2 to CO by soft functional
  materials",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Electrochemical reduction of CO2 to CO is a promising strategy. However,
achieving high Faradaic efficiency with high current density using ILs
electrolyte remains a challenge. In this study, the IL N octyltrimethyl 1,2,4
triazole ammonium shows outstanding performance for electrochemical reduction
of CO2 to CO on the commercial Ag electrode, and the current density can be up
to 50.8 mA cm-2 with a Faradaic efficiency of 90.6%. The current density of CO
is much higher than those reported in the ILs electrolyte. In addition, the
density functional theory calculation further proved that IL interacts with CO2
to form IL CO2 complex which played a key role in reducing the activation
energy of CO2. According to the molecular orbital theory, the electrons
obtained from ILs was filled in the anti bonding orbit of the CO2, resulting in
reducing the C=O bond energy. This work provides a new strategy to design novel
ILs for high efficiency electrochemical reduction of CO2 to CO.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:32:01 GMT""}]","2021-02-10"
"2102.04840","Akhilesh Nautiyal","Gaetano Lambiase, Subhendra Mohanty, Akhilesh Nautiyal and Soumya Rao","Constraints on electromagnetic form factors of sub-GeV dark matter from
  the Cosmic Microwave Background anisotropy","Version to appear in Physical Review D","Phys. Rev. D 104, 023519 (2021)","10.1103/PhysRevD.104.023519",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We consider dark matter which have non-zero electromagnetic form factors like
electric/magnetic dipole moments and anapole moment for fermionic dark matter
and Rayleigh form factor for scalar dark matter. We consider dark matter mass
$m_\chi > \cal{ O}({\rm MeV})$ and put constraints on their mass and
electromagnetic couplings from CMB and LSS observations. Fermionic dark matter
with non-zero electromagnetic form factors can annihilate to $e^+ e^-$ and
scalar dark matter can annihilate to $2\gamma$ at the time of recombination and
distort the CMB. We analyze dark matter with multipole moments with Planck and
BAO observations. We find upper bounds on anapole moment $g_{A}<7.163\times
10^{3} \text{GeV}^{-2}$, electric dipole moment ${\cal D}<7.978\times 10^{-9}
\text{e-cm}$, magnetic dipole moment ${\mu}<2.959\times 10^{-7} \mu_B$, and the
bound on Rayleigh form factor of dark matter is $g_4/\Lambda_4^2<1.085\times
10^{-2}\text{GeV}^{-2}$ with $95\%$C.L.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:32:45 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 12:04:08 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 05:23:27 GMT""}]","2021-07-21"
"2102.04841","Eduardo Vitral","Eduardo Vitral","BALRoGO: Bayesian Astrometric Likelihood Recovery of Galactic Objects --
  Global properties of over one hundred globular clusters with Gaia EDR3","16 pages, 10 figures, 2 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab947",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present BALRoGO: Bayesian Astrometric Likelihood Recovery of Galactic
Objects, a public code to measure the centers, effective radii, and bulk proper
motions of Milky Way globular clusters and Local Group dwarf spheroidals, whose
data are mixed with Milky Way field stars. Our approach presents innovative
methods such as surface density fits allowing for strong interloper
contamination and proper motion fits using a Pearson VII distribution for
interlopers, instead of classic Gaussian-mixture recipes. We also use
non-parametric approaches to represent the color-magnitude diagram of such
stellar systems based in their membership probabilities, previously derived
from surface density and proper motion fits. The robustness of our method is
verified by comparing its results with previous estimates from the literature
as well as by testing it on mock data from N-body simulations. We applied
BALRoGO to Gaia EDR3 data for over one hundred Milky Way globular clusters and
nine Local Group dwarf spheroidals, and we provide positions, effective radii,
and bulk proper motions. Finally, we make our algorithm available as an open
source software.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:35:55 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 10:24:08 GMT""}]","2021-04-21"
"2102.04845","Haozhen Zhao","Rishi Chhatwal, Robert Keeling, Peter Gronvall, Nathaniel
  Huber-Fliflet, Jianping Zhang, Haozhen Zhao","CNN Application in Detection of Privileged Documents in Legal Document
  Review","2020 IEEE International Conference on Big Data (Big Data)",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Protecting privileged communications and data from disclosure is paramount
for legal teams. Legal advice, such as attorney-client communications or
litigation strategy are typically exempt from disclosure in litigations or
regulatory events and are vital to the attorney-client relationship. To protect
this information from disclosure, companies and outside counsel often review
vast amounts of documents to determine those that contain privileged material.
This process is extremely costly and time consuming. As data volumes increase,
legal counsel normally employs methods to reduce the number of documents
requiring review while balancing the need to ensure the protection of
privileged information. Keyword searching is relied upon as a method to target
privileged information and reduce document review populations. Keyword searches
are effective at casting a wide net but often return overly inclusive results -
most of which do not contain privileged information. To overcome the weaknesses
of keyword searching, legal teams increasingly are using machine learning
techniques to target privileged information. In these studies, classic text
classification techniques are applied to build classification models to
identify privileged documents. In this paper, the authors propose a different
method by applying machine learning / convolutional neural network techniques
(CNN) to identify privileged documents. Our proposed method combines keyword
searching with CNN. For each keyword term, a CNN model is created using the
context of the occurrences of the keyword. In addition, a method was proposed
to select reliable privileged (positive) training keyword occurrences from
labeled positive training documents. Extensive experiments were conducted, and
the results show that the proposed methods can significantly reduce false
positives while still capturing most of the true positives.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:42:02 GMT""}]","2021-02-10"
"2102.04846","Emil Mallmin","Emil Mallmin and Johan du Buisson and Hugo Touchette","Large deviations of currents in diffusions with reflective boundaries","24 pages, 2 figures","J. Phys. A: Math. Theor. 54 295001 (2021)","10.1088/1751-8121/ac039a",,"cond-mat.stat-mech math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the large deviations of current-type observables defined for Markov
diffusion processes evolving in smooth bounded regions of $\mathbb{R}^d$ with
reflections at the boundaries. We derive for these the correct boundary
conditions that must be imposed on the spectral problem associated with the
scaled cumulant generating function, which gives, by Legendre transform, the
rate function characterizing the likelihood of current fluctuations. Two
methods for obtaining the boundary conditions are presented, based on the
diffusive limit of random walks and on the Feynman--Kac equation underlying the
evolution of generating functions. Our results generalize recent works on
density-type observables, and are illustrated for an $N$-particle single-file
diffusion on a ring, which can be mapped to a reflected $N$-dimensional
diffusion.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:42:50 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 15:31:52 GMT""}]","2021-06-22"
"2102.04847","Akaash Srikanth","Akaash Srikanth, Bharat Chandra, Binukumar G Nair, Nirmal K, Margarita
  Safonova, Shanti Prabha, Rekhesh Mohan, Jayant Murthy, Rajini G.K","Testing a Prototype 1U CubeSat on a Stratospheric Balloon Flight",,,,,"astro-ph.IM physics.ao-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-altitude balloon experiments are becoming very popular among
universities and research institutes as they can be used for testing
instruments eventually intended for space, and for simple astronomical
observations of Solar System objects like the Moon, comets, and asteroids,
difficult to observe from the ground due to atmosphere. Further, they are one
of the best platforms for atmospheric studies. In this experiment, we build a
simple 1U CubeSat and, by flying it on a high-altitude balloon to an altitude
of about 30 km, where the total payload weighted 4.9 kg and examine how some
parameters, such as magnetic field, humidity, temperature or pressure, vary as
a function of altitude. We also calibrate the magnetometer to remove the hard
iron and soft iron errors. Such experiments and studies through a stratospheric
balloon flights can also be used to study the performance of easily available
commercial sensors in extreme conditions as well. We present the results of the
first flight, which helped us study the functionality of the various sensors
and electronics at low temperatures reaching about -40 degrees Celsius. Further
the motion of the payload has been tracked throughout this flight. This
experiment took place on 8 March 2020 from the CREST campus of the Indian
Institute of Astrophysics, Bangalore. Using the results from this flight, we
identify and rectify the errors to obtain better results from the subsequent
flights.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:43:23 GMT""}]","2021-02-10"
"2102.04848","Yu Liu","Yu Liu, Lianghua Huang, Pan Pan, Bin Wang, Yinghui Xu, Rong Jin","Train a One-Million-Way Instance Classifier for Unsupervised Visual
  Representation Learning","Accepted by AAAI2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a simple unsupervised visual representation learning
method with a pretext task of discriminating all images in a dataset using a
parametric, instance-level classifier. The overall framework is a replica of a
supervised classification model, where semantic classes (e.g., dog, bird, and
ship) are replaced by instance IDs. However, scaling up the classification task
from thousands of semantic labels to millions of instance labels brings
specific challenges including 1) the large-scale softmax computation; 2) the
slow convergence due to the infrequent visiting of instance samples; and 3) the
massive number of negative classes that can be noisy. This work presents
several novel techniques to handle these difficulties. First, we introduce a
hybrid parallel training framework to make large-scale training feasible.
Second, we present a raw-feature initialization mechanism for classification
weights, which we assume offers a contrastive prior for instance discrimination
and can clearly speed up converge in our experiments. Finally, we propose to
smooth the labels of a few hardest classes to avoid optimizing over very
similar negative pairs. While being conceptually simple, our framework achieves
competitive or superior performance compared to state-of-the-art unsupervised
approaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation
protocol and on several downstream visual tasks, verifying that full instance
classification is a strong pretraining technique for many semantic visual
tasks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:44:18 GMT""}]","2021-02-10"
"2102.04849","Pritam Anand South Asian University","Pritam Anand","Learning a powerful SVM using piece-wise linear loss functions","9 pages",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we have considered general k-piece-wise linear convex loss
functions in SVM model for measuring the empirical risk. The resulting
k-Piece-wise Linear loss Support Vector Machine (k-PL-SVM) model is an adaptive
SVM model which can learn a suitable piece-wise linear loss function according
to nature of the given training set. The k-PL-SVM models are general SVM models
and existing popular SVM models, like C-SVM, LS-SVM and Pin-SVM models, are
their particular cases. We have performed the extensive numerical experiments
with k-PL-SVM models for k = 2 and 3 and shown that they are improvement over
existing SVM models.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:45:08 GMT""}]","2021-02-10"
"2102.04851","Lei Yin","Lei Yin, De-fu Hou, Hai-cang Ren","Chiral Magnetic Effect and Three-point Function from AdS/CFT
  Correspondence","36 pages, 2 figure","J. High Energ. Phys. 2021, 117 (2021)","10.1007/JHEP09(2021)117",,"hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The chiral magnetic effect with a fluctuating chiral imbalance is more
realistic in the evolution of quark-gluon plasma, which reflects the random
gluonic topological transition. Incorporating this dynamics, we calculate the
chiral magnetic current in response to space-time dependent axial gauge
potential and magnetic field in AdS/CFT correspondence. In contrast to
conventional treatment of constant axial chemical potential, the response
function here is the AVV three-point function of the $\mathcal{N}=4$ super
Yang-Mills at strong coupling. Through an iterative solution of the nonlinear
equations of motion in Schwarzschild-AdS$_5$ background, we are able to express
the AVV function in terms of two Heun functions and prove its UV/IR finiteness,
as expected for $\mathcal{N}=4$ super Yang-Mills theory. We found that the
dependence of the chiral magnetic current on a non-constant chiral imbalance is
non-local, different from hydrodynamic approximation, and demonstrates the
subtlety of the infrared limit discovered in field theoretic approach. We
expect our results enrich the understanding of the phenomenology of the chiral
magnetic effect in the context of relativistic heavy ion collisions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:48:06 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 12:18:27 GMT""}]","2021-09-27"
"2102.04852","Xinghe Chu","Xinghe Chu, Zhaoming Lu, David Gesbert, Luhan Wang, Xiangming Wen","Vehicle Localization via Cooperative Channel Mapping",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses vehicle positioning, a topic whose importance has risen
dramatically in the context of future autonomous driving systems. While
classical methods that use GPS and/or beacon signals from network
infrastructure for triangulation tend to be sensitive to multi-paths and signal
obstruction, our method exhibits robustness with respect to such phenomena. Our
approach builds on the recently proposed Channel-SLAM method which first
enabled leveraging of multi-path so as to improve (single) vehicle positioning.
Here, we propose a cooperative mapping approach which builds upon the
Channel-SLAM concept, referred to here as Team Channel-SLAM. Team Channel-SLAM
not only exploits the stationary nature of many reflecting objects around the
vehicle, but also capitalizes on the multi-vehicle nature of road traffic. The
key intuition behind our method is the exploitation for the first time of the
correlation between reflectors around multiple neighboring vehicles. An
algorithm is derived for reflector selection and estimation, combined with a
team particle filter (TPF) so as to achieve high precision simultaneous
multiple vehicle positioning. We obtain large improvement over the
single-vehicle positioning scenario, with gains being already noticeable for
moderate vehicle densities, such as over 40% improvement for a vehicle density
as low as 4 vehicles in 132 meters' length road.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:48:28 GMT""}]","2021-02-10"
"2102.04853","Vinayak Kamble PhD","Kusuma Urs MB, Vinayak B Kamble","Protonic Conduction Induced Selective Room Temperature Hydrogen Response
  in ZnO/NiO Heterojunction Surfaces",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we show that the ionic conduction through surface chemisorbed
ambient moisture leads to the remarkably high room temperature selective
response towards hydrogen gas. The surface adsorbed moisture acts as surface
states and shows ionic conduction, as a result of smaller size of ZnO
nanoparticles of 20 +/- 5 nm. This response is enhanced remarkably i.e. from
10% to 190% for 1200 ppm H2 gas when p-type NiO quasi-nanowires (width ~50 nm)
are mixed with these n-type ZnO nanoparticles to form a homogenous NiO/ZnO
nano-bulk p-n heterostructure. The maximum response is obtained for about 50-50
% composition of NiO/ZnO although it is of still n-type character. The dominant
carrier type reversal from n to p type takes place at rather high NiO content
of about 60-80% in ZnO, depicting dominating contribution of ZnO into the
response. The parallel surface ionic current through chemisorbed moisture
(surface states) has been identified as a primary factor for high sensitivity
at room temperature. Thus, the presence of heterojunction barrier at the
NiO-ZnO interface assisted with the surface ionic conductivity due to adsorbed
moisture results in large, selective response to hydrogen at room temperature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:48:36 GMT""}]","2021-02-10"
"2102.04856","Anzor Beridze","Vladimer Baladze, Anzor Beridze, Leonard Mdzinarishvili","On Axiomatic Characterization of Alexander-Spanier Normal Homology
  Theory of General Topological Spaces",,,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  The Alexandroff-\v{C}ech normal cohomology theory [Mor$_1$], [Bar],
[Ba$_1$],[Ba$_2$] is the unique continuous extension \cite{Wat} of the additive
cohomology theory [Mil], [Ber-Mdz$_1$] from the category of polyhedral pairs
$\mathcal{K}^2_{Pol}$ to the category of closed normally embedded, the so
called, $P$-pairs of general topological spaces $\mathcal{K}^2_{Top}$. In this
paper we define the Alexander-Spanier normal cohomology theory based on all
normal coverings and show that it is isomorphic to the Alexandroff-\v{C}ech
normal cohomology. Using this fact and methods developed in [Ber-Mdz$_3$] we
construct an exact, the so called, Alexander-Spanier normal homology theory on
the category $\mathcal{K}^2_{Top},$ which is isomorphic to the Steenrod
homology theory on the subcategory of compact pairs $\mathcal{K}^2_{C}.$
Moreover, we give an axiomatic characterization of the constructed homology
theory.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:51:04 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 14:26:11 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 07:05:55 GMT""}]","2021-08-17"
"2102.04858","Tobias Ekholm","Johan Asplund and Tobias Ekholm","Chekanov-Eliashberg dg-algebras for singular Legendrians","33 pages, 17 figures, version accepted for publication in J.
  Symplectic Geom","J. Symplectic Geom. 20(3), 509-559, 2022","10.4310/JSG.2022.v20.n3.a1",,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Chekanov-Eliashberg dg-algebra is a holomorphic curve invariant
associated to Legendrian submanifolds of a contact manifold. We extend the
definition to Legendrian embeddings of skeleta of Weinstein manifolds. Via
Legendrian surgery, the new definition gives direct proofs of wrapped Floer
cohomology push-out diagrams. It also leads to a proof of a conjectured
isomorphism between partially wrapped Floer cohomology and Chekanov-Eliashberg
dg-algebras with coefficients in chains on the based loop space.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:51:49 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 09:58:53 GMT""}]","2023-03-02"
"2102.04860","Yimin Peng","Yimin Peng, Yunlong Li, Zijing Fang","An underwater binocular stereo matching algorithm based on the best
  search domain",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binocular stereo vision is an important branch of machine vision, which
imitates the human eye and matches the left and right images captured by the
camera based on epipolar constraints. The matched disparity map can be
calculated according to the camera imaging model to obtain a depth map, and
then the depth map is converted to a point cloud image to obtain spatial point
coordinates, thereby achieving the purpose of ranging. However, due to the
influence of illumination under water, the captured images no longer meet the
epipolar constraints, and the changes in imaging models make traditional
calibration methods no longer applicable. Therefore, this paper proposes a new
underwater real-time calibration method and a matching method based on the best
search domain to improve the accuracy of underwater distance measurement using
binoculars.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:53:07 GMT""}]","2021-02-10"
"2102.04863","Thomas Theurer","Michele Masini, Thomas Theurer, Martin B. Plenio","Coherence of operations and interferometry","5+15 pages, matches published version","Phys. Rev. A 103, 042426 (2021)","10.1103/PhysRevA.103.042426",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum coherence is one of the key features that fuels applications for
which quantum mechanics exceeds the power of classical physics. This explains
the considerable efforts that were undertaken to quantify coherence via quantum
resource theories. An application of the resulting framework to concrete
technological tasks is however largely missing. Here, we address this problem
and connect the ability of an operation to detect or create coherence to the
performance of interferometric experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:58:28 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 08:13:43 GMT""}]","2021-05-19"
"2102.04864","Pooja Devi","Pooja Devi, Jagdev Singh, Ramesh Chandra, Muthu Priyal and Reetika
  Joshi","Variation of Chromospheric Features as a Function of Latitude and Time
  using Ca-K Spectroheliograms for Solar Cycles 15-23: Implications for
  Meridional Flow","21 pages, 8 figures, 2 tables",,"10.1007/s11207-021-01798-1",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have analysed the Ca-K images obtained at Kodaikanal Observatory as a
function of latitude and time for the period of 1913 - 2004 covering the Solar
Cycle 15 to 23. We have classified the chromospheric activity into plage,
Enhanced Network (EN), Active Network (AN), and Quiet Network (QN) areas to
differentiate between large strong active and small weak active regions. The
strong active regions represent toroidal and weak active regions poloidal
component of the magnetic field. We find that plages areas mostly up to 50 deg
latitude belt vary with about 11-year Solar Cycle. We also find that weak
activity represented by EN, AN and QN varies with about 11-year with
significant amplitude up to about 50 deg latitude in both the hemispheres. The
amplitude of variation is minimum around 50 deg latitude and again increases by
small amount in the polar region. In addition, the plots of plages, EN, AN and
QN as a function of time indicate the maximum of activity at different latitude
occur at different epoch. To determine the phase difference for the different
latitude belts, we have computed the cross-correlation coefficients of other
latitude belts with 35 deg latitude belt. We find that activity shifts from
mid-latitude belts towards equatorial belts at fast speed at the beginning of
Solar Cycle and at slower speed as the cycle progresses. The speed of shift
varies between approximately 19 and 3 m/s considering all the data for the
observed period. This speed can be linked with speed of meridional flows those
believed to occur between convection zone and the surface of the Sun.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:59:25 GMT""}]","2021-03-31"
"2102.04865","Ricardo Menares","Sebasti\'an Herrero, Ricardo Menares, Juan Rivera-Letelier","p-Adic distribution of CM points and Hecke orbits. II: Linnik
  equidistribution on the supersingular locus","79 pages",,,,"math.NT math.AG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a prime number $p$, we study the asymptotic distribution of CM points on
the moduli space of elliptic curves over $\mathbb{C}_p$. In stark contrast to
the complex case, in the $p$-adic setting there are infinitely many different
measures describing the asymptotic distribution of CM points. In this paper we
identify all of these measures. A key insight is to translate this problem into
a $p$-adic version of Linnik's classical problem on the asymptotic distribution
of integer points on spheres. To do this translation, we use the close
relationship between the deformation theories of elliptic curves and formal
modules and then apply results of Gross and Hopkins. We solve this $p$-adic
Linnik problem using a deviation estimate extracted from the bounds for the
Fourier coefficients of cuspidal modular forms of Deligne, Iwaniec and Duke. We
also identify all accumulation measures of an arbitrary Hecke orbit.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:59:39 GMT""}]","2021-02-10"
"2102.04866","Jennifer Hobbs","Jennifer Hobbs, Ivan Dozier, Naira Hovakimyan","Residue Density Segmentation for Monitoring and Optimizing Tillage
  Practices",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ""No-till"" and cover cropping are often identified as the leading simple, best
management practices for carbon sequestration in agriculture. However, the root
of the problem is more complex, with the potential benefits of these approaches
depending on numerous factors including a field's soil type(s), topography, and
management history. Instead of using computer vision approaches to simply
classify a field a still vs. no-till, we instead seek to identify the degree of
residue coverage across afield through a probabilistic deep learning
segmentation approach to enable more accurate analysis of carbon holding
potential and realization. This approach will not only provide more precise
insights into currently implemented practices, but also enable a more accurate
identification process of fields with the greatest potential for adopting new
practices to significantly impact carbon sequestration in agriculture.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:00:45 GMT""}]","2021-02-10"
"2102.04867","G.R. Boroun","G.R.Boroun","Physical limits in the Color Dipole Model Bounds",,"Eur. Phys. J. A 57, 219 (2021)","10.1140/epja/s10050-021-00517-5",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The ratio of the cross sections for the transversely and longitudinally
virtual photon polarizations, $\sigma^{\gamma^{*}p}_{L/T}$, at high
photon-hadron energy scattering is studied. I investigate the relationship
between the gluon distribution obtained using the color dipole model and
standard gluons obtained from the Dokshitzer-Gribov-Lipatov-Altarelli-Parisi
(DGLAP) evolution and the Altarelli-Martinelli equations. It is shown that the
color dipole bounds are dependent on the gluon distribution behavior. This
behavior is considered by the expansion and Laplace transform methods.
Numerical calculations and comparison with the color dipole model (CDM) bounds
can indicate the range of validity of this method at small dipole sizes, $r\sim
1/Q{\ll}1/Q_{s}$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:02:56 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 11:03:05 GMT""},{""version"":""v3"",""created"":""Tue, 4 May 2021 04:13:45 GMT""}]","2021-07-07"
"2102.04868","Zelalem Arega Worku","Zelalem Arega Worku and David W. Zingg","Stability and Functional Superconvergence of Narrow-Stencil
  Second-Derivative Generalized Summation-By-Parts Discretizations","21 pages, 8 figures","Journal of Scientific Computing, 90:42 (2022)","10.1007/s10915-021-01707-5",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the stability and functional superconvergence of discretizations
of diffusion problems with the narrow-stencil second-derivative generalized
summation-by-parts (SBP) operators coupled with simultaneous approximation
terms (SATs). Provided that the primal and adjoint solutions are sufficiently
smooth and the SBP-SAT discretization is primal and adjoint consistent, we show
that linear functionals associated with the steady diffusion problem
superconverge at a rate of $ 2p $ when a degree $ p+1 $ narrow-stencil or a
degree $ p $ wide-stencil generalized SBP operator is used for the spatial
discretization. Sufficient conditions for stability of adjoint consistent
discretizations with the narrow-stencil generalized SBP operators are
presented. The stability analysis assumes nullspace consistency of the
second-derivative operator and the invertibility of the matrix approximating
the first derivative at the element boundaries. The theoretical results are
verified by numerical experiments with the one-dimensional Poisson problem.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:03:51 GMT""}]","2021-12-21"
"2102.04869","Hojjat Salehinejad","Hojjat Salehinejad, Jumpei Kitamura, Noah Ditkofsky, Amy Lin, Aditya
  Bharatha, Suradech Suthiphosuwan, Hui-Ming Lin, Jefferson R. Wilson, Muhammad
  Mamdani, and Errol Colak","A Real-World Demonstration of Machine Learning Generalizability:
  Intracranial Hemorrhage Detection on Head CT","This paper is under review",,"10.1038/s41598-021-95533-2",,"eess.IV cs.CV cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning (ML) holds great promise in transforming healthcare. While
published studies have shown the utility of ML models in interpreting medical
imaging examinations, these are often evaluated under laboratory settings. The
importance of real world evaluation is best illustrated by case studies that
have documented successes and failures in the translation of these models into
clinical environments. A key prerequisite for the clinical adoption of these
technologies is demonstrating generalizable ML model performance under real
world circumstances. The purpose of this study was to demonstrate that ML model
generalizability is achievable in medical imaging with the detection of
intracranial hemorrhage (ICH) on non-contrast computed tomography (CT) scans
serving as the use case. An ML model was trained using 21,784 scans from the
RSNA Intracranial Hemorrhage CT dataset while generalizability was evaluated
using an external validation dataset obtained from our busy trauma and
neurosurgical center. This real world external validation dataset consisted of
every unenhanced head CT scan (n = 5,965) performed in our emergency department
in 2019 without exclusion. The model demonstrated an AUC of 98.4%, sensitivity
of 98.8%, and specificity of 98.0%, on the test dataset. On external
validation, the model demonstrated an AUC of 95.4%, sensitivity of 91.3%, and
specificity of 94.1%. Evaluating the ML model using a real world external
validation dataset that is temporally and geographically distinct from the
training dataset indicates that ML generalizability is achievable in medical
imaging applications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:05:48 GMT""}]","2021-08-24"
"2102.04870","Ilya Eremin","Anatoly F. Volkov and Ilya M. Eremin","Note on possibility of proximity induced spontaneous currents in
  superconductor/normal metal heterostructures","6 pages, the anaylsis includes the contribution of the boundary to
  the free energy, absent in the previous version. The conclusions are modified",,,,"cond-mat.supr-con cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse the possibility of the appearance of spontaneous currents in
proximated superconducting/normal metal (S/N) heterostructure when Cooper pairs
penetrate into the normal metal from the superconductor. In particular, we
calculate the free energy of the S/N structure. We show that whereas the free
energy of the N film $F_{N}$ in the presence of the proximity effect increases
compared to the normal state, the total free energy, which includes the
boundary term $F_{B}$, decreases. The condensate current decreases $F_{N}$, but
increases the total free energy making the current-carrying state of the S/N
system energetically unfavorable.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:10:45 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 21:07:34 GMT""}]","2021-03-02"
"2102.04871","Kenneth Reid","Kenneth N. Reid, Iliya Miralavy, Stephen Kelly, Wolfgang Banzhaf,
  Cedric Gondro","The Factory Must Grow: Automation in Factorio","Submitted to GECCO 2021",,,,"cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  Efficient optimization of resources is paramount to success in many problems
faced today. In the field of operational research the efficient scheduling of
employees; packing of vans; routing of vehicles; logistics of airlines and
transport of materials can be the difference between emission reduction or
excess, profits or losses and feasibility or unworkable solutions. The video
game Factorio, by Wube Software, has a myriad of problems which are analogous
to such real-world problems, and is a useful simulator for developing solutions
for these problems. In this paper we define the logistic transport belt problem
and define mathematical integer programming model of it. We developed an
interface to allow optimizers in any programming language to interact with
Factorio, and we provide an initial benchmark of logistic transport belt
problems. We present results for Simulated Annealing, quick Genetic Programming
and Evolutionary Reinforcement Learning, three different meta-heuristic
techniques to optimize this novel problem.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:14:27 GMT""}]","2021-02-10"
"2102.04872","Luca Moscadelli","L. Moscadelli, H. Beuther, A. Ahmadi, C. Gieser, F. Massi, R.
  Cesaroni, \'A. S\'anchez-Monge, F. Bacciotti, M.T. Beltr\'an, T. Csengeri, R.
  Galv\'an-Madrid, Th. Henning, P.D. Klaassen, R. Kuiper, S. Leurini, S.N.
  Longmore, L.T. Maud, T. M\""oller, A. Palau, T. Peters, R.E. Pudritz, A.
  Sanna, D. Semenov, J.S. Urquhart, J.M. Winters, and H. Zinnecker","Multi-scale view of star formation in IRAS 21078+5211: From clump
  fragmentation to disk wind","25 pages, 16 figures","A&A 647, A114 (2021)","10.1051/0004-6361/202039837",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the massive star-forming region IRAS 21078+5211, a highly fragmented
cluster (0.1~pc in size) of molecular cores is observed, located at the density
peak of an elongated (1~pc in size) molecular cloud. A small (1~km/s per
0.1~pc) LSR velocity (Vlsr) gradient is detected across the axis of the
molecular cloud. Assuming we are observing a mass flow from the harboring cloud
to the cluster, we derive a mass infall rate of about 10^{-4}~M_{sun}~yr^{-1}.
The most massive cores (labeled 1, 2, and 3) are found at the center of the
cluster, and these are the only ones that present a signature of protostellar
activity in terms of emission from high-excitation molecular lines or a
molecular outflow. We reveal an extended (size about 0.1~pc), bipolar
collimated molecular outflow emerging from core 1. We believe this is powered
by a (previously discovered) compact (size <= 1000~au) radio jet, ejected by a
YSO embedded in core 1 (named YSO-1), since the molecular outflow and the radio
jet are almost parallel and have a comparable momentum rate. By means of
high-excitation lines, we find a large (14~km/s over 500~au) Vlsr gradient at
the position of YSO-1, oriented approximately perpendicular to the radio jet.
Assuming this is an edge-on, rotating disk and fitting a Keplerian rotation
pattern, we determine the YSO-1 mass to be 5.6+/-2.0~M_{sun}. The water masers
(previously observed with VLBI) emerge within 100-300~au from YSO-1 and are
unique tracers of the jet kinematics. Their three-dimensional (3D) velocity
pattern reveals that the gas flows along, and rotates about, the jet axis. We
show that the 3D maser velocities are fully consistent with the
magneto-centrifugal disk-wind models predicting a cylindrical rotating jet.
Under this hypothesis, we determine the jet radius to be about 16~au and the
corresponding launching radius and terminal velocity to be about 2.2~au and
200~km/s, respectively.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:17:20 GMT""}]","2021-03-17"
"2102.04873","Marija Tepegjozova","Marija Tepegjozova, Jing Zhou, Gerda Claeskens and Claudia Czado","Nonparametric C- and D-vine based quantile regression",,,"10.1515/demo-2022-0100",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantile regression is a field with steadily growing importance in
statistical modeling. It is a complementary method to linear regression, since
computing a range of conditional quantile functions provides a more accurate
modelling of the stochastic relationship among variables, especially in the
tails. We introduce a non-restrictive and highly flexible nonparametric
quantile regression approach based on C- and D-vine copulas. Vine copulas allow
for separate modeling of marginal distributions and the dependence structure in
the data, and can be expressed through a graph theoretical model given by a
sequence of trees. This way we obtain a quantile regression model, that
overcomes typical issues of quantile regression such as quantile crossings or
collinearity, the need for transformations and interactions of variables. Our
approach incorporates a two-step ahead ordering of variables, by maximizing the
conditional log-likelihood of the tree sequence, while taking into account the
next two tree levels. Further, we show that the nonparametric conditional
quantile estimator is consistent. The performance of the proposed methods is
evaluated in both low- and high-dimensional settings using simulated and real
world data. The results support the superior prediction ability of the proposed
models.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:17:50 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 21:34:47 GMT""}]","2022-05-09"
"2102.04874","Murwan Siddig","Murwan Siddig, Yongjia Song, Amin Khademi","Rolling Horizon Policies in Multistage Stochastic Programming",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multistage Stochastic Programming (MSP) is a class of models for sequential
decision-making under uncertainty. MSP problems are known for their
computational intractability due to the sequential nature of the
decision-making structure and the uncertainty in the problem data due to the
so-called curse of dimensionality. A common approach to tackle MSP problems
with a large number of stages is a rolling-horizon (RH) procedure, where one
solves a sequence of MSP problems with a smaller number of stages. This leads
to a delicate issue of how many stages to include in the smaller problems used
in the RH procedure. This paper addresses this question for, both, finite and
infinite horizon MSP problems. For the infinite horizon case with discounted
costs, we derive a bound which can be used to prescribe an epsilon-sufficient
number of stages. For the finite horizon case, we propose a heuristic approach
from the perspective of approximate dynamic programming to provide a sufficient
number of stages for each roll in the RH procedure. Our numerical experiments
on a hydrothermal power generation planning problem show the effectiveness of
the proposed approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:18:07 GMT""}]","2021-02-10"
"2102.04875","Parwat Singh Anjana","Parwat Singh Anjana, Sweta Kumari, Sathya Peri, Sachin Rathor, Archit
  Somani","OptSmart: A Space Efficient Optimistic Concurrent Execution of Smart
  Contracts","43 pages, 13 figure, 1 Table",,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Popular blockchains such as Ethereum and several others execute complex
transactions in blocks through user-defined scripts known as smart contracts.
Serial execution of smart contract transactions/atomic-units (AUs) fails to
harness the multiprocessing power offered by the prevalence of multi-core
processors. By adding concurrency to the execution of AUs, we can achieve
better efficiency and higher throughput.
  In this paper, we develop a concurrent miner that proposes a block by
executing the AUs concurrently using optimistic Software Transactional Memory
systems (STMs). It captures the independent AUs in a concurrent bin and
dependent AUs in the block graph (BG) efficiently. Later, we propose a
concurrent validator that re-executes the same AUs concurrently and
deterministically using a concurrent bin followed by a BG given by the miner to
verify the proposed block. We rigorously prove the correctness of concurrent
execution of AUs and achieve significant performance gain over the
state-of-the-art.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:18:42 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 06:20:02 GMT""}]","2021-02-18"
"2102.04876","Sylvain Douteau","Sylvain Douteau","A stratified Kan-Quillen equivalence","33 pages",,,,"math.AT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We exhibit a Quillen equivalence between two model categories encoding the
homotopy theory of stratified spaces : the model category of filtered
simplicial sets, and that of filtered spaces. Additionally, we introduce a new
class of filtered spaces, that of vertical filtered CW-complexes, providing a
nice model for the homotopy category of stratified spaces.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:18:44 GMT""}]","2021-02-10"
"2102.04877","Soon Hoe Lim","Soon Hoe Lim, N. Benjamin Erichson, Liam Hodgkinson, Michael W.
  Mahoney","Noisy Recurrent Neural Networks","38 pages","NeurIPS 2021
  (https://proceedings.neurips.cc/paper/2021/hash/29301521774ff3cbd26652b2d5c95996-Abstract.html)",,,"stat.ML cs.LG math.DS math.PR","http://creativecommons.org/licenses/by/4.0/","  We provide a general framework for studying recurrent neural networks (RNNs)
trained by injecting noise into hidden states. Specifically, we consider RNNs
that can be viewed as discretizations of stochastic differential equations
driven by input data. This framework allows us to study the implicit
regularization effect of general noise injection schemes by deriving an
approximate explicit regularizer in the small noise regime. We find that, under
reasonable assumptions, this implicit regularization promotes flatter minima;
it biases towards models with more stable dynamics; and, in classification
tasks, it favors models with larger classification margin. Sufficient
conditions for global stability are obtained, highlighting the phenomenon of
stochastic stabilization, where noise injection can improve stability during
training. Our theory is supported by empirical results which demonstrate that
the RNNs have improved robustness with respect to various input perturbations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:20:50 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 17:08:10 GMT""},{""version"":""v3"",""created"":""Wed, 1 Dec 2021 09:25:20 GMT""}]","2021-12-02"
"2102.04879","Fotios Petropoulos","Spyros Makridakis, Chris Fry, Fotios Petropoulos and Evangelos
  Spiliotis","The future of forecasting competitions: Design attributes and principles",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Forecasting competitions are the equivalent of laboratory experimentation
widely used in physical and life sciences. They provide useful, objective
information to improve the theory and practice of forecasting, advancing the
field, expanding its usage and enhancing its value to decision and
policymakers. We describe ten design attributes to be considered when
organizing forecasting competitions, taking into account trade-offs between
optimal choices and practical concerns like costs, as well as the time and
effort required to participate in them. Consequently, we map all major past
competitions in respect to their design attributes, identifying similarities
and differences between them, as well as design gaps, and making suggestions
about the principles to be included in future competitions, putting a
particular emphasis on learning as much as possible from their implementation
in order to help improve forecasting accuracy and uncertainty. We discuss that
the task of forecasting often presents a multitude of challenges that can be
difficult to be captured in a single forecasting contest. To assess the caliber
of a forecaster, we, therefore, propose that organizers of future competitions
consider a multi-contest approach. We suggest the idea of a forecasting
""athlon"", where different challenges of varying characteristics take place.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:24:07 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 11:10:30 GMT""}]","2021-05-20"
"2102.04881","Florian E. Dorner","Florian E. Dorner","Measuring Progress in Deep Reinforcement Learning Sample Efficiency","26 pages, 6 figures, 5 tables",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sampled environment transitions are a critical input to deep reinforcement
learning (DRL) algorithms. Current DRL benchmarks often allow for the cheap and
easy generation of large amounts of samples such that perceived progress in DRL
does not necessarily correspond to improved sample efficiency. As simulating
real world processes is often prohibitively hard and collecting real world
experience is costly, sample efficiency is an important indicator for
economically relevant applications of DRL. We investigate progress in sample
efficiency on Atari games and continuous control tasks by comparing the number
of samples that a variety of algorithms need to reach a given performance level
according to training curves in the corresponding publications. We find
exponential progress in sample efficiency with estimated doubling times of
around 10 to 18 months on Atari, 5 to 24 months on state-based continuous
control and of around 4 to 9 months on pixel-based continuous control depending
on the specific task and performance level.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:27:47 GMT""}]","2021-02-10"
"2102.04883","Titus Neupert","Titus Neupert, Mark H Fischer, Eliska Greplova, Kenny Choo, M. Michael
  Denner","Introduction to Machine Learning for the Sciences","84 pages, 37 figures. The content of these lecture notes together
  with exercises is available under http://www.ml-lectures.org. A shorter
  German version of the lecture notes is published in the Springer essential
  series, ISBN 978-3-658-32268-7, doi:10.1007/978-3-658-32268-7",,,,"physics.comp-ph cond-mat.dis-nn cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is an introductory machine-learning course specifically developed with
STEM students in mind. Our goal is to provide the interested reader with the
basics to employ machine learning in their own projects and to familiarize
themself with the terminology as a foundation for further reading of the
relevant literature. In these lecture notes, we discuss supervised,
unsupervised, and reinforcement learning. The notes start with an exposition of
machine learning methods without neural networks, such as principle component
analysis, t-SNE, clustering, as well as linear regression and linear
classifiers. We continue with an introduction to both basic and advanced
neural-network structures such as dense feed-forward and conventional neural
networks, recurrent neural networks, restricted Boltzmann machines,
(variational) autoencoders, generative adversarial networks. Questions of
interpretability are discussed for latent-space representations and using the
examples of dreaming and adversarial attacks. The final section is dedicated to
reinforcement learning, where we introduce basic notions of value functions and
policy learning.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:25:46 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 09:45:26 GMT""}]","2022-06-23"
"2102.04884","Mingkang Wang","Mingkang Wang, Diego J. Perez-Morelo, Vladimir Aksyuk","Using thermo-optical nonlinearity to robustly separate absorption and
  radiation losses in nanophotonic resonators",,"Optics Express Vol. 29, Issue 5, pp. 6967-6979 (2021)","10.1364/OE.416576",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-loss nanophotonic resonators have been widely used in fundamental science
and applications thanks to their ability to concentrate optical energy. Key for
resonator engineering, the total intrinsic loss is easily determined by
spectroscopy, however, quantitatively separating absorption and radiative
losses is challenging. While the concentrated heat generated by absorption
within the small mode volume results in generally unwanted thermo-optical
effects, they can provide a way for quantifying absorption. Here, we propose
and experimentally demonstrate a technique for separating the loss mechanisms
with high confidence using only linear spectroscopic measurements. We use the
optically measured resonator thermal time constant to experimentally connect
the easily-calculable heat capacity to the thermal impedance, needed to
calculate the absorbed power from the temperature change. We report the
absorption, radiation, and coupling losses for ten whispering-gallery modes of
three different radial orders on a Si microdisk. Similar absorptive loss rates
are found for all the modes, despite order-of-magnitude differences in the
total dissipation rate due to widely differing radiation losses. Measuring
radiation losses of many modes enables distinguishing the two major components
of radiation loss originating from scattering and leakage. The all-optical
characterization technique is applicable to any nanophotonic resonators subject
to thermo-optical effects.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:32:07 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 19:19:45 GMT""}]","2021-02-23"
"2102.04885","\'Eric Dupuis","\'Eric Dupuis, William Witczak-Krempa","Monopole hierarchy in transitions out of a Dirac spin liquid","46 pages. Paper submitted to a special issue of Annals of Physics
  dedicated to Philip W. Anderson",,"10.1016/j.aop.2021.168496",,"cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum spin liquids host novel emergent excitations, such as monopoles of an
emergent gauge field. Here, we study the hierarchy of monopole operators that
emerges at quantum critical points (QCPs) between a two-dimensional Dirac spin
liquid and various ordered phases. This is described by a confinement
transition of quantum electrodynamics in two spatial dimensions (QED3
Gross-Neveu theories). Focusing on a spin ordering transition, we get the
scaling dimension of monopoles at leading order in a large-N expansion, where
2N is the number of Dirac fermions, as a function of the monopole's total
magnetic spin. Monopoles with a maximal spin have the smallest scaling
dimension while monopoles with a vanishing magnetic spin have the largest one,
the same as in pure QED3. The organization of monopoles in multiplets of the
QCP's symmetry group SU(2) x SU(N) is shown for general N.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:34:09 GMT""}]","2022-01-05"
"2102.04886","Antonio Lotta","D. Di Pinto, A. Lotta","On Einstein hypersurfaces of a remarkable class of Sasakian manifolds","arXiv admin note: text overlap with arXiv:2006.07922",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a non existence result of complete, Einstein hypersurfaces tangent
to the Reeb vector field of a regular Sasakian manifold which fibers onto a
complex Stein manifold.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:38:07 GMT""}]","2021-02-10"
"2102.04887","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Yang Yu, Tao Qi, Yongfeng Huang, Qi Liu","NewsBERT: Distilling Pre-trained Language Model for Intelligent News
  Application",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained language models (PLMs) like BERT have made great progress in NLP.
News articles usually contain rich textual information, and PLMs have the
potentials to enhance news text modeling for various intelligent news
applications like news recommendation and retrieval. However, most existing
PLMs are in huge size with hundreds of millions of parameters. Many online news
applications need to serve millions of users with low latency tolerance, which
poses huge challenges to incorporating PLMs in these scenarios. Knowledge
distillation techniques can compress a large PLM into a much smaller one and
meanwhile keeps good performance. However, existing language models are
pre-trained and distilled on general corpus like Wikipedia, which has some gaps
with the news domain and may be suboptimal for news intelligence. In this
paper, we propose NewsBERT, which can distill PLMs for efficient and effective
news intelligence. In our approach, we design a teacher-student joint learning
and distillation framework to collaboratively learn both teacher and student
models, where the student model can learn from the learning experience of the
teacher model. In addition, we propose a momentum distillation method by
incorporating the gradients of teacher model into the update of student model
to better transfer useful knowledge learned by the teacher model. Extensive
experiments on two real-world datasets with three tasks show that NewsBERT can
effectively improve the model performance in various intelligent news
applications with much smaller models.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:41:12 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 08:09:42 GMT""}]","2021-09-03"
"2102.04888","Feng Fu","Matthew I. Jones, Scott D. Pauls, Feng Fu","Random Choices can Facilitate the Solving of Collective Network Coloring
  Problems by Artificial Agents","Comments are welcome",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Global coordination is required to solve a wide variety of challenging
collective action problems from network colorings to the tragedy of the
commons. Recent empirical study shows that the presence of a few noisy
autonomous agents can greatly improve collective performance of humans in
solving networked color coordination games. To provide further analytical
insights into the role of behavioral randomness, here we study myopic
artificial agents attempt to solve similar network coloring problems using
decision update rules that are only based on local information but allow random
choices at various stages of their heuristic reasonings. We consider that
agents are distributed over a random bipartite network which is guaranteed to
be solvable with two colors. Using agent-based simulations and theoretical
analysis, we show that the resulting efficacy of resolving color conflicts is
dependent on the specific implementation of random behavior of agents,
including the fraction of noisy agents and at which decision stage noise is
introduced. Moreover, behavioral randomness can be finely tuned to the specific
underlying population structure such as network size and average network degree
in order to produce advantageous results in finding collective coloring
solutions. Our work demonstrates that distributed greedy optimization
algorithms exploiting local information should be deployed in combination with
occasional exploration via random choices in order to overcome local minima and
achieve global coordination.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:41:17 GMT""}]","2021-02-10"
"2102.04889","Antonios Anastasopoulos","Claytone Sikasote and Antonios Anastasopoulos","BembaSpeech: A Speech Recognition Corpus for the Bemba Language",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a preprocessed, ready-to-use automatic speech recognition corpus,
BembaSpeech, consisting over 24 hours of read speech in the Bemba language, a
written but low-resourced language spoken by over 30% of the population in
Zambia. To assess its usefulness for training and testing ASR systems for
Bemba, we train an end-to-end Bemba ASR system by fine-tuning a pre-trained
DeepSpeech English model on the training portion of the BembaSpeech corpus. Our
best model achieves a word error rate (WER) of 54.78%. The results show that
the corpus can be used for building ASR systems for Bemba. The corpus and
models are publicly released at https://github.com/csikasote/BembaSpeech.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:42:00 GMT""}]","2021-02-10"
"2102.04890","Mahdi Torabi Rad Ph.D.","M. Torabi Rad, A. Viardin, and M. Apel","On Theory-training Neural Networks to Infer the Solution of Highly
  Coupled Differential Equations",,,,,"cs.LG physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks are transforming fields ranging from computer vision to
computational medicine, and we recently extended their application to the field
of phase-change heat transfer by introducing theory-trained neural networks
(TTNs) for a solidification problem \cite{TTN}. Here, we present general,
in-depth, and empirical insights into theory-training networks for learning the
solution of highly coupled differential equations. We analyze the deteriorating
effects of the oscillating loss on the ability of a network to satisfy the
equations at the training data points, measured by the final training loss, and
on the accuracy of the inferred solution. We introduce a theory-training
technique that, by leveraging regularization, eliminates those oscillations,
decreases the final training loss, and improves the accuracy of the inferred
solution, with no additional computational cost. Then, we present guidelines
that allow a systematic search for the network that has the optimal training
time and inference accuracy for a given set of equations; following these
guidelines can reduce the number of tedious training iterations in that search.
Finally, a comparison between theory-training and the rival, conventional
method of solving differential equations using discretization attests to the
advantages of theory-training not being necessarily limited to high-dimensional
sets of equations. The comparison also reveals a limitation of the current
theory-training framework that may limit its application in domains where
extreme accuracies are necessary.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:45:08 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 09:52:18 GMT""}]","2021-02-11"
"2102.04891","Piet Van Mieghem","P. Van Mieghem","Binet's factorial series and extensions to Laplace transforms","We have integrated Gilbert's investigations of 1876",,,"Delft University of Technology, report20210202","math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a generalization of Binet's factorial series in the parameter
$\alpha$ \[ \mu\left( z\right) =\sum_{m=1}^{\infty}\frac{b_{m}\left(
\alpha\right) }{\prod_{k=0}^{m-1}(z+\alpha+k)}% \] due to Gilbert, for the
Binet function \[ \mu\left( z\right) =\log\Gamma\left( z\right) -\left(
z-\frac{1} {2}\right) \log z+z-\frac{1}{2}\log\left( 2\pi\right) \] After a
review of the Binet function $\mu\left( z\right) $ and Gilbert's investigations
of $\mu\left( z\right) $, several properties of the Binet polynomials
$b_{m}\left( \alpha\right) $ are presented. We compare Gilbert's generalized
factorial series with Stirling's asymptotic expansion and demonstrate by a
numerical example that, with a same number of terms evaluated, the Gilbert
generalized factorial series with an optimized value of $\alpha$ can beat the
best possible accuracy of Stirling's expansion. Finally, we extend Binet's
method to factorial series of Laplace transforms.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:47:37 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 14:26:55 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 13:12:08 GMT""},{""version"":""v4"",""created"":""Tue, 6 Apr 2021 14:27:22 GMT""},{""version"":""v5"",""created"":""Fri, 13 Aug 2021 13:29:22 GMT""},{""version"":""v6"",""created"":""Sun, 26 Sep 2021 13:13:09 GMT""},{""version"":""v7"",""created"":""Thu, 16 Feb 2023 09:42:38 GMT""}]","2023-02-17"
"2102.04892","Manoj B. R.","B. R. Manoj, Guoda Tian, Sara Gunnarsson, Fredrik Tufvesson, Erik G.
  Larsson","Moving Object Classification with a Sub-6 GHz Massive MIMO Array using
  Real Data","To be published in proceedings of IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP) 2021",,,,"cs.IT cs.LG eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classification between different activities in an indoor environment using
wireless signals is an emerging technology for various applications, including
intrusion detection, patient care, and smart home. Researchers have shown
different methods to classify activities and their potential benefits by
utilizing WiFi signals. In this paper, we analyze classification of moving
objects by employing machine learning on real data from a massive
multi-input-multi-output (MIMO) system in an indoor environment. We conduct
measurements for different activities in both line-of-sight and non
line-of-sight scenarios with a massive MIMO testbed operating at 3.7 GHz. We
propose algorithms to exploit amplitude and phase-based features classification
task. For the considered setup, we benchmark the classification performance and
show that we can achieve up to 98% accuracy using real massive MIMO data, even
with a small number of experiments. Furthermore, we demonstrate the gain in
performance results with a massive MIMO system as compared with that of a
limited number of antennas such as in WiFi devices.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:48:35 GMT""}]","2021-02-10"
"2102.04894","Sara Bernardi","Sara Bernardi, Raluca Eftimie, Kevin J. Painter","Leadership through influence: what mechanisms allow leaders to steer a
  swarm?",,,,,"q-bio.PE math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collective migration of cells and animals often relies on a specialised set
of ""leaders"", whose role is to steer a population of naive followers towards
some target. We formulate a continuous model to understand the dynamics and
structure of such groups, splitting a population into separate follower and
leader types with distinct orientation responses. We incorporate ""leader
influence"" via three principal mechanisms: a bias in the orientation of leaders
according to the destination, distinct speeds of movement and distinct levels
of conspicuousness. Using a combination of analysis and numerical computation
on a sequence of models of increasing complexity, we assess the extent to which
leaders successfully shepherd the swarm. While all three mechanisms can lead to
a successfully steered swarm, parameter regime is crucial with non successful
choices generating a variety of unsuccessful attempts, including movement away
from the target, swarm splitting or swarm dispersal.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:50:34 GMT""}]","2021-02-10"
"2102.04895","John Gallacer","John D Gallacher","Leveraging cross-platform data to improve automated hate speech
  detection","34 pages, 10 figures",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Hate speech is increasingly prevalent online, and its negative outcomes
include increased prejudice, extremism, and even offline hate crime. Automatic
detection of online hate speech can help us to better understand these impacts.
However, while the field has recently progressed through advances in natural
language processing, challenges still remain. In particular, most existing
approaches for hate speech detection focus on a single social media platform in
isolation. This limits both the use of these models and their validity, as the
nature of language varies from platform to platform. Here we propose a new
cross-platform approach to detect hate speech which leverages multiple datasets
and classification models from different platforms and trains a superlearner
that can combine existing and novel training data to improve detection and
increase model applicability. We demonstrate how this approach outperforms
existing models, and achieves good performance when tested on messages from
novel social media platforms not included in the original training data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:52:34 GMT""}]","2021-02-10"
"2102.04897","Zeyu Zheng","Zeyu Zheng, Vivek Veeriah, Risto Vuorio, Richard Lewis, Satinder Singh","Learning State Representations from Random Deep Action-conditional
  Predictions","NeurIPS 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our main contribution in this work is an empirical finding that random
General Value Functions (GVFs), i.e., deep action-conditional predictions --
random both in what feature of observations they predict as well as in the
sequence of actions the predictions are conditioned upon -- form good auxiliary
tasks for reinforcement learning (RL) problems. In particular, we show that
random deep action-conditional predictions when used as auxiliary tasks yield
state representations that produce control performance competitive with
state-of-the-art hand-crafted auxiliary tasks like value prediction, pixel
control, and CURL in both Atari and DeepMind Lab tasks. In another set of
experiments we stop the gradients from the RL part of the network to the state
representation learning part of the network and show, perhaps surprisingly,
that the auxiliary tasks alone are sufficient to learn state representations
good enough to outperform an end-to-end trained actor-critic baseline. We
opensourced our code at https://github.com/Hwhitetooth/random_gvfs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:53:22 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 18:19:02 GMT""}]","2021-11-09"
"2102.04899","Ashley Wilkins","Ashley Wilkins, Gerasimos Rigopoulos and Enrico Masoero","Coarse-graining in time with the Functional Renormalisation Group:
  Relaxation in Brownian Motion","26 pages, 16 figures, 1 tables, 3 Appendices. Minor changes from
  version 2 include black and white friendly plots. Matches version accepted
  for publication in PRE. arXiv admin note: text overlap with arXiv:2008.00472",,"10.1103/PhysRevE.106.054109",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the functional Renormalisation Group (fRG) to study relaxation in a
stochastic process governed by an overdamped Langevin equation with one degree
of freedom, exploiting the connection with supersymmetric quantum mechanics in
imaginary time. After reviewing the functional integral formulation of the
system and its underlying symmetries, including the resulting Ward-Takahashi
identities for arbitrary initial conditions, we compute the effective action
$\Gamma$ from the fRG, approximated in terms of the leading and subleading
terms in the gradient expansion: the Local Potential Approximation and
Wavefunction Renormalisation respectively. This is achieved by coarse-graining
the thermal fluctuations in time resulting in e.g. an effective potential
incorporating fluctuations at all timescales. We then use the resulting
effective equations of motion to describe the decay of the covariance, and the
relaxation of the average position and variance towards their equilibrium
values at different temperatures. We use as examples a simple polynomial
potential, an unequal Lennard-Jones type potential and a more complex potential
with multiple trapping wells and barriers. We find that these are all handled
well, with the accuracy of the approximations improving as the relaxation's
spectral representation shifts to lower eigenvalues, in line with expectations
about the validity of the gradient expansion. The spectral representation's
range also correlates with temperature, leading to the conclusion that the
gradient expansion works better for higher temperatures than lower ones. This
work demonstrates the ability of the fRG to expedite the computation of
statistical objects in otherwise long-timescale simulations, acting as a first
step to more complicated systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:55:16 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 11:29:41 GMT""},{""version"":""v3"",""created"":""Mon, 31 Oct 2022 15:40:31 GMT""}]","2023-06-06"
"2102.04900","Peng Luo","Hua Chen, Peng Luo","The spectral gap to torsion problem for some non-convex domains","18pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the following torsion problem \begin{equation*}
\begin{cases} -\Delta u=1~&\mbox{in}\ \Omega,\\[1mm] u=0~&\mbox{on}\
\partial\Omega. \end{cases} \end{equation*} Let $\Omega\subset \mathbb{R}^2$ be
a bounded, convex domain and $u_0(x)$ be the solution of above problem with its
maximum $y_0\in \Omega$. Steinerberger proved that there are universal
constants $c_1, c_2>0$ satisfying \begin{equation*}
\lambda_{\max}\left(D^2u_0(y_0)\right)\leq
-c_1\mbox{exp}\left(-c_2\frac{\text{diam}(\Omega)}{\mbox{inrad}(\Omega)}\right).
\end{equation*} And he proposed following open problem:
  ""Does above result hold true on domains that are not convex but merely simply
connected or perhaps only bounded? The proof uses convexity of the domain
$\Omega$ in a very essential way and it is not clear to us whether the
statement remains valid in other settings.""
  Here by some new idea involving the computations on Green's function, we
compute the spectral gap $\lambda_{\max}D^2u(y_0)$ for some non-convex smooth
bounded domains, which gives a negative answer to above open problem. Also some
extensions are given.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:56:09 GMT""}]","2021-02-10"
"2102.04901","Yan Li","Yan Li, Rong-Feng Shen","Estimates of the early EM emission from compact binary mergers","16 pages, 6 Figures. Accepted for publication in ApJ",,"10.3847/1538-4357/abe462",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Compact binary mergers that involve at least one neutron star, either binary
neutron star or black hole--neutron star coalescences, are thought to be the
potential sources of electromagnetic emission due to the material ejected
during the merger or those left outside the central object after the merger.
Since the intensity of these electromagnetic transients decay rapidly with
time, one should pay more attention to early emissions from such events, which
are useful in revealing the nature of these mergers. In this work, we study the
early emission of kilonovae, short $\gamma$-ray bursts and cocoons that could
be produced in those mergers. We estimate their luminosities and time scales as
functions of the chirp mass which is the most readily constrained parameter
from the gravitational wave detections of these events. We focus on the range
of chirp mass as $1.3M_{\odot} -2.7M_{\odot}$ which is compatible with one of
the merging component being a so-called `mass gap' black hole. We show that the
electromagnetic observation of these transients could be used to distinguish
the types of the mergers when the detected chirp mass falls in the range of
$1.5M_{\odot}-1.7M_{\odot}$. Applying our analysis to the sub-threshold GRB
GBM-190816, we found that for this particular event the effective spin should
be larger than 0.6 and the mass of the heavier object might be larger than
5.5$M_{\odot}$ for the SFHo equation of state.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:57:18 GMT""}]","2021-04-28"
"2102.04902","Alexander Balandin","Zahra Barani, Fariborz Kargar, Yassamin Ghafouri, Saba Baraghani,
  Sriharsha Sudhindra, Amirmahdi Mohammadzadeh, Tina T. Salguero, and Alexander
  A. Balandin","Electromagnetic-Polarization Selective Composites with Quasi-1D van der
  Waals Metallic Fillers","20 pages, 6 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the preparation of flexible polymer composite films with aligned
metallic fillers comprised of atomic chain bundles of the quasi-one-dimensional
(1D) van der Waals material tantalum triselenide, TaSe3. The material
functionality, embedded at the nanoscale level, is achieved by mimicking the
design of an electromagnetic aperture grid antenna. The processed composites
employ chemically exfoliated TaSe3 nanowires as the grid building blocks
incorporated within the thin film. Filler alignment is achieved using the
""blade coating"" method. Measurements conducted in the X-band frequency range
demonstrate that the electromagnetic transmission through such films can be
varied significantly by changing the relative orientations of the quasi-1D
fillers and the polarization of the electromagnetic wave. We argue that such
polarization-sensitive polymer films with quasi-1D fillers are applicable to
advanced electromagnetic interference shielding in future communication
systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:58:00 GMT""}]","2021-02-10"
"2102.05039","Claudio Nassif Cruz","Cl\'audio Nassif (retired professor) and A. C. Amaro de Faria Jr","Variation of the fundamental constants over the cosmological time:
  veracity of Dirac's intriguing hypothesis","6 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1211.1936, arXiv:2009.05397, arXiv:1205.2298","Canadian Journal of Physics, Vol.94, n.1 (2016)","10.1139/cjp-2015-0515",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate how the universal constants, including the fine structure
constant, have varied since the early universe close to the Planck energy scale
($E_P\sim 10^{19}$GeV) and, thus, how they have evoluted over the cosmological
time related to the temperature of the expanding universe. We have already
shown that the speed of light was much higher close to the Planck scale. In the
present work, we will go further, first by showing that both the Planck
constant and the electron charge were also too large in the early universe.
However, we conclude that the fine structure constant ($\alpha\cong 1/137$) has
remained invariant with the age and temperature of the universe, which is in
agreement with laboratory tests and some observational data. Furthermore, we
will obtain the divergence of the electron (or proton) mass and also the
gravitational constant ($G$) at the Planck scale. Thus, we will be able to
verify the veracity of Dirac's belief about the existence of ""coincidences""
between dimensionless ratios of sub-atomic and cosmological quantities, leading
to a variation of $G$ with time, i.e., the ratio of the electrostatic to
gravitational force between an electron and a proton ($\sim 10^{41}$) is
roughly equal to the age of the universe divided by an elementary time
constant, so that the strength of gravity, as determined by $G$, must vary
inversely with time just in the approximation of lower temperature or for times
very far from the early period, in order to compensate for the time-variation
of the Hubble parameter ($H\sim t^{-1}$). In short, we will show the validity
of Dirac's hypothesis only for times very far from the early period or $T\sim
T_P\sim 10^{32}$K.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:30:36 GMT""}]","2021-02-11"
"2102.05040","Christoph M\""uller","Christoph M\""uller","Top-pair production via gluon fusion in the Standard Model Effective
  Field Theory",,,"10.1103/PhysRevD.104.095003",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the leading corrections to the differential cross section for
top-pair production via gluon fusion due to dimension-six operators at leading
order in QCD. The Standard Model fields are assumed to couple only weakly to
the hypothetical new sector. A systematic approach then suggests treating
single insertions of the operator class containing gluon field strength tensors
on the same footing as expli\-citly loop suppressed contributions from
four-fermion operators. This is in particular the case for the chromomagnetic
operator $Q_{(uG)}$ and the purely bosonic operators $Q_{(G)}$ and $Q_{(\varphi
G)}$. All leading order dimension-six contributions are consequently suppressed
with a loop factor $1/16\pi^2$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:36:56 GMT""}]","2021-11-17"
"2102.05041","Ricardo Menares","Sebasti\'an Herrero, Ricardo Menares, Juan Rivera-Letelier","There are at most finitely many singular moduli that are $S$-units","Improved main theorem beyond the j-invariant. The new results apply
  to other Hauptmoduli, such as the lambda invariants and the McKay-Thompson
  series associated to the elements of the monster group. 33 pages",,,,"math.NT math.AG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that for every finite set of prime numbers $S$, there are at most
finitely many singular moduli that are $S$-units. The key new ingredient is
that for every prime number $p$, singular moduli are $p$-adically disperse. We
prove analogous results for the Weber modular functions, the
$\lambda$-invariants and the McKay-Thompson series associated to the elements
of the monster group. Finally, we also obtain that a modular function that
specializes to infinitely many algebraic units at quadratic imaginary numbers
must be a modular unit.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:04:02 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 13:46:44 GMT""}]","2021-07-28"
"2102.05042","Thomas Nikas","Thomas Nikas, Evangelos Pikasis, Dimitris Syvridis","Static Skew Compensation in Multi Core Radio over Fiber systems for 5G
  Mmwave Beamforming","arXiv admin note: substantial text overlap with arXiv:2102.04813","In 2018 Photonics in Switching and Computing (PSC) (pp. 1-3). IEEE",,,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multicore fibers can be used for Radio over Fiber transmission of mmwave
signals for phased array antennas in 5G networks. The inter-core skew of these
fibers distort the radiation pattern. We propose an efficient method to
compensate the differential delays, without full equalization of the
transmission path lengths, reducing the power loss and complexity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:43:52 GMT""}]","2021-02-11"
"2102.05442","Sean Lawley","Elijah D Counterman and Sean D Lawley","What should patients do if they miss a dose of medication? A theoretical
  approach","38 pages, 7 figures",,,,"q-bio.QM math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medication adherence is a major problem for patients with chronic diseases
that require long term pharmacotherapy. Many unanswered questions surround
adherence, including how adherence rates translate into treatment efficacy and
how missed doses of medication should be handled. To address these questions,
we formulate and analyze a mathematical model of the drug concentration in a
patient with imperfect adherence. We find exact formulas for drug concentration
statistics, including the mean, the coefficient of variation, and the deviation
from perfect adherence. We determine how adherence rates translate into drug
concentrations, and how this depends on the drug half-life, the dosing
interval, and how missed doses are handled. While clinical recommendations
require extensive validation and should depend on drug and patient specifics,
as a general principle our theory suggests that nonadherence is best mitigated
by taking double doses following missed doses if the drug has a long half-life.
This conclusion contradicts some existing recommendations that cite long drug
half-lives as the reason to avoid a double dose after a missed dose.
Furthermore, we show that a patient who takes double doses after missed doses
can have at most only slightly more drug in their body than a perfectly
adherent patient if the drug half-life is long. We also investigate other ways
of handling missed doses, including taking an extra fractional dose following a
missed dose. We discuss our results in the context of hypothyroid patients
taking levothyroxine.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 03:26:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 22:32:08 GMT""}]","2021-12-30"
"2102.05443","Muhammad Sharif","M. Sharif and Faisal Javed","Stability of Charged Thin-Shell Gravastars with Quintessence","23 pages, 9 figures","Eur. Phys. J. C 81(2021)47","10.1140/epjc/s10052-020-08802-1",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a new solution of gravitational vacuum star in the
background of charged Kiselev black holes as an exterior manifold. We explore
physical features and stability of thin-shell gravastars with radial
perturbation. The matter thin layer located at thin-shell greatly affects
stable configuration of the developed structure. We assume three different
choices of matter distribution such as barotropic, generalized Chaplygin gas
and generalized phantomlike equation of state. The last two models depend on
the shell radius, also known as variable equation of state. For barotropic
model, the structure of thin-shell gravastar is mostly unstable while it shows
stable configuration for such type of matter distribution with extraordinary
quintessence parameter. The resulting gravastar structure indicates stable
behavior for generalized Chaplygin gas but unstable for generalized phantomlike
model. It is also found that proper length, entropy and energy within the shell
show linear relation with thickness of the shell.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:21:55 GMT""}]","2021-02-17"
"2102.05448","Yifan Yao","Yifan Yao, Lina Wang","Combination of window-sliding and prediction range method based on LSTM
  model for predicting cryptocurrency","30 pages,23 figures",,,,"q-fin.ST","http://creativecommons.org/licenses/by/4.0/","  The present study aims to establish the model of the cryptocurrency price
trend based on financial theory using the LSTM model with multiple combinations
between the window length and the predicting horizons, the random walk model is
also applied with different parameter settings.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:07:51 GMT""}]","2021-02-11"
"2102.05454","Xinyi Li","Xinyi Li, Haibin Ling","On the Robustness of Multi-View Rotation Averaging",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Rotation averaging is a synchronization process on single or multiple
rotation groups, and is a fundamental problem in many computer vision tasks
such as multi-view structure from motion (SfM). Specifically, rotation
averaging involves the recovery of an underlying pose-graph consistency from
pairwise relative camera poses. Specifically, given pairwise motion in rotation
groups, especially 3-dimensional rotation groups (\eg, $\mathbb{SO}(3)$), one
is interested in recovering the original signal of multiple rotations with
respect to a fixed frame. In this paper, we propose a robust framework to solve
multiple rotation averaging problem, especially in the cases that a significant
amount of noisy measurements are present. By introducing the $\epsilon$-cycle
consistency term into the solver, we enable the robust initialization scheme to
be implemented into the IRLS solver. Instead of conducting the costly edge
removal, we implicitly constrain the negative effect of erroneous measurements
by weight reducing, such that IRLS failures caused by poor initialization can
be effectively avoided. Experiment results demonstrate that our proposed
approach outperforms state of the arts on various benchmarks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:47:37 GMT""}]","2021-02-11"
"2102.05463","Gabriel Goldberg","Gabriel Goldberg","A note on Woodin's HOD dichotomy","3 pages",,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  A version of Woodin's HOD dichotomy is proved assuming the existence of just
one strongly compact cardinal.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:37:00 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 05:46:13 GMT""},{""version"":""v3"",""created"":""Sun, 14 Feb 2021 17:41:44 GMT""},{""version"":""v4"",""created"":""Thu, 18 Feb 2021 06:07:25 GMT""}]","2021-02-19"
"2102.05708","Fatemah Husain","Fatemah Husain and Ozlem Uzuner","Transfer Learning Approach for Arabic Offensive Language Detection
  System -- BERT-Based Model","2021 4th International Conference on Computer Applications &
  Information Security (ICCAIS) - Contemporary Computer Technologies and
  Applications",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Developing a system to detect online offensive language is very important to
the health and the security of online users. Studies have shown that cyberhate,
online harassment and other misuses of technology are on the rise, particularly
during the global Coronavirus pandemic in 2020. According to the latest report
by the Anti-Defamation League (ADL), 35% of online users reported online
harassment related to their identity-based characteristics, which is a 3%
increase over 2019. Applying advanced techniques from the Natural Language
Processing (NLP) field to support the development of an online hate-free
community is a critical task for social justice. Transfer learning enhances the
performance of the classifier by allowing the transfer of knowledge from one
domain or one dataset to others that have not been seen before, thus,
supporting the classifier to be more generalizable. In our study, we apply the
principles of transfer learning cross multiple Arabic offensive language
datasets to compare the effects on system performance. This study aims at
investigating the effects of fine-tuning and training Bidirectional Encoder
Representations from Transformers (BERT) model on multiple Arabic offensive
language datasets individually and testing it using other datasets
individually. Our experiment starts with a comparison among multiple BERT
models to guide the selection of the main model that is used for our study. The
study also investigates the effects of concatenating all datasets to be used
for fine-tuning and training BERT model. Our results demonstrate the limited
effects of transfer learning on the performance of the classifiers,
particularly for highly dialectic comments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:58:18 GMT""}]","2021-02-12"
"2102.06025","Liuyihan Song","Liuyihan Song and Pan Pan and Kang Zhao and Hao Yang and Yiming Chen
  and Yingya Zhang and Yinghui Xu and Rong Jin","Large-Scale Training System for 100-Million Classification at Alibaba","Accepted by KDD 2020. In Proceedings of the 26th ACM SIGKDD
  International Conference on Knowledge Discovery & Data Mining (2020)",,"10.1145/3394486.3403342",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the last decades, extreme classification has become an essential topic for
deep learning. It has achieved great success in many areas, especially in
computer vision and natural language processing (NLP). However, it is very
challenging to train a deep model with millions of classes due to the memory
and computation explosion in the last output layer. In this paper, we propose a
large-scale training system to address these challenges. First, we build a
hybrid parallel training framework to make the training process feasible.
Second, we propose a novel softmax variation named KNN softmax, which reduces
both the GPU memory consumption and computation costs and improves the
throughput of training. Then, to eliminate the communication overhead, we
propose a new overlapping pipeline and a gradient sparsification method.
Furthermore, we design a fast continuous convergence strategy to reduce total
training iterations by adaptively adjusting learning rate and updating model
parameters. With the help of all the proposed methods, we gain 3.9$\times$
throughput of our training system and reduce almost 60\% of training
iterations. The experimental results show that using an in-house 256 GPUs
cluster, we could train a classifier of 100 million classes on Alibaba Retail
Product Dataset in about five days while achieving a comparable accuracy with
the naive softmax training process.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 06:53:31 GMT""}]","2021-02-12"
"2102.06026","Gadekallu Thippa Reddy","Rajesh Kaluri, Dharmendra Singh Rajput, Qin Xin, Kuruva Lakshmanna,
  Sweta Bhattacharya, Thippa Reddy Gadekallu and Praveen Kumar Reddy Maddikunta","Roughsets-based Approach for Predicting Battery Life in IoT",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Internet of Things (IoT) and related applications have successfully
contributed towards enhancing the value of life in this planet. The advanced
wireless sensor networks and its revolutionary computational capabilities have
enabled various IoT applications become the next frontier, touching almost all
domains of life. With this enormous progress, energy optimization has also
become a primary concern with the need to attend to green technologies. The
present study focuses on the predictions pertinent to the sustainability of
battery life in IoT frameworks in the marine environment. The data used is a
publicly available dataset collected from the Chicago district beach water.
Firstly, the missing values in the data are replaced with the attribute mean.
Later, one-hot encoding technique is applied for achieving data homogeneity
followed by the standard scalar technique to normalize the data. Then, rough
set theory is used for feature extraction, and the resultant data is fed into a
Deep Neural Network (DNN) model for the optimized prediction results. The
proposed model is then compared with the state of the art machine learning
models and the results justify its superiority on the basis of performance
metrics such as Mean Squared Error, Mean Absolute Error, Root Mean Squared
Error, and Test Variance Score.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:42:04 GMT""}]","2021-02-12"
"2102.06027","Zhengyang Zhou","Zhengyang Zhou, Yang Wang, Xike Xie, Lei Qiao, Yuantao Li","STUaNet: Understanding uncertainty in spatiotemporal collective human
  mobility","12 pages, 8 figures, WWW 2021 Conference",,"10.1145/3442381.3449817",,"cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The high dynamics and heterogeneous interactions in the complicated urban
systems have raised the issue of uncertainty quantification in spatiotemporal
human mobility, to support critical decision-makings in risk-aware web
applications such as urban event prediction where fluctuations are of
significant interests. Given the fact that uncertainty quantifies the potential
variations around prediction results, traditional learning schemes always lack
uncertainty labels, and conventional uncertainty quantification approaches
mostly rely upon statistical estimations with Bayesian Neural Networks or
ensemble methods. However, they have never involved any spatiotemporal
evolution of uncertainties under various contexts, and also have kept suffering
from the poor efficiency of statistical uncertainty estimation while training
models with multiple times. To provide high-quality uncertainty quantification
for spatiotemporal forecasting, we propose an uncertainty learning mechanism to
simultaneously estimate internal data quality and quantify external uncertainty
regarding various contextual interactions. To address the issue of lacking
labels of uncertainty, we propose a hierarchical data turbulence scheme where
we can actively inject controllable uncertainty for guidance, and hence provide
insights to both uncertainty quantification and weak supervised learning.
Finally, we re-calibrate and boost the prediction performance by devising a
gated-based bridge to adaptively leverage the learned uncertainty into
predictions. Extensive experiments on three real-world spatiotemporal mobility
sets have corroborated the superiority of our proposed model in terms of both
forecasting and uncertainty quantification.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 01:43:27 GMT""}]","2021-02-12"
"2102.06077","Reza Nikandish","M. J. Nikmehr, R. Nikandish, A. Yassine","On weakly $1$-absorbing prime ideals of commutative rings",,,,,"math.AC math.RA","http://creativecommons.org/licenses/by/4.0/","  Let $R$ be a commutative ring with identity. In this paper, we introduce the
concept of weakly $1$-absorbing prime ideals which is a generalization of
weakly prime ideals. A proper ideal $I$ of $R$ is called weakly $1$-absorbing
prime if for all nonunit elements $a,b,c \in R$ such that $0\neq abc \in I$,
then either $ab \in I$ or $c \in I$. A number of results concerning weakly
$1$-absorbing prime ideals and examples of weakly $1$-absorbing prime ideals
are given. It is proved that if $I$ is a weakly $1$-absorbing prime ideal of a
ring $R$ and $0 \neq I_1I_2I_3 \subseteq I$ for some ideals $I_1, I_2, I_3$ of
$R$ such that $I$ is free triple-zero with respect to $I_1I_2I_3$, then $
I_1I_2 \subseteq I$ or $I_3\subseteq I$. Among other things, it is shown that
if $I$ is a weakly $1$-absorbing prime ideal of $R$ that is not $1$-absorbing
prime, then $I^3 = 0$. Moreover, weakly $1$-absorbing prime ideals of PID's and
Dedekind domains are characterized. Finally, we investigate commutative rings
with the property that all proper ideals are weakly $1$-absorbing primes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:11:37 GMT""}]","2021-02-12"
"2102.06102","Moran Xu","Moran Xu, Dianlin Hu, Weifei Wu, and Weiwen Wu","Deep Iteration Assisted by Multi-level Obey-pixel Network Discriminator
  (DIAMOND) for Medical Image Recovery",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image restoration is a typical ill-posed problem, and it contains various
tasks. In the medical imaging field, an ill-posed image interrupts diagnosis
and even following image processing. Both traditional iterative and up-to-date
deep networks have attracted much attention and obtained a significant
improvement in reconstructing satisfying images. This study combines their
advantages into one unified mathematical model and proposes a general image
restoration strategy to deal with such problems. This strategy consists of two
modules. First, a novel generative adversarial net(GAN) with WGAN-GP training
is built to recover image structures and subtle details. Then, a deep iteration
module promotes image quality with a combination of pre-trained deep networks
and compressed sensing algorithms by ADMM optimization. (D)eep (I)teration
module suppresses image artifacts and further recovers subtle image details,
(A)ssisted by (M)ulti-level (O)bey-pixel feature extraction networks
(D)iscriminator to recover general structures. Therefore, the proposed strategy
is named DIAMOND.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 16:57:33 GMT""}]","2021-02-12"
"2102.06531","Ahmet M. Tekalp","A. Murat Tekalp, Michele Covell, Radu Timofte, Chao Dong","Editorial: Introduction to the Issue on Deep Learning for Image/Video
  Restoration and Compression",,"IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, vol. 15, no.
  2, FEBRUARY 2021",,,"eess.IV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent works have shown that learned models can achieve significant
performance gains, especially in terms of perceptual quality measures, over
traditional methods. Hence, the state of the art in image restoration and
compression is getting redefined. This special issue covers the state of the
art in learned image/video restoration and compression to promote further
progress in innovative architectures and training methods for effective and
efficient networks for image/video restoration and compression.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 11:24:20 GMT""}]","2021-05-03"
"2102.06533","Francesco Campaioli","Francesco Campaioli, Jared H. Cole","Exciton transport in amorphous polymers and the role of morphology and
  thermalisation","11 pages, 4 figures, 2 tables",,"10.1088/1367-2630/ac37c7",,"cond-mat.mtrl-sci quant-ph","http://creativecommons.org/licenses/by/4.0/","  Understanding the transport mechanism of electronic excitations in conjugated
polymers is key to advancing organic optoelectronic applications, such as solar
cells, OLEDs and flexible electronics. While crystalline polymers can be
studied using solid-state techniques based on lattice periodicity, the
characterisation of amorphous polymers is hindered by an intermediate regime of
disorder and the associated lack of symmetries. To overcome these hurdles we
use a reduced state quantum master equation approach based on the Merrifield
exciton formalism. Using this model we study exciton transport in conjugated
polymers and its dependence on morphology and temperature. Exciton dynamics
consists of a thermalisation process, whose features depend on the relative
strength of thermal energy, electronic couplings and disorder, resulting in
remarkably different transport regimes. By applying this method to
representative systems based on poly(p-phenylene vinylene) (PPV) we obtain
insight into the role of temperature and disorder on localisation, charge
separation, non-equilibrium dynamics, and experimental accessibility of thermal
equilibrium states of excitons in amorphous polymers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 00:57:49 GMT""}]","2021-12-13"
"2102.06534","Jamie Foster Dr","Ivan Korotkin, Smita Sahu, Simon O'Kane, Giles Richardson, Jamie M.
  Foster","DandeLiion v1: An extremely fast solver for the Newman model of
  lithium-ion battery (dis)charge",,,"10.1149/1945-7111/ac085f",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DandeLiion (available at dandeliion.com) is a robust and extremely fast
solver for the Doyle Fuller Newman (DFN) model, the standard electrochemical
model for (dis)charge of a planar lithium-ion cell. DandeLiion conserves
lithium, uses a second order spatial discretisation method (enabling accurate
computations using relatively coarse discretisations) and is many times faster
than its competitors. The code can be used `in the cloud' and does not require
installation before use. The difference in compute time between DandeLiion and
its commercial counterparts is roughly a factor of 100 for the moderately-sized
test case of the discharge of a single cell. Its linear scaling property means
that the disparity in performance is even more pronounced for bigger systems,
making it particularly suitable for applications involving multiple coupled
cells. The model is characterised by a number of phenomenological parameters
and functions, which may either be provided by the user or chosen from
DandeLiion's library. This library contains data for the most commonly used
electrolyte (LiPF6) and a number of common active material chemistries
including graphite, lithium iron phosphate (LFP), nickel cobalt aluminium
(NCA), and a variant of nickel cobalt manganese (NMC).
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:06:05 GMT""}]","2021-08-20"
"2102.06535","Zainab Abohashima","Essam H. Houssein, Zainab Abohashima, Mohamed Elhoseny, Waleed M.
  Mohamed","Hybrid quantum convolutional neural networks model for COVID-19
  prediction using chest X-Ray images",,"Journal of Computational Design and Engineering, Volume 9, Issue
  2, April 2022,","10.1093/jcde/qwac003",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Despite the great efforts to find an effective way for COVID-19 prediction,
the virus nature and mutation represent a critical challenge to diagnose the
covered cases. However, developing a model to predict COVID-19 via Chest X-Ray
(CXR) images with accurate performance is necessary to help in early diagnosis.
In this paper, a hybrid quantum-classical convolutional Neural Networks (HQCNN)
model used the random quantum circuits (RQCs) as a base to detect COVID-19
patients with CXR images. A collection of 6952 CXR images, including 1161
COVID-19, 1575 normal, and 5216 pneumonia images, were used as a dataset in
this work. The proposed HQCNN model achieved higher performance with an
accuracy of 98.4\% and a sensitivity of 99.3\% on the first dataset cases.
Besides, it obtained an accuracy of 99\% and a sensitivity of 99.7\% on the
second dataset cases. Also, it achieved accuracy, and sensitivity of 88.6\%,
and 88.7\%, respectively, on the third multi-class dataset cases. Furthermore,
the HQCNN model outperforms various models in balanced accuracy, precision,
F1-measure, and AUC-ROC score. The experimental results are achieved by the
proposed model prove its ability in predicting positive COVID-19 cases.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 18:22:53 GMT""}]","2022-03-14"
"2102.06575","Snehanshu Saha","Anuj Tambwekar, Anirudh Maiya, Soma Dhavala, Snehanshu Saha","Estimation and Applications of Quantiles in Deep Binary Classification",,,,"BPGC/RIG/2020-21-10","cs.LG","http://creativecommons.org/licenses/by/4.0/","  Quantile regression, based on check loss, is a widely used inferential
paradigm in Econometrics and Statistics. The conditional quantiles provide a
robust alternative to classical conditional means, and also allow uncertainty
quantification of the predictions, while making very few distributional
assumptions. We consider the analogue of check loss in the binary
classification setting. We assume that the conditional quantiles are smooth
functions that can be learnt by Deep Neural Networks (DNNs). Subsequently, we
compute the Lipschitz constant of the proposed loss, and also show that its
curvature is bounded, under some regularity conditions. Consequently, recent
results on the error rates and DNN architecture complexity become directly
applicable.
  We quantify the uncertainty of the class probabilities in terms of prediction
intervals, and develop individualized confidence scores that can be used to
decide whether a prediction is reliable or not at scoring time. By aggregating
the confidence scores at the dataset level, we provide two additional metrics,
model confidence, and retention rate, to complement the widely used classifier
summaries. We also the robustness of the proposed non-parametric binary
quantile classification framework are also studied, and we demonstrate how to
obtain several univariate summary statistics of the conditional distributions,
in particular conditional means, using smoothed conditional quantiles, allowing
the use of explanation techniques like Shapley to explain the mean predictions.
Finally, we demonstrate an efficient training regime for this loss based on
Stochastic Gradient Descent with Lipschitz Adaptive Learning Rates (LALR).
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:07:42 GMT""}]","2021-02-15"
"2102.06675","Sebastian Kubis","Sebastian Kubis and W{\l}odzimierz W\'ojcik","The role of the electric Bond number in the stability of pasta phases","8 pages, 6 figures",,"10.1016/j.physletb.2022.137474",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stability of pasta phases in cylindrical and spherical Wigner-Seitz (W-S)
cells is examined. The electric Bond number is introduced as the ratio of
electric and surface energies. In the case of a charged rod in vacuum, other
kinds of instabilities appear in addition to the well known Plateau- Rayleigh
mode. For the case of a rod confined in a W-S cell the variety of unstable
modes is reduced. It comes from the virial theorem, which bounds the value of
the Bond number from above and reduces the role played by electric forces. A
similar analysis is done for the spherical W-S cell, where it appears that the
inclusion of the virial theorem stabilizes all of the modes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:31:54 GMT""}]","2022-10-26"
"2102.07619","Zhang Junlin","Zhiqiang Wang, Qingyun She, Junlin Zhang","MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models
  by Instance-Guided Mask","In Proceedings of DLP-KDD 2021. ACM,Singapore. arXiv admin note: text
  overlap with arXiv:2006.12753",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Click-Through Rate(CTR) estimation has become one of the most fundamental
tasks in many real-world applications and it's important for ranking models to
effectively capture complex high-order features. Shallow feed-forward network
is widely used in many state-of-the-art DNN models such as FNN, DeepFM and
xDeepFM to implicitly capture high-order feature interactions. However, some
research has proved that addictive feature interaction, particular feed-forward
neural networks, is inefficient in capturing common feature interaction. To
resolve this problem, we introduce specific multiplicative operation into DNN
ranking system by proposing instance-guided mask which performs element-wise
product both on the feature embedding and feed-forward layers guided by input
instance. We also turn the feed-forward layer in DNN model into a mixture of
addictive and multiplicative feature interactions by proposing MaskBlock in
this paper. MaskBlock combines the layer normalization, instance-guided mask,
and feed-forward layer and it is a basic building block to be used to design
new ranking model under various configurations. The model consisting of
MaskBlock is called MaskNet in this paper and two new MaskNet models are
proposed to show the effectiveness of MaskBlock as basic building block for
composing high performance ranking systems. The experiment results on three
real-world datasets demonstrate that our proposed MaskNet models outperform
state-of-the-art models such as DeepFM and xDeepFM significantly, which implies
MaskBlock is an effective basic building unit for composing new high
performance ranking systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 12:27:49 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 08:31:31 GMT""}]","2021-07-27"
"2102.07640","Jinjiang Guo Ph.D.","Yutong Jin, Jie Li, Xinyu Wang, Peiyao Li, Jinjiang Guo, Junfeng Wu,
  Dawei Leng, Lurong Pan","Real-time tracking of COVID-19 and coronavirus research updates through
  text mining",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  The novel coronavirus (SARS-CoV-2) which causes COVID-19 is an ongoing
pandemic. There are ongoing studies with up to hundreds of publications
uploaded to databases daily. We are exploring the use-case of artificial
intelligence and natural language processing in order to efficiently sort
through these publications. We demonstrate that clinical trial information,
preclinical studies, and a general topic model can be used as text mining data
intelligence tools for scientists all over the world to use as a resource for
their own research. To evaluate our method, several metrics are used to measure
the information extraction and clustering results. In addition, we demonstrate
that our workflow not only have a use-case for COVID-19, but for other disease
areas as well. Overall, our system aims to allow scientists to more efficiently
research coronavirus. Our automatically updating modules are available on our
information portal at https://ghddi-ailab.github.io/Targeting2019-nCoV/ for
public viewing.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:09:42 GMT""}]","2021-02-16"
"2102.08209","Masoumeh Zareh","Masoumeh Zareh, Mohammad Hossein Manshaei, and Sayed Jalal Zahabi","Modeling the Hallucinating Brain: A Generative Adversarial Framework",,,,,"q-bio.NC cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  This paper looks into the modeling of hallucination in the human's brain.
Hallucinations are known to be causally associated with some malfunctions
within the interaction of different areas of the brain involved in perception.
Focusing on visual hallucination and its underlying causes, we identify an
adversarial mechanism between different parts of the brain which are
responsible in the process of visual perception. We then show how the
characterized adversarial interactions in the brain can be modeled by a
generative adversarial network.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:30:14 GMT""}]","2021-02-17"
"2102.08938","Stefan Szyniszewski","M. Pelacci, A. G. Robins and S. Szyniszewski","Drag Reduction of a Circular Cylinder Through the Use of an
  Architectured Lattice Material","37 pages, 7 figures",,,,"physics.flu-dyn physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Materials with periodic architectures exhibit many beneficial characteristics
such as high specific stiffness thanks to the material placement along the
stress paths and the nano-scale strength amplification achieved through the use
of hierarchical architectures. Recently, the porosity of architectured
materials was leveraged to increase the efficiency of compact heat exchangers,
and their internal aerodynamics was studied. However, their performance on
external aerodynamics applications is generally assumed to be detrimental.
Here, we demonstrate that exposing 3D lattice material to the external flow
reduced the drag of a circular cylinder when placed at carefully selected
angular locations. We tested two configurations with the lattice material
installed at the windward and leeward regions. On the one hand, the windward
configuration showed a strong Re dependency, with a drag reduction of up to 45%
at Re=11E4. On the other hand, the lattice material in the leeward region
reduced the drag by 25% with weak Re dependency. Alterations of the lattice
material topology had a noticeable effect on the drag reduction in both cases.
Adding aerodynamic features to the already proven beneficial structural
properties of 3D lattice materials might aid in the development of low-powered
automotive, naval, and aerospace vehicles.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 20:45:29 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 12:46:04 GMT""}]","2021-02-25"
"2102.09369","Sweta Swarnam","Sweta Swarnam","Effect of Social Media Use on Mental Health during Lockdown in India","15 Pages",,,,"cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  This research paper studies about the role of social media use and increase
the risk factor of mental health during covid 19 or lockdown. Although few
studies have been conducted on the role about the effect of social media use on
mental health during lockdown and impact on human reactive nature during
lockdown. As a rapidly spreading pandemic, a biomedical disease has serious
physical and tremendous mental health implications. An occupational community
of internal migrant workers is one of the most vulnerable, but neglected, and
is likely to develop psychological ill-effects due to COVID-19's double whammy
impact. Mental health is a crucial aspect that needs to be addressed during
this lock-down as all modes of communication revolve around the virus. There
are many difficulties with the unprecedented changes that have occurred so
quickly due to the pandemic and stay-at - home confinement to achieve social
distance and mitigate the risk of infection. These include impaired health,
well-being, and sleep as a result of daily routine disruption, anxiety, worry,
isolation, greater stress on family and work, and excessive screen time. An
essential part of our overall health and well-being is mental and emotional
health. An important skill is managing emotions and maintaining emotional
balance. It helps you face challenges and stress when you manage your emotional
health. Lack of skills in emotional regulation may lead to poor mental health
and relationship difficulties. It is as important to look after our mental
health as it is to look after our physical health. For mental health
professionals, the pandemic has also brought many ethical challenges.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 14:52:33 GMT""}]","2021-02-19"
"2102.09370","Lara Gauder","Lara Gauder, Leonardo Pepino, Pablo Riera, Silvina Brussino, Jazm\'in
  Vidal, Agust\'in Gravano, Luciana Ferrer","A Study on the Manifestation of Trust in Speech","arXiv admin note: text overlap with arXiv:2007.15711,
  arXiv:2006.05977",,,,"cs.HC cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Research has shown that trust is an essential aspect of human-computer
interaction directly determining the degree to which the person is willing to
use a system. An automatic prediction of the level of trust that a user has on
a certain system could be used to attempt to correct potential distrust by
having the system take relevant actions like, for example, apologizing or
explaining its decisions. In this work, we explore the feasibility of
automatically detecting the level of trust that a user has on a virtual
assistant (VA) based on their speech. We developed a novel protocol for
collecting speech data from subjects induced to have different degrees of trust
in the skills of a VA. The protocol consists of an interactive session where
the subject is asked to respond to a series of factual questions with the help
of a virtual assistant. In order to induce subjects to either trust or distrust
the VA's skills, they are first informed that the VA was previously rated by
other users as being either good or bad; subsequently, the VA answers the
subjects' questions consistently to its alleged abilities. All interactions are
speech-based, with subjects and VAs communicating verbally, which allows the
recording of speech produced under different trust conditions. Using this
protocol, we collected a speech corpus in Argentine Spanish. We show clear
evidence that the protocol effectively succeeded in influencing subjects into
the desired mental state of either trusting or distrusting the agent's skills,
and present results of a perceptual study of the degree of trust performed by
expert listeners. Finally, we found that the subject's speech can be used to
detect which type of VA they were using, which could be considered a proxy for
the user's trust toward the VA's abilities, with an accuracy up to 76%,
compared to a random baseline of 50%.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:08:54 GMT""}]","2021-02-19"
"2102.09371","Wolfgang Bietenholz","Wolfgang Bietenholz","From Ramanujan to renormalization: the art of doing away with
  divergences and arriving at physical results","32 pages, LaTex, 6 figures, a number of minor improvements","Revista Mexicana de Fisica E 18 (2021) 020203","10.31349/RevMexFisE.18.020203",,"physics.hist-ph physics.pop-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  A century ago, Srinivasa Ramanujan -- the great self-taught Indian genius of
mathematics -- died, shortly after returning from Cambridge, UK, where he had
collaborated with Godfrey Hardy. Ramanujan contributed numerous outstanding
results to different branches of mathematics, like analysis and number theory,
with a focus on special functions and series. Here we refer to apparently weird
values which he assigned to two simple divergent series, $\sum_{n \geq 1} n$
and $\sum_{n \geq 1} n^{3}$. These values are sensible, however, as analytic
continuations, which correspond to Riemann's $\zeta$-function. Moreover, they
have applications in physics: we discuss the vacuum energy of the photon field,
from which one can derive the Casimir force, which has been experimentally
measured. We further discuss its interpretation, which remains controversial.
This is a simple way to illustrate the concept of renormalization, which is
vital in quantum field theory.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 07:13:41 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 00:20:05 GMT""}]","2021-08-18"
"2102.09372","Sheshank Shankar","Joseph Bae, Rohan Sukumaran, Sheshank Shankar, Anshuman Sharma, Ishaan
  Singh, Haris Nazir, Colin Kang, Saurish Srivastava, Parth Patwa, Abhishek
  Singh, Priyanshi Katiyar, Vitor Pamplona, Ramesh Raskar","Mobile Apps Prioritizing Privacy, Efficiency and Equity: A Decentralized
  Approach to COVID-19 Vaccination Coordination",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this early draft, we describe a decentralized, app-based approach to
COVID-19 vaccine distribution that facilitates zero knowledge verification,
dynamic vaccine scheduling, continuous symptoms reporting, access to aggregate
analytics based on population trends and more. To ensure equity, our solution
is developed to work with limited internet access as well. In addition, we
describe the six critical functions that we believe last mile vaccination
management platforms must perform, examine existing vaccine management systems,
and present a model for privacy-focused, individual-centric solutions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:37:36 GMT""}]","2021-02-19"
"2102.09373","Parinaz Barakhshan","Parinaz Barakhshan, Rudolf Eigenmann","Exchanging Best Practices and Tools for Supporting Computational and
  Data-Intensive Research, The Xpert Network",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  We present best practices and tools for professionals who support
computational and data intensive (CDI) research projects. The practices
resulted from an initiative that brings together national projects and
university teams that include individual or groups of such professionals. We
focus particularly on practices that differ from those in a general software
engineering context. The paper also describes the initiative , the Xpert
Network , where participants exchange successes, challenges, and general
information about their activities, leading to increased productivity,
efficiency, and coordination in the ever growing community of scientists that
use computational and data-intensive research methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 05:00:57 GMT""}]","2021-02-19"
"2102.10990","Mirjana Povi\'c","Mirjana Povi\'c, Vanessa McBride, Priscilla Muheki, Carolina
  \""Odman-Govender, Somaya Saad, Nana Ama Brown Klutse, Aster Tsegaye, Tigist
  Getachew, Melody Kelemu, Hanna Kibret, Jerusalem Tamirat, Deborah
  Telahun-Teka, Beza Tesfaye, and Feven Tigistu-Sahle","Inclusive education and research through African Network of Women in
  Astronomy and STEM for GIRLS in Ethiopia initiatives","Proceedings paper of the International Astronomical Union Symposium
  367: Education and Heritage in the Era of Big Data in Astronomy",,"10.1017/S1743921321000995",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The African Network of Women in Astronomy and STEM for GIRLS in Ethiopia
initiatives have been established with aim to strengthen the participation of
girls and women in astronomy and science in Africa and Ethiopia. We will not be
able to achieve the UN Sustainable Development Goals without full participation
of women and girls in all aspects of our society and without giving in future
the same opportunity to all children to access education independently on their
socio-economical status. In this paper both initiatives are briefly introduced.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:13:51 GMT""}]","2022-01-05"
"2102.11212","Brinnae Bent","Brinnae Bent, Maria Henriquez, Jessilyn Dunn","cgmquantify: Python and R packages for comprehensive analysis of
  interstitial glucose and glycemic variability from continuous glucose monitor
  data","10 pages, 2 figures, 1 table",,"10.1109/OJEMB.2021.3105816",,"q-bio.QM stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Continuous glucose monitoring (CGM) systems provide real-time, dynamic
glucose information by tracking interstitial glucose values throughout the day
(typically values are recorded every 5 minutes). CGMs are commonly used in
diabetes management by clinicians and patients and in research to understand
how factors of longitudinal glucose and glucose variability relate to disease
onset and severity and the efficacy of interventions. CGM data presents unique
bioinformatic challenges because the data is longitudinal, temporal, and there
are nearly infinite possible ways to summarize and use this data. There are
over 20 metrics of glucose variability, no standardization of metrics, and
little validation across studies. Here we present open source python and R
packages called cgmquantify, which contains over 20 functions with over 25
clinically validated metrics of glucose and glucose variability and functions
for visualizing longitudinal CGM data. This is expected to be useful for
researchers and may provide additional insights to patients and clinicians
about glucose patterns.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:21:48 GMT""}]","2021-10-05"
"2102.12366","Wencong Wang","Wencong Wang, Liyuan Huang, Caixue Liu, Han Feng, Jiang Niu, Qidong
  Dai, Guoen Fu, Linfeng Yang, Mingchang Wu","First Application of Large Reactivity Measurement through Rod Drop Based
  on Three-Dimensional Space-Time Dynamics","29 pages, 4 figures",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reactivity measurement is an essential part of a zero-power physics test,
which is critical to reactor design and development. The rod drop experimental
technique is used to measure the control rod worth in a zero-power physics
test. The conventional rod drop experimental technique is limited by the
spatial effect and the difference between the calculated static reactivity and
measured dynamic reactivity; thus, the method must be improved. In this study,
a modified rod drop experimental technique that constrains the detector neutron
flux shape function based on three-dimensional space-time dynamics to reduce
the reactivity perturbation and a new method for calculating the detector
neutron flux shape function are proposed. Correction factors were determined
using Monte Carlo N-Particle transport code and transient analysis code for a
pressurized water reactor at the Ulsan National Institute of Science and
Technology and Xi'an Jiaotong University, and a large reactivity of over 2000
pcm was measured using the modified technique. This research evaluated the
modified technique accuracy, studied the influence of the correction factors on
the modification, and investigated the effect of constraining the shape
function on the reactivity perturbation reduction caused by the difference
between the calculated neutron flux and true value, using the new method to
calculate the shape function of the detector neutron flux and avoiding the
neutron detector response function (weighting factor) calculation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:00:48 GMT""}]","2021-02-25"
"2102.12391","Roudy El Haddad","Roudy El Haddad","Repeated Sums and Binomial Coefficients","21 pages","Open Journal of Discrete Applied Mathematics Vol. 4 (2021), Issue
  2, pp. 30-47","10.30538/psrp-odam2021.0057",,"math.GM","http://creativecommons.org/licenses/by/4.0/","  Binomial coefficients have been used for centuries in a variety of fields and
have accumulated numerous definitions. In this paper, we introduce a new way of
defining binomial coefficients as repeated sums of ones. A multitude of
binomial coefficient identities will be shown in order to prove this
definition. Using this new definition, we simplify some particular sums such as
the repeated Harmonic sum and the repeated Binomial-Harmonic sum. We derive
formulae for simplifying general repeated sums as well as a variant containing
binomial coefficients. Additionally, we study the $m$-th difference of a
sequence and show how sequences whose $m$-th difference is constant can be
related to binomial coefficients.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 13:50:55 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 19:17:27 GMT""}]","2021-09-10"
"2103.03096","Rudresh Dwivedi","Devam Dave, Het Naik, Smiti Singhal, Rudresh Dwivedi, Pankesh Patel","Towards Designing Computer Vision-based Explainable-AI Solution: A Use
  Case of Livestock Mart Industry","8 pages, 5 figures",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of an online Mart is to match buyers and sellers, to weigh
animals and to oversee their sale. A reliable pricing method can be developed
by ML models that can read through historical sales data. However, when AI
models suggest or recommend a price, that in itself does not reveal too much
(i.e., it acts like a black box) about the qualities and the abilities of an
animal. An interested buyer would like to know more about the salient features
of an animal before making the right choice based on his requirements. A model
capable of explaining the different factors that impact the price point is
essential for the needs of the market. It can also inspire confidence in buyers
and sellers about the price point offered. To achieve these objectives, we have
been working with the team at MartEye, a startup based in Portershed in Galway
City, Ireland. Through this paper, we report our work-in-progress research
towards building a smart video analytic platform, leveraging Explainable AI
techniques.
","[{""version"":""v1"",""created"":""Mon, 8 Feb 2021 17:11:19 GMT""}]","2021-03-05"
"2103.03222","Tuan  Phung-Duc","E.V. Morozov, S. S. Rogozin, H.Q.Nguyen, T. Phung-Duc","Modified Erlang loss system for cognitive wireless networks","Submitted to Journal of Mathematical Sciences",,,,"cs.PF math.PR","http://creativecommons.org/licenses/by/4.0/","  This paper considers a modified Erlang loss system for cognitive wireless
networks and related applications. A primary user has preemptive priority over
secondary users and the primary customer is lost if upon arrival all the
channels are used by other primary users. Secondary users cognitively use idle
channels and they can wait at an infinite buffer in cases idle channels are not
available upon arrival or they are interrupted by primary users. We obtain
explicit stability condition for the cases where arrival processes of primary
users and secondary users follow Poisson processes and their service times
follow two distinct arbitrary distributions. The stability condition is
insensitive to the service time distributions and implies the maximal
throughout of secondary users. For a special case of exponential service time
distributions, we analyze in depth to show the effect of parameters on the
delay performance and the mean number of interruptions of secondary users. Our
simulations for distributions rather than exponential reveal that the mean
number of terminations for secondary users is less sensitive to the service
time distribution of primary users.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:52:01 GMT""}]","2021-03-05"
"2103.03816","Stephan Meighen-Berger","Stephan Meighen-Berger, Li Ruohan, Golo Wimmer","Bioluminescence modeling for deep sea experiments",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a modeling framework for bioluminescence light found in the deep
sea near neutrino telescopes by combining a hydrodynamic model with a
stochastic one. The bioluminescence is caused by organisms when exposed to a
non-constant water flow, such as past the neutrino telescopes. We model the
flow using the incompressible Navier-Stokes equations for Reynolds numbers
between 4000 and 23000. The discretization relies on a finite element method
which includes upwind-stabilization for the velocity field. On top of the flow
model, we simulate a population of random microscopic organisms. Their movement
and emission are stochastic processes which we model using Monte Carlo methods.
We observe unique time-series for the photon counts depending on the flow
velocity and detector specifications. This opens up the possibility of
categorizing organisms using neutrino detectors. We show that the average
light-yield and pulse shapes require precise flow modeling, while the emission
timing is chaotic. From this we construct a fast modeling scheme, requiring
only a subset of computationally expensive flow and population modeling.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 09:08:52 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 21:04:51 GMT""}]","2021-06-30"
"2103.08457","Zhiwei Xu","Zhiwei Xu, Thalaiyasingam Ajanthan, Vibhav Vineet, Richard Hartley","RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs","this is an extension of our 3DV2020 conference paper RANP. arXiv
  admin note: substantial text overlap with arXiv:2010.02488",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although 3D Convolutional Neural Networks are essential for most learning
based applications involving dense 3D data, their applicability is limited due
to excessive memory and computational requirements. Compressing such networks
by pruning therefore becomes highly desirable. However, pruning 3D CNNs is
largely unexplored possibly because of the complex nature of typical pruning
algorithms that embeds pruning into an iterative optimization paradigm. In this
work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm that prunes
3D CNNs at initialization to high sparsity levels. Specifically, the core idea
is to obtain an importance score for each neuron based on their sensitivity to
the loss function. This neuron importance is then reweighted according to the
neuron resource consumption related to FLOPs or memory. We demonstrate the
effectiveness of our pruning method on 3D semantic segmentation with widely
used 3D-UNets on ShapeNet and BraTS'18 datasets, video classification with
MobileNetV2 and I3D on UCF101 dataset, and two-view stereo matching with
Pyramid Stereo Matching (PSM) network on SceneFlow dataset. In these
experiments, our RANP leads to roughly 50%-95% reduction in FLOPs and 35%-80%
reduction in memory with negligible loss in accuracy compared to the unpruned
networks. This significantly reduces the computational resources required to
train 3D CNNs. The pruned network obtained by our algorithm can also be easily
scaled up and transferred to another dataset for training.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 04:35:29 GMT""}]","2021-03-16"
"2103.11774","Noah Daniels","Najib Ishaq, Thomas J. Howard III, Noah M. Daniels","Clustered Hierarchical Anomaly and Outlier Detection Algorithms","As published in IEEE Big Data 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly and outlier detection is a long-standing problem in machine learning.
In some cases, anomaly detection is easy, such as when data are drawn from
well-characterized distributions such as the Gaussian. However, when data
occupy high-dimensional spaces, anomaly detection becomes more difficult. We
present CLAM (Clustered Learning of Approximate Manifolds), a manifold mapping
technique in any metric space. CLAM begins with a fast hierarchical clustering
technique and then induces a graph from the cluster tree, based on overlapping
clusters as selected using several geometric and topological features. Using
these graphs, we implement CHAODA (Clustered Hierarchical Anomaly and Outlier
Detection Algorithms), exploring various properties of the graphs and their
constituent clusters to find outliers. CHAODA employs a form of transfer
learning based on a training set of datasets, and applies this knowledge to a
separate test set of datasets of different cardinalities, dimensionalities, and
domains. On 24 publicly available datasets, we compare CHAODA (by measure of
ROC AUC) to a variety of state-of-the-art unsupervised anomaly-detection
algorithms. Six of the datasets are used for training. CHAODA outperforms other
approaches on 16 of the remaining 18 datasets. CLAM and CHAODA scale to large,
high-dimensional ""big data"" anomaly-detection problems, and generalize across
datasets and distance functions. Source code to CLAM and CHAODA are freely
available on GitHub at https://github.com/URI-ABD/clam.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 15:27:52 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 16:14:17 GMT""}]","2021-11-24"

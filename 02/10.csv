"2102.04903","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang","FeedRec: News Feed Recommendation with Various User Feedbacks","WWW 2022",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Accurate user interest modeling is important for news recommendation. Most
existing methods for news recommendation rely on implicit feedbacks like click
for inferring user interests and model training. However, click behaviors
usually contain heavy noise, and cannot help infer complicated user interest
such as dislike. Besides, the feed recommendation models trained solely on
click behaviors cannot optimize other objectives such as user engagement. In
this paper, we present a news feed recommendation method that can exploit
various kinds of user feedbacks to enhance both user interest modeling and
model training. We propose a unified user modeling framework to incorporate
various explicit and implicit user feedbacks to infer both positive and
negative user interests. In addition, we propose a strong-to-weak attention
network that uses the representations of stronger feedbacks to distill positive
and negative user interests from implicit weak feedbacks for accurate user
interest modeling. Besides, we propose a multi-feedback model training
framework to learn an engagement-aware feed recommendation model. Extensive
experiments on a real-world dataset show that our approach can effectively
improve the model performance in terms of both news clicks and user engagement.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:00:25 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 16:58:22 GMT""}]","2022-02-07"
"2102.04904","Makrina Agaoglou","R. Crossley, M. Agaoglou, M. Katsanikas, S. Wiggins","From Poincare Maps to Lagrangian Descriptors: The Case of the Valley
  Ridge Inflection Point Potential","19 pages",,"10.1134/S1560354721020040",,"nlin.CD math.DS physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we compare the method of Lagrangian descriptors with the
classical method of Poincare maps for revealing the phase space structure of
two degree-of-freedom Hamiltonian systems. The comparison is carried out by
considering the dynamics of a two degree-of-freedom system having a valley
ridge inflection point (VRI) potential energy surface. VRI potential energy
surfaces have four critical points: a high energy saddle and a lower energy
saddle separating two wells. In between the two saddle points is a valley ridge
inflection point that is the point where the potential energy surface geometry
changes from a valley to a ridge. The region between the two saddles forms a
reaction channel and the dynamical issue of interest is how trajectories cross
the high energy saddle, evolve towards the lower energy saddle, and select a
particular well to enter. Lagrangian descriptors and Poincare maps are compared
for their ability to determine the phase space structures that govern this
dynamical process.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:00:40 GMT""}]","2021-04-21"
"2102.04905","Nikita Ratanov","Nikita Ratanov","On telegraph processes, their first passage times and running extrema","9 pages",,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this note, we present some ideas for describing the distributions of the
running maximum/minimum, first passage times and telegraphic meanders. Explicit
formulae for joint distribution of the extrema, the number of velocity switches
and the terminal position are derived using coupled integral equations
technique.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:00:44 GMT""}]","2021-02-10"
"2102.04906","Yizeng Han","Yizeng Han, Gao Huang, Shiji Song, Le Yang, Honghui Wang, Yulin Wang","Dynamic Neural Networks: A Survey",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic neural network is an emerging research topic in deep learning.
Compared to static models which have fixed computational graphs and parameters
at the inference stage, dynamic networks can adapt their structures or
parameters to different inputs, leading to notable advantages in terms of
accuracy, computational efficiency, adaptiveness, etc. In this survey, we
comprehensively review this rapidly developing area by dividing dynamic
networks into three main categories: 1) instance-wise dynamic models that
process each instance with data-dependent architectures or parameters; 2)
spatial-wise dynamic networks that conduct adaptive computation with respect to
different spatial locations of image data and 3) temporal-wise dynamic models
that perform adaptive inference along the temporal dimension for sequential
data such as videos and texts. The important research problems of dynamic
networks, e.g., architecture design, decision making scheme, optimization
technique and applications, are reviewed systematically. Finally, we discuss
the open problems in this field together with interesting future research
directions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:02:00 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 13:45:05 GMT""},{""version"":""v3"",""created"":""Fri, 11 Jun 2021 14:16:16 GMT""},{""version"":""v4"",""created"":""Thu, 2 Dec 2021 12:28:53 GMT""}]","2021-12-03"
"2102.04908","Carsten Hartmann","Hafida Bouanani, Carsten Hartmann and Omar Kebiri","Model reduction and uncertainty quantification of multiscale diffusions
  with parameter uncertainties using nonlinear expectations","22 pages, 4 figures",,,,"math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study model reduction of linear and bilinear quadratic
stochastic control problems with parameter uncertainties. Specifically, we
consider slow-fast systems with unknown diffusion coefficient and study the
convergence of the slow process in the limit of infinite scale separation. The
aim of our work is two-fold: Firstly, we want to propose a general framework
for averaging and homogenisation of multiscale systems with parametric
uncertainties in the drift or in the diffusion coefficient. Secondly, we want
to use this framework to quantify the uncertainty in the reduced system by
deriving a limit equation that represents a worst-case scenario for any given
(possibly path-dependent) quantity of interest. We do so by reformulating the
slow-fast system as an optimal control problem in which the unknown parameter
plays the role of a control variable that can take values in a closed bounded
set. For systems with unknown diffusion coefficient, the underlying stochastic
control problem admits an interpretation in terms of a stochastic differential
equation driven by a G-Brownian motion. We prove convergence of the slow
process with respect to the nonlinear expectation on the probability space
induced by the G-Brownian motion. The idea here is to formulate the nonlinear
dynamic programming equation of the underlying control problem as a
forward-backward stochastic differential equation in the G-Brownian motion
framework (in brief: G-FBSDE), for which convergence can be proved by standard
means. We illustrate the theoretical findings with two simple numerical
examples, exploiting the connection between fully nonlinear dynamic programming
equations and second-order BSDE (2BSDE): a linear quadratic Gaussian regulator
problem and a bilinear multiplicative triad that is a standard benchmark system
in turbulence and climate modelling.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:05:27 GMT""}]","2021-02-10"
"2102.04909","Tomer Ezra","Moshe Babaioff, Tomer Ezra, Uriel Feige","Best-of-Both-Worlds Fair-Share Allocations",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of fair allocation of indivisible items among $n$
agents with additive valuations, when agents have equal entitlements to the
goods, and there are no transfers. Best-of-Both-Worlds (BoBW) fairness
mechanisms aim to give all agents both an ex-ante guarantee (such as getting
the proportional share in expectation) and an ex-post guarantee. Prior BoBW
results have focused on ex-post guarantees that are based on the ""up to one
item"" paradigm, such as envy-free up to one item (EF1). In this work we attempt
to give every agent a high value ex-post, and specifically, a constant fraction
of his maximin share (MMS). The up to one item paradigm fails to give such a
guarantee, and it is not difficult to present examples in which previous BoBW
mechanisms give agents only a $\frac{1}{n}$ fraction of their MMS.
  Our main result is a deterministic polynomial time algorithm that computes a
distribution over allocations that is ex-ante proportional, and ex-post, every
allocation gives every agent at least his proportional share up to one item,
and more importantly, at least half of his MMS. Moreover, this last ex-post
guarantee holds even with respect to a more demanding notion of a share,
introduced in this paper, that we refer to as the truncated proportional share
(TPS). Our guarantees are nearly best possible, in the sense that one cannot
guarantee agents more than their proportional share ex-ante, and one cannot
guarantee agents more than a $\frac{n}{2n-1}$ fraction of their TPS ex-post.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:07:37 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 15:16:10 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 14:39:25 GMT""},{""version"":""v4"",""created"":""Thu, 24 Mar 2022 12:12:36 GMT""}]","2022-03-25"
"2102.04910","Konstantinos Konstantoudakis","Konstantinos Konstantoudakis, David Breitgand, Alexandros Doumanoglou,
  Nikolaos Zioulis, Avi Weit, Kyriaki Christaki, Petros Drakoulis, Emmanouil
  Christakis, Dimitrios Zarpalas, Petros Daras","Serverless Streaming for Emerging Media: Towards 5G Network-Driven Cost
  Optimization","32 pages, 12 figures, preprint: to appear in ""Multimedia Tools and
  Applications: 5G Multimedia Communications"" special issue",,"10.1007/s11042-020-10219-7",,"cs.NI cs.MM","http://creativecommons.org/licenses/by/4.0/","  Immersive 3D media is an emerging type of media that captures, encodes and
reconstructs the 3D appearance of people and objects, with applications in
tele-presence, teleconference, entertainment, gaming and other fields. In this
paper, we discuss a novel concept of live 3D immersive media streaming in a
serverless setting. In particular, we present a novel network-centric adaptive
streaming framework which deviates from a traditional client-based adaptive
streaming used in 2D video. In our framework, the decisions for the production
of the transcoding profiles are taken in a centralized manner, by considering
consumer metrics vs provisioning costs and inferring an expected consumer
quality of experience and behaviour based on them. In addition, we demonstrate
that a naive application of the serverless paradigm might be sub optimal under
some common immersive 3D media scenarios.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:08:10 GMT""}]","2021-02-10"
"2102.04911","Yasir Zaki","Muhammad Khan and Yasir Zaki and Shiva Iyer and Talal Ahamd and Thomas
  P\""otsch and Jay Chen and Anirudh Sivaraman and Lakshmi Subramanian","The case for model-driven interpretability of delay-based congestion
  control protocols",,,,,"cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Analyzing and interpreting the exact behavior of new delay-based congestion
control protocols with complex non-linear control loops is exceptionally
difficult in highly variable networks such as cellular networks. This paper
proposes a Model-Driven Interpretability (MDI) congestion control framework,
which derives a model version of a delay-based protocol by simplifying a
congestion control protocol's response into a guided random walk over a
two-dimensional Markov model. We demonstrate the case for the MDI framework by
using MDI to analyze and interpret the behavior of two delay-based protocols
over cellular channels: Verus and Copa. Our results show a successful
approximation of throughput and delay characteristics of the protocols' model
versions across variable network conditions. The learned model of a protocol
provides key insights into an algorithm's convergence properties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:08:26 GMT""}]","2021-02-10"
"2102.04912","Kolesnikova Lucie","E. R. Alonso, L. Kolesnikov\'a, A. Belloche, S. Mata, R. T. Garrod, A.
  Jabri, I. Le\'on, J.-C. Guillemin, H. S. P. M\""uller, K. M. Menten, J. L.
  Alonso","Rotational spectroscopic study and astronomical search for propiolamide
  in Sgr B2(N)","The article will be published as a regular paper in Astronomy and
  Astrophysics","A&A 647, A55 (2021)","10.1051/0004-6361/202040211",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For all the amides detected in the interstellar medium (ISM), the
corresponding nitriles or isonitriles have also been detected in the ISM, some
of which have relatively high abundances. Among the abundant nitriles for which
the corresponding amide has not yet been detected is cyanoacetylene (HCCCN),
whose amide counterpart is propiolamide (HCCC(O)NH$_2$). With the aim of
supporting searches for this amide in the ISM, we provide a complete rotational
study of propiolamide from 6 GHz to 440 GHz using rotational spectroscopic
techniques in the frequency and time domain. We identified and measured more
than 5500 distinct frequency lines of propiolamide and obtained accurate sets
of spectroscopic parameters for the ground state and the three low-lying
excited vibrational states. We used the ReMoCA spectral line survey performed
with the Atacama Large Millimeter/submillimeter Array toward the star-forming
region Sgr B2(N) to search for propiolamide. We report the nondetection of
propiolamide toward the hot cores Sgr B2(N1S) and Sgr B2(N2). We find that
propiolamide is at least 50 and 13 times less abundant than acetamide in Sgr
B2(N1S) and Sgr B2(N2), respectively, indicating that the abundance difference
between both amides is more pronounced by at least a factor of 8 and 2,
respectively, than for their corresponding nitriles. Although propiolamide has
yet to be included in astrochemical modeling networks, the observed upper limit
to the ratio of propiolamide to acetamide seems consistent with the ratios of
related species as determined from past simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:08:37 GMT""}]","2021-03-10"
"2102.04913","Jan M. L. Martin","Golokesh Santra, Minsik Cho, and Jan M.L. Martin","Exploring Avenues Beyond Revised DSD Functionals: I. range separation,
  with xDSD as a special case","J. Phys. Chem. A 125, ASAP (2021) Creative Commons License (1st of
  two papers back-to-back)","J. Phys. Chem. A 125, 4614-4627 (2021)","10.1021/acs.jpca.1c01294",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have explored the use of range separation as a possible avenue for further
improvement on our revDSD minimally empirical double hybrid functionals. Such
$\omega$DSD functionals encompass the XYG3 type of double hybrid (i.e., xDSD)
as a special case for $\omega$->0. As in our previous studies, the large and
chemically diverse GMTKN55 benchmark suite was used for evaluation. Especially
when using the D4 rather than D3BJ dispersion model, xDSD has a slight
performance advantage in WTMAD2. As found previously, PBEP86 is the winning
combination for the semilocal parts. xDSDn-PBEP86-D4 marginally outperforms the
previous 'best in class' $\omega$B97M(2) Berkeley double hybrid, but without
range separation and using fewer than half the number of empirical parameters.
Range separation turns out to offer only marginal further improvements on
GMTKN55 itself. While $\omega$B97M(2) still yields better performance for
small-molecule thermochemistry, this is outweighed in WTMAD2 by superior
performance of the new functionals for conformer equilibria. Results for two
external test sets with pronounced static correlation effects may indicate that
range-separated double hybrids are more resilient to such effects.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:09:27 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 18:37:07 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 13:51:40 GMT""},{""version"":""v4"",""created"":""Sat, 22 May 2021 19:09:14 GMT""}]","2021-06-10"
"2102.04914","Dan Itzhak Florentin","Dan Itzhak Florentin, Yaron Ostrover, Daniel Rosen","Caustic-Free Regions for Billiards on Surfaces of Constant Curvature","17 pages, 11 figures",,,,"math.DS math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we study caustic-free regions for convex billiard tables in the
hyperbolic plane or the hemisphere. In particular, following a result by Gutkin
and Katok in the Euclidean case, we estimate the size of such regions in terms
of the geometry of the billiard table. Moreover, we extend to this setting a
theorem due to Hubacher which shows that no caustics exist near the boundary of
a convex billiard table whose curvature is discontinuous.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:10:06 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 12:16:08 GMT""},{""version"":""v3"",""created"":""Sun, 13 Jun 2021 20:19:08 GMT""}]","2021-06-15"
"2102.04915","Hossein Arabi","Samaneh Mostafapour, Faeze Gholamiankhah, Sirvan Maroofpour, Mahdi
  Momennezhad, Mohsen Asadinezhad, Seyed Rasoul Zakavi, Hossein Arabi","Deep learning-based attenuation correction in the image domain for
  myocardial perfusion SPECT imaging",,,,,"physics.med-ph eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objective: In this work, we set out to investigate the accuracy of direct
attenuation correction (AC) in the image domain for the myocardial perfusion
SPECT imaging (MPI-SPECT) using two residual (ResNet) and UNet deep
convolutional neural networks. Methods: The MPI-SPECT 99mTc-sestamibi images of
99 participants were retrospectively examined. UNet and ResNet networks were
trained using SPECT non-attenuation corrected images as input and CT-based
attenuation corrected SPECT images (CT-AC) as reference. The Chang AC approach,
considering a uniform attenuation coefficient within the body contour, was also
implemented. Quantitative and clinical evaluation of the proposed methods were
performed considering SPECT CT-AC images of 19 subjects as reference using the
mean absolute error (MAE), structural similarity index (SSIM) metrics, as well
as relevant clinical indices such as perfusion deficit (TPD). Results: Overall,
the deep learning solution exhibited good agreement with the CT-based AC,
noticeably outperforming the Chang method. The ResNet and UNet models resulted
in the ME (count) of ${-6.99\pm16.72}$ and ${-4.41\pm11.8}$ and SSIM of
${0.99\pm0.04}$ and ${0.98\pm0.05}$, respectively. While the Change approach
led to ME and SSIM of ${25.52\pm33.98}$ and ${0.93\pm0.09}$, respectively.
Similarly, the clinical evaluation revealed a mean TPD of ${12.78\pm9.22}$ and
${12.57\pm8.93}$ for the ResNet and UNet models, respectively, compared to
${12.84\pm8.63}$ obtained from the reference SPECT CT-AC images. On the other
hand, the Chang approach led to a mean TPD of ${16.68\pm11.24}$. Conclusion: We
evaluated two deep convolutional neural networks to estimate SPECT-AC images
directly from the non-attenuation corrected images. The deep learning solutions
exhibited the promising potential to generate reliable attenuation corrected
SPECT images without the use of transmission scanning.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:10:40 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 10:35:35 GMT""}]","2021-02-11"
"2102.04916","Pierre Aumjaud","Pierre Aumjaud, David McAuliffe, Francisco Javier Rodr\'iguez Lera,
  Philip Cardiff","rl_reach: Reproducible Reinforcement Learning Experiments for Robotic
  Reaching Tasks","7 pages, 5 figures","Software Impacts. 8 (2021) 100061","10.1016/j.simpa.2021.100061",,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  Training reinforcement learning agents at solving a given task is highly
dependent on identifying optimal sets of hyperparameters and selecting suitable
environment input / output configurations. This tedious process could be eased
with a straightforward toolbox allowing its user to quickly compare different
training parameter sets. We present rl_reach, a self-contained, open-source and
easy-to-use software package designed to run reproducible reinforcement
learning experiments for customisable robotic reaching tasks. rl_reach packs
together training environments, agents, hyperparameter optimisation tools and
policy evaluation scripts, allowing its users to quickly investigate and
identify optimal training configurations. rl_reach is publicly available at
this URL: https://github.com/PierreExeter/rl_reach.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:14:10 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 19:32:01 GMT""}]","2021-03-03"
"2102.04917","Antongiulio Fornasiero","Antongiulio Fornasiero","Hilbert polynomial of length functions","Expanded the introduction and added some references. Added Sections
  2.2 and 3. Added Section 11 on Intrinsic Hilbert Polynomial",,,,"math.AC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let L be a general length function for modules over a Noetherian ring R. We
use L to define Hilbert series and polynomials for R[X]-modules. The leading
term of any such polynomial is an invariant of R[X]-modules, which refines the
algebraic entropy.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:15:51 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:56:18 GMT""},{""version"":""v3"",""created"":""Sat, 27 Mar 2021 15:57:40 GMT""}]","2021-03-30"
"2102.04918","Maozhen Wang","Maozhen Wang, Rui Luo, Aykut Ozgun Onol, Taskin Padir","Affordance-Based Mobile Robot Navigation Among Movable Obstacles","IROS 2020",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Avoiding obstacles in the perceived world has been the classical approach to
autonomous mobile robot navigation. However, this usually leads to unnatural
and inefficient motions that significantly differ from the way humans move in
tight and dynamic spaces, as we do not refrain interacting with the environment
around us when necessary. Inspired by this observation, we propose a framework
for autonomous robot navigation among movable obstacles (NAMO) that is based on
the theory of affordances and contact-implicit motion planning. We consider a
realistic scenario in which a mobile service robot negotiates unknown obstacles
in the environment while navigating to a goal state. An affordance extraction
procedure is performed for novel obstacles to detect their movability, and a
contact-implicit trajectory optimization method is used to enable the robot to
interact with movable obstacles to improve the task performance or to complete
an otherwise infeasible task. We demonstrate the performance of the proposed
framework by hardware experiments with Toyota's Human Support Robot.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:16:15 GMT""}]","2021-02-10"
"2102.04919","Maxime Dupont","Maxime Dupont, Nicolas Laflorencie","Quantum magnetism on small-world networks","12 pages, 8 figures","Phys. Rev. B 103, 174415 (2021)","10.1103/PhysRevB.103.174415",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While classical spin systems in random networks have been intensively
studied, much less is known about quantum magnets in random graphs. Here, we
investigate interacting quantum spins on small-world networks, building on
mean-field theory and extensive quantum Monte Carlo simulations. Starting from
one-dimensional (1D) rings, we consider two situations: all-to-all interacting
and long-range interactions randomly added. The effective infinite dimension of
the lattice leads to a magnetic ordering at finite temperature $T_\mathrm{c}$
with mean-field criticality. Nevertheless, in contrast to the classical case,
we find two distinct power-law behaviors for $T_\mathrm{c}$ versus the average
strength of the extra couplings. This is controlled by a competition between a
characteristic length scale of the random graph and the thermal correlation
length of the underlying 1D system, thus challenging mean-field theories. We
also investigate the fate of a gapped 1D spin chain against the small-world
effect.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:22:37 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 00:28:56 GMT""}]","2021-05-17"
"2102.04920","Fiorenzo Vincenzo","Fiorenzo Vincenzo, Todd A. Thompson, David H. Weinberg, Emily J.
  Griffith, James W. Johnson, Jennifer A. Johnson","Nucleosynthesis signatures of neutrino-driven winds from proto-neutron
  stars: a perspective from chemical evolution models","Accepted for publication in MNRAS",,"10.1093/mnras/stab2828",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We test the hypothesis that the observed first-peak (Sr, Y, Zr) and
second-peak (Ba) s-process elemental abundances in low-metallicity Milky Way
stars, and the abundances of the elements Mo and Ru, can be explained by a
pervasive r-process contribution originating in neutrino-driven winds from
highly-magnetic and rapidly rotating proto-neutron stars (proto-NSs). We
construct chemical evolution models that incorporate recent calculations of
proto-NS yields in addition to contributions from AGB stars, Type Ia
supernovae, and two alternative sets of yields for massive star winds and
core-collapse supernovae. For non-rotating massive star yields from either set,
models without proto-NS winds underpredict the observed s-process peak
abundances by $0.3$-$1\,\text{dex}$ at low metallicity, and they severely
underpredict Mo and Ru at all metallicities. Models incorporating wind yields
from proto-NSs with spin periods $P \sim 2$-$5\,\text{ms}$ fit the observed
trends for all these elements well. Alternatively, models omitting proto-NS
winds but adopting yields of rapidly rotating massive stars, with $v_{\rm rot}$
between $150$ and $300\,\text{km}\,\text{s}^{-1}$, can explain the observed
abundance levels reasonably well for $\text{[Fe/H]}<-2$. These models
overpredict [Sr/Fe] and [Mo/Fe] at higher metallicities, but with a tuned
dependence of $v_{\rm rot}$ on stellar metallicity they might achieve an
acceptable fit at all [Fe/H]. If many proto-NSs are born with strong magnetic
fields and short spin periods, then their neutrino-driven winds provide a
natural source for Sr, Y, Zr, Mo, Ru, and Ba in low-metallicity stellar
populations. Conversely, spherical winds from unmagnetized proto-NSs
overproduce the observed Sr, Y, and Zr abundances by a large factor.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:23:18 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 14:16:00 GMT""}]","2021-10-13"
"2102.04921","Shang-Yung Wang","Shang-Yung Wang","Comment on ""Fluctuations in Extractable Work Bound the Charging Power of
  Quantum Batteries""","1 page, comment on arXiv:1909.03558, completely rewritten with focus
  on closed-system analysis",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In an article by Garc\'ia-Pintos et al. [Rev. Lett. 125, 040601 (2020)] the
connection between the charging power of a quantum battery and the fluctuations
of a ""free energy operator"" whose expectation value characterizes the maximum
extractable work of the battery is studied. The result of the closed-system
analysis shows that for a general charging process the battery will have a
nonzero charging power if and only if the state of the battery is not an
eigenstate of the free energy operator. In this Comment, we point out a few
mistakes in the analysis and obtain the correct bound on the charging power.
Consequently, the result for closed-system dynamics is in general not correct.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:24:08 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 14:38:24 GMT""},{""version"":""v3"",""created"":""Fri, 16 Jul 2021 07:47:24 GMT""}]","2021-07-19"
"2102.04922","Yann Strozecki","D. Auger and X. Badin de Montjoye and Y. Strozecki","A Generic Strategy Improvement Method for Simple Stochastic Games","Accepted at MFCS 2021",,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  We present a generic strategy iteration algorithm (GSIA) to find an optimal
strategy of a simple stochastic game (SSG). We prove the correctness of GSIA,
and derive a general complexity bound, which implies and improves on the
results of several articles. First, we remove the assumption that the SSG is
stopping, which is usually obtained by a polynomial blowup of the game. Second,
we prove a tight bound on the denominator of the values associated to a
strategy, and use it to prove that all strategy iteration algorithms are in
fact fixed parameter tractable in the number of random vertices. All known
strategy iteration algorithms can be seen as instances of GSIA, which allows to
analyze the complexity of converge from below by Condon and to propose a class
of algorithms generalising Gimbert and Horn's algorithm. These algorithms
require less than $r!$ iterations in general and less iterations than the
current best deterministic algorithm for binary SSGs given by Ibsen-Jensen and
Miltersen.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:25:17 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 09:58:19 GMT""}]","2021-07-09"
"2102.04923","Zhuo-Song Zhang","Qi-Man Shao and Zhuo-Song Zhang","Berry--Esseen Bounds for Multivariate Nonlinear Statistics with
  Applications to M-estimators and Stochastic Gradient Descent Algorithms","54 pages",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a Berry--Esseen bound for general multivariate nonlinear
statistics by developing a new multivariate-type randomized concentration
inequality. The bound is the best possible for many known statistics. As
applications, Berry--Esseen bounds for M-estimators and averaged stochastic
gradient descent algorithms are obtained.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:29:52 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 04:26:44 GMT""}]","2021-04-02"
"2102.04924","Roee Cates","Roee Cates, Daphna Weinshall","More Is More -- Narrowing the Generalization Gap by Adding
  Classification Heads",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Overfit is a fundamental problem in machine learning in general, and in deep
learning in particular. In order to reduce overfit and improve generalization
in the classification of images, some employ invariance to a group of
transformations, such as rotations and reflections. However, since not all
objects exhibit necessarily the same invariance, it seems desirable to allow
the network to learn the useful level of invariance from the data. To this end,
motivated by self-supervision, we introduce an architecture enhancement for
existing neural network models based on input transformations, termed
'TransNet', together with a training algorithm suitable for it. Our model can
be employed during training time only and then pruned for prediction, resulting
in an equivalent architecture to the base model. Thus pruned, we show that our
model improves performance on various data-sets while exhibiting improved
generalization, which is achieved in turn by enforcing soft invariance on the
convolutional kernels of the last layer in the base model. Theoretical analysis
is provided to support the proposed method.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:30:33 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 12:16:26 GMT""}]","2021-02-12"
"2102.04925","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, Xing Xie","FedGNN: Federated Graph Neural Network for Privacy-Preserving
  Recommendation",,,"10.1038/s41467-022-30714-9",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Graph neural network (GNN) is widely used for recommendation to model
high-order interactions between users and items. Existing GNN-based
recommendation methods rely on centralized storage of user-item graphs and
centralized model learning. However, user data is privacy-sensitive, and the
centralized storage of user-item graphs may arouse privacy concerns and risk.
In this paper, we propose a federated framework for privacy-preserving
GNN-based recommendation, which can collectively train GNN models from
decentralized user data and meanwhile exploit high-order user-item interaction
information with privacy well protected. In our method, we locally train GNN
model in each user client based on the user-item graph inferred from the local
user-item interaction data. Each client uploads the local gradients of GNN to a
server for aggregation, which are further sent to user clients for updating
local GNN models. Since local gradients may contain private information, we
apply local differential privacy techniques to the local gradients to protect
user privacy. In addition, in order to protect the items that users have
interactions with, we propose to incorporate randomly sampled items as pseudo
interacted items for anonymity. To incorporate high-order user-item
interactions, we propose a user-item graph expansion method that can find
neighboring users with co-interacted items and exchange their embeddings for
expanding the local user-item graphs in a privacy-preserving way. Extensive
experiments on six benchmark datasets validate that our approach can achieve
competitive results with existing centralized GNN-based recommendation methods
and meanwhile effectively protect user privacy.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:30:53 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 08:27:46 GMT""}]","2022-10-12"
"2102.04926","Ibrahima N'Doye","I. N'Doye and W. Cai and A. Alalwan and X. Sun and W. G. Headary and
  M.-S. Alouini and B.-S. Ooi and T.-M. Laleg-Kirati","Reduction of the Beam Pointing Error for Improved Free-Space Optical
  Communication Link Performance",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Free-space optical communication is emerging as a low-power, low-cost, and
high data rate alternative to radio-frequency communication in short-to
medium-range applications. However, it requires a close-to-line-of-sight link
between the transmitter and the receiver. This paper proposes a robust $\cHi$
control law for free-space optical (FSO) beam pointing error systems under
controlled weak turbulence conditions. The objective is to maintain the
transmitter-receiver line, which means the center of the optical beam as close
as possible to the center of the receiving aperture within a prescribed
disturbance attenuation level. First, we derive an augmented nonlinear
discrete-time model for pointing error loss due to misalignment caused by weak
atmospheric turbulence. We then investigate the $\cHi$-norm optimization
problem that guarantees the closed-loop pointing error is stable and ensures
the prescribed weak disturbance attenuation. Furthermore, we evaluate the
closed-loop outage probability error and bit error rate (BER) that quantify the
free-space optical communication performance in fading channels. Finally, the
paper concludes with a numerical simulation of the proposed approach to the FSO
link's error performance.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:36:50 GMT""}]","2021-02-10"
"2102.04927","Mate Hartstein","Yu-Te Hsu, M\'at\'e Hartstein, Alexander J. Davies, Alexander J.
  Hickey, Mun K. Chan, Juan Porras, Toshinao Loew, Sofia V. Taylor, Hsu Liu,
  Alexander G. Eaton, Matthieu Le Tacon, Huakun Zuo, Jinhua Wang, Zengwei Zhu,
  Gilbert G. Lonzarich, Bernhard Keimer, Neil Harrison, Suchitra E. Sebastian","Unconventional quantum vortex matter state hosts quantum oscillations in
  the underdoped high-temperature cuprate superconductors","PNAS Commentary 'Fragile superconductivity at high magnetic fields'
  by Michael R. Norman, PNAS February 16, 2021 118 (7) e2100372118;
  https://doi.org/10.1073/pnas.2100372118","PNAS February 16, 2021 118 (7) e2021216118","10.1073/pnas.2021216118",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A central question in the underdoped cuprates pertains to the nature of the
pseudogap ground state. A conventional metallic ground state of the pseudogap
region has been argued to host quantum oscillations upon destruction of the
superconducting order parameter by modest magnetic fields. Here we use low
applied measurement currents and millikelvin temperatures on ultra-pure single
crystals of underdoped YBa$_2$Cu$_3$O$_{6+x}$ to unearth an unconventional
quantum vortex matter ground state characterized by vanishing electrical
resistivity, magnetic hysteresis, and non-ohmic electrical transport
characteristics beyond the highest laboratory accessible static fields. A new
model of the pseudogap ground state is now required to explain quantum
oscillations that are hosted by the bulk quantum vortex matter state without
experiencing sizeable additional damping in the presence of a large maximum
superconducting gap; possibilities include a pair density wave.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:38:20 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 18:48:56 GMT""}]","2021-03-02"
"2102.04928","Rafa{\l} Wawrzy\'nczak","Rafa{\l} Wawrzy\'nczak, Stanislaw Galeski, Jonathan Noky, Yan Sun,
  Claudia Felser, Johannes Gooth","Quasi-quantized Hall response in bulk InAs",,,"10.1038/s41598-022-05916-2",,"cond-mat.mes-hall cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quasi-quantized Hall effect (QQHE) is the three-dimensional (3D)
counterpart of the integer quantum Hall effect (QHE),exhibited only by
two-dimensional (2D) electron systems. It has recently been observed in layered
materials, consisting of stacks of weakly coupled 2D platelets that are yet
characterized by a 3D anisotropic Fermi surface. However, it is predicted that
the quasi-quantized 3D version of the 2D QHE should occur in a much broader
class of bulk materials, regardless of the underlying crystal structure. Here,
we compare the observation of quasi-quantized plateau-like features in the Hall
conductivity of then-type bulk semiconductor InAs with the predictions for the
3D QQHE in presence of parabolic electron bands. InAs takes form of a cubic
crystal without any low-dimensional substructure. The onset of the plateau-like
feature in the Hall conductivity scales with $\sqrt{2/3}k_{F}^{z}/\pi$ in units
of the conductance quantum and is accompanied by a Shubnikov-de Haas minimum in
the longitudinal resistivity, consistent wit the results of calculations. This
confirms the suggestion that the 3D QQHE may be a generic effect directly
observable in materials with small Fermi surfaces, placed in sufficiently
strong magnetic fields
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:38:54 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 17:05:42 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 15:50:41 GMT""}]","2022-02-10"
"2102.04929","Sajal Mukhopadhyay","Surja Sanyal, Vikash Kumar Singh, Fatos Xhafa, Banhi Sanyal, Sajal
  Mukhopadhyay","A Game Theoretic Framework for Surplus Food Distribution in Smart Cities
  and Beyond","31 pages, 8 figures, 5 tables",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Food waste is a major challenge for the present world. It is the precursor to
several socioeconomic problems that are plaguing the modern society. To counter
the same and to, simultaneously, stand by the undernourished, surplus food
redistribution has surfaced as a viable solution. Information and
Communications Technology (ICT)-mediated food redistribution is a highly
scalable approach and it percolates into the masses far better. Even if ICT is
not brought into the picture, the presence of food surplus redistribution in
developing countries like India is scarce and is limited to only a few of the
major cities. The discussion of a surplus food redistribution framework under
strategic settings is a less discussed topic around the globe. This paper aims
at addressing a surplus food redistribution framework under strategic settings,
thereby facilitating a smoother exchange of surplus food in the smart cities of
developing countries, and beyond. As ICT is seamlessly available in smart
cities, the paper aims to focus the framework in these cities. However, this
can be extended beyond the smart cities to places with greater human
involvement.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:40:35 GMT""}]","2021-02-10"
"2102.04930","Eanna E. Flanagan","Eanna E Flanagan","An order-unity correction to Hawking radiation","5 pages, no figures; v2 minor corrections; v3 minor clarifications
  and figure added","Phys. Rev. Lett. 127, 041301 (2021)","10.1103/PhysRevLett.127.041301",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a black hole first forms, the properties of the emitted radiation as
measured by observers near future null infinity are very close to the 1974
prediction of Hawking. However, deviations grow with time, and become of order
unity after a time $t \sim M_i^{7/3}$, where $M_i$ is the initial mass in
Planck units. After an evaporation time the corrections are large: the angular
distribution of the emitted radiation is no longer dominated by low multipoles,
with an exponential fall off at high multipoles. Instead, the radiation is
redistributed as a power law spectrum over a broad range of angular scales, all
the way down to the scale $\Delta \theta \sim 1/M_i$, beyond which there is
exponential falloff. This effect is is a quantum gravitational effect, whose
origin is the spreading of the wavefunction of the black hole's center of mass
location caused by the kicks of the individual outgoing quanta, discovered by
Page in 1980. The modified angular distribution of the Hawking radiation has an
important consequence: the number of soft hair modes that can effectively
interact with outgoing Hawking quanta increases from the handful of modes at
low multipoles $l$, to a large number of modes, of order $\sim M_i^2$. We argue
that this change unlocks the Hawking-Perry-Strominger mechanism for purifying
the Hawking radiation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:40:58 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 15:07:13 GMT""},{""version"":""v3"",""created"":""Thu, 3 Jun 2021 14:26:44 GMT""}]","2021-07-28"
"2102.04931","Stefan Steinerberger","Stefan Steinerberger","Max-Cut via Kuramoto-type Oscillators",,,,,"math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Max-Cut problem. Let $G = (V,E)$ be a graph with adjacency
matrix $(a_{ij})_{i,j=1}^{n}$. Burer, Monteiro & Zhang proposed to find, for
$n$ angles $\left\{\theta_1, \theta_2, \dots, \theta_n\right\} \subset [0,
2\pi]$, minima of the energy $$ f(\theta_1, \dots, \theta_n) = \sum_{i,j=1}^{n}
a_{ij} \cos{(\theta_i - \theta_j)}$$ because configurations achieving a global
minimum leads to a partition of size 0.878 Max-Cut(G). This approach is known
to be computationally viable and leads to very good results in practice. We
prove that by replacing $\cos{(\theta_i - \theta_j)}$ with an explicit function
$g_{\varepsilon}(\theta_i - \theta_j)$ global minima of this new functional
lead to a $(1-\varepsilon)$Max-Cut(G). This suggests some interesting
algorithms that perform well. It also shows that the problem of finding
approximate global minima of energy functionals of this type is NP-hard in
general.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:41:00 GMT""}]","2021-02-10"
"2102.04932","Hieu Nguyen","Kai Zhen (1 and 2), Hieu Duy Nguyen (2), Feng-Ju Chang (2), Athanasios
  Mouchtaris (2), and Ariya Rastrow (2). ((1) Indiana University Bloomington,
  (2) Alexa Machine Learning, Amazon, USA)","Sparsification via Compressed Sensing for Automatic Speech Recognition","5 pages, accepted for publication in (ICASSP 2021) 2021 IEEE
  International Conference on Acoustics, Speech, and Signal Processing. June
  6-12, 2021. Location: Toronto, ON, Canada",,,,"cs.LG cs.AI cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to achieve high accuracy for machine learning (ML) applications, it
is essential to employ models with a large number of parameters. Certain
applications, such as Automatic Speech Recognition (ASR), however, require
real-time interactions with users, hence compelling the model to have as low
latency as possible. Deploying large scale ML applications thus necessitates
model quantization and compression, especially when running ML models on
resource constrained devices. For example, by forcing some of the model weight
values into zero, it is possible to apply zero-weight compression, which
reduces both the model size and model reading time from the memory. In the
literature, such methods are referred to as sparse pruning. The fundamental
questions are when and which weights should be forced to zero, i.e. be pruned.
In this work, we propose a compressed sensing based pruning (CSP) approach to
effectively address those questions. By reformulating sparse pruning as a
sparsity inducing and compression-error reduction dual problem, we introduce
the classic compressed sensing process into the ML model training process.
Using ASR task as an example, we show that CSP consistently outperforms
existing approaches in the literature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:41:31 GMT""}]","2021-02-10"
"2102.04933","Jie Jiang","Jie Jiang and Xiaojun Chen","Pure Characteristics Demand Models and Distributionally Robust
  Mathematical Programs with Stochastic Complementarity Constraints",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate pure characteristics demand models under uncertainties of
probability distributions as distributionally robust mathematical programs with
stochastic complementarity constraints (DRMP-SCC). For any fixed first-stage
variable and a random realization, the second-stage problem of DRMP-SCC is a
monotone linear complementarity problem (LCP). To deal with uncertainties of
probability distributions of the involved random variables in the stochastic
LCP, we use the distributionally robust approach. Moreover, we propose an
approximation problem with regularization and discretization to solve DRMP-SCC,
which is a two-stage nonconvex-nonconcave minimax optimization problem. We
prove the convergence of the approximation problem to DRMP-SCC regarding the
optimal solution sets, optimal values and stationary points as the
regularization parameter goes to zero and the sample size goes to infinity.
Finally, preliminary numerical results for investigating distributional
robustness of pure characteristics demand models are reported to illustrate the
effectiveness and efficiency of our approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:42:10 GMT""}]","2021-02-10"
"2102.04934","Katarina Cicak","Katarina Cicak","Low-Temperature Collective Transport and Dynamics in Charge Density Wave
  Conductor Niobium Triselenide","264 pages, 81 figures. Ph.D. Thesis, Cornell University (2020)",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigated low-temperature dynamics in a charge density wave (CDW)
conductor NbSe3, a widely studied representative of a class of systems of
driven periodic media with quenched disorder and relevant to a wider group of
systems exhibiting collective transport behaviors. To date, theoretical efforts
have not converged to produce a consistent description of the rich dynamics
observed in these systems, especially in the low temperature regime. We
developed modern sample preparation techniques and used frequency- and
time-domain transport measurements below the second characteristic Peierls CDW
transition to investigate the regime of temporally-ordered collective creep in
NbSe3 samples in the low temperature regime between 15 K and 32 K. By measuring
the frequency of coherent oscillations between two characteristic threshold
fields, ET and ET*, we show that in nine high-quality samples, pure, Ta-, or
Ti-doped, the current-field relation for the collective transport in this
regime closely follows a modified Anderson-Kim form across five orders of
magnitude with thermally- and field-activated behavior above ET for a range of
temperatures. This study, combined with our transport relaxation measurements,
provides relevant length, energy, and time scales that set the dynamics in this
regime and reveals that the collective dynamics, governed by large length and
energy scales, must be reconciled with microscopic local dynamics, with
barriers at orders of magnitude smaller scales. The interplay between the
collective and local mechanisms set the dynamics that is responsible for
extremely slow (creep-like) collective, yet temporally-ordered behavior.
Combined with the existing work, our results paint a consistent picture of a
transport phase diagram for CDWs, and density-wave systems in general, and
provide essential ingredients for a much-needed correct theoretical description
of these systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:42:36 GMT""}]","2021-02-10"
"2102.04935","Nikola Sandri\'c","Nikola Sandri\'c and Ivana Valenti\'c","A CLT for degenerate diffusions with periodic coefficients, and
  application to homogenisation of linear PDEs",,,,,"math.PR","http://creativecommons.org/publicdomain/zero/1.0/","  In this article, we obtain a functional CLT for a class of degenerate
diffusion processes with periodic coefficients, thus generalizing the already
classical results in the context of uniformly elliptic diffusions. As an
application, we also discuss periodic homogenization of a class of linear
degenerate elliptic and parabolic PDEs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:44:00 GMT""}]","2021-02-10"
"2102.04937","Chihoon Lee","Chihoon Lee, Amy R. Ward, Heng-Qing Ye","Stationary Distribution Convergence of the Offered Waiting Processes in
  Heavy Traffic under General Patience Time Scaling",,,,,"math.PR stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a sequence of single server queues with customer abandonment
(GI/GI/1+GI) under heavy traffic. The patience time distributions vary with the
sequence, which allows for a wider scope of applications. It is known ([20,
18]) that the sequence of scaled offered waiting time processes converges
weakly to a reflecting diffusion process with non-linear drift, as the traffic
intensity approaches one. In this paper, we further show that the sequence of
stationary distributions and moments of the offered waiting times, with
diffusion scaling, converge to those of the limit diffusion process. This
justifies the stationary performance of the diffusion limit as a valid
approximation for the stationary performance of the GI/GI/1+GI queue.
Consequently, we also derive the approximation for the abandonment probability
for the GI/GI/1+GI queue in the stationary state.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:48:19 GMT""}]","2021-02-10"
"2102.04938","Oleksii Bashkanov","Oleksii Bashkanov, Anneke Meyer, Daniel Schindele, Martin Schostak,
  Klaus T\""onnies, Christian Hansen, Marko Rak","Learning Multi-Modal Volumetric Prostate Registration with Weak
  Inter-Subject Spatial Correspondence",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies demonstrated the eligibility of convolutional neural networks
(CNNs) for solving the image registration problem. CNNs enable faster
transformation estimation and greater generalization capability needed for
better support during medical interventions. Conventional fully-supervised
training requires a lot of high-quality ground truth data such as
voxel-to-voxel transformations, which typically are attained in a too tedious
and error-prone manner. In our work, we use weakly-supervised learning, which
optimizes the model indirectly only via segmentation masks that are a more
accessible ground truth than the deformation fields. Concerning the weak
supervision, we investigate two segmentation similarity measures: multiscale
Dice similarity coefficient (mDSC) and the similarity between
segmentation-derived signed distance maps (SDMs). We show that the combination
of mDSC and SDM similarity measures results in a more accurate and natural
transformation pattern together with a stronger gradient coverage. Furthermore,
we introduce an auxiliary input to the neural network for the prior information
about the prostate location in the MR sequence, which mostly is available
preoperatively. This approach significantly outperforms the standard two-input
models. With weakly labelled MR-TRUS prostate data, we showed registration
quality comparable to the state-of-the-art deep learning-based method.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:48:59 GMT""}]","2021-02-10"
"2102.04939","Jeongyeol Kwon","Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor","RL for Latent MDPs: Regret Guarantees and a Lower Bound",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we consider the regret minimization problem for reinforcement
learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is
randomly drawn from a set of $M$ possible MDPs at the beginning of the
interaction, but the identity of the chosen MDP is not revealed to the agent.
We first show that a general instance of LMDPs requires at least
$\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we
consider sufficient assumptions under which learning good policies requires
polynomial number of episodes. We show that the key link is a notion of
separation between the MDP system dynamics. With sufficient separation, we
provide an efficient algorithm with local guarantee, {\it i.e.,} providing a
sublinear regret guarantee when we are given a good initialization. Finally, if
we are given standard statistical sufficiency assumptions common in the
Predictive State Representation (PSR) literature (e.g., Boots et al.) and a
reachability assumption, we show that the need for initialization can be
removed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:49:58 GMT""}]","2021-02-10"
"2102.04940","Rivu Gupta","Rivu Gupta, Saptarshi Roy, Shiladitya Mal, Aditi Sen De","Emergence of Monogamy under Static and Dynamic Scenarios","14 pages, 15 figures and 5 tables",,,,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Characterizing multipartite quantum correlations beyond two parties is of
utmost importance for building cutting edge quantum technologies, although the
comprehensive picture is still missing. Here we investigate quantum
correlations (QCs) present in a multipartite system by exploring connections
between monogamy score (MS), localizable quantum correlations (LQC), and
genuine multipartite entanglement (GME) content of the state. We find that the
frequency distribution of GME for Dicke states with higher excitations
resembles that of random states. We show that there is a critical value of GME
beyond which all states become monogamous and it is investigated by considering
different powers of MS which provide various layers of monogamy relations.
Interestingly, such a relation between LQC and MS as well as GME does not hold.
States having a very low GME (low monogamy score, both positive and negative)
can localize a high amount of QCs in two parties. We also provide an upper
bound to the sum of bipartite QC measures including LQC for random states and
establish a gap between the actual upper bound and the algebraic maximum.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:50:37 GMT""}]","2021-02-10"
"2102.04941","Aria Nouri","Aria Nouri, Reza Asvadi, Jun Chen and Pascal O. Vontobel","Constrained Secrecy Capacity of Finite-Input Intersymbol Interference
  Wiretap Channels","16 pages, 8 figures, 1 table",,"10.1109/TCOMM.2023.3256415",,"cs.IT math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider reliable and secure communication over intersymbol interference
wiretap channels (ISI-WTCs). In particular, we first derive an achievable
secure rate for ISI-WTCs without imposing any constraints on the input
distribution. Afterwards, we focus on the setup where the input distribution of
the ISI-WTC is constrained to be a time-invariant finite-order Markov chain.
Optimizing the parameters of this Markov chain toward maximizing the achievable
secure rates is a computationally intractable problem in general, and so,
toward finding a local maximum, we propose an iterative algorithm that at every
iteration replaces the secure rate function with a suitable~surrogate function
whose maximum can be found efficiently. Although the secure rates achieved in
the unconstrained setup are potentially larger than the secure rates achieved
in the constrained setup, the latter setup has the advantage of leading to
efficient algorithms for estimating and optimizing the achievable secure rates,
and also has the benefit of being the basis of efficient coding schemes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:51:43 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 16:07:17 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 17:57:19 GMT""},{""version"":""v4"",""created"":""Fri, 15 Jul 2022 15:00:48 GMT""},{""version"":""v5"",""created"":""Wed, 12 Apr 2023 19:18:19 GMT""}]","2023-04-14"
"2102.04942","F\'elix G. Harvey","F\'elix G. Harvey, Mike Yurick, Derek Nowrouzezahrai, Christopher Pal","Robust Motion In-betweening","Published at SIGGRAPH 2020",,"10.1145/3386569.3392480",,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  In this work we present a novel, robust transition generation technique that
can serve as a new tool for 3D animators, based on adversarial recurrent neural
networks. The system synthesizes high-quality motions that use
temporally-sparse keyframes as animation constraints. This is reminiscent of
the job of in-betweening in traditional animation pipelines, in which an
animator draws motion frames between provided keyframes. We first show that a
state-of-the-art motion prediction model cannot be easily converted into a
robust transition generator when only adding conditioning information about
future keyframes. To solve this problem, we then propose two novel additive
embedding modifiers that are applied at each timestep to latent representations
encoded inside the network's architecture. One modifier is a time-to-arrival
embedding that allows variations of the transition length with a single model.
The other is a scheduled target noise vector that allows the system to be
robust to target distortions and to sample different transitions given fixed
keyframes. To qualitatively evaluate our method, we present a custom
MotionBuilder plugin that uses our trained model to perform in-betweening in
production scenarios. To quantitatively evaluate performance on transitions and
generalizations to longer time horizons, we present well-defined in-betweening
benchmarks on a subset of the widely used Human3.6M dataset and on LaFAN1, a
novel high quality motion capture dataset that is more appropriate for
transition generation. We are releasing this new dataset along with this work,
with accompanying code for reproducing our baseline results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:52:45 GMT""}]","2021-02-10"
"2102.04943","Jan M. L. Martin","Golokesh Santra, Emmanouil Semidalas, and Jan M.L. Martin","Exploring Avenues Beyond Revised DSD Functionals: II. Random-Phase
  Approximation and scaled MP3 corrections","J. Phys. Chem. A 125, ASAP (2021) Creative Commons License","J. Phys. Chem. A 125, 4628-4638 (2021)","10.1021/acs.jpca.1c01295",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For revDSD double hybrids, the G\""orling-Levy second-order perturbation
theory component is an Achilles' Heel when applied to systems with significant
near-degeneracy (""static"") correlation. We have explored its replacement by the
direct random phase approximation (dRPA), inspired by the SCS-dRPA75 functional
of K\'allay and coworkers. The addition to the final energy of both a D4
empirical dispersion correction, and of a semilocal correlation component lead,
to significant improvements, with DSD-PBEdRPA75-D4 approaching the performance
of revDSD-PBEP86-D4 and the Berkeley $\omega$B97M(2). This form appears to be
fairly insensitive to the choice of semilocal functional, but does exhibit
stronger basis set sensitivity than the PT2-based double hybrids (due to much
larger prefactors for the nonlocal correlation). As an alternative, we explored
adding an MP3-like correction term (in a medium-sized basis sets) to a
range-separated $\omega$DSD-PBEP86-D4 double hybrid, and found it to have
significantly lower WTMAD2 (weighted mean absolute deviation) for the large and
chemically diverse GMTKN55 benchmark suite; the added computational cost can be
mitigated through density fitting techniques.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:55:31 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 04:00:57 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 19:07:08 GMT""}]","2021-06-10"
"2102.04944","Maxim Buzdalov","Maxim Buzdalov and Carola Doerr","Optimal Static Mutation Strength Distributions for the $(1+\lambda)$
  Evolutionary Algorithm on OneMax","Submitted for review to GECCO'21",,"10.1145/3449639.3459389",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most evolutionary algorithms have parameters, which allow a great flexibility
in controlling their behavior and adapting them to new problems. To achieve the
best performance, it is often needed to control some of the parameters during
optimization, which gave rise to various parameter control methods. In recent
works, however, similar advantages have been shown, and even proven, for
sampling parameter values from certain, often heavy-tailed, fixed
distributions. This produced a family of algorithms currently known as ""fast
evolution strategies"" and ""fast genetic algorithms"".
  However, only little is known so far about the influence of these
distributions on the performance of evolutionary algorithms, and about the
relationships between (dynamic) parameter control and (static) parameter
sampling. We contribute to the body of knowledge by presenting, for the first
time, an algorithm that computes the optimal static distributions, which
describe the mutation operator used in the well-known simple $(1+\lambda)$
evolutionary algorithm on a classic benchmark problem OneMax. We show that, for
large enough population sizes, such optimal distributions may be surprisingly
complicated and counter-intuitive. We investigate certain properties of these
distributions, and also evaluate the performance regrets of the $(1+\lambda)$
evolutionary algorithm using commonly used mutation distributions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:56:25 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 01:58:28 GMT""}]","2021-06-07"
"2102.04945","Jordi Pons","Xiaoyu Liu and Jordi Pons","On permutation invariant training for speech source separation","In proceedings of ICASSP2021",,,,"cs.SD cs.AI eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study permutation invariant training (PIT), which targets at the
permutation ambiguity problem for speaker independent source separation models.
We extend two state-of-the-art PIT strategies. First, we look at the two-stage
speaker separation and tracking algorithm based on frame level PIT (tPIT) and
clustering, which was originally proposed for the STFT domain, and we adapt it
to work with waveforms and over a learned latent space. Further, we propose an
efficient clustering loss scalable to waveform models. Second, we extend a
recently proposed auxiliary speaker-ID loss with a deep feature loss based on
""problem agnostic speech features"", to reduce the local permutation errors made
by the utterance level PIT (uPIT). Our results show that the proposed
extensions help reducing permutation ambiguity. However, we also note that the
studied STFT-based models are more effective at reducing permutation errors
than waveform-based models, a perspective overlooked in recent studies.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:57:32 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 07:04:59 GMT""}]","2021-04-06"
"2102.04946","Laura Wolz","Laura Wolz, Alkistis Pourtsidou, Kiyoshi W. Masui, Tzu-Ching Chang,
  Julian E. Bautista, Eva-Maria Mueller, Santiago Avila, David Bacon, Will J.
  Percival, Steven Cunnington, Chris Anderson, Xuelei Chen, Jean-Paul Kneib,
  Yi-Chao Li, Yu-Wei Liao, Ue-Li Pen, Jeffrey B. Peterson, Graziano Rossi,
  Donald P. Schneider, Jaswant Yadav, Gong-Bo Zhao","HI constraints from the cross-correlation of eBOSS galaxies and Green
  Bank Telescope intensity maps","18 pages, 19 figures, 1 table; accepted by MNRAS",,"10.1093/mnras/stab3621",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present the joint analysis of Neutral Hydrogen (HI) Intensity Mapping
observations with three galaxy samples: the Luminous Red Galaxy (LRG) and
Emission Line Galaxy (ELG) samples from the eBOSS survey, and the WiggleZ Dark
Energy Survey sample. The HI intensity maps are Green Bank Telescope
observations of the redshifted 21cm emission on 100deg2 covering the redshift
range $0.6<z<1.0$. We process the data by separating and removing the
foregrounds with FastICA, and construct a transfer function to correct for the
effects of foreground removal on the HI signal. We cross-correlate the cleaned
HI data with the galaxy samples and study the overall amplitude as well as the
scale-dependence of the power spectrum. We also qualitatively compare our
findings with the predictions by a semi-analytic galaxy evolution simulation.
The cross-correlations constrain the quantity $\Omega_{{HI}} b_{{HI}}
r_{{HI},{opt}}$ at an effective scale $k_{eff}$, where $\Omega_{HI}$ is the HI
density fraction, $b_{HI}$ is the HI bias, and $r_{{HI},{opt}}$ the
galaxy-hydrogen correlation coefficient, which is dependent on the HI content
of the optical galaxy sample. At $k_{eff}=0.31 \, h/{Mpc}$ we find
$\Omega_{{HI}} b_{{HI}} r_{{HI},{Wig}} = [0.58 \pm 0.09 \, {(stat) \pm 0.05 \,
{(sys)}}] \times 10^{-3}$ for GBT-WiggleZ, $\Omega_{{HI}} b_{{HI}}
r_{{HI,{ELG}}} = [0.40 \pm 0.09 \, {(stat) \pm 0.04 \, {(sys)}}] \times
10^{-3}$ for GBT-ELG, and $\Omega_{{HI}} b_{{HI}} r_{{HI},{LRG}} = [0.35 \pm
0.08 \, {(stat) \pm 0.03 \, {(sys)}}] \times 10^{-3}$ for GBT-LRG, at $z\simeq
0.8$. We also report results at $k_{eff}=0.24 \, h/{Mpc}$ and $k_{eff}=0.48 \,
h/{Mpc}$. With little information on HI parameters beyond our local Universe,
these are amongst the most precise constraints on neutral hydrogen density
fluctuations in an underexplored redshift range.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:58:34 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 13:37:42 GMT""}]","2021-12-22"
"2102.04947","Christian Scharrer","Christian Scharrer","Embedded Delaunay tori and their Willmore energy","28 pages. Final version to appear in Nonlinear Analysis (TMA)",,"10.1016/j.na.2022.113010",,"math.DG math.CA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A family of embedded rotationally symmetric tori in the Euclidean 3-space
consisting of two opposite signed constant mean curvature surfaces that
converge as varifolds to a double round sphere is constructed. Using complete
elliptic integrals, it is shown that their Willmore energy lies strictly below
$8\pi$. Combining such a strict inequality with previous works by
Keller-Mondino-Rivi\`ere and Mondino-Scharrer allows to conclude that for every
isoperimetric ratio there exists a smoothly embedded torus minimising the
Willmore functional under isoperimetric constraint, thus completing the
solution of the isoperimetric-constrained Willmore problem for tori. Similarly,
we deduce the existence of smoothly embedded tori minimising the Helfrich
functional with small spontaneous curvature. Moreover, it is shown that the
tori degenerate in the moduli space which gives an application also to the
conformally-constrained Willmore problem. Finally, because of their symmetry,
the Delaunay tori can be used to construct spheres of high isoperimetric ratio,
leading to an alternative proof of the known result for the genus zero case.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:00:38 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 12:13:18 GMT""},{""version"":""v3"",""created"":""Tue, 31 May 2022 15:07:27 GMT""}]","2022-06-01"
"2102.04948","Brahim El Asri","Brahim El Asri and Nacer Ourkiya","Infinite Horizon Multi-Dimensional BSDE with Oblique Reflection and
  Switching Problem","18 pages. Reflected backward stochastic differential equations,
  Switching problem, Backward stochastic differential equations, Infinite
  horizon, Oblique reflection. Accepted in Stochastics and Dynamics (SD)",,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper studies a system of multi-dimensional reflected backward
stochastic differential equations with oblique reflections (RBSDEs for short)
in infinite horizon associated to switching problems. The existence and
uniqueness of the adapted solution is obtained by using a method based oa
combination of penalization, verification method and contraction property.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:01:00 GMT""},{""version"":""v2"",""created"":""Sun, 26 Feb 2023 10:39:47 GMT""}]","2023-02-28"
"2102.04949","Luoqin Liu","Luoqin Liu and Srinidhi N. Gadde and Richard J. A. M. Stevens","Universal Wind Profile for Conventionally Neutral Atmospheric Boundary
  Layers","11 pages, 6 figures, the article has been accepted by Physical Review
  Letters, see
  https://journals.aps.org/prl/accepted/2807bYecI411db78409a3879761405c3a75de2a07","Physical Review Letters 126, 104502 (2021)","10.1073/pnas.2119369119",,"physics.ao-ph physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Conventionally neutral atmospheric boundary layers (CNBLs), which are
characterized with zero surface potential temperature flux and capped by an
inversion of potential temperature, are frequently encountered in nature.
Therefore, predicting the wind speed profiles of CNBLs is relevant for weather
forecasting, climate modeling, and wind energy applications. However, previous
attempts to predict the velocity profiles in CNBLs have had limited success due
to the complicated interplay between buoyancy, shear, and Coriolis effects.
Here, we utilize ideas from the classical Monin-Obukhov similarity theory in
combination with a local scaling hypothesis to derive an analytic expression
for the stability correction function $\psi = -c_\psi (z/L)^{1/2}$, where
$c_\psi = 4.2$ is an empirical constant, $z$ is the height above ground, and
$L$ is the local Obukhov length based on potential temperature flux at that
height, for CNBLs. An analytic expression for this flux is also derived using
dimensional analysis and a perturbation method approach. We find that the
derived profile agrees excellently with the velocity profile in the entire
boundary layer obtained from high-fidelity large eddy simulations of typical
CNBLs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:01:02 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 05:46:36 GMT""}]","2022-07-06"
"2102.04950","Enrichetta Iodice","E. Iodice, M. Spavone, M.A. Raj, M. Capaccioli, M. Cantiello and VEGAS
  science team","The VST Early-type GAlaxy Survey (VEGAS) data release 1",,,,,"astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first data release (DR1) of the VST Early-type GAlaxy Survey
(VEGAS). This is a deep multi-band (u'g'r'i') imaging survey, carried out with
the ESO VLT Survey Telescope (VST). To date, using about 90% of the total
observing time, VEGAS has already collected 43 targets (groups and clusters of
galaxies) covering a total area on the sky of about 95 square degrees. Taking
advantage of the wide (1 deg^2) field-of-view of OmegaCAM@VST, the long
integration time and the wide variety of targets, VEGAS has proven to be a gold
mine to explore the structure of galaxies down to the faintest surface
brightness levels of about 27-30 mag/arcsec^2 in the SDSS g' band, for the
dense clusters of galaxies and for the unexplored poor groups of galaxies.
Based on the analysed data, VEGAS allowed us to i) study the galaxy outskirts,
detect the intra-cluster light and low-surface brightness features in the
intra-cluster/group space, ii) trace the mass assembly in galaxies, by
estimating the accreted mass fraction in the stellar halos and provide results
that can be directly compared with the predictions of galaxy formation models,
iii) trace the spatial distribution of candidate globular clusters, and iv)
detect the ultra-diffuse galaxies. With the DR1, we provide the reduced VST
mosaics of 10 targets, which have been presented in the VEGAS publications. The
data products are available via the ESO Science Portal (see
http://www.eso.org/sci/observing/phase3/news.html#VEGAS-DR1).
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:03:58 GMT""}]","2021-02-10"
"2102.04951","Antonio Candelieri","Antonio Candelieri, Francesco Archetti","MISO-wiLDCosts: Multi Information Source Optimization with Location
  Dependent Costs",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses black-box optimization over multiple information sources
whose both fidelity and query cost change over the search space, that is they
are location dependent. The approach uses: (i) an Augmented Gaussian Process,
recently proposed in multi-information source optimization as a single model of
the objective function over search space and sources, and (ii) a Gaussian
Process to model the location-dependent cost of each source. The former is used
into a Confidence Bound based acquisition function to select the next source
and location to query, while the latter is used to penalize the value of the
acquisition depending on the expected query cost for any source-location pair.
The proposed approach is evaluated on a set of Hyperparameters Optimization
tasks, consisting of two Machine Learning classifiers and three datasets of
different sizes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:04:17 GMT""}]","2021-02-10"
"2102.04952","Luca Marchese","Luca Marchese","A genus 4 origami with minimal hitting time and an intersection property","13 pages, 2 figures",,,,"math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a minimal flow, the hitting time is the exponent of the power law, as r
goes to zero, for the time needed by orbits to become r-dense. We show that on
the so-called Ornithorynque origami the hitting time of the flow in an
irrational slope equals the diophantine type of the slope. We give a general
criterion for such equality. In general, for genus at least two, hitting time
is strictly bigger than diophantine type.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:04:28 GMT""}]","2021-02-10"
"2102.04953","Robin Karlsson","Robin Karlsson, Andrei Parnachev, Petar Tadi\'c","Thermalization in Large-N CFTs","67 pages. 6 figures. v2: References added. v3: Minor corrections",,"10.1007/JHEP09(2021)205",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In d-dimensional CFTs with a large number of degrees of freedom an important
set of operators consists of the stress tensor and its products, multi stress
tensors. Thermalization of such operators, the equality between their
expectation values in heavy states and at finite temperature, is equivalent to
a universal behavior of their OPE coefficients with a pair of identical heavy
operators. We verify this behavior in a number of examples which include
holographic and free CFTs and provide a bootstrap argument for the general
case. In a free CFT we check the thermalization of multi stress tensor
operators directly and also confirm the equality between the contributions of
multi stress tensors to heavy-heavy-light-light correlators and to the
corresponding thermal light-light two-point functions by disentangling the
contributions of other light operators. Unlike multi stress tensors, these
light operators violate the Eigenstate Thermalization Hypothesis and do not
thermalize.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:09:03 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 17:13:43 GMT""},{""version"":""v3"",""created"":""Thu, 5 Aug 2021 13:38:42 GMT""}]","2021-10-12"
"2102.04954","Di Zhang","Di Zhang and Shun Zhou","Radiative Decays of Charged Leptons in the Seesaw Effective Field Theory
  with One-loop Matching","20 pages, 3 figures, matches the version published in PLB","Phys.Lett.B 819 (2021) 136463","10.1016/j.physletb.2021.136463",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The canonical type-I seesaw model with three heavy Majorana neutrinos is one
of the most natural extensions of the standard model (SM) to accommodate tiny
Majorana masses of three ordinary neutrinos. At low-energy scales, Majorana
neutrino masses and unitarity violation of lepton flavor mixing have been
extensively discussed in the literature, which are respectively generated by
the unique dimension-five Weinberg operator and one dimension-six operator in
the seesaw effective field theory (SEFT) with the tree-level matching. In this
work, we clarify that a self-consistent calculation of radiative decays of
charged leptons $\beta^- \to \alpha^- + \gamma$ requires the SEFT with one-loop
matching, where new six-dimensional operators emerge and make important
contributions. For the first time, the Wilson coefficients of all the relevant
six-dimensional operators are computed by carrying out the one-loop matching
between the effective theory and full seesaw model, and applied to calculate
the total rates of radiative decays of charged leptons.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:09:55 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 13:18:36 GMT""},{""version"":""v3"",""created"":""Wed, 30 Jun 2021 02:57:12 GMT""}]","2021-07-01"
"2102.04955","Fan Feng","Fan Feng, Daniel Duffy, Mark Warner, and John S. Biggins","Interfacial metric mechanics: stitching patterns of shape change in
  active sheets","26 pages, 11 figures","Proc. R. Soc. A. 478:20220230.20220230 (2022)","10.1098/rspa.2022.0230",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A flat sheet programmed with a planar pattern of spontaneous shape change
will morph into a curved surface. Such metric mechanics is seen in growing
biological sheets, and may be engineered in actuating soft matter sheets such
as phase-changing liquid crystal elastomers (LCEs), swelling gels and inflating
baromorphs. Here, we show how to combine multiple patterns in a sheet by
stitching regions of different shape changes together piecewise along
interfaces. This approach allows simple patterns to be used as building blocks,
and enables the design of multi-material or active/passive sheets. We give a
general condition for an interface to be geometrically compatible, and explore
its consequences for LCE/LCE, gel/gel, and active/passive interfaces. In
contraction/elongation systems such as LCEs, we find an infinite set of
compatible interfaces between any pair of patterns along which the metric is
discontinuous, and a finite number across which the metric is continuous. As an
example, we find all possible interfaces between pairs of LCE logarithmic
spiral patterns. In contrast, in isotropic systems such as swelling gels, only
a finite number of continuous interfaces are available, greatly limiting the
potential of stitching. In both continuous and discontinuous cases, we find the
stitched interfaces generically carry singular Gaussian curvature, leading to
intrinsically curved folds in the actuated surface. We give a general
expression for the distribution of this curvature, and a more specialized form
for interfaces in LCE patterns. The interfaces thus also have rich geometric
and mechanical properties in their own right.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:10:58 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 19:10:24 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 13:09:38 GMT""},{""version"":""v4"",""created"":""Fri, 1 Apr 2022 17:09:42 GMT""},{""version"":""v5"",""created"":""Thu, 30 Jun 2022 11:03:36 GMT""}]","2022-07-01"
"2102.04956","Khalil Zakeri Lori","Kh. Zakeri, A. Hjelt, I. V. Maznichenko, P. Buczek, and A. Ernst","Nonlinear Decay of Quantum Confined Magnons in Itinerant Ferromagnets",,"Phys. Rev. Lett. 126, 177203 (2021)","10.1103/PhysRevLett.126.177203",,"cond-mat.mtrl-sci cond-mat.str-el physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum confinement leads to the emergence of several magnon modes in
ultrathin layered magnetic structures. We probe the lifetime of these quantum
confined modes in a model system composed of three atomic layers of Co grown on
different surfaces. We demonstrate that the quantum confined magnons exhibit
nonlinear decay rates, which strongly depend on the mode number, in sharp
contrast to what is assumed in the classical dynamics. Combining the
experimental results with those of linear-response density functional
calculations we provide a quantitative explanation for this nonlinear damping
effect. The results provide new insights into the decay mechanism of spin
excitations in ultrathin films and multilayers and pave the way for tuning the
dynamical properties of such structures.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:12:06 GMT""}]","2021-04-29"
"2102.04957","James Tuite","James Tuite, Grahame Erskine, Nika Salia","Turan problems for $k$-geodetic digraphs",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A digraph $G$ is \emph{$k$-geodetic} if for any pair of (not necessarily
distinct) vertices $u,v \in V(G)$ there is at most one walk of length $\leq k$
from $u$ to $v$ in $G$. In this paper we determine the largest possible size of
a $k$-geodetic digraph with given order. We then consider the more difficult
problem of the largest size of a strongly-connected $k$-geodetic digraph with
given order, solving this problem for $k = 2$ and giving a construction which
we conjecture to be extremal for larger $k$. We close with some results on
generalised Tur\'{a}n problems for the number of directed cycles and paths in
$k$-geodetic digraphs.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:12:51 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 17:40:21 GMT""}]","2022-03-29"
"2102.04958","Robyn Kozierok","Robyn Kozierok, John Aberdeen, Cheryl Clark, Christopher Garay,
  Bradley Goodman, Tonia Korves, Lynette Hirschman, Patricia L. McDermott,
  Matthew W. Peterson","Hallmarks of Human-Machine Collaboration: A framework for assessment in
  the DARPA Communicating with Computers Program","20 pages, 21 figures",,,"MITRE Document Number: MTR210002","cs.HC cs.AI cs.CL cs.MA cs.MM","http://creativecommons.org/licenses/by/4.0/","  There is a growing desire to create computer systems that can communicate
effectively to collaborate with humans on complex, open-ended activities.
Assessing these systems presents significant challenges. We describe a
framework for evaluating systems engaged in open-ended complex scenarios where
evaluators do not have the luxury of comparing performance to a single right
answer. This framework has been used to evaluate human-machine creative
collaborations across story and music generation, interactive block building,
and exploration of molecular mechanisms in cancer. These activities are
fundamentally different from the more constrained tasks performed by most
contemporary personal assistants as they are generally open-ended, with no
single correct solution, and often no obvious completion criteria.
  We identified the Key Properties that must be exhibited by successful
systems. From there we identified ""Hallmarks"" of success -- capabilities and
features that evaluators can observe that would be indicative of progress
toward achieving a Key Property. In addition to being a framework for
assessment, the Key Properties and Hallmarks are intended to serve as goals in
guiding research direction.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:13:53 GMT""}]","2021-02-10"
"2102.04959","Arlene Cristina Aguilar","A. C. Aguilar, F. De Soto, M. N. Ferreira, J. Papavassiliou, J.
  Rodr\'iguez-Quintero","Infrared facets of the three-gluon vertex","7 pages, 7 figures",,"10.1016/j.physletb.2021.136352",,"hep-ph hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present novel lattice results for the form factors of the quenched
three-gluon vertex of QCD, in two special kinematic configurations that depend
on a single momentum scale. We consider three form factors, two associated with
a classical tensor structure and one without tree-level counterpart, exhibiting
markedly different infrared behaviors. Specifically, while the former display
the typical suppression driven by a negative logarithmic singularity at the
origin, the latter saturates at a small negative constant. These exceptional
features are analyzed within the Schwinger-Dyson framework, with the aid of
special relations obtained from the Slavnov-Taylor identities of the theory.
The emerging picture of the underlying dynamics is thoroughly corroborated by
the lattice results, both qualitatively as well as quantitatively.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:17:03 GMT""}]","2021-05-12"
"2102.04961","Artem Volosniev","David Huber, Oleksandr V. Marchukov, Hans-Werner Hammer, and Artem G.
  Volosniev","Morphology of three-body quantum states from machine learning","version accepted for publication in New Journal of Physics (Focus
  Issue on Machine Learning Across Physics)","New J. Phys. 23, 065009 (2021)","10.1088/1367-2630/ac0576",,"quant-ph cond-mat.quant-gas nlin.SI nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relative motion of three impenetrable particles on a ring, in our case
two identical fermions and one impurity, is isomorphic to a triangular quantum
billiard. Depending on the ratio $\kappa$ of the impurity and fermion masses,
the billiards can be integrable or non-integrable (also referred to in the main
text as chaotic). To set the stage, we first investigate the energy level
distributions of the billiards as a function of $1/\kappa\in [0,1]$ and find no
evidence of integrable cases beyond the limiting values $1/\kappa=1$ and
$1/\kappa=0$. Then, we use machine learning tools to analyze properties of
probability distributions of individual quantum states. We find that
convolutional neural networks can correctly classify integrable and
non-integrable states.The decisive features of the wave functions are the
normalization and a large number of zero elements, corresponding to the
existence of a nodal line. The network achieves typical accuracies of 97%,
suggesting that machine learning tools can be used to analyze and classify the
morphology of probability densities obtained in theory or experiment.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:23:08 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 14:09:47 GMT""}]","2021-08-03"
"2102.04962","Matteo Sfragara","Matteo Sfragara","Adding edge dynamics to bipartite random-access networks","33 pages, 1 figure",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider random-access networks with nodes representing
transmitter-receiver pairs whose signals interfere with each other depending on
their vicinity. Data packets arrive at the nodes over time and form queues. The
nodes can be either active or inactive: a node deactivates at unit rate, while
it activates at a rate that depends on its queue length, provided none of its
neighbors is active. In order to model the effects of user mobility in wireless
networks, we analyze dynamic interference graphs where the edges are allowed to
appear and disappear over time. We focus on bipartite graphs and study the
transition time between the two states where one part of the network is active
and the other part is inactive, in the limit as the queue lengths become large.
Depending on the speed of the dynamics, we are able to obtain a rough
classification of the effects of the dynamics on the transition time.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:26:11 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 17:13:38 GMT""},{""version"":""v3"",""created"":""Fri, 18 Feb 2022 12:24:28 GMT""},{""version"":""v4"",""created"":""Tue, 3 May 2022 17:58:39 GMT""}]","2022-05-04"
"2102.04963","Francesco Polizzi","Francesco Polizzi, Pietro Sabatino","Extra-special quotients of surface braid groups and double Kodaira
  fibrations with small signature","28 pages, 2 figures. Title changed. Final version, to appear in
  Geometriae Dedicata","Geometriae Dedicata 216, article 65 (2022)","10.1007/s10711-022-00720-8",,"math.AG math.GR math.GT","http://creativecommons.org/licenses/by/4.0/","  We study some special systems of generators on finite groups, introduced in
previous work by the first author and called ""diagonal double Kodaira
structures"", in order to investigate non-abelian, finite quotients of the pure
braid group on two strands $\mathsf{P}_2(\Sigma_b)$, where $\Sigma_b$ is a
closed Riemann surface of genus $b$. In particular, we prove that, if a finite
group $G$ admits a diagonal double Kodaira structure, then $|G|\geq 32$, and
equality holds if and only if $G$ is extra-special. In the last section, as a
geometrical application of our algebraic results, we construct two
$3$-dimensional families of double Kodaira fibrations having signature $16$.
Such surfaces are different from the ones recently constructed by Lee, L\""onne
and Rollenske and, as far as we know, they provide the first examples of
positive-dimensional families of double Kodaira fibrations with small
signature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:32:24 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 10:22:41 GMT""},{""version"":""v3"",""created"":""Fri, 29 Jul 2022 15:15:59 GMT""},{""version"":""v4"",""created"":""Mon, 1 Aug 2022 07:33:59 GMT""}]","2022-09-07"
"2102.04964","Louise Harra","L. Harra, D. H. Brooks, S. D. Bale, C. H. Mandrini, K. Barczynski, R.
  Sharma, S. T. Badman, S. Vargas Dominguez and M. Pulupa","The active region source of a type III radio storm observed by Parker
  Solar Probe during Encounter 2",,"A&A 650, A7 (2021)","10.1051/0004-6361/202039514",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. To investigate the source of a type III radio burst storm during
encounter 2 of NASA's Parker Solar Probe (PSP) mission.
  Aims. It was observed that in encounter 2 of NASA's Parker Solar Probe
mission there was a large amount of radio activity, and in particular a noise
storm of frequent, small type III bursts from 31st March to 6th April 2019. Our
aim is to investigate the source of these small and frequent bursts.
  Methods. In order to do this, we analysed data from the Hinode EUV Imaging
Spectrometer (EIS), PSP FIELDS, and the Solar Dynamics Observatory (SDO)
Atmospheric Imaging Assembly (AIA). We studied the behaviour of active region
12737, whose emergence and evolution coincides with the timing of the radio
noise storm and determined the possible origins of the electron beams within
the active region. To do this, we probe the dynamics, Doppler velocity,
non-thermal velocity, FIP bias, densities, and carry out magnetic modelling.
  Results. We demonstrate that although the active region on the disk produces
no significant flares, its evolution indicates it is a source of the electron
beams causing the radio storm. They most likely originate from the area at the
edge of the active region that shows strong blue-shifted plasma. We demonstrate
that as the active region grows and expands, the area of the blue-shifted
region at the edge increases, which is also consistent with the increasing area
where large-scale or expanding magnetic field lines from our modelling are
anchored. This expansion is most significant between 1 and 4 April 2019,
coinciding with the onset of the type III storm and the decrease of the
individual burst's peak frequency, indicating the height at which the peak
radiation is emitted increases as the active region evolves.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:34:44 GMT""}]","2021-06-02"
"2102.04965","Michal Balazia","Michal Balazia, S L Happy, Francois Bremond, Antitza Dantcheva","How Unique Is a Face: An Investigative Study","Preprint. Full paper accepted at the IEEE/IAPR International
  Conference on Pattern Recognition (ICPR), Milan, Italy, January 2021. 6 pages",,"10.1109/ICPR48806.2021.9412446",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face recognition has been widely accepted as a means of identification in
applications ranging from border control to security in the banking sector.
Surprisingly, while widely accepted, we still lack the understanding of
uniqueness or distinctiveness of faces as biometric modality. In this work, we
study the impact of factors such as image resolution, feature representation,
database size, age and gender on uniqueness denoted by the Kullback-Leibler
divergence between genuine and impostor distributions. Towards understanding
the impact, we present experimental results on the datasets AT&T, LFW,
IMDb-Face, as well as ND-TWINS, with the feature extraction algorithms VGGFace,
VGG16, ResNet50, InceptionV3, MobileNet and DenseNet121, that reveal the
quantitative impact of the named factors. While these are early results, our
findings indicate the need for a better understanding of the concept of
biometric uniqueness and its implication on face recognition.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:35:39 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 15:07:41 GMT""},{""version"":""v3"",""created"":""Wed, 7 Dec 2022 22:17:24 GMT""}]","2022-12-09"
"2102.04966","Christian Fredrik S{\ae}tre","Christian Fredrik S{\ae}tre and Anton S. Shiriaev","Orbital Stabilization of Point-to-Point Maneuvers in Underactuated
  Mechanical Systems","Accepted for publication in Automatica",,"10.1016/j.automatica.2022.110735",,"eess.SY cs.RO cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of inducing, via continuous static state-feedback control, an
asymptotically stable heteroclinic orbit in a nonlinear control system is
considered in this paper. The main motivation comes from the problem of
ensuring convergence to a so-called point-to-point maneuver in an underactuated
mechanical system. Namely, to a smooth curve in its state--control space, which
is consistent with the system dynamics and connects two (linearly) stabilizable
equilibrium points. The proposed method uses a particular parameterization,
together with a state projection onto the maneuver as to combine two
linearization techniques for this purpose: the Jacobian linearization at the
equilibria on the boundaries and a transverse linearization along the orbit.
This allows for the computation of stabilizing control gains offline by solving
a semidefinite programming problem. The resulting nonlinear controller, which
simultaneously asymptotically stabilizes both the orbit and the final
equilibrium, is time-invariant, locally Lipschitz continuous, requires no
switching, and has a familiar feedforward plus feedback--like structure. The
method is also complemented by synchronization function--based arguments for
planning such maneuvers for mechanical systems with one degree of
underactuation. Numerical simulations of the non-prehensile manipulation task
of a ball rolling between two points upon the ""butterfly"" robot demonstrates
the efficacy of the synthesis.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:35:44 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 12:36:56 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jun 2022 11:14:07 GMT""},{""version"":""v4"",""created"":""Mon, 14 Nov 2022 15:44:12 GMT""}]","2023-02-16"
"2102.04967","Sachi Hashimoto","Sachi Hashimoto and Pim Spelier","A geometric linear Chabauty comparison theorem","fixed minor issues and updated exposition; to appear in Acta
  Arithmetica",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Chabauty-Coleman method is a $p$-adic method for finding all rational
points on curves of genus $g$ whose Jacobians have Mordell-Weil rank $r < g$.
Recently, Edixhoven and Lido developed a geometric quadratic Chabauty method
that was adapted by Spelier to cover the case of geometric linear Chabauty. We
compare the geometric linear Chabauty method and the Chabauty-Coleman method
and show that geometric linear Chabauty can outperform Chabauty-Coleman in
certain cases. However, as Chabauty-Coleman remains more practical for general
computations, we discuss how to strengthen Chabauty-Coleman to make it
theoretically equivalent to geometric linear Chabauty. We apply these methods
to genus 2 and genus 3 curves.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:35:47 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 16:54:39 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 14:31:31 GMT""}]","2021-12-13"
"2102.04968","Bing Zhang","Bing Zhang, Yu Wang and Liang Li","Dissecting the Energy Budget of a Gamma-Ray Burst Fireball","Matching the version published in ApJL","2021, ApJL, 909, L3","10.3847/2041-8213/abe6ab",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The jet composition and radiative efficiency of GRBs are poorly constrained
from the data. If the jet composition is matter-dominated (i.e. a fireball),
the GRB prompt emission spectra would include a dominant thermal component
originating from the fireball photosphere, and a non-thermal component
presumably originating from internal shocks whose radii are greater than the
photosphere radius. We propose a method to directly dissect the GRB fireball
energy budget into three components and measure their values by combining the
prompt emission and early afterglow data. The measured parameters include the
initial dimensionless specific enthalpy density ($\eta$), bulk Lorentz factors
at the photosphere radius ($\Gamma_{\rm ph}$) and before fireball deceleration
($\Gamma_0$), the amount of mass loading ($M$), as well as the GRB radiative
efficiency ($\eta_\gamma$). All the parameters can be derived from the data for
a GRB with a dominant thermal spectral component, a deceleration bump feature
in the early afterglow lightcurve, and a measured redshift. The results only
weakly depend on the density $n$ of the interstellar medium when the
composition ${\cal Y}$ parameter (typically unity) is specified.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:37:07 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 21:54:35 GMT""}]","2021-03-10"
"2102.04970","Michael Hutchings","Dan Cristofaro-Gardiner, Umberto Hryniewicz, Michael Hutchings, Hui
  Liu","Contact three-manifolds with exactly two simple Reeb orbits","29 pages; v4 has minor edits, to appear in Geometry and Topology",,,,"math.SG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that every contact form on a closed three-manifold has at least
two simple Reeb orbits, and a generic contact form has infinitely many. We show
that if there are exactly two simple Reeb orbits, then the contact form is
nondegenerate. Combined with a previous result, this implies that the
three-manifold is diffeomorphic to the three-sphere or a lens space, and the
two simple Reeb orbits are the core circles of a genus one Heegaard splitting.
We also obtain further information about the Reeb dynamics and the contact
structure. For example the Reeb flow has a disk-like global surface of section
and so its dynamics are described by a pseudorotation; the contact struture is
universally tight; and in the case of the three-sphere, the contact volume and
the periods and rotation numbers of the simple Reeb orbits satisfy the same
relations as for an irrational ellipsoid.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:40:47 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 17:18:04 GMT""},{""version"":""v3"",""created"":""Sat, 26 Jun 2021 21:02:38 GMT""},{""version"":""v4"",""created"":""Thu, 24 Mar 2022 16:50:25 GMT""}]","2022-03-25"
"2102.04971","Gunther Rei{\ss}ig","Mohamed Serry and Gunther Reissig","Over-approximating reachable tubes of linear time-varying systems","Accepted version","IEEE Trans Autom Control, 2022","10.1109/TAC.2021.3057504",,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  We present a method to over-approximate reachable tubes over compact
time-intervals, for linear continuous-time, time-varying control systems whose
initial states and inputs are subject to compact convex uncertainty. The method
uses numerical approximations of transition matrices, is convergent of first
order, and assumes the ability to compute with compact convex sets in finite
dimension. We also present a variant that applies to the case of zonotopic
uncertainties, uses only linear algebraic operations, and yields zonotopic
over-approximations. The performance of the latter variant is demonstrated on
an example.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:42:48 GMT""}]","2021-02-10"
"2102.04972","Shane Mueller","Shane T. Mueller, Elizabeth S. Veinott, Robert R. Hoffman, Gary Klein,
  Lamia Alam, Tauseef Mamun, and William J. Clancey","Principles of Explanation in Human-AI Systems","AAAI-2021, Explainable Agency in Artificial Intelligence WS, AAAI,
  Feb, 2021, Virtual Conference, United States",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explainable Artificial Intelligence (XAI) has re-emerged in response to the
development of modern AI and ML systems. These systems are complex and
sometimes biased, but they nevertheless make decisions that impact our lives.
XAI systems are frequently algorithm-focused; starting and ending with an
algorithm that implements a basic untested idea about explainability. These
systems are often not tested to determine whether the algorithm helps users
accomplish any goals, and so their explainability remains unproven. We propose
an alternative: to start with human-focused principles for the design, testing,
and implementation of XAI systems, and implement algorithms to serve that
purpose. In this paper, we review some of the basic concepts that have been
used for user-centered XAI systems over the past 40 years of research. Based on
these, we describe the ""Self-Explanation Scorecard"", which can help developers
understand how they can empower users by enabling self-explanation. Finally, we
present a set of empirically-grounded, user-centered design principles that may
guide developers to create successful explainable systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:43:45 GMT""}]","2021-02-10"
"2102.04973","David Wilson","Luke Gayer, Nicolas Lang, Sin\'ead M. Ryan, David Tims, Christopher E.
  Thomas, David J. Wilson","Isospin-1/2 $D\pi$ scattering and the lightest $D_0^\ast$ resonance from
  lattice QCD","40 pages, 15 figures. Various small changes to match the version
  accepted by JHEP","JHEP 07 (2021) 123","10.1007/JHEP07(2021)123",,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Isospin-1/2 $D\pi$ scattering amplitudes are computed using lattice QCD,
working in a single volume of approximately $(3.6\; \mathrm{fm})^3$ and with a
light quark mass corresponding to $m_\pi\approx239$ MeV. The spectrum of the
elastic $D\pi$ energy region is computed yielding 20 energy levels. Using the
L\""uscher finite-volume quantisation condition, these energies are translated
into constraints on the infinite-volume scattering amplitudes and hence enable
us to map out the energy dependence of elastic $D\pi$ scattering. By
analytically continuing a range of scattering amplitudes, a $D_0^\ast$
resonance pole is consistently found strongly coupled to the $S$-wave $D\pi$
channel, with a mass $m\approx 2200$ MeV and a width $\Gamma\approx400$ MeV.
Combined with earlier work investigating the $D_{s0}^\ast$, and $D_0^\ast$ with
heavier light quarks, similar couplings between each of these scalar states and
their relevant meson-meson scattering channels are determined. The mass of the
$D_0^\ast$ is consistently found well below that of the $D_{s0}^\ast$, in
contrast to the currently reported experimental result.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:45:20 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 09:18:42 GMT""}]","2021-08-30"
"2102.04974","Michele Garetto","Michele Garetto and Emilio Leonardi and Giovanni Neglia","Content Placement in Networks of Similarity Caches",,,,,"cs.NI cs.DC cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Similarity caching systems have recently attracted the attention of the
scientific community, as they can be profitably used in many application
contexts, like multimedia retrieval, advertising, object recognition,
recommender systems and online content-match applications. In such systems, a
user request for an object $o$, which is not in the cache, can be (partially)
satisfied by a similar stored object $o$', at the cost of a loss of user
utility. In this paper we make a first step into the novel area of similarity
caching networks, where requests can be forwarded along a path of caches to get
the best efficiency-accuracy tradeoff. The offline problem of content placement
can be easily shown to be NP-hard, while different polynomial algorithms can be
devised to approach the optimal solution in discrete cases. As the content
space grows large, we propose a continuous problem formulation whose solution
exhibits a simple structure in a class of tree topologies. We verify our
findings using synthetic and realistic request traces.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:48:24 GMT""}]","2021-02-10"
"2102.04975","Prasanth Shyamsundar","Prasanth Shyamsundar","Non-Boolean Quantum Amplitude Amplification and Quantum Mean Estimation","36 pages, 16 figures",,,"FERMILAB-PUB-21-018-QIS","quant-ph","http://creativecommons.org/licenses/by/4.0/","  This paper generalizes the quantum amplitude amplification and amplitude
estimation algorithms to work with non-boolean oracles. The action of a
non-boolean oracle $U_\varphi$ on an eigenstate $|x\rangle$ is to apply a
state-dependent phase-shift $\varphi(x)$. Unlike boolean oracles, the
eigenvalues $\exp(i\varphi(x))$ of a non-boolean oracle are not restricted to
be $\pm 1$. Two new oracular algorithms based on such non-boolean oracles are
introduced. The first is the non-boolean amplitude amplification algorithm,
which preferentially amplifies the amplitudes of the eigenstates based on the
value of $\varphi(x)$. Starting from a given initial superposition state
$|\psi_0\rangle$, the basis states with lower values of $\cos(\varphi)$ are
amplified at the expense of the basis states with higher values of
$\cos(\varphi)$. The second algorithm is the quantum mean estimation algorithm,
which uses quantum phase estimation to estimate the expectation
$\langle\psi_0|U_\varphi|\psi_0\rangle$, i.e., the expected value of
$\exp(i\varphi(x))$ for a random $x$ sampled by making a measurement on
$|\psi_0\rangle$. It is shown that the quantum mean estimation algorithm offers
a quadratic speedup over the corresponding classical algorithm. Both algorithms
are demonstrated using simulations for a toy example. Potential applications of
the algorithms are briefly discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:48:38 GMT""}]","2021-02-10"
"2102.04976","Ben Zhu","Ben Zhu, Haruki Seto, Xue-qiao Xu, Masatoshi Yagi","Drift reduced Landau fluid model for magnetized plasma turbulence
  simulations in BOUT++ framework","26 pages, 14 figures",,"10.1016/j.cpc.2021.108079",,"physics.plasm-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently the drift-reduced Landau fluid six-field turbulence model within the
BOUT++ framework has been upgraded. In particular, this new model employs a new
normalization, adds a volumetric flux-driven source option, the Landau fluid
closure for parallel heat flux and a Laplacian inversion solver which is able
to capture n=0 axisymmetric mode evolution in realistic tokamak configurations.
These improvements substantially extended model's capability to study a wider
range of tokamak edge phenomena, and are essential to build a fully
self-consistent edge turbulence model capable of both transient (e.g., ELM,
disruption) and transport time-scale simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:49:12 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 17:43:49 GMT""}]","2021-07-28"
"2102.04977","Sutanay Choudhury","Logan Ward and Jenna A. Bilbrey and Sutanay Choudhury and Neeraj Kumar
  and Ganesh Sivaraman","Benchmarking Deep Graph Generative Models for Optimizing New Drug
  Molecules for COVID-19",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Design of new drug compounds with target properties is a key area of research
in generative modeling. We present a small drug molecule design pipeline based
on graph-generative models and a comparison study of two state-of-the-art graph
generative models for designing COVID-19 targeted drug candidates: 1) a
variational autoencoder-based approach (VAE) that uses prior knowledge of
molecules that have been shown to be effective for earlier coronavirus
treatments and 2) a deep Q-learning method (DQN) that generates optimized
molecules without any proximity constraints. We evaluate the novelty of the
automated molecule generation approaches by validating the candidate molecules
with drug-protein binding affinity models. The VAE method produced two novel
molecules with similar structures to the antiretroviral protease inhibitor
Indinavir that show potential binding affinity for the SARS-CoV-2 protein
target 3-chymotrypsin-like protease (3CL-protease).
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:49:26 GMT""}]","2021-02-10"
"2102.04978","Susanne Westhoff","Susanne Westhoff","Global Searches for New Physics with Top Quarks","Talk at the 13th International Workshop on Top Quark Physics, Durham,
  UK (videoconference), 14-18 September 2020",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a brief summary of the latest searches for virtual effects of new
physics in the top sector. In the framework of the Standard Model Effective
Field Theory (SMEFT), I show how to resolve the structure of effective
couplings by combining observables at the LHC and at flavor experiments in a
global fit. With this approach we start exploring the features of a UV theory
at energies beyond current colliders.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:49:43 GMT""}]","2021-02-10"
"2102.04979","Jakin Ng","Fiona Abney-McPeek, Serena An, and Jakin Ng","The Stembridge Equality for Skew Stable Grothendieck Polynomials and
  Skew Dual Stable Grothendieck Polynomials","23 pages, 0 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Schur polynomials $s_{\lambda}$ are essential in understanding the
representation theory of the general linear group. They also describe the
cohomology ring of the Grassmannians. For $\rho = (n, n-1, \dots, 1)$ a
staircase shape and $\mu \subseteq \rho$ a subpartition, the Stembridge
equality states that $s_{\rho/\mu} = s_{\rho/\mu^T}$. This equality provides
information about the symmetry of the cohomology ring. The stable Grothendieck
polynomials $G_{\lambda}$, and the dual stable Grothendieck polynomials
$g_{\lambda}$, developed by Buch, Lam, and Pylyavskyy, are variants of the
Schur polynomials and describe the $K$-theory of the Grassmannians. Using the
Hopf algebra structure of the ring of symmetric functions and a generalized
Littlewood-Richardson rule, we prove that $G_{\rho/\mu} = G_{\rho/\mu^T}$ and
$g_{\rho/\mu} = g_{\rho/\mu^T}$, the analogues of the Stembridge equality for
the skew stable and skew dual stable Grothendieck polynomials.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:50:50 GMT""},{""version"":""v2"",""created"":""Sat, 2 Oct 2021 20:51:34 GMT""}]","2021-10-05"
"2102.04980","Soravit Changpinyo","Soravit Changpinyo, Jordi Pont-Tuset, Vittorio Ferrari, Radu Soricut","Telling the What while Pointing to the Where: Multimodal Queries for
  Image Retrieval","IEEE/CVF International Conference on Computer Vision (ICCV 2021)",,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Most existing image retrieval systems use text queries as a way for the user
to express what they are looking for. However, fine-grained image retrieval
often requires the ability to also express where in the image the content they
are looking for is. The text modality can only cumbersomely express such
localization preferences, whereas pointing is a more natural fit. In this
paper, we propose an image retrieval setup with a new form of multimodal
queries, where the user simultaneously uses both spoken natural language (the
what) and mouse traces over an empty canvas (the where) to express the
characteristics of the desired target image. We then describe simple
modifications to an existing image retrieval model, enabling it to operate in
this setup. Qualitative and quantitative experiments show that our model
effectively takes this spatial guidance into account, and provides
significantly more accurate retrieval results compared to text-only equivalent
systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:54:34 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 07:55:58 GMT""},{""version"":""v3"",""created"":""Tue, 24 Aug 2021 22:04:53 GMT""}]","2021-08-26"
"2102.04981","Tom Allison","Myles C. Silfies, Grzegorz Kowzan, Neomi Lewis, Thomas K. Allison","Broadband cavity-enhanced ultrafast spectroscopy",,"Phys. Chem. Chem. Phys. 23, 9743 (2021)","10.1039/D1CP00631B",,"physics.optics physics.atom-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Broadband ultrafast optical spectroscopy methods, such as transient
absorption spectroscopy and 2D spectroscopy, are widely used to study molecular
dynamics. However, these techniques are typically restricted to optically thick
samples, such as solids and liquid solutions. In this article we discuss a
cavity-enhanced ultrafast transient absorption spectrometer covering almost the
entire visible range with a detection limit of $\Delta$OD $ < 1 \times
10^{-9}$, extending broadband all-optical ultrafast spectroscopy techniques to
dilute beams of gas-phase molecules and clusters. We describe the technical
innovations behind the spectrometer and present transient absorption data on
two archetypical molecular systems for excited-state intramolecular proton
transfer, 1'-hydroxy-2'-acetonapthone and salicylideneaniline, under jet-cooled
and Ar cluster conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:55:34 GMT""}]","2021-04-29"
"2102.04982","Tomasz Witczak","Tomasz Witczak","Negotiation sets: a general framework",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  It is well-known fact that there exists 1-1 correspondence between so-called
double (or flou) sets and intuitionistic sets (also known as orthopairs). At
first glance, these two concepts seem to be irreconcilable. However, one must
remember that algebraic operations in these two classes are also defined
differently. Hence, the expected compatibility is possible. Contrary to this
approach, we combine standard definition of double set with operations which
are typical for intuitionistic sets. We show certain advantages and limitations
of this viewpoint. Moreover, we suggest an interpretation of our sets and
operations in terms of logic, data clustering and multi-criteria decision
making. As a result, we obtain a structure of discussion between several
participants who propose their ""necessary"" and ""allowable"" requirements or
propositions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:56:42 GMT""}]","2021-02-10"
"2102.04984","Will Perkins","Ewan Davies and Will Perkins","Approximately counting independent sets of a given size in
  bounded-degree graphs",,,,,"cs.DS cs.CC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the computational complexity of approximately counting and
sampling independent sets of a given size in bounded-degree graphs. That is, we
identify a critical density $\alpha_c(\Delta)$ and provide (i) for $\alpha <
\alpha_c(\Delta)$ randomized polynomial-time algorithms for approximately
sampling and counting independent sets of given size at most $\alpha n$ in
$n$-vertex graphs of maximum degree $\Delta$; and (ii) a proof that unless
NP=RP, no such algorithms exist for $\alpha>\alpha_c(\Delta)$. The critical
density is the occupancy fraction of the hard core model on the complete graph
$K_{\Delta+1}$ at the uniqueness threshold on the infinite $\Delta$-regular
tree, giving $\alpha_c(\Delta)\sim\frac{e}{1+e}\frac{1}{\Delta}$ as
$\Delta\to\infty$. Our methods apply more generally to anti-ferromagnetic
2-spin systems and motivate new questions in extremal combinatorics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 17:57:26 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 18:15:25 GMT""},{""version"":""v3"",""created"":""Tue, 24 Jan 2023 20:50:52 GMT""}]","2023-01-26"
"2102.04989","Nuno M. Santos","Nuno M. Santos, Carlos A. R. Herdeiro","Black holes, stationary clouds and magnetic fields","9 pages, 4 figures. Accepted for publication in Physics Letters B","Phys. Lett. B 815 (2021) 136142","10.1016/j.physletb.2021.136142",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the electron in the hydrogen atom, a bosonic field can bind itself to a
black hole occupying a discrete infinite set of states. When (i) the spacetime
is prone to superradiance and (ii) a confinement mechanism is present, some of
such states are infinitely long-lived. These equilibrium configurations, known
as stationary clouds, are states ""synchronized"" with a rotating black hole's
event horizon. For most, if not all, stationary clouds studied in the
literature so far, the requirements (i)-(ii) are independent of each other.
However, this is not always the case. This paper shows that massless neutral
scalar fields can form stationary clouds around a Reissner-Nordstr\""{o}m black
hole when both are subject to a uniform magnetic field. The latter
simultaneously enacts both requirements by creating an ergoregion (thereby
opening up the possibility of superradiance) and trapping the scalar field in
the black hole's vicinity. This leads to some novel features, in particular,
that only black holes with a subset of the possible charge to mass ratios can
support stationary clouds.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:00:00 GMT""}]","2021-02-19"
"2102.04990","Subarna Tripathi","Kien Nguyen and Subarna Tripathi and Bang Du and Tanaya Guha and
  Truong Q. Nguyen","In Defense of Scene Graphs for Image Captioning","Accepted to ICCV 2021",,,,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mainstream image captioning models rely on Convolutional Neural Network
(CNN) image features to generate captions via recurrent models. Recently, image
scene graphs have been used to augment captioning models so as to leverage
their structural semantics, such as object entities, relationships and
attributes. Several studies have noted that the naive use of scene graphs from
a black-box scene graph generator harms image captioning performance and that
scene graph-based captioning models have to incur the overhead of explicit use
of image features to generate decent captions. Addressing these challenges, we
propose \textbf{SG2Caps}, a framework that utilizes only the scene graph labels
for competitive image captioning performance. The basic idea is to close the
semantic gap between the two scene graphs - one derived from the input image
and the other from its caption. In order to achieve this, we leverage the
spatial location of objects and the Human-Object-Interaction (HOI) labels as an
additional HOI graph. SG2Caps outperforms existing scene graph-only captioning
models by a large margin, indicating scene graphs as a promising representation
for image captioning. Direct utilization of scene graph labels avoids expensive
graph convolutions over high-dimensional CNN features resulting in 49% fewer
trainable parameters. Our code is available at:
https://github.com/Kien085/SG2Caps
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:00:53 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 08:07:37 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 16:56:00 GMT""}]","2021-08-18"
"2102.04991","Joao Florindo","Eduardo Abreu, Joao B. Florindo","A study on a feedforward neural network to solve partial differential
  equations in hyperbolic-transport problems",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this work we present an application of modern deep learning methodologies
to the numerical solution of partial differential equations in transport
models. More specifically, we employ a supervised deep neural network that
takes into account the equation and initial conditions of the model. We apply
it to the Riemann problems over the inviscid nonlinear Burger's equation, whose
solutions might develop discontinuity (shock wave) and rarefaction, as well as
to the classical one-dimensional Buckley-Leverett two-phase problem. The
Buckley-Leverett case is slightly more complex and interesting because it has a
non-convex flux function with one inflection point. Our results suggest that a
relatively simple deep learning model was capable of achieving promising
results in such challenging tasks, providing numerical approximation of entropy
solutions with very good precision and consistent to classical as well as to
recently novel numerical methods in these particular scenarios.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:01:03 GMT""}]","2021-02-10"
"2102.04992","Yuan-Sen Ting Dr.","Yuan-Sen Ting and David H. Weinberg","How Many Elements Matter?","36 pages, 17 figures, ApJ (Accepted for publication)",,"10.3847/1538-4357/ac5023",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some studies of stars' multi-element abundance distributions suggest at least
5-7 significant dimensions, but others show that many elemental abundances can
be predicted to high accuracy from [Fe/H] and [Mg/Fe] (or [Fe/H] and age)
alone. We show that both propositions can be, and are, simultaneously true. We
adopt a machine learning technique known as normalizing flow to reconstruct the
probability distribution of Milky Way disk stars in the space of 15 elemental
abundances measured by APOGEE. Conditioning on Teff and log g minimizes the
differential systematics. After further conditioning on [Fe/H] and [Mg/Fe], the
residual scatter for most abundances is $\sigma_{[X/{\rm H}]} \lesssim 0.02$
dex, consistent with APOGEE's reported statistical uncertainties of
$\sim$0.01-0.015 dex and intrinsic scatter of 0.01-0.02 dex. Despite the small
scatter, residual abundances display clear correlations between elements, which
we show are too large to be explained by measurement uncertainties or by the
finite sampling noise. We must condition on at least seven elements to reduce
correlations to a level consistent with observational uncertainties. Our
results demonstrate that cross-element correlations are a much more sensitive
probe of hidden structure than dispersion, and they can be measured precisely
in a large sample even if star-by-star measurement noise is comparable to the
intrinsic scatter. We conclude that many elements have an independent story to
tell, even for the ""mundane"" disk stars and elements produced by core-collapse
and Type Ia supernovae. The only way to learn these lessons is to measure the
abundances directly, and not merely infer them.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:01:12 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 05:25:29 GMT""}]","2022-03-30"
"2102.04993","Marc G\'orriz Blanch","Marc G\'orriz, Saverio Blasi, Alan F. Smeaton, Noel E. O'Connor, Marta
  Mrak","Attention-Based Neural Networks for Chroma Intra Prediction in Video
  Coding",,"IEEE Journal of Selected Topics in Signal Processing, 2020","10.1109/JSTSP.2020.3044482",,"eess.IV cs.CC cs.CV cs.LG cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural networks can be successfully used to improve several modules of
advanced video coding schemes. In particular, compression of colour components
was shown to greatly benefit from usage of machine learning models, thanks to
the design of appropriate attention-based architectures that allow the
prediction to exploit specific samples in the reference region. However, such
architectures tend to be complex and computationally intense, and may be
difficult to deploy in a practical video coding pipeline. This work focuses on
reducing the complexity of such methodologies, to design a set of simplified
and cost-effective attention-based architectures for chroma intra-prediction. A
novel size-agnostic multi-model approach is proposed to reduce the complexity
of the inference process. The resulting simplified architecture is still
capable of outperforming state-of-the-art methods. Moreover, a collection of
simplifications is presented in this paper, to further reduce the complexity
overhead of the proposed prediction architecture. Thanks to these
simplifications, a reduction in the number of parameters of around 90% is
achieved with respect to the original attention-based methodologies.
Simplifications include a framework for reducing the overhead of the
convolutional operations, a simplified cross-component processing model
integrated into the original architecture, and a methodology to perform
integer-precision approximations with the aim to obtain fast and hardware-aware
implementations. The proposed schemes are integrated into the Versatile Video
Coding (VVC) prediction pipeline, retaining compression efficiency of
state-of-the-art chroma intra-prediction methods based on neural networks,
while offering different directions for significantly reducing coding
complexity.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:01:22 GMT""}]","2021-02-10"
"2102.04994","Alexander Scott","Maria Chudnovsky, Alex Scott, Paul Seymour, Sophie Spirkl","Erdos-Hajnal for graphs with no 5-hole",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Erdos-Hajnal conjecture says that for every graph H there exists c>0 such
that every graph G not containing H as an induced subgraph has a clique or
stable set of cardinality at least |G|^c. We prove that this is true when H is
a cycle of length five.
  We also prove several further results: for instance, that if C is a cycle and
H is the complement of a forest, there exists c>0 such that every graph G
containing neither of C,H as an induced subgraph has a clique or stable set of
cardinality at least |G|^c.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:02:02 GMT""}]","2021-02-10"
"2102.04995","Alejandra Rinc\'on-Hidalgo","Dominic Bunnett and Alejandra Rinc\'on-Hidalgo","Moduli of Bridgeland semistable holomorphic triples","30 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the moduli stack of Bridgeland semistable holomorphic triples
over a curve of $g(C)\geq 1$ with a fixed numerical class and phase is an
algebraic stack of finite type over $\mathbb{C}$ and admits a proper good
moduli space. We prove that this also holds for a class of Bridgeland stability
conditions on the category of holomorphic chains $\mathcal{T}_{C,n}$.
  In the process, we construct an explicit geometric realisation of
$\mathcal{T}_{C,n}$ and prove the open heart property for noetherian hearts in
admissible categories of $D^b(X)$, where $X$ is a smooth projective variety
over $\mathbb{C}$, whose orthogonal complements are geometric triangulated
categories.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:04:15 GMT""}]","2021-02-10"
"2102.04996","Fabian Keller","Fabian Keller and Andreas Heuer","Chain ordering of phospholipids in membranes containing cholesterol:
  What matters?","14 pages (2-column, rsc style), 21 figures (including SI)",,,,"physics.bio-ph cond-mat.soft physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cholesterol (CHOL) drives lipid segregation and is thus a key player for the
formation of lipid rafts and followingly for the ability of a cell to, e.g.,
enable selective agglomeration of proteins. The lipid segregation is driven by
cholesterol's affinity for saturated lipids, which stands directly in relation
to the ability of cholesterol to order the individual phospholipid (PL) acyl
chains. In this work, Molecular Dynamics simulations of DPPC
(Dipalmitoylphosphatidylcholine, saturated lipid) and DLiPC
(Dilineoylphosphatidylcholine, unsaturated lipid) mixtures with cholesterol are
used to elucidate the underlying mechanisms of the cholesterol ordering effect.
To this end, all enthalpic contributions, experienced by the PL molecules, are
recorded as a function of the PL's acyl chain order. This involves, the PL-PL,
the PL-cholesterol interaction, the interaction of the PLs with water, and the
interleaflet interaction. This systematic analysis allows one to unravel
differences of saturated and unsaturated lipids in terms of the different
interaction factors. It turns out that cholesterol's impact on chain ordering
stems not only from direct interactions with the PLs but is also indirectly
present in the other energy contributions. Furthermore, the analysis sheds
light on the relevance of the entropic contributions, related to the degrees of
freedom of the acyl chain.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:04:27 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 13:31:38 GMT""},{""version"":""v3"",""created"":""Thu, 25 Mar 2021 17:13:11 GMT""}]","2021-03-26"
"2102.04997","Madhurananda Pahar","Madhurananda Pahar, Igor Miranda, Andreas Diacon and Thomas Niesler","Deep Neural Network based Cough Detection using Bed-mounted
  Accelerometer Measurements","It has been accepted in ICASSP, 2021. Copyright information is shown
  at the very first page","ICASSP 2021 - 2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), 2021","10.1109/ICASSP39728.2021.9414744",,"cs.LG cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  We have performed cough detection based on measurements from an accelerometer
attached to the patient's bed. This form of monitoring is less intrusive than
body-attached accelerometer sensors, and sidesteps privacy concerns encountered
when using audio for cough detection. For our experiments, we have compiled a
manually-annotated dataset containing the acceleration signals of approximately
6000 cough and 68000 non-cough events from 14 adult male patients in a
tuberculosis clinic. As classifiers, we have considered convolutional neural
networks (CNN), long-short-term-memory (LSTM) networks, and a residual neural
network (Resnet50). We find that all classifiers are able to distinguish
between the acceleration signals due to coughing and those due to other
activities including sneezing, throat-clearing and movement in the bed with
high accuracy. The Resnet50 performs the best, achieving an area under the ROC
curve (AUC) exceeding 0.98 in cross-validation experiments. We conclude that
high-accuracy cough monitoring based only on measurements from the
accelerometer in a consumer smartphone is possible. Since the need to gather
audio is avoided and therefore privacy is inherently protected, and since the
accelerometer is attached to the bed and not worn, this form of monitoring may
represent a more convenient and readily accepted method of long-term patient
cough monitoring.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:04:35 GMT""}]","2022-05-12"
"2102.04998","Niladri Chatterji","Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett","When does gradient descent with logistic loss interpolate using deep
  networks with smoothed ReLU activations?",,,,,"stat.ML cs.AI cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish conditions under which gradient descent applied to fixed-width
deep networks drives the logistic loss to zero, and prove bounds on the rate of
convergence. Our analysis applies for smoothed approximations to the ReLU, such
as Swish and the Huberized ReLU, proposed in previous applied work. We provide
two sufficient conditions for convergence. The first is simply a bound on the
loss at initialization. The second is a data separation condition used in prior
analyses.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:04:37 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 04:14:30 GMT""}]","2021-07-02"
"2102.04999","Zeyu Zheng","Zeyu Zheng, Risto Vuorio, Richard Lewis, Satinder Singh","Adaptive Pairwise Weights for Temporal Credit Assignment","AAAI 2022. The first two authors contributed equally",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  How much credit (or blame) should an action taken in a state get for a future
reward? This is the fundamental temporal credit assignment problem in
Reinforcement Learning (RL). One of the earliest and still most widely used
heuristics is to assign this credit based on a scalar coefficient, $\lambda$
(treated as a hyperparameter), raised to the power of the time interval between
the state-action and the reward. In this empirical paper, we explore heuristics
based on more general pairwise weightings that are functions of the state in
which the action was taken, the state at the time of the reward, as well as the
time interval between the two. Of course it isn't clear what these pairwise
weight functions should be, and because they are too complex to be treated as
hyperparameters we develop a metagradient procedure for learning these weight
functions during the usual RL training of a policy. Our empirical work shows
that it is often possible to learn these pairwise weight functions during
learning of the policy to achieve better performance than competing approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:06:29 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 15:02:56 GMT""}]","2022-06-07"
"2102.05000","Ivan K. Kostov","Ivan Kostov and Valentina B. Petkova","Octagon with finite bridge: free fermions and determinant identities","29 pages, no figures. Minor corrections in v2",,"10.1007/JHEP06(2021)098",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We continue the study of the octagon form factor which helps to evaluate a
class of four-point correlation functions in $\mathcal{N}=4$ SYM theory. The
octagon is characterised, besides the kinematical parameters, by a ""bridge"" of
$\ell$ propagators connecting two non-adjacent operators. In this paper we
construct an operator representation of the octagon with finite bridge as an
expectation value in the Fock space of free complex fermions. The bridge $\ell$
appears as the level of filling of the Dirac sea. We obtain determinant
identities relating octagons with different bridges, which we derive from the
expression of the octagon in terms of discrete fermionic oscillators. The
derivation is based on the existence of a previously conjectured similarity
transformation, which we find here explicitly.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:07:19 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 15:14:50 GMT""}]","2021-06-30"
"2102.05001","Joao Florindo","Joao B. Florindo, Eduardo Abreu","An application of a pseudo-parabolic modeling to texture image
  recognition",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this work, we present a novel methodology for texture image recognition
using a partial differential equation modeling. More specifically, we employ
the pseudo-parabolic Buckley-Leverett equation to provide a dynamics to the
digital image representation and collect local descriptors from those images
evolving in time. For the local descriptors we employ the magnitude and signal
binary patterns and a simple histogram of these features was capable of
achieving promising results in a classification task. We compare the accuracy
over well established benchmark texture databases and the results demonstrate
competitiveness, even with the most modern deep learning approaches. The
achieved results open space for future investigation on this type of modeling
for image analysis, especially when there is no large amount of data for
training deep learning models and therefore model-based approaches arise as
suitable alternatives.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:08:42 GMT""}]","2021-02-10"
"2102.05002","Jerzy Dydak","Yuankui Ma and Jerzy Dydak","Coarse Freundenthal compactification and ends of groups","16 pages",,,,"math.MG math.GN math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A coarse compactification of a proper metric space $X$ is any
compactification of $X$ that is dominated by its Higson compactification. In
this paper we describe the maximal coarse compactification of $X$ whose corona
is of dimension $0$. In case of geodesic spaces $X$, it coincides with the
Freundenthal compactification of $X$. As an application we provide an
alternative way of extending the concept of the number of ends from finitely
generated groups to arbitrary countable groups. We present a geometric proof of
a generalization of Stallings' theorem by showing that any countable group of
two ends contains an infinite cyclic subgroup of finite index. Finally, we
define ends of arbitrary coarse spaces.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:08:55 GMT""}]","2021-02-10"
"2102.05003","Nawaf Mohammed","Nawaf Mohammed, Edward Furman and Jianxi Su","Can a regulatory risk measure induce profit-maximizing risk capital
  allocations? The case of Conditional Tail Expectation",,,,,"q-fin.RM","http://creativecommons.org/licenses/by/4.0/","  Risk capital allocations (RCAs) are an important tool in quantitative risk
management, where they are utilized to, e.g., gauge the profitability of
distinct business units, determine the price of a new product, and conduct the
marginal economic capital analysis. Nevertheless, the notion of RCA has been
living in the shadow of another, closely related notion, of risk measure (RM)
in the sense that the latter notion often shapes the fashion in which the
former notion is implemented. In fact, as the majority of the RCAs known
nowadays are induced by RMs, the popularity of the two are apparently very much
correlated. As a result, it is the RCA that is induced by the Conditional Tail
Expectation (CTE) RM that has arguably prevailed in scholarly literature and
applications. Admittedly, the CTE RM is a sound mathematical object and an
important regulatory RM, but its appropriateness is controversial in, e.g.,
profitability analysis and pricing. In this paper, we address the question as
to whether or not the RCA induced by the CTE RM may concur with alternatives
that arise from the context of profit maximization. More specifically, we
provide exhaustive description of all those probabilistic model settings, in
which the mathematical and regulatory CTE RM may also reflect the risk
perception of a profit-maximizing insurer.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:09:44 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 14:27:41 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 12:52:33 GMT""}]","2021-08-27"
"2102.05004","Munish Sharma","Kuldeep Kumar and Munish Sharma","DNA Nucleobase Interaction Driven Electronic and Optical Fingerprints in
  Gallium Selenide Monolayer for DNA Sequencing Devices",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interaction of DNA nucleobases with monolayer GaSe has been studied with
in DFT framework using vdW functional. We found that nucleobases are
physisorbed on the GaSe monolayer. The order of binding energy per atom is C >
T > G > A. The room temperature recovery time estimated to be maximum of 113.88
micro sec. for T+GaSe indicting reusability of the GaSe based devices. The
modulation in the electronic structures of GaSe has been clearly captured
within the simulated STM measurements. We also demonstrate quantum capacitance
as a key parameter for sensing applications. Furthermore, in optical
properties, electron energy loss (EEL) spectra show red shift in photon energy
on nucleobase adsorption in UV region. In nutshell, GaSe monolayer exhibit
anisotropic optical response in UV-region which can be highly beneficial for
developing polarized optical sensors. Our results demonstrate that GaSe
monolayer can be utilized to fabricate reusable DNA sequencing devices for
biotechnology and medical science.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:13:44 GMT""}]","2021-02-10"
"2102.05005","Qun Wang","Qun Wang, Han Hu, Haijian Sun, Rose Qingyang Hu","Secure and Energy-Efficient Offloading and Resource Allocation in a
  NOMA-Based MEC Network",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Energy efficiency and security are two critical issues for mobile edge
computing (MEC) networks. With stochastic task arrivals, time-varying dynamic
environment, and passive existing attackers, it is very challenging to offload
computation tasks securely and efficiently. In this paper, we study the task
offloading and resource allocation problem in a non-orthogonal multiple access
(NOMA) assisted MEC network with security and energy efficiency considerations.
To tackle the problem, a dynamic secure task offloading and resource allocation
algorithm is proposed based on Lyapunov optimization theory. A stochastic
non-convex problem is formulated to jointly optimize the local-CPU frequency
and transmit power, aiming at maximizing the network energy efficiency, which
is defined as the ratio of the long-term average secure rate to the long-term
average power consumption of all users. The formulated problem is decomposed
into the deterministic sub-problems in each time slot. The optimal local
CPU-cycle and the transmit power of each user can be given in the closed-from.
Simulation results evaluate the impacts of different parameters on the
efficiency metrics and demonstrate that the proposed method can achieve better
performance compared with other benchmark methods in terms of energy
efficiency.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:15:31 GMT""}]","2021-02-10"
"2102.05006","Joseph Baron","Joseph W. Baron","Persistent individual bias in a voter model with quenched disorder","15 pages, 7 figures","Phys. Rev. E 103, 052309 (2021)","10.1103/PhysRevE.103.052309",,"physics.soc-ph cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  Many theoretical studies of the voter model (or variations thereupon) involve
order parameters that are population-averaged. While enlightening, such
quantities may obscure important statistical features that are only apparent on
the level of the individual. In this work, we ask which factors contribute to a
single voter maintaining a long-term statistical bias for one opinion over the
other in the face of social influence. To this end, a modified version of the
network voter model is proposed, which also incorporates quenched disorder in
the interaction strengths between individuals and the possibility of
antagonistic relationships. We find that a sparse interaction network and
heterogeneity in interaction strengths give rise to the possibility of
arbitrarily long-lived individual biases, even when there is no
population-averaged bias for one opinion over the other. This is demonstrated
by calculating the eigenvalue spectrum of the weighted network Laplacian using
the theory of sparse random matrices.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:16:52 GMT""}]","2021-06-02"
"2102.05007","Matan Eyal","Matan Eyal, Asaf Amrami, Hillel Taub-Tabib, Yoav Goldberg","Bootstrapping Relation Extractors using Syntactic Search by Examples","EACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The advent of neural-networks in NLP brought with it substantial improvements
in supervised relation extraction. However, obtaining a sufficient quantity of
training data remains a key challenge. In this work we propose a process for
bootstrapping training datasets which can be performed quickly by
non-NLP-experts. We take advantage of search engines over syntactic-graphs
(Such as Shlain et al. (2020)) which expose a friendly by-example syntax. We
use these to obtain positive examples by searching for sentences that are
syntactically similar to user input examples. We apply this technique to
relations from TACRED and DocRED and show that the resulting models are
competitive with models trained on manually annotated data and on data obtained
from distant supervision. The models also outperform models trained using NLG
data augmentation techniques. Extending the search-based approach with the NLG
method further improves the results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:17:59 GMT""}]","2021-02-10"
"2102.05008","Lewis Hammond","Lewis Hammond, James Fox, Tom Everitt, Alessandro Abate, Michael
  Wooldridge","Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and
  Practice","Accepted to the 20th International Conference on Autonomous Agents
  and Multiagent Systems (AAMAS-21)",,,,"cs.MA cs.AI cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-agent influence diagrams (MAIDs) are a popular form of graphical model
that, for certain classes of games, have been shown to offer key complexity and
explainability advantages over traditional extensive form game (EFG)
representations. In this paper, we extend previous work on MAIDs by introducing
the concept of a MAID subgame, as well as subgame perfect and trembling hand
perfect equilibrium refinements. We then prove several equivalence results
between MAIDs and EFGs. Finally, we describe an open source implementation for
reasoning about MAIDs and computing their equilibria.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:20:50 GMT""}]","2021-02-10"
"2102.05009","Manasvi Lingam","Manasvi Lingam","Theoretical constraints imposed by gradient detection and dispersal on
  microbial size in astrobiological environments","Published in Astrobiology; 39 pages; 2 figures","Astrobiology, Vol. 21, No. 7, 813-830 (2021)","10.1089/ast.2020.2392",,"astro-ph.EP physics.bio-ph q-bio.CB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The capacity to sense gradients efficiently and acquire information about the
ambient environment confers many advantages like facilitating movement toward
nutrient sources or away from toxic chemicals. The amplified dispersal evinced
by organisms endowed with motility is possibly beneficial in related contexts.
Hence, the connections between information acquisition, motility, and microbial
size are explored from an explicitly astrobiological standpoint. By using prior
theoretical models, the constraints on organism size imposed by gradient
detection and motility are elucidated in the form of simple heuristic scaling
relations. It is argued that environments such as alkaline hydrothermal vents,
which are distinguished by the presence of steep gradients, might be conducive
to the existence of ""small"" microbes (with radii of $\gtrsim 0.1$ $\mu$m) in
principle, when only the above two factors are considered; other biological
functions (e.g., metabolism and genetic exchange) could, however, regulate the
lower bound on microbial size and elevate it. The derived expressions are
potentially applicable to a diverse array of settings, including those
entailing solvents other than water; for example, the lakes and seas of Titan.
The paper concludes with a brief exposition of how this formalism may be of
practical and theoretical value to astrobiology.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:23:36 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 00:35:01 GMT""}]","2021-07-16"
"2102.05010","Roman Lubkov","Roman Lubkov","The reverse decomposition of unipotents for bivectors","9 pages, 3 figures",,,,"math.GR math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the second fundamental representation of the general linear group over a
commutative ring $R$ we construct straightforward and uniform polynomial
expressions of elementary generators as products of elementary conjugates of an
arbitrary matrix and its inverse. Towards the solution we get stabilization
theorems for any column of a matrix from $GL_{n \choose 2}(R)$ or from the
exterior square of $GL_n(R)$, $n\geq 3$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:23:42 GMT""}]","2021-02-10"
"2102.05011","Kiri Wagstaff","Kiri Wagstaff (1), Steven Lu (1), Emily Dunkel (1), Kevin Grimes (1),
  Brandon Zhao (2), Jesse Cai (3), Shoshanna B. Cole (4), Gary Doran (1),
  Raymond Francis (1), Jake Lee (1), and Lukas Mandrake (1) ((1) Jet Propulsion
  Laboratory, California Institute of Technology, (2) Duke University, (3)
  California Institute of Technology, (4) Space Science Institute)","Mars Image Content Classification: Three Years of NASA Deployment and
  Recent Advances","Published at the Thirty-Third Annual Conference on Innovative
  Applications of Artificial Intelligence (IAAI-21). IAAI Innovative
  Application Award. 10 pages, 11 figures, 6 tables",,,,"cs.LG cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The NASA Planetary Data System hosts millions of images acquired from the
planet Mars. To help users quickly find images of interest, we have developed
and deployed content-based classification and search capabilities for Mars
orbital and surface images. The deployed systems are publicly accessible using
the PDS Image Atlas. We describe the process of training, evaluating,
calibrating, and deploying updates to two CNN classifiers for images collected
by Mars missions. We also report on three years of deployment including usage
statistics, lessons learned, and plans for the future.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:26:25 GMT""}]","2021-02-10"
"2102.05012","Shu-Yu Ho","Chia-Hung Vincent Chang, Chuan-Ren Chen, Shu-Yu Ho, Shih-Yen Tseng","Explaining the MiniBooNE Anomalous Excess via Leptophilic ALP-Sterile
  Neutrino Coupling","19+1 pages, 8+1 figures, and 1 table; v2: Typos fixed, figure added,
  note added, references added, matched to the published version","Phys. Rev. D 104, 015030 (2021)","10.1103/PhysRevD.104.015030","KIAS-P21006","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the MiniBooNE experiment at Fermilab has updated the results with
increased data and reported an excess of $560.6 \pm 119.6$ electronlike events
($4.7\sigma$) in the neutrino operation mode. In this paper, we propose a
scenario to account for the excess where a Dirac-type sterile neutrino,
produced by a charged kaon decay through the neutrino mixing, decays into a
leptophilic axionlike particle ($\ell$ALP) and a muon neutrino. The
electron-positron pairs produced from the $\ell$ALP decays can be interpreted
as electronlike events provided that their opening angle is sufficiently small.
In our framework, we consider the $\ell$ALP with a mass $m^{}_a =
20\,\text{MeV}$ and an inverse decay constant $c^{}_e/f^{}_a =
10^{-2}\,\text{GeV}^{-1}$, allowed by the astrophysical and experimental
constraints. Then, after integrating the predicted angular or visible energy
spectra of the $\ell$ALP to obtain the total excess event number, we find that
our scenario with sterile neutrino masses within $150\,\text{MeV}\lesssim
m^{}_N \lesssim 380 \,\text{MeV}$ ($150\,\text{MeV}\lesssim m^{}_N \lesssim 180
\,\text{MeV}$) and neutrino mixing parameters between $10^{-10} \lesssim
|U_{\mu 4}|^2 \lesssim 10^{-8}$ ($3\times 10^{-7} \lesssim |U_{\mu 4}|^2
\lesssim 8 \times10^{-7}$) can explain the MiniBooNE data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:30:30 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 12:14:20 GMT""}]","2021-08-04"
"2102.05013","Yi Liu","Yi Liu, Limei Wang, Meng Liu, Xuan Zhang, Bora Oztekin, Shuiwang Ji","Spherical Message Passing for 3D Graph Networks","The paper has been accepted by ICLR 2022. You can also cite the
  conference version",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider representation learning of 3D molecular graphs in which each atom
is associated with a spatial position in 3D. This is an under-explored area of
research, and a principled message passing framework is currently lacking. In
this work, we conduct analyses in the spherical coordinate system (SCS) for the
complete identification of 3D graph structures. Based on such observations, we
propose the spherical message passing (SMP) as a novel and powerful scheme for
3D molecular learning. SMP dramatically reduces training complexity, enabling
it to perform efficiently on large-scale molecules. In addition, SMP is capable
of distinguishing almost all molecular structures, and the uncovered cases may
not exist in practice. Based on meaningful physically-based representations of
3D information, we further propose the SphereNet for 3D molecular learning.
Experimental results demonstrate that the use of meaningful 3D information in
SphereNet leads to significant performance improvements in prediction tasks.
Our results also demonstrate the advantages of SphereNet in terms of
capability, efficiency, and scalability. Our code is publicly available as part
of the DIG library (https://github.com/divelab/DIG).
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:31:23 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 03:39:42 GMT""},{""version"":""v3"",""created"":""Wed, 25 May 2022 18:03:47 GMT""},{""version"":""v4"",""created"":""Sat, 8 Oct 2022 17:55:03 GMT""},{""version"":""v5"",""created"":""Thu, 24 Nov 2022 22:41:20 GMT""}]","2022-11-28"
"2102.05014","James Usevitch","James Usevitch, Dimitra Panagou","Adversarial Resilience for Sampled-Data Systems under
  High-Relative-Degree Safety Constraints",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Control barrier functions (CBFs) have recently become a powerful method for
rendering desired safe sets forward invariant in single- and multi-agent
systems. In the multi-agent case, prior literature has considered scenarios
where all agents cooperate to ensure that the corresponding set remains
invariant. However, these works do not consider scenarios where a subset of the
agents are behaving adversarially with the intent to violate safety bounds. In
addition, prior results on multi-agent CBFs typically assume that control
inputs are continuous and do not consider sampled-data dynamics. This paper
presents a framework for normally-behaving agents in a multi-agent system with
heterogeneous control-affine, sampled-data dynamics to render a safe set
forward invariant in the presence of adversarial agents. The proposed approach
considers several aspects of practical control systems including input
constraints, clock asynchrony and disturbances, and distributed calculation of
control inputs. Our approach also considers functions describing safe sets
having high relative degree with respect to system dynamics. The efficacy of
these results are demonstrated through simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:32:01 GMT""}]","2021-02-10"
"2102.05015","Sepehr Rezvani","Sepehr Rezvani, Eduard A. Jorswieck, Nader Mokari, and Mohammad R.
  Javan","Optimal SIC Ordering and Power Allocation in Downlink Multi-Cell NOMA
  Systems","55 pages, 33 figures","IEEE Transactions on Wireless Communications, 21 October 2021","10.1109/TWC.2021.3120325",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a globally optimal joint successive interference
cancellation (SIC) ordering and power allocation (JSPA) algorithm for the
sum-rate maximization problem in downlink multi-cell non-orthogonal multiple
access (NOMA) systems. The proposed algorithm is based on the exploration of
base stations (BSs) power consumption, and closed-form of optimal powers
obtained for each cell. Although the optimal JSPA algorithm scales well with
larger number of users, it is still exponential in the number of cells. For any
suboptimal decoding order, we propose a low-complexity near-optimal joint rate
and power allocation (JRPA) strategy in which the complete rate region of users
is exploited. Furthermore, we design a near-optimal semi-centralized JSPA
framework for a two-tier heterogeneous network such that it scales well with
larger number of small-BSs and users. Numerical results show that JRPA highly
outperforms the case that the users are enforced to achieve their channel
capacity by imposing the well-known SIC necessary condition on power
allocation. Moreover, the proposed semi-centralized JSPA framework
significantly outperforms the fully distributed framework, where all the BSs
operate in their maximum power budget. Therefore, the centralized JRPA and
semi-centralized JSPA algorithms with near-optimal performances are good
choices for larger number of cells and users.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:32:19 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 15:08:32 GMT""},{""version"":""v3"",""created"":""Wed, 29 Sep 2021 14:58:28 GMT""}]","2021-10-26"
"2102.05016","Marco Manetti","Emma Lepri, Marco Manetti","Connections and $L_{\infty}$ liftings of semiregularity maps","V3: minor changes, references updated",,,"Roma01.math.AG.2102.05016","math.AG math.DG math.QA","http://creativecommons.org/licenses/by-sa/4.0/","  Let $E^*$ be a finite complex of locally free sheaves on a complex manifold
$X$. We prove that to every connection of type $(1,0)$ on $E^*$ it is
canonically associated an $L_{\infty}$ morphism $g\colon A^{0,
*}_X(\mathcal{H}om^*_{O_X}(E^*,E^*))\to \dfrac{A^{*,*}_X}{A^{\ge 2,*}_X}[2]$
that lifts the 1-component of Buchweitz-Flenner semiregularity map. An
application to deformations of coherent sheaves on projective manifolds is
given.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:32:42 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 08:25:53 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 06:14:29 GMT""}]","2021-05-25"
"2102.05017","Arthur Hutsalyuk","Arthur Hutsalyuk and Andrii Liashyk","Master equation for correlation functions in algebra symmetry
  $\mathfrak{gl}(2|1)$ related models","18 pages",,,,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider integrable models solved by the nested algebraic Bethe ansatz and
associated with $\mathfrak{gl}(2|1)$ or $\mathfrak{gl}(3)$ algebra symmetry.
The analogue of sum formulae, previously formulated for scalar products, is
established for the form factors and correlation functions. These formulae are
direct generalisation of the some earlier results derived for models with
$\mathfrak{gl}(2)$ symmetric $R$-matrix. It is also shown that in the case of
algebra symmetry $\mathfrak{gl}(2|1)$ related models such formula allows to
establish a multiple integral representation for correlation functions and form
factors.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:35:11 GMT""}]","2021-02-10"
"2102.05018","Jianyi Yang","Jianyi Yang, Shaolei Ren","Robust Bandit Learning with Imperfect Context",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A standard assumption in contextual multi-arm bandit is that the true context
is perfectly known before arm selection. Nonetheless, in many practical
applications (e.g., cloud resource management), prior to arm selection, the
context information can only be acquired by prediction subject to errors or
adversarial modification. In this paper, we study a contextual bandit setting
in which only imperfect context is available for arm selection while the true
context is revealed at the end of each round. We propose two robust arm
selection algorithms: MaxMinUCB (Maximize Minimum UCB) which maximizes the
worst-case reward, and MinWD (Minimize Worst-case Degradation) which minimizes
the worst-case regret. Importantly, we analyze the robustness of MaxMinUCB and
MinWD by deriving both regret and reward bounds compared to an oracle that
knows the true context. Our results show that as time goes on, MaxMinUCB and
MinWD both perform as asymptotically well as their optimal counterparts that
know the reward function. Finally, we apply MaxMinUCB and MinWD to online edge
datacenter selection, and run synthetic simulations to validate our theoretical
analysis.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:35:33 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 03:27:22 GMT""},{""version"":""v3"",""created"":""Sun, 4 Apr 2021 19:35:34 GMT""}]","2021-04-06"
"2102.05019","Noah Fleming","Noah Fleming, Mika G\""o\""os, Russell Impagliazzo, Toniann Pitassi,
  Robert Robere, Li-Yang Tan, Avi Wigderson","On the Power and Limitations of Branch and Cut",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  The Stabbing Planes proof system was introduced to model the reasoning
carried out in practical mixed integer programming solvers. As a proof system,
it is powerful enough to simulate Cutting Planes and to refute the Tseitin
formulas -- certain unsatisfiable systems of linear equations mod 2 -- which
are canonical hard examples for many algebraic proof systems. In a recent (and
surprising) result, Dadush and Tiwari showed that these short refutations of
the Tseitin formulas could be translated into quasi-polynomial size and depth
Cutting Planes proofs, refuting a long-standing conjecture. This translation
raises several interesting questions. First, whether all Stabbing Planes proofs
can be efficiently simulated by Cutting Planes. This would allow for the
substantial analysis done on the Cutting Planes system to be lifted to
practical mixed integer programming solvers. Second, whether the
quasi-polynomial depth of these proofs is inherent to Cutting Planes.
  In this paper we make progress towards answering both of these questions.
First, we show that any Stabbing Planes proof with bounded coefficients SP* can
be translated into Cutting Planes. As a consequence of the known lower bounds
for Cutting Planes, this establishes the first exponential lower bounds on SP*.
Using this translation, we extend the result of Dadush and Tiwari to show that
Cutting Planes has short refutations of any unsatisfiable system of linear
equations over a finite field. Like the Cutting Planes proofs of Dadush and
Tiwari, our refutations also incur a quasi-polynomial blow-up in depth, and we
conjecture that this is inherent. As a step towards this conjecture, we develop
a new geometric technique for proving lower bounds on the depth of Cutting
Planes proofs. This allows us to establish the first lower bounds on the depth
of Semantic Cutting Planes proofs of the Tseitin formulas.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:36:54 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 14:13:14 GMT""}]","2021-05-24"
"2102.05020","Xianghao Zhan","Xianghao Zhan, Yiheng Li, Yuzhe Liu, August G. Domel, Hossein Vahid
  Alizadeh, Zhou Zhou, Nicholas J. Cecchi, Samuel J. Raymond, Stephen Tiernan,
  Jesse Ruan, Saeed Barbat, Olivier Gevaert, Michael M. Zeineh, Gerald A.
  Grant, David B. Camarillo","Predictive Factors of Kinematics in Traumatic Brain Injury from Head
  Impacts Based on Statistical Interpretation",,,"10.1007/s10439-021-02813-z",,"physics.bio-ph cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  Brain tissue deformation resulting from head impacts is primarily caused by
rotation and can lead to traumatic brain injury. To quantify brain injury risk
based on measurements of kinematics on the head, finite element (FE) models and
various brain injury criteria based on different factors of these kinematics
have been developed, but the contribution of different kinematic factors has
not been comprehensively analyzed across different types of head impacts in a
data-driven manner. To better design brain injury criteria, the predictive
power of rotational kinematics factors, which are different in 1) the
derivative order (angular velocity, angular acceleration, angular jerk), 2) the
direction and 3) the power (e.g., square-rooted, squared, cubic) of the angular
velocity, were analyzed based on different datasets including laboratory
impacts, American football, mixed martial arts (MMA), NHTSA automobile
crashworthiness tests and NASCAR crash events. Ordinary least squares
regressions were built from kinematics factors to the 95\% maximum principal
strain (MPS95), and we compared zero-order correlation coefficients, structure
coefficients, commonality analysis, and dominance analysis. The angular
acceleration, the magnitude, and the first power factors showed the highest
predictive power for the majority of impacts including laboratory impacts,
American football impacts, with few exceptions (angular velocity for MMA and
NASCAR impacts). The predictive power of rotational kinematics in three
directions (x: posterior-to-anterior, y: left-to-right, z:
superior-to-inferior) of kinematics varied with different sports and types of
head impacts.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:37:20 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 19:53:49 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 16:15:37 GMT""}]","2022-12-07"
"2102.05021","Haimonti Dutta","Haimonti Dutta, Nitin Nataraj, Saurabh Amarnath Mahindre","Consensus Based Multi-Layer Perceptrons for Edge Computing",,,,,"cs.LG cs.DC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, storing large volumes of data on distributed devices has
become commonplace. Applications involving sensors, for example, capture data
in different modalities including image, video, audio, GPS and others. Novel
algorithms are required to learn from this rich distributed data. In this
paper, we present consensus based multi-layer perceptrons for
resource-constrained devices. Assuming nodes (devices) in the distributed
system are arranged in a graph and contain vertically partitioned data, the
goal is to learn a global function that minimizes the loss. Each node learns a
feed-forward multi-layer perceptron and obtains a loss on data stored locally.
It then gossips with a neighbor, chosen uniformly at random, and exchanges
information about the loss. The updated loss is used to run a back propagation
algorithm and adjust weights appropriately. This method enables nodes to learn
the global function without exchange of data in the network. Empirical results
reveal that the consensus algorithm converges to the centralized model and has
performance comparable to centralized multi-layer perceptrons and tree-based
algorithms including random forests and gradient boosted decision trees.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:39:46 GMT""}]","2021-02-10"
"2102.05022","Thomas Orvis","Thomas Orvis, Tengfei Cao, Mythili Surendran, Harish
  Kumarasubramanian, Austin Cunniff, Rohan Mishra, and Jayakanth Ravichandran","Direct Observation and Control of Surface Termination in Perovskite
  Oxide Heterostructures","23 pages, 3 figures, submitted to ACS Nano Letters",,"10.1021/acs.nanolett.0c04818",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The interfacial behavior of quantum materials leads to emergent phenomena
such as two dimensional electron gases, quantum phase transitions, and
metastable functional phases. Probes for in situ and real time surface
sensitive characterization are critical for active monitoring and control of
epitaxial synthesis, and hence the atomic-scale engineering of heterostructures
and superlattices. Termination switching, especially as an interfacial process
in ternary complex oxides, has been studied using a variety of probes, often ex
situ; however, direct observation of this phenomena is lacking. To address this
need, we establish in situ and real time reflection high energy electron
diffraction and Auger electron spectroscopy for pulsed laser deposition, which
provide structural and compositional information of the surface during film
deposition. Using this unique capability, we show, for the first time, the
direct observation and control of surface termination in complex oxide
heterostructures of SrTiO3 and SrRuO3. Density-functional-theory calculations
capture the energetics and stability of the observed structures and elucidate
their electronic behavior. This demonstration opens up a novel approach to
monitor and control the composition of materials at the atomic scale to enable
next-generation heterostructures for control over emergent phenomena, as well
as electronics, photonics, and energy applications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:41:33 GMT""}]","2021-06-09"
"2102.05023","Aniket Bhattacharya","Swarnadeep Seth and Aniket Bhattacharya","DNA Barcodes using a Double Nanopore System",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The potential of a double nanopore system to determine DNA barcodes has been
demonstrated experimentally. By carrying out Brownian dynamics simulation on a
coarse-grained model DNA with protein tag (barcodes) at known locations along
the chain backbone, we demonstrate that due to large variation of velocities of
the chain segments between the tags, it is inevitable to under/overestimate the
genetic lengths from the experimental current blockade and time of flight data.
We demonstrate that it is the tension propagation along the chain's backbone
that governs the motion of the entire chain and is the key element to explain
the non uniformity and disparate velocities of the tags and DNA monomers under
translocation that introduce errors in measurement of the length segments
between protein tags. Using simulation data we further demonstrate that it is
important to consider the dynamics of the entire chain and suggest methods to
accurately decipher barcodes. We introduce and validate an interpolation scheme
using simulation data for a broad distribution of tag separations and suggest
how to implement the scheme experimentally.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:42:21 GMT""}]","2021-02-10"
"2102.05024","Shengtai Ju","Shengtai Ju, Sneha Mahapatra, Marisa A. Erasmus, Amy R. Reibman,
  Fengqing Zhu","Turkey Behavior Identification System with a GUI Using Deep Learning and
  Video Analytics",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a video analytics system to identify the behavior
of turkeys. Turkey behavior provides evidence to assess turkey welfare, which
can be negatively impacted by uncomfortable ambient temperature and various
diseases. In particular, healthy and sick turkeys behave differently in terms
of the duration and frequency of activities such as eating, drinking, preening,
and aggressive interactions. Our system incorporates recent advances in object
detection and tracking to automate the process of identifying and analyzing
turkey behavior captured by commercial grade cameras. We combine deep-learning
and traditional image processing methods to address challenges in this
practical agricultural problem. Our system also includes a web-based user
interface to create visualization of automated analysis results. Together, we
provide an improved tool for turkey researchers to assess turkey welfare
without the time-consuming and labor-intensive manual inspection.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:43:38 GMT""}]","2021-02-10"
"2102.05025","Raashiq Ishraaq","Raashiq Ishraaq, Mahmudur Rashid, Shahriar Muhammad Nahid","Reinforcing Iron Metal Matrix Composite by Multi-Wall Carbon Nanotube: A
  Combined Theoretical and Computational Approach","This paper is under review in RSC Advances",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Carbon nanotube (CNT) reinforced metal matrix composites have been the focus
of researchers due to their high load-bearing capacity. Among single and
multi-wall carbon nanotubes (MWCNT), the latter is preferred by manufacturers
and engineers for making composites due to their economic feasibility of
synthesizing. However, the effect of layer numbers along with other parameters
of the reinforcing MWCNT must be understood before its industrial application.
In this article, we developed a novel theoretical approach for predicting the
variation of strength and stiffness of MWCNT reinforced iron composites
(MWCNT-Fe) with the layer number of reinforcing MWCNT and validated the
prediction with a series of Molecular dynamics (MD) simulation. Our analysis
revealed that for every addition of two extra layers, the strength and
stiffness of the composite increase 9.8% and 7.2% respectively up to eight
layered MWCNT and then becomes saturated. We also employed MD simulations for
investigating the effect of grain boundary on the failure mechanism of CNT
reinforced iron composites in contrast to previous studies. Our investigations
revealed that instead of the matrix-fiber interface, the failure was initiated
from the grain boundary and merges with the interface. The results in this
study will not only help engineers and manufacturers choose optimal layered
MWCNT for synthesizing composite for a specific application but also provide
scientists a new method to model composites for predicting desired properties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:43:47 GMT""}]","2021-02-10"
"2102.05026","Marco Ciccone","Federico Cacciamani, Andrea Celli, Marco Ciccone, Nicola Gatti","Multi-Agent Coordination in Adversarial Environments through Signal
  Mediated Strategies","Accepted at AAMAS 2021 (full paper)",,,,"cs.MA cs.AI cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world scenarios involve teams of agents that have to coordinate
their actions to reach a shared goal. We focus on the setting in which a team
of agents faces an opponent in a zero-sum, imperfect-information game. Team
members can coordinate their strategies before the beginning of the game, but
are unable to communicate during the playing phase of the game. This is the
case, for example, in Bridge, collusion in poker, and collusion in bidding. In
this setting, model-free RL methods are oftentimes unable to capture
coordination because agents' policies are executed in a decentralized fashion.
Our first contribution is a game-theoretic centralized training regimen to
effectively perform trajectory sampling so as to foster team coordination. When
team members can observe each other actions, we show that this approach
provably yields equilibrium strategies. Then, we introduce a signaling-based
framework to represent team coordinated strategies given a buffer of past
experiences. Each team member's policy is parametrized as a neural network
whose output is conditioned on a suitable exogenous signal, drawn from a
learned probability distribution. By combining these two elements, we
empirically show convergence to coordinated equilibria in cases where previous
state-of-the-art multi-agent RL algorithms did not.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:44:16 GMT""}]","2021-02-10"
"2102.05027","Ravi Kumar Kopparapu","Ravi Kopparapu, Giada Arney, Jacob Haqq-Misra, Jacob Lustig-Yaeger,
  Geronimo Villanueva","Nitrogen Dioxide Pollution as a Signature of Extraterrestrial Technology","Accepted to Astrophysical Journal (in press). 1-D photochemical code
  from 'Atmos' is available at:
  https://github.com/VirtualPlanetaryLaboratory/atmos",,"10.3847/1538-4357/abd7f7",,"astro-ph.EP astro-ph.IM physics.pop-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nitrogen dioxide (NO$_2$) on Earth today has biogenic and anthropogenic
sources. During the COVID-19 pandemic, observations of global NO$_2$ emissions
have shown significant decrease in urban areas. Drawing upon this example of
NO$_2$ as an industrial byproduct, we use a one-dimensional photochemical model
and synthetic spectral generator to assess the detectability of NO$_2$ as an
atmospheric technosignature on exoplanets. We consider cases of an Earth-like
planet around Sun-like, K-dwarf and M-dwarf stars. We find that NO$_2$
concentrations increase on planets around cooler stars due to less
short-wavelength photons that can photolyze NO$_2$. In cloud-free results,
present Earth-level NO$_2$ on an Earth-like planet around a Sun-like star at
10pc can be detected with SNR ~5 within ~400 hours with a 15 meter LUVOIR-like
telescope when observed in the 0.2 - 0.7micron range where NO$_2$ has a strong
absorption. However, clouds and aerosols can reduce the detectability and could
mimic the NO$_2$ feature. Historically, global NO$_2$ levels were 3x higher,
indicating the capability of detecting a 40-year old Earth-level civilization.
Transit and direct imaging observations to detect infrared spectral signatures
of NO$_2$ on habitable planets around M-dwarfs would need several 100s of hours
of observation time, both due to weaker NO$_2$ absorption in this region, and
also because of masking features by dominant H$_2$O and CO$_2$ bands in the
infrared part of the spectrum. Non-detection at these levels could be used to
place upper limits on the prevalence of NO$_2$ as a technosignature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:45:37 GMT""}]","2021-03-03"
"2102.05028","Cyrus Hettle","Cyrus Hettle, Shixiang Zhu, Swati Gupta, Yao Xie","Balanced Districting on Grid Graphs with Provable Compactness and
  Contiguity",,,,,"cs.DS math.CO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a graph $G = (V,E)$ with vertex weights $w(v)$ and a desired number of
parts $k$, the goal in graph partitioning problems is to partition the vertex
set V into parts $V_1,\ldots,V_k$. Metrics for compactness, contiguity, and
balance of the parts $V_i$ are frequent objectives, with much existing
literature focusing on compactness and balance. Revisiting an old method known
as striping, we give the first polynomial-time algorithms with guaranteed
contiguity and provable bicriteria approximations for compactness and balance
for planar grid graphs. We consider several types of graph partitioning,
including when vertex weights vary smoothly or are stochastic, reflecting
concerns in various real-world instances. We show significant improvements in
experiments for balancing workloads for the fire department and reducing
over-policing using 911 call data from South Fulton, GA.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:46:10 GMT""}]","2021-02-10"
"2102.05029","Yoni BenTov","Yoni BenTov","Schwinger-Keldysh path integral for the quantum harmonic oscillator","112 pages, 1 figure",,,,"hep-th cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I review the generating function for quantum-statistical mechanics, known as
the Feynman-Vernon influence functional, the decoherence functional, or the
Schwinger-Keldysh path integral. I describe a probability-conserving
$i\varepsilon$ prescription from a path-integral implementation of Lindblad
evolution. I also explain how to generalize the formalism to accommodate
out-of-time-ordered correlators (OTOCs), leading to a Larkin-Ovchinnikov path
integral. My goal is to provide step-by-step calculations of path integrals
associated to the harmonic oscillator.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:47:32 GMT""}]","2021-02-10"
"2102.05030","Alec Coffman","Alec J. Coffman, Jianfeng Lu, Joseph E. Subotnik","A Grid-free Approach for Simulating Sweep and Cyclic Voltammetry",,,"10.1063/5.0044156",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We present a new computational approach to simulate linear sweep and cyclic
voltammetry experiments that does not require a discretized grid in space to
quantify diffusion. By using a Green's function solution coupled to a standard
implicit ordinary differential equation solver, we are able to simulate current
and redox species concentrations using only a small grid in time. As a result,
where benchmarking is possible, we find that the current method is faster (and
quantitatively identical) to established techniques. The present algorithm
should help open the door to studying adsorption effects in inner sphere
electrochemistry.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:48:49 GMT""}]","2021-05-05"
"2102.05031","Thomas Orvis","Thomas Orvis, Harish Kumarasubramanian, Mythili Surendran, Shanmukh
  Kutagulla, Austin Cunniff, and Jayakanth Ravichandran","In situ Monitoring of Composition and Sensitivity to Growth Parameters
  of Pulsed Laser Deposition","24 pages, 6 figures, submitted to ACS Applied Electronic Materials",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Complex oxide perovskites have been widely studied for their diverse
functional properties. When dimensionally reduced to epitaxial thin films and
heterostructures these properties are frequently tunable, and the
symmetry-breaking inherent to thin film structures can result in the emergence
of new, novel, phenomena and properties. However, the ability to control and
harness these structures relies on an atomic-level understanding and control of
the growth process, made challenging by the lack of suitable in situ
compositional characterization tools. In this work, the
compositional-dependence of SrTiO3 on pulsed laser deposition growth parameters
is investigated with in situ Auger electron spectroscopy and ex situ thin film
x-ray diffraction, and verified with a simple escape depth model. We show that
this is a suitable technique for monitoring subtle compositional shifts
occurring during the deposition process, with broad implications for the
continued development of thin film synthesis techniques.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:53:55 GMT""}]","2021-02-10"
"2102.05032","Masayuki Hase Oka","C. Dias and M. O. Hase","Weakening connections in heterogeneous mean-field models",,"J. Stat. Mech. (2021) 013404",,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two versions of the susceptible-infected-susceptible epidemic model, which
have different transmission rules, are analysed. Both models are considered on
a weighted network to simulate a mitigation in the connection between the
individuals. The analysis is performed through a heterogeneous mean-field
approach on a scale-free network. For a suitable choice of the parameters, both
models exhibit a positive infection threshold, when they share the same
critical exponents associated with the behaviour of the prevalence against the
infection rate. Nevertheless, when the infection threshold vanishes, the
prevalence of these models display different algebraic decays to zero for low
values of the infection rate.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:55:10 GMT""}]","2021-02-10"
"2102.05033","Lindsey Bleem","L. E. Bleem, T. M. Crawford, B. Ansarinejad, B. A. Benson, S. Bocquet,
  J. E. Carlstrom, C. L. Chang, R. Chown, A. T. Crites, T. de Haan, M. A.
  Dobbs, W. B. Everett, E. M. George, R. Gualtieri, N. W. Halverson, G. P.
  Holder, W. L. Holzapfel, J. D. Hrubes, L. Knox, A. T. Lee, D. Luong-Van, D.
  P. Marrone, J. J. McMahon, S. S. Meyer, M. Millea, L. M. Mocanu, J. J. Mohr,
  T. Natoli, Y. Omori, S. Padin, C. Pryke, S. Raghunathan, C. L. Reichardt, J.
  E. Ruhl, K. K. Schaffer, E. Shirokoff, Z. Staniszewski, A. A. Stark, J. D.
  Vieira, and R. Williamson","CMB/kSZ and Compton-$y$ Maps from 2500 square degrees of SPT-SZ and
  Planck Survey Data","Minor changes to match version accepted in ApJS",,"10.3847/1538-4365/ac35e9",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present component-separated maps of the primary cosmic microwave
background/kinematic Sunyaev-Zel'dovich (SZ) amplitude and the thermal SZ
Compton-$y$ parameter, created using data from the South Pole Telescope (SPT)
and the Planck satellite. These maps, which cover the $\sim$2500 square degrees
of the Southern sky imaged by the SPT-SZ survey, represent a significant
improvement over previous such products available in this region by virtue of
their higher angular resolution (1.25 arcminutes for our highest resolution
Compton-$y$ maps) and lower noise at small angular scales. In this work we
detail the construction of these maps using linear combination techniques,
including our method for limiting the correlation of our lowest-noise
Compton-$y$ map products with the cosmic infrared background. We perform a
range of validation tests on these data products to test our sky modeling and
combination algorithms, and we find good performance in all of these tests.
Recognizing the potential utility of these data products for a wide range of
astrophysical and cosmological analyses, including studies of the gas
properties of galaxies, groups, and clusters, we make these products publicly
available at http://pole.uchicago.edu/public/data/sptsz_ymap and on the
NASA/LAMBDA website.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:55:25 GMT""},{""version"":""v2"",""created"":""Wed, 24 Nov 2021 04:16:04 GMT""}]","2022-02-09"
"2102.05034","Bahare Fatemi","Bahare Fatemi, Layla El Asri, Seyed Mehran Kazemi","SLAPS: Self-Supervision Improves Structure Learning for Graph Neural
  Networks","Accepted at NeurIPS 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural networks (GNNs) work well when the graph structure is provided.
However, this structure may not always be available in real-world applications.
One solution to this problem is to infer a task-specific latent structure and
then apply a GNN to the inferred graph. Unfortunately, the space of possible
graph structures grows super-exponentially with the number of nodes and so the
task-specific supervision may be insufficient for learning both the structure
and the GNN parameters. In this work, we propose the Simultaneous Learning of
Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that
provides more supervision for inferring a graph structure through
self-supervision. A comprehensive experimental study demonstrates that SLAPS
scales to large graphs with hundreds of thousands of nodes and outperforms
several models that have been proposed to learn a task-specific graph structure
on established benchmarks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:56:01 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 21:51:44 GMT""}]","2021-11-02"
"2102.05035","Martin A. Guerrero","You-Hua Chu, Jesus A. Toala, Martin A. Guerrero, Florian Bauer, Jana
  Bilikova, Robert A. Gruendl","Hard X-ray Emission Associated with White Dwarfs. IV. Signs of Accretion
  from Sub-stellar Companions","Accepted for publication for The Astrophysical Journal",,"10.3847/1538-4357/abe5a5",,"astro-ph.SR astro-ph.EP astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  KPD 0005+5106, with an effective temperature of $\simeq$200,000 K, is one of
the hottest white dwarfs (WDs). ROSAT unexpectedly detected ""hard"" ($\sim$1
keV) X-rays from this apparently single WD. We have obtained Chandra
observations that confirm the spatial coincidence of this hard X-ray source
with KPD 0005+5106. We have also obtained XMM-Newton observations of KPD
0005+5106, as well as PG 1159$-$035 and WD 0121$-$756, which are also
apparently single and whose hard X-rays were detected by ROSAT at
3$\sigma$-4$\sigma$ levels. The XMM-Newton spectra of the three WDs show
remarkably similar shapes that can be fitted by models including a blackbody
component for the stellar photospheric emission, a thermal plasma emission
component, and a power-law component. Their X-ray luminosities in the $0.6-3.0$
keV band range from $4\times10^{29}$ to $4\times10^{30}$ erg~s$^{-1}$. The
XMM-Newton EPIC-pn soft-band ($0.3-0.5$ keV) lightcurve of KPD 0005+5106 is
essentially constant, but the hard-band ($0.6-3.0$ keV) lightcurve shows
periodic variations. An analysis of the generalized Lomb-Scargle periodograms
for the XMM-Newton and Chandra hard-band lightcurves finds a convincing
modulation (false alarm probability of 0.41%) with a period of 4.7$\pm$0.3 hr.
Assuming that this period corresponds to a binary orbital period, the Roche
radii of three viable types of companion have been calculated: M9V star, T
brown dwarf, and Jupiter-like planet. Only the planet has a size larger than
its Roche radius, although the M9V star and T brown dwarf may be heated by the
WD and inflate past the Roche radius. Thus, all three types of companion may be
donors to fuel accretion-powered hard X-ray emission.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:59:47 GMT""}]","2021-04-14"
"2102.05036","Eva Laplace","E. Laplace, S. Justham, M. Renzo, Y. G\""otberg, R. Farmer, D.
  Vartanyan and S. E. de Mink","Different to the core: the pre-supernova structures of massive single
  and binary-stripped stars","Accepted for publication on October 5th, 2021. Reproduced with
  permission from Astronomy & Astrophysics, \c{opyright} ESO. The pre-supernova
  models are available online at https://doi.org/10.5281/zenodo.4506803","A&A 656, A58 (2021)","10.1051/0004-6361/202140506",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The majority of massive stars live in binary or multiple systems and will
interact during their lifetimes, which helps to explain the observed diversity
of core-collapse supernovae. Donor stars in binary systems can lose most of
their hydrogen-rich envelopes through mass transfer, which not only affects the
surface properties, but also the core structure. However, most calculations of
the core-collapse properties of massive stars rely on single-star models. We
present a systematic study of the difference between the pre-supernova
structures of single stars and stars of the same initial mass (11 - 21\Msun)
that have been stripped due to stable post-main sequence mass transfer at solar
metallicity. We present the pre-supernova core composition with novel diagrams
that give an intuitive representation of the isotope distribution. As shown in
previous studies, at the edge of the carbon-oxygen core, the binary-stripped
star models contain an extended gradient of carbon, oxygen, and neon. This
layer originates from the receding of the convective helium core during core
helium burning in binary-stripped stars, which does not occur in single-star
models. We find that this same evolutionary phase leads to systematic
differences in the final density and nuclear energy generation profiles.
Binary-stripped star models have systematically higher total masses of carbon
at the moment of core collapse compared to single star models, which likely
results in systematically different supernova yields. In about half of our
models, the silicon-burning and oxygen-rich layers merge after core silicon
burning. We discuss the implications of our findings for the explodability,
supernova observations, and nucleosynthesis from these stars. Our models will
be publicly available and can be readily used as input for supernova
simulations. [Abridged]
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:59:58 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 14:52:49 GMT""}]","2021-12-08"
"2102.05043","Jaejin Shin","Jaejin Shin, Jong-Hak Woo, Minjin Kim, Junfeng Wang","Revisiting the complex kinematics of ionized gas at the central region
  of NGC 1068: evidence of an additional active galactic nucleus?","12 pages, 7 figures, ApJ, in press",,"10.3847/1538-4357/abd779",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a spatially resolved analysis of ionized gas at the nuclear region
of the nearby galaxy NGC 1068. While NGC 1068 has been known to have gas
outflows driven by its active galactic nucleus (AGN), more complex kinematical
signatures were recently reported, which were inconsistent with a rotation or
simple biconical outflows. To account for the nature of gas kinematics, we
performed a spatially resolved kinematical study, finding a morphologically
symmetric pair of approaching and receding gas blobs in the northeast region.
The midpoint of the two blobs is located at a distance of 180 pc from the
nucleus in the projected plane. The ionized gas at the midpoint shows zero
velocity and high velocity dispersion, which are characteristics of an
outflow-launching position, as the two sides of a bicone, i.e., approaching and
receding outflows are superposed on the line of sight, leading to no velocity
shift but high velocity dispersion. We investigate the potential scenario of an
additional AGN based on a multiwavelength data set. While there are other
possibilities, i.e., X-ray binary or supernova shock, the results from optical
spectropolarimetry analysis are consistent with the presence of an additional
AGN, which likely originates from a minor merger.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""}]","2021-02-24"
"2102.05044","Christian Bauer","Christian W. Bauer, Marat Freytsis and Benjamin Nachman","Simulating collider physics on quantum computers using effective field
  theories","5 pages, plus 11 pages of Supplemental Materials",,"10.1103/PhysRevLett.127.212001",,"hep-ph hep-lat quant-ph","http://creativecommons.org/licenses/by/4.0/","  Simulating the full dynamics of a quantum field theory over a wide range of
energies requires exceptionally large quantum computing resources. Yet for many
observables in particle physics, perturbative techniques are sufficient to
accurately model all but a constrained range of energies within the validity of
the theory. We demonstrate that effective field theories (EFTs) provide an
efficient mechanism to separate the high energy dynamics that is easily
calculated by traditional perturbation theory from the dynamics at low energy
and show how quantum algorithms can be used to simulate the dynamics of the low
energy EFT from first principles. As an explicit example we calculate the
expectation values of vacuum-to-vacuum and vacuum-to-one-particle transitions
in the presence of a time-ordered product of two Wilson lines in scalar field
theory, an object closely related to those arising in EFTs of the Standard
Model of particle physics. Calculations are performed using simulations of a
quantum computer as well as measurements using the IBMQ Manhattan machine.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""}]","2021-12-01"
"2102.05045","Zhoujian Zhang","Zhoujian Zhang (1), Michael C. Liu (1), William M. J. Best (2), Trent
  J. Dupuy (3 and 4), Robert J. Siverd (3) ((1) Institute for Astronomy,
  University of Hawaii at Manoa, Honolulu, HI, USA, (2) Department of
  Astronomy, University of Texas at Austin, Austin, Texas, USA, (3) Gemini
  Observatory/NSF's NOIRLab, Hilo, HI, USA, (4) Institute for Astronomy,
  University of Edinburgh, Royal Observatory, Edinburgh, UK)","The Hawaii Infrared Parallax Program. V. New T-Dwarf Members and
  Candidate Members of Nearby Young Moving Groups","ApJ, in press. 27 pages including 6 figures and 5 tables",,"10.3847/1538-4357/abe3fa",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a search for new planetary-mass members of nearby young moving
groups (YMGs) using astrometry for 694 T and Y dwarfs, including 447 objects
with parallaxes, mostly produced by recent large parallax programs from UKIRT
and Spitzer. Using the BANYAN $\Sigma$ and LACEwING algorithms, we identify 30
new candidate YMG members, with spectral types of T0$-$T9 and distances of
$10-43$ pc. Some candidates have unusually red colors and/or faint absolute
magnitudes compared to field dwarfs with similar spectral types, providing
supporting evidence for their youth, including 4 early-T dwarfs. We establish
one of these, the variable T1.5 dwarf 2MASS J21392676$+$0220226, as a new
planetary-mass member ($14.6^{+3.2}_{-1.6}$ M$_{\rm Jup}$) of the Carina-Near
group ($200\pm50$ Myr) based on its full six-dimensional kinematics, including
a new parallax measurement from CFHT. The high-amplitude variability of this
object is suggestive of a young age, given the coexistence of variability and
youth seen in previously known YMG T dwarfs. Our four latest-type (T8$-$T9) YMG
candidates, WISE J031624.35$+$430709.1, ULAS J130217.21$+$130851.2, WISEPC
J225540.74$-$311841.8, and WISE J233226.49$-$432510.6, if confirmed, will be
the first free-floating planets ($\approx2-6$ M$_{\rm Jup}$) whose ages and
luminosities are compatible with both hot-start and cold-start evolutionary
models, and thus overlap the properties of the directly-imaged planet 51 Eri b.
Several of our early/mid-T candidates have peculiar near-infrared spectra,
indicative of heterogenous photospheres or unresolved binarity. Radial velocity
measurements needed for final membership assessment for most of our candidates
await upcoming 20$-$30 meter class telescopes. In addition, we compile all 15
known T7$-$Y1 benchmarks and derive a homogeneous set of their effective
temperatures, surface gravities, radii, and masses.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""}]","2021-04-14"
"2102.05046","Luca Delacr\'etaz","Gabriel Cuomo, Luca V. Delacretaz and Umang Mehta","Large Charge Sector of 3d Parity-Violating CFTs","44 pages, 2 figures",,"10.1007/JHEP05(2021)115","EFI-21-1","hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Certain CFTs with a global $U(1)$ symmetry become superfluids when coupled to
a chemical potential. When this happens, a Goldstone effective field theory
controls the spectrum and correlators of the lightest large charge operators.
We show that in 3d, this EFT contains a single parity-violating 1-derivative
term with quantized coefficient. This term forces the superfluid ground state
to have vortices on the sphere, leading to a spectrum of large charge operators
that is remarkably richer than in parity-invariant CFTs. We test our
predictions in a weakly coupled Chern-Simons matter theory.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 16 May 2021 22:21:03 GMT""}]","2021-06-02"
"2102.05047","Max Hopkins","Max Hopkins, Daniel Kane, Shachar Lovett, Michal Moshkovitz","Bounded Memory Active Learning through Enriched Queries",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The explosive growth of easily-accessible unlabeled data has lead to growing
interest in active learning, a paradigm in which data-hungry learning
algorithms adaptively select informative examples in order to lower
prohibitively expensive labeling costs. Unfortunately, in standard worst-case
models of learning, the active setting often provides no improvement over
non-adaptive algorithms. To combat this, a series of recent works have
considered a model in which the learner may ask enriched queries beyond labels.
While such models have seen success in drastically lowering label costs, they
tend to come at the expense of requiring large amounts of memory. In this work,
we study what families of classifiers can be learned in bounded memory. To this
end, we introduce a novel streaming-variant of enriched-query active learning
along with a natural combinatorial parameter called lossless sample compression
that is sufficient for learning not only with bounded memory, but in a
query-optimal and computationally efficient manner as well. Finally, we give
three fundamental examples of classifier families with small, easy to compute
lossless compression schemes when given access to basic enriched queries:
axis-aligned rectangles, decision trees, and halfspaces in two dimensions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""}]","2021-02-11"
"2102.05048","William J. Torres Bobadilla Dr.","William J. Torres Bobadilla","Loop-tree duality from vertices and edges","26 pages, 3 figures. v2: added all loop causal representation +
  corrected a few typos. v3: references added; matches published version",,"10.1007/JHEP04(2021)183","MPP-2021-14","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  The causal representation of multi-loop scattering amplitudes, obtained from
the application of the loop-tree duality formalism, comprehensively elucidates,
at integrand level, the behaviour of only physical singularities. This
representation is found to manifest compact expressions for multi-loop
topologies that have the same number of \textit{vertices}. Interestingly,
integrands considered in former studies, with up-to six vertices and $L$
internal lines, display the same structure of up-to four-loop ones. The former
is an insight that there should be a correspondence between vertices and the
collection of internal lines, \textit{edges}, that characterise a multi-loop
topology. By virtue of this relation, in this paper, we embrace an approach to
properly classify multi-loop topologies according to vertices and edges.
Differently from former studies, we consider the most general topologies, by
connecting vertices and edges in all possible ways. Likewise, we provide a
procedure to generate causal representation of multi-loop topologies by
considering the structure of causal propagators. Explicit causal
representations of loop topologies with up-to nine vertices are provided.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 06:37:45 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 16:12:38 GMT""}]","2021-06-23"
"2102.05049","Adrian Bayer","Adrian E. Bayer, Francisco Villaescusa-Navarro, Elena Massara, Jia
  Liu, David N. Spergel, Licia Verde, Benjamin D. Wandelt, Matteo Viel, Shirley
  Ho","Detecting Neutrino Mass by Combining Matter Clustering, Halos, and Voids","11+5 pages, 10 figures, 2 tables","ApJ 919 1 24 (2021)","10.3847/1538-4357/ac0e91",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We quantify the information content of the non-linear matter power spectrum,
the halo mass function, and the void size function, using the Quijote $N$-body
simulations. We find that these three statistics exhibit very different
degeneracies amongst the cosmological parameters, and thus the combination of
all three probes enables the breaking of degeneracies, in turn yielding
remarkably tight constraints. We perform a Fisher analysis using the full
covariance matrix, including all auto- and cross-correlations, finding that
this increases the information content for neutrino mass compared to a
correlation-free analysis. The multiplicative improvement of the constraints on
the cosmological parameters obtained by combining all three probes compared to
using the power spectrum alone are: 137, 5, 8, 20, 10, and 43, for $\Omega_m$,
$\Omega_b$, $h$, $n_s$, $\sigma_8$, and $M_\nu$, respectively. The marginalized
error on the sum of the neutrino masses is $\sigma(M_\nu)=0.018\,{\rm eV}$ for
a cosmological volume of $1\,(h^{-1}{\rm Gpc})^3$, using $k_{\max}=0.5\,h{\rm
Mpc}^{-1}$, and without CMB priors. We note that this error is an underestimate
insomuch as we do not consider super-sample covariance, baryonic effects, and
realistic survey noises and systematics. On the other hand, it is an
overestimate insomuch as our cuts and binning are suboptimal due to
restrictions imposed by the simulation resolution. Given upcoming galaxy
surveys will observe volumes spanning $\sim 100\,(h^{-1}{\rm Gpc})^3$, this
presents a promising new avenue to measure neutrino mass without being
restricted by the need for accurate knowledge of the optical depth, which is
required for CMB-based measurements. Furthermore, the improved constraints on
other cosmological parameters, notably $\Omega_m$, may also be competitive with
CMB-based measurements.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 15:13:19 GMT""}]","2021-09-21"
"2102.05050","Devontae Baxter","Devontae C. Baxter, M. C. Cooper, Sean P. Fillingham","A Machine Learning Approach to Measuring the Quenched Fraction of
  Low-Mass Satellites Beyond the Local Group","Key Figures: 3, 4 and 8; 11 pages; 8 figures; Accepted for
  publication in MNRAS 2021 February 18. Received 2021 February 15; in original
  form 2020 December 11",,"10.1093/mnras/stab523",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations suggest that satellite quenching plays a major role in the
build-up of passive, low-mass galaxies at late cosmic times. Studies of
low-mass satellites, however, are limited by the ability to robustly
characterize the local environment and star-formation activity of faint
systems. In an effort to overcome the limitations of existing data sets, we
utilize deep photometry in Stripe 82 of the Sloan Digital Sky Survey, in
conjunction with a neural network classification scheme, to study the
suppression of star formation in low-mass satellite galaxies in the local
Universe. Using a statistically-driven approach, we are able to push beyond the
limits of existing spectroscopic data sets, measuring the satellite quenched
fraction down to satellite stellar masses of ${\sim}10^7~{\rm M}_{\odot}$ in
group environments (${M}_{\rm{halo}} = 10^{13-14}~h^{-1}~{\rm M}_{\odot}$). At
high satellite stellar masses ($\gtrsim 10^{10}~{\rm M}_{\odot}$), our analysis
successfully reproduces existing measurements of the quenched fraction based on
spectroscopic samples. Pushing to lower masses, we find that the fraction of
passive satellites increases, potentially signaling a change in the dominant
quenching mechanism at ${M}_{\star} \sim 10^{9}~{\rm M}_{\odot}$. Similar to
the results of previous studies of the Local Group, this increase in the
quenched fraction at low satellite masses may correspond to an increase in the
efficacy of ram-pressure stripping as a quenching mechanism in groups.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 19:39:51 GMT""}]","2022-08-08"
"2102.05051","Alessandro Lupi","Alessandro Lupi, Zoltan Haiman, and Marta Volonteri","Forming massive seed black holes in high-redshift quasar host
  progenitors","16 pages, 9 figures, 3 tables, matches the published version",,"10.1093/mnras/stab692",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The presence of massive black holes (BHs) with masses of order $10^9\rm\,
M_\odot$, powering bright quasars when the Universe was less than 1 Gyr old,
poses strong constraints on their formation mechanism. Several scenarios have
been proposed to date to explain massive BH formation, from the low-mass seed
BH remnants of the first generation of stars to the massive seed BHs resulting
from the rapid collapse of massive gas clouds. However, the plausibility of
some of these scenarios to occur within the progenitors of high-z quasars has
not yet been thoroughly explored. In this work, we investigate, by combining
dark-matter only N-body simulations with a semi-analytic framework, whether the
conditions for the formation of massive seed BHs from synchronised
atomic-cooling halo pairs and/or dynamically-heated mini-haloes are fulfilled
in the overdense regions where the progenitors of a typical high-redshift
quasar host form and evolve. Our analysis shows that the peculiar conditions in
such regions, i.e. strong halo clustering and high star formation rates, are
crucial to produce a non-negligible number of massive seed BH host candidates:
we find $\approx1400$ dynamically heated metal-free mini-haloes, including one
of these which evolves to a synchronised pair and ends up in the massive
quasar-host halo by $z=6$. This demonstrates that the progenitors of
high-redshift quasar host haloes can harbour early massive seed BHs. Our
results further suggest that multiple massive seed BHs may form in or near the
quasar host's progenitors, potentially merging at lower redshifts and yielding
gravitational wave events.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 16:23:23 GMT""}]","2022-01-05"
"2102.05052","SangEun Han","SangEun Han, Yong Baek Kim","Non-Fermi liquid induced by Bose metal with protected subsystem
  symmetries","Main text: 6 pages, 2 figures, Supplemental Material: 7 pages, 3
  figures","Phys. Rev. B 106, L081106 (2022)","10.1103/PhysRevB.106.L081106",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding non-Fermi liquids in dimensions higher than one, has been a
subject of great interest. Such phases may serve as parent states for other
unconventional phases of quantum matter, in a similar manner that conventional
broken symmetry states can be understood as instabilities of the Fermi liquid.
In this work, we investigate the emergence of a novel non-Fermi liquid in two
dimensions, where the fermions with quadratic band-touching dispersion interact
with the Bose metal. The bosonic excitations in the Bose metal possess an
extended nodal-line spectrum in momentum space, which arises due to the
subsystem symmetry or the restricted motion of bosons. Using renormalization
group analysis and direct computations, we show that the extended infrared (IR)
singularity of the Bose metal leads to a line of interacting fixed points of
novel non-Fermi liquids, where the anomalous dimension of the fermions varies
continuously, akin to the Luttinger liquid in one dimension. Further, the
generalization of the model with multiple low-energy excitations is used to
explore other unusual features of the resulting ground state.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 03:20:51 GMT""},{""version"":""v3"",""created"":""Mon, 8 Aug 2022 18:29:26 GMT""}]","2022-08-10"
"2102.05053","Jonah Kudler-Flam","Jonah Kudler-Flam","Relative Entropy of Random States and Black Holes","5+3 pages; v2: two appendices, discussion of implications for quantum
  hypothesis testing, and references added","Phys. Rev. Lett. 126, 171603 (2021)","10.1103/PhysRevLett.126.171603",,"hep-th cond-mat.stat-mech cond-mat.str-el math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relative entropy of highly excited quantum states. First, we
sample states from the Wishart ensemble and develop a large-N diagrammatic
technique for the relative entropy. The solution is exactly expressed in terms
of elementary functions. We compare the analytic results to small-N numerics,
finding precise agreement. Furthermore, the random matrix theory results
accurately match the behavior of chaotic many-body eigenstates, a manifestation
of eigenstate thermalization. We apply this formalism to the AdS/CFT
correspondence where the relative entropy measures the distinguishability
between different black hole microstates. We find that black hole microstates
are distinguishable even when the observer has arbitrarily small access to the
quantum state, though the distinguishability is nonperturbatively small in
Newton's constant. Finally, we interpret these results in the context of the
subsystem Eigenstate Thermalization Hypothesis (sETH), concluding that
holographic systems obey sETH up to subsystems half the size of the total
system.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 14:36:27 GMT""}]","2021-04-28"
"2102.05054","David J. Luitz","David J. Luitz","Polynomial filter diagonalization of large Floquet unitary operators","4 pages, 4 figures, 1 table","SciPost Phys. 11, 021 (2021)","10.21468/SciPostPhys.11.2.021",,"cond-mat.dis-nn cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodically driven quantum many-body systems play a central role for our
understanding of nonequilibrium phenomena. For studies of quantum chaos,
thermalization, many-body localization and time crystals, the properties of
eigenvectors and eigenvalues of the unitary evolution operator, and their
scaling with physical system size $L$ are of interest. While for static
systems, powerful methods for the partial diagonalization of the Hamiltonian
were developed, the unitary eigenproblem remains daunting. In this paper, we
introduce a Krylov space diagonalization method to obtain exact eigenpairs of
the unitary Floquet operator with eigenvalue closest to a target on the unit
circle. Our method is based on a complex polynomial spectral transformation
given by the geometric sum, leading to rapid convergence of the Arnoldi
algorithm. We demonstrate that our method is much more efficient than the shift
invert method in terms of both runtime and memory requirements, pushing the
accessible system sizes to the realm of 20 qubits, with Hilbert space
dimensions $\geq 10^6$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 19:44:29 GMT""}]","2021-08-04"
"2102.05055","Enrico Nardi","Luc Darm\'e and Enrico Nardi","Exact accidental U(1) symmetries for the axion","6 pages","Phys. Rev. D 104, 055013 (2021)","10.1103/PhysRevD.104.055013",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a class of gauge groups that can automatically yield a
perturbatively exact Peccei-Quinn symmetry, and we outline a model in which the
axion quality problem is solved at all operator dimensions. Gauge groups
belonging to this class can also enforce and protect accidental symmetries of
the clockwork type, and we present a toy model where an `invisible' axion
arises from a single breaking of the gauge and global symmetries.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:01 GMT""}]","2021-09-22"
"2102.05056","Sebastian Turner","Sebastian Turner, Ma{\l}gorzata Siudek, Samir Salim, Ivan K. Baldry,
  Agnieszka Pollo, Steven N. Longmore, Katarzyna Ma{\l}ek, Chris A. Collins,
  Paulo J. Lisboa, Janusz Krywult, Thibaud Moutard, Daniela Vergani, and
  Alexander Fritz","Synergies between low- and intermediate-redshift galaxy populations
  revealed with unsupervised machine learning","Accepted for publication in MNRAS. 22 pages, 15 figures",,"10.1093/mnras/stab653",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The colour bimodality of galaxies provides an empirical basis for theories of
galaxy evolution. However, the balance of processes that begets this bimodality
has not yet been constrained. A more detailed view of the galaxy population is
needed, which we achieve in this paper by using unsupervised machine learning
to combine multi-dimensional data at two different epochs. We aim to understand
the cosmic evolution of galaxy subpopulations by uncovering substructures
within the colour bimodality. We choose a clustering algorithm that models
clusters using only the most discriminative data available, and apply it to two
galaxy samples: one from the second edition of the GALEX-SDSS-WISE Legacy
Catalogue (GSWLC-2; $z \sim 0.06$), and the other from the VIMOS Public
Extragalactic Redshift Survey (VIPERS; $z \sim 0.65$). We cluster within a
nine-dimensional feature space defined purely by rest-frame
ultraviolet-through-near-infrared colours. Both samples are similarly
partitioned into seven clusters, breaking down into four of mostly star-forming
galaxies (including the vast majority of green valley galaxies) and three of
mostly passive galaxies. The separation between these two families of clusters
suggests differences in the evolution of their galaxies, and that these
differences are strongly expressed in their colours alone. The samples are
closely related, with star-forming/green-valley clusters at both epochs forming
morphological sequences, capturing the gradual internally-driven growth of
galaxy bulges. At high stellar masses, this growth is linked with quenching.
However, it is only in our low-redshift sample that additional, environmental
processes appear to be involved in the evolution of low-mass passive galaxies.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 15:33:43 GMT""}]","2021-06-08"
"2102.05057","Mark Van Raamsdonk","Mark Van Raamsdonk","Cosmology from confinement?","45 pages, 16 figures, v2: typos corrected",,"10.1007/JHEP03(2022)039",,"hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a class of holographic models that may describe the physics of
certain four-dimensional big-bang / big-crunch cosmologies. The construction
involves a pair of 3D Euclidean holographic CFTs each on a homogeneous and
isotropic space $M$ coupled at either end of an interval ${\cal I}$ to a
Euclidean 4D CFT on $M \times {\cal I}$ with many fewer local degrees of
freedom. We argue that in some cases, when the size of $M$ is much greater than
the length of ${\cal I}$, the theory flows to a gapped / confining
three-dimensional field theory on $M$ in the infrared, and this is reflected in
the dual description by the asymptotically AdS spacetimes dual to the two 3D
CFTs joining up in the IR to give a Euclidean wormhole. The Euclidean
construction can be reinterpreted as generating a state of Lorentzian 4D CFT on
$M \times {\rm time}$ whose dual includes the physics of a big-bang /
big-crunch cosmology. When $M$ is $\mathbb{R}^3$, we can alternatively
analytically continue one of the $\mathbb{R}^3$ directions to get an eternally
traversable four-dimensional planar wormhole. We suggest explicit microscopic
examples where the 4D CFT is ${\cal N}=4$ SYM theory and the 3D CFTs are
superconformal field theories with opposite orientation. In this case, the two
geometries dual to the pair of 3D SCFTs can be understood as a geometrical
version of a brane-antibrane pair, and the tendency of the geometries to
connect up is related to the standard instability of brane-antibrane systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 18:17:32 GMT""}]","2022-03-23"
"2102.05058","Vedant Chandra","Vedant Chandra and Kevin C. Schlaufman","Searching for Low-mass Population III Stars Disguised as White Dwarfs","16 pages, 5 figures, and 1 table in aastex63 format; accepted for
  publication in AJ",,"10.3847/1538-3881/abe535",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is uncertain whether or not low-mass Population III stars ever existed.
While limits on the number density of Population III stars with $M_{\ast}
\approx 0.8~M_{\odot}$ have been derived using Sloan Digital Sky Survey (SDSS)
data, little is known about the occurrence of Population III stars at lower
masses. In the absence of reliable parallaxes, the spectra of metal-poor main
sequence (MPMS) stars with $M_{\ast} \lesssim 0.8~M_{\odot}$ can easily be
confused with cool white dwarfs. To resolve this ambiguity, we present a
classifier that differentiates between MPMS stars and white dwarfs based on
photometry and/or spectroscopy without the use of parallax information. We
build and train our classifier using state-of-the-art theoretical spectra and
evaluate it on existing SDSS-based classifications for objects with reliable
Gaia DR2 parallaxes. We then apply our classifier to a large catalog of objects
with SDSS photometry and spectroscopy to search for MPMS candidates. We
discover several previously unknown candidate extremely metal-poor (EMP) stars
and recover numerous confirmed EMP stars already in the literature. We conclude
that archival SDSS spectroscopy has already been exhaustively searched for EMP
stars. We predict that the lowest-mass primordial-composition stars will have
redder optical-to-infrared colors than cool white dwarfs at constant effective
temperature due to surface gravity-dependent collision-induced absorption from
molecular hydrogen. We suggest that the application of our classifier to data
produced by next-generation spectroscopic surveys will set stronger constraints
on the number density of low-mass Population III stars in the Milky Way.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:02 GMT""}]","2021-03-29"
"2102.05059","Kai Zhang","Kai Zhang, Zhesen Yang, and Chen Fang","Universal non-Hermitian skin effect in two and higher dimensions","21 pages, 10 figures","Nat Commun 13, 2496 (2022)","10.1038/s41467-022-30161-6",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Skin effect, experimentally discovered in one dimension, describes the
physical phenomenon that on an open chain, an extensive number of eigenstates
of a non-Hermitian hamiltonian are localized at the end(s) of the chain. Here
in two and higher dimensions, we establish a theorem that the skin effect
exists, if and only if periodic-boundary spectrum of the hamiltonian covers a
finite area on the complex plane. This theorem establishes the universality of
the effect, because the above condition is satisfied in almost every generic
non-Hermitian hamiltonian, and, unlike in one dimension, is compatible with all
spatial symmetries. We propose two new types of skin effect in two and higher
dimensions: the corner-skin effect where all eigenstates are localized at one
corner of the system, and the geometry-dependent-skin effect where skin modes
disappear for systems of a particular shape, but appear on generic polygons. An
immediate corollary of our theorem is that any non-Hermitian system having
exceptional points (lines) in two (three) dimensions exhibits skin effect,
making this phenomenon accessible to experiments in photonic crystals, Weyl
semimetals, and Kondo insulators.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 15:03:27 GMT""}]","2022-05-09"
"2102.05060","Hong Yao","Xun Cai, Zi-Xiang Li, Hong Yao","Antiferromagnetism induced by electron-phonon-coupling","6.2 pages + Supplemental materials, 6 figures; v2: added more
  references","Phys. Rev. Lett. 127, 247203 (2021)","10.1103/PhysRevLett.127.247203",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Antiferromagnetism (AF) such as Neel ordering is often closely related to
Coulomb interactions such as Hubbard repulsion in two-dimensional (2D) systems.
Whether Neel AF ordering in 2D can be dominantly induced by electron-phonon
couplings (EPC) has not been completely understood. Here, by employing
numerically-exact sign-problem-free quantum Monte Carlo (QMC) simulations, we
show that optical Su-Schrieffer-Heeger (SSH) phonons with frequency $\omega$
and EPC constant $\lambda$ can induce AF ordering for a wide range of phonon
frequency $\omega>\omega_c$. For $\omega<\omega_c$, a valence-bond-solid (VBS)
order appears and there is a direct quantum phase transition between VBS and AF
phases at $\omega_c$. The phonon mechanism of the AF ordering is related to the
fact that SSH phonons directly couple to electron hopping whose second-order
process can induce an effective AF spin exchange. Our results shall shed new
lights to understanding AF ordering in correlated quantum materials.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 04:46:22 GMT""}]","2022-01-17"
"2102.05061","Stephanie Tonnesen","Stephanie Tonnesen (1) and Greg L. Bryan (1 and 2) ((1) Center for
  Computational Astrophysics, Flatiron Institute, (2) Columbia University)","It's Cloud's Illusions I Recall: Mixing Drives the Acceleration of
  Clouds from Ram Pressure Stripped Galaxies","submitted to AAS Journals",,"10.3847/1538-4357/abe7e2",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Ram Pressure Stripping can remove gas from satellite galaxies in clusters via
a direct interaction between the intracluster medium (ICM) and the interstellar
medium. This interaction is generally thought of as a contact force per area,
however we point out that these gases must interact in a hydrodynamic fashion,
and argue that this will lead to mixing of the galactic gas with the ICM wind.
We develop an analytic framework for how mixing is related to the acceleration
of stripped gas from a satellite galaxy. We then test this model using three
""wind-tunnel"" simulations of Milky Way-like galaxies interacting with a moving
ICM, and find excellent agreement with predictions using the analytic
framework. Focusing on the dense clumps in the stripped tails, we find that
they are nearly uniformly mixed with the ICM, indicating that all gas in the
tail mixes with the surroundings, and dense clumps are not separate entities to
be modeled differently than diffuse gas. We find that while mixing drives
acceleration of stripped gas, the density and velocity of the surrounding wind
will determine whether the mixing results in the heating of stripped gas into
the ICM, or the cooling of the ICM into dense clouds.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:04 GMT""}]","2021-04-28"
"2102.05062","German F. R. Sborlini","German F. R. Sborlini","Geometrical approach to causality in multi-loop amplitudes","11 pages, 4 figures. Extended discussion about selection criteria.
  Final version published in PRD","Phys. Rev. D 104, 036014 (2021)","10.1103/PhysRevD.104.036014","DESY 21-017","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  An impressive effort is being placed in order to develop new strategies that
allow an efficient computation of multi-loop multi-leg Feynman integrals and
scattering amplitudes, with a particular emphasis on removing spurious
singularities and numerical instabilities. In this article, we describe an
innovative geometric approach based on graph theory to unveil the causal
structure of any multi-loop multi-leg amplitude in Quantum Field Theory. Our
purely geometric construction reproduces faithfully the manifestly causal
integrand-level behaviour of the Loop-Tree Duality representation. We found
that the causal structure is fully determined by the vertex matrix, through a
suitable definition of connected partitions of the underlying diagrams. Causal
representations for a given topological family are obtained by summing over
subsets of all the possible causal entangled thresholds that originate
connected and oriented partitions of the underlying topology. These results are
compatible with Cutkosky rules. Moreover, we found that diagrams with the same
number of vertices and multi-edges exhibit similar causal structures,
regardless of the number of loops.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 09:43:13 GMT""}]","2021-09-08"
"2102.05063","Nishat Fiza","Nishat Fiza, Mehedi Masud and Manimala Mitra","Exploring the new physics phases in 3+1 scenario in neutrino oscillation
  experiments","25 pages; 10 figures; added more details about simulation, prior and
  event spectra; corrected NDBD analysis; accepted for publication in JHEP","JHEP09(2021)162","10.1007/JHEP09(2021)162",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The various global analyses of available neutrino oscillation data indicate
the presence of the standard $3+0$ neutrino oscillation picture. However, there
are a few short baseline anomalies that point to the possible existence of a
fourth neutrino (with mass in the eV-scale), essentially sterile in nature.
Should sterile neutrino exist in nature and its presence is not taken into
consideration properly in the analyses of neutrino data, the interference terms
arising due to the additional CP phases in presence of a sterile neutrino can
severely impact the physics searches in long baseline (LBL) neutrino
oscillation experiments. In the current work we consider one light (eV-scale)
sterile neutrino and probe all the three CP phases ($\delta_{13}$,
$\delta_{24}$, $\delta_{34}$) in the context of the upcoming Deep Underground
Neutrino Experiment (DUNE) and also estimate how the results improve when data
from NOvA, T2K and T2HK are added in the analysis. We illustrate the $\Delta
\chi^2$ correlations of the CP phases among each other, and also with the three
active-sterile mixing angles. Finally, we briefly illustrate how the relevant
parameter spaces in the context of neutrinoless double beta decay get modified
in light of the bounds in presence of a light sterile neutrino.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:08 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 15:11:48 GMT""}]","2021-10-05"
"2102.05064","Jonathan J. Fortney","Jonathan J. Fortney, Rebekah I. Dawson, and Thaddeus D. Komacek","Hot Jupiters: Origins, Structure, Atmospheres","References fixed, Figures revised, text edited slightly to better
  match final version, open access at: http://dx.doi.org/10.1029/2020JE006629",,"10.1029/2020JE006629",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We provide a brief review of many aspects of the planetary physics of hot
Jupiters. Our aim is to cover most of the major areas of current study while
providing the reader with additional references for more detailed follow-up. We
first discuss giant planet formation and subsequent orbital evolution via
disk-driven torques or dynamical interactions. More than one formation pathway
is needed to understand the population. Next, we examine our current
understanding of the evolutionary history and current interior structure of the
planets, where we focus on bulk composition as well as viable models to explain
the inflated radii of the population. Finally we discuss aspects of their
atmospheres in the context of observations and 1D and 3D models, including
atmospheric structure and escape, spectroscopic signatures, and complex
atmospheric circulation. The major opacity sources in these atmospheres,
including alkali metals, water vapor, and others, are discussed. We discuss
physics that control the 3D atmospheric circulation and day-to-night
temperature structures. We conclude by suggesting important future work for
still-open questions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:12 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 02:32:06 GMT""},{""version"":""v3"",""created"":""Sat, 13 Mar 2021 22:07:34 GMT""},{""version"":""v4"",""created"":""Tue, 16 Mar 2021 04:56:37 GMT""}]","2021-03-17"
"2102.05065","Pratyush Anshul","Pratyush Anshul, Anand Narayanan, Sowgat Muzahid, Alexander Beckett,
  Simon L. Morris","Pair Lines of Sight Observations of Multiphase Gas Bearing O VI in a
  Galaxy Environment","20 pages, 12 figures, 5 tables, Accepted for publication in MNRAS",,"10.1093/mnras/stab396",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using $HST$/COS observations of the twin quasar lines of sight Q$0107-025$A
$\&$ Q$0107-025$B, we report on the physical properties, chemical abundances
and transverse sizes of gas in a multiple galaxy environment at $z = 0.399$
across a transverse separation of $520$ kpc. The absorber towards Q$0107-025$B
has $\log N(H I)/cm^{-2} \approx 16.8$ (partial Lyman limit) while the absorber
towards the other sightline has $N(H I) \approx 2$ dex lower. The O VI along
both sightlines have comparable column densities and broad $b$-values, whereas
the low ionization lines are considerably narrower. The low ionization gas is
inconsistent with the O VI when modelled assuming photoionization in a single
phase. Along both the lines-of-sight, O VI and coinciding broad H I are best
explained through collisional ionization in a cooling plasma with solar
metallicity. Ionization models infer $1/10$-th solar metallicity for the pLLS
and solar metallicity for the lower column density absorber along the other
sightline. Within $\pm~250~km~s^{-1}$ and $2$ Mpc of projected distance from
the sightlines 12 galaxies are identified, of which 3 are within $300$ kpc. One
of them is a dwarf galaxy while the other two are intermediate mass systems at
impact parameters of $\rho \sim (1-4)R_{vir}$. The O VI along both
lines-of-sight could be either tracing narrow transition temperature zones at
the interface of low ionization gas and the hot halo of nearest galaxy, or a
more spread-out warm gas bound to the circumgalactic halo/intragroup medium.
This latter scenario leads to a warm gas mass limit of $M \gtrsim 4.5 \times
10^{9}$ M$_\odot$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:20 GMT""}]","2021-02-24"
"2102.05066","Jos\'e Luis Bernal","Jos\'e Luis Bernal, Licia Verde, Raul Jimenez, Marc Kamionkowski,
  David Valcin, Benjamin D. Wandelt","The trouble beyond $H_0$ and the new cosmic triangles","11 pages, 5 figures. Minimal changes, conclusions unchanged, matches
  the published version","Phys. Rev. D 103, 103533 (2021)","10.1103/PhysRevD.103.103533",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The distance ladder using supernovae yields higher values of the Hubble
constant $H_0$ than those inferred from measurements of the cosmic microwave
background (CMB) and galaxy surveys, a discrepancy that has come to be known as
the `Hubble tension'. This has motivated the exploration of extensions to the
standard cosmological model in which higher values of $H_0$ can be obtained
from CMB measurements and galaxy surveys. The trouble, however, goes beyond
$H_0$; such modifications affect other quantities, too. In particular, their
effects on cosmic times are usually neglected. We explore here the implications
that measurements of the age $t_{\rm U}$ of the Universe, such as a recent
inference from the age of the oldest globular clusters, can have for potential
solutions to the $H_0$ tension. The value of $H_0$ inferred from the CMB and
galaxy surveys is related to the sound horizon at CMB decoupling (or at
radiation drag), but it is also related to the matter density and to $t_{\rm
U}$. Given this observation, we show how model-independent measurements may
support or disfavor proposed new-physics solutions to the Hubble tension.
Finally, we argue that cosmological measurements today provide constraints
that, within a given cosmological model, represent an over-constrained system,
offering a powerful diagnostic tool of consistency. We propose the use of
ternary plots to simultaneously visualize independent constraints on key
quantities related to $H_0$ like $t_{\rm U}$, the sound horizon at radiation
drag, and the matter density parameter. We envision that this representation
will help find a solution to the trouble of and beyond $H_0$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:26 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 16:32:17 GMT""}]","2021-05-27"
"2102.05067","Silvia Cascianelli PhD","Silvia Cascianelli, Gabriele Costante, Alessandro Devo, Thomas A.
  Ciarfuglia, Paolo Valigi, Mario L. Fravolini","The Role of the Input in Natural Language Video Description","In IEEE Transactions on Multimedia","IEEE Transactions on Multimedia, 22(1), 271-283 (2019)",,,"cs.CV cs.CL cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural Language Video Description (NLVD) has recently received strong
interest in the Computer Vision, Natural Language Processing (NLP), Multimedia,
and Autonomous Robotics communities. The State-of-the-Art (SotA) approaches
obtained remarkable results when tested on the benchmark datasets. However,
those approaches poorly generalize to new datasets. In addition, none of the
existing works focus on the processing of the input to the NLVD systems, which
is both visual and textual. In this work, it is presented an extensive study
dealing with the role of the visual input, evaluated with respect to the
overall NLP performance. This is achieved performing data augmentation of the
visual component, applying common transformations to model camera distortions,
noise, lighting, and camera positioning, that are typical in real-world
operative scenarios. A t-SNE based analysis is proposed to evaluate the effects
of the considered transformations on the overall visual data distribution. For
this study, it is considered the English subset of Microsoft Research Video
Description (MSVD) dataset, which is used commonly for NLVD. It was observed
that this dataset contains a relevant amount of syntactic and semantic errors.
These errors have been amended manually, and the new version of the dataset
(called MSVD-v2) is used in the experimentation. The MSVD-v2 dataset is
released to help to gain insight into the NLVD problem.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:35 GMT""}]","2021-02-11"
"2102.05068","Chikako Yasui","Chikako Yasui, Naoto Kobayashi, Masao Saito, Natsuko Izumi, Warren
  Skidmore","Low-metallicity Young Clusters in the Outer Galaxy. III. Sh 2-127","Accepted for publication in AJ",,"10.3847/1538-3881/abd331",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  In deep near-infrared imaging of the low-metallicity (${\rm [O/H]}=-0.7$ dex)
H II region Sh 2-127 (S127) with Subaru/MOIRCS, we detected two young clusters
with 413 members (S127A) in a slightly extended H II region and another with
338 members (S127B) in a compact H II region. The limiting magnitude was
$K=21.3$ mag (10$\sigma$), corresponding to a mass detection limit of $\sim$0.2
$M_\odot$. These clusters are an order of magnitude larger than previously
studied young low-metallicity clusters and larger than the majority of solar
neighborhood young clusters. Fits to the K-band luminosity functions indicate
very young cluster ages of 0.5 Myr for S127A and 0.1-0.5 Myr for S127B,
consistent with the large extinction (up to $A_V\simeq20$ mag) from thick
molecular clouds and the presence of a compact H II region and class I source
candidates, and suggest that the initial mass function (IMF) of the
low-metallicity clusters is indistinguishable from typical solar neighborhood
IMFs. Disk fractions of $28\% \pm 3\%$ for S127A and $40\% \pm 4\%$ for S127B
are significantly lower than those of similarly aged solar neighborhood
clusters ($\sim$50$\%$-60$\%$). The disk fraction for S127B is higher than
those of previously studied low-metallicity clusters ($<$30 $\%$), probably due
to S127B's age. This suggests that a large fraction of very young stars in
low-metallicity environments have disks, but the disks are lost on a very short
timescale. These results are consistent with our previous studies of
low-metallicity star-forming regions, suggesting that a solar neighborhood IMF
and low disk fraction are typical characteristics for low-metallicity regions,
regardless of cluster scales.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:37 GMT""}]","2021-03-03"
"2102.05069","David Rubin","David Rubin, Aleksandar Cikota, Greg Aldering, Andy Fruchter, Saul
  Perlmutter, Masao Sako","Going Forward with the Nancy Grace Roman Space Telescope Transient
  Survey: Validation of Precision Forward-Modeling Photometry for Undersampled
  Imaging","Accepted for Publication in PASP",,"10.1088/1538-3873/abf406",,"astro-ph.IM astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Nancy Grace Roman Space Telescope (Roman) is an observatory for both
wide-field observations and coronagraphy that is scheduled for launch in the
mid 2020's. Part of the planned survey is a deep, cadenced field or fields that
enable cosmological measurements with type Ia supernovae (SNe Ia). With a pixel
scale of 0"".11, the Wide Field Instrument will be undersampled, presenting a
difficulty for precisely subtracting the galaxy light underneath the SNe. We
use simulated data to validate the ability of a forward-model code (such codes
are frequently also called ""scene-modeling"" codes) to perform precision
supernova photometry for the Nancy Grace Roman Space Telescope SN survey. Our
simulation includes over 760,000 image cutouts around SNe Ia or host galaxies
(~ 10% of a full-scale survey). To have a realistic 2D distribution of
underlying galaxy light, we use the VELA simulated high-resolution images of
galaxies. We run each set of cutouts through our forward-modeling code which
automatically measures time-dependent SN fluxes. Given our assumed inputs of a
perfect model of the instrument PSFs and calibration, we find biases at the
millimagnitude level from this method in four red filters (Y106, J129, H158,
and F184), easily meeting the 0.5% Roman inter-filter calibration requirement
for a cutting-edge measurement of cosmological parameters using SNe Ia.
Simulated data in the bluer Z087 filter shows larger ~ 2--3 millimagnitude
biases, also meeting this requirement, but with more room for improvement. Our
forward-model code has been released on Zenodo.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:00:44 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 17:47:50 GMT""}]","2021-07-07"
"2102.05070","Nikita Blinov","Nikita Blinov, Matthew J. Dolan, Patrick Draper, Jessie Shelton","Dark Matter Microhalos From Simplified Models","46 pages, 11 figures","Phys. Rev. D 103, 103514 (2021)","10.1103/PhysRevD.103.103514","FERMILAB-PUB-21-015-AE-T","astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce simplified models for enhancements in the matter power spectrum
at small scales and study their implications for dark matter substructure and
gravitational observables. These models capture the salient aspects of a
variety of early universe scenarios that predict enhanced small-scale
structure, such as axion-like particle dark matter, light vector dark matter,
and epochs of early matter domination. We use a model-independent,
semi-analytic treatment to map bumps in the matter power spectrum to
early-forming sub-solar mass dark matter halos and estimate their evolution,
disruption, and contribution to substructure of clusters and galaxies at late
times. We discuss the sensitivity of gravitational observables, including
pulsar timing arrays and caustic microlensing, to both the presence of bumps in
the power spectrum and variations in their basic properties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:01:04 GMT""}]","2021-05-19"
"2102.05071","Margarita Khokhlova","M.A. Khokhlova, M.Yu. Emelin, M.Yu. Ryabikin, and V.V. Strelkov","Polarisation control of quasi-monochromatic XUV produced via resonant
  high harmonic generation",,"Phys. Rev. A 103, 043114 (2021)","10.1103/PhysRevA.103.043114",,"physics.optics physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a numerical study of the resonant high harmonic generation by tin
ions in an elliptically-polarised laser field along with a simple analytical
model revealing the mechanism and main features of this process. We show that
the yield of the resonant harmonics behaves anomalously with the fundamental
field ellipticity, namely the drop of the resonant harmonic intensity with the
fundamental ellipticity is much slower than for high harmonics generated
through the nonresonant mechanism. Moreover, we study the polarisation
properties of high harmonics generated in elliptically-polarised field and show
that the ellipticity of harmonics near the resonance is significantly higher
than for ones far off the resonance. This introduces a prospective way to
create a source of the quasi-monochromatic coherent XUV with controllable
ellipticity potentially up to circular.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:01:25 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 13:08:17 GMT""}]","2021-04-22"
"2102.05072","Gilles Monnoyer de Galland","Gilles Monnoyer de Galland and Thomas Feuillen and Luc Vandendorpe and
  Laurent Jacques","Sparse Factorization-based Detection of Off-the-Grid Moving targets
  using FMCW radars","Accepted to ICASSP2021, Toronto, Canada, 6-11 June 2021",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the application of continuous sparse signal
reconstruction algorithms for the estimation of the ranges and speeds of
multiple moving targets using an FMCW radar. Conventionally, to be
reconstructed, continuous sparse signals are approximated by a discrete
representation. This discretization of the signal's parameter domain leads to
mismatches with the actual signal. While increasing the grid density mitigates
these errors, it dramatically increases the algorithmic complexity of the
reconstruction. To overcome this issue, we propose a fast greedy algorithm for
off-the-grid detection of multiple moving targets. This algorithm extends
existing continuous greedy algorithms to the framework of factorized sparse
representations of the signals. This factorized representation is obtained from
simplifications of the radar signal model which, up to a model mismatch,
strongly reduces the dimensionality of the problem. Monte-Carlo simulations of
a K-band radar system validate the ability of our method to produce more
accurate estimations with less computation time than the on-the-grid methods
and than methods based on non-factorized representations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:01:34 GMT""}]","2021-02-11"
"2102.05073","Vinicius Mikuni","Vinicius Mikuni, Florencia Canelli","Point Cloud Transformers applied to Collider Physics","12 pages, 3 figures","2021 Mach. Learn.: Sci. Technol. 2 035027","10.1088/2632-2153/ac07f6",,"physics.data-an cs.LG hep-ex","http://creativecommons.org/licenses/by/4.0/","  Methods for processing point cloud information have seen a great success in
collider physics applications. One recent breakthrough in machine learning is
the usage of Transformer networks to learn semantic relationships between
sequences in language processing. In this work, we apply a modified Transformer
network called Point Cloud Transformer as a method to incorporate the
advantages of the Transformer architecture to an unordered set of particles
resulting from collision events. To compare the performance with other
strategies, we study jet-tagging applications for highly-boosted particles.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:02:24 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 09:54:43 GMT""}]","2021-07-19"
"2102.05074","Francisco X. Linares Cede\~no","Francisco X. Linares Cede\~no and L. Arturo Ure\~na-L\'opez","One-parametric description for scalar field dark matter potentials","6 pages, 3 figures. Matches published version in Astronomische
  Nachrichten",,"10.1002/asna.202113942",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the cosmological evolution for a scalar field dark matter model, by
considering a parameterization of the evolution equations that allow us to
unify in a single parameter a family of potentials: quadratic (free case),
trigonometric (Axion-like case), and hyperbolic. After exploring the
cosmological dynamics of this model, we perform a statistical analysis to study
the viability of such model in comparison with the standard Cold Dark Matter
model. We found that the free case is preferred over the other scalar field
potentials, but in any case all of them are disfavored by the cosmological
observations with respect to the standard model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:04:08 GMT""}]","2021-03-31"
"2102.05075","Alex Lambert","Alex Lambert, Sanjeel Parekh, Zolt\'an Szab\'o, Florence d'Alch\'e-Buc","Emotion Transfer Using Vector-Valued Infinite Task Learning","17 pages, 10 figures",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Style transfer is a significant problem of machine learning with numerous
successful applications. In this work, we present a novel style transfer
framework building upon infinite task learning and vector-valued reproducing
kernel Hilbert spaces. We instantiate the idea in emotion transfer where the
goal is to transform facial images to different target emotions. The proposed
approach provides a principled way to gain explicit control over the continuous
style space. We demonstrate the efficiency of the technique on popular facial
emotion benchmarks, achieving low reconstruction cost and high emotion
classification accuracy.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:05:56 GMT""}]","2021-02-11"
"2102.05076","Tom Seccull","Tom Seccull, Wesley C. Fraser, Thomas H. Puzia","The Reflectance of Cold Classical Trans-Neptunian Objects in the Nearest
  Infrared","15 pages, 4 figures, accepted to the Planetary Science Journal,
  bibliography now includes book titles in citations to book chapters",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Recent photometric surveys of Trans-Neptunian Objects (TNOs) have revealed
that the cold classical TNOs have distinct z-band color characteristics, and
occupy their own distinct surface class. This suggested the presence of an
absorption band in the reflectance spectra of cold classicals at wavelengths
above 0.8 micron. Here we present reflectance spectra spanning 0.55-1.0 micron
for six TNOs occupying dynamically cold orbits at semimajor axes close to 44
au. Five of our spectra show a clear and broadly consistent reduction in
spectral gradient above 0.8 micron that diverges from their linear red optical
continuum and agrees with their reported photometric colour data. Despite
predictions, we find no evidence that the spectral flattening is caused by an
absorption band centered near 1.0 micron. We predict that the overall
consistent shape of these five spectra is related to the presence of similar
refractory organics on each of their surfaces, and/or their similar physical
surface properties such as porosity or grain size distribution. The observed
consistency of the reflectance spectra of these five targets aligns with
predictions that the cold classicals share a common history in terms of
formation and surface evolution. Our sixth target, which has been ambiguously
classified as either a hot or cold classical at various points in the past, has
a spectrum which remains nearly linear across the full range observed. This
suggests that this TNO is a hot classical interloper in the cold classical
dynamical range, and supports the idea that other such interlopers may be
identifiable by their linear reflectance spectra in the range 0.8-1.0 micron.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:06:23 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 07:38:46 GMT""}]","2021-02-18"
"2102.05077","William Kuszmaul","William Kuszmaul, Qi Qi","The Multiplicative Version of Azuma's Inequality, with an Application to
  Contention Analysis",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Azuma's inequality is a tool for proving concentration bounds on random
variables. The inequality can be thought of as a natural generalization of
additive Chernoff bounds. On the other hand, the analogous generalization of
multiplicative Chernoff bounds has, to our knowledge, never been explicitly
formulated.
  We formulate a multiplicative-error version of Azuma's inequality. We then
show how to apply this new inequality in order to greatly simplify (and
correct) the analysis of contention delays in multithreaded systems managed by
randomized work stealing.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:06:35 GMT""}]","2021-02-11"
"2102.05078","Ryan Creedon","Ryan Creedon, Bernard Deconinck, Olga Trichtchenko","High-Frequency Instabilities of a Boussinesq-Whitham System: A
  Perturbative Approach","22 pages, 10 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We analyze the spectral stability of small-amplitude, periodic,
traveling-wave solutions of a Boussinesq-Whitham system. These solutions are
shown numerically to exhibit high-frequency instabilities when subject to
bounded perturbations on the real line. We use a formal perturbation method to
estimate the asymptotic behavior of these instabilities in the small-amplitude
regime. We compare these asymptotic results with direct numerical computations.
This is the second paper in a series of three that investigates high-frequency
instabilities of Stokes waves.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:09:46 GMT""}]","2021-02-11"
"2102.05079","Gerrit Farren","Gerrit S. Farren, Bruce Partridge, R\""udiger Kneissl, Simone Aiola,
  Rahul Datta, Megan Gralla and Yaqiong Li","Confirming ALMA Calibration using Planck and ACT Observations","26 pages, 4 figures, 6 tables, accepted to ApJS",,"10.3847/1538-4365/ac090d",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We test the accuracy of ALMA flux density calibration by comparing ALMA flux
density measurements of extragalactic sources to measurements made by the
Planck mission; Planck is absolutely calibrated to sub-percent precision using
the dipole signal induced by the satellite's orbit around the solar system
barycenter. Planck observations ended before ALMA began systematic
observations, however, and many of the sources are variable, so we employ
measurements by the Atacama Cosmology Telescope (ACT) to bridge the two epochs.
We compare ACT observations at 93 and $\sim$145 GHz to Planck measurements at
100 and 143 GHz and to ALMA measurements made at 91.5 and 103.5 GHz in Band 3.
For both comparisons, flux density measurements were corrected to account for
the small differences in frequency using the best available spectral index for
each source. We find the ALMA flux density scale (based on observations of
Uranus) is consistent with Planck. All methods used to make the comparison are
consistent with ALMA flux densities in Band 3 averaging 0.99 times those
measured by Planck. One specific test gives ALMA/Planck = $0.996 \pm 0.024.$ We
also test the absolute calibration of both ACT at 93 and $\sim$145 GHz and the
South Pole Telescope (SPT) at 97.43, 152.9 and 215.8 GHz, again with reference
to Planck measurements at 100, 143 and 217 GHz, as well as the internal
consistency of measurements of compact sources made by all three instruments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:11:19 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 10:45:05 GMT""}]","2022-01-27"
"2102.05080","Vikram Singh","Vikram Singh, Steven Frankel, Jan Nordstr\""om","Impact of wall modeling on kinetic energy stability for the compressible
  Navier-Stokes equations","Accepted in Computers and Fluids",,"10.1016/j.compfluid.2021.104870",,"physics.flu-dyn cs.NA math.NA physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Affordable, high order simulations of turbulent flows on unstructured grids
for very high Reynolds number flows require wall models for efficiency.
However, different wall models have different accuracy and stability
properties. Here, we develop a kinetic energy stability estimate to investigate
stability of wall model boundary conditions. Using this norm, two wall models
are studied, a popular equilibrium stress wall model, which is found to be
unstable and the dynamic slip wall model which is found to be stable. These
results are extended to the discrete case using the Summation by parts (SBP)
property of the discontinuous Galerkin method. Numerical tests show that while
the equilibrium stress wall model is accurate but unstable, the dynamic slip
wall model is inaccurate but stable.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:15:40 GMT""}]","2021-05-03"
"2102.05081","Simone Campanoni","Angelo Matni and Enrico Armenio Deiana and Yian Su and Lukas Gross and
  Souradip Ghosh and Sotiris Apostolakis and Ziyang Xu and Zujun Tan and Ishita
  Chaturvedi and David I. August and Simone Campanoni","NOELLE Offers Empowering LLVM Extensions",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Modern and emerging architectures demand increasingly complex compiler
analyses and transformations. As the emphasis on compiler infrastructure moves
beyond support for peephole optimizations and the extraction of
instruction-level parallelism, they should support custom tools designed to
meet these demands with higher-level analysis-powered abstractions of wider
program scope. This paper introduces NOELLE, a robust open-source
domain-independent compilation layer built upon LLVM providing this support.
NOELLE is modular and demand-driven, making it easy-to-extend and adaptable to
custom-tool-specific needs without unduly wasting compile time and memory. This
paper shows the power of NOELLE by presenting a diverse set of ten custom tools
built upon it, with a 33.2% to 99.2% reduction in code size (LoC) compared to
their counterparts without NOELLE.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:16:41 GMT""}]","2021-02-11"
"2102.05082","A. Tuan Nguyen","A. Tuan Nguyen, Toan Tran, Yarin Gal, At{\i}l{\i}m G\""une\c{s} Baydin","Domain Invariant Representation Learning with Domain Density
  Transformations","NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalization refers to the problem where we aim to train a model on
data from a set of source domains so that the model can generalize to unseen
target domains. Naively training a model on the aggregate set of data (pooled
from all source domains) has been shown to perform suboptimally, since the
information learned by that model might be domain-specific and generalize
imperfectly to target domains. To tackle this problem, a predominant approach
is to find and learn some domain-invariant information in order to use it for
the prediction task. In this paper, we propose a theoretically grounded method
to learn a domain-invariant representation by enforcing the representation
network to be invariant under all transformation functions among domains. We
also show how to use generative adversarial networks to learn such domain
transformations to implement our method in practice. We demonstrate the
effectiveness of our method on several widely used datasets for the domain
generalization problem, on all of which we achieve competitive results with
state-of-the-art models.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:25:32 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 14:05:09 GMT""},{""version"":""v3"",""created"":""Tue, 15 Feb 2022 16:47:59 GMT""}]","2022-02-16"
"2102.05083","Ernest Ma","Ernest Ma (UC Riverside)","Dirac Neutrino Mass Matrix and its Link to Freeze-in Dark Matter","9 pages, no figure",,"10.1016/j.physletb.2021.136162","UCRHEP-T609 (Feb 2021)","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a mechanism which allows naturally small Dirac neutrino masses and its
linkage to a dark gauge $U(1)_D$ symmetry, a realistic Dirac neutrino mass
matrix is derived from $S_3$. The dark sector naturally contains a fermion
singlet having a small seesaw mass. It is thus a good candidate for freeze-in
dark matter from the decay of the $U(1)_D$ Higgs boson.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:28:36 GMT""}]","2021-03-17"
"2102.05084","Andrey Kotov","V.V. Braguta, A.Yu. Kotov, D.D. Kuznedelev, A.A. Roenko","Influence of relativistic rotation on the confinement/deconfinement
  transition in gluodynamics","18 pages, 14 figures, 2 tables. Version accepted for publication in
  PRD","Phys. Rev. D 103, 094515 (2021)","10.1103/PhysRevD.103.094515",,"hep-lat hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider the influence of relativistic rotation on the
confinement/deconfinement transition in gluodynamics within lattice simulation.
We perform the simulation in the reference frame which rotates with the system
under investigation, where rotation is reduced to external gravitational field.
To study the confinement/deconfinement transition the Polyakov loop and its
susceptibility are calculated for various lattice parameters and the values of
angular velocities which are characteristic for heavy-ion collision
experiments. Different types of boundary conditions (open, periodic, Dirichlet)
are imposed in directions, orthogonal to rotation axis. Our data for the
critical temperature are well described by a simple quadratic function
$T_c(\Omega)/T_c(0) = 1 + C_2 \Omega^2$ with $C_2>0$ for all boundary
conditions and all lattice parameters used in the simulations. From this we
conclude that the critical temperature of the confinement/deconfinement
transition in gluodynamics increases with increasing angular velocity. This
conclusion does not depend on the boundary conditions used in our study and we
believe that this is universal property of gluodynamics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:28:37 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 22:24:46 GMT""}]","2021-05-26"
"2102.05085","Andrew Smart","Atoosa Kasirzadeh, Andrew Smart","The Use and Misuse of Counterfactuals in Ethical Machine Learning","9 pages, 1 table, 1 figure",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The use of counterfactuals for considerations of algorithmic fairness and
explainability is gaining prominence within the machine learning community and
industry. This paper argues for more caution with the use of counterfactuals
when the facts to be considered are social categories such as race or gender.
We review a broad body of papers from philosophy and social sciences on social
ontology and the semantics of counterfactuals, and we conclude that the
counterfactual approach in machine learning fairness and social explainability
can require an incoherent theory of what social categories are. Our findings
suggest that most often the social categories may not admit counterfactual
manipulation, and hence may not appropriately satisfy the demands for
evaluating the truth or falsity of counterfactuals. This is important because
the widespread use of counterfactuals in machine learning can lead to
misleading results when applied in high-stakes domains. Accordingly, we argue
that even though counterfactuals play an essential part in some causal
inferences, their use for questions of algorithmic fairness and social
explanations can create more problems than they resolve. Our positive result is
a set of tenets about using counterfactuals for fairness and explanations in
machine learning.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:28:41 GMT""}]","2021-02-11"
"2102.05086","Daniel Sobral Blanco","Daniel Sobral-Blanco and Camille Bonvin","Measuring anisotropic stress with relativistic effects","6 pages, no figures. V2 is the published version","Phys. Rev. D 104, 063516 (2021)","10.1103/PhysRevD.104.063516",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  One of the main goal of large-scale structure surveys is to test the
consistency of General Relativity at cosmological scales. In the $\Lambda$CDM
model of cosmology, the relations between the fields describing the geometry
and the content of our Universe are uniquely determined. In particular, the two
gravitational potentials -- that describe the spatial and temporal fluctuations
in the geometry -- are equal. Whereas large classes of dark energy models
preserve this equality, theories of modified gravity generally create a
difference between the potentials, known as anisotropic stress. Even though
measuring this anisotropic stress is one of the key goals of large-scale
structure surveys, there are currently no methods able to measure it directly.
Current methods all rely on measurements of galaxy peculiar velocities (through
redshift-space distortions), from which the time component of the metric is
inferred, assuming that dark matter follows geodesics. If this is not the case,
all the proposed tests fail to measure the anisotropic stress. In this letter,
we propose a novel test which directly measures anisotropic stress, without
relying on any assumption about the unknown dark matter. Our method uses
relativistic effects in the galaxy number counts to provide a direct
measurement of the time component of the metric. By comparing this with lensing
observations our test provides a direct measurement of the anisotropic stress.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:30:30 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 11:37:56 GMT""}]","2021-11-02"
"2102.05087","Abigail Frost","A. J. Frost, R. D. Oudmaijer, W. J. de Wit, S. L. Lumsden","Unveiling the traits of massive young stellar objects through a
  multi-scale survey",,"A&A 648, A62 (2021)","10.1051/0004-6361/202039748",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rarity and deeply embedded nature of stars with masses larger than 8
solar masses has limited our understanding of their formation. Previous work
has shown that complementing spectral energy distributions with interferometric
and imaging data can probe the circumstellar environments of massive young
stellar objects (MYSOs) well. However, complex studies of single objects often
use different approaches in their analysis. Therefore the results of these
studies cannot be directly compared. This work aims to obtain the physical
characteristics of a sample of MYSOs at ~0.01"" scales, at 0.1"" scales, and as a
whole, which enables us to compare the characteristics of the sources. We apply
the same multi-scale method and analysis to a sample of MYSOs. High-resolution
interferometric data, near-diffraction-limited imaging data, and a
multi-wavelength spectral energy distribution are combined. By fitting
simulated observables derived from 2.5D radiative transfer models of
disk-outflow-envelope systems to our observations, the properties of the MYSOs
are constrained. We find that the observables of all the MYSOs can be
reproduced by models with disk-outflow-envelope geometries, analogous to the
Class I geometry associated with low-mass protostars. The characteristics of
the envelopes and the cavities within them are very similar across our sample.
On the other hand, the disks seem to differ between the objects, in particular
with regards to what we interpret as evidence of complex structures and inner
holes. This is comparable to the morphologies observed for low-mass young
stellar objects. A strong correlation is found between the luminosity of the
central MYSO and the size of the transition disk-like inner hole for the MYSOs,
implying that photoevaporation or the presence of binary companions may be the
cause.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:31:06 GMT""}]","2021-04-14"
"2102.05088","Mostafa Bagheri","Mostafa Bagheri, Mohammad Mohammadi Aghdam, Meitham Amereh","Coupled Torsional and Transverse Vibration Analysis of Panels Partially
  Supported by Elastic Beam",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  This study presents torsional and transverse vibration analysis of a solar
panel including a rectangular thin plate locally supported by an elastic beam.
The plate is totally free in all boundaries, except for the local part attached
to the beam. The response of the system, which is subjected to a combination of
torsional and transverse vibration, identifies with a couple of PDEs developed
by the Euler-Bernoulli assumption and classical plate theory. To calculate the
system's natural frequencies, the domain of the solution is discretized by
zeroes of the Chebyshev polynomials to apply the Modified Generalized
Differential Quadrature method (MGDQ). Furthermore, governing equations along
with continuity and boundary conditions are discretized. After obtaining
solutions to the eigenvalue problem, several studies are investigated to
validate the accuracy of the proposed method. As can be concluded from the
tables, MGDQ improves the accuracy of results obtained by GDQ. Results for
various case studies reveal that MGDQ is properly devised for the vibration
analysis of systems with local boundary and continuity conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:37:13 GMT""}]","2021-02-11"
"2102.05089","Mauricio Souza","Rodrigo Henrique Barbosa Monteiro, Maur\'icio Ronny de Almeida Souza,
  Sandro Ronaldo Bezerra Oliveira, Carlos dos Santos Portela and Cesar Elias de
  Cristo Lobato","The Diversity of Gamification Evaluation in the Software Engineering
  Education and Industry: Trends, Comparisons and Gaps","43rd International Conference on Software Engineering (ICSE 2021),
  JSEET - Joint Track on Software Engineering Education and Training",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gamification has been used to motivate and engage participants in software
engineering education and practice activities. There is a significant demand
for empirical studies for the understanding of the impacts and efficacy of
gamification. However, the lack of standard procedures and models for the
evaluation of gamification is a challenge for the design, comparison, and
report of results related to the assessment of gamification approaches and its
effects. The goal of this study is to identify models and strategies for the
evaluation of gamification reported in the literature. To achieve this goal, we
conducted a systematic mapping study to investigate strategies for the
evaluation of gamification in the context of software engineering. We selected
100 primary studies on gamification in software engineering (from 2011 to
2020). We categorized the studies regarding the presence of evaluation
procedures or models for the evaluation of gamification, the purpose of the
evaluation, the criteria used, the type of data, instruments, and procedures
for data analysis. Our results show that 64 studies report procedures for the
evaluation of gamification. However, only three studies actually propose
evaluation models for gamification. We observed that the evaluation of
gamification focuses on two aspects: the evaluation of the gamification
strategy itself, related to the user experience and perceptions; and the
evaluation of the outcomes and effects of gamification on its users and
context. The most recurring criteria for the evaluation are 'engagement',
'motivation', 'satisfaction', and 'performance'. Finally, the evaluation of
gamification requires a mix of subjective and objective inputs, and qualitative
and quantitative data analysis approaches. Depending of the focus of the
evaluation (the strategy or the outcomes), there is a predominance of a type of
data and analysis.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:39:07 GMT""}]","2021-02-11"
"2102.05090","Akanda Wahid -Ul- Ashraf","Marcin Budka, Akanda Wahid Ul Ashraf, Scott Neville, Alun Mackrill,
  Matthew Bennett","Deep Multilabel CNN for Forensic Footwear Impression Descriptor
  Identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years deep neural networks have become the workhorse of computer
vision. In this paper, we employ a deep learning approach to classify footwear
impression's features known as \emph{descriptors} for forensic use cases.
Within this process, we develop and evaluate an effective technique for feeding
downsampled greyscale impressions to a neural network pre-trained on data from
a different domain. Our approach relies on learnable preprocessing layer paired
with multiple interpolation methods used in parallel. We empirically show that
this technique outperforms using a single type of interpolated image without
learnable preprocessing, and can help to avoid the computational penalty
related to using high resolution inputs, by making more efficient use of the
low resolution inputs. We also investigate the effect of preserving the aspect
ratio of the inputs, which leads to considerable boost in accuracy without
increasing the computational budget with respect to squished rectangular
images. Finally, we formulate a set of best practices for transfer learning
with greyscale inputs, potentially widely applicable in computer vision tasks
ranging from footwear impression classification to medical imaging.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:39:28 GMT""}]","2021-02-11"
"2102.05091","Di Che","Di Che, Junho Cho, Xi Chen","Does Probabilistic Constellation Shaping Benefit IM-DD Systems without
  Optical Amplifiers?",,,"10.1109/JLT.2021.3083530",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Probabilistic constellation shaping (PCS) has been widely applied to
amplified coherent optical transmissions owing to its shaping gain over the
uniform signaling and fine-grained rate adaptation to the underlying fiber
channel condition. These merits stimulate the study of applying PCS to
short-reach applications dominated by intensity modulation (IM) direct
detection (DD) systems. As commercial IM-DD systems typically do not employ
optical amplification to save the cost and power consumption, they are no
longer subject to an average power constraint (APC) but a peak power constraint
(PPC), which poses unique challenges to take full advantages of PCS. This paper
provides a comprehensive investigation of PCS in IM-DD systems without optical
amplifiers. In particular, we reveal that if the transmitter enhances the
peak-to-average power ratio of the signal, a PPC system can be partially or
even fully converted to an APC system in which the classical PCS offers its
merits. The findings are verified through an IM-DD experiment using 4- and
8-ary pulse amplitude modulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:39:36 GMT""}]","2021-09-08"
"2102.05092","Zhaoyi Xu","Konstantinos Diamantaras, Zhaoyi Xu, Athina Petropulu","Sparse Antenna Array Design for MIMO Radar Using Softmax Selection","arXiv admin note: text overlap with arXiv:2101.06837",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MIMO transmit arrays allow for flexible design of the transmit beampattern.
However, the large number of elements required to achieve certain performance
using uniform linear arrays (ULA) maybe be too costly. This motivated the need
for thinned arrays by appropriately selecting a small number of elements so
that the full array beampattern is preserved. In this paper, we propose
Learn-to-Select (L2S), a novel machine learning model for selecting antennas
from a dense ULA employing a combination of multiple Softmax layers constrained
by an orthogonalization criterion. The proposed approach can be efficiently
scaled for larger problems as it avoids the combinatorial explosion of the
selection problem. It also offers a flexible array design framework as the
selection problem can be easily formulated for any metric.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:43:41 GMT""}]","2021-02-11"
"2102.05093","David Ambrose","David M. Ambrose and Anna L. Mazzucato","Global solutions of the two-dimensional Kuramoto-Sivashinsky equation
  with a linearly growing mode in each direction","Fixed a minor error and typos, and simplified the presentation",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In two spatial dimensions, there are very few global existence results for
the Kuramoto-Sivashinsky equation. The majority of the few results in the
literature are strongly anisotropic, i.e. are results of thin-domain type. In
the spatially periodic case, the dynamics of the Kuramoto-Sivashinsky equation
are in part governed by the size of the domain, as this determines how many
linearly growing Fourier modes are present. The strongly anisotropic results
allow linearly growing Fourier modes in only one of the spatial directions. We
provide here the first proof of global solutions for the two-dimensional
Kuramoto-Sivashinsky equation with a linearly growing mode in both spatial
directions. We develop a new method to this end, categorizing wavenumbers as
low (linearly growing modes), intermediate (linearly decaying modes which serve
as energy sinks for the low modes), and high (strongly linearly decaying
modes). The low and intermediate modes are controlled by means of a Lyapunov
function, while the high modes are controlled with operator estimates in
function spaces based on the Wiener algebra.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:46:00 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 14:34:16 GMT""}]","2021-09-03"
"2102.05094","Louis H. Y. Chen","Louis H. Y. Chen, Arturo Jaramillo and Xiaochuan Yang","A probabilistic approach to the Erd\""os-Kac theorem for additive
  functions",,,,,"math.PR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new perspective of assessing the rates of convergence to the
Gaussian and Poisson distributions in the Erd\""os-Kac theorem for additive
arithmetic functions $\psi$ of a random integer $J_n$ uniformly distributed
over $\{1,...,n\}$. Our approach is probabilistic, working directly on spaces
of random variables without any use of Fourier analytic methods, and our $\psi$
is more general than those considered in the literature. Our main results are
(i) bounds on the Kolmogorov distance and Wasserstein distance between the
distribution of the normalized $\psi(J_n)$ and the standard Gaussian
distribution, and (ii) bounds on the Kolmogorov distance and total variation
distance between the distribution of $\psi(J_n)$ and a Poisson distribution
under mild additional assumptions on $\psi$. Our results generalize the
existing ones in the literature.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:48:16 GMT""}]","2021-02-11"
"2102.05095","Gedas Bertasius","Gedas Bertasius, Heng Wang, Lorenzo Torresani","Is Space-Time Attention All You Need for Video Understanding?","Accepted to ICML 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a convolution-free approach to video classification built
exclusively on self-attention over space and time. Our method, named
""TimeSformer,"" adapts the standard Transformer architecture to video by
enabling spatiotemporal feature learning directly from a sequence of
frame-level patches. Our experimental study compares different self-attention
schemes and suggests that ""divided attention,"" where temporal attention and
spatial attention are separately applied within each block, leads to the best
video classification accuracy among the design choices considered. Despite the
radically new design, TimeSformer achieves state-of-the-art results on several
action recognition benchmarks, including the best reported accuracy on
Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks,
our model is faster to train, it can achieve dramatically higher test
efficiency (at a small drop in accuracy), and it can also be applied to much
longer video clips (over one minute long). Code and models are available at:
https://github.com/facebookresearch/TimeSformer.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:49:33 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 14:52:06 GMT""},{""version"":""v3"",""created"":""Fri, 16 Apr 2021 14:41:50 GMT""},{""version"":""v4"",""created"":""Wed, 9 Jun 2021 14:48:13 GMT""}]","2021-06-10"
"2102.05096","Jay Nandy","Jay Nandy and Sudipan Saha and Wynne Hsu and Mong Li Lee and Xiao
  Xiang Zhu","Towards Bridging the gap between Empirical and Certified Robustness
  against Adversarial Examples","An abridged version of this work has been presented at ICLR 2021
  Workshop on Security and Safety in Machine Learning Systems:
  https://aisecure-workshop.github.io/aml-iclr2021/papers/2.pdf",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current state-of-the-art defense methods against adversarial examples
typically focus on improving either empirical or certified robustness. Among
them, adversarially trained (AT) models produce empirical state-of-the-art
defense against adversarial examples without providing any robustness
guarantees for large classifiers or higher-dimensional inputs. In contrast,
existing randomized smoothing based models achieve state-of-the-art certified
robustness while significantly degrading the empirical robustness against
adversarial examples. In this paper, we propose a novel method, called
\emph{Certification through Adaptation}, that transforms an AT model into a
randomized smoothing classifier during inference to provide certified
robustness for $\ell_2$ norm without affecting their empirical robustness
against adversarial attacks. We also propose \emph{Auto-Noise} technique that
efficiently approximates the appropriate noise levels to flexibly certify the
test examples using randomized smoothing technique. Our proposed
\emph{Certification through Adaptation} with \emph{Auto-Noise} technique
achieves an \textit{average certified radius (ACR) scores} up to $1.102$ and
$1.148$ respectively for CIFAR-10 and ImageNet datasets using AT models without
affecting their empirical robustness or benign accuracy. Therefore, our paper
is a step towards bridging the gap between the empirical and certified
robustness against adversarial examples by achieving both using the same
classifier.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:51:56 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 08:16:34 GMT""},{""version"":""v3"",""created"":""Sat, 30 Jul 2022 06:41:56 GMT""}]","2022-08-02"
"2102.05097","McKinley Brumback","McKinley C. Brumback, Ryan C. Hickox, Felix S. F\""urst, Katja
  Pottschmidt, John A. Tomsick, J\""orn Wilms, R\""udiger Staubert, Saeqa Vrtilek","A broad-band X-ray view of the precessing accretion disk and pre-eclipse
  dip in the pulsar Her X-1 with NuSTAR and XMM-Newton","23 pages, 13 figures. Accepted to ApJ",,"10.3847/1538-4357/abe122",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a broad-band X-ray timing study of the variations in pulse
behavior with superorbital cycle in the low-mass X-ray binary Her X-1. This
source shows a 35-day superorbital modulation in X-ray flux that is likely
caused by occultation by a warped, precessing accretion disk. Our data set
consists of four joint XMM-Newton and NuSTAR observations of Her X-1 which
sample a complete superorbital cycle. We focus our analysis on the first and
fourth observations, which occur during the bright ""main-on"" phase, because
these observations have strongly detected pulsations. We added an archival
XMM-Newton observation during the ""short-on"" phase of the superorbital cycle
since our observations at that phase are lower in signal to noise. We find that
the energy-resolved pulse profiles show the same shape at similar superorbital
phases and the profiles are consistent with expectations from a precessing
disk. We demonstrate that a simple precessing accretion disk model is
sufficient to reproduce the observed pulse profiles. The results of this model
suggest that the similarities in the observed pulse profiles are due to
reprocessing by a precessing disk that has returned to its original precession
phase. We determine that the broad-band spectrum is well fit by an absorbed
power law with a soft blackbody component, and show that the spectral continuum
also exhibits dependence on the superorbital cycle. We also present a brief
analysis of the energy resolved light curves of a pre-eclipse dip, which shows
soft X-ray absorption and hard X-ray variability during the dip.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:52:27 GMT""}]","2021-03-24"
"2102.05098","Fr\'ed\'eric Bouchard","Fr\'ed\'eric Bouchard, Duncan England, Philip J. Bustard, Kate L.
  Fenwick, Ebrahim Karimi, Khabat Heshami, Benjamin Sussman","Achieving ultimate noise tolerance in quantum communication","11 pages, 9 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At the fundamental level, quantum communication is ultimately limited by
noise. For instance, quantum signals cannot be amplified without the
introduction of noise in the amplified states. Furthermore, photon loss reduces
the signal-to-noise ratio, accentuating the effect of noise. Thus, most of the
efforts in quantum communications have been directed towards overcoming noise
to achieve longer communication distances, larger secret key rates, or to
operate in noisier environmental conditions. Here, we propose and
experimentally demonstrate a platform for quantum communication based on
ultrafast optical techniques. In particular, our scheme enables the
experimental realization of high-rates and quantum signal filtering approaching
a single spectro-temporal mode, resulting in a dramatic reduction in channel
noise. By experimentally realizing a 1-ps optically induced temporal gate, we
show that ultrafast time filtering can result in an improvement in noise
tolerance by a factor of up to 1200 compared to a 2-ns electronic filter
enabling daytime quantum key distribution or quantum communication in bright
fibers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:55:14 GMT""}]","2021-02-11"
"2102.05099","Kimberly Hsieh","Kimberly Hsieh, Vidya Kochat, Tathagata Biswas, Chandra Sekhar Tiwary,
  Abhishek Mishra, Gopalakrishnan Ramalingam, Aditya Jayaraman, Kamanio
  Chattopadhyay, Srinivasan Raghavan, Manish Jain, and Arindam Ghosh","Spontaneous time reversal symmetry breaking at individual grain
  boundaries in graphene",,"Phys. Rev. Lett. 126, 206803 (2021)","10.1103/PhysRevLett.126.206803",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphene grain boundaries have attracted interest for their ability to host
nearly dispersionless electronic bands and magnetic instabilities. Here, we
employ quantum transport and universal conductance fluctuations (UCF)
measurements to experimentally demonstrate a spontaneous breaking of time
reversal symmetry (TRS) across individual GBs of chemical vapour deposited
graphene. While quantum transport across the GBs indicate
spin-scattering-induced dephasing, and hence formation of local magnetic
moments, below $T\lesssim 4$ K, we observe complete lifting of TRS at high
carrier densities ($n \gtrsim 5\times 10^{12}$cm$^{-2}$) and low temperature
($T\lesssim 2$ K). An unprecedented thirty times reduction in the UCF magnitude
with increasing doping density further supports the possibility of an emergent
frozen magnetic state at the GBs. Our experimental results suggest that
realistic GBs of graphene can be a promising resource for new electronic phases
and spin-based applications.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:56:21 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 19:12:21 GMT""}]","2021-05-26"
"2102.05100","Franz-Georg Wieland","Franz-Georg Wieland, Adrian L. Hauber, Marcus Rosenblatt, Christian
  T\""onsing, Jens Timmer","On structural and practical identifiability",,,"10.1016/j.coisb.2021.03.005",,"stat.ME physics.data-an q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  We discuss issues of structural and practical identifiability of partially
observed differential equations which are often applied in systems biology. The
development of mathematical methods to investigate structural
non-identifiability has a long tradition. Computationally efficient methods to
detect and cure it have been developed recently. Practical non-identifiability
on the other hand has not been investigated at the same conceptually clear
level. We argue that practical identifiability is more challenging than
structural identifiability when it comes to modelling experimental data. We
discuss that the classical approach based on the Fisher information matrix has
severe shortcomings. As an alternative, we propose using the profile
likelihood, which is a powerful approach to detect and resolve practical
non-identifiability.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:58:29 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 10:29:09 GMT""}]","2021-04-20"
"2102.05101","Pete Riley","Pete Riley, Roberto Lionello, Ronald M. Caplan, Cooper Downs, Jon A.
  Linker, Samuel T. Badman and Michael L. Stevens","Using Parker Solar Probe observations during the first four perihelia to
  constrain global magnetohydrodynamic models",,"A&A 650, A19 (2021)","10.1051/0004-6361/202039815",,"physics.space-ph astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Parker Solar Probe (PSP) is providing an unprecedented view of the Sun's
corona as it progressively dips closer into the solar atmosphere with each
solar encounter. Each set of observations provides a unique opportunity to test
and constrain global models of the solar corona and inner heliosphere and, in
turn, use the model results to provide a global context for interpreting such
observations. In this study, we develop a set of global magnetohydrodynamic
(MHD) model solutions of varying degrees of sophistication for PSP's first four
encounters and compare the results with in situ measurements from PSP,
Stereo-A, and Earth-based spacecraft, with the objective of assessing which
models perform better or worse. All models were primarily driven by the
observed photospheric magnetic field using data from Solar Dynamics
Observatory's Helioseismic and Magnetic Imager (HMI) instrument. Overall, we
find that there are substantial differences between the model results, both in
terms of the large-scale structure of the inner heliosphere during these time
periods, as well as in the inferred time-series at various spacecraft. The
""thermodynamic"" model, which represents the ""middle ground"", in terms of model
complexity, appears to reproduce the observations most closely for all four
encounters. Our results also contradict an earlier study that had hinted that
the open flux problem may disappear nearer the Sun. Instead, our results
suggest that this ""missing"" solar flux is still missing even at 26.9 Rs, and
thus it cannot be explained by interplanetary processes. Finally, the model
results were also used to provide a global context for interpreting the
localized in situ measurements.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 19:58:49 GMT""}]","2021-06-02"
"2102.05102","Michael McGuigan","Josh Apanavicius, Yuan Feng, Yasmin Flores, Mohammad Hassan, Michael
  McGuigan","Morse Potential on a Quantum Computer for Molecules and Supersymmetric
  Quantum Mechanics",,,,,"quant-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we discuss the Morse potential on a quantum computer. The Morse
potential is useful to describe diatomic molecules and has a finite number of
bound states which can be measured through spectroscopy. It is also a example
of an exactly soluble potential using supersymmetric quantum mechanics. Using
the the supersymmetric quantum mechanics formalism one can derive a heirachy of
Hamiltonians such that the ground state of the next rung on the heirarchy yeids
the first excited state of the hamiltonian below it. Using this method one can
determine all the states of the Morse potential by calculating all the ground
states of the sequence of Hamiltonians in the heirarchy. We use the IBM QISKit
software together with the Variational Quantum Eiegensolver (VQE) algorithm to
calculate the ground state and first excited state energy of the Morse
potential and find agreement with the exact expression for the bound state
energies of the Morse Potential. We analyze different optimizers to study the
numerical effect on the calculations. Finally we perform quantum computations
for diatomic and triatomic molecules to illustrate the application of these
techniques on near term quantum computers and find excellent agreement with
experimental data.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:00:06 GMT""}]","2021-02-11"
"2102.05103","Thomas Maullin-Sapey","Thomas Maullin-Sapey, Thomas E. Nichols","Fisher Scoring for crossed factor Linear Mixed Models","For supplementary material see
  https://www.overleaf.com/read/bvscgqrvqnjh . For code and notebooks, see
  https://github.com/TomMaullin/LMMPaper",,,,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  The analysis of longitudinal, heterogeneous or unbalanced clustered data is
of primary importance to a wide range of applications. The Linear Mixed Model
(LMM) is a popular and flexible extension of the linear model specifically
designed for such purposes. Historically, a large proportion of material
published on the LMM concerns the application of popular numerical optimization
algorithms, such as Newton-Raphson, Fisher Scoring and Expectation Maximization
to single-factor LMMs (i.e. LMMs that only contain one ""factor"" by which
observations are grouped). However, in recent years, the focus of the LMM
literature has moved towards the development of estimation and inference
methods for more complex, multi-factored designs. In this paper, we present and
derive new expressions for the extension of an algorithm classically used for
single-factor LMM parameter estimation, Fisher Scoring, to multiple,
crossed-factor designs. Through simulation and real data examples, we compare
five variants of the Fisher Scoring algorithm with one another, as well as
against a baseline established by the R package lmer, and find evidence of
correctness and strong computational efficiency for four of the five proposed
approaches. Additionally, we provide a new method for LMM Satterthwaite degrees
of freedom estimation based on analytical results, which does not require
iterative gradient estimation. Via simulation, we find that this approach
produces estimates with both lower bias and lower variance than the existing
methods.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:00:11 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 20:35:01 GMT""}]","2021-02-16"
"2102.05104","Sahar Abdelnabi","Sahar Abdelnabi and Mario Fritz","""What's in the box?!"": Deflecting Adversarial Attacks by Randomly
  Deploying Adversarially-Disjoint Models",,,,,"cs.LG cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning models are now widely deployed in real-world applications.
However, the existence of adversarial examples has been long considered a real
threat to such models. While numerous defenses aiming to improve the robustness
have been proposed, many have been shown ineffective. As these vulnerabilities
are still nowhere near being eliminated, we propose an alternative
deployment-based defense paradigm that goes beyond the traditional white-box
and black-box threat models. Instead of training a single partially-robust
model, one could train a set of same-functionality, yet, adversarially-disjoint
models with minimal in-between attack transferability. These models could then
be randomly and individually deployed, such that accessing one of them
minimally affects the others. Our experiments on CIFAR-10 and a wide range of
attacks show that we achieve a significantly lower attack transferability
across our disjoint models compared to a baseline of ensemble diversity. In
addition, compared to an adversarially trained set, we achieve a higher average
robust accuracy while maintaining the accuracy of clean examples.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:07:13 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 13:53:52 GMT""}]","2021-03-10"
"2102.05105","Angel Villar-Corrales","Angel Villar-Corrales, Franziska Schirrmacher and Christian Riess","Deep learning architectural designs for super-resolution of noisy images",,,,,"cs.CV cs.MM eess.IV","http://creativecommons.org/licenses/by/4.0/","  Recent advances in deep learning have led to significant improvements in
single image super-resolution (SR) research. However, due to the amplification
of noise during the upsampling steps, state-of-the-art methods often fail at
reconstructing high-resolution images from noisy versions of their
low-resolution counterparts. However, this is especially important for images
from unknown cameras with unseen types of image degradation. In this work, we
propose to jointly perform denoising and super-resolution. To this end, we
investigate two architectural designs: ""in-network"" combines both tasks at
feature level, while ""pre-network"" first performs denoising and then
super-resolution. Our experiments show that both variants have specific
advantages: The in-network design obtains the strongest results when the type
of image corruption is aligned in the training and testing dataset, for any
choice of denoiser. The pre-network design exhibits superior performance on
unseen types of image corruption, which is a pathological failure case of
existing super-resolution models. We hope that these findings help to enable
super-resolution also in less constrained scenarios where source camera or
imaging conditions are not well controlled. Source code and pretrained models
are available at https://github.com/
angelvillar96/super-resolution-noisy-images.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:09:42 GMT""}]","2021-02-11"
"2102.05106","Guillaume Baffou","Guillaume Baffou","Quantitative phase microscopy using quadriwave lateral shearing
  interferometry (QLSI): principle, terminology, algorithm and grating shadow
  description","12 figures. 15 pages","J. Phys. D.: Appl. Phys. 54, 294002 (2021)","10.1088/1361-6463/abfbf9",,"physics.optics physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quadriwave lateral shearing interferometry (QLSI) is a quantitative phase
imaging technique based on the use of a diffraction grating placed in front of
a camera. This grating creates a wire-mesh-like image, called an interferogram,
that is postprocessed to retrieve both the intensity and phase profiles of an
incoming light beam. Invented in the 90s, QLSI has been used in numerous
applications, e.g., laser beam characterization, lens metrology, topography
measurements, adaptive optics, or gas jet metrology. More recently, the
technique has been implemented on optical microscopes to characterize micro and
nano-objects for bioimaging and nanophotonics applications. However, not much
effort has been placed on disseminating this powerful technology so far, while
it is yet a particularly simple technique. In this article, we intend to
popularize this technique by describing all its facets in the framework of
optical microscopy, namely the working principle, its implementation on a
microscope and the theory of image formation, using simple pictures. Also, we
provide and comment an algorithm of interferogram processing, written in
Matlab. Then, following the new extension of the technique for microscopy and
nanophotonics applications, and the deviation from what the technique was
initially invented for, we propose to revisit the description of the technique,
in particular by discussing the terminology, insisting more on a grating-shadow
description rather than a quadriwave process, and proposing an alternative
appellation, namely ""grating shadow phase microscopy"" or ""grating-assisted
phase imaging"".
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:09:51 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 16:10:26 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 05:33:06 GMT""},{""version"":""v4"",""created"":""Sat, 15 May 2021 04:54:34 GMT""},{""version"":""v5"",""created"":""Sun, 13 Mar 2022 17:11:23 GMT""}]","2022-03-15"
"2102.05107","Jonathan Weyn","Jonathan A. Weyn, Dale R. Durran, Rich Caruana, Nathaniel
  Cresswell-Clay","Sub-seasonal forecasting with a large ensemble of deep-learning weather
  prediction models","Submitted to Journal of Advances in Modeling Earth Systems","Sub-Seasonal Forecasting With a Large Ensemble of Deep-Learning
  Weather Prediction Models. Journal of Advances in Modeling Earth Systems,
  2021","10.1029/2021MS002502",,"physics.ao-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an ensemble prediction system using a Deep Learning Weather
Prediction (DLWP) model that recursively predicts key atmospheric variables
with six-hour time resolution. This model uses convolutional neural networks
(CNNs) on a cubed sphere grid to produce global forecasts. The approach is
computationally efficient, requiring just three minutes on a single GPU to
produce a 320-member set of six-week forecasts at 1.4{\deg} resolution.
Ensemble spread is primarily produced by randomizing the CNN training process
to create a set of 32 DLWP models with slightly different learned weights.
Although our DLWP model does not forecast precipitation, it does forecast total
column water vapor, and it gives a reasonable 4.5-day deterministic forecast of
Hurricane Irma. In addition to simulating mid-latitude weather systems, it
spontaneously generates tropical cyclones in a one-year free-running
simulation. Averaged globally and over a two-year test set, the ensemble mean
RMSE retains skill relative to climatology beyond two-weeks, with anomaly
correlation coefficients remaining above 0.6 through six days. Our primary
application is to subseasonal-to-seasonal (S2S) forecasting at lead times from
two to six weeks. Current forecast systems have low skill in predicting one- or
2-week-average weather patterns at S2S time scales. The continuous ranked
probability score (CRPS) and the ranked probability skill score (RPSS) show
that the DLWP ensemble is only modestly inferior in performance to the European
Centre for Medium Range Weather Forecasts (ECMWF) S2S ensemble over land at
lead times of 4 and 5-6 weeks. At shorter lead times, the ECMWF ensemble
performs better than DLWP.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:14:43 GMT""}]","2021-12-10"
"2102.05108","Francois Courvoisier","Chen Xie, Remi Meyer, Luc Froehly, Remo Giust, Francois Courvoisier","In-situ diagnostic of femtosecond probes for high resolution ultrafast
  imaging",,,,,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrafast imaging is essential in physics and chemistry to investigate the
femtosecond dynamics of nonuniform samples or of phenomena with strong spatial
variations. It relies on observing the phenomena induced by an ultrashort laser
pump pulse using an ultrashort probe pulse at a later time. Recent years have
seen the emergence of very successful ultrafast imaging techniques of single
non-reproducible events with extremely high frame rate, based on wavelength or
spatial frequency encoding. However, further progress in ultrafast imaging
towards high spatial resolution is hampered by the lack of characterization of
weak probe beams. Because of the difference in group velocities between pump
and probe in the bulk of the material, the determination of the absolute
pump-probe delay depends on the sample position. In addition, pulse-front tilt
is a widespread issue, unacceptable for ultrafast imaging, but which is
conventionally very difficult to evaluate for the low-intensity probe pulses.
Here we show that a pump-induced micro-grating generated from the electronic
Kerr effect provides a detailed in-situ characterization of a weak probe pulse.
It allows solving the two issues. Our approach is valid whatever the
transparent medium, whatever the probe pulse polarization and wavelength.
Because it is nondestructive and fast to implement, this in-situ probe
diagnostic can be repeated to calibrate experimental conditions, particularly
in the case where complex wavelength, spatial frequency or polarization
encoding is used. We anticipate that this technique will enable previously
inaccessible spatiotemporal imaging in all fields of ultrafast science and high
field physics at the micro- and nanoscale.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:14:54 GMT""}]","2021-02-11"
"2102.05109","Pranay Manocha","Pranay Manocha, Zeyu Jin, Richard Zhang, Adam Finkelstein","CDPAM: Contrastive learning for perceptual audio similarity","Dataset, code and sound examples can be found at
  https://github.com/pranaymanocha/PerceptualAudio/tree/master/cdpam",,,,"eess.AS cs.LG cs.SD","http://creativecommons.org/licenses/by/4.0/","  Many speech processing methods based on deep learning require an automatic
and differentiable audio metric for the loss function. The DPAM approach of
Manocha et al. learns a full-reference metric trained directly on human
judgments, and thus correlates well with human perception. However, it requires
a large number of human annotations and does not generalize well outside the
range of perturbations on which it was trained. This paper introduces CDPAM, a
metric that builds on and advances DPAM. The primary improvement is to combine
contrastive learning and multi-dimensional representations to build robust
models from limited data. In addition, we collect human judgments on triplet
comparisons to improve generalization to a broader range of audio
perturbations. CDPAM correlates well with human responses across nine varied
datasets. We also show that adding this metric to existing speech synthesis and
enhancement methods yields significant improvement, as measured by objective
and subjective tests.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:15:29 GMT""}]","2021-02-11"
"2102.05110","Jacob Springer","Jacob M. Springer, Melanie Mitchell, Garrett T. Kenyon","Adversarial Perturbations Are Not So Weird: Entanglement of Robust and
  Non-Robust Features in Neural Network Classifiers","20 pages, 14 figures, 6 tables",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural networks trained on visual data are well-known to be vulnerable to
often imperceptible adversarial perturbations. The reasons for this
vulnerability are still being debated in the literature. Recently Ilyas et al.
(2019) showed that this vulnerability arises, in part, because neural network
classifiers rely on highly predictive but brittle ""non-robust"" features. In
this paper we extend the work of Ilyas et al. by investigating the nature of
the input patterns that give rise to these features. In particular, we
hypothesize that in a neural network trained in a standard way, non-robust
features respond to small, ""non-semantic"" patterns that are typically entangled
with larger, robust patterns, known to be more human-interpretable, as opposed
to solely responding to statistical artifacts in a dataset. Thus, adversarial
examples can be formed via minimal perturbations to these small, entangled
patterns. In addition, we demonstrate a corollary of our hypothesis: robust
classifiers are more effective than standard (non-robust) ones as a source for
generating transferable adversarial examples in both the untargeted and
targeted settings. The results we present in this paper provide new insight
into the nature of the non-robust features responsible for adversarial
vulnerability of neural network classifiers.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:21:31 GMT""}]","2021-02-11"
"2102.05111","Miaomiao Wang","Miaomiao Wang, Soulaimane Berkane, and Abdelhamid Tayebi","Nonlinear Observers Design for Vision-Aided Inertial Navigation Systems","Accepted for publication in IEEE Transaction on Automatic Control. 16
  pages, 6 figures",,"10.1109/TAC.2021.3086459",,"math.OC cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the simultaneous estimation of the attitude, position
and linear velocity for vision-aided inertial navigation systems. We propose a
nonlinear observer on $SO(3)\times \mathbb{R}^{15}$ relying on body-frame
acceleration, angular velocity and (stereo or monocular) bearing measurements
of some landmarks that are constant and known in the inertial frame. Unlike the
existing local Kalman-type observers, our proposed nonlinear observer
guarantees almost global asymptotic stability and local exponential stability.
A detailed uniform observability analysis has been conducted and sufficient
conditions are derived. Moreover, a hybrid version of the proposed observer is
provided to handle the intermittent nature of the measurements in practical
applications. Simulation and experimental results are provided to illustrate
the effectiveness of the proposed state observer.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:22:11 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 17:44:41 GMT""}]","2021-06-08"
"2102.05112","Kun Meng","Kun Meng, Lianzhen Cao, Jiaqiang Zhao, Fuyong Qin, Tao Zhou, Meihua
  Deng","Dyonic Born-Infeld black hole in four-dimensional Horndeski gravity","13 pages, 2 figures. Phys.Lett.B 819 (2021) 136420",,"10.1016/j.physletb.2021.136420",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The action of four-dimensional Horndeski gravity coupled to Born-Infeld
electromagnetic fields is given via the Kaluza-Klein process. Dyonic black hole
solution of the theory is constructed. The metric is devoid of singularity at
the origin independent of the parameter selections, this property is different
from the one of Einstein-Born-Infeld black holes. Thermodynamics of the black
hole is studied, thermodynamic quantities are calculated and the first law is
checked to be satisfied. Thermodynamic phase transitions of the black holes are
studied in extended phase space.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:24:53 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 05:42:49 GMT""},{""version"":""v3"",""created"":""Sat, 17 Apr 2021 17:09:08 GMT""},{""version"":""v4"",""created"":""Sat, 12 Jun 2021 11:34:44 GMT""}]","2021-06-15"
"2102.05113","Abhishek Sinha","Abhishek Sinha, Kumar Ayush, Jiaming Song, Burak Uzkent, Hongxia Jin,
  Stefano Ermon","Negative Data Augmentation","Accepted at ICLR 2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Data augmentation is often used to enlarge datasets with synthetic samples
generated in accordance with the underlying data distribution. To enable a
wider range of augmentations, we explore negative data augmentation strategies
(NDA)that intentionally create out-of-distribution samples. We show that such
negative out-of-distribution samples provide information on the support of the
data distribution, and can be leveraged for generative modeling and
representation learning. We introduce a new GAN training objective where we use
NDA as an additional source of synthetic data for the discriminator. We prove
that under suitable conditions, optimizing the resulting objective still
recovers the true data distribution but can directly bias the generator towards
avoiding samples that lack the desired structure. Empirically, models trained
with our method achieve improved conditional/unconditional image generation
along with improved anomaly detection capabilities. Further, we incorporate the
same negative data augmentation strategy in a contrastive learning framework
for self-supervised representation learning on images and videos, achieving
improved performance on downstream image classification, object detection, and
action recognition tasks. These results suggest that prior knowledge on what
does not constitute valid data is an effective form of weak supervision across
a range of unsupervised learning tasks.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:28:35 GMT""}]","2021-02-11"
"2102.05114","Alessio Muscillo","Alessio Muscillo","A note on (matricial and fast) ways to compute Burt's structural holes","8 pages, 3 figures",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  In this note I derive simple formulas based on the adjacency matrix of a
network to compute measures associated with Ronald S. Burt's structural holes
(effective size, redundancy, local constraint and constraint). This can help to
interpret these measures and also to define naive algorithms for their
computation based on matrix operations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:11:52 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 15:49:26 GMT""},{""version"":""v3"",""created"":""Thu, 18 Feb 2021 09:22:04 GMT""},{""version"":""v4"",""created"":""Mon, 7 Jun 2021 10:22:27 GMT""}]","2021-06-08"
"2102.05115","Shane Rightley","Shane Rightley and S.D. Baalrud","A Kinetic Model for Electron-Ion Transport in Warm Dense Matter","14 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:2001.11438","Phys. Rev. E 103, 063206 (2021)","10.1103/PhysRevE.103.063206",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model for electron-ion transport in Warm Dense Matter that
incorporates Coulomb coupling effects into the quantum Boltzmann equation of
Uehling and Uhlenbeck through the use of a statistical potential of mean force.
Although this model has been derived rigorously in the classical limit [S.D.
Baalrud and J. Daligault, Physics of Plasmas 26, 8, 082106 (2019)], its quantum
generalization is complicated by the uncertainty principle. Here we apply an
existing model for the potential of mean force based on the quantum
Ornstein-Zernike equation coupled with an average-atom model [C. E. Starrett,
High Energy Density Phys. 25, 8 (2017)]. This potential contains correlations
due to both Coulomb coupling and exchange, and the collision kernel of the
kinetic theory enforces Pauli blocking while allowing for electron diffraction
and large-angle collisions. By solving the Uehling-Uhlenbeck equation for
electron-ion relaxation rates, we predict the momentum and temperature
relaxation time and electrical conductivity of solid density aluminum plasma
based on electron-ion collisions. We present results for density and
temperature conditions that span the transition from classical weakly-coupled
plasma to degenerate moderately-coupled plasma. Our findings agree well with
recent quantum molecular dynamics simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:35:22 GMT""}]","2021-06-23"
"2102.05116","Dirk K. Morr","Eric Mascot, Sagen Cocklin, Martin Graham, Mahdi Mashkoori, Stephan
  Rachel, and Dirk K. Morr","Origin of Topological Surface Superconductivity in
  FeSe$_{0.45}$Te$_{0.55}$",,"Commun. Phys. 5, 188 (2022)","10.1038/s42005-022-00943-x",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The engineering of Majorana zero modes in topological superconductors, a new
paradigm for the realization of topological quantum computing and
topology-based devices, has been hampered by the absence of materials with
sufficiently large superconducting gaps. Recent experiments, however, have
provided enthralling evidence for the existence of topological surface
superconductivity in the iron-based superconductor FeSe$_{0.45}$Te$_{0.55}$
possessing a full $s_\pm$-wave gap of a few meV. Here, we propose a mechanism
for the emergence of topological superconductivity on the surface of
FeSe$_{0.45}$Te$_{0.55}$ by demonstrating that the interplay between the
$s_\pm$-wave symmetry of the superconducting gap, recently observed surface
magnetism, and a Rashba spin-orbit interaction gives rise to several
topological superconducting phases. Moreover, the proposed mechanism explains a
series of experimentally observed hallmarks of topological superconductivity,
such as the emergence of Majorana zero modes in the center of vortex cores and
at the end of line defects, as well as of chiral Majorana edge modes along
certain types of domain walls. We also propose that the spatial distribution of
supercurrents near a domain wall is a characteristic signature measurable via a
scanning superconducting quantum interference device that can distinguish
between chiral Majorana edge modes and trivial in-gap states.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:37:11 GMT""}]","2023-01-18"
"2102.05117","Kamak Ebadi","Kamak Ebadi, Matteo Palieri, Sally Wood, Curtis Padgett, Ali-akbar
  Agha-mohammadi","DARE-SLAM: Degeneracy-Aware and Resilient Loop Closing in
  Perceptually-Degraded Environments","Accepted for publication in Journal of Intelligent and Robotic
  Systems, 2021",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Enabling fully autonomous robots capable of navigating and exploring
large-scale, unknown and complex environments has been at the core of robotics
research for several decades. A key requirement in autonomous exploration is
building accurate and consistent maps of the unknown environment that can be
used for reliable navigation. Loop closure detection, the ability to assert
that a robot has returned to a previously visited location, is crucial for
consistent mapping as it reduces the drift caused by error accumulation in the
estimated robot trajectory. Moreover, in multi-robot systems, loop closures
enable merging local maps obtained by a team of robots into a consistent global
map of the environment. In this paper, we present a degeneracy-aware and
drift-resilient loop closing method to improve place recognition and resolve 3D
location ambiguities for simultaneous localization and mapping (SLAM) in
GPS-denied, large-scale and perceptually-degraded environments. More
specifically, we focus on SLAM in subterranean environments (e.g., lava tubes,
caves, and mines) that represent examples of complex and ambiguous environments
where current methods have inadequate performance.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:37:17 GMT""}]","2021-02-11"
"2102.05118","Sebastian Deffner","Sebastian Deffner","Energetic cost of Hamiltonian quantum gates","7 pages, 1 figure; corrected very unfortunate typo in the derivation","EPL 134, 40002 (2021)","10.1209/0295-5075/134/40002",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Landauer's principle laid the main foundation for the development of modern
thermodynamics of information. However, in its original inception the principle
relies on semiformal arguments and dissipative dynamics. Hence, if and how
Landauer's principle applies to unitary quantum computing is less than obvious.
Here, we prove an inequality bounding the change of Shannon information encoded
in the logical quantum states by quantifying the energetic cost of Hamiltonian
gate operations. The utility of this bound is demonstrated by outlining how it
can be applied to identify energetically optimal quantum gates in theory and
experiment. The analysis is concluded by discussing the energetic cost of
quantum error correcting codes with non-interacting qubits, such as Shor's
code.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:39:35 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:46:59 GMT""},{""version"":""v3"",""created"":""Fri, 12 Feb 2021 07:01:47 GMT""}]","2021-08-04"
"2102.05119","Marcelo Byrro Ribeiro","Osvaldo L. Santos-Pereira (1), Everton M. C. Abreu (2,3,4), Marcelo B.
  Ribeiro (1,4,5) ((1) Physics Institute, Universidade Federal do Rio de
  Janeiro, (2) Physics Department, Universidade Federal Rural do Rio de
  Janeiro, (3) Physics Department, Universidade Federal de Juiz de Fora, (4)
  Applied Physics Graduate Program, Physics Institute, Universidade Federal do
  Rio de Janeiro, (5) Valongo Observatory, Universidade Federal do Rio de
  Janeiro)","Charged dust solutions for the warp drive spacetime","21 pages, 1 table. LaTeX. Accepted for publication in General
  Relativity and Gravitation","Gen. Rel. Grav. 53 (2021) 23","10.1007/s10714-021-02799-y",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The Alcubierre warp drive metric is a spacetime construction where a massive
particle located inside a spacetime distortion, called warp bubble, travels at
velocities arbitrarily higher than the velocity of light. This theoretically
constructed spacetime geometry is a consequence of general relativity where
global superluminal velocities, also known as warp speeds, are possible,
whereas local speeds are limited to subluminal ones as required by special
relativity. In this work we analyze the solutions of the Einstein equations
having charged dust energy-momentum tensor as source for warp velocities. The
Einstein equations with the cosmological constant are written and all solutions
having energy-momentum tensor components for electromagnetic fields generated
by charged dust are presented, as well as the respective energy conditions. The
results show an interplay between the energy conditions and the electromagnetic
field such that in some cases the former can be satisfied by both positive and
negative matter density. In other cases the dominant and null energy conditions
are violated. A result connecting the electric energy density with the
cosmological constant is also presented, as well as the effects of the
electromagnetic field on the bubble dynamics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:41:09 GMT""}]","2021-02-24"
"2102.05120","Alageshan Jaya Kumar","Omstavan Samant, Jaya Kumar Alageshan, Sarveshwar Sharma, and Animesh
  Kuley","Dynamic Mode Decomposition of inertial particle caustics in Taylor-Green
  flow","9 pages, 6 figures",,,,"physics.flu-dyn cs.LG","http://creativecommons.org/licenses/by/4.0/","  Inertial particles advected by a background flow can show complex structures.
We consider inertial particles in a 2D Taylor-Green (TG) flow and characterize
particle dynamics as a function of the particle's Stokes number using dynamic
mode decomposition (DMD) method from particle image velocimetry (PIV)
like-data. We observe the formation of caustic structures and analyze them
using DMD to (a) determine the Stokes number of the particles, and (b) estimate
the particle Stokes number composition. Our analysis in this idealized flow
will provide useful insight to analyze inertial particles in more complex or
turbulent flows. We propose that the DMD technique can be used to perform a
similar analysis on an experimental system.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:42:35 GMT""}]","2021-02-11"
"2102.05121","Paul E. Gunnells","Paul E. Gunnells","Generalized Catalan numbers from hypergraphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Catalan numbers (C_n)_{n >= 0} = 1,1,2,5,14,42,... form one of the most
venerable sequences in combinatorics. They have many combinatorial
interpretations, from counting bracketings of products in non-associative
algebra to counting plane trees and noncrossing set partitions. They also arise
in the GUE matrix model as the leading coefficient of certain polynomials, a
connection closely related to the plane trees and noncrossing set partitions
interpretations. In this paper we define a generalization of the Catalan
numbers. In fact we define an infinite collection of generalizations C_n^(m), m
>= 1, with m=1 giving the usual Catalans. The sequence C_n^(m) comes from
studying certain matrix models attached to hypergraphs. We also give some
combinatorial interpretations of these numbers, and conjecture some
asymptotics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:46:17 GMT""}]","2021-02-11"
"2102.05122","Renzi Wang","Yingzhao Lian, Renzi Wang and Colin N.Jones","Koopman based data-driven predictive control",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Sparked by the Willems' fundamental lemma, a class of data-driven control
methods has been developed for LTI systems. At the same time, the Koopman
operator theory attempts to cast a nonlinear control problem into a standard
linear one albeit infinite-dimensional. Motivated by these two ideas, a
data-driven control scheme for nonlinear systems is proposed in this work. The
proposed scheme is compatible with most differential regressors enabling
offline learning. In particular, the model uncertainty is considered, enabling
a novel data-driven simulation framework based on Wasserstein distance.
Numerical experiments are performed with Bayesian neural networks to show the
effectiveness of both the proposed control and simulation scheme.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:46:53 GMT""},{""version"":""v2"",""created"":""Sat, 27 Feb 2021 16:19:31 GMT""}]","2021-03-02"
"2102.05123","Guangyu Shen","Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu,
  Siyuan Cheng, Shiqing Ma, Xiangyu Zhang","Backdoor Scanning for Deep Neural Networks through K-Arm Optimization",,,,,"cs.LG cs.AI cs.CR","http://creativecommons.org/licenses/by/4.0/","  Back-door attack poses a severe threat to deep learning systems. It injects
hidden malicious behaviors to a model such that any input stamped with a
special pattern can trigger such behaviors. Detecting back-door is hence of
pressing need. Many existing defense techniques use optimization to generate
the smallest input pattern that forces the model to misclassify a set of benign
inputs injected with the pattern to a target label. However, the complexity is
quadratic to the number of class labels such that they can hardly handle models
with many classes. Inspired by Multi-Arm Bandit in Reinforcement Learning, we
propose a K-Arm optimization method for backdoor detection. By iteratively and
stochastically selecting the most promising labels for optimization with the
guidance of an objective function, we substantially reduce the complexity,
allowing to handle models with many classes. Moreover, by iteratively refining
the selection of labels to optimize, it substantially mitigates the uncertainty
in choosing the right labels, improving detection accuracy. At the time of
submission, the evaluation of our method on over 4000 models in the IARPA
TrojAI competition from round 1 to the latest round 4 achieves top performance
on the leaderboard. Our technique also supersedes three state-of-the-art
techniques in terms of accuracy and the scanning time needed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:49:06 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 19:17:09 GMT""},{""version"":""v3"",""created"":""Mon, 2 Aug 2021 15:42:02 GMT""}]","2021-08-03"
"2102.05124","Taegyun Kim","Taegyun Kim and Adam Martin","A $W^\pm$ polarization analyzer from Deep Neural Networks",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we train a Convolutional Neural Network to classify
longitudinally and transversely polarized hadronic $W^\pm$ using the images of
boosted $W^{\pm}$ jets as input. The images capture angular and energy
information from the jet constituents that is faithful to properties of the
original quark/anti-quark $W^{\pm}$ decay products without the need for
invasive substructure cuts. We find that the difference between the
polarizations is too subtle for the network to be used as an event-by-event
tagger. However, given an ensemble of $W^{\pm}$ events with unknown
polarization, the average network output from that ensemble can be used to
extract the longitudinal fraction $f_L$. We test the network on Standard Model
$pp \to W^{\pm}Z$ events and on $pp \to W^{\pm}Z$ in the presence of
dimension-6 operators that perturb the polarization composition.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:49:13 GMT""}]","2021-02-11"
"2102.05125","Cristian Mej\'ia-Cort\'es","Cristian Mej\'ia-Cort\'es and Mario I. Molina","Fractional discrete vortex solitons","15 pages, 4 figures",,"10.1364/OL.421970",,"nlin.PS physics.optics","http://creativecommons.org/licenses/by/4.0/","  We examine the existence and stability of nonlinear discrete vortex solitons
in a square lattice when the standard discrete Laplacian is replaced by a
fractional version. This creates a new, effective site-energy term, and a
coupling among sites, whose range depends on the value of the fractional
exponent $\alpha$, becoming effectively long-range at small $\alpha$ values. At
long-distance, it can be shown that this coupling decreases faster than
exponential: $\sim \exp(- |{\bf n}|)/\sqrt{|\bf{n}|}$. In general, we observe
that the stability domain of the discrete vortex solitons is extended to lower
power levels, as the $\alpha$ coefficient diminishes, independently of their
topological charge and/or pattern distribution.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:51:34 GMT""}]","2021-05-19"
"2102.05126","Jon\'a\v{s} Kulh\'anek","Jon\'a\v{s} Kulh\'anek and Vojt\v{e}ch Hude\v{c}ek and Tom\'a\v{s}
  Nekvinda and Ond\v{r}ej Du\v{s}ek","AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue
  with Pre-Trained Language Models",,"Proceedings of the 3rd Workshop on Natural Language Processing for
  Conversational AI (2021), 198-210","10.18653/v1/2021.nlp4convai-1.19",,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attention-based pre-trained language models such as GPT-2 brought
considerable progress to end-to-end dialogue modelling. However, they also
present considerable risks for task-oriented dialogue, such as lack of
knowledge grounding or diversity. To address these issues, we introduce
modified training objectives for language model finetuning, and we employ
massive data augmentation via back-translation to increase the diversity of the
training data. We further examine the possibilities of combining data from
multiples sources to improve performance on the target dataset. We carefully
evaluate our contributions with both human and automatic methods. Our model
substantially outperforms the baseline on the MultiWOZ data and shows
competitive performance with state of the art in both automatic and human
evaluation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:53:34 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 08:28:40 GMT""},{""version"":""v3"",""created"":""Fri, 14 Jan 2022 14:42:11 GMT""}]","2022-01-17"
"2102.05127","Rahul Kumar","Rahul Kumar","Extensions of Watson's theorem and the Ramanujan-Guinand formula",,,,,"math.NT math.CA","http://creativecommons.org/licenses/by/4.0/","  Ramanujan provided several results involving the modified Bessel function
$K_z(x)$ in his Lost Notebook. One of them is the famous Ramanujan-Guinand
formula, equivalent to the functional equation of the non-holomorphic
Eiesenstien series on $SL_2(z)$. Recently, this formula was generalized by
Dixit, Kesarwani, and Moll. In this article, we first obtain a generalization
of a theorem of Watson and, as an application of it, give a new proof of the
result of Dixit, Kesarwani, and Moll. Watson's theorem is also generalized in a
different direction using ${}_\mu K_z(x,\lambda)$ which is itself a
generalization of $K_z(x)$. Analytic continuation of all these results are also
given.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:54:12 GMT""}]","2021-02-11"
"2102.05128","Giuseppe Favacchio","Enrico Carlini, Maria Virginia Catalisano, Giuseppe Favacchio, Elena
  Guardo","Rational normal curves and Hadamard products",,,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given $r>n$ general hyperplanes in $\mathbb P^n,$ a star configuration of
points is the set of all the $n$-wise intersection of them. We introduce {\it
contact star configurations}, which are star configurations where all the
hyperplanes are osculating to the same rational normal curve. In this paper we
find a relation between this construction and Hadamard products of linear
varieties. Moreover, we study the union of contact star configurations on a
same conic in $\mathbb P^2$, we prove that the union of two contact star
configurations has a special $h$-vector and, in some cases, this is a complete
intersection.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:55:08 GMT""}]","2021-02-11"
"2102.05129","Haim Diamant","Haim Diamant","Parametric excitation of wrinkles in elastic sheets on elastic and
  viscoelastic substrates","10 pages, thoroughly revised and extended to include substrate
  inertia","Eur. Phys. J. E 44, 78 (2021)","10.1140/epje/s10189-021-00085-y",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thin elastic sheets supported on compliant media form wrinkles under lateral
compression. Since the lateral pressure is coupled to the sheet's deformation,
varying it periodically in time creates a parametric excitation. We study the
resulting parametric resonance of wrinkling modes in sheets supported on
semi-infinite elastic or viscoelastic media, at pressures smaller than the
critical pressure of static wrinkling. We find distinctive behaviors as a
function of excitation amplitude and frequency, including (a) a different
dependence of the dynamic wrinkle wavelength on sheet thickness compared to the
static wavelength; and (b) a discontinuous decrease of the wrinkle wavelength
upon increasing excitation frequency at sufficiently large pressures. In the
case of a viscoelastic substrate, resonant wrinkling requires crossing a
threshold of excitation amplitude. The frequencies for observing these
phenomena in relevant experimental systems are of the order of a kilohertz and
above. We discuss experimental implications of the results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:56:33 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 22:37:59 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 09:57:14 GMT""}]","2021-06-25"
"2102.05130","Thomas Fenzl","Thomas Fenzl","Extended skeletons of poly-stable pairs","v2: minor corrections, in Section 4 we consider ""closure"" instead of
  ""compactification""",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of poly-stable pairs of formal schemes over the
valuation ring of a non-archimedean field. For such pairs we define and
investigate the dual intersection complex. We proceed to develop the so called
extended skeleton of a poly-stable pair via an approximation process using the
classical skeletons constructed by Berkovich. This is essentially a
generalization of a construction by Gubler, Rabinoff and Werner from the
strictly semi-stable case to the arbitrary poly-stable case and we extend their
results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 11:05:49 GMT""}]","2021-08-04"
"2102.05131","Dara Bahri","Dara Bahri and Heinrich Jiang and Yi Tay and Donald Metzler","Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting out-of-distribution (OOD) examples is critical in many
applications. We propose an unsupervised method to detect OOD samples using a
$k$-NN density estimate with respect to a classification model's intermediate
activations on in-distribution samples. We leverage a recent insight about
label smoothing, which we call the \emph{Label Smoothed Embedding Hypothesis},
and show that one of the implications is that the $k$-NN density estimator
performs better as an OOD detection method both theoretically and empirically
when the model is trained with label smoothing. Finally, we show that our
proposal outperforms many OOD baselines and also provide new finite-sample
high-probability statistical results for $k$-NN density estimation's ability to
detect OOD examples.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:04:44 GMT""}]","2021-02-11"
"2102.05132","J. Quetzalcoatl Toledo-Marin","J. Quetzalcoatl Toledo-Marin and James A. Glazier","Using Deep LSD to build operators in GANs latent space with meaning in
  real space","9pp, 8 figs, 1 pseudocode, code available",,,,"cs.LG cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Generative models rely on the key idea that data can be represented in terms
of latent variables which are uncorrelated by definition. Lack of correlation
is important because it suggests that the latent space manifold is simpler to
understand and manipulate. Generative models are widely used in deep learning,
e.g., variational autoencoders (VAEs) and generative adversarial networks
(GANs). Here we propose a method to build a set of linearly independent vectors
in the latent space of a GANs, which we call quasi-eigenvectors. These
quasi-eigenvectors have two key properties: i) They span all the latent space,
ii) A set of these quasi-eigenvectors map to each of the labeled features
one-on-one. We show that in the case of the MNIST, while the number of
dimensions in latent space is large by construction, 98% of the data in real
space map to a sub-domain of latent space of dimensionality equal to the number
of labels. We then show how the quasi-eigenvalues can be used for Latent
Spectral Decomposition (LSD), which has applications in denoising images and
for performing matrix operations in latent space that map to feature
transformations in real space. We show how this method provides insight into
the latent space topology. The key point is that the set of quasi-eigenvectors
form a basis set in latent space and each direction corresponds to a feature in
real space.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:05:20 GMT""}]","2021-02-11"
"2102.05133","Dennis Bonatsos","Andriana Martinou, Dennis Bonatsos, T. J. Mertzimekis, K. E.
  Karakatsanis, I.E. Assimakis, S. K. Peroulis, S. Sarantopoulou, and N. Minkov","The islands of shape coexistence within the Elliott and the proxy-SU(3)
  Models","31 pages, 25 figures, 4 tables","Eur. Phys. J. A 57 (2021) 84","10.1140/epja/s10050-021-00396-w",,"nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A novel dual-shell mechanism for the phenomenon of shape coexistence in
nuclei within the Elliott SU(3) and the proxy-SU(3) symmetry is proposed for
all mass regions. It is supposed, that shape coexistence is activated by large
quadrupole-quadrupole interaction and involves the interchange among the
spin-orbit (SO) like shells within nucleon numbers 6-14, 14-28, 28-50, 50-82,
82-126, 126-184, which are being described by the proxy-SU(3) symmetry, and the
harmonic oscillator (HO) shells within nucleon numbers 2-8, 8-20, 20-40, 40-70,
70-112, 112-168 of the Elliott SU(3) symmetry. The outcome is, that shape
coexistence may occur in certain islands on the nuclear map. The dual-shell
mechanism predicts without any free parameters, that nuclei with proton number
(Z) or neutron number (N) between 7-8, 17-20, 34-40, 59-70, 96-112, 146-168 are
possible candidates for shape coexistence. In the light nuclei the nucleons
flip from the HO shell to the neighboring SO-like shell, which means, that
particle excitations occur. For this mass region, the predicted islands of
shape coexistence, coincide with the islands of inversion. But in medium mass
and heavy nuclei, in which the nucleons inhabit the SO-like shells, shape
coexistence is accompanied by a merging of the SO-like shell with the open HO
shell. The shell merging can be accomplished by the outer product of the SU(3)
irreps of the two shells and represents the unification of the HO shell with
the SO-like shell.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:08:44 GMT""}]","2021-03-09"
"2102.05134","Thomas Kerdreux","Thomas Kerdreux, Alexandre d'Aspremont, and Sebastian Pokutta","Local and Global Uniform Convexity Conditions",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review various characterizations of uniform convexity and smoothness on
norm balls in finite-dimensional spaces and connect results stemming from the
geometry of Banach spaces with \textit{scaling inequalities} used in analysing
the convergence of optimization methods. In particular, we establish local
versions of these conditions to provide sharper insights on a recent body of
complexity results in learning theory, online learning, or offline
optimization, which rely on the strong convexity of the feasible set. While
they have a significant impact on complexity, these strong convexity or uniform
convexity properties of feasible sets are not exploited as thoroughly as their
functional counterparts, and this work is an effort to correct this imbalance.
We conclude with some practical examples in optimization and machine learning
where leveraging these conditions and localized assumptions lead to new
complexity results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:09:53 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 18:11:09 GMT""}]","2021-02-19"
"2102.05135","Taman Narayan","Taman Narayan, Serena Wang, Kevin Canini, Maya Gupta","Regularization Strategies for Quantile Regression",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate different methods for regularizing quantile regression when
predicting either a subset of quantiles or the full inverse CDF. We show that
minimizing an expected pinball loss over a continuous distribution of quantiles
is a good regularizer even when only predicting a specific quantile. For
predicting multiple quantiles, we propose achieving the classic goal of
non-crossing quantiles by using deep lattice networks that treat the quantile
as a monotonic input feature, and we discuss why monotonicity on other features
is an apt regularizer for quantile regression. We show that lattice models
enable regularizing the predicted distribution to a location-scale family.
Lastly, we propose applying rate constraints to improve the calibration of the
quantile predictions on specific subsets of interest and improve fairness
metrics. We demonstrate our contributions on simulations, benchmark datasets,
and real quantile regression problems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:10:35 GMT""}]","2021-02-11"
"2102.05136","Sergy Grebenshchikov","Sergy Grebenshchikov and Sergio Carbajo","Quantum mechanical study of the attosecond nonlinear Fourier transform
  spectroscopy of carbon dioxide","8 figures",,,,"physics.chem-ph physics.ao-ph physics.atm-clus physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Attosecond nonlinear Fourier transform (NFT) pump probe spectroscopy is an
experimental technique which allows investigation of the electronic excitation,
ionization, and unimolecular dissociation processes. The NFT spectroscopy
utilizes ultrafast multiphoton ionization in the extreme ultraviolet spectral
range and detects the dissociation products of the unstable ionized species. In
this paper, a quantum mechanical description of NFT spectra is suggested, which
is based on the second order perturbation theory in molecule-light interaction
and the high level ab initio calculations of CO2 and CO2+ in the Franck-Condon
zone. The calculations capture the characteristic features of the available
experimental NFT spectra of CO2. Approximate analytic expressions are derived
and used to assign the calculated spectra in terms of participating electronic
states and harmonic photon frequencies. The developed approach provides a
convenient framework within which the origin and the significance of near
harmonic and non-harmonic NFT spectral lines can be analyzed. The framework is
scalable and the spectra of di- and triatomic species as well as the
dependences on the control parameters can by predicted semi-quantitatively.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:22:32 GMT""}]","2021-02-11"
"2102.05137","Jan Kaiser","Jan Kaiser, William A. Borders, Kerem Y. Camsari, Shunsuke Fukami,
  Hideo Ohno, and Supriyo Datta","Hardware-aware $in \ situ$ Boltzmann machine learning using stochastic
  magnetic tunnel junctions",,"Phys. Rev. Applied 17, 014016 (2022)","10.1103/PhysRevApplied.17.014016",,"cond-mat.mes-hall cond-mat.dis-nn cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the big challenges of current electronics is the design and
implementation of hardware neural networks that perform fast and
energy-efficient machine learning. Spintronics is a promising catalyst for this
field with the capabilities of nanosecond operation and compatibility with
existing microelectronics. Considering large-scale, viable neuromorphic systems
however, variability of device properties is a serious concern. In this paper,
we show an autonomously operating circuit that performs hardware-aware machine
learning utilizing probabilistic neurons built with stochastic magnetic tunnel
junctions. We show that $in \ situ$ learning of weights and biases in a
Boltzmann machine can counter device-to-device variations and learn the
probability distribution of meaningful operations such as a full adder. This
scalable autonomously operating learning circuit using spintronics-based
neurons could be especially of interest for standalone artificial-intelligence
devices capable of fast and efficient learning at the edge.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:26:21 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 03:59:16 GMT""}]","2022-01-17"
"2102.05138","Konstantin Stankevich","Konstantin Stankevich and Alexander Studenikin","Collective neutrino oscillations accounting for neutrino quantum
  decoherence","3 pages in LaTex, based on the presentation at the 40th International
  Conference on High Energy Physics (ICHEP 2020), 28 July - 6 August 2020,
  Prague, Czech Republic",,"10.22323/1.390.0216",,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  In our previous studies (see [1] and references therein) we developed a new
theoretical framework that enabled one to consider a new mechanism of neutrino
quantum decoherence engendered by the neutrino radiative decay. In parallel,
another framework was developed (see [2] and references therein) for the
description of the neutrino quantum decoherence due to the non-forward neutrino
scattering processes. Both mechanisms are described by the master equations in
the Lindblad form.
  We study the influence of the neutrino quantum decoherence on collective
neutrino oscillations. In the present studies we are are not interested in a
specific mechanism of neutrino quantum decoherence. Therefore, we use the
general Lindblad master equation for the description of the neutrino quantum
decoherence and do not fix an analytical expressions for the decoherence and
relaxation parameters.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:27:41 GMT""}]","2022-09-21"
"2102.05139","Ustim Khristenko","Ustim Khristenko, Barbara Wohlmuth","Solving time-fractional differential equation via rational approximation","26 pages, 10 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fractional differential equations (FDEs) describe subdiffusion behavior of
dynamical systems. Its non-local structure requires taking into account the
whole evolution history during the time integration, which then possibly causes
additional memory use to store the history, growing in time. An alternative to
a quadrature for the history integral is to approximate the fractional kernel
with the sum of exponentials, which is equivalent to considering the FDE
solution as a sum of solutions to a system of ODEs. One possibility to
construct this system is to approximate the Laplace spectrum of the fractional
kernel with a rational function. In this paper, we use the adaptive
Antoulas--Anderson (AAA) algorithm for the rational approximation of the kernel
spectrum which yields only a small number of real valued poles. We propose a
numerical scheme based on this idea and study its stability and convergence
properties. In addition, we apply the algorithm to a time-fractional
Cahn-Hilliard problem.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:35:03 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 19:49:44 GMT""}]","2022-02-17"
"2102.05140","Dara Bahri","Dara Bahri and Heinrich Jiang","Locally Adaptive Label Smoothing for Predictive Churn","ICML 2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Training modern neural networks is an inherently noisy process that can lead
to high \emph{prediction churn} -- disagreements between re-trainings of the
same model due to factors such as randomization in the parameter initialization
and mini-batches -- even when the trained models all attain similar accuracies.
Such prediction churn can be very undesirable in practice. In this paper, we
present several baselines for reducing churn and show that training on soft
labels obtained by adaptively smoothing each example's label based on the
example's neighboring labels often outperforms the baselines on churn while
improving accuracy on a variety of benchmark classification tasks and model
architectures.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:38:37 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 22:36:46 GMT""}]","2021-06-15"
"2102.05141","Barbara J. Anthony-Twarog","B. J. Anthony-Twarog (1), C. P. Deliyannis (2). B. A. Twarog (1) ((1)
  Univ. of Kansas, (2) Indiana Univ.)","WIYN Open Cluster Study LXXXV. Li in NGC 2243 -- Implications for
  Stellar and Galactic Evolution","24 pages; 12 figures; accepted for Astronomical Journal",,"10.3847/1538-3881/abe0b7",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dispersion spectra in the Li 6708 Angstrom region have been obtained and
analyzed in the old, metal-deficient cluster, NGC 2243. From Hydra spectra for
29 astrometric and radial-velocity members, we derive rotational velocities, as
well as [Fe/H], [Ca/H], [Si/H], and [Ni/H] based on 17, 1, 1, and 3 lines,
respectively. Using ROBOSPECT, an automatic equivalent width measurement
program, we derive [Fe/H] = -0.54 +/- 0.11 (MAD), for an internal precision for
the cluster [Fe/H] below 0.03 dex. Given the more restricted line set,
comparable values for [Ca/H], [Si/H], and [Ni/H] are -0.48 +/- 0.19, -0.44 +/-
0.11, and -0.61 +/- 0.06, respectively. With E(B-V) = 0.055, appropriate
isochrones imply (m-M) = 13.2 +/- 0.1 and an age of 3.6 +/- 0.2 Gyr. Using
available VLT spectra and published Li abundances, we construct a Li sample of
over 100 stars extending from the tip of the giant branch to 0.5 mag below the
Li-dip. The Li-dip is well populated and, when combined with results for NGC
6819 and Hyades/Praesepe, implies a mass/metallicity slope of 0.4
solar-mass/dex for the high mass edge of the Li-dip. The A(Li) distribution
among giants reflects the degree of Li variation among the turnoff stars above
the Li-dip, itself a function of stellar mass and metallicity and strongly
anticorrelated with a v_rot distribution that dramatically narrows with age.
Potential implications of these patterns for the interpretation of Li among
dwarf and giant field populations, especially selection biases tied to age and
metallicity, are discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:38:42 GMT""}]","2021-03-10"
"2102.05142","Daniel Hawtin","Daniel R. Hawtin and Jesse Lansdown","The Non-Existence of Block-Transitive Subspace Designs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $q$ be a prime power and $V\cong{\mathbb F}_q^n$. A $t$-$(n,k,\lambda)_q$
design, or simply a subspace design, is a pair ${\mathcal D}=(V,{\mathcal B})$,
where ${\mathcal B}$ is a subset of the set of all $k$-dimensional subspaces of
$V$, with the property that each $t$-dimensional subspace of $V$ is contained
in precisely $\lambda$ elements of ${\mathcal B}$. Subspace designs are the
$q$-analogues of balanced incomplete block designs. Such a design is called
block-transitive if its automorphism group ${\rm Aut}({\mathcal D})$ acts
transitively on ${\mathcal B}$. It is shown here that if $t\geq 2$ and
${\mathcal D}$ is a block-transitive $t$-$(n,k,\lambda)_q$ design then
${\mathcal D}$ is trivial, that is, ${\mathcal B}$ is the set of all
$k$-dimensional subspaces of $V$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:42:27 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 13:30:34 GMT""}]","2022-01-12"
"2102.05143","Waleed Yousef","Waleed A. Yousef, Issa Traore, William Briguglio","Classifier Calibration: with application to threat scores in
  cybersecurity",,,"10.1109/TDSC.2022.3170011",,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores the calibration of a classifier output score in binary
classification problems. A calibrator is a function that maps the arbitrary
classifier score, of a testing observation, onto $[0,1]$ to provide an estimate
for the posterior probability of belonging to one of the two classes.
Calibration is important for two reasons; first, it provides a meaningful
score, that is the posterior probability; second, it puts the scores of
different classifiers on the same scale for comparable interpretation. The
paper presents three main contributions: (1) Introducing multi-score
calibration, when more than one classifier provides a score for a single
observation. (2) Introducing the idea that the classifier scores to a
calibration process are nothing but features to a classifier, hence proposing
expanding the classifier scores to higher dimensions to boost the calibrator's
performance. (3) Conducting a massive simulation study, in the order of 24,000
experiments, that incorporates different configurations, in addition to
experimenting on two real datasets from the cybersecurity domain. The results
show that there is no overall winner among the different calibrators and
different configurations. However, general advices for practitioners include
the following: the Platt's
calibrator~\citep{Platt1999ProbabilisticOutputsForSupport}, a version of the
logistic regression that decreases bias for a small sample size, has a very
stable and acceptable performance among all experiments; our suggested
multi-score calibration provides better performance than single score
calibration in the majority of experiments, including the two real datasets. In
addition, expanding the scores can help in some experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:45:23 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 16:12:08 GMT""},{""version"":""v3"",""created"":""Wed, 27 Apr 2022 19:20:35 GMT""}]","2022-04-29"
"2102.05144","Mehdi Hosseinzadeh","Mehdi Hosseinzadeh, Bruno Sinopoli, Aaron F. Bobick","Toward Safe and Efficient Human-Robot Interaction via Behavior-Driven
  Danger Signaling",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper introduces the notion of danger awareness in the context of
Human-Robot Interaction (HRI), which decodes whether a human is aware of the
existence of the robot, and illuminates whether the human is willing to engage
in enforcing the safety. This paper also proposes a method to quantify this
notion as a single binary variable, so-called danger awareness coefficient. By
analyzing the effect of this coefficient on the human's actions, an online
Bayesian learning method is proposed to update the belief about the value of
the coefficient. It is shown that based upon the danger awareness coefficient
and the proposed learning method, the robot can build a predictive human model
to anticipate the human's future actions. In order to create a communication
channel between the human and the robot, to enrich the observations and get
informative data about the human, and to improve the efficiency of the robot,
the robot is equipped with a danger signaling system. A predictive planning
scheme, coupled with the predictive human model, is also proposed to provide an
efficient and Probabilistically safe plan for the robot. The effectiveness of
the proposed scheme is demonstrated through simulation studies on an
interaction between a self-driving car and a pedestrian.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:45:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 01:28:37 GMT""}]","2021-02-12"
"2102.05145","James David Watson","James D. Watson, Emilio Onorati, Toby S. Cubitt","Uncomputably Complex Renormalisation Group Flows","88 pages, 11 figures","Nature Communications 13, 7618 (2022)","10.1038/s41467-022-35179-4",,"quant-ph cond-mat.other math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Renormalisation group (RG) methods provide one of the most important
techniques for analysing the physics of many-body systems, both analytically
and numerically. By iterating an RG map, which ""course-grains"" the description
of a many-body system and generates a flow in the parameter space, physical
properties of interest can be extracted even for complex models. RG analysis
also provides an explanation of physical phenomena such as universality. Many
systems exhibit simple RG flows, but more complicated -- even chaotic --
behaviour is also known. Nonetheless, the structure of such RG flows can still
be analysed, elucidating the physics of the system, even if specific
trajectories may be highly sensitive to the initial point. In contrast, recent
work has shown that important physical properties of quantum many-body systems,
such as its spectral gap and phase diagram, can be uncomputable.
  In this work, we show that such undecidable systems exhibit a novel type of
RG flow, revealing a qualitatively different and more extreme form of
unpredictability than chaotic RG flows. In contrast to chaotic RG flows in
which initially close points can diverge exponentially, trajectories under
these novel uncomputable RG flows can remain arbitrarily close together for an
uncomputable number of iterations, before abruptly diverging to different fixed
points that are in separate phases. The structure of such uncomputable RG flows
is so complex that it cannot be computed or approximated, even in principle. We
give a mathematically rigorous construction of the block-renormalisation-group
map for the original undecidable many-body system that appeared in the
literature (Cubitt, P\'erez-Garcia, Wolf, Nature 528, 207-211 (2015)). We prove
that each step of this RG map is computable, and that it converges to the
correct fixed points, yet the resulting RG flow is uncomputable.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:46:55 GMT""}]","2022-12-26"
"2102.05146","Dragan Damjanovic","Lukas M. Riemer, Li Jin, Hana Ur\v{s}i\v{c}, Mojca Otonicar, Tadej
  Rojac and Dragan Damjanovic","Dielectric and electro-mechanic nonlinearities in perovskite oxide
  ferroelectrics, relaxors and relaxor ferroelectrics","main text 35 pages, 8 figures; supplementary material 3 pages and 5
  figures","J. Appl. Phys. Vol. 129, p. 054101 (2021)","10.1063/5.0035859",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The polarization and strain response of ferroelectric materials at fields
below the macroscopic coercive field is of a paramount importance for the
operation of many electronic devices. The response of real ferroelectric and
related materials is in general complex and difficult to interpret. The reason
for this is that many processes in a ferroelectric material contribute to its
properties, often concurrently. Examples include motion of ferroelectric and
ferroelastic domains, presence of domains within domains, dynamics of different
types of polar nano-entities, interaction of polar nano-entities (e.g., polar
nanoregions in relaxors) with the strain and polarization within domains,
motion of defects and rearrangement of defect clusters and their interaction
with polarization and strain. One signature of these processes is nonlinearity
of the strain and polarization. Most ferroelectrics exhibit nonlinear response
at all practical field levels meaning that the apparent material coefficients
depend on the amplitude of the driving excitation. In this paper we show that
an investigation of nonlinear behavior is a sensitive way to study various
mechanisms operating in dielectric and piezoelectric materials. We review the
basic formalism of the nonlinear description of polarization and strain, give a
physical interpretation of different terms and illustrate this approach on
numerous examples of relaxors, relaxor ferroelectrics, hard and soft
ferroelectrics, and morphotropic phase boundary compositions. An experimental
approach based on a lock-in technique that is well-suited for such studies is
also discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:53:07 GMT""}]","2021-06-08"
"2102.05147","Kolawole Ogunsina","Kolawole Ogunsina, Marios Papamichalis, Daniel DeLaurentis","Relational Dynamic Bayesian Network Modeling for Uncertainty
  Quantification and Propagation in Airline Disruption Management","Published in Elsevier Journal of Engineering Applications of
  Artificial Intelligence",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Disruption management during the airline scheduling process can be
compartmentalized into proactive and reactive processes depending upon the time
of schedule execution. The state of the art for decision-making in airline
disruption management involves a heuristic human-centric approach that does not
categorically study uncertainty in proactive and reactive processes for
managing airline schedule disruptions. Hence, this paper introduces an
uncertainty transfer function model (UTFM) framework that characterizes
uncertainty for proactive airline disruption management before schedule
execution, reactive airline disruption management during schedule execution,
and proactive airline disruption management after schedule execution to enable
the construction of quantitative tools that can allow an intelligent agent to
rationalize complex interactions and procedures for robust airline disruption
management. Specifically, we use historical scheduling and operations data from
a major U.S. airline to facilitate the development and assessment of the UTFM,
defined by hidden Markov models (a special class of probabilistic graphical
models) that can efficiently perform pattern learning and inference on portions
of large data sets. We employ the UTFM to assess two independent and separately
disrupted flight legs from the airline route network. Assessment of a flight
leg from Dallas to Houston, disrupted by air traffic control hold for bad
weather at Dallas, revealed that proactive disruption management for turnaround
in Dallas before schedule execution is impractical because of zero transition
probability between turnaround and taxi-out.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:57:04 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 13:35:51 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 17:23:30 GMT""}]","2022-03-24"
"2102.05148","Jesse Rodr\'iguez","Jesse A. Rodriguez, Ahmed I. Abdalla, Benjamin Wang, Beicheng Lou,
  Shanhui Fan, Mark A. Cappelli","Inverse design of plasma metamaterial devices for optical computing",,"Phys. Rev. Applied 16, 014023 (2021)","10.1103/PhysRevApplied.16.014023",,"physics.app-ph physics.optics physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  We apply inverse design methods to produce two-dimensional plasma
metamaterial (PMM) devices. Backpropagated finite difference frequency domain
(FDFD) simulations are used to design waveguides and demultiplexers operating
under both transverse electric (TE) and transverse magnetic (TM) modes.
Demultiplexing and waveguiding are demonstrated for devices composed of plasma
elements with reasonable plasma densities ~7 GHz, allowing for future in-situ
training and experimental realization of these designs. We also explore the
possible applicability of PMMs to nonlinear boolean operations for use in
optical computing. Functionally complete logical connectives (OR and AND) are
achieved in the TM mode.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:58:58 GMT""},{""version"":""v2"",""created"":""Sun, 25 Apr 2021 23:57:29 GMT""},{""version"":""v3"",""created"":""Wed, 9 Jun 2021 16:30:51 GMT""}]","2021-07-14"
"2102.05149","Piotr Gawlowicz","Piotr Gaw{\l}owicz, Jean Walrand, Adam Wolisz","Distributed Learning for Proportional-Fair Resource Allocation in
  Coexisting WiFi Networks",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we revisit the widely known performance anomaly that results
in severe network utility degradation in WiFi networks when nodes use diverse
modulation and coding schemes. The proportional-fair allocation was shown to
mitigate this anomaly and provide a good throughput to the stations. It can be
achieved through the selection of contention window values based on the
explicit solution of an optimization problem or, as proposed recently, by
following a learning-based approach that uses a centralized gradient descent
algorithm. In this paper, we leverage our recent theoretical work on
asynchronous distributed optimization and propose a simple algorithm that
allows WiFi nodes to independently tune their contention window to achieve
proportional fairness. We compare the throughputs and air-time allocation that
this algorithm achieves to those of the standard WiFi binary exponential
back-off and show the improvements.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:00:30 GMT""}]","2021-02-11"
"2102.05150","Yizhou Wang","Yizhou Wang, Zhongyu Jiang, Yudong Li, Jenq-Neng Hwang, Guanbin Xing,
  Hui Liu","RODNet: A Real-Time Radar Object Detection Network Cross-Supervised by
  Camera-Radar Fused Object 3D Localization","IEEE Journal of Selected Topics in Signal Processing Special Issue on
  Recent Advances in Automotive Radar Signal Processing. arXiv admin note: text
  overlap with arXiv:2003.01816",,"10.1109/JSTSP.2021.3058895",,"cs.CV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various autonomous or assisted driving strategies have been facilitated
through the accurate and reliable perception of the environment around a
vehicle. Among the commonly used sensors, radar has usually been considered as
a robust and cost-effective solution even in adverse driving scenarios, e.g.,
weak/strong lighting or bad weather. Instead of considering to fuse the
unreliable information from all available sensors, perception from pure radar
data becomes a valuable alternative that is worth exploring. In this paper, we
propose a deep radar object detection network, named RODNet, which is
cross-supervised by a camera-radar fused algorithm without laborious annotation
efforts, to effectively detect objects from the radio frequency (RF) images in
real-time. First, the raw signals captured by millimeter-wave radars are
transformed to RF images in range-azimuth coordinates. Second, our proposed
RODNet takes a sequence of RF images as the input to predict the likelihood of
objects in the radar field of view (FoV). Two customized modules are also added
to handle multi-chirp information and object relative motion. Instead of using
human-labeled ground truth for training, the proposed RODNet is
cross-supervised by a novel 3D localization of detected objects using a
camera-radar fusion (CRF) strategy in the training stage. Finally, we propose a
method to evaluate the object detection performance of the RODNet. Due to no
existing public dataset available for our task, we create a new dataset, named
CRUW, which contains synchronized RGB and RF image sequences in various driving
scenarios. With intensive experiments, our proposed cross-supervised RODNet
achieves 86% average precision and 88% average recall of object detection
performance, which shows the robustness to noisy scenarios in various driving
conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:01:55 GMT""}]","2021-07-07"
"2102.05151","Turab Iqbal","Turab Iqbal, Karim Helwani, Arvindh Krishnaswamy, Wenwu Wang","Enhancing Audio Augmentation Methods with Consistency Learning","Accepted to 46th International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2021)",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data augmentation is an inexpensive way to increase training data diversity
and is commonly achieved via transformations of existing data. For tasks such
as classification, there is a good case for learning representations of the
data that are invariant to such transformations, yet this is not explicitly
enforced by classification losses such as the cross-entropy loss. This paper
investigates the use of training objectives that explicitly impose this
consistency constraint and how it can impact downstream audio classification
tasks. In the context of deep convolutional neural networks in the supervised
setting, we show empirically that certain measures of consistency are not
implicitly captured by the cross-entropy loss and that incorporating such
measures into the loss function can improve the performance of audio
classification systems. Put another way, we demonstrate how existing
augmentation methods can further improve learning by enforcing consistency.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:01:58 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 18:09:47 GMT""},{""version"":""v3"",""created"":""Mon, 19 Apr 2021 15:04:13 GMT""}]","2021-04-20"
"2102.05152","Hao Yuan","Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, Shuiwang Ji","On Explainability of Graph Neural Networks via Subgraph Explorations","Accepted by ICML 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of explaining the predictions of graph neural
networks (GNNs), which otherwise are considered as black boxes. Existing
methods invariably focus on explaining the importance of graph nodes or edges
but ignore the substructures of graphs, which are more intuitive and
human-intelligible. In this work, we propose a novel method, known as
SubgraphX, to explain GNNs by identifying important subgraphs. Given a trained
GNN model and an input graph, our SubgraphX explains its predictions by
efficiently exploring different subgraphs with Monte Carlo tree search. To make
the tree search more effective, we propose to use Shapley values as a measure
of subgraph importance, which can also capture the interactions among different
subgraphs. To expedite computations, we propose efficient approximation schemes
to compute Shapley values for graph data. Our work represents the first attempt
to explain GNNs via identifying subgraphs explicitly and directly. Experimental
results show that our SubgraphX achieves significantly improved explanations,
while keeping computations at a reasonable level.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:12:26 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 21:16:36 GMT""}]","2021-06-02"
"2102.05153","Johannes Fr\""och","Angus Gale, Johannes E. Fr\""och, Mehran Kianinia, James Bishop, Igor
  Aharonovich, Milos Toth","Recoil Implantation Using Gas-Phase Precursor Molecules",,,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Ion implantation underpins a vast range of devices and technologies that
require precise control over the physical, chemical, electronic, magnetic and
optical properties of materials. A variant termed recoil implantation - in
which a precursor is deposited onto a substrate as a thin film and implanted
via momentum transfer from incident energetic ions - has a number of compelling
advantages, particularly when performed using an inert ion nano-beam [Fr\""och
et al., Nat Commun 11, 5039 (2020)]. However, a major drawback of this approach
is that the implant species are limited to the constituents of solid thin
films. Here we overcome this limitation by demonstrating recoil implantation
using gas-phase precursors. Specifically, we fabricate nitrogen-vacancy (NV)
color centers in diamond using an Ar ion beam and the nitrogen-containing
precursor gases N2, NH3 and NF3. Our work expands the applicability of recoil
implantation to most of the periodic table, and to applications in which thin
film deposition or removal is impractical.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:12:36 GMT""}]","2021-02-11"
"2102.05154","Akos G.Horvath","\'Akos G.Horv\'ath","A note on the low-dimensional Minkowski-reduction","9 pages",,,,"math.MG","http://creativecommons.org/licenses/by/4.0/","  In this paper we recall the basic results of reduction theory of positive
definite quadratic forms. Since finding the shortest vectors in a lattice is an
NP-hard problem, the low-dimensional results in lattice reduction theory have
important role. Using the result of Ryskov on admissible centerings and the
result of Tammela about the determination of a Minkowski-reduced form, we prove
that the absolute values of coordinates of a minimum vector in a
six-dimensional Minkowski-reduced basis are less or equal to three. To get this
sharpening of P. Tammela's interesting works, we combine some elementary
geometric reasonings with the mentioned theoretical results.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:15:14 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 12:25:03 GMT""}]","2023-04-03"
"2102.05155","Francois Golse","Fran\c{c}ois Golse and Thierry Paul","Observability for the Schr\""odinger Equation: an Optimal Transport
  Approach","15 pages, no figure",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We establish an observation inequality for the Schr\""odinger equation on
$\mathbf{R}^d$, uniform in the Planck constant $\hbar\in[0,1]$. The proof is
based on the pseudometric introduced in [F. Golse, T. Paul, Arch. Rational
Mech. Anal. 223 (2017), 57-94]. This inequality involves only effective
constants which are computed explicitly in their dependence in $\hbar$ and all
parameters involved.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:21:40 GMT""}]","2021-02-11"
"2102.05156","Georgia Pierrou","Georgia Pierrou and Xiaozhe Wang","An Online Network Model-Free Wide-Area Voltage Control Method Using PMUs","11 pages, Accepted by IEEE Transactions on Power Systems for future
  publication",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel online measurement-based Wide-Area Voltage
Control (WAVC) method using Phasor Measurement Unit (PMU) data in power systems
with Flexible AC Transmission System (FACTS) devices. As opposed to previous
WAVC methods, the proposed WAVC does not require any model knowledge or the
participation of all buses and considers both active and reactive power
perturbations. Specifically, the proposed WAVC method exploits the regression
theorem of the Ornstein-Uhlenbeck process to estimate the sensitivity matrices
through PMU data online, which are further used to design and apply the voltage
regulation by updating the reference points of FACTS devices. Numerical results
on the IEEE 39- Bus and IEEE 68-Bus systems demonstrate that the proposed
model-free WAVC can provide effective voltage control in various network
topologies, different combinations of voltage-controlled and
voltage-uncontrolled buses, under measurement noise, and in case of missing
PMUs. Particularly, the proposed WAVC algorithm may outperform the model-based
WAVC when an undetected topology change happens.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:26:49 GMT""}]","2021-02-11"
"2102.05157","Dmitry Chubukov","D.V. Chubukov, L.V. Skripnikov, A.N. Petrov, V.N. Kutuzov, L.N.
  Labzowsky","$\mathcal{P}$, $\mathcal{T}$-odd Faraday rotation in intracavity
  absorption spectroscopy with molecular beam as a possible way to improve the
  sensitivity of the search for the time reflection noninvariant effects in
  nature","arXiv admin note: text overlap with arXiv:1907.11761","Phys. Rev. A 103, 042802 (2021)","10.1103/PhysRevA.103.042802",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The present constraint on the space parity ($\mathcal{P}$) and time
reflection invariance ($\mathcal{T}$) violating electron electric dipole moment
($e$EDM) is based on the observation of the electron spin precession in an
external electric field using the ThO molecule. We propose an alternative
approach: observation of the $\mathcal{P}$,~$\mathcal{T}$-odd Faraday effect in
an external electric field using the cavity-enhanced polarimetric scheme in
combination with a molecular beam crossing the cavity. Our theoretical
simulation of the proposed experiment with the PbF and ThO molecular beams
shows that the present constraint on the $e$EDM in principle can be improved by
a few orders of magnitude.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:28:13 GMT""}]","2021-04-07"
"2102.05158","Olivier Mila","Matilde Lal\'in and Olivier Mila","Hyperbolic Heron Triangles and Elliptic Curves","16 pages",,,,"math.NT math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define hyperbolic Heron triangles (hyperbolic triangles with ""rational""
side-lengths and area) and parametrize them in two ways as rational points of
certain elliptic curves. We show that there are infinitely many hyperbolic
Heron triangles with one angle $\alpha$ and area $A$ for any (admissible)
choice of $\alpha$ and $A$; in particular, the congruent number problem has
always infinitely many solutions in the hyperbolic setting. We also explore the
question of hyperbolic triangles with a rational median and a rational area
bisector (median splitting the triangle in half).
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:29:10 GMT""}]","2021-02-11"
"2102.05159","Kevin Wagner","K. Wagner, A. Boehle, P. Pathak, M. Kasper, R. Arsenault, G. Jakob, U.
  Kaufl, S. Leveratto, A.-L. Maire, E. Pantin, R. Siebenmorgen, G. Zins, O.
  Absil, N. Ageorges, D. Apai, A. Carlotti, \'E. Choquet, C. Delacroix, K.
  Dohlen, P. Duhoux, P. Forsberg, E. Fuenteseca, S. Gutruf, O. Guyon, E. Huby,
  D. Kampf, M. Karlsson, P. Kervella, J.-P. Kirchbauer, P. Klupar, J. Kolb, D.
  Mawet, M. N'Diaye, G. Orban de Xivry, S. P. Quanz, A. Reutlinger, G. Ruane,
  M. Riquelme, C. Soenke, M. Sterzik, A. Vigan, T. de Zeeuw","Imaging low-mass planets within the habitable zone of {\alpha} Centauri","29 pages, 11 figures, published in Nature Communications",,"10.1038/s41467-021-21176-6",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Giant exoplanets on wide orbits have been directly imaged around young stars.
If the thermal background in the mid-infrared can be mitigated, then exoplanets
with lower masses can also be imaged. Here we present a ground-based
mid-infrared observing approach that enables imaging low-mass temperate
exoplanets around nearby stars, and in particular within the closest stellar
system, Alpha Centauri. Based on 75-80% of the best quality images from 100
hours of cumulative observations, we demonstrate sensitivity to warm
sub-Neptune-sized planets throughout much of the habitable zone of Alpha
Centauri A. This is an order of magnitude more sensitive than state-of-the-art
exoplanet imaging mass detection limits. We also discuss a possible exoplanet
or exozodiacal disk detection around Alpha Centauri A. However, an instrumental
artifact of unknown origin cannot be ruled out. These results demonstrate the
feasibility of imaging rocky habitable-zone exoplanets with current and
upcoming telescopes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:32:58 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 19:41:42 GMT""}]","2021-04-15"
"2102.05160","Michael Kramer","M. Kramer, I.H. Stairs, V. Venkatraman Krishnan, P.C.C. Freire, F.
  Abbate, M. Bailes, M. Burgay, S. Buchner, D.J. Champion, I. Cognard, T.
  Gautam, M.Geyer, L. Guillemot, H. Hu, G. Janssen, M.E. Lower, A.
  Parthasarathy, A. Possenti, S. Ransom, D.J. Reardon, A. Ridolfi, M. Serylak,
  R.M. Shannon, R. Spiewak, G. Theureau, W. van Straten, N. Wex, L.S. Oswald,
  B. Posselt, C. Sobey, E.D. Barr, F. Camilo, B. Hugo, A. Jameson, S. Johnston,
  A. Karastergiou, M. Keith, S. Oslowski","The Relativistic Binary Programme on MeerKAT: Science objectives and
  first results","21 pages 16 figures, published in MNRAS (replaced earlier submission
  after small changes added in proofs)",,"10.1093/mnras/stab375",,"astro-ph.HE gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We describe the ongoing Relativistic Binary programme (RelBin), a part of the
MeerTime large survey project with the MeerKAT radio telescope. RelBin is
primarily focused on observations of relativistic effects in binary pulsars to
enable measurements of neutron star masses and tests of theories of gravity. We
selected 25 pulsars as an initial high priority list of targets based on their
characteristics and observational history with other telescopes. In this paper,
we provide an outline of the programme, present polarisation calibrated pulse
profiles for all selected pulsars as a reference catalogue along with updated
dispersion measures. We report Faraday rotation measures for 24 pulsars, twelve
of which have been measured for the first time. More than a third of our
selected pulsars show a flat position angle swing confirming earlier
observations. We demonstrate the ability of the Rotating Vector Model (RVM),
fitted here to seven binary pulsars, including the Double Pulsar (PSR
J0737$-$3039A), to obtain information about the orbital inclination angle. We
present a high time resolution light curve of the eclipse of PSR J0737$-$3039A
by the companion's magnetosphere, a high-phase resolution position angle swing
for PSR J1141$-$6545, an improved detection of the Shapiro delay of PSR
J1811$-$2405, and pulse scattering measurements for PSRs J1227$-$6208,
J1757$-$1854, and J1811$-$1736. Finally, we demonstrate that timing
observations with MeerKAT improve on existing data sets by a factor of,
typically, 2-3, sometimes by an order of magnitude.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:35:37 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 11:30:08 GMT""}]","2021-05-10"
"2102.05161","Yann Hamdaoui","Yann Hamdaoui and Beno\^it Valiron","An Interactive Proof of Termination for a Concurrent $\lambda$-calculus
  with References and Explicit Substitutions",,,,,"cs.LO cs.PL","http://creativecommons.org/licenses/by/4.0/","  In this paper we introduce a typed, concurrent $\lambda$-calculus with
references featuring explicit substitutions for variables and references.
Alongside usual safety properties, we recover strong normalization. The proof
is based on a reducibility technique and an original interactive property
reminiscent of the Game Semantics approach.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:35:54 GMT""}]","2021-02-11"
"2102.05162","Mahmoud Jafari","Ashkan Shekaari and Mahmoud Jafari","Thermodynamic equilibrium of biological macromolecules under mechanical
  constraints",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Equilibrating proteins and other biomacromolecules is cardinal for molecular
dynamics simulation of such biological systems in which they perform free
dynamics without any externally-applied mechanical constraint, until
thermodynamic equilibrium with the surrounding is attained. However, in some
important cases, we have to equilibrate the system of interest in the constant
presence of certain constraints, being referred to as constrained equilibration
in the present work. A clear illustration of this type is a single amyloid
\b{eta}-strand or RNA, when the reaction coordinate is defined as the distance
between the two ends of the strand and we are interested in carrying out
replica-exchange umbrella sampling to map the associated free energy profile as
the dependent quantity of interest. In such cases, each sample has to be
equilibrated with the two ends fixed. Here, we introduced a simulation trick to
perform this so-called constrained equilibration using steered molecular
dynamics. We then applied this method to equilibrate a single, stretched
\b{eta}-strand of an amyloid beta dodecamer fibril with fixed ends. Examining
the associated curves of the total energy and the force exerted on the
practically-fixed SMD atom over the total timespan broadly supported the
validity of this kind of equilibration.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:36:03 GMT""}]","2021-02-11"
"2102.05163","Will Perkins","Will Perkins and Changji Xu","Frozen $1$-RSB structure of the symmetric Ising perceptron",,,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove, under an assumption on the critical points of a real-valued
function, that the symmetric Ising perceptron exhibits the `frozen 1-RSB'
structure conjectured by Krauth and Mezard in the physics literature; that is,
typical solutions of the model lie in clusters of vanishing entropy density.
Moreover, we prove this in a very strong form conjectured by Huang, Wong, and
Kabashima: a typical solution of the model is isolated with high probability
and the Hamming distance to all other solutions is linear in the dimension. The
frozen 1-RSB scenario is part of a recent and intriguing explanation of the
performance of learning algorithms by Baldassi, Ingrosso, Lucibello, Saglietti,
and Zecchina. We prove this structural result by comparing the symmetric Ising
perceptron model to a planted model and proving a comparison result between the
two models. Our main technical tool towards this comparison is an inductive
argument for the concentration of the logarithm of number of solutions in the
model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:36:41 GMT""}]","2021-02-11"
"2102.05164","X. Flora Meng","X. Flora Meng, Tuhin Sarkar, Munther A. Dahleh","Nonstochastic Bandits with Infinitely Many Experts","Added numerical experiments",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of nonstochastic bandits with expert advice, extending
the setting from finitely many experts to any countably infinite set: A learner
aims to maximize the total reward by taking actions sequentially based on
bandit feedback while benchmarking against a set of experts. We propose a
variant of Exp4.P that, for finitely many experts, enables inference of correct
expert rankings while preserving the order of the regret upper bound. We then
incorporate the variant into a meta-algorithm that works on infinitely many
experts. We prove a high-probability upper bound of $\tilde{\mathcal{O}} \big(
i^*K + \sqrt{KT} \big)$ on the regret, up to polylog factors, where $i^*$ is
the unknown position of the best expert, $K$ is the number of actions, and $T$
is the time horizon. We also provide an example of structured experts and
discuss how to expedite learning in such case. Our meta-learning algorithm
achieves optimal regret up to polylog factors when $i^* = \tilde{\mathcal{O}}
\big( \sqrt{T/K} \big)$. If a prior distribution is assumed to exist for $i^*$,
the probability of optimality increases with $T$, the rate of which can be
fast.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:42:36 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 03:31:00 GMT""}]","2021-03-29"
"2102.05165","Francesco Paolo Maiale","Kennedy Obinna Idu and Francesco Paolo Maiale","$C^{1,\alpha}$-rectifiability in low codimension in Heisenberg groups","Corrected typos. Added more information in Section 2.1
  (preliminaries) and detailed proofs in Section 2.2. Added Lemma 3.3 and
  modified the main proof (Section 3.1) accordingly",,,,"math.MG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A natural notion of higher order rectifiability is introduced for subsets of
Heisenberg groups $\mathbb{H}^n$ in terms of covering a set almost everywhere
by a countable union of $(\mathbf{C}_H^{1,\alpha},\mathbb{H})$-regular
surfaces, for some $0 < \alpha \leq 1$. We prove that a sufficient condition
for $C^{1,\alpha}$-rectifiability of low-codimensional subsets in Heisenberg
groups is the almost everywhere existence of suitable approximate tangent
paraboloids.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:43:45 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 07:12:50 GMT""}]","2021-06-29"
"2102.05166","Kenan Uriostegui K. Uriostegui","Kenan Uriostegui and Kurt Bernardo Wolf","Discrete Bessel and Mathieu functions",,,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The two-dimensional Helmholtz equation separates in elliptic coordinates
based on two distinct foci, a limit case of which includes polar coordinate
systems when the two foci coalesce. This equation is invariant under the
Euclidean group of translations and orthogonal transformations; we replace the
latter by the discrete dihedral group of N discrete rotations and reflections.
The separation of variables in polar and elliptic coordinates is then used to
define discrete Bessel and Mathieu functions, as approximants to the well-known
continuous Bessel and Mathieu functions, as N-point Fourier transforms
approximate the Fourier transform over the circle, with integrals replaced by
finite sums. We find that these 'discrete' functions approximate the numerical
values of their continuous counterparts very closely and preserve some key
special function relations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:45:30 GMT""}]","2021-02-11"
"2102.05167","Edwin Goh","Edwin Goh, Hamsa Shwetha Venkataram, Mark Hoffmann, Mark Johnston,
  Brian Wilson","Scheduling the NASA Deep Space Network with Deep Reinforcement Learning",,,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With three complexes spread evenly across the Earth, NASA's Deep Space
Network (DSN) is the primary means of communications as well as a significant
scientific instrument for dozens of active missions around the world. A rapidly
rising number of spacecraft and increasingly complex scientific instruments
with higher bandwidth requirements have resulted in demand that exceeds the
network's capacity across its 12 antennae. The existing DSN scheduling process
operates on a rolling weekly basis and is time-consuming; for a given week,
generation of the final baseline schedule of spacecraft tracking passes takes
roughly 5 months from the initial requirements submission deadline, with
several weeks of peer-to-peer negotiations in between. This paper proposes a
deep reinforcement learning (RL) approach to generate candidate DSN schedules
from mission requests and spacecraft ephemeris data with demonstrated
capability to address real-world operational constraints. A deep RL agent is
developed that takes mission requests for a given week as input, and interacts
with a DSN scheduling environment to allocate tracks such that its reward
signal is maximized. A comparison is made between an agent trained using
Proximal Policy Optimization and its random, untrained counterpart. The results
represent a proof-of-concept that, given a well-shaped reward signal, a deep RL
agent can learn the complex heuristics used by experts to schedule the DSN. A
trained agent can potentially be used to generate candidate schedules to
bootstrap the scheduling process and thus reduce the turnaround cycle for DSN
scheduling.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:48:05 GMT""}]","2021-11-24"
"2102.05168","Ellis Hershkowitz","Bernhard Haeupler and D Ellis Hershkowitz and Goran Zuzic","Deterministic Tree Embeddings with Copies for Algorithms Against
  Adaptive Adversaries",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Embeddings of graphs into distributions of trees that preserve distances in
expectation are a cornerstone of many optimization algorithms. Unfortunately,
online or dynamic algorithms which use these embeddings seem inherently
randomized and ill-suited against adaptive adversaries.
  In this paper we provide a new tree embedding which addresses these issues by
deterministically embedding a graph into a single tree containing $O(\log n)$
copies of each vertex while preserving the connectivity structure of every
subgraph and $O(\log^2 n)$-approximating the cost of every subgraph.
  Using this embedding we obtain several new algorithmic results: We reduce an
open question of Alon et al. [SODA 2004] -- the existence of a deterministic
poly-log-competitive algorithm for online group Steiner tree on a general graph
-- to its tree case. We give a poly-log-competitive deterministic algorithm for
a closely related problem -- online partial group Steiner tree -- which,
roughly, is a bicriteria version of online group Steiner tree. Lastly, we give
the first poly-log approximations for demand-robust Steiner forest, group
Steiner tree and group Steiner forest.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:50:34 GMT""}]","2021-02-11"
"2102.05169","Eunsol Choi","Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski,
  Dipanjan Das, Michael Collins","Decontextualization: Making Sentences Stand-Alone","To appear in Transactions of the Association for Computational
  Linguistics (TACL)",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Models for question answering, dialogue agents, and summarization often
interpret the meaning of a sentence in a rich context and use that meaning in a
new context. Taking excerpts of text can be problematic, as key pieces may not
be explicit in a local window. We isolate and define the problem of sentence
decontextualization: taking a sentence together with its context and rewriting
it to be interpretable out of context, while preserving its meaning. We
describe an annotation procedure, collect data on the Wikipedia corpus, and use
the data to train models to automatically decontextualize sentences. We present
preliminary studies that show the value of sentence decontextualization in a
user facing task, and as preprocessing for systems that perform document
understanding. We argue that decontextualization is an important subtask in
many downstream applications, and that the definitions and resources provided
can benefit tasks that operate on sentences that occur in a richer context.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:52:37 GMT""}]","2021-02-11"
"2102.05170","Iosif Pinelis","Iosif Pinelis","Exact lower bound on an ""exactly one"" probability","6 pages; to appear in the Bulletin of the Australian Mathematical
  Society",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exact lower bound on the probability of the occurrence of exactly one of
$n$ random events each of probability $p$ is obtained.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:52:59 GMT""}]","2021-02-11"
"2102.05171","Shannon Ezzat","Shannon Ezzat, Scott Rodney","The Cognition of Counterexample in Mathematics Students",,,,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  Studying Mathematics requires a synthesis of skills from a multitude of
academic disciplines; logical reasoning being chief among them. This paper
explores mathematical logical preparedness of students entering first year
university mathematics courses and also the effectiveness of using logical
facility to predict successful course outcomes. We analyze data collected from
students enrolled at the University of Winnipeg in a pre-service course for
high school teachers. We do find that, being able to successfully answer
logical questions, both before and after intervention, are significant in
relation to improved student outcomes.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:53:42 GMT""}]","2021-02-11"
"2102.05172","Parastoo Sadeghi","Rafael G. L. D'Oliveira, Muriel Medard, Parastoo Sadeghi","Differential Privacy for Binary Functions via Randomized Graph Colorings","Submitted to IEEE ISIT 2021",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a framework for designing differentially private (DP) mechanisms
for binary functions via a graph representation of datasets. Datasets are nodes
in the graph and any two neighboring datasets are connected by an edge. The
true binary function we want to approximate assigns a value (or true color) to
a dataset. Randomized DP mechanisms are then equivalent to randomized colorings
of the graph. A key notion we use is that of the boundary of the graph. Any two
neighboring datasets assigned a different true color belong to the boundary.
  Under this framework, we show that fixing the mechanism behavior at the
boundary induces a unique optimal mechanism. Moreover, if the mechanism is to
have a homogeneous behavior at the boundary, we present a closed expression for
the optimal mechanism, which is obtained by means of a \emph{pullback}
operation on the optimal mechanism of a line graph. For balanced mechanisms,
not favoring one binary value over another, the optimal $(\epsilon,\delta)$-DP
mechanism takes a particularly simple form, depending only on the minimum
distance to the boundary, on $\epsilon$, and on $\delta$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:57:57 GMT""}]","2021-02-11"
"2102.05173","Bin Chen","Bin Chen (1), Marina Battaglia (2), S\""am Krucker (2), Katharine K.
  Reeves (3), Lindsay Glesener (4) ((1) New Jersey Institute of Technology, (2)
  University of Applied Sciences and Arts Northwestern Switzerland, (3)
  Harvard-Smithsonian Center for Astrophysics, (4) University of Minnesota,
  Twin Cities)","Energetic Electron Distribution of the Coronal Acceleration Region:
  First results from Joint Microwave and Hard X-ray Imaging Spectroscopy","12 pages, 5 figures, accepted for publication in The Astrophysical
  Journal Letters",,"10.3847/2041-8213/abe471",,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Nonthermal sources located above bright flare arcades, referred to as the
""above-the-loop-top"" sources, have been often suggested as the primary electron
acceleration site in major solar flares. The X8.2 limb flare on 2017 September
10 features such an above-the-loop-top source, which was observed in both
microwaves and hard X-rays (HXRs) by the Expanded Owens Valley Solar Array
(EOVSA) and the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI),
respectively. By combining the microwave and HXR imaging spectroscopy
observations with multi-filter extreme ultraviolet and soft X-ray imaging data,
we derive the energetic electron distribution of this source over a broad
energy range from $<$10 keV up to $\sim$MeV during the early impulsive phase of
the flare. The best-fit electron distribution consists of a thermal ""core"" from
$\sim$25 MK plasma. Meanwhile, a nonthermal power-law ""tail"" joins the thermal
core at $\sim$16 keV with a spectral index of $\sim$3.6, which breaks down at
above $\sim$160 keV to $>$6.0. In addition, temporally resolved analysis
suggests that the electron distribution above the break energy rapidly hardens
with the spectral index decreasing from $>$20 to $\sim$6.0 within 20 s, or less
than $\sim$10 Alfv\'{e}n crossing times in the source. These results provide
strong support for the above-the-loop-top source as the primary site where an
on-going bulk acceleration of energetic electrons is taking place very early in
the flare energy release.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:02:31 GMT""}]","2021-03-03"
"2102.05174","Daniel Liang","Aravind Gollakota and Daniel Liang","On the Hardness of PAC-learning Stabilizer States with Noise",,"Quantum 6, 640 (2022)","10.22331/q-2022-02-02-640","2022-02-02, volume 6, page 640","quant-ph cs.DS cs.LG","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of learning stabilizer states with noise in the
Probably Approximately Correct (PAC) framework of Aaronson (2007) for learning
quantum states. In the noiseless setting, an algorithm for this problem was
recently given by Rocchetto (2018), but the noisy case was left open. Motivated
by approaches to noise tolerance from classical learning theory, we introduce
the Statistical Query (SQ) model for PAC-learning quantum states, and prove
that algorithms in this model are indeed resilient to common forms of noise,
including classification and depolarizing noise. We prove an exponential lower
bound on learning stabilizer states in the SQ model. Even outside the SQ model,
we prove that learning stabilizer states with noise is in general as hard as
Learning Parity with Noise (LPN) using classical examples. Our results position
the problem of learning stabilizer states as a natural quantum analogue of the
classical problem of learning parities: easy in the noiseless setting, but
seemingly intractable even with simple forms of noise.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:06:54 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 16:10:33 GMT""},{""version"":""v3"",""created"":""Mon, 31 Jan 2022 16:24:17 GMT""}]","2022-02-09"
"2102.05175","Lingrui Ge Dr","Lingrui Ge, Yiqian Wang, Jiangong You and Xin Zhao","Transition space for the continuity of the Lyapunov exponent of
  quasiperiodic Schr\""odinger cocycles","27 pages",,,,"math.DS math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct discontinuous point of the Lyapunov exponent of quasiperiodic
Schr\""odinger cocycles in the Gevrey space $G^{s}$ with $s>2$. In contrast, the
Lyapunov exponent has been proved to be continuous in the Gevrey space $G^{s}$
with $s<2$ \cite{klein,cgyz}. This shows that $G^2$ is the transition space for
the continuity of the Lyapunov exponent.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:07:06 GMT""}]","2021-02-11"
"2102.05176","Tom\'a\v{s} Chobola","Tom\'a\v{s} Chobola, Daniel Va\v{s}ata, Pavel Kord\'ik","Transfer learning based few-shot classification using optimal transport
  mapping from preprocessed latent space of backbone neural network",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  MetaDL Challenge 2020 focused on image classification tasks in few-shot
settings. This paper describes second best submission in the competition. Our
meta learning approach modifies the distribution of classes in a latent space
produced by a backbone network for each class in order to better follow the
Gaussian distribution. After this operation which we call Latent Space
Transform algorithm, centers of classes are further aligned in an iterative
fashion of the Expectation Maximisation algorithm to utilize information in
unlabeled data that are often provided on top of few labelled instances. For
this task, we utilize optimal transport mapping using the Sinkhorn algorithm.
Our experiments show that this approach outperforms previous works as well as
other variants of the algorithm, using K-Nearest Neighbour algorithm, Gaussian
Mixture Models, etc.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:10:58 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:04:28 GMT""}]","2021-02-12"
"2102.05177","Francois Golse","Fran\c{c}ois Golse and Thierry Paul","Time Dependent Quantum Perturbations Uniform in the Semiclassical Regime","18 pages",,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We present a time dependent quantum perturbation result, uniform in the
Planck constant, for perturbations of potentials whose gradients are Lipschitz
continuous by potentials whose gradients are only bounded a.e.. Though this low
regularity of the full potential is not enough to provide the existence of the
classical underlying dynamics, at variance with the quantum one, our result
shows that the classical limit of the perturbed quantum dynamics remains in a
tubular neighbourhood of the classical unperturbed one of size of order of the
square root of the size of the perturbation. We treat both Schr\""odinger and
von Neumann-Heisenberg equations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:16:57 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 00:17:13 GMT""}]","2021-03-19"
"2102.05178","Miguel Lago","Miguel A. Lago and Craig K. Abbey and Miguel P. Eckstein","Medical Image Quality Metrics for Foveated Model Observers","24 pages, 5 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  A recently proposed model observer mimics the foveated nature of the human
visual system by processing the entire image with varying spatial detail,
executing eye movements and scrolling through slices. The model can predict how
human search performance changes with signal type and modality (2D vs. 3D), yet
its implementation is computationally expensive and time-consuming. Here, we
evaluate various image quality metrics using extensions of the classic index of
detectability expressions and assess foveated model observers for
location-known exactly tasks. We evaluated foveated extensions of a Channelized
Hotelling and Non-prewhitening model with an eye filter. The proposed methods
involve calculating a model index of detectability (d') for each retinal
eccentricity and combining these with a weighting function into a single
detectability metric. We assessed different versions of the weighting function
that varied in the required measurements of the human observers' search (no
measurements, eye movement patterns, and size of the image and median search
times). We show that the index of detectability across eccentricities weighted
using the eye movement patterns of observers best predicted human performance
in 2D vs. 3D search performance for a small microcalcification-like signal and
a larger mass-like. The metric with weighting function based on median search
times was the second best at predicting human results. The findings provide a
set of model observer tools to evaluate image quality in the early stages of
imaging system evaluation or design without implementing the more
computationally complex foveated search model.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:18:38 GMT""}]","2021-02-11"
"2102.05179","Bita Safaee","Bita Safaee and Serkan Gugercin","Structure-preserving Model Reduction of Parametric Power Networks",,,,,"eess.SY cs.CE cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a structure-preserving parametric model reduction approach for
linearized swing equations where parametrization corresponds to variations in
operating conditions. We employ a global basis approach to develop the
parametric reduced model in which we concatenate the local bases obtained via
$\mathcal{H}_2$-based interpolatory model reduction. The residue of the
underlying dynamics corresponding to the simple pole at zero varies with the
parameters. Therefore, to have bounded $\mathcal{H}_2$ and $\mathcal{H}_\infty$
errors, the reduced model residue for the pole at zero should match the
original one over the entire parameter domain. Our framework achieves this goal
by enriching the global basis based on a residue analysis. The effectiveness of
the proposed method is illustrated through two numerical examples.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:20:58 GMT""}]","2021-02-11"
"2102.05180","Ildar Gabitov","J. Gibney, I. A. Kuk and I. R. Gabitov","Pulse interactions in weakly nonlinear coherent optical communication
  links",,,"10.1088/1742-6596/1890/1/012006",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  The intrachannel interaction of pulses in weakly nonlinear coherent optical
fiber lines is theoretically investigated. It is shown that the main
contribution to the perturbation of the optical field comes from resonant
interactions of ordered triplets of pulses. The structure of triplets is
determined. The weight contributions of such interactions are calculated. A
classification of interactions using Loeschian numbers is proposed. Using
computer simulation, the dependence of the average energy of the optical field
perturbations on the distance is shown. Based on the performed analysis, an
effective algorithm is proposed for assessing the perturbations resulting from
intrachannel interaction.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:24:11 GMT""}]","2021-05-26"
"2102.05181","Yu Sun","Yu Sun, Jiaming Liu, Mingyang Xie, Brendt Wohlberg, Ulugbek S. Kamilov","CoIL: Coordinate-based Internal Learning for Imaging Inverse Problems",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  We propose Coordinate-based Internal Learning (CoIL) as a new deep-learning
(DL) methodology for the continuous representation of measurements. Unlike
traditional DL methods that learn a mapping from the measurements to the
desired image, CoIL trains a multilayer perceptron (MLP) to encode the complete
measurement field by mapping the coordinates of the measurements to their
responses. CoIL is a self-supervised method that requires no training examples
besides the measurements of the test object itself. Once the MLP is trained,
CoIL generates new measurements that can be used within a majority of image
reconstruction methods. We validate CoIL on sparse-view computed tomography
using several widely-used reconstruction methods, including purely model-based
methods and those based on DL. Our results demonstrate the ability of CoIL to
consistently improve the performance of all the considered methods by providing
high-fidelity measurement fields.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:29:07 GMT""}]","2021-02-11"
"2102.05182","Skanda Koppula","Skanda Koppula, Victor Bapst, Marc Huertas-Company, Sam Blackwell,
  Agnieszka Grabska-Barwinska, Sander Dieleman, Andrea Huber, Natasha
  Antropova, Mikolaj Binkowski, Hannah Openshaw, Adria Recasens, Fernando Caro,
  Avishai Deke, Yohan Dubois, Jesus Vega Ferrero, David C. Koo, Joel R.
  Primack, Trevor Back","A Deep Learning Approach for Characterizing Major Galaxy Mergers","Third Workshop on Machine Learning and the Physical Sciences (NeurIPS
  2020), Vancouver, Canada",,,,"astro-ph.GA cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fine-grained estimation of galaxy merger stages from observations is a key
problem useful for validation of our current theoretical understanding of
galaxy formation. To this end, we demonstrate a CNN-based regression model that
is able to predict, for the first time, using a single image, the merger stage
relative to the first perigee passage with a median error of 38.3 million years
(Myrs) over a period of 400 Myrs. This model uses no specific dynamical
modeling and learns only from simulated merger events. We show that our model
provides reasonable estimates on real observations, approximately matching
prior estimates provided by detailed dynamical modeling. We provide a
preliminary interpretability analysis of our models, and demonstrate first
steps toward calibrated uncertainty estimation.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:30:15 GMT""}]","2021-02-11"
"2102.05184","Francois Golse","Fran\c{c}ois Golse and Thierry Paul","Quantum and Semiquantum Pseudometrics and Applications","33 pages, no figure",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We establish a Kantorovich duality for the pseudometric $\mathcal{E}_\hbar$
introduced in [F. Golse, T. Paul, Arch. Rational Mech. Anal. 223 (2017),
57--94], obtained from the usual Monge-Kantorovich distance $d_{MK,2}$ between
classical densities by quantization of one of the two densities involved. We
show several type of inequalities comparing $d_{MK,2}$, $\mathcal{E}_\hbar$ and
$MK_\hbar$, a full quantum analogue of $d_{MK,2}$ introduced in [F. Golse, C.
Mouhot, T. Paul, Commun. Math. Phys. 343 (2016), 165--205], including an up to
$\hbar$ triangle inequality for $MK_\hbar$. Finally, we show that, when nice
optimal Kantorovich potentials exist for $\mathcal{E}_\hbar$, optimal couplings
induce classical/quantum optimal transports and the potentials are linked by a
semiquantum Legendre type transform.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:33:02 GMT""}]","2021-02-11"
"2102.05185","Andrew Ross","Andrew Slavin Ross and Finale Doshi-Velez","Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement","ICML 2021 paper, fixed incorrect version upload",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In representation learning, there has been recent interest in developing
algorithms to disentangle the ground-truth generative factors behind a dataset,
and metrics to quantify how fully this occurs. However, these algorithms and
metrics often assume that both representations and ground-truth factors are
flat, continuous, and factorized, whereas many real-world generative processes
involve rich hierarchical structure, mixtures of discrete and continuous
variables with dependence between them, and even varying intrinsic
dimensionality. In this work, we develop benchmarks, algorithms, and metrics
for learning such hierarchical representations.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:34:24 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 15:22:16 GMT""},{""version"":""v3"",""created"":""Fri, 7 Jan 2022 19:27:38 GMT""},{""version"":""v4"",""created"":""Fri, 8 Apr 2022 12:48:03 GMT""}]","2022-04-11"
"2102.05186","Elijah Bodish","Elijah Bodish","Triple clasp formulas for $C_2$ webs","30 pages, many color figures, v.2 simplified some arguments v.3 nicer
  looking diagrams, expanded introduction",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the light ladder basis for Kuperberg's $C_2$ webs, we derive triple
clasp formulas for idempotents projecting to the top summand in each tensor
product of fundamental representations. We then find explicit formulas for the
coefficients occurring in the clasps, by computing these coefficients as local
intersection forms. Our formulas provide further evidence for Elias's clasp
conjecture, which was given for type $A$ webs, and suggests how to generalize
the conjecture to non-simply laced types.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:38:20 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 04:39:22 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 13:49:30 GMT""}]","2022-04-26"
"2102.05187","Luanzheng Guo","Ruiqin Tian, Luanzheng Guo, Jiajia Li, Bin Ren, Gokcen Kestor","A High-Performance Sparse Tensor Algebra Compiler in Multi-Level IR",,,,,"cs.DC cs.PL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Tensor algebra is widely used in many applications, such as scientific
computing, machine learning, and data analytics. The tensors represented
real-world data are usually large and sparse. There are tens of storage formats
designed for sparse matrices and/or tensors and the performance of sparse
tensor operations depends on a particular architecture and/or selected sparse
format, which makes it challenging to implement and optimize every tensor
operation of interest and transfer the code from one architecture to another.
We propose a tensor algebra domain-specific language (DSL) and compiler
infrastructure to automatically generate kernels for mixed sparse-dense tensor
algebra operations, named COMET. The proposed DSL provides high-level
programming abstractions that resemble the familiar Einstein notation to
represent tensor algebra operations. The compiler performs code optimizations
and transformations for efficient code generation while covering a wide range
of tensor storage formats. COMET compiler also leverages data reordering to
improve spatial or temporal locality for better performance. Our results show
that the performance of automatically generated kernels outperforms the
state-of-the-art sparse tensor algebra compiler, with up to 20.92x, 6.39x, and
13.9x performance improvement, for parallel SpMV, SpMM, and TTM over TACO,
respectively.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:43:53 GMT""}]","2021-02-11"
"2102.05188","Adam Dziedzic","Christopher A. Choquette-Choo, Natalie Dullerud, Adam Dziedzic,
  Yunxiang Zhang, Somesh Jha, Nicolas Papernot, Xiao Wang","CaPC Learning: Confidential and Private Collaborative Learning","Published as a conference paper at ICLR 2021",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning benefits from large training datasets, which may not always
be possible to collect by any single entity, especially when using
privacy-sensitive data. In many contexts, such as healthcare and finance,
separate parties may wish to collaborate and learn from each other's data but
are prevented from doing so due to privacy regulations. Some regulations
prevent explicit sharing of data between parties by joining datasets in a
central location (confidentiality). Others also limit implicit sharing of data,
e.g., through model predictions (privacy). There is currently no method that
enables machine learning in such a setting, where both confidentiality and
privacy need to be preserved, to prevent both explicit and implicit sharing of
data. Federated learning only provides confidentiality, not privacy, since
gradients shared still contain private information. Differentially private
learning assumes unreasonably large datasets. Furthermore, both of these
learning paradigms produce a central model whose architecture was previously
agreed upon by all parties rather than enabling collaborative learning where
each party learns and improves their own local model. We introduce Confidential
and Private Collaborative (CaPC) learning, the first method provably achieving
both confidentiality and privacy in a collaborative setting. We leverage secure
multi-party computation (MPC), homomorphic encryption (HE), and other
techniques in combination with privately aggregated teacher models. We
demonstrate how CaPC allows participants to collaborate without having to
explicitly join their training sets or train a central model. Each party is
able to improve the accuracy and fairness of their model, even in settings
where each party has a model that performs well on their own dataset or when
datasets are not IID and model architectures are heterogeneous across parties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:50:24 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 19:31:05 GMT""}]","2021-03-23"
"2102.05189","Quang Tuan Dang","Quang-Tuan Dang","Pluripotential Monge-Amp{\`e}re flows in Big Cohomology Classes","47 pages, to appear in J. Funct. Anal",,"10.1016/j.jfa.2021.109373",,"math.DG math.AP math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study pluripotential complex Monge-Amp\`ere flows in big cohomology
classes on compact K{\""a}hler manifolds. We use the Perron method, considering
pluripotential subsolutions to the Cauchy problem. We prove that, under natural
assumptions on the data, the upper envelope of all subsolutions is continuous
in space and semi-concave in time, and provides a unique pluripotential
solution with such regularity. We apply this theory to study pluripotential
K{\""a}hler-Ricci flows on compact K{\""a}hler manifolds of general type as well
as on stable varieties.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:52:59 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 13:55:02 GMT""},{""version"":""v3"",""created"":""Mon, 3 Jan 2022 15:33:10 GMT""}]","2022-01-04"
"2102.05190","Nima Rasekh","Nima Rasekh","Cartesian Fibrations of Complete Segal Spaces","27 Pages. Updated references. Comments welcome. arXiv admin note:
  text overlap with arXiv:1711.03670",,,,"math.CT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cartesian fibrations were originally defined by Lurie in the context of
quasi-categories and are commonly used in $(\infty,1)$-category theory to study
presheaves valued in $(\infty,1)$-categories. In this work we define and study
fibrations modeling presheaves valued in simplicial spaces and their
localizations. This includes defining a model structure for these fibrations
and giving effective tools to recognize its fibrations and weak equivalences.
This in particular gives us a new method to construct Cartesian fibrations via
complete Segal spaces. In addition to that, it allows us to define and study
fibrations modeling presheaves of Segal spaces.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:53:36 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 06:58:55 GMT""}]","2021-02-12"
"2102.05191","Wenhao Li","Wenhao Li, Niranjan Bidargaddi, John Fouyaxis","DHLink: A Microservice Platform supporting Rapid Application Development
  and Secure Real-time Data Sharing in Digital Health","12 pages",,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Digital health applications that leverage multiple sources of patient data
for insights to patients' behaviours or disease symptoms as well as remote
patient monitoring, nudging and treatments are becoming increasingly popular in
various medical practices and research. One common issue among these
applications is that they are generally based on project-specific solutions and
developed from scratch. Such application development fashion results in large
amounts of repetitive effort, for example, in building study specific websites
and mobile frontends, deploying customised infrastructures, and collecting data
that may have already been collected in other studies and projects. What is
worse, the data collected, and functions built cannot be easily reused by other
applications. In this paper, we present an event-driven microservice platform,
namely DHLink, to address this issue. DHLink securely links existing digital
health applications of different projects, facilitates real-time data sharing,
and supports rapid application development by reusing data and functions of
existing digital health applications. In addition, comes with DHLink, a set of
highly generic and reusable microservices is provided, which allows developers
to rapidly create a typical above-mentioned digital health application by only
developing the core algorithms. Two use cases outlined in this paper have shown
the use of DHLink and the set of microservices for application collaboration
and new application development to be efficient and practical.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:55:16 GMT""}]","2021-02-11"
"2102.05192","Nima Rasekh","Nima Rasekh","Quasi-Categories vs. Segal Spaces: Cartesian Edition","Final version, Published in Journal of Homotopy and Related
  Structures",,"10.1007/s40062-021-00288-2",,"math.CT math.AT","http://creativecommons.org/licenses/by/4.0/","  We prove that four different ways of defining Cartesian fibrations and the
Cartesian model structure are all Quillen equivalent: On marked simplicial
sets, on bisimplicial spaces, on bisimplicial sets, on marked simplicial
spaces. The main way to prove these equivalences is by using the Quillen
equivalences between quasi-categories and complete Segal spaces as defined by
Joyal-Tierney and the straightening construction due to Lurie.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 07:02:43 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 20:52:47 GMT""}]","2021-08-24"
"2102.05193","Christopher Raymond","Christopher Raymond, David Ridout, Jorgen Rasmussen","Staggered modules of $N=2$ superconformal minimal models","25 pages, 10 figures, comments are welcome.V2 corrected typos,
  improved arguments in section 5.2","Nucl. Phys. B 967 (2021) 115397","10.1016/j.nuclphysb.2021.115397",,"hep-th math-ph math.MP math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a class of reducible yet indecomposable modules over the $N=2$
superconformal algebras. These so-called staggered modules exhibit a
non-diagonalisable action of the Virasoro mode $L_{0}$. Using recent results on
the coset construction of $N=2$ minimal models, we explicitly construct such
modules for central charges $c = -1$ and $c = -6$. We also describe
spectral-flow orbits and symmetries of the families of staggered modules which
arise via the coset.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:04:58 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 04:03:12 GMT""}]","2021-04-23"
"2102.05194","Kuan-Jung Chiang","Kuan-Jung Chiang, Chun-Shu Wei, Masaki Nakanishi and Tzyy-Ping Jung","Boosting Template-based SSVEP Decoding by Cross-domain Transfer Learning","Mirror version of the manuscript in the Journal of Neural Engineering
  on IOP Science
  (https://iopscience.iop.org/article/10.1088/1741-2552/abcb6e/meta), Journal
  of Neural Engineering (2020)",,"10.1088/1741-2552/abcb6e",,"cs.LG eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective: This study aims to establish a generalized transfer-learning
framework for boosting the performance of steady-state visual evoked potential
(SSVEP)-based brain-computer interfaces (BCIs) by leveraging cross-domain data
transferring. Approach: We enhanced the state-of-the-art template-based SSVEP
decoding through incorporating a least-squares transformation (LST)-based
transfer learning to leverage calibration data across multiple domains
(sessions, subjects, and EEG montages). Main results: Study results verified
the efficacy of LST in obviating the variability of SSVEPs when transferring
existing data across domains. Furthermore, the LST-based method achieved
significantly higher SSVEP-decoding accuracy than the standard task-related
component analysis (TRCA)-based method and the non-LST naive transfer-learning
method. Significance: This study demonstrated the capability of the LST-based
transfer learning to leverage existing data across subjects and/or devices with
an in-depth investigation of its rationale and behavior in various
circumstances. The proposed framework significantly improved the SSVEP decoding
accuracy over the standard TRCA approach when calibration data are limited. Its
performance in calibration reduction could facilitate plug-and-play SSVEP-based
BCIs and further practical applications.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:14:06 GMT""}]","2021-02-11"
"2102.05195","Hyun Bin Lee","Hyun Bin Lee (1), Tushar M. Jois (2), Christopher W. Fletcher (1),
  Carl A. Gunter (1) ((1) University of Illinois at Urbana-Champaign, (2) Johns
  Hopkins University)","DOVE: A Data-Oblivious Virtual Environment","Appears in the proceedings of the 28th Network and Distributed System
  Security Symposium (NDSS), 2021",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Users can improve the security of remote communications by using Trusted
Execution Environments (TEEs) to protect against direct introspection and
tampering of sensitive data. This can even be done with applications coded in
high-level languages with complex programming stacks such as R, Python, and
Ruby. However, this creates a trade-off between programming convenience versus
the risk of attacks using microarchitectural side channels.
  In this paper, we argue that it is possible to address this problem for
important applications by instrumenting a complex programming environment (like
R) to produce a Data-Oblivious Transcript (DOT) that is explicitly designed to
support computation that excludes side channels. Such a transcript is then
evaluated on a Trusted Execution Environment (TEE) containing the sensitive
data using a small trusted computing base called the Data-Oblivious Virtual
Environment (DOVE).
  To motivate the problem, we demonstrate a number of subtle side-channel
vulnerabilities in the R language. We then provide an illustrative design and
implementation of DOVE for R, creating the first side-channel resistant R
programming stack. We demonstrate that the two-phase architecture provided by
DOT generation and DOVE evaluation can provide practical support for complex
programming languages with usable performance and high security assurances
against side channels.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:15:29 GMT""}]","2021-02-11"
"2102.05196","Ian Goldberg","Rob Jansen, Justin Tracey, Ian Goldberg","Once is Never Enough: Foundations for Sound Statistical Inference in Tor
  Network Experimentation",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tor is a popular low-latency anonymous communication system that focuses on
usability and performance: a faster network will attract more users, which in
turn will improve the anonymity of everyone using the system. The standard
practice for previous research attempting to enhance Tor performance is to draw
conclusions from the observed results of a single simulation for standard Tor
and for each research variant. But because the simulations are run in sampled
Tor networks, it is possible that sampling error alone could cause the observed
effects. Therefore, we call into question the practical meaning of any
conclusions that are drawn without considering the statistical significance of
the reported results.
  In this paper, we build foundations upon which we improve the Tor
experimental method. First, we present a new Tor network modeling methodology
that produces more representative Tor networks as well as new and improved
experimentation tools that run Tor simulations faster and at a larger scale
than was previously possible. We showcase these contributions by running
simulations with 6,489 relays and 792k simultaneously active users, the largest
known Tor network simulations and the first at a network scale of 100%. Second,
we present new statistical methodologies through which we: (i) show that
running multiple simulations in independently sampled networks is necessary in
order to produce informative results; and (ii) show how to use the results from
multiple simulations to conduct sound statistical inference. We present a case
study using 420 simulations to demonstrate how to apply our methodologies to a
concrete set of Tor experiments and how to analyze the results.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:28:57 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 18:50:28 GMT""}]","2021-03-26"
"2102.05197","Michael Kane","Jonathan Cohen, Michael Kane, Alexia Marriott, Franklin Ollivierre
  III, and Krissy Govertsen","Economic controls co-design of hybrid microgrids with tidal/PV
  generation and lithium ion/flow battery storage","21 pages, 6 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Islanded microgrids powered by renewable energy require costly energy storage
systems due to the uncontrollable generators. Energy storage needs are
amplified when load and generation are misaligned on hourly, monthly, or
seasonal timescales. Diversification of both loads and generation can smooth
out such mismatches. The ideal type of battery to smooth out remaining
generation deficits will depend on the duration(s) that energy is stored. This
study presents a controls co-design approach to design an islanded microgrid,
showing the benefit of hybridizing tidal and solar generation and hybridizing
lithium-ion and flow battery energy storage. The optimization of the
microgrid's levelized cost of energy is initially studied in grid-search slices
to understand convexity and smoothness, then a particle swarm optimization is
proposed and used to study the sensitivity of the hybrid system configuration
to variations in component costs. The study highlights the benefits of controls
co-design, the need to model premature battery failure, and the importance of
using battery cost models that are applicable across orders of magnitude
variations in energy storage durations. The results indicate that such a hybrid
microgrid would currently produce energy at five times the cost of diesel
generation, but flow battery innovations could bring this closer to only twice
the cost while using 100% renewable energy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:37:34 GMT""}]","2021-02-11"
"2102.05198","Tesi Xiao","Yanhao Jin, Tesi Xiao, Krishnakumar Balasubramanian","Statistical Inference for Polyak-Ruppert Averaged Zeroth-order
  Stochastic Gradient Algorithm",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical machine learning models trained with stochastic gradient
algorithms are increasingly being deployed in critical scientific applications.
However, computing the stochastic gradient in several such applications is
highly expensive or even impossible at times. In such cases, derivative-free or
zeroth-order algorithms are used. An important question which has thus far not
been addressed sufficiently in the statistical machine learning literature is
that of equipping stochastic zeroth-order algorithms with practical yet
rigorous inferential capabilities so that we not only have point estimates or
predictions but also quantify the associated uncertainty via confidence
intervals or sets. Towards this, in this work, we first establish a central
limit theorem for Polyak-Ruppert averaged stochastic zeroth-order gradient
algorithm. We then provide online estimators of the asymptotic covariance
matrix appearing in the central limit theorem, thereby providing a practical
procedure for constructing asymptotically valid confidence sets (or intervals)
for parameter estimation (or prediction) in the zeroth-order setting.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:47:20 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 21:22:39 GMT""},{""version"":""v3"",""created"":""Sun, 14 Nov 2021 19:56:32 GMT""}]","2021-11-16"
"2102.05199","Igor Rizaev","Igor G. Rizaev, Oktay Karakus, S. John Hogan, Alin Achim","Modeling and SAR Imaging of the Sea Surface: a Review of the
  State-of-the-Art with Simulations",,,,,"physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Among other remote sensing technologies, synthetic aperture radar (SAR) has
become firmly established in the practice of oceanographic research. Despite
solid experience in this field, comprehensive knowledge and interpretation of
ocean/sea and vessel wave signatures on radar images are still very
challenging. Many technical parameters and scanning conditions vary for
different SAR platforms, which also imposes some restrictions on the
cross-analysis of their respective images. Numerical simulation of SAR images
allows the analysis of many radar imaging parameters including environmental,
ship, or platform related. In this paper, we present a universal simulation
framework for SAR imagery of the sea surface, which includes the superposition
of sea-ship waves. This paper is the first attempt to cover exhaustively all
SAR imaging effects for the sea waves and ship wakes scene. The study is based
on well proven concepts: the linear theory of sea surface modeling, Michell
thin-ship theory for Kelvin wake modeling, and ocean SAR imaging theory. We
demonstrate the role of two main factors that affect imaging of both types of
waves: (i) SAR parameters and (ii) Hydrodynamic related parameters such as wind
state and Froude number. The SAR parameters include frequency, signal
polarization, mean incidence angle, image resolution, variation by scanning
platform (airborne or spaceborne) of the range-to-velocity (R/V) ratio, and
velocity bunching with associated shifting, smearing and azimuthal cutoff
effects. We perform modeling for five wave frequency spectra and four ship
models. We also compare spectra in two aspects: with Cox and Munk's probability
density function (PDF), and with a novel proposed evaluation of ship wake
detectability. The simulation results agree well with SAR imaging theory. The
study gives a fuller understanding of radar imaging mechanisms for sea waves
and ship wakes.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:47:38 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 11:55:58 GMT""}]","2022-01-26"
"2102.05200","Jiangyong Jia","Chunjian Zhang, Arabinda Behera, Somadutta Bhatta and Jiangyong Jia","Non-flow effects in correlation between harmonic flow and transverse
  momentum in nuclear collisions","9 pages, 8 figures including an appendix, replace with published
  version",,"10.1016/j.physletb.2021.136702",,"nucl-th hep-ph nucl-ex","http://creativecommons.org/licenses/by-sa/4.0/","  A large anti-correlation signal between elliptic flow $v_2$ and average
transverse momentum $[p_{\mathrm{T}}]$ was recently measured in small collision
systems, consistent with a final-state hydrodynamic response to the initial
geometry. This negative $v_2$-$[p_{\mathrm{T}}]$ correlation was predicted to
change to positive correlation for events with very small charged particle
multiplicity $N_{\mathrm{ch}}$ due to initial-state momentum anisotropies of
the gluon saturation effects. However, the role of non-flow correlations is
expected to be important in these systems, which is not yet studied. We
estimate the non-flow effects in $pp$, $p$Pb and peripheral PbPb collisions
using {\tt Pythia} and {\tt Hijing} models, and compare them with the
experimental data. We show that the non-flow effects are largely suppressed
using the rapidity-separated subevent cumulant method (details of the cumulant
framework are also provided). The magnitude of the residual non-flow is much
less than the experimental observation in the higher $N_{\mathrm{ch}}$ region,
supporting the final-state response interpretation. In the very low
$N_{\mathrm{ch}}$ region, however, the sign and magnitude of the residual
non-flow depend on the model details. Therefore, it is unclear at this moment
whether the sign change of $v_2$-$[p_{\mathrm{T}}]$ can serve as evidence for
initial state momentum anisotropies predicted by the gluon saturation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:47:40 GMT""},{""version"":""v2"",""created"":""Sun, 2 Jan 2022 18:48:06 GMT""}]","2022-01-04"
"2102.05201","Eman AlOmar","Eman Abdullah AlOmar, Hussein AlRubaye, Mohamed Wiem Mkaouer, Ali
  Ouni, Marouane Kessentini","Refactoring Practices in the Context of Modern Code Review: An
  Industrial Case Study at Xerox",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern code review is a common and essential practice employed in both
industrial and open-source projects to improve software quality, share
knowledge, and ensure conformance with coding standards. During code review,
developers may inspect and discuss various changes including refactoring
activities before merging code changes in the codebase. To date, code review
has been extensively studied to explore its general challenges, best practices
and outcomes, and socio-technical aspects. However, little is known about how
refactoring activities are being reviewed, perceived, and practiced. This study
aims to reveal insights into how reviewers develop a decision about accepting
or rejecting a submitted refactoring request, and what makes such review
challenging. We present an industrial case study with 24 professional
developers at Xerox. Particularly, we study the motivations, documentation
practices, challenges, verification, and implications of refactoring activities
during code review. Our study delivers several important findings. Our results
report the lack of a proper procedure to follow by developers when documenting
their refactorings for review. Our survey with reviewers has also revealed
several difficulties related to understanding the refactoring intent and
implications on the functional and non-functional aspects of the software. In
light of our findings, we recommended a procedure to properly document
refactoring activities, as part of our survey feedback.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:54:30 GMT""}]","2021-02-11"
"2102.05202","Ilton Ferreira De Menezes","Romildo Pina, Ilton Menezes, Lucyjane Silva","Rigity results on $\rho$-Einstein solitons with zero scalar curvature","16 pages. arXiv admin note: text overlap with arXiv:2010.06729",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that a $\rho$-Einstein solitons conformal to a
pseudo-Euclidean space, invariant under the action of the pseudo-orthogonal
group with zero scalar curvature is stady and consequently flat. How
application of the results obtained we present an explicit example for a the
question proposed by Kazdan in [17].
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:57:41 GMT""}]","2021-02-11"
"2102.05203","T. S. Mahesh Dr.","T S Mahesh, Deepak Khurana, Krithika V R, Sreejith G J, and C S
  Sudheer Kumar","Star-topology Registers: NMR and Quantum Information Perspectives","15 pages, 10 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum control of large spin registers is crucial for many applications
ranging from spectroscopy to quantum information. A key factor that determines
the efficiency of a register for implementing a given information processing
task is its network topology. One particular type, called star-topology,
involves a central qubit uniformly interacting with a set of ancillary qubits.
A particular advantage of the star-topology quantum registers is in the
efficient preparation of large entangled states, called NOON states, and their
generalized variants. Thanks to the robust generation of such correlated
states, spectral simplicity, ease of polarization transfer from ancillary
qubits to the central qubit, as well as the availability of large
spin-clusters, the star-topology registers have been utilized for several
interesting applications over the last few years. Here we review some recent
progress with the star-topology registers, particularly via nuclear magnetic
resonance methods.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:58:16 GMT""}]","2021-02-11"
"2102.05204","Tongping Liu","Xin Zhao (University of Massachusetts Amherst), Jin Zhou (University
  of Massachusetts Amherst), Hui Guan (University of Massachusetts Amherst),
  Wei Wang (University of Texas at San Antonio), Xu Liu (North Carolina State
  University), Tongping Liu (University of Massachusetts Amherst)","NumaPerf: Predictive and Full NUMA Profiling",,,,,"cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Parallel applications are extremely challenging to achieve the optimal
performance on the NUMA architecture, which necessitates the assistance of
profiling tools. However, existing NUMA-profiling tools share some similar
shortcomings, such as portability, effectiveness, and helpfulness issues. This
paper proposes a novel profiling tool - NumaPerf - that overcomes these issues.
NumaPerf aims to identify potential performance issues for any NUMA
architecture, instead of only on the current hardware. To achieve this,
NumaPerf focuses on memory sharing patterns between threads, instead of real
remote accesses. NumaPerf further detects potential thread migrations and load
imbalance issues that could significantly affect the performance but are
omitted by existing profilers. NumaPerf also separates cache coherence issues
that may require different fix strategies. Based on our extensive evaluation,
NumaPerf is able to identify more performance issues than any existing tool,
while fixing these bugs leads to up to 5.94x performance speedup.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:07:41 GMT""}]","2021-02-11"
"2102.05205","Arkady Kitover","Arkady Kitover and Mehmet Orhon","Spectrum of Weighted Composition Operators Part VII Essential spectra of
  weighted composition operators on $C(K)$. The case of non-invertible
  homeomorphisms","arXiv admin note: text overlap with arXiv:2009.09303",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a complete description of the spectrum and the essential spectra
of weighted composition operators $T=wT_\varphi$ on $C(K)$ in the case when the
map $\varphi$ is a non-invertible homeomorphism of $K$ into itself.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:15:03 GMT""}]","2021-02-11"
"2102.05206","Malcolm Connolly","Vivek Chidambaram, Anders Kringh{\o}j, Lucas Casparis, Ferdinand
  Kuemmeth, Tiantian Wang, Candice Thomas, Sergei Gronin, Geoffrey C. Gardner,
  Zhengyi Cui, Chenlu Liu, Kristof Moors, Michael J. Manfra, Karl D. Petersson,
  Malcolm R. Connolly","Microwave Sensing of Andreev Bound States in a Gate-Defined
  Superconducting Quantum Point Contact",,"Phys. Rev. Research 4, 023170 (2022)","10.1103/PhysRevResearch.4.023170","NBI QDEV 2021","cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We use a superconducting microresonator as a cavity to sense absorption of
microwaves by a superconducting quantum point contact defined by surface gates
over a proximitized two-dimensional electron gas. Renormalization of the cavity
frequency with phase difference across the point contact is consistent with
adiabatic coupling to Andreev bound states. Near $\pi$ phase difference, we
observe random fluctuations in absorption with gate voltage, related to quantum
interference-induced modulations in the electron transmission. We identify
features consistent with the presence of single Andreev bound states and
describe the Andreev-cavity interaction using a dispersive Jaynes-Cummings
model. By fitting the weak Andreev-cavity coupling, we extract ~GHz decoherence
consistent with charge noise and the transmission dispersion associated with a
localized state.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:17:21 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 15:06:10 GMT""}]","2022-10-19"
"2102.05207","Zhangjie Cao","Zhangjie Cao and Minae Kwon and Dorsa Sadigh","Transfer Reinforcement Learning across Homotopy Classes","Accepted by IEEE Robotics and Automation Letters 2021",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability for robots to transfer their learned knowledge to new tasks --
where data is scarce -- is a fundamental challenge for successful robot
learning. While fine-tuning has been well-studied as a simple but effective
transfer approach in the context of supervised learning, it is not as
well-explored in the context of reinforcement learning. In this work, we study
the problem of fine-tuning in transfer reinforcement learning when tasks are
parameterized by their reward functions, which are known beforehand. We
conjecture that fine-tuning drastically underperforms when source and target
trajectories are part of different homotopy classes. We demonstrate that
fine-tuning policy parameters across homotopy classes compared to fine-tuning
within a homotopy class requires more interaction with the environment, and in
certain cases is impossible. We propose a novel fine-tuning algorithm,
Ease-In-Ease-Out fine-tuning, that consists of a relaxing stage and a
curriculum learning stage to enable transfer learning across homotopy classes.
Finally, we evaluate our approach on several robotics-inspired simulated
environments and empirically verify that the Ease-In-Ease-Out fine-tuning
method can successfully fine-tune in a sample-efficient way compared to
existing baselines.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:18:24 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 02:00:51 GMT""},{""version"":""v3"",""created"":""Sun, 8 Aug 2021 23:09:00 GMT""}]","2021-08-10"
"2102.05208","Kuilin Chen","Kuilin Chen, Chi-Guhn Lee","Attentive Gaussian processes for probabilistic time-series generation",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The transduction of sequence has been mostly done by recurrent networks,
which are computationally demanding and often underestimate uncertainty
severely. We propose a computationally efficient attention-based network
combined with the Gaussian process regression to generate real-valued sequence,
which we call the Attentive-GP. The proposed model not only improves the
training efficiency by dispensing recurrence and convolutions but also learns
the factorized generative distribution with Bayesian representation. However,
the presence of the GP precludes the commonly used mini-batch approach to the
training of the attention network. Therefore, we develop a block-wise training
algorithm to allow mini-batch training of the network while the GP is trained
using full-batch, resulting in a scalable training method. The algorithm has
been proved to converge and shows comparable, if not better, quality of the
found solution. As the algorithm does not assume any specific network
architecture, it can be used with a wide range of hybrid models such as neural
networks with kernel machine layers in the scarcity of resources for
computation and memory.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:19:15 GMT""}]","2021-02-11"
"2102.05209","Mohsen Heidari","Mohsen Heidari and Wojciech Szpankowski","Learning k-qubit Quantum Operators via Pauli Decomposition","AISTATS'23",,,,"quant-ph cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the limited qubit capacity of current quantum systems, we study
the quantum sample complexity of $k$-qubit quantum operators, i.e., operations
applicable on only $k$ out of $d$ qubits. The problem is studied according to
the quantum probably approximately correct (QPAC) model abiding by quantum
mechanical laws such as no-cloning, state collapse, and measurement
incompatibility. With the delicacy of quantum samples and the richness of
quantum operations, one expects a significantly larger quantum sample
complexity.
  This paper proves the contrary. We show that the quantum sample complexity of
$k$-qubit quantum operations is comparable to the classical sample complexity
of their counterparts (juntas), at least when $\frac{k}{d}\ll 1$. This is
surprising, especially since sample duplication is prohibited, and measurement
incompatibility would lead to an exponentially larger sample complexity with
standard methods. Our approach is based on the Pauli decomposition of quantum
operators and a technique that we name Quantum Shadow Sampling (QSS) to reduce
the sample complexity exponentially. The results are proved by developing (i) a
connection between the learning loss and the Pauli decomposition; (ii) a
scalable QSS circuit for estimating the Pauli coefficients; and (iii) a quantum
algorithm for learning $k$-qubit operators with sample complexity
$O(\frac{k4^k}{\epsilon^2}\log d)$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:20:55 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 16:38:59 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 22:11:47 GMT""},{""version"":""v4"",""created"":""Mon, 24 Apr 2023 19:50:31 GMT""}]","2023-04-26"
"2102.05210","Guanglei Zhang","Xiangyu Zhao, Peng Zhang, Fan Song, Guangda Fan, Yangyang Sun, Yujia
  Wang, Zheyuan Tian, Luqi Zhang, Guanglei Zhang","D2A U-Net: Automatic Segmentation of COVID-19 Lesions from CT Slices
  with Dilated Convolution and Dual Attention Mechanism",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Coronavirus Disease 2019 (COVID-19) has caused great casualties and becomes
almost the most urgent public health events worldwide. Computed tomography (CT)
is a significant screening tool for COVID-19 infection, and automated
segmentation of lung infection in COVID-19 CT images will greatly assist
diagnosis and health care of patients. However, accurate and automatic
segmentation of COVID-19 lung infections remains to be challenging. In this
paper we propose a dilated dual attention U-Net (D2A U-Net) for COVID-19 lesion
segmentation in CT slices based on dilated convolution and a novel dual
attention mechanism to address the issues above. We introduce a dilated
convolution module in model decoder to achieve large receptive field, which
refines decoding process and contributes to segmentation accuracy. Also, we
present a dual attention mechanism composed of two attention modules which are
inserted to skip connection and model decoder respectively. The dual attention
mechanism is utilized to refine feature maps and reduce semantic gap between
different levels of the model. The proposed method has been evaluated on
open-source dataset and outperforms cutting edges methods in semantic
segmentation. Our proposed D2A U-Net with pretrained encoder achieves a Dice
score of 0.7298 and recall score of 0.7071. Besides, we also build a simplified
D2A U-Net without pretrained encoder to provide a fair comparison with other
models trained from scratch, which still outperforms popular U-Net family
models with a Dice score of 0.7047 and recall score of 0.6626. Our experiment
results have shown that by introducing dilated convolution and dual attention
mechanism, the number of false positives is significantly reduced, which
improves sensitivity to COVID-19 lesions and subsequently brings significant
increase to Dice score.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:21:59 GMT""}]","2021-02-11"
"2102.05211","Jingbo Tan","Linglong Dai, Jingbo Tan, and H. Vincent Poor","Delay-Phase Precoding for Wideband THz Massive MIMO","Accepted by IEEE TWC. We first reveal a fundamental problem called
  the beam split effect in THz massive MIMO. To solve this problem, we then
  propose a new precoding architecture named delay-phase precoding. Simulation
  codes are provided:
  http://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html",,"10.1109/TWC.2022.3157315",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benefiting from tens of GHz bandwidth, terahertz (THz) communication is
considered to be a promising technology to provide ultra-high speed data rates
for future 6G wireless systems. To compensate for the serious propagation
attenuation of THz signals, massive multiple-input multiple-output (MIMO) with
hybrid precoding can be utilized to generate directional beams with high array
gains. However, the standard hybrid precoding architecture based on
frequency-independent phase-shifters cannot cope with the beam split effect in
THz massive MIMO systems, where the directional beams will split into different
physical directions at different subcarrier frequencies. The beam split effect
will result in a serious array gain loss across the entire bandwidth, which has
not been well investigated in THz massive MIMO systems. In this paper, we first
reveal and quantify the seriousness of the beam split effect in THz massive
MIMO systems by analyzing the array gain loss it causes. Then, we propose a new
precoding architecture called delay-phase precoding (DPP) to mitigate this
effect. Specifically, the proposed DPP introduces a time delay network as a new
precoding layer between radio-frequency chains and phase-shifters in the
standard hybrid precoding architecture. In this way, conventional
phase-controlled analog beamforming can be converted into delay-phase
controlled analog beamforming. Unlike frequency-independent phase shifts, the
time delay network introduced in the DPP can realize frequency-dependent phase
shifts, which can be designed to generate frequency-dependent beams towards the
target physical direction across the entire THz bandwidth. Due to the joint
control of delay and phase, the proposed DPP can significantly relieve the
array gain loss caused by the beam split effect. Furthermore, we propose a
hardware structure by using true-time-delayers to realize the concept of DPP.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:32:44 GMT""},{""version"":""v2"",""created"":""Sun, 6 Mar 2022 13:25:16 GMT""}]","2022-03-08"
"2102.05212","Moein Shakeri","Moein Shakeri, Shing Yan Loo, Hong Zhang","Polarimetric Monocular Dense Mapping Using Relative Deep Depth Prior","9 pages, 9 figure",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with polarimetric dense map reconstruction based on a
polarization camera with the help of relative depth information as a prior. In
general, polarization imaging is able to reveal information about surface
normal such as azimuth and zenith angles, which can support the development of
solutions to the problem of dense reconstruction, especially in texture-poor
regions. However, polarimetric shape cues are ambiguous due to two types of
polarized reflection (specular/diffuse). Although methods have been proposed to
address this issue, they either are offline and therefore not practical in
robotics applications, or use incomplete polarimetric cues, leading to
sub-optimal performance. In this paper, we propose an online reconstruction
method that uses full polarimetric cues available from the polarization camera.
With our online method, we can propagate sparse depth values both along and
perpendicular to iso-depth contours. Through comprehensive experiments on
challenging image sequences, we demonstrate that our method is able to
significantly improve the accuracy of the depthmap as well as increase its
density, specially in regions of poor texture.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:34:37 GMT""}]","2021-02-11"
"2102.05213","Alexander Kiselev","Alexander Kiselev and Yao Yao","Small scale formations in the incompressible porous media equation","21 pages, 3 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We construct examples of solutions to the incompressible porous media (IPM)
equation that must exhibit infinite in time growth of derivatives provided they
remain smooth. As an application, this allows us to obtain nonlinear
instability for a class of stratified steady states of IPM.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:36:23 GMT""}]","2021-02-11"
"2102.05214","Andrew Wagenmaker","Andrew Wagenmaker, Max Simchowitz, Kevin Jamieson","Task-Optimal Exploration in Linear Dynamical Systems",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exploration in unknown environments is a fundamental problem in reinforcement
learning and control. In this work, we study task-guided exploration and
determine what precisely an agent must learn about their environment in order
to complete a particular task. Formally, we study a broad class of
decision-making problems in the setting of linear dynamical systems, a class
that includes the linear quadratic regulator problem. We provide instance- and
task-dependent lower bounds which explicitly quantify the difficulty of
completing a task of interest. Motivated by our lower bound, we propose a
computationally efficient experiment-design based exploration algorithm. We
show that it optimally explores the environment, collecting precisely the
information needed to complete the task, and provide finite-time bounds
guaranteeing that it achieves the instance- and task-optimal sample complexity,
up to constant factors. Through several examples of the LQR problem, we show
that performing task-guided exploration provably improves on exploration
schemes which do not take into account the task of interest. Along the way, we
establish that certainty equivalence decision making is instance- and
task-optimal, and obtain the first algorithm for the linear quadratic regulator
problem which is instance-optimal. We conclude with several experiments
illustrating the effectiveness of our approach in practice.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:42:22 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 22:42:11 GMT""}]","2021-07-13"
"2102.05215","Yuanzhe Xi","Difeng Cai and James Nagy and Yuanzhe Xi","Fast deterministic approximation of symmetric indefinite kernel matrices
  with high dimensional datasets","27 pages, 16 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Kernel methods are used frequently in various applications of machine
learning. For large-scale high dimensional applications, the success of kernel
methods hinges on the ability to operate certain large dense kernel matrix K.
An enormous amount of literature has been devoted to the study of symmetric
positive semi-definite (SPSD) kernels, where Nystrom methods compute a low-rank
approximation to the kernel matrix via choosing landmark points. In this paper,
we study the Nystrom method for approximating both symmetric indefinite kernel
matrices as well SPSD ones. We first develop a theoretical framework for
general symmetric kernel matrices, which provides a theoretical guidance for
the selection of landmark points. We then leverage discrepancy theory to
propose the anchor net method for computing accurate Nystrom approximations
with optimal complexity. The anchor net method operates entirely on the dataset
without requiring the access to $K$ or its matrix-vector product. Results on
various types of kernels (both indefinite and SPSD ones) and machine learning
datasets demonstrate that the new method achieves better accuracy and stability
with lower computational cost compared to the state-of-the-art Nystrom methods.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:45:29 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 07:51:26 GMT""}]","2021-12-30"
"2102.05216","Sara Bunian","Sara Bunian, Kai Li, Chaima Jemmali, Casper Harteveld, Yun Fu, Magy
  Seif El-Nasr","VINS: Visual Search for Mobile User Interface Design",,,,,"cs.HC cs.CV cs.DB cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searching for relative mobile user interface (UI) design examples can aid
interface designers in gaining inspiration and comparing design alternatives.
However, finding such design examples is challenging, especially as current
search systems rely on only text-based queries and do not consider the UI
structure and content into account. This paper introduces VINS, a visual search
framework, that takes as input a UI image (wireframe, high-fidelity) and
retrieves visually similar design examples. We first survey interface designers
to better understand their example finding process. We then develop a
large-scale UI dataset that provides an accurate specification of the
interface's view hierarchy (i.e., all the UI components and their specific
location). By utilizing this dataset, we propose an object-detection based
image retrieval framework that models the UI context and hierarchical
structure. The framework achieves a mean Average Precision of 76.39\% for the
UI detection and high performance in querying similar UI designs.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:46:33 GMT""}]","2021-02-11"
"2102.05217","Hisashi Morioka","Kazunori Ando, Hiroshi Isozaki, Evgeny Korotyaev, Hisashi Morioka","Inverse scattering on the quantum graph for graphene","Many parts of this paper, especially the part dealing with the the
  forward problem, can be generalized to more general lattices, which can be
  seen in arXiv:1911.05233",,,,"math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the inverse scattering on the quantum graph associated with the
hexagonal lattice. Assuming that the potentials on the edges are compactly
supported and symmetric, we show that the S-matrix for all energies in any
given open set in the continuous spectrum determines the potentials.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:48:42 GMT""}]","2021-02-11"
"2102.05218","Qian Yang","Qian Yang, Jianyi Zhang, Weituo Hao, Gregory Spell, Lawrence Carin","FLOP: Federated Learning on Medical Datasets using Partial Networks","To appear in KDD 2021",,"10.1145/3447548.3467185",,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outbreak of COVID-19 Disease due to the novel coronavirus has caused a
shortage of medical resources. To aid and accelerate the diagnosis process,
automatic diagnosis of COVID-19 via deep learning models has recently been
explored by researchers across the world. While different data-driven deep
learning models have been developed to mitigate the diagnosis of COVID-19, the
data itself is still scarce due to patient privacy concerns. Federated Learning
(FL) is a natural solution because it allows different organizations to
cooperatively learn an effective deep learning model without sharing raw data.
However, recent studies show that FL still lacks privacy protection and may
cause data leakage. We investigate this challenging problem by proposing a
simple yet effective algorithm, named \textbf{F}ederated \textbf{L}earning
\textbf{o}n Medical Datasets using \textbf{P}artial Networks (FLOP), that
shares only a partial model between the server and clients. Extensive
experiments on benchmark data and real-world healthcare tasks show that our
approach achieves comparable or better performance while reducing the privacy
and security risks. Of particular interest, we conduct experiments on the
COVID-19 dataset and find that our FLOP algorithm can allow different hospitals
to collaboratively and effectively train a partially shared model without
sharing local patients' data.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:56:58 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 01:41:15 GMT""}]","2021-06-24"
"2102.05219","Ching-Yu Huang","Dimitrios Giataganas, Ching-Yu Huang, Feng-Li Lin","Neural Network flows of low q-state Potts and clock Models",,,"10.1088/1367-2630/ac63da",,"cond-mat.dis-nn cond-mat.stat-mech hep-th","http://creativecommons.org/licenses/by/4.0/","  It is known that a trained Restricted Boltzmann Machine (RBM) on the binary
Monte Carlo Ising spin configurations, generates a series of iterative
reconstructed spin configurations which spontaneously flow and stabilize to the
critical point of physical system. Here we construct a variety of Neural
Network (NN) flows using the RBM and (variational) autoencoders, to study the
q-state Potts and clock models on the square lattice for q = 2, 3, 4. The NN
are trained on Monte Carlo spin configurations at various temperatures. We find
that the trained NN flow does develop a stable point that coincides with
critical point of the q-state spin models. The behavior of the NN flow is
nontrivial and generative, since the training is unsupervised and without any
prior knowledge about the critical point and the Hamiltonian of the underlying
spin model. Moreover, we find that the convergence of the flow is independent
of the types of NNs and spin models, hinting a universal behavior. Our results
strengthen the potential applicability of the notion of the NN flow in studying
various states of matter and offer additional evidence on the connection with
the Renormalization Group flow.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:05:15 GMT""}]","2022-05-11"
"2102.05220","Yuanjie Ren","Yuanjie Ren, Axel Drees","Study of the $\eta$ to $\pi^0$ Ratio in Heavy-Ion Collisions","DNP meeting 2019
  https://ui.adsabs.harvard.edu/abs/2019APS..DNP.LJ008R/abstract 9 pages, 10
  figures","Phys. Rev. C 104, 054902, 2021","10.1103/PhysRevC.104.054902",,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that the $p_T$ dependence of the $\eta/\pi^0$ ratio is
universal within a few percent for high energy $p$+$p$, $p$+A and $d$+A
collisions, over a broad range of collision energies. The $\eta/\pi^0$ ratio
increases with $p_T$ up to 4 to 5 GeV/$c$ where it saturates at a nearly
constant value of 0.487$\pm$0.024. Above $p_T = 5$ GeV/$c$ the same constant
value is also observed in A+A collisions independent of collision system,
energy, and centrality. At lower $p_T$, where accurate $\eta/\pi^0$ data is
absent for A+A collisions, we estimate possible deviations from the universal
behavior, which could arise due to the rapid radial hydrodynamic expansion of
the A+A collision system. For A+A collisions at RHIC we find that possible
deviations are limited to the $p_T$ range from 0.4 to 3 GeV/$c$, and remain
less than 20% for the most central collisions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:09:47 GMT""}]","2022-06-22"
"2102.05221","Matthieu Herrmann","Matthieu Herrmann and Geoffrey I. Webb","Early Abandoning and Pruning for Elastic Distances including Dynamic
  Time Warping","Updated taking reviewers' comments into account",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Nearest neighbor search under elastic distances is a key tool for time series
analysis, supporting many applications. However, straightforward
implementations of distances require $O(n^2)$ space and time complexities,
preventing these applications from scaling to long series. Much work has been
devoted to speeding up the NN search process, mostly with the development of
lower bounds, allowing to avoid costly distance computations when a given
threshold is exceeded. This threshold, provided by the similarity search
process, also allows to early abandon the computation of a distance itself.
Another approach, is to prune parts of the computation. All these techniques
are othogonal to each other. In this work, we develop a new generic strategy,
""EAPruned"", that tightly integrates pruning with early abandoning. We apply it
to six elastic distance measures: DTW, CDTW, WDTW, ERP, MSM and TWE, showing
substantial speedup in NN search applications. Pruning alone also shows
substantial speedup for some distances, benefiting applications beyond the
scope of NN search (e.g. requiring all pairwise distances), and hence where
early abandoning is not applicable. We~release our implementation as part of a
new C++ library for time series classification, along with easy to use
Python/Numpy bindings.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:13:27 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 01:17:11 GMT""}]","2021-06-04"
"2102.05222","Anthony Harkin","Anthony Harkin, Adam Giammarese, Nathaniel S. Barlow, Steven J.
  Weinstein","The Rayleigh collapse of two spherical bubbles","14 pages, 3 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inertial collapse of two interacting and non-translating spherical
bubbles of equal size is considered. The exact analytic solution to the
nonlinear ordinary differential equation that governs the bubble radii during
collapse is first obtained via a slowly converging power series. An asymptotic
approximant is then constructed that accelerates convergence of the series and
imposes the asymptotic collapse behavior when the radii are small. The solution
generalizes the classical 1917 Rayleigh problem of single bubble collapse, as
this configuration is recovered when the distance between the bubble centers
far exceeds that of their radii.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:13:39 GMT""}]","2021-02-11"
"2102.05223","Jiaqi Gu","Jiaqi Gu and Guosheng Yin","Bayesian Knockoff Filter","39 pages, 10 figures",,,,"stat.ME","http://creativecommons.org/publicdomain/zero/1.0/","  In many scientific fields, researchers are interested in discovering features
with substantial effect on the response from a large number of features while
controlling the proportion of false discoveries. By incorporating the knockoff
procedure in the Bayesian framework, we develop the Bayesian knockoff filter
(BKF) for selecting features that have important effect on the response. In
contrast to the fixed knockoff variables in a frequentist procedure, we allow
the knockoff variables to be continuously updated using the Markov chain Monte
Carlo. Based on the posterior samples and the elaborated greedy selection
procedure, our method can distinguish the truly important features from
unimportant ones and the Bayesian false discovery rate can be controlled at a
desirable level. Numerical experiments on both synthetic and real data
demonstrate the advantages of our BKF over existing knockoff methods and
Bayesian variable selection approaches, i.e., the BKF possesses higher power
and yields a lower false discovery rate.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:21:41 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 01:12:37 GMT""}]","2023-02-28"
"2102.05224","Hyeongtaek Lee","Hyeongtaek Lee, Hyuckjin Choi, Hwanjin Kim, Sucheol Kim, Chulhee Jang,
  Yongyun Choi, and Junil Choi","Downlink Channel Reconstruction for Spatial Multiplexing in Massive MIMO
  Systems","Submitted to IEEE Transactions on Wireless Communications","IEEE Transactions on Wireless Communications, vol. 20, no. 9, pp.
  6154-6166, Sept. 2021","10.1109/TWC.2021.3072158",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To get channel state information (CSI) at a base station (BS), most of
researches on massive multiple-input multiple-output (MIMO) systems consider
time division duplexing (TDD) to get benefit from the uplink and downlink
channel reciprocity. Even in TDD, however, the BS still needs to transmit
downlink training signals, which are referred to as channel state information
reference signals (CSI-RSs) in the 3GPP standard, to support spatial
multiplexing in practice. This is because there are many cases that the number
of transmit antennas is less than the number of receive antennas at a user
equipment (UE) due to power consumption and circuit complexity issues. Because
of this mismatch, uplink sounding reference signals (SRSs) from the UE are not
enough for the BS to obtain full downlink MIMO CSI. Therefore, after receiving
the downlink CSI-RSs, the UE needs to feed back quantized CSI to the BS using a
pre-defined codebook to support spatial multiplexing. In this paper, possible
approaches to reconstruct full downlink MIMO CSI at the BS are proposed by
exploiting both the SRS and quantized downlink CSI considering practical
antenna structures with reduced downlink CSI-RS overhead. Numerical results
show that the spectral efficiencies by spatial multiplexing based on the
proposed downlink MIMO CSI reconstruction techniques outperform the
conventional methods solely based on the quantized CSI.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:26:01 GMT""}]","2022-06-28"
"2102.05225","Andreas Grammenos","Jing Han, Chlo\""e Brown, Jagmohan Chauhan, Andreas Grammenos, Apinan
  Hasthanasombat, Dimitris Spathis, Tong Xia, Pietro Cicuta, Cecilia Mascolo","Exploring Automatic COVID-19 Diagnosis via voice and symptoms from
  Crowdsourced Data","5 pages, 3 figures, 2 tables, Accepted for publication at ICASSP 2021",,"10.1109/ICASSP39728.2021.9414576",,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The development of fast and accurate screening tools, which could facilitate
testing and prevent more costly clinical tests, is key to the current pandemic
of COVID-19. In this context, some initial work shows promise in detecting
diagnostic signals of COVID-19 from audio sounds. In this paper, we propose a
voice-based framework to automatically detect individuals who have tested
positive for COVID-19. We evaluate the performance of the proposed framework on
a subset of data crowdsourced from our app, containing 828 samples from 343
participants. By combining voice signals and reported symptoms, an AUC of
$0.79$ has been attained, with a sensitivity of $0.68$ and a specificity of
$0.82$. We hope that this study opens the door to rapid, low-cost, and
convenient pre-screening tools to automatically detect the disease.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:28:16 GMT""}]","2021-05-17"
"2102.05226","Radhakrishna Tumbalam Gooty","Jose Adrian Chavez Velasco and Radhakrishna Tumbalam Gooty and Mohit
  Tawarmalani and Rakesh Agrawal","Optimal Design of Membrane Cascades for Gaseous and Liquid Mixtures via
  MINLP","37 pages, 12 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Given the growing concern of reducing CO2 emissions, it is desirable to
identify, for a given separation carried out through a membrane cascade, the
optimum design that yields the lowest energy consumption. Nevertheless,
designing a membrane cascade is challenging since, there are often multiple
feasible configurations that differ in their energy consumption and cost. In
this work, we develop a Mixed Integer Non-linear Program (MINLP) that, for a
given binary separation, which may be either liquid or gaseous, finds the
cascade and its operating conditions that minimize energy consumption. To model
the separation at each membrane in the cascade, we utilize the analytical
solution of a system of differential and algebraic equations derived from the
crossflow model and the solution-diffusion theory. We provide numerical
evidence which shows that our single-stage membrane model accurately predicts
experimental data. Unfortunately, the resulting membrane model is non-convex
and, even state-of-the-art solvers struggle to prove global optimality of the
cascades and the operating conditions identified. In this paper, we derive
various cuts that help with relaxation quality and, consequently, accelerate
convergence of branch-and-bound based solvers. More specifically, we
demonstrate, on various examples, that our cuts help branch-and-bound solvers
converge within 5\% optimality gap in a reasonable amount of time and such a
tolerance level was not achieved by a simple formulation of the membrane model.
The proposed optimization model is an easy-to-use tool for practitioners and
researchers to design energy efficient membrane cascades.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:36:25 GMT""}]","2021-02-11"
"2102.05227","Ulysse Chabaud","Ulysse Chabaud","Continuous Variable Quantum Advantages and Applications in Quantum
  Optics","Ph.D. Thesis, Sorbonne Universit\'e (2020)",,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis focuses on three main questions in the continuous variable and
optical settings: where does a quantum advantage, that is, the ability of
quantum machines to outperform classical machines, come from? How to ensure the
proper functioning of a quantum machine? What advantages can be gained in
practice from the use of quantum information?
  Quantum advantage in continuous variable comes in particular from the use of
so-called non-Gaussian quantum states. We introduce the stellar formalism to
characterize these states. We then study the transition from classically
simulable models to models which are universal for quantum computing. We show
that quantum computational supremacy, the dramatic speedup of quantum computers
over their classical counterparts, may be realised with non-Gaussian states and
Gaussian measurements.
  Quantum certification denotes the methods seeking to verify the correct
functioning of a quantum machine. We consider certification of quantum states
in continuous variable, introducing several protocols according to the
assumptions made on the tested state. We develop efficient methods for the
verification of a large class of multimode quantum states, including the output
states of the Boson Sampling model, enabling the experimental verification of
quantum supremacy with photonic quantum computing.
  We give several new examples of practical applications of quantum information
in linear quantum optics. Generalising the swap test, we highlight a connection
between the ability to distinguish two quantum states and the ability to
perform universal programmable quantum measurements, for which we give various
implementations in linear optics, based on the use of single photons or
coherent states. Finally, we obtain, thanks to linear optics, the first
implementation of a quantum protocol for weak coin flipping, a building block
for many cryptographic applications.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:43:27 GMT""}]","2021-02-11"
"2102.05228","Hyungsik Jung","Hyungsik Jung and Youngrock Oh","Towards Better Explanations of Class Activation Mapping","Accepted to ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasing demands for understanding the internal behavior of convolutional
neural networks (CNNs) have led to remarkable improvements in explanation
methods. Particularly, several class activation mapping (CAM) based methods,
which generate visual explanation maps by a linear combination of activation
maps from CNNs, have been proposed. However, the majority of the methods lack a
clear theoretical basis on how they assign the coefficients of the linear
combination. In this paper, we revisit the intrinsic linearity of CAM with
respect to the activation maps; we construct an explanation model of CNN as a
linear function of binary variables that denote the existence of the
corresponding activation maps. With this approach, the explanation model can be
determined by additive feature attribution methods in an analytic manner. We
then demonstrate the adequacy of SHAP values, which is a unique solution for
the explanation model with a set of desirable properties, as the coefficients
of CAM. Since the exact SHAP values are unattainable, we introduce an efficient
approximation method, LIFT-CAM, based on DeepLIFT. Our proposed LIFT-CAM can
estimate the SHAP values of the activation maps with high speed and accuracy.
Furthermore, it greatly outperforms other previous CAM-based methods in both
qualitative and quantitative aspects.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:43:50 GMT""},{""version"":""v2"",""created"":""Sun, 27 Jun 2021 03:14:33 GMT""},{""version"":""v3"",""created"":""Mon, 27 Sep 2021 07:54:52 GMT""}]","2021-09-28"
"2102.05229","Binjie Qin","Dongdong Hao, Song Ding, Linwei Qiu, Yisong Lv, Baowei Fei, Yueqi Zhu,
  Binjie Qin","Sequential vessel segmentation via deep channel attention network","14","Neural Networks, 2020","10.1016/j.neunet.2020.05.005",,"cs.CV physics.med-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper develops a novel encoder-decoder deep network architecture which
exploits the several contextual frames of 2D+t sequential images in a sliding
window centered at current frame to segment 2D vessel masks from the current
frame. The architecture is equipped with temporal-spatial feature extraction in
encoder stage, feature fusion in skip connection layers and channel attention
mechanism in decoder stage. In the encoder stage, a series of 3D convolutional
layers are employed to hierarchically extract temporal-spatial features. Skip
connection layers subsequently fuse the temporal-spatial feature maps and
deliver them to the corresponding decoder stages. To efficiently discriminate
vessel features from the complex and noisy backgrounds in the XCA images, the
decoder stage effectively utilizes channel attention blocks to refine the
intermediate feature maps from skip connection layers for subsequently decoding
the refined features in 2D ways to produce the segmented vessel masks.
Furthermore, Dice loss function is implemented to train the proposed deep
network in order to tackle the class imbalance problem in the XCA data due to
the wide distribution of complex background artifacts. Extensive experiments by
comparing our method with other state-of-the-art algorithms demonstrate the
proposed method's superior performance over other methods in terms of the
quantitative metrics and visual validation. The source codes are at
https://github.com/Binjie-Qin/SVS-net
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:45:08 GMT""}]","2021-02-11"
"2102.05230","Hideaki Hata","Hideaki Hata, Nicole Novielli, Sebastian Baltes, Raula Gaikovina Kula,
  Christoph Treude","GitHub Discussions: An Exploratory Study of Early Adoption","37 pages, Empirical Software Engineering",,,,"cs.SE cs.CY","http://creativecommons.org/licenses/by/4.0/","  Discussions is a new feature of GitHub for asking questions or discussing
topics outside of specific Issues or Pull Requests. Before being available to
all projects in December 2020, it had been tested on selected open source
software projects. To understand how developers use this novel feature, how
they perceive it, and how it impacts the development processes, we conducted a
mixed-methods study based on early adopters of GitHub discussions from January
until July 2020. We found that: (1) errors, unexpected behavior, and code
reviews are prevalent discussion categories; (2) there is a positive
relationship between project member involvement and discussion frequency; (3)
developers consider GitHub Discussions useful but face the problem of topic
duplication between Discussions and Issues; (4) Discussions play a crucial role
in advancing the development of projects; and (5) positive sentiment in
Discussions is more frequent than in Stack Overflow posts. Our findings are a
first step towards data-informed guidance for using GitHub Discussions, opening
up avenues for future work on this novel communication channel.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:49:03 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 10:43:24 GMT""},{""version"":""v3"",""created"":""Thu, 30 Sep 2021 06:17:00 GMT""}]","2021-10-01"
"2102.05231","Jinggang Zhuo","Yufan Li, Jinggang Zhuo, Ling Fan, Harry Jiannan Wang","Culture-inspired Multi-modal Color Palette Generation and Colorization:
  A Chinese Youth Subculture Case","accepted by the 3rd IEEE Workshop on Artificial Intelligence for Art
  Creation",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Color is an essential component of graphic design, acting not only as a
visual factor but also carrying cultural implications. However, existing
research on algorithmic color palette generation and colorization largely
ignores the cultural aspect. In this paper, we contribute to this line of
research by first constructing a unique color dataset inspired by a specific
culture, i.e., Chinese Youth Subculture (CYS), which is an vibrant and trending
cultural group especially for the Gen Z population. We show that the colors
used in CYS have special aesthetic and semantic characteristics that are
different from generic color theory. We then develop an interactive multi-modal
generative framework to create CYS-styled color palettes, which can be used to
put a CYS twist on images using our automatic colorization model. Our framework
is illustrated via a demo system designed with the human-in-the-loop principle
that constantly provides feedback to our algorithms. User studies are also
conducted to evaluate our generation results.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:56:37 GMT""}]","2021-02-11"
"2102.05232","Pankajeshwara Nand Sharma","Pankajeshwara Nand Sharma, Bastin Tony Roy Savarimuthu, Nigel Stanger","Extracting Rationale for Open Source Software Development Decisions -- A
  Study of Python Email Archives","12 pages, 5 figures, 3 tables, appears in the proceedings of the 43rd
  International Conference on Software Engineering (ICSE 2021)",,,,"cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  A sound Decision-Making (DM) process is key to the successful governance of
software projects. In many Open Source Software Development (OSSD) communities,
DM processes lie buried amongst vast amounts of publicly available data. Hidden
within this data lie the rationale for decisions that led to the evolution and
maintenance of software products. While there have been some efforts to extract
DM processes from publicly available data, the rationale behind how the
decisions are made have seldom been explored. Extracting the rationale for
these decisions can facilitate transparency (by making them known), and also
promote accountability on the part of decision-makers. This work bridges this
gap by means of a large-scale study that unearths the rationale behind
decisions from Python development email archives comprising about 1.5 million
emails. This paper makes two main contributions. First, it makes a knowledge
contribution by unearthing and presenting the rationale behind decisions made.
Second, it makes a methodological contribution by presenting a heuristics-based
rationale extraction system called Rationale Miner that employs multiple
heuristics, and follows a data-driven, bottom-up approach to infer the
rationale behind specific decisions (e.g., whether a new module is implemented
based on core developer consensus or benevolent dictator's pronouncement). Our
approach can be applied to extract rationale in other OSSD communities that
have similar governance structures.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:59:05 GMT""}]","2021-02-11"
"2102.05233","Takuya Kawata","Takuya Kawata, Takahiro Tsukahara","Scale interactions in turbulent plane Couette flows in minimal domains",,"J. Fluid Mech., vol. 911, A55 (2021)","10.1017/jfm.2020.1063",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Interscale energy transfer in wall turbulence has been intensively studied in
recent years, and both the forward (i.e. from larger to smaller scales) and
reversed transfers of turbulent energy have been found whereas their
corresponding physical phenomena have not been revealed. In the present study,
we perform DNS of turbulent plane Couette flow with reduced-size computational
domains, where either the streamwise or spanwise domain size is reduced to
their minimal lengths, aiming at elucidating the role of scale interactions in
each direction. Our computational results with the streamwise-minimal domain
suggest that the interplays between streamwise-elongated streaks and vortices
smaller than the streamwise minimal length are the essential scale interactions
for both the inner and outer structures. We further show that these
streamwise-independent and smaller-scale structures exchange energy through
forward and reversed interscale energy transfers, and the reversed energy
transfer maintains the energy production at larger scales. Based on the
resemblance of the observed Reynolds-stress transport and the scenario of the
self-sustaining cycle, we conjecture that the forward and reversed energy
transfers mainly represent the streak instabilities and regeneration of
streamwise vortices, respectively. Furthermore, the computation with the
spanwise-minimal domain indicates that the interscale energy transfers observed
by one-dimensional spanwise spectral analysis are likely related to individual
dynamics of each inner and outer structure, rather than represent their
interactions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:08:32 GMT""}]","2021-02-11"
"2102.05234","Jingbo Yang","Jingbo Yang, Ruge Zhao, Meixian Zhu, David Hallac, Jaka Sodnik, Jure
  Leskovec","Driver2vec: Driver Identification from Automotive Data","7 pages, 3 figures, 6 tables in the main text. First publisehd to 6th
  Workshop on Mining and Learning from Time Series (2020)",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With increasing focus on privacy protection, alternative methods to identify
vehicle operator without the use of biometric identifiers have gained traction
for automotive data analysis. The wide variety of sensors installed on modern
vehicles enable autonomous driving, reduce accidents and improve vehicle
handling. On the other hand, the data these sensors collect reflect drivers'
habit. Drivers' use of turn indicators, following distance, rate of
acceleration, etc. can be transformed to an embedding that is representative of
their behavior and identity. In this paper, we develop a deep learning
architecture (Driver2vec) to map a short interval of driving data into an
embedding space that represents the driver's behavior to assist in driver
identification. We develop a custom model that leverages performance gains of
temporal convolutional networks, embedding separation power of triplet loss and
classification accuracy of gradient boosting decision trees. Trained on a
dataset of 51 drivers provided by Nervtech, Driver2vec is able to accurately
identify the driver from a short 10-second interval of sensor data, achieving
an average pairwise driver identification accuracy of 83.1% from this 10-second
interval, which is remarkably higher than performance obtained in previous
studies. We then analyzed performance of Driver2vec to show that its
performance is consistent across scenarios and that modeling choices are sound.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:09:13 GMT""}]","2021-02-11"
"2102.05235","Aneta Neumann","William Reid, Aneta Neumann, Simon Ratcliffe, Frank Neumann","Advanced Ore Mine Optimisation under Uncertainty Using Evolution",,,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the impact of uncertainty in advanced ore mine
optimisation. We consider Maptek's software system Evolution which optimizes
extraction sequences based on evolutionary computation techniques and quantify
the uncertainty of the obtained solutions with respect to the ore deposit based
on predictions obtained by ensembles of neural networks. Furthermore, we
investigate the impact of staging on the obtained optimized solutions and
discuss a wide range of components for this large scale stochastic optimisation
problem which allow to mitigate the uncertainty in the ore deposit while
maintaining high profitability.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:10:02 GMT""}]","2021-02-11"
"2102.05236","Pan Wang","Pan Wang, Rui Zhou, Shuo Wang, Ling Li, Wenjia Bai, Jialu Fan, Chunlin
  Li, Peter Childs, and Yike Guo","A General Framework for Revealing Human Mind with auto-encoding GANs",,,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Addressing the question of visualising human mind could help us to find
regions that are associated with observed cognition and responsible for
expressing the elusive mental image, leading to a better understanding of
cognitive function. The traditional approach treats brain decoding as a
classification problem, reading the mind through statistical analysis of brain
activity. However, human thought is rich and varied, that it is often
influenced by more of a combination of object features than a specific type of
category. For this reason, we propose an end-to-end brain decoding framework
which translates brain activity into an image by latent space alignment. To
find the correspondence from brain signal features to image features, we
embedded them into two latent spaces with modality-specific encoders and then
aligned the two spaces by minimising the distance between paired latent
representations. The proposed framework was trained by simultaneous
electroencephalogram and functional MRI data, which were recorded when the
subjects were viewing or imagining a set of image stimuli. In this paper, we
focused on implementing the fMRI experiment. Our experimental results
demonstrated the feasibility of translating brain activity to an image. The
reconstructed image matches image stimuli approximate in both shape and colour.
Our framework provides a promising direction for building a direct
visualisation to reveal human mind.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:18:46 GMT""}]","2021-02-11"
"2102.05237","Kyle Bishop","Zhengyan Zhang and Hang Yuan and Yong Dou and Monica Olvera de la Cruz
  and Kyle J. M. Bishop","Quincke oscillations of colloids at planar electrodes",,"Phys. Rev. Lett. 126, 258001 (2021)","10.1103/PhysRevLett.126.258001",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Dielectric particles in weakly conducting fluids rotate spontaneously when
subject to strong electric fields. Such Quincke rotation near a plane electrode
leads to particle translation that enables physical models of active matter.
Here, we show that Quincke rollers can also exhibit oscillatory dynamics,
whereby particles move back and forth about a fixed location. We explain how
oscillations arise for micron-scale particles commensurate with the thickness
of a field-induced boundary layer in the nonpolar electrolyte. This work
enables the design of colloidal oscillators.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:25:33 GMT""}]","2021-06-30"
"2102.05238","Shantanu Sharma","Peeyush Gupta, Sharad Mehrotra, Shantanu Sharma, Nalini
  Venkatasubramanian, Guoxi Wang","Concealer: SGX-based Secure, Volume Hiding, and Verifiable Processing of
  Spatial Time-Series Datasets","A preliminary version of this paper has been accepted in the 24th
  International Conference on Extending Database Technology (EDBT) 2021",,,,"cs.CR cs.DB cs.DC cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a system, entitled Concealer that allows sharing
time-varying spatial data (e.g., as produced by sensors) in encrypted form to
an untrusted third-party service provider to provide location-based
applications (involving aggregation queries over selected regions over time
windows) to users. Concealer exploits carefully selected encryption techniques
to use indexes supported by database systems and combines ways to add fake
tuples in order to realize an efficient system that protects against leakage
based on output-size. Thus, the design of Concealer overcomes two limitations
of existing symmetric searchable encryption (SSE) techniques: (i) it avoids the
need of specialized data structures that limit usability/practicality of SSE in
large scale deployments, and (ii) it avoids information leakages based on the
output-size, which may leak data distributions. Experimental results validate
the efficiency of the proposed algorithms over a spatial time-series dataset
(collected from a smart space) and TPC-H datasets, each of 136 Million rows,
the size of which prior approaches have not scaled to.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:28:25 GMT""}]","2021-02-11"
"2102.05239","Fan Ye","Fan Ye, Qingchang Liu, Baoxing Xu, Philip X.-L. Feng, Xian Zhang","Very High Interfacial Thermal Conductance in Fully hBN-Encapsulated MoS2
  van der Waals Heterostructure",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report experimental and computational studies of thermal transport
properties in hexagonal boron nitride (hBN) encapsulated molybdenum disulfide
(MoS2) structure using refined optothermal Raman techniques, and reveal very
high interfacial thermal conductance between hBN and MoS2. By studying the
Raman shift of hBN and MoS2 in suspended and substrate-supported thin films
under varying laser power and temperature, we calibrate lateral (in-plane)
thermal conductivity of hBN and MoS2 and the vertical interfacial thermal
conductance in the hBN/MoS2/hBN heterostructure as well as the interfaces
between heterostructure and substrate. Crucially, we have found that
interfacial thermal conductance between hBN and encapsulated MoS2 is 74MW/m2K
and 72MW/m2K in supported and suspended films, respectively, which are
significantly higher than interfacial thermal conductance between MoS2 and
other substrates. Molecular dynamics (MD) computations conducted in parallel
have shown consistent results. This work provides clear evidence of
significantly efficient heat dissipation in hBN/MoS2/hBN heterostructures and
sheds light on building novel hBN encapsulated nanoelectronics with efficient
thermal management.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:28:51 GMT""}]","2021-02-11"
"2102.05240","Jie Xu","Jie Xu, Panpan He, Delong Feng, Kangle Yong, Lujun Hong, Yun Shen, and
  Yun Zhou","Slow wave and truly rainbow trapping in one-way terahertz waveguide",,,"10.1364/OE.422274",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Slow or even stop electromagnetic (EM) waves attract researchers' attentions
for its potential applications in energy storage, optical buffer and
nonlinearity enhancement. However, in most cases of the EM waves trapping, the
EM waves are not truly trapped due to the existence of reflection. In this
paper, a novel metal-semiconductor-semiconductor-metal (MSSM) structure, and a
novel truly rainbow trapping in a tapered MSSM model at terahertz frequencies
are demonstrated by theoretical analysis and numerical simulations. More
importantly, functional devices such as optical buffer, optical switch and
optical filter are achieved in our designed MSSM structure based on truly
rainbow trapping theory. Owing to the property of one-way propagation, these
new types of optical devices can be high-performance and are expected to be
used in integrated optical circuits.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:30:39 GMT""}]","2021-07-15"
"2102.05241","Xuankai Liu","Fengting Li, Xuankai Liu, Xiaoli Zhang, Qi Li, Kun Sun, Kang Li","Detecting Localized Adversarial Examples: A Generic Approach using
  Critical Region Analysis",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have been applied in a wide range of
applications,e.g.,face recognition and image classification; however,they are
vulnerable to adversarial examples. By adding a small amount of imperceptible
perturbations,an attacker can easily manipulate the outputs of a DNN.
Particularly,the localized adversarial examples only perturb a small and
contiguous region of the target object,so that they are robust and effective in
both digital and physical worlds. Although the localized adversarial examples
have more severe real-world impacts than traditional pixel attacks,they have
not been well addressed in the literature. In this paper,we propose a generic
defense system called TaintRadar to accurately detect localized adversarial
examples via analyzing critical regions that have been manipulated by
attackers. The main idea is that when removing critical regions from input
images,the ranking changes of adversarial labels will be larger than those of
benign labels. Compared with existing defense solutions,TaintRadar can
effectively capture sophisticated localized partial attacks, e.g.,the
eye-glasses attack,while not requiring additional training or fine-tuning of
the original model's structure. Comprehensive experiments have been conducted
in both digital and physical worlds to verify the effectiveness and robustness
of our defense.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:31:16 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 02:29:21 GMT""}]","2021-02-16"
"2102.05242","Moritz Hardt","Moritz Hardt and Benjamin Recht","Patterns, predictions, and actions: A story about machine learning","Manuscript submitted to publisher for copy editing",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This graduate textbook on machine learning tells a story of how patterns in
data support predictions and consequential actions. Starting with the
foundations of decision making, we cover representation, optimization, and
generalization as the constituents of supervised learning. A chapter on
datasets as benchmarks examines their histories and scientific bases.
Self-contained introductions to causality, the practice of causal inference,
sequential decision making, and reinforcement learning equip the reader with
concepts and tools to reason about actions and their consequences. Throughout,
the text discusses historical context and societal impact. We invite readers
from all backgrounds; some experience with probability, calculus, and linear
algebra suffices.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:42:03 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 15:54:29 GMT""}]","2021-10-27"
"2102.05243","Allison Moore H","Christopher Flippen and Allison H. Moore and Essak Seddiq","Quotients of the Gordian and H(2)-Gordian graphs","20 pages, 9 figures. This version similar to the one published in the
  Journal of Knot Theory and Its Ramifications",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Gordian graph and H(2)-Gordian graphs of knots are abstract graphs whose
vertex sets represent isotopy classes of unoriented knots, and whose edge sets
record whether pairs of knots are related by crossing changes or H(2)-moves,
respectively. We investigate quotients of these graphs under equivalence
relations defined by several knot invariants including the determinant, the
span of the Jones polynomial, and an invariant related to tricolorability. We
show, in all cases considered, that the quotient graphs are Gromov hyperbolic.
We then prove a collection of results about the graph isomorphism type of the
quotient graphs. In particular, we find that the H(2)-Gordian graph of links
modulo the relation induced by the span of the Jones polynomial is isomorphic
with the complete graph on infinitely many vertices.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:43:16 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 17:12:58 GMT""}]","2021-11-24"
"2102.05244","Maria Lu\'isa Buzzo","M. L. Buzzo, B. Ziegler, P. Amram, M. Verdugo, C. E. Barbosa, B.
  Ciocan, P. Papaderos, S. Torres-Flores, C. Mendes de Oliveira","Physical and kinematic conditions of the local merging galaxy NGC 1487","Accepted for publication in MNRAS: 19 pages, 15 figures, 1 table",,"10.1093/mnras/stab426",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present optical VLT/MUSE integral field spectroscopy data of the merging
galaxy NGC 1487. We use fitting techniques to study the ionized gas emission of
this merger and its main morphological and kinematical properties. We measured
flat and sometimes inverted oxygen abundance gradients in the subsystems
composing NGC 1487, explained by metal mixing processes common in merging
galaxies. We also measured widespread star-forming bursts, indicating that
photoionisation by stars is the primary ionization source of the galaxy. The
kinematic map revealed a rotating pattern in the gas in the northern tail of
the system, suggesting that the galaxy may be in the process of rebuilding a
disc. The gas located in the central region has larger velocity dispersion
($\sigma\approx 50$ km s$^{-1}$) than the remaining regions, indicating
kinematic heating, possibly owing to the ongoing interaction. Similar trends
were, however, not observed in the stellar velocity-dispersion map, indicating
that the galaxy has not yet achieved equilibrium, and the nebular and stellar
components are still kinematically decoupled. Based on all our measurements and
findings, and specially on the mass estimates, metallicity gradients and
velocity fields of the system, we propose that NGC 1487 is the result of an
ongoing merger event involving smallish dwarf galaxies within a group, in a
pre-merger phase, resulting in a relic with mass and physical parameters
similar to a dwarf galaxy. Thus, we may be witnessing the formation of a dwarf
galaxy by merging of smaller clumps at z=0.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:44:22 GMT""}]","2021-02-24"
"2102.05245","Jean-Marc Valin","Jean-Marc Valin, Srikanth Tenneti, Karim Helwani, Umut Isik, Arvindh
  Krishnaswamy","Low-Complexity, Real-Time Joint Neural Echo Control and Speech
  Enhancement Based On PercepNet","Accepted for ICASSP 2021, 5 pages",,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech enhancement algorithms based on deep learning have greatly surpassed
their traditional counterparts and are now being considered for the task of
removing acoustic echo from hands-free communication systems. This is a
challenging problem due to both real-world constraints like loudspeaker
non-linearities, and to limited compute capabilities in some communication
systems. In this work, we propose a system combining a traditional acoustic
echo canceller, and a low-complexity joint residual echo and noise suppressor
based on a hybrid signal processing/deep neural network (DSP/DNN) approach. We
show that the proposed system outperforms both traditional and other neural
approaches, while requiring only 5.5% CPU for real-time operation. We further
show that the system can scale to even lower complexity levels.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:44:25 GMT""}]","2021-02-11"
"2102.05246","Yi Luo","Yi Luo, Aiguo Chen, Bei Hui, Ke Yan","Memory-Associated Differential Learning","7 pages, 4 figures, 2 tables",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional Supervised Learning approaches focus on the mapping from input
features to output labels. After training, the learnt models alone are adapted
onto testing features to predict testing labels in isolation, with training
data wasted and their associations ignored. To take full advantage of the vast
number of training data and their associations, we propose a novel learning
paradigm called Memory-Associated Differential (MAD) Learning. We first
introduce an additional component called Memory to memorize all the training
data. Then we learn the differences of labels as well as the associations of
features in the combination of a differential equation and some sampling
methods. Finally, in the evaluating phase, we predict unknown labels by
inferencing from the memorized facts plus the learnt differences and
associations in a geometrically meaningful manner. We gently build this theory
in unary situations and apply it on Image Recognition, then extend it into Link
Prediction as a binary situation, in which our method outperforms strong
state-of-the-art baselines on ogbl-ddi dataset.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:48:12 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 06:41:03 GMT""}]","2021-06-16"
"2102.05247","Qiang Han","Yiming Wang and Zhidan Li and Qiang Han","Explicit forms of zero modes in symmetric interacting Kitaev chain
  without and with dimerization","7 pages, 3 figures","Chin. Phys. B 27, 067101 (2018)","10.1088/1674-1056/27/6/067101",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fermionic and bosonic zero modes of the 1D interacting Kitaev chain at
the symmetric point are unveiled. The many-body structures of the Majorana zero
modes in the topological region are given explicitly by carrying out
perturbation expansion up to infinite order. We also give the analytic
expressions of the bosonic zero modes in the topologically trivial phase. Our
results are generalized to the hybrid fermion system comprised of the
interacting Kitaev model and the Su-Schrieffer-Heeger model, in which we show
that these two types of zero modes can coexist in certain region of its phase
diagram.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:49:28 GMT""}]","2021-02-11"
"2102.05248","Adam Rumpf","Hemanshu Kaul (Illinois Institute of Technology) and Adam Rumpf
  (Florida Polytechnic University)","A linear input dependence model for interdependent networks","35 pages, 11 figures; Edits made in response to reviewer comments","European Journal of Operational Research, 302(2):781-797, 2022","10.1016/j.ejor.2022.01.020",,"math.OC cs.DM","http://creativecommons.org/licenses/by/4.0/","  We consider a linear relaxation of a generalized minimum-cost network flow
problem with binary input dependencies. In this model the flows through certain
arcs are bounded by linear (or more generally, piecewise linear concave)
functions of the flows through other arcs. This formulation can be used to
model interrelated systems in which the components of one system require the
delivery of material from another system in order to function (for example,
components of a subway system may require delivery of electrical power from a
separate system). We propose and study randomized rounding schemes for how this
model can be used to approximate solutions to a related mixed integer linear
program for modeling binary input dependencies. The introduction of side
constraints prevents this problem from being solved using the well-known
network simplex algorithm, however by characterizing its basis structure we
develop a generalization of network simplex algorithm that can be used for its
{computationally} efficient solution.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:49:41 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 06:25:11 GMT""}]","2022-05-27"
"2102.05249","Arash Mahyari","Arash Mahyari","Policy Augmentation: An Exploration Strategy for Faster Convergence of
  Deep Reinforcement Learning Algorithms","proceedings of 46th IEEE International Conference on Acoustics,
  Speech, and Signal Processing (ICASSP), 2021",,,,"cs.LG cs.AI cs.CV cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite advancements in deep reinforcement learning algorithms, developing an
effective exploration strategy is still an open problem. Most existing
exploration strategies either are based on simple heuristics, or require the
model of the environment, or train additional deep neural networks to generate
imagination-augmented paths. In this paper, a revolutionary algorithm, called
Policy Augmentation, is introduced. Policy Augmentation is based on a newly
developed inductive matrix completion method. The proposed algorithm augments
the values of unexplored state-action pairs, helping the agent take actions
that will result in high-value returns while the agent is in the early
episodes. Training deep reinforcement learning algorithms with high-value
rollouts leads to the faster convergence of deep reinforcement learning
algorithms. Our experiments show the superior performance of Policy
Augmentation. The code can be found at:
https://github.com/arashmahyari/PolicyAugmentation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 03:51:45 GMT""}]","2021-02-11"
"2102.05250","Andriaherimanana Sarobidy Razafimahatratra","Andriaherimanana Sarobidy Razafimahatratra","On multipartite derangement graphs","14 pages, published version",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a finite transitive permutation group $G\leq
\operatorname{Sym}(\Omega)$, with $|\Omega|\geq 2$, the derangement graph
$\Gamma_G$ of $G$ is the Cayley graph
$\operatorname{Cay}(G,\operatorname{Der}(G))$, where $\operatorname{Der}(G)$ is
the set of all derangements of $G$. Meagher et al. [On triangles in derangement
graphs, {\it J. Combin. Theory Ser. A}, 180:105390, 2021] recently proved that
$\operatorname{Sym}(2)$ acting on $\{1,2\}$ is the only transitive group whose
derangement graph is bipartite and any transitive group of degree at least
three has a triangle in its derangement graph. They also showed that there
exist transitive groups whose derangement graphs are complete multipartite.
  This paper gives two new families of transitive groups with complete
multipartite derangement graphs. In addition, we prove that if $p$ is an odd
prime and $G$ is a transitive group of degree $2p$, then the independence
number of $\Gamma_{G}$ is at most twice the size of a point-stabilizer of $G$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:01:39 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 22:26:11 GMT""}]","2021-09-07"
"2102.05251","Gia-Wei Chern","Yifei Shi, Cristiano Nisoli, Gia-Wei Chern","Ice, glass, and solid phases in artificial spin systems with quenched
  disorder","6 pages, 6 figures","Appl. Phys. Lett. 118, 122407 (2021)","10.1063/5.0046083",,"cond-mat.dis-nn cond-mat.mes-hall cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a numerical study on a disordered artificial spin-ice system which
interpolates between the long-range ordered square ice and the fully degenerate
shakti ice. Starting from the square-ice geometry, disorder is implemented by
adding vertical/horizontal magnetic islands to the center of some randomly
chosen square plaquettes of the array, at different densities. When no island
is added we have ordered square ice. When all square plaquettes have been
modified we obtain shakti ice, which is disordered yet in a topological phase
corresponding to the Rys F-model. In between, geometrical frustration due to
these additional center spins disrupts the long-range Ising order of
square-ice, giving rise to a spin-glass regime at low temperatures. The
artificial spin system proposed in our work provides an experimental platform
to study the interplay between quenched disorder and geometrical frustration.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:01:57 GMT""}]","2021-05-27"
"2102.05252","Ashoke De","Pradeep Kumar Seshadri and Ashoke De","Flow Past Stationary and Oscillating Airfoil at Low Reynolds number
  Using Sharp Interface Immersed Boundary Approach",,"Journal of Flow Visualization and Image Processing, 2020","10.1615/JFlowVisImageProc.2020030995",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present study reports on flow past airfoils (stationary and moving) using
sharp interface immersed-boundary approach. Non-boundary conforming approach
like immersed-boundary method offers a viable alternative over traditional
boundary conforming approach by allowing us to model flow past arbitrarily
complex shapes, by eliminating the need to re-grid the flow domain as the body
exhibits motion. We present flow past a NACA 0012 airfoil at stationary
conditions as well as exhibiting pitching motion. Evolution of vortex dynamics
and wake structures are presented to show that the developed sharp interface
immersed-boundary approach captures the flow physics of dynamic stall
accurately. Moving body problems involving immersed-boundary approach usually
encounter the issues of spurious oscillations and mass conservation. This is
handled through a field extension strategy based on ghost cell approach, which
allows for extrapolating the flow field value onto the ghost nodes, ensuring
smooth temporal transition as the immersed surface moves through time. The
results presented here show excellent agreement with the experimental results
found in the literature.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:04:57 GMT""}]","2021-02-11"
"2102.05253","Ashoke De","Jithin M., Nimish Kumar, Ashoke De, Malay K. Das","Pore-scale Simulation of Shear-Thinning Fluid Flow using Lattice
  Boltzmann Method",,"Transport in Porous Media, 2018","10.1007/s11242-017-0984-z",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Present work attempts to identify the roles of flow- and geometric-variables
on the scaling factor which is a necessary parameter for modeling the apparent
viscosity of non-Newtonian fluid in porous media. While idealizing the porous
media microstructure as arrays of circular and square cylinders, present study
uses multi-relaxation time lattice Boltzmann method to conduct pore-scale
simulation of shear thinning non-Newtonian fluid flow. Variation in the size
and inclusion ratio of the solid cylinders generates wide range of porous media
with varying porosity and permeability. Present study also used stochastic
reconstruction technique to generate realistic, random porous microstructures.
For each case, pore-scale fluid flow simulation enables the calculation of
equivalent viscosity based on the computed shear rate within the pores. It is
observed that the scaling factor has strong dependence on porosity,
permeability, tortuosity and the percolation threshold, while approaching the
maximum value at the percolation threshold porosity. Present investigation
quantifies and proposes meaningful correlations between the scaling factor and
the macroscopic properties of the porous media.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:08:52 GMT""}]","2021-02-11"
"2102.05254","Ricardo Ruiz Baier I","Veronica Anaya, Ruben Caraballo, Bryan Gomez-Vargas, David Mora,
  Ricardo Ruiz-Baier","Velocity-vorticity-pressure formulation for the Oseen problem with
  variable viscosity","18 pages","Calcolo, 58(4):e44, 2021","10.1007/s10092-021-00433-6",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We propose and analyse an augmented mixed finite element method for the Oseen
equations written in terms of velocity, vorticity, and pressure with
non-constant viscosity and homogeneous Dirichlet boundary condition for the
velocity. The weak formulation includes least-squares terms arising from the
constitutive equation and from the incompressibility condition, and we show
that it satisfies the hypotheses of the Babu\vska-Brezzi theory. Repeating the
arguments of the continuous analysis, the stability and solvability of the
discrete problem are established. The method is suited for any Stokes inf-sup
stable finite element pair for velocity and pressure, while for vorticity any
generic discrete space (of arbitrary order) can be used. A priori and a
posteriori error estimates are derived using two specific families of discrete
subspaces. Finally, we provide a set of numerical tests illustrating the
behaviour of the scheme, verifying the theoretical convergence rates, and
showing the performance of the adaptive algorithm guided by residual a
posteriori error estimation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:15:36 GMT""}]","2021-11-04"
"2102.05255","Prasenjit Ghosh","Prasenjit Ghosh and Tapas Kumar Samanta","Some properties of K-frame in n-Hilbert space","15 pages. arXiv admin note: text overlap with arXiv:2101.01657,
  arXiv:2101.01938",,,,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  The notion of a K-frame in n-Hilbert space is presented and some of their
characterizations are given. We verify that sum of two K-frames is also a
K-frame in n-Hilbert space. Also, the concept of tight K-frame in n-Hilbert
space is described and some properties of its are going to be established.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:17:30 GMT""}]","2021-02-11"
"2102.05256","Tadashi Wadayama","Tadashi Wadayama and Satoshi Takabe","Proximal Decoding for LDPC-coded Massive MIMO Channels",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We propose a novel optimization-based decoding algorithm for LDPC-coded
massive MIMO channels. The proposed decoding algorithm is based on a proximal
gradient method for solving an approximate maximum a posteriori (MAP) decoding
problem. The key idea is the use of a code-constraint polynomial penalizing a
vector far from a codeword as a regularizer in the approximate MAP objective
function. The code proximal operator is naturally derived from code-constraint
polynomials. The proposed algorithm, called proximal decoding, can be described
by a simple recursion consisting of the gradient descent step for a negative
log-likelihood function and the code proximal operation. Several numerical
experiments show that the proposed algorithm outperforms known massive MIMO
detection algorithms, such as an MMSE detector with belief propagation
decoding.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:20:12 GMT""}]","2021-02-11"
"2102.05257","Ching Pui Wan","Ching Pui Wan, Qifeng Chen","Robust Federated Learning with Attack-Adaptive Aggregation","14 pages, submitted to FTL-IJCAI'21",,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  Federated learning is vulnerable to various attacks, such as model poisoning
and backdoor attacks, even if some existing defense strategies are used. To
address this challenge, we propose an attack-adaptive aggregation strategy to
defend against various attacks for robust federated learning. The proposed
approach is based on training a neural network with an attention mechanism that
learns the vulnerability of federated learning models from a set of plausible
attacks. To the best of our knowledge, our aggregation strategy is the first
one that can be adapted to defend against various attacks in a data-driven
fashion. Our approach has achieved competitive performance in defending model
poisoning and backdoor attacks in federated learning tasks on image and text
datasets.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:23:23 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 13:25:46 GMT""}]","2021-08-09"
"2102.05258","Shan You","Xiu Su, Shan You, Tao Huang, Fei Wang, Chen Qian, Changshui Zhang,
  Chang Xu","Locally Free Weight Sharing for Network Width Search","Accepted by ICLR 2021 Spotlight",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searching for network width is an effective way to slim deep neural networks
with hardware budgets. With this aim, a one-shot supernet is usually leveraged
as a performance evaluator to rank the performance \wrt~different width.
Nevertheless, current methods mainly follow a manually fixed weight sharing
pattern, which is limited to distinguish the performance gap of different
width. In this paper, to better evaluate each width, we propose a locally free
weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more
freely shared, and each width is jointly indicated by its base channels and
free channels, where free channels are supposed to loCAte FrEely in a local
zone to better represent each width. Besides, we propose to further reduce the
search space by leveraging our introduced FLOPs-sensitive bins. As a result,
our CafeNet can be trained stochastically and get optimized within a min-min
strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO
dataset have verified our superiority comparing to other state-of-the-art
baselines. For example, our method can further boost the benchmark NAS network
EfficientNet-B0 by 0.41\% via searching its width more delicately.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:36:09 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 13:31:12 GMT""}]","2021-02-25"
"2102.05259","Joon-Hyuk Chang","Joon-Young Yang and Joon-Hyuk Chang","VACE-WPE: Virtual Acoustic Channel Expansion Based On Neural Networks
  for Weighted Prediction Error-Based Speech Dereverberation","13 pages, 12 figures, 10 tables",,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech dereverberation is an important issue for many real-world speech
processing applications. Among the techniques developed, the weighted
prediction error (WPE) algorithm has been widely adopted and advanced over the
last decade, which blindly cancels out the late reverberation component from
the reverberant mixture of microphone signals. In this study, we extend the
neural-network-based virtual acoustic channel expansion (VACE) framework for
the WPE-based speech dereverberation, a variant of the WPE that we recently
proposed to enable the use of dual-channel WPE algorithm in a single-microphone
speech dereverberation scenario. Based on the previous study, some ablation
studies are conducted regarding the constituents of the VACE-WPE in an offline
processing scenario. These studies help understand the dynamics of the system,
thereby simplifying the architecture and leading to the introduction of new
strategies for training the neural network for the VACE. Experimental results
in noisy reverberant environments reveal that VACE-WPE considerably outperforms
its single-channel counterpart in terms of objective speech quality and is
complementary to the single-channel WPE when employed as the front-end for the
far-field automatic speech recognizer.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:40:47 GMT""}]","2021-02-11"
"2102.05260","Sm Zobaed","Sm Zobaed, Md Enamul Haque, Md Fazle Rabby, and Mohsen Amini Salehi","SensPick: Sense Picking for Word Sense Disambiguation",,"16th IEEE International Conference on Semantic Computing,
  ICSC'2021",,,"cs.CL cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  Word sense disambiguation (WSD) methods identify the most suitable meaning of
a word with respect to the usage of that word in a specific context. Neural
network-based WSD approaches rely on a sense-annotated corpus since they do not
utilize lexical resources. In this study, we utilize both context and related
gloss information of a target word to model the semantic relationship between
the word and the set of glosses. We propose SensPick, a type of stacked
bidirectional Long Short Term Memory (LSTM) network to perform the WSD task.
The experimental evaluation demonstrates that SensPick outperforms traditional
and state-of-the-art models on most of the benchmark datasets with a relative
improvement of 3.5% in F-1 score. While the improvement is not significant,
incorporating semantic relationships brings SensPick in the leading position
compared to others.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:52:42 GMT""}]","2021-02-11"
"2102.05261","Shi Dong","Shi Dong, Benjamin Van Roy, Zhengyuan Zhou","Simple Agent, Complex Environment: Efficient Reinforcement Learning with
  Agent States",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design a simple reinforcement learning (RL) agent that implements an
optimistic version of $Q$-learning and establish through regret analysis that
this agent can operate with some level of competence in any environment. While
we leverage concepts from the literature on provably efficient RL, we consider
a general agent-environment interface and provide a novel agent design and
analysis. This level of generality positions our results to inform the design
of future agents for operation in complex real environments. We establish that,
as time progresses, our agent performs competitively relative to policies that
require longer times to evaluate. The time it takes to approach asymptotic
performance is polynomial in the complexity of the agent's state representation
and the time required to evaluate the best policy that the agent can represent.
Notably, there is no dependence on the complexity of the environment. The
ultimate per-period performance loss of the agent is bounded by a constant
multiple of a measure of distortion introduced by the agent's state
representation. This work is the first to establish that an algorithm
approaches this asymptotic condition within a tractable time frame.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:53:12 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:49:32 GMT""},{""version"":""v3"",""created"":""Thu, 18 Feb 2021 20:20:34 GMT""},{""version"":""v4"",""created"":""Mon, 8 Mar 2021 17:44:14 GMT""},{""version"":""v5"",""created"":""Sat, 13 Mar 2021 05:41:21 GMT""},{""version"":""v6"",""created"":""Wed, 7 Jul 2021 06:31:41 GMT""},{""version"":""v7"",""created"":""Mon, 12 Jul 2021 02:07:04 GMT""}]","2021-07-13"
"2102.05262","Guillaume Charpiat","Guillaume Charpiat, Nicolas Girard, Loris Felardos, Yuliya Tarabalka","Input Similarity from the Neural Network Perspective","Published at NeurIPS 2019",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We first exhibit a multimodal image registration task, for which a neural
network trained on a dataset with noisy labels reaches almost perfect accuracy,
far beyond noise variance. This surprising auto-denoising phenomenon can be
explained as a noise averaging effect over the labels of similar input
examples. This effect theoretically grows with the number of similar examples;
the question is then to define and estimate the similarity of examples.
  We express a proper definition of similarity, from the neural network
perspective, i.e. we quantify how undissociable two inputs $A$ and $B$ are,
taking a machine learning viewpoint: how much a parameter variation designed to
change the output for $A$ would impact the output for $B$ as well?
  We study the mathematical properties of this similarity measure, and show how
to use it on a trained network to estimate sample density, in low complexity,
enabling new types of statistical analysis for neural networks. We analyze data
by retrieving samples perceived as similar by the network, and are able to
quantify the denoising effect without requiring true labels. We also propose,
during training, to enforce that examples known to be similar should also be
seen as similar by the network, and notice speed-up training effects for
certain datasets.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:57:30 GMT""}]","2021-02-11"
"2102.05263","Santiago Ontanon","Robert C. Gray, Jichen Zhu, Santiago Onta\~n\'on","Regression Oracles and Exploration Strategies for Short-Horizon
  Multi-Armed Bandits","8 pages","In proceedings of the 2020 IEEE Conference on Games (CoG) (pp.
  312-319)",,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores multi-armed bandit (MAB) strategies in very short horizon
scenarios, i.e., when the bandit strategy is only allowed very few interactions
with the environment. This is an understudied setting in the MAB literature
with many applications in the context of games, such as player modeling.
Specifically, we pursue three different ideas. First, we explore the use of
regression oracles, which replace the simple average used in strategies such as
epsilon-greedy with linear regression models. Second, we examine different
exploration patterns such as forced exploration phases. Finally, we introduce a
new variant of the UCB1 strategy called UCBT that has interesting properties
and no tunable parameters. We present experimental results in a domain
motivated by exergames, where the goal is to maximize a player's daily steps.
Our results show that the combination of epsilon-greedy or epsilon-decreasing
with regression oracles outperforms all other tested strategies in the short
horizon setting.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 04:58:44 GMT""}]","2021-02-11"
"2102.05264","Santiago Ontanon","Robert C. Gray, Jichen Zhu, Dannielle Arigo, Evan Forman and Santiago
  Onta\~n\'on","Player Modeling via Multi-Armed Bandits",,"In Proceedings of the International Conference on the Foundations
  of Digital Games (FDG 2020)",,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on building personalized player models solely from player
behavior in the context of adaptive games. We present two main contributions:
The first is a novel approach to player modeling based on multi-armed bandits
(MABs). This approach addresses, at the same time and in a principled way, both
the problem of collecting data to model the characteristics of interest for the
current player and the problem of adapting the interactive experience based on
this model. Second, we present an approach to evaluating and fine-tuning these
algorithms prior to generating data in a user study. This is an important
problem, because conducting user studies is an expensive and labor-intensive
process; therefore, an ability to evaluate the algorithms beforehand can save a
significant amount of resources. We evaluate our approach in the context of
modeling players' social comparison orientation (SCO) and present empirical
results from both simulations and real players.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:04:45 GMT""}]","2021-02-11"
"2102.05265","Anar Akhmedov","Anar Akhmedov, S\""umeyra Sakall{\i}, Sai-Kee Yeung","Complex Ball Quotients and New Symplectic 4-manifolds with Nonnegative
  Signatures","20 pages. arXiv admin note: text overlap with arXiv:1506.00230. Minor
  typos corrected",,,,"math.SG math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the various constructions of new symplectic $4$-manifolds with
non-negative signatures using the complex surfaces on the BMY line $c_1^2 =
9\chi_h$, the Cartwright-Steger surfaces, the quotients of Hirzebruch's certain
line-arrangement surfaces, along with the exotic symplectic $4$-manifolds
constructed in \cite{AP2, AS}. In particular, our constructions yield to (i) an
irreducible symplectic and infinitely many non-symplectic $4$-manifolds that
are homeomorphic but not diffeomorphic to $(2n-1)CP^{2}\#(2n-1)\bar{CP}^{2}$
for each integer $n \geq 9$, (ii) the families of simply connected irreducible
nonspin symplectic $4$-manifolds that have the smallest Euler characteristics
among the all known simply connected $4$-manifolds with positive signatures and
with more than one smooth structure. We also construct a complex surface with
positive signature from the Hirzebruch's line-arrangement surfaces, which is a
ball quotient.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:14:04 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 03:07:16 GMT""}]","2021-02-17"
"2102.05266","Jinhui Chen","Diyu Shen, Jinhui Chen, Zi-Wei Lin","The effect of hadronic scatterings on the measurement of vector meson
  spin alignments in heavy-ion collisions","8 pages, 7 figures, submit to Chin. Phys. C",,"10.1088/1674-1137/abe763",,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin alignments of vector mesons and hyperons in relativistic heavy-ion
collisions have been proposed as signals of the global polarization. The STAR
experiment first observed the $\rm \Lambda$ polarization. Recently, the ALICE
collaboration measured the transverse momentum ($p_T$) and the collision
centrality dependence of $K^*$ and $\phi$ spin alignments in Pb-Pb collisions
at $\rm \sqrt{s_{NN}}$ = 2.76 TeV. A large signal is observed in the low $p_T$
region of mid-central collisions for $K^*$ while the signal is much smaller for
$\phi$, and these have not been understood yet. Since vector mesons have
different lifetimes and their decay products have different scattering cross
sections, they suffer from different hadronic effects. In this paper, we study
the effect of hadronic interactions on the spin alignment of $K^*$, $\phi$ and
$\rho$ mesons in relativistic heavy-ion collisions with a multi-phase transport
model. We find that hadronic scatterings lead to a deviation of the observed
spin alignment matrix element $\rho_{00}$ away from the true value for $\rho$
and $K^*$ mesons (with a bigger effect on $\rho$) while the effect is
negligible for the $\phi$ meson. The effect depends on the kinematic
acceptance: the observed $\rho_{00}$ value is lower than the true value when
the pseudorapidity ($\eta$) coverage is small while there is little effect when
the $\eta$ coverage is big. Our study thus provides valuable information to
understand the vector meson spin alignment signals observed in the experiments.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:15:26 GMT""}]","2021-05-26"
"2102.05267","Lie-Wen Chen","Tong-Gang Yue, Lie-Wen Chen, Zhen Zhang, Ying Zhou","Constraints on the Symmetry Energy from PREX-II in the Multimessenger
  Era","6 pages, 4 figures. The published PREX-II result used, results
  updated and discussions added. Accepted version to appear in Physical Review
  Research as a Letter","Phys. Rev. Research 4, L022054 (2022)","10.1103/PhysRevResearch.4.L022054",,"nucl-th astro-ph.HE hep-ph nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The neutron skin thickness $\Delta r_{\rm{np}}$ of heavy nuclei is
essentially determined by the symmetry energy density slope $L({\rho })$ at
$\rho_c = 0.11~{\rm {fm}^{-3}}\approx 2/3\rho_0$ ($\rho_0$ is nuclear
saturation density), roughly corresponding to the average density of finite
nuclei. The PREX collaboration recently reported a model-independent extraction
of $\Delta r^{208}_{\rm{np}} = 0.283 \pm 0.071$ fm for the $\Delta r_{\rm{np}}$
of $^{208}$Pb, suggesting a rather stiff symmetry energy $E_{\rm{sym}}({\rho
})$ with $L({\rho_c }) \ge 52$ MeV. We show that the $E_{\rm{sym}}({\rho })$
cannot be too stiff and $L({\rho_c }) \le 73$ MeV is necessary to be compatible
with (1) the ground-state properties and giant monopole resonances of finite
nuclei, (2) the constraints on the equation of state of symmetric nuclear
matter at suprasaturation densities from flow data in heavy-ion collisions, (3)
the largest neutron star (NS) mass reported so far for PSR J0740+6620, (4) the
NS tidal deformability extracted from gravitational wave signal GW170817 and
(5) the mass-radius of PSR J0030+045 measured simultaneously by NICER. This
allows us to obtain $52 \le L({\rho_c }) \le 73$ MeV and $0.212 \le \Delta
r^{208}_{\rm{np}} \le 0.271$ fm, and further $E_{\rm{sym}}({\rho_0 }) = 34.3
\pm 1.7$ MeV, $L({\rho_0 }) = 83.1 \pm 24.7$ MeV, and $E_{\rm{sym}}({2\rho_0 })
= 62.8 \pm 15.9$ MeV. A number of critical implications on nuclear physics and
astrophysics are discussed.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:18:27 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 16:23:40 GMT""}]","2022-06-13"
"2102.05268","Sean Kross","Sean Kross, Eszter Hargittai, Elissa M. Redmiles","Characterizing the Online Learning Landscape: What and How People Learn
  Online","19 pages, To Appear in the Proceedings of the ACM (PACM)
  Human-Computer Interaction, CSCW 2021",,"10.1145/3449220",,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hundreds of millions of people learn something new online every day.
Simultaneously, the study of online education has blossomed within the human
computer interaction community, with new systems, experiments, and observations
creating and exploring previously undiscovered online learning environments. In
this study we endeavor to characterize this entire landscape of online learning
experiences using a national survey of 2260 US adults who are balanced to match
the demographics of the U.S. We examine the online learning resources that they
consult, and we analyze the subjects that they pursue using those resources.
Furthermore, we compare both formal and informal online learning experiences on
a larger scale than has ever been done before, to our knowledge, to better
understand which subjects people are seeking for intensive study. We find that
there is a core set of online learning experiences that are central to other
experiences and these are shared among the majority of people who learn online.
We conclude by showing how looking outside of these core online learning
experiences can reveal opportunities for innovation in online education.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:18:59 GMT""}]","2021-02-11"
"2102.05269","Arian Ahmadi","Arian Ahmadi and Omid Semiari","Reinforcement Learning for Optimized Beam Training in Multi-Hop
  Terahertz Communications","2021 IEEE International Conference on Communications (ICC): Mobile
  and Wireless Networks Symposium",,,,"cs.IT cs.LG cs.NI eess.SP math.IT stat.ML","http://creativecommons.org/licenses/by/4.0/","  Communication at terahertz (THz) frequency bands is a promising solution for
achieving extremely high data rates in next-generation wireless networks. While
the THz communication is conventionally envisioned for short-range wireless
applications due to the high atmospheric absorption at THz frequencies,
multi-hop directional transmissions can be enabled to extend the communication
range. However, to realize multi-hop THz communications, conventional beam
training schemes, such as exhaustive search or hierarchical methods with a
fixed number of training levels, can lead to a very large time overhead. To
address this challenge, in this paper, a novel hierarchical beam training
scheme with dynamic training levels is proposed to optimize the performance of
multi-hop THz links. In fact, an optimization problem is formulated to maximize
the overall spectral efficiency of the multi-hop THz link by dynamically and
jointly selecting the number of beam training levels across all the constituent
single-hop links. To solve this problem in presence of unknown channel state
information, noise, and path loss, a new reinforcement learning solution based
on the multi-armed bandit (MAB) is developed. Simulation results show the fast
convergence of the proposed scheme in presence of random channels and noise.
The results also show that the proposed scheme can yield up to 75% performance
gain, in terms of spectral efficiency, compared to the conventional
hierarchical beam training with a fixed number of training levels.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:24:09 GMT""}]","2021-02-11"
"2102.05270","Rajsekhar Bhattacharyya","Rajsekhar Bhattacharyya","The second vanishing theorem for Stanley-Reisner ring and its
  generalization","4 pages, one section added",,,,"math.AC","http://creativecommons.org/licenses/by/4.0/","  For regular local ring, the ""second vanishing theorem"" or ""SVT"" of local
cohomology has been proved in several cases. In this paper, we extend the
result of the SVT to Stanley-Reisner ring with an interpretation from
combinatorial topology. Finally, in this context, we generalize the result of
SVT.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:25:14 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 15:20:49 GMT""}]","2021-02-12"
"2102.05271","Vinay Joshi","Vinay Joshi, Wangxin He, Jae-sun Seo and Bipin Rajendran","Hybrid In-memory Computing Architecture for the Training of Deep Neural
  Networks","Accepted at ISCAS 2021 for publication",,,,"cs.AR cs.AI cs.ET cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cost involved in training deep neural networks (DNNs) on von-Neumann
architectures has motivated the development of novel solutions for efficient
DNN training accelerators. We propose a hybrid in-memory computing (HIC)
architecture for the training of DNNs on hardware accelerators that results in
memory-efficient inference and outperforms baseline software accuracy in
benchmark tasks. We introduce a weight representation technique that exploits
both binary and multi-level phase-change memory (PCM) devices, and this leads
to a memory-efficient inference accelerator. Unlike previous in-memory
computing-based implementations, we use a low precision weight update
accumulator that results in more memory savings. We trained the ResNet-32
network to classify CIFAR-10 images using HIC. For a comparable model size,
HIC-based training outperforms baseline network, trained in floating-point
32-bit (FP32) precision, by leveraging appropriate network width multiplier.
Furthermore, we observe that HIC-based training results in about 50% less
inference model size to achieve baseline comparable accuracy. We also show that
the temporal drift in PCM devices has a negligible effect on post-training
inference accuracy for extended periods (year). Finally, our simulations
indicate HIC-based training naturally ensures that the number of write-erase
cycles seen by the devices is a small fraction of the endurance limit of PCM,
demonstrating the feasibility of this architecture for achieving hardware
platforms that can learn in the field.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:26:27 GMT""}]","2021-02-11"
"2102.05272","Jinhuan Wang","Jinhuan Wang and Pengtao Chen and Bin Ma and Jiajun Zhou and Zhongyuan
  Ruan and Guanrong Chen and Qi Xuan","Sampling Subgraph Network with Application to Graph Classification",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphs are naturally used to describe the structures of various real-world
systems in biology, society, computer science etc., where subgraphs or motifs
as basic blocks play an important role in function expression and information
processing. However, existing research focuses on the basic statistics of
certain motifs, largely ignoring the connection patterns among them. Recently,
a subgraph network (SGN) model is proposed to study the potential structure
among motifs, and it was found that the integration of SGN can enhance a series
of graph classification methods. However, SGN model lacks diversity and is of
quite high time complexity, making it difficult to widely apply in practice. In
this paper, we introduce sampling strategies into SGN, and design a novel
sampling subgraph network model, which is scale-controllable and of higher
diversity. We also present a hierarchical feature fusion framework to integrate
the structural features of diverse sampling SGNs, so as to improve the
performance of graph classification. Extensive experiments demonstrate that, by
comparing with the SGN model, our new model indeed has much lower time
complexity (reduced by two orders of magnitude) and can better enhance a series
of graph classification methods (doubling the performance enhancement).
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:32:26 GMT""}]","2021-02-11"
"2102.05273","Yoshihiro Sugimoto","Yoshihiro Sugimoto","On the Hofer-Zehnder conjecture for non-contractible periodic orbits in
  Hamiltonian dynamics",,,,,"math.SG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we treat an open problem related to the number of periodic
orbits of Hamiltonian diffeomorphisms on closed symplectic manifolds.
Hofer-Zehnder conjecture states that a Hamiltonian diffeomorphisms has
infinitely many periodic orbits if it has ""homologically unnecessary periodic
orbits"""". For example, non-contractible periodic orbits are homologically
unnecessary periodic orbits because Floer homology of non-contractible periodic
orbits is trivial. We prove Hofer-Zehnder conjecture for non-contractible
periodic orbits for very wide classes of symplectic manifolds.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:35:14 GMT""}]","2021-02-11"
"2102.05274","Wenjia Zhang","Yikai Zhang, Wenjia Zhang, Sammy Bald, Vamsi Pingali, Chao Chen,
  Mayank Goswami","Stability of SGD: Tightness Analysis and Improved Bounds",,,,,"cs.LG math.OC stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  Stochastic Gradient Descent (SGD) based methods have been widely used for
training large-scale machine learning models that also generalize well in
practice. Several explanations have been offered for this generalization
performance, a prominent one being algorithmic stability [18]. However, there
are no known examples of smooth loss functions for which the analysis can be
shown to be tight. Furthermore, apart from the properties of the loss function,
data distribution has also been shown to be an important factor in
generalization performance. This raises the question: is the stability analysis
of [18] tight for smooth functions, and if not, for what kind of loss functions
and data distributions can the stability analysis be improved? In this paper we
first settle open questions regarding tightness of bounds in the
data-independent setting: we show that for general datasets, the existing
analysis for convex and strongly-convex loss functions is tight, but it can be
improved for non-convex loss functions. Next, we give a novel and improved
data-dependent bounds: we show stability upper bounds for a large class of
convex regularized loss functions, with negligible regularization parameters,
and improve existing data-dependent bounds in the non-convex setting. We hope
that our results will initiate further efforts to better understand the
data-dependent setting under non-convex loss functions, leading to an improved
understanding of the generalization abilities of deep networks.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:43:27 GMT""}]","2021-02-11"
"2102.05275","Tairu Qiu","Tairu Qiu, Guanxian Chen, Zhongang Qi, Bin Li, Ying Shan, Xiangyang
  Xue","A Generic Object Re-identification System for Short Videos","9 pages, 8 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Short video applications like TikTok and Kwai have been a great hit recently.
In order to meet the increasing demands and take full advantage of visual
information in short videos, objects in each short video need to be located and
analyzed as an upstream task. A question is thus raised -- how to improve the
accuracy and robustness of object detection, tracking, and re-identification
across tons of short videos with hundreds of categories and complicated visual
effects (VFX). To this end, a system composed of a detection module, a tracking
module and a generic object re-identification module, is proposed in this
paper, which captures features of major objects from short videos. In
particular, towards the high efficiency demands in practical short video
application, a Temporal Information Fusion Network (TIFN) is proposed in the
object detection module, which shows comparable accuracy and improved time
efficiency to the state-of-the-art video object detector. Furthermore, in order
to mitigate the fragmented issue of tracklets in short videos, a Cross-Layer
Pointwise Siamese Network (CPSN) is proposed in the tracking module to enhance
the robustness of the appearance model. Moreover, in order to evaluate the
proposed system, two challenge datasets containing real-world short videos are
built for video object trajectory extraction and generic object
re-identification respectively. Overall, extensive experiments for each module
and the whole system demonstrate the effectiveness and efficiency of our
system.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 05:45:09 GMT""}]","2021-02-11"
"2102.05276","Fumiya Hanamura","Fumiya Hanamura, Warit Asavanant, Kosuke Fukui, Shunya Konno, and
  Akira Furusawa","Estimation of Gaussian random displacement using non-Gaussian states","14 pages, 8 figures","Phys. Rev. A 104, 062601 (2021)","10.1103/PhysRevA.104.062601",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In continuous-variable quantum information processing, quantum error
correction of Gaussian errors requires simultaneous estimation of both
quadrature components of displacements on phase space. However, quadrature
operators $x$ and $p$ are non-commutative conjugate observables, whose
simultaneous measurement is prohibited by the uncertainty principle.
Gottesman-Kitaev-Preskill (GKP) error correction deals with this problem using
complex non-Gaussian states called GKP states. On the other hand, simultaneous
estimation of displacement using experimentally feasible non-Gaussian states
has not been well studied. In this paper, we consider a multi-parameter
estimation problem of displacements assuming an isotropic Gaussian prior
distribution and allowing post-selection of measurement outcomes. We derive a
lower bound for the estimation error when only Gaussian operations are used,
and show that even simple non-Gaussian states such as single-photon states can
beat this bound. Based on Ghosh's bound, we also obtain a lower bound for the
estimation error when the maximum photon number of the input state is given.
Our results reveal the role of non-Gaussianity in the estimation of
displacements, and pave the way toward the error correction of Gaussian errors
using experimentally feasible non-Gaussian states.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:00:37 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 04:21:53 GMT""},{""version"":""v3"",""created"":""Wed, 6 Oct 2021 15:05:53 GMT""},{""version"":""v4"",""created"":""Wed, 10 Nov 2021 01:58:29 GMT""}]","2022-01-24"
"2102.05277","Long Li","Long Li","Approximation of weak geodesics and subharmonicity of Mabuchi energy,
  II: $\epsilon$-geodesics","We corrected some errors and typos, and added several remarks and
  more details to explain this paper. Moreover, the more complicated proof of
  the strong L^2-convergence of the fiberwise volume element of the epsilon
  geodesic has been moved to the Appendix, and only remain the simpler one in
  the main context",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  The purpose of this article is to study the strict convexity of the Mabuchi
functional along a $C^{1,1}$-geodesic, with the aid of the
$\epsilon$-geodesics. We proved the $L^2$-convergence of the fiberwise volume
element of the $\epsilon$-geodesic. Moreover, the geodesic is proved to be
uniformly fiberwise non-degenerate if the Mabuchi functional is
$\epsilon$-affine.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:00:57 GMT""},{""version"":""v2"",""created"":""Sat, 27 Aug 2022 08:51:26 GMT""}]","2022-08-30"
"2102.05278","Christopher Butler","C. J. Butler, M. Yoshida, T. Hanaguri and Y. Iwasa","Doublon-like excitations and their phononic coupling in a Mott
  charge-density-wave system","8 pages, 5 figures, with Supplementary Information (6 pages, 8
  figures). Accepted for publication in Physical Review X","Phys. Rev. X 11, 011059 (2021)","10.1103/PhysRevX.11.011059",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Electron-phonon-driven charge density waves can in some circumstances allow
electronic correlations to become predominant, driving a system into a Mott
insulating state. New insights into both the Mott state and preceding charge
density wave may result from observations of the coupled dynamics of their
underlying degrees of freedom. Here, tunneling injection of single electrons
into the upper Hubbard band of the Mott charge-density-wave material 1T-TaS2
reveals extraordinarily narrow electronic excitations which couple to amplitude
mode phonons associated with the charge density wave's periodic lattice
distortion. This gives a vivid microscopic view of the interplay between
excitations of the Mott state and the lattice dynamics of its charge density
wave precursor.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:04:13 GMT""}]","2021-03-31"
"2102.05279","Heejune Kim","Heejune Kim","Cutoff phenomenon of the Glauber dynamics for the Ising model on
  complete multipartite graphs in the high temperature regime","Submitted to Markov Processes And Related Fields","Markov Processes and Related Fields, v.28, Issue 1, 113-148 (2022)",,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, the Glauber dynamics for the Ising model on the complete
multipartite graph $K_{np_1,\dots,np_m}$ is investigated where $0<p_i<1$ is the
proportion of the vertices in the $i$th component. We show that the dynamics
exhibits the cutoff phenomena at $t_n = \frac{1}{2(1-\beta/\beta_{cr})} n\ln n
$ with window size $O(n)$ in the high temperature regime $\beta< \beta_{cr}$
where $\beta_{cr}$ is a constant only depending on $p_1,\dots,p_m$.
Exponentially slow mixing is shown in the low temperature regime
$\beta>\beta_{cr}$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:04:41 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 01:08:10 GMT""}]","2023-03-21"
"2102.05280","Ying-Li Zhang","Rampei Kimura, Teruaki Suyama, Masahide Yamaguchi, Ying-li Zhang","Reconstruction of Primordial Power Spectrum of curvature perturbation
  from the merger rate of Primordial Black Hole Binaries","13 pages, 2 figures",,"10.1088/1475-7516/2021/04/031",,"astro-ph.CO gr-qc hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  The properties of primordial curvature perturbations on small scales are
still unknown while those on large scales have been well probed by the
observations of the cosmic microwave background anisotropies and the large
scale structure. In this paper, we propose the reconstruction method of
primordial curvature perturbations on small scales through the merger rate of
binary primordial black holes, which could form from large primordial curvature
perturbation on small scales.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:16:32 GMT""}]","2021-04-21"
"2102.05281","Qiao Jin","Qiao Jin, Zheng Yuan, Guangzhi Xiong, Qianlan Yu, Huaiyuan Ying,
  Chuanqi Tan, Mosha Chen, Songfang Huang, Xiaozhong Liu, Sheng Yu","Biomedical Question Answering: A Survey of Approaches and Challenges","In submission to ACM Computing Surveys",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Automatic Question Answering (QA) has been successfully applied in various
domains such as search engines and chatbots. Biomedical QA (BQA), as an
emerging QA task, enables innovative applications to effectively perceive,
access and understand complex biomedical knowledge. There have been tremendous
developments of BQA in the past two decades, which we classify into 5
distinctive approaches: classic, information retrieval, machine reading
comprehension, knowledge base and question entailment approaches. In this
survey, we introduce available datasets and representative methods of each BQA
approach in detail. Despite the developments, BQA systems are still immature
and rarely used in real-life settings. We identify and characterize several key
challenges in BQA that might lead to this issue, and discuss some potential
future directions to explore.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:16:35 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 01:20:25 GMT""}]","2021-09-10"
"2102.05282","Brayden R. Hull","Brayden R. Hull, Robert B. Mann","Thermodynamics of Exotic Black Holes in Lovelock Gravity","28 pages, 15 figures","Phys. Rev. D 104, 084032 (2021)","10.1103/PhysRevD.104.084032",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We examine the thermodynamics of a new class of asymptotically AdS black
holes with non-constant curvature event horizons in Gauss-Bonnet Lovelock
gravity, with the cosmological constant acting as thermodynamic pressure. We
find that non-trivial curvature on the horizon can significantly affect their
thermodynamic behaviour. We observe novel triple points in 6 dimensions between
large and small uncharged black holes and thermal AdS. For charged black holes
we find a continuous set of triple points whose range depends on the parameters
in the horizon geometry. We also find new generalizations of massless and
negative mass solutions previously observed in Einstein gravity.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:18:39 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 18:16:50 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jul 2022 17:24:25 GMT""}]","2022-07-08"
"2102.05283","Akmal Absalamov","A.T. Absalamov and U.A. Rozikov","A Regular Gonosomal Evolution Operator with uncountable set of fixed
  points",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study dynamical systems generated by a gonosomal evolution
operator of a bisexual population. We find explicitly all (uncountable set) of
fixed points of the operator. It is shown that each fixed point has eigenvalues
less or equal to 1. Moreover, we show that each trajectory converges to a fixed
point, i.e. the operator is reqular. There are uncountable family of invariant
sets each of which consisting unique fixed point. Thus there is one-to-one
correspondence between such invariant sets and the set of fixed points. Any
trajectory started at a point of the invariant set converges to the
corresponding fixed point.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:25:01 GMT""}]","2021-02-11"
"2102.05284","Liyu Chen","Liyu Chen and Haipeng Luo","Finding the Stochastic Shortest Path with Low Regret: The Adversarial
  Cost and Unknown Transition Case","ICML 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We make significant progress toward the stochastic shortest path problem with
adversarial costs and unknown transition. Specifically, we develop algorithms
that achieve $\widetilde{O}(\sqrt{S^2ADT_\star K})$ regret for the
full-information setting and $\widetilde{O}(\sqrt{S^3A^2DT_\star K})$ regret
for the bandit feedback setting, where $D$ is the diameter, $T_\star$ is the
expected hitting time of the optimal policy, $S$ is the number of states, $A$
is the number of actions, and $K$ is the number of episodes. Our work strictly
improves (Rosenberg and Mansour, 2020) in the full information setting, extends
(Chen et al., 2020) from known transition to unknown transition, and is also
the first to consider the most challenging combination: bandit feedback with
adversarial costs and unknown transition. To remedy the gap between our upper
bounds and the current best lower bounds constructed via a stochastically
oblivious adversary, we also propose algorithms with near-optimal regret for
this special case.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:33:04 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 07:13:54 GMT""}]","2021-06-15"
"2102.05285","Niels Kj{\ae}rgaard","J. Susanne Otto, Marisol K. Hunter, Niels Kj{\ae}rgaard and Amita B.
  Deb","Data capacity scaling of a distributed Rydberg atomic receiver array",,"Journal of Applied Physics 129, 154503 (2021)","10.1063/5.0048415",,"quant-ph physics.app-ph physics.atom-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The data transfer capacity of a communication channel is limited by the
Shannon-Hartley theorem and scales as $\text{log}_2(1 + \text{SNR})$ for a
single channel with the power signal-to-noise ratio (SNR). We implement an
array of atom-optical receivers in a single-input-multi-output (SIMO)
configuration by using spatially distributed probe light beams. The data
capacity of the distributed receiver configuration is observed to scale as
$\text{log}_2(1 + N\times\text{SNR})$ for an array consisting of $N$ receivers.
Our result is independent on the modulation frequency, and we show that such
enhancement of the bandwidth cannot be obtained by a single receiver with a
similar level of combined optical power. We investigate both theoretically and
experimentally the origins of the single channel capacity limit for our
implementation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:39:52 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 11:17:00 GMT""}]","2021-04-22"
"2102.05286","Yihong Du Prof","Yihong Du and Wenjie Ni","The high dimensional Fisher-KPP nonlocal diffusion equation with free
  boundary and radial symmetry",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the radially symmetric high dimensional Fisher-KPP nonlocal
diffusion equation with free boundary, and reveal some fundamental differences
from its one dimensional version considered in \cite{cdjfa} recently.
Technically, this high dimensional problem is much more difficult to treat
since it involves two kernel functions which arise from the original kernel
function $J(|x|)$ in rather implicit ways. By introducing new techniques, we
are able to determine the long-time dynamics of the model, including firstly
finding the threshold condition on the kernel function that governs the onset
of accelerated spreading, and the determination of the spreading speed when it
is finite. Moreover, for two important classes of kernel functions, sharp
estimates of the spreading profile are obtained. More precisely, for kernel
functions with compact support, we show that logarithmic shifting occurs from
the finite wave speed propagation, which is strikingly different from the one
dimension case; for kernel functions $J(|x|)$ behaving like $|x|^{-\beta}$ for
$x\in\R^N$ near infinity, we obtain the rate of accelerated spreading when
$\beta\in (N, N+1]$, which is the exact range of $\beta$ where accelerated
spreading is possible. These sharp estimates are obtained by constructing
subtle upper and lower solutions, based on careful analysis of the involved
kernel functions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:42:32 GMT""}]","2021-02-11"
"2102.05287","Man Long Wong","Man Long Wong, Jordan B. Angel, Michael F. Barad, Cetin C. Kiris","A positivity-preserving high-order weighted compact nonlinear scheme for
  compressible gas-liquid flows",,,"10.1016/j.jcp.2021.110569",,"physics.comp-ph cs.CE physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a robust, highly accurate, and efficient positivity- and
boundedness-preserving diffuse interface method for the simulations of
compressible gas-liquid two-phase flows with the five-equation model by Allaire
et al. using high-order finite difference weighted compact nonlinear scheme
(WCNS) in the explicit form. The equation of states of gas and liquid are given
by the ideal gas and stiffened gas laws respectively. Under a mild assumption
on the relative magnitude between the ratios of specific heats of the gas and
liquid, we can construct limiting procedures for the fifth order
incremental-stencil WCNS (WCNS-IS) with the first order Harten-Lax-van Leer
contact (HLLC) flux such that positive partial densities and squared speed of
sound can be ensured in the solutions, together with bounded volume fractions
and mass fractions. The limiting procedures are discretely conservative for all
conservative equations in the five-equation model and can also be easily
extended for any other conservative finite difference or finite volume scheme.
Numerical tests with liquid water and air are reported to demonstrate the
robustness and high accuracy of the WCNS-IS with the positivity- and
boundedness-preserving limiters even under extreme conditions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:01:00 GMT""}]","2021-08-18"
"2102.05288","Keisuke Imoto","Noriyuki Tonami and Keisuke Imoto and Yuki Okamoto and Takahiro
  Fukumori and Yoichi Yamashita","Sound Event Detection Based on Curriculum Learning Considering Learning
  Difficulty of Events","Accepted to ICASSP 2021",,,,"cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In conventional sound event detection (SED) models, two types of events,
namely, those that are present and those that do not occur in an acoustic
scene, are regarded as the same type of events. The conventional SED methods
cannot effectively exploit the difference between the two types of events. All
time frames of sound events that do not occur in an acoustic scene are easily
regarded as inactive in the scene, that is, the events are easy-to-train. The
time frames of the events that are present in a scene must be classified as
active in addition to inactive in the acoustic scene, that is, the events are
difficult-to-train. To take advantage of the training difficulty, we apply
curriculum learning into SED, where models are trained from easy- to
difficult-to-train events. To utilize the curriculum learning, we propose a new
objective function for SED, wherein the events are trained from easy- to
difficult-to-train events. Experimental results show that the F-score of the
proposed method is improved by 10.09 percentage points compared with that of
the conventional binary cross entropy-based SED.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:04:13 GMT""}]","2021-02-11"
"2102.05289","Matthew Wicker","Matthew Wicker, Luca Laurenti, Andrea Patane, Zhoutong Chen, Zheng
  Zhang, Marta Kwiatkowska","Bayesian Inference with Certifiable Adversarial Robustness","Accepted AISTATS2021",,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  We consider adversarial training of deep neural networks through the lens of
Bayesian learning, and present a principled framework for adversarial training
of Bayesian Neural Networks (BNNs) with certifiable guarantees. We rely on
techniques from constraint relaxation of non-convex optimisation problems and
modify the standard cross-entropy error model to enforce posterior robustness
to worst-case perturbations in $\epsilon$-balls around input points. We
illustrate how the resulting framework can be combined with methods commonly
employed for approximate inference of BNNs. In an empirical investigation, we
demonstrate that the presented approach enables training of certifiably robust
models on MNIST, FashionMNIST and CIFAR-10 and can also be beneficial for
uncertainty calibration. Our method is the first to directly train certifiable
BNNs, thus facilitating their deployment in safety-critical applications.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:17:49 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 04:23:58 GMT""}]","2021-02-24"
"2102.05290","Ryo Kawaoka","Ryo Kawaoka, Daiki Chiba, Takuya Watanabe, Mitsuaki Akiyama, Tatsuya
  Mori","A First Look at COVID-19 Domain Names: Origin and Implications","9 pages, 4 figures, 4 tables. Accepted at the Passive and Active
  Measurement Conference 2021 (PAM 2021)",,,,"cs.CY cs.CR","http://creativecommons.org/licenses/by/4.0/","  This work takes a first look at domain names related to COVID-19 (Cov19doms
in short), using a large-scale registered Internet domain name database, which
accounts for 260M of distinct domain names registered for 1.6K of distinct
top-level domains. We extracted 167K of Cov19doms that have been registered
between the end of December 2019 and the end of September 2020. We attempt to
answer the following research questions through our measurement study: RQ1: Is
the number of Cov19doms registrations correlated with the COVID-19 outbreaks?,
RQ2: For what purpose do people register Cov19doms? Our chief findings are as
follows: (1) Similar to the global COVID-19 pandemic observed around April
2020, the number of Cov19doms registrations also experienced the drastic
growth, which, interestingly, pre-ceded the COVID-19 pandemic by about a month,
(2) 70 % of active Cov19doms websites with visible content provided useful
information such as health, tools, or product sales related to COVID-19, and
(3) non-negligible number of registered Cov19doms was used for malicious
purposes. These findings imply that it has become more challenging to
distinguish domain names registered for legitimate purposes from others and
that it is crucial to pay close attention to how Cov19doms will be used/misused
in the future.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:19:36 GMT""}]","2021-02-11"
"2102.05291","Zhaowei Zhu","Zhaowei Zhu, Yiwen Song, Yang Liu","Clusterability as an Alternative to Anchor Points When Learning with
  Noisy Labels","ICML 2021",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The label noise transition matrix, characterizing the probabilities of a
training instance being wrongly annotated, is crucial to designing popular
solutions to learning with noisy labels. Existing works heavily rely on finding
""anchor points"" or their approximates, defined as instances belonging to a
particular class almost surely. Nonetheless, finding anchor points remains a
non-trivial task, and the estimation accuracy is also often throttled by the
number of available anchor points. In this paper, we propose an alternative
option to the above task. Our main contribution is the discovery of an
efficient estimation procedure based on a clusterability condition. We prove
that with clusterable representations of features, using up to third-order
consensuses of noisy labels among neighbor representations is sufficient to
estimate a unique transition matrix. Compared with methods using anchor points,
our approach uses substantially more instances and benefits from a much better
sample complexity. We demonstrate the estimation accuracy and advantages of our
estimates using both synthetic noisy labels (on CIFAR-10/100) and real
human-level noisy labels (on Clothing1M and our self-collected human-annotated
CIFAR-10). Our code and human-level noisy CIFAR-10 labels are available at
https://github.com/UCSC-REAL/HOC.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:22:56 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 21:33:49 GMT""}]","2021-07-15"
"2102.05292","Hyun-Chul Kim","Nam-Yong Ghim, Ghil-Seok Yang, Hyun-Chul Kim, Ulugbek Yakhshiev","Baryonic matter and the medium modification of the baryon masses","14 pages, 8 figures","Phys. Rev. C 103, 064306 (2021)","10.1103/PhysRevC.103.064306","INHA-NTG-02/2021","nucl-th astro-ph.HE hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the properties of baryonic matter within the framework of the
in-medium modified chiral soliton model by taking into account the effects of
surrounding baryonic environment on the properties of in-medium baryons. The
internal parameters of the model are determined based on nuclear phenomenology
at nonstrange sector and fitted by reproducing nuclear matter properties near
the saturation point. We discuss the equations of state in different nuclear
environments such as symmetric nuclear matter, neutron and strange matters. We
show that the results for the equations of state are in good agreement with the
phenomenology of nuclear matter. We also discuss how the SU(3) baryons masses
undergo changes in these various types of nuclear matter.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:24:22 GMT""}]","2021-06-16"
"2102.05293","Hai-Bing Fu","Dan-Dan Hu, Hai-Bing Fu, Tao Zhong, Long Zeng, Wei Cheng, Xing-Gang Wu","$\eta^{(\prime)}$-meson twist-2 distribution amplitude within QCD sum
  rule approach and its application to the semi-leptonic decay $ D_s^+
  \to\eta^{(\prime)}\ell^+ \nu_\ell$","52 pages, 11 figures, version to be published in EPJC","Eur. Phys. J. C 82 (2022) 12","10.1140/epjc/s10052-021-09958-0",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we make a detailed discussion on the $\eta$ and $\eta'$-meson
leading-twist light-cone distribution amplitude
$\phi_{2;\eta^{(\prime)}}(u,\mu)$ by using QCD sum rules approach under the
background field theory. Taking both the non-perturbative condensates up to
dimension-six and NLO QCD corrections to the perturbative part, its first three
moments $\langle\xi^n_{2;\eta^{(\prime)}}\rangle|_{\mu_0} $ with $n = (2,4,6)$
at initial scale $\mu_0 = 1$ GeV can be determined. e.g.
$\langle\xi_{2;\eta}^2\rangle|_{\mu_0} =0.231_{-0.013}^{+0.010}$,
$\langle\xi_{2;\eta}^4 \rangle|_{\mu_0} =0.109_{-0.007}^{+0.007}$, and
$\langle\xi_{2;\eta}^6 \rangle|_{\mu_0} =0.066_{-0.006}^{+0.006}$ for
$\eta$-meson, $\langle\xi_{2;\eta'}^2\rangle|_{\mu_0}
=0.211_{-0.017}^{+0.015}$, $\langle\xi_{2;\eta'}^4 \rangle|_{\mu_0}
=0.093_{-0.009}^{+0.009}$, and $\langle\xi_{2;\eta'}^6 \rangle|_{\mu_0}
=0.054_{-0.008}^{+0.008}$ for $\eta'$-meson. Next, we calculate
$D_s\to\eta^{(\prime)}$ TFFs $f^{\eta^{(\prime)}}_+(q^2)$ within QCD light-cone
sum rules approach up to NLO level. The values at large recoil region are
$f^{\eta}_+(0) = 0.476_{-0.036}^{+0.040}$ and $f^{\eta'}_+(0) =
0.544_{-0.042}^{+0.046}$. After extrapolating TFFs to the allowable physical
regions within the series expansion, we obtain the branching fractions of the
semi-leptonic decay, i.e. $D_s^+\to\eta^{(\prime)}\ell^+ \nu_\ell$, i.e. ${\cal
B}(D_s^+\to\eta^{(\prime)}
e^+\nu_e)=2.346_{-0.331}^{+0.418}(0.792_{-0.118}^{+0.141})\times10^{-2}$ and
${\cal B}(D_s^+\to\eta^{(\prime)}
\mu^+\nu_\mu)=2.320_{-0.327}^{+0.413}(0.773_{-0.115}^{+0.138})\times10^{-2}$
for $\ell = (e, \mu)$ channels respectively. And in addition to that, the
mixing angle for $\eta-\eta'$ with $\varphi$ and ratio for the different decay
channels ${\cal R}_{\eta'/\eta}^\ell$ are given, which show good agreement with
the recent BESIII measurements.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:24:49 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 21:46:32 GMT""},{""version"":""v3"",""created"":""Sun, 19 Dec 2021 01:30:20 GMT""}]","2022-01-11"
"2102.05294","Mamiya Kawaguchi","Mamiya Kawaguchi, Shinya Matsuzaki, Akio Tomiya","Detecting scale anomaly in chiral phase transition of QCD: new critical
  endpoint pinned down","23 pages, 7 figures, some references added, minor corrections made,
  version accepted in JHEP",,"10.1007/JHEP12(2021)175",,"hep-ph hep-lat hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Violation of scale symmetry, scale anomaly, being a radical concept in
quantum field theory, is of importance to comprehend the vacuum structure of
QCD, and should potentially contribute to the chiral phase transition in
thermal QCD, as well as the chiral and U(1) axial symmetry. Though it should be
essential, direct evidence of scale anomalies has never been observed in the
chiral phase transition. We propose a methodology to detect a scale anomaly in
the chiral phase transition, which is an electromagnetically induced scale
anomaly: apply a weak magnetic field background onto two-flavor massless QCD
with an extremely heavy strange quark, first observe the chiral crossover;
second, adjusting the strange quark mass to be smaller and smaller, observe the
second-order chiral phase transition, and then the first-order one in the
massless-three flavor limit. Thus, the second-order chiral phase transition,
observed as the evidence of the quantum scale anomaly, is a new critical
endpoint. It turns out that this electromagnetic scale anomaly gets most
operative in the weak magnetic field regime, rather than a strong field region.
We also briefly address accessibility of lattice QCD, a prospected application
to dense matter system, and implications to astrophysical observations, such as
gravitational wave productions provided from thermomagnetic QCD-like theories.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:27:49 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 05:57:32 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 01:52:17 GMT""}]","2022-01-05"
"2102.05295","Xin Liu","Xin Liu, Bin Li, Pengyi Shi, Lei Ying","An Efficient Pessimistic-Optimistic Algorithm for Stochastic Linear
  Bandits with General Constraints",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers stochastic linear bandits with general nonlinear
constraints. The objective is to maximize the expected cumulative reward over
horizon $T$ subject to a set of constraints in each round $\tau\leq T$. We
propose a pessimistic-optimistic algorithm for this problem, which is efficient
in two aspects. First, the algorithm yields $\tilde{\cal
O}\left(\left(\frac{K^{0.75}}{\delta}+d\right)\sqrt{\tau}\right)$ (pseudo)
regret in round $\tau\leq T,$ where $K$ is the number of constraints, $d$ is
the dimension of the reward feature space, and $\delta$ is a Slater's constant;
and zero constraint violation in any round $\tau>\tau',$ where $\tau'$ is
independent of horizon $T.$ Second, the algorithm is computationally efficient.
Our algorithm is based on the primal-dual approach in optimization and includes
two components. The primal component is similar to unconstrained stochastic
linear bandits (our algorithm uses the linear upper confidence bound algorithm
(LinUCB)). The computational complexity of the dual component depends on the
number of constraints, but is independent of the sizes of the contextual space,
the action space, and the feature space. Thus, the overall computational
complexity of our algorithm is similar to that of the linear UCB for
unconstrained stochastic linear bandits.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:30:37 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 13:50:55 GMT""},{""version"":""v3"",""created"":""Wed, 10 Nov 2021 02:52:58 GMT""}]","2021-11-11"
"2102.05296","Veekesh Kumar","Veekesh Kumar","On inhomogeneous extension of Thue-Roth's type inequality with moving
  targets","arXiv admin note: text overlap with arXiv:2001.00386","International Mathematics Research Notices, 2022;, rnac046","10.1093/imrn/rnac046",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Gamma\subset \overline{\mathbb Q}^{\times}$ be a finitely generated
multiplicative group of algebraic numbers. Let $\delta,
\beta\in\overline{\mathbb Q}^\times$ be algebraic numbers with $\beta$
irrational. In this paper, we prove that there exist only finitely many triples
$(u, q, p)\in\Gamma\times\mathbb{Z}^2$ with $d = [\mathbb{Q}(u):\mathbb{Q}]$
such that $$ 0<|\delta qu+\beta-p|<\frac{1}{H^\varepsilon(u)q^{d+\varepsilon}},
$$ where $H(u)$ denotes the absolute Weil height. As an application of this
result, we also prove a transcendence result, which states as follows: Let
$\alpha>1$ be a real number. Let $\beta$ be an algebraic irrational and
$\lambda$ be a non-zero real algebraic number. For a given real number
$\varepsilon >0$, if there are infinitely many natural numbers $n$ for which
$||\lambda\alpha^n+\beta|| < 2^{- \varepsilon n}$ holds true, then $\alpha$ is
transcendental, where $||x||$ denotes the distance from its nearest integer.
When $\alpha$ and $\beta$ both are algebraic satisfying same conditions, then a
particular result of Kulkarni, Mavraki and Nguyen, proved in [3] asserts that
$\alpha^d$ is a Pisot number. When $\beta $ is algebraic irrational, our result
implies that no algebraic number $\alpha$ satisfies the inequality for
infinitely many natural numbers $n$. Also, our result strengthens a result of
Wagner and Ziegler [6]. The proof of our results uses the Subspace Theorem
based on the idea of Corvaja and Zannier [2] together with various modification
play a crucial role in the proof.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:31:28 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 17:26:05 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 04:44:42 GMT""},{""version"":""v4"",""created"":""Sun, 2 Oct 2022 05:17:42 GMT""}]","2022-10-04"
"2102.05297","Ji\v{r}\'i Filipovi\v{c}","Ji\v{r}\'i Filipovi\v{c} and Jana Hozzov\'a and Amin Nezarat and
  Jaroslav O\v{l}ha and Filip Petrovi\v{c}","Using hardware performance counters to speed up autotuning convergence
  on GPUs",,,,,"cs.DC cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, GPU accelerators are commonly used to speed up general-purpose
computing tasks on a variety of hardware. However, due to the diversity of GPU
architectures and processed data, optimization of codes for a particular type
of hardware and specific data characteristics can be extremely challenging. The
autotuning of performance-relevant source-code parameters allows for automatic
optimization of applications and keeps their performance portable. Although the
autotuning process typically results in code speed-up, searching the tuning
space can bring unacceptable overhead if (i) the tuning space is vast and full
of poorly-performing implementations, or (ii) the autotuning process has to be
repeated frequently because of changes in processed data or migration to
different hardware.
  In this paper, we introduce a novel method for searching tuning spaces. The
method takes advantage of collecting hardware performance counters (also known
as profiling counters) during empirical tuning. Those counters are used to
navigate the searching process towards faster implementations. The method
requires the tuning space to be sampled on any GPU. It builds a
problem-specific model, which can be used during autotuning on various, even
previously unseen inputs or GPUs. Using a set of five benchmarks, we
experimentally demonstrate that our method can speed up autotuning when an
application needs to be ported to different hardware or when it needs to
process data with different characteristics. We also compared our method to
state of the art and show that our method is superior in terms of the number of
searching steps and typically outperforms other searches in terms of
convergence time.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:42:39 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 10:48:21 GMT""}]","2021-09-20"
"2102.05298","Yunfei Chu","Yunfei Chu, Xiaowei Wang, Jianxin Ma, Kunyang Jia, Jingren Zhou,
  Hongxia Yang","Inductive Granger Causal Modeling for Multivariate Time Series","6 pages, 6 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Granger causal modeling is an emerging topic that can uncover Granger causal
relationship behind multivariate time series data. In many real-world systems,
it is common to encounter a large amount of multivariate time series data
collected from different individuals with sharing commonalities. However, there
are ongoing concerns regarding Granger causality's applicability in such large
scale complex scenarios, presenting both challenges and opportunities for
Granger causal structure reconstruction. Existing methods usually train a
distinct model for each individual, suffering from inefficiency and
over-fitting issues. To bridge this gap, we propose an Inductive GRanger cAusal
modeling (InGRA) framework for inductive Granger causality learning and common
causal structure detection on multivariate time series, which exploits the
shared commonalities underlying the different individuals. In particular, we
train one global model for individuals with different Granger causal structures
through a novel attention mechanism, called prototypical Granger causal
attention. The model can detect common causal structures for different
individuals and infer Granger causal structures for newly arrived individuals.
Extensive experiments, as well as an online A/B test on an E-commercial
advertising platform, demonstrate the superior performances of InGRA.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:48:00 GMT""}]","2021-02-11"
"2102.05299","Ji\v{r}\'i Filipovi\v{c}","Ji\v{r}\'i Filipovi\v{c} and Jana Hozzov\'a and Amin Nezarat and
  Jaroslav O\v{l}ha and Filip Petrovi\v{c}","Searching CUDA code autotuning spaces with hardware performance
  counters: data from benchmarks running on various GPU architectures",,,,,"cs.DC cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed several autotuning benchmarks in CUDA that take into
account performance-relevant source-code parameters and reach near
peak-performance on various GPU architectures. We have used them during the
development and evaluation of a novel search method for tuning space proposed
in [1]. With our framework Kernel Tuning Toolkit, freely available at Github,
we measured computation times and hardware performance counters on several GPUs
for the complete tuning spaces of five benchmarks. These data, which we provide
here, might benefit research of search algorithms for the tuning spaces of GPU
codes or research of relation between applied code optimization, hardware
performance counters, and GPU kernels' performance.
  Moreover, we describe the scripts we used for robust evaluation of our
searcher and comparison to others in detail. In particular, the script that
simulates the tuning, i.e., replaces time-demanding compiling and executing the
tuned kernels with a quick reading of the computation time from our measured
data, makes it possible to inspect the convergence of tuning search over a
large number of experiments. These scripts, freely available with our other
codes, make it easier to experiment with search algorithms and compare them in
a robust way.
  During our research, we generated models for predicting values of performance
counters from values of tuning parameters of our benchmarks. Here, we provide
the models themselves and describe the scripts we implemented for their
training. These data might benefit researchers who want to reproduce or build
on our research.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:51:09 GMT""}]","2021-02-11"
"2102.05300","Kohei Hayashi","Kohei Hayashi, Elisa G. M. Ferreira, and Hei Yin Jowett Chan","Narrowing the mass range of Fuzzy Dark Matter with Ultra-faint Dwarfs","7 pages, 3 figures. Accepted for publication in ApJ Letters",,"10.3847/2041-8213/abf501",,"astro-ph.CO astro-ph.GA hep-ph","http://creativecommons.org/licenses/by/4.0/","  Fuzzy dark matter (FDM) is an attractive dark matter candidate motivated by
small scale problems in astrophysics and with a rich phenomenology on those
scales. We scrutinize the FDM model, more specifically the mass of the FDM
particle, through a dynamical analysis for the Galactic ultra-faint dwarf (UFD)
galaxies. We use a sample of 18 UFDs to place the strongest constraints to date
on the mass of the FDM particle, updating on previous bounds using a subset of
the sample used here. We find that most of the sample UFDs prefer a FDM
particle mass heavier than $10^{-21}\mathrm{eV}$. In particular, Segue 1
provides the strongest constraint, with
$m_\psi=1.1^{+8.3}_{-0.7}\times10^{-19}\mathrm{eV}$. The constraints found here
are the first that are compatible with various other independent cosmological
and astrophysical bounds found in the literature, in particular with the latest
bounds using the Lyman-$\alpha$ forest. We also find that the constraints
obtained in this work are not compatible with the bounds from luminous dwarf
galaxies, as already pointed out in the previous work using UFDs. This could
indicate that although a viable dark matter model, it might be challenging for
the FDM model to solve the small scale problems.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:51:13 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 02:35:27 GMT""}]","2021-05-05"
"2102.05301","Daniel Anderson","Daniel Anderson and Guy E. Blelloch","Parallel Minimum Cuts in $O(m \log^2(n))$ Work and Low Depth","This is the full version of the paper appearing in the ACM Symposium
  on Parallelism in Algorithms and Architectures (SPAA), 2021","Proceedings of The 33rd ACM Symposium on Parallelism in Algorithms
  and Architectures (SPAA '21) (2021) 71-82","10.1145/3409964.3461797",,"cs.DS cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a randomized $O(m \log^2 n)$ work, $O(\text{polylog } n)$ depth
parallel algorithm for minimum cut. This algorithm matches the work bounds of a
recent sequential algorithm by Gawrychowski, Mozes, and Weimann [ICALP'20], and
improves on the previously best parallel algorithm by Geissmann and Gianinazzi
[SPAA'18], which performs $O(m \log^4 n)$ work in $O(\text{polylog } n)$ depth.
  Our algorithm makes use of three components that might be of independent
interest. Firstly, we design a parallel data structure that efficiently
supports batched mixed queries and updates on trees. It generalizes and
improves the work bounds of a previous data structure of Geissmann and
Gianinazzi and is work efficient with respect to the best sequential algorithm.
Secondly, we design a parallel algorithm for approximate minimum cut that
improves on previous results by Karger and Motwani. We use this algorithm to
give a work-efficient procedure to produce a tree packing, as in Karger's
sequential algorithm for minimum cuts. Lastly, we design an efficient parallel
algorithm for solving the minimum $2$-respecting cut problem.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:56:02 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 00:31:30 GMT""}]","2021-12-30"
"2102.05302","Brajesh Kumar Mani","Ravi Kumar, S. Chattopadhyay, D. Angom and B. K. Mani","RCC calculation of electric dipole polarizability and correlation energy
  of Cn, Nh$^+$ and Og: Correlation effects from lighter to superheavy elements","15 pages, 12 tables, 10 figures","Phys. Rev. A 103, 062803 (2021)","10.1103/PhysRevA.103.062803",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We employ a fully relativistic coupled-cluster theory to calculate the
ground-state electric dipole polarizability and electron correlation energy of
superheavy elements Cn, Nh$^+$ and Og. To assess the trend of electron
correlation as function of $Z$, we also calculate the correlation energies for
three lighter homologs--Zn, Cd and Hg; Ga$^+$, In$^+$ and Tl$^+$; Kr, Xe and
Rn--for each superheavy elements. The relativistic effects and quantum
electrodynamical corrections are included using the Dirac-Coulomb-Breit
Hamiltonian with the corrections from the Uehling potential and the
self-energy. The effects of triple excitations are considered perturbatively in
the theory. Furthermore, large bases are used to test the convergence of
results. Our recommended values of polarizability are in good agreement with
previous theoretical results for all SHEs. From our calculations we find that
the dominant contribution to polarizability is from the valence electrons in
all superheavy elements. Except for Cn and Og, we observe a decreasing
contribution from lighter to superheavy elements from the Breit interaction.
For the corrections from the vacuum polarization and self-energy, we observe a
trend of increasing contributions with $Z$. From energy calculations, we find
that the second-order many-body perturbation theory overestimates the electron
correlation energy for all the elements considered in this work.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:56:03 GMT""}]","2021-06-09"
"2102.05303","Yue Xie","Yue Xie, Aneta Neumann, Frank Neumann","Heuristic Strategies for Solving Complex Interacting Stockpile Blending
  Problem with Chance Constraints",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heuristic algorithms have shown a good ability to solve a variety of
optimization problems. Stockpile blending problem as an important component of
the mine scheduling problem is an optimization problem with continuous search
space containing uncertainty in the geologic input data. The objective of the
optimization process is to maximize the total volume of materials of the
operation and subject to resource capacities, chemical processes, and customer
requirements. In this paper, we consider the uncertainty in material grades and
introduce chance constraints that are used to ensure the constraints with high
confidence. To address the stockpile blending problem with chance constraints,
we propose a differential evolution algorithm combining two repair operators
that are used to tackle the two complex constraints. In the experiment section,
we compare the performance of the approach with the deterministic model and
stochastic models by considering different chance constraints and evaluate the
effectiveness of different chance constraints.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 07:56:18 GMT""}]","2021-02-11"
"2102.05304","Vinod Kumar","Vinod Kumar and Krishnendra Shekhawat","A Theory of Rectangularly Dualizable Graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A plane graph is called a rectangular graph if each of its edges can be
oriented either horizontally or vertically, each of its interior regions is a
four-sided region and all interior regions can be fitted in a rectangular
enclosure. Only planar graphs can be dualized. If the dual of a plane graph is
a rectangular graph, then the plane graph is a rectangularly dualizable graph.
  In 1985, Ko\'zmi\'nski and Kinnen presented a necessary and sufficient
condition for the existence of a rectangularly dualizable graph for a separable
connected plane graph. In this paper, we present a counter example for which
the conditions given by them for separable connected plane graphs fail and
hence, we derive a necessary and sufficient condition for a plane graph to be a
rectangularly dualizable graph.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:01:59 GMT""}]","2021-02-11"
"2102.05305","Sagnick Mukherjee Mr","Sagnick Mukherjee, Natasha E. Batalha, Mark S. Marley","Cloud Parameterizations and their Effect on Retrievals of Exoplanet
  Reflection Spectroscopy","21 Pages, 18 Figures, Accepted for publication in The Astrophysical
  Journal (ApJ)",,"10.3847/1538-4357/abe53b",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Future space-based direct imaging missions will perform low-resolution
(R$<$100) optical (0.3-1~$\mu$m) spectroscopy of planets, thus enabling
reflected spectroscopy of cool giants. Reflected light spectroscopy is encoded
with rich information about the scattering and absorbing properties of planet
atmospheres. Given the diversity of clouds and hazes expected in exoplanets, it
is imperative we solidify the methodology to accurately and precisely retrieve
these scattering and absorbing properties that are agnostic to cloud species.
In particular, we focus on determining how different cloud parameterizations
affect resultant inferences of both cloud and atmospheric composition. We
simulate mock observations of the reflected spectra from three top priority
direct imaging cool giant targets with different effective temperatures,
ranging from 135 K to 533 K. We perform retrievals of cloud structure and
molecular abundances on these three planets using four different
parameterizations, each with increasing levels of cloud complexity. We find
that the retrieved atmospheric and scattering properties strongly depend on the
choice of cloud parameterization. For example, parameterizations that are too
simplistic tend to overestimate the abundances. Overall, we are unable to
retrieve precise/accurate gravity beyond $\pm$50\%. Lastly, we find that even
low SNR=5, low R=40 reflected light spectroscopy gives cursory zeroth order
insights into cloud deck position relative to molecular and Rayleigh optical
depth level.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:04:28 GMT""}]","2021-04-14"
"2102.05306","Andrew Feutrill","Andrew Feutrill and Matthew Roughan","Differential Entropy Rate Characterisations of Long Range Dependent
  Processes",,,,,"cs.IT math.IT math.PR","http://creativecommons.org/licenses/by/4.0/","  A quantity of interest to characterise continuous-valued stochastic processes
is the differential entropy rate. The rate of convergence of many properties of
LRD processes is slower than might be expected, based on the intuition for
conventional processes, e.g. Markov processes. Is this also true of the entropy
rate?
  In this paper we consider the properties of the differential entropy rate of
stochastic processes that have an autocorrelation function that decays as a
power law. We show that power law decaying processes with similar
autocorrelation and spectral density functions, Fractional Gaussian Noise and
ARFIMA(0,d,0), have different entropic properties, particularly for negatively
correlated parameterisations. Then we provide an equivalence between the mutual
information between past and future and the differential excess entropy for
stationary Gaussian processes, showing the finiteness of this quantity is the
boundary between long and short range dependence. Finally, we analyse the
convergence of the conditional entropy to the differential entropy rate and
show that for short range dependence that the rate of convergence is of the
order $O(n^{-1})$, but it is slower for long range dependent processes and
depends on the Hurst parameter.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:06:36 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 05:23:46 GMT""}]","2021-11-02"
"2102.05307","Nakahiro Yoshida","Haruhiko Inatsugu and Nakahiro Yoshida","Global jump filters and realized volatility","Some modifications and corrections have been done",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a semimartingale with jumps, we propose a new estimation method for
integrated volatility, i.e., the quadratic variation of the continuous
martingale part, based on the global jump filter proposed by Inatsugu and
Yoshida [8]. To decide whether each increment of the process has jumps, the
global jump filter adopts the upper $\alpha$-quantile of the absolute
increments as the threshold. This jump filter is called global since it uses
all the observations to classify one increment. We give a rate of convergence
and prove asymptotic mixed normality of the global realized volatility and its
variant ""Winsorized global volatility"". By simulation studies, we show that our
estimators outperform previous realized volatility estimators that use a few
adjacent increments to mitigate the effects of jumps.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:07:38 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 05:53:11 GMT""}]","2021-02-16"
"2102.05308","Brandon Lockhart BSc","Brandon Lockhart, Jinglin Peng, Weiyuan Wu, Jiannan Wang, Eugene Wu","Explaining Inference Queries with Bayesian Optimization",,,,,"cs.DB cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Obtaining an explanation for an SQL query result can enrich the analysis
experience, reveal data errors, and provide deeper insight into the data.
Inference query explanation seeks to explain unexpected aggregate query results
on inference data; such queries are challenging to explain because an
explanation may need to be derived from the source, training, or inference data
in an ML pipeline. In this paper, we model an objective function as a black-box
function and propose BOExplain, a novel framework for explaining inference
queries using Bayesian optimization (BO). An explanation is a predicate
defining the input tuples that should be removed so that the query result of
interest is significantly affected. BO - a technique for finding the global
optimum of a black-box function - is used to find the best predicate. We
develop two new techniques (individual contribution encoding and warm start) to
handle categorical variables. We perform experiments showing that the
predicates found by BOExplain have a higher degree of explanation compared to
those found by the state-of-the-art query explanation engines. We also show
that BOExplain is effective at deriving explanations for inference queries from
source and training data on a variety of real-world datasets. BOExplain is
open-sourced as a Python package at https://github.com/sfu-db/BOExplain.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:08:32 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 16:49:38 GMT""}]","2021-06-22"
"2102.05309","Junjie Cao","Haijing Zhou, Junjie Cao, Jingwei Lian, Di Zhang","Singlino-dominated dark matter in $Z_3$-NMSSM","28 pages, 8 figures","Phys. Rev. D 104, 015017 (2021)","10.1103/PhysRevD.104.015017",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Singlino-dominated dark matter properties are investigated in the $Z_3$
Next-to-Minimal Supersymmetric Standard Model, producing superweak interactions
with nucleons involved in dark matter direct detection experiments. Approximate
analytical formulas describing the dark matter abundance and cross section in
the scattering with nucleons are used to illustrate a dependence on theoretical
parameters in neutralino and Higgs sectors. It is shown that the measured
abundance requires a sizable singlet--doublet Higgs coupling parameter
$\lambda$, while the experimental detection results prefer a small $\lambda$.
The parameter space is then surveyed using a nest sampling technique guided by
a likelihood function containing various observables in dark matter, Higgs, and
B physics, such as the abundance and the scattering cross section. It is
demonstrated that dark matter can achieve the correct abundance through
$\tilde{\chi}_1^0 \tilde{\chi}_1^0 \to t \bar{t}$ or co-annihilation with
higgsinos. The former process provides significantly larger Bayesian evidence
than the latter, but this will be examined by the near-future PandaX-4T
experiment. If the experiment shows no signs of dark matter, it will become
highly disfavored. Furthermore, four cases are summarized to suppress dark
matter scattering with nucleons, namely, a small $\lambda$ and three kinds of
cancellation between different contributions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:14:39 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 14:40:03 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 01:32:04 GMT""},{""version"":""v4"",""created"":""Fri, 28 May 2021 00:23:18 GMT""}]","2021-07-21"
"2102.05310","Florian Auer","Florian Auer and Rasmus Ros and Lukas Kaltenbrunner and Per Runeson
  and Michael Felderer","Controlled Experimentation in Continuous Experimentation: Knowledge and
  Challenges",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context: Continuous experimentation and A/B testing is an established
industry practice that has been researched for more than 10 years. Our aim is
to synthesize the conducted research.
  Objective: We wanted to find the core constituents of a framework for
continuous experimentation and the solutions that are applied within the field.
Finally, we were interested in the challenges and benefits reported of
continuous experimentation.
  Method: We applied forward snowballing on a known set of papers and
identified a total of 128 relevant papers. Based on this set of papers we
performed two qualitative narrative syntheses and a thematic synthesis to
answer the research questions.
  Results: The framework constituents for continuous experimentation include
experimentation processes as well as supportive technical and organizational
infrastructure. The solutions found in the literature were synthesized to nine
themes, e.g. experiment design, automated experiments, or metric specification.
Concerning the challenges of continuous experimentation, the analysis
identified cultural, organizational, business, technical, statistical, ethical,
and domain-specific challenges. Further, the study concludes that the benefits
of experimentation are mostly implicit in the studies.
  Conclusions: The research on continuous experimentation has yielded a large
body of knowledge on experimentation. The synthesis of published research
presented within include recommended infrastructure and experimentation process
models, guidelines to mitigate the identified challenges, and what problems the
various published solutions solve.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:15:12 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 11:41:06 GMT""}]","2021-02-18"
"2102.05311","Hanshu Yan","Hanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan,
  Masashi Sugiyama","CIFS: Improving Adversarial Robustness of CNNs via Channel-wise
  Importance-based Feature Selection",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the adversarial robustness of CNNs from the perspective of
channel-wise activations. By comparing \textit{non-robust} (normally trained)
and \textit{robustified} (adversarially trained) models, we observe that
adversarial training (AT) robustifies CNNs by aligning the channel-wise
activations of adversarial data with those of their natural counterparts.
However, the channels that are \textit{negatively-relevant} (NR) to predictions
are still over-activated when processing adversarial data. Besides, we also
observe that AT does not result in similar robustness for all classes. For the
robust classes, channels with larger activation magnitudes are usually more
\textit{positively-relevant} (PR) to predictions, but this alignment does not
hold for the non-robust classes. Given these observations, we hypothesize that
suppressing NR channels and aligning PR ones with their relevances further
enhances the robustness of CNNs under AT. To examine this hypothesis, we
introduce a novel mechanism, i.e., \underline{C}hannel-wise
\underline{I}mportance-based \underline{F}eature \underline{S}election (CIFS).
The CIFS manipulates channels' activations of certain layers by generating
non-negative multipliers to these channels based on their relevances to
predictions. Extensive experiments on benchmark datasets including CIFAR10 and
SVHN clearly verify the hypothesis and CIFS's effectiveness of robustifying
CNNs. \url{https://github.com/HanshuYAN/CIFS}
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:16:43 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 02:34:34 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 03:27:29 GMT""},{""version"":""v4"",""created"":""Wed, 10 Nov 2021 02:37:20 GMT""}]","2021-11-11"
"2102.05312","Chicheng Zhang","Chicheng Zhang and Yinan Li","Improved Algorithms for Efficient Active Learning Halfspaces with
  Massart and Tsybakov noise","32 pages; COLT 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a computationally-efficient PAC active learning algorithm for
$d$-dimensional homogeneous halfspaces that can tolerate Massart noise (Massart
and N\'ed\'elec, 2006) and Tsybakov noise (Tsybakov, 2004). Specialized to the
$\eta$-Massart noise setting, our algorithm achieves an
information-theoretically near-optimal label complexity of $\tilde{O}\left(
\frac{d}{(1-2\eta)^2} \mathrm{polylog}(\frac1\epsilon) \right)$ under a wide
range of unlabeled data distributions (specifically, the family of ""structured
distributions"" defined in Diakonikolas et al. (2020)). Under the more
challenging Tsybakov noise condition, we identify two subfamilies of noise
conditions, under which our efficient algorithm provides label complexity
guarantees strictly lower than passive learning algorithms.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:17:17 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 05:37:19 GMT""}]","2021-08-12"
"2102.05313","Carl Remlinger","Carl Remlinger, Joseph Mikael, Romuald Elie","Conditional Loss and Deep Euler Scheme for Time Series Generation","14 page, 9 Figures",,,,"stat.ML cs.LG math.PR stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce three new generative models for time series that are based on
Euler discretization of Stochastic Differential Equations (SDEs) and
Wasserstein metrics. Two of these methods rely on the adaptation of generative
adversarial networks (GANs) to time series. The third algorithm, called
Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the
transition probability distributions over all time steps. In the context of Ito
processes, we provide theoretical guarantees that minimizing this criterion
implies accurate estimations of the drift and volatility parameters. We
demonstrate empirically that CEGEN outperforms state-of-the-art and GAN
generators on both marginal and temporal dynamics metrics. Besides, it
identifies accurate correlation structures in high dimension. When few data
points are available, we verify the effectiveness of CEGEN, when combined with
transfer learning methods on Monte Carlo simulations. Finally, we illustrate
the robustness of our method on various real-world datasets.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:18:35 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 15:09:04 GMT""},{""version"":""v3"",""created"":""Tue, 8 Jun 2021 10:45:08 GMT""},{""version"":""v4"",""created"":""Fri, 11 Jun 2021 07:32:40 GMT""},{""version"":""v5"",""created"":""Wed, 6 Oct 2021 15:00:23 GMT""}]","2021-10-07"
"2102.05314","Yohann de Castro","Yohann de Castro (ICJ, CERMICS), Luca Mencarelli (CERMICS)","Forecasting Nonnegative Time Series via Sliding Mask Method (SMM) and
  Latent Clustered Forecast (LCF)",,,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider nonnegative time series forecasting framework. Based on recent
advances in Nonnegative Matrix Factorization (NMF) and Archetypal Analysis, we
introduce two procedures referred to as Sliding Mask Method (SMM) and Latent
Clustered Forecast (LCF). SMM is a simple and powerful method based on time
window prediction using Completion of Nonnegative Matrices. This new procedure
combines low nonnegative rank decomposition and matrix completion where the
hidden values are to be forecasted. LCF is two stage: it leverages archetypal
analysis for dimension reduction and clustering of time series, then it uses
any black-box supervised forecast solver on the clustered latent
representation. Theoretical guarantees on uniqueness and robustness of the
solution of NMF Completion-type problems are also provided for the first time.
Finally, numerical experiments on real-world and synthetic data-set confirms
forecasting accuracy for both the methodologies.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:29:55 GMT""}]","2021-02-11"
"2102.05315","Baptiste Gault","Xinglong Ye, Fengkai Yan, Lukas Schaefer, Di Wang, Holger Ge{\ss}wein,
  Wu Wang, Mohammed Reda Chellali, Leigh T. Stephenson, Konstantin Skokov,
  Oliver Gutfleisch, Dierk Raabe, Horst Hahn, Baptiste Gault, Robert Kruk","Magneto-electric Tuning of Pinning-Type Permanent Magnets through
  Atomic-Scale Engineering of Grain Boundaries",,,"10.1002/adma.202006853",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pinning-type magnets maintaining high coercivity, i.e. the ability to sustain
magnetization, at high temperature are at the core of thriving clean-energy
technologies. Among these, Sm2Co17-based magnets are excellent candidates owing
to their high-temperature stability. However, despite decades of efforts to
optimize the intragranular microstructure, the coercivity currently only
reaches 20~30% of the theoretical limits. Here, the roles of the grain-interior
nanostructure and the grain boundaries in controlling coercivity are
disentangled by an emerging magneto-electric approach. Through hydrogen
charging/discharging by applying voltages of only ~ 1 V, the coercivity is
reversibly tuned by an unprecedented value of ~ 1.3 T. In situ
magneto-structural measurements and atomic-scale tracking of hydrogen atoms
reveal that the segregation of hydrogen atoms at the grain boundaries, rather
than the change of the crystal structure, dominates the reversible and
substantial change of coercivity. Hydrogen lowers the local magnetocrystalline
anisotropy and facilitates the magnetization reversal starting from the grain
boundaries. Our study reveals the previously neglected critical role of grain
boundaries in the conventional magnetisation-switching paradigm, suggesting a
critical reconsideration of strategies to overcome the coercivity limits in
permanent magnets, via for instance atomic-scale grain boundary engineering.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:30:52 GMT""}]","2021-02-11"
"2102.05316","Raphael Mitteau","R Mitteau (IRFM), P Chappuis (IRFM), L Moncel (IRFM), J Schlosser
  (IRFM)","Evidence of damage in carbon fibre composite tiles joined to a metallic
  heat sink under high heat flux fatigue",,"Journal of Nuclear Materials, Elsevier, 1998, 258-263, pp.972 -
  977","10.1016/S0022-3115(98)00314-6",,"physics.plasm-ph physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two years experience with Active Metal Casting flat bonds shows that this
technology is suitable for the heat fluxes expected in Tore Supra (10
MW/m${}^2$). Tests were pursued up to 3330 cycles, with elements still
functional. At higher heat fluxes, fatigue damage is observed, but the bond
resists remarkably well with no tile detachment. Examination of such
deliberately damaged bonds showed distributed cracking, proving the absence of
any weak link. The limitations to those higher heat fluxes are more related to
the design and the base materials than to the bond itself.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:32:58 GMT""}]","2021-02-17"
"2102.05317","Junjie Cao","Junjie Cao, Demin Li, Jingwei Lian, Yuanfang Yue, and Haijing Zhou","Singlino-dominated dark matter in general NMSSM","29 pages, 9 figures",,"10.1007/JHEP06(2021)176",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The general Next-to-Minimal Supersymmetric Standard Model (NMSSM) describes
the singlino-dominated dark-matter (DM) property by four independent
parameters: singlet-doublet Higgs coupling coefficient $\lambda$, Higgsino mass
$\mu_{tot}$, DM mass $m_{\tilde{\chi}_1^0}$, and singlet Higgs self-coupling
coefficient $\kappa$. The first three parameters strongly influence the
DM-nucleon scattering rate, while $\kappa$ usually affects the scattering only
slightly. This characteristic implies that singlet-dominated particles may form
a secluded DM sector. Under such a theoretical structure, the DM achieves the
correct abundance by annihilating into a pair of singlet-dominated Higgs bosons
by adjusting $\kappa$'s value. Its scattering with nucleons is suppressed when
$\lambda v/\mu_{tot}$ is small. This speculation is verified by sophisticated
scanning of the theory's parameter space with various experiment constraints
considered. In addition, the Bayesian evidence of the general NMSSM and that of
$Z_3$-NMSSM is computed. It is found that, at the cost of introducing one
additional parameter, the former is approximately $3.3 \times 10^3$ times the
latter. This result corresponds to Jeffrey's scale of 8.05 and implies that the
considered experiments strongly prefer the general NMSSM to the $Z_3$-NMSSM.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:34:37 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 14:34:23 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 01:23:43 GMT""}]","2021-07-14"
"2102.05318","Abhinav K. Jha","Zitong Yu, Md Ashequr Rahman, Thomas Schindler, Richard Laforest,
  Abhinav K. Jha","A physics and learning-based transmission-less attenuation compensation
  method for SPECT","9 pages, 4 figures, SPIE conference",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attenuation compensation (AC) is a pre-requisite for reliable quantification
and beneficial for visual interpretation tasks in single-photon emission
computed tomography (SPECT). Typical AC methods require the availability of an
attenuation map obtained using a transmission scan, such as a CT scan. This has
several disadvantages such as increased radiation dose, higher costs, and
possible misalignment between SPECT and CT scans. Also, often a CT scan is
unavailable. In this context, we and others are showing that scattered photons
in SPECT contain information to estimate the attenuation distribution. To
exploit this observation, we propose a physics and learning-based method that
uses the SPECT emission data in the photopeak and scatter windows to perform
transmission-less AC in SPECT. The proposed method uses data acquired in the
scatter window to reconstruct an initial estimate of the attenuation map using
a physics-based approach. A convolutional neural network is then trained to
segment this initial estimate into different regions. Pre-defined attenuation
coefficients are assigned to these regions, yielding the reconstructed
attenuation map, which is then used to reconstruct the activity map using an
ordered subsets expectation maximization-based reconstruction approach. We
objectively evaluated the performance of this method using a highly realistic
simulation study conducted on the clinically relevant task of detecting
perfusion defects in myocardial perfusion SPECT. Our results showed no
statistically significant differences between the performance achieved using
the proposed method and that with the true attenuation maps. Visually, the
images reconstructed using the proposed method looked similar to those with the
true attenuation map. Overall, these results provide evidence of the capability
of the proposed method to perform transmission-less AC and motivate further
evaluation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:35:51 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 08:18:27 GMT""}]","2021-02-12"
"2102.05319","Hua Chen","Hua Chen and X. C. Xie","Orbital order in a bosonic $p$-band triangular lattice","9 pages, 4 figures","Phys. Rev. B 103, 205144 (2021)","10.1103/PhysRevB.103.205144",,"cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a detailed study of the Bose-Hubbard model in a $p$-band
triangular lattice by focusing on the evolution of orbital order across the
superfluid-Mott insulator transition. Two distinct phases are found in the
superfluid regime. One of these phases adiabatically connects the weak
interacting limit. This phase is characterized by the intertwining of axial
$p_\pm=p_x \pm ip_y$ and in-plane $p_\theta=\cos\theta p_x+\sin\theta p_y$
orbital orders, which break the time-reversal symmetry and lattice symmetries
simultaneously. In addition, the calculated Bogoliubov excitation spectrum gaps
the original Dirac points in the single-particle spectrum but exhibits emergent
Dirac points. The other superfluid phase in close proximity to the Mott
insulator with unit boson filling shows a detwined in-plane ferro-orbital
order. Finally, an orbital exchange model is constructed for the Mott insulator
phase. Its classical ground state has an emergent SO$(2)$ rotational symmetry
in the in-plane orbital space and therefore enjoys an infinite degeneracy,
which is ultimately lifted by the orbital fluctuation via the order by disorder
mechanism. Our systematic analysis suggests that the in-plane ferro-orbital
order in the Mott insulator phase agrees with and likely evolves from the
latter superfluid phase.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:38:03 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 00:48:35 GMT""}]","2021-07-13"
"2102.05320","Sen Na","Sen Na, Mihai Anitescu, Mladen Kolar","An Adaptive Stochastic Sequential Quadratic Programming with
  Differentiable Exact Augmented Lagrangians","60 pages, 24 figures",,,,"math.OC cs.NA math.NA stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  We consider solving nonlinear optimization problems with a stochastic
objective and deterministic equality constraints. We assume for the objective
that its evaluation, gradient, and Hessian are inaccessible, while one can
compute their stochastic estimates by, for example, subsampling. We propose a
stochastic algorithm based on sequential quadratic programming (SQP) that uses
a differentiable exact augmented Lagrangian as the merit function. To motivate
our algorithm design, we first revisit and simplify an old SQP method
\citep{Lucidi1990Recursive} developed for solving deterministic problems, which
serves as the skeleton of our stochastic algorithm. Based on the simplified
deterministic algorithm, we then propose a non-adaptive SQP for dealing with
stochastic objective, where the gradient and Hessian are replaced by stochastic
estimates but the stepsizes are deterministic and prespecified. Finally, we
incorporate a recent stochastic line search procedure
\citep{Paquette2020Stochastic} into the non-adaptive stochastic SQP to
adaptively select the random stepsizes, which leads to an adaptive stochastic
SQP. The global ""almost sure"" convergence for both non-adaptive and adaptive
SQP methods is established. Numerical experiments on nonlinear problems in
CUTEst test set demonstrate the superiority of the adaptive algorithm.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:40:55 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 17:01:40 GMT""}]","2022-06-07"
"2102.05321","Siyuan Niu","Siyuan Niu and Aida Todri-Sanial","Enabling Multi-programming Mechanism for Quantum Computing in the NISQ
  Era",,"Quantum 7, 925 (2023)","10.22331/q-2023-02-16-925",,"cs.AR quant-ph","http://creativecommons.org/licenses/by/4.0/","  NISQ devices have several physical limitations and unavoidable noisy quantum
operations, and only small circuits can be executed on a quantum machine to get
reliable results. This leads to the quantum hardware under-utilization issue.
Here, we address this problem and improve the quantum hardware throughput by
proposing a Quantum Multi-programming Compiler (QuMC) to execute multiple
quantum circuits on quantum hardware simultaneously. This approach can also
reduce the total runtime of circuits. We first introduce a parallelism manager
to select an appropriate number of circuits to be executed at the same time.
Second, we present two different qubit partitioning algorithms to allocate
reliable partitions to multiple circuits - a greedy and a heuristic. Third, we
use the Simultaneous Randomized Benchmarking protocol to characterize the
crosstalk properties and consider them in the qubit partition process to avoid
the crosstalk effect during simultaneous executions. Finally, we enhance the
mapping transition algorithm to make circuits executable on hardware using a
decreased number of inserted gates. We demonstrate the performance of our QuMC
approach by executing circuits of different sizes on IBM quantum hardware
simultaneously. We also investigate this method on VQE algorithm to reduce its
overhead.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:46:16 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 10:28:02 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 09:53:55 GMT""}]","2023-02-22"
"2102.05322","Patrick Huber","Karolina Waszkowska, Pierre Josse, Clement Cabanetos, Philippe
  Blanchard, Bouchta Sahraoui, Dominique Guichaoua, Igor Syvorotka, Olha Kityk,
  Robert Wielgosz, Patrick Huber, Andriy V. Kityk","Anisotropic Confinement of Chromophores Induces Second-Order Nonlinear
  Optics in a Nanoporous Photonic Metamaterial","4 pages, 5 figures","Optics Letters 46, pp. 845-848 (2021)","10.1364/OL.416948",,"physics.optics cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Second-order nonlinear optics is the base for a large variety of devices
aimed at the active manipulation of light. However, physical principles
restrict its occurrence to non-centrosymmetric, anisotropic matter. This
significantly limits the number of base materials exhibiting nonlinear optics.
Here, we show that embedding chromophores in an array of conical channels 13 nm
across in monolithic silica results in mesoscopic anisotropic matter and thus
in a hybrid material showing second-harmonic generation (SHG). This non-linear
optics is compared to the one achieved in corona-poled polymer films containing
the identical chromophores. It originates in confinement-induced orientational
order of the elongated guest molecules in the nanochannels. This leads to a
non-centrosymmetric dipolar order and hence to a non-linear light-matter
interaction on the sub-wavelength, single-pore scale. Our study demonstrates
that the advent of large-scale, self-organised nanoporosity in monolithic
solids along with confinement-controllable orientational order of chromophores
at the single-pore scale provides a reliable and accessible tool to design
materials with a nonlinear meta-optics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:48:04 GMT""}]","2021-02-11"
"2102.05323","Takashi Imoto","Takashi Imoto, Yuya Seki, Yuichiro Matsuzaki, Shiro Kawabata","Improving the accuracy of the energy estimation by combining quantum
  annealing with classical computation","8 pages, 5 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum chemistry calculations are important applications of quantum
annealing. For practical applications in quantum chemistry, it is essential to
estimate a ground state energy of the Hamiltonian with chemical accuracy.
However, there are no known methods to guarantee the accuracy of the estimation
of the energy calculated by quantum annealing. Here, we propose a way to
improve the accuracy of the estimate of the ground state energy by combining
quantum annealing with classical computation. In our scheme, before running the
QA, we need a pre-estimation of the energies of the ground state and first
excited state with some error bars (corresponding to possible estimation error)
by performing classical computation with some approximations. We show that, if
an expectation value and variance of the energy of the state after the QA are
smaller than certain threshold values (that we can calculate from the
pre-estimation), the QA provides us with a better estimate of the ground state
energy than that of the pre-estimation. Since the expectation value and
variance of the energy can be experimentally measurable by the QA, our results
pave the way for accurate estimation of the ground state energy with the QA.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:52:39 GMT""}]","2021-02-11"
"2102.05324","Thibaut Verron","Xavier Caruso (IMB, CNRS), Tristan Vaccon (XLIM), Thibaut Verron (JKU)","On FGLM Algorithms with Tate Algebras",,,,,"cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tate introduced in [Ta71] the notion of Tate algebras to serve, in the
context of analytic geometry over the-adics, as a counterpart of polynomial
algebras in classical algebraic geometry. In [CVV19, CVV20] the formalism of
Gr{\""o}bner bases over Tate algebras has been introduced and advanced
signature-based algorithms have been proposed. In the present article, we
extend the FGLM algorithm of [FGLM93] to Tate algebras. Beyond allowing for
fast change of ordering, this strategy has two other important benefits. First,
it provides an efficient algorithm for changing the radii of convergence which,
in particular, makes effective the bridge between the polynomial setting and
the Tate setting and may help in speeding up the computation of Gr{\""o}bner
basis over Tate algebras. Second, it gives the foundations for designing a fast
algorithm for interreduction, which could serve as basic primitive in our
previous algorithms and accelerate them significantly.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:53:55 GMT""}]","2021-02-11"
"2102.05325","Dominique Chatain","Maya Kini, Subin Lee, Alan Savan (RUB), Benjamin Breitbach, Younes
  Addab (CINaM), Wenjun Lu, Matteo Ghidelli (LSPM), Alfred Ludwig (RUB),
  Nathalie Bozzolo (CEMEF), Christina Scheu, Dominique Chatain (CINaM), Gerhard
  Dehm","Nanocrystalline equiatomic CoCrFeNi alloy thin films: Are they single
  phase fcc?",,"Surface and Coatings Technology, Elsevier, 2021, pp.126945","10.1016/j.surfcoat.2021.126945",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The bulk quaternary equiatomic CoCrFeNi alloy is studied extensively in
literature. Under experimental conditions, it shows a single-phase fcc
structure and its physical and mechanical properties are similar to those of
the quinary equiatomic CoCrFeMnNi alloy. Many studies in literature have
focused on the mechanical properties of bulk nanocrystalline high entropy
alloys or compositionally complex alloys, and their microstructure evolution
upon annealing. The thin film processing route offers an excellent alternative
to form nanocrystalline alloys. Due to the high nucleation rate and high
density of defects in thin films synthesized by sputtering, the kinetics of
microstructure evolution is often accelerated compared to those taking place in
the bulk. Here, thin films are used to study the phase evolution in
nanocrystalline CoCrFeNi deposited on Si/SiO 2 and c-sapphire substrates by
magnetron cosputtering from elemental sources. The phases and microstructure of
the films are discussed in comparison to the bulk alloy. The main conclusion is
that second phases can form even at room temperature provided there are
sufficient nucleation sites.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:55:33 GMT""}]","2021-02-11"
"2102.05326","Mar\'ia Vallet-Regi","Victor M. Moreno, Alejandro Baeza, Maria Vallet-Regi","Evaluation of the Penetration Process of Fluorescent Collagenase
  Nanocapsules in a 3D Collagen Gel","11 pages, 8 figures","Acta Biomaterialia 121,267-274 (2020)","10.1016/j.actbio.2020.12.022","63384","q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  One of the major limitations of nanomedicine is the scarce penetration of
nanoparticles in tumoral tissues. These constrains have been tried to be solved
by different strategies, such as the employ of polyethyleneglycol (PEG) to
avoid the opsonization or reducing the extracellular matrix (ECM) density. Our
research group has developed some strategies to overcome these limitations such
as the employ of pH-sensitive collagenase nanocapsules for the digestion of the
collagen-rich extracellular matrix present in most of tumoral tissues. However,
a deeper understanding of physicochemical kinetics involved in the nanocapsules
degradation process is needed to understand the nanocapsule framework
degradation process produced during the penetration in the tissue. For this, in
this work it has been employed a double-fluorescent labelling strategy of the
polymeric enzyme nanocapsule as a crucial chemical tool which allowed the
analysis of nanocapsules and free collagenase during the diffusion process
throughout a tumour-like collagen matrix. This extrinsic label strategy
provides far greater advantages for observing biological processes. For the
detection of enzyme, collagenase has been labelled with fluorescein
Isothiocyanate (FITC), whereas the nanocapsule surface was labelled with
rhodamine Isothiocyanate (RITC). Thus, it has been possible to monitor the
hydrolysis of nanocapsules and their diffusion throughout a thick 3D Collagen
gel during the time, obtaining a detailed temporal evaluation of the
pH-sensitive collagenase nanocapsule behaviour. These collagenase nanocapsules
displayed a high enzymatic activity in low concentrations at acidic pH, and
their efficiency to penetrate into tissue models pave the way to a wide range
of possible nanomedical applications, especially in cancer therapy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:57:22 GMT""}]","2021-02-11"
"2102.05327","Jin-Lei Wu","Jin-Xuan Han, Jin-Lei Wu, Yan Wang, Yan Xia, Yong-Yuan Jiang, and Jie
  Song","Large-scale GHZ states through topologically protected zero-energy mode
  in a superconducting qutrit-resonator chain","15 pages; 9 figures",,"10.1103/PhysRevA.103.032402",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We propose a superconducting qutrit-resonator chain model, and analytically
work out forms of its topological edge states. The existence of the zero-energy
mode enables to generate a state transfer between two ends of the chain,
accompanied with state flips of all intermediate qutrits, based on which
$N$-body Greenberger-Horne-Zeilinger (GHZ) states can be generated with great
robustness against disorders of coupling strengths. Three schemes of generating
large-scale GHZ states are designed, each of which possesses the robustness
against loss of qutrits or of resonators, meeting a certain performance
requirement of different experimental devices. With experimentally feasible
qutrit-resonator coupling strengths and available coherence times of qutrits
and resonators, it has a potential to generate large-scale GHZ states among
dozens of qutrits with a high fidelity. Further, we show the experimental
consideration of generating GHZ states based on the circuit QED system, and
discuss the prospect of realizing fast GHZ states.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:00:39 GMT""}]","2021-03-17"
"2102.05328","Fabrizio Bianchi","Fabrizio Bianchi (CNRS, LPP), Samuele Mongodi","On minimal kernels and Levi currents on weakly complete complex
  manifolds",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A complex manifold $X$ is \emph{weakly complete} if it admits a continuous
plurisubharmonic exhaustion function $\phi$. The minimal kernels $\Sigma_X^k, k
\in [0,\infty]$ (the loci where are all $\mathcal{C}^k$ plurisubharmonic
exhaustion functions fail to be strictly plurisubharmonic),introduced by
Slodkowski-Tomassini, and the Levi currents, introduced by Sibony, are both
concepts aimed at measuring how far $X$ is from being Stein. We compare these
notions, prove that all Levi currents are supported by all the $\Sigma_X^k$'s,
and give sufficient conditions for points in $\Sigma_X^k$ to be in the support
of some Levi current. When $X$ is a surface and $\phi$ can be chosen analytic,
building on previous work by the second author, Slodkowski, and Tomassini,we
prove the existence of a Levi current precisely supported on $\Sigma_X^\infty$,
and give a classification of Levi currents on $X$. In particular,unless $X$ is
a modification of a Stein space, every point in $X$ is in the support of some
Levi current.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:00:59 GMT""}]","2021-02-11"
"2102.05329","Pernille Hansen Ms","Pernille EH. Hansen, Rasmus Waagepetersen, Anne Marie Svane, Jon
  Sporring, Hans JT. Stephensen, Stine Hasselholt and Stefan Sommer","Currents and K-functions for Fiber Point Processes","12 pages, 2 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analysis of images of sets of fibers such as myelin sheaths or skeletal
muscles must account for both the spatial distribution of fibers and
differences in fiber shape. This necessitates a combination of point process
and shape analysis methodology. In this paper, we develop a K-function for
shape-valued point processes by embedding shapes as currents, thus equipping
the point process domain with metric structure inherited from a reproducing
kernel Hilbert space. We extend Ripley's K-function which measures deviations
from spatial homogeneity of point processes to fiber data. The paper provides a
theoretical account of the statistical foundation of the K-function and its
extension to fiber data, and we test the developed K-function on simulated as
well as real data sets. This includes a fiber data set consisting of myelin
sheaths, visualizing the spatial and fiber shape behavior of myelin
configurations at different debts.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:02:19 GMT""}]","2021-02-11"
"2102.05330","Mariusz Tarnopolski","Mariusz Tarnopolski, Volodymyr Marchenko","A Comprehensive Power Spectral Density Analysis of Astronomical Time
  Series. II. The Swift/BAT Long Gamma-Ray Bursts","22 pages, 9 figures, 2 tables (one online only ancillary file);
  accepted in ApJ",,"10.3847/1538-4357/abe5b1",,"astro-ph.HE astro-ph.CO physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  We investigated the prompt light curves (LCs) of long gamma-ray bursts (GRBs)
from the Swift/BAT catalog. We aimed to characterize their power spectral
densities (PSDs), search for quasiperiodic oscillations (QPOs), and conduct
novel analyses directly in the time domain. We analyzed the PSDs using
Lomb-Scargle periodograms, and searched for QPOs using wavelet scalograms. We
also attempted to classify the GRBs using the Hurst exponent, $H$, and the
$\mathcal{A}-\mathcal{T}$ plane. The PSDs fall into three categories: power law
(PL; $P(f)\propto 1/f^\beta$) with index $\beta\in(0,2)$, PL with a
non-negligible Poisson noise level (PLC) with $\beta\in(1,3)$, and a smoothly
broken PL (SBPL; with Poisson noise level) yielding high-frequency index
$\beta_2\in(2,6)$. The latter yields break time scales on the order of
1--100\,seconds. The PL and PLC models are broadly consistent with a fully
developed turbulence, $\beta=5/3$. For an overwhelming majority of GRBs (93\%),
$H>0.5$, implying ubiquity of the long-term memory. We find no convincing
substructure in the $\mathcal{A}-\mathcal{T}$ plane. Finally, we report on 34
new QPOs: with one or more constant leading periods, as well as several
chirping signals. The presence of breaks and QPOs suggests the existence of
characteristic time scales that in at least some GRBs might be related to the
dynamical properties of plasma trajectories in the accretion disks powering the
relativistic jets.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:04:38 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 13:13:26 GMT""}]","2021-04-21"
"2102.05331","Martin Schmitt","Martin Schmitt and Hinrich Sch\""utze","Language Models for Lexical Inference in Context","Final version of EACL 2021 long paper",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Lexical inference in context (LIiC) is the task of recognizing textual
entailment between two very similar sentences, i.e., sentences that only differ
in one expression. It can therefore be seen as a variant of the natural
language inference task that is focused on lexical semantics. We formulate and
evaluate the first approaches based on pretrained language models (LMs) for
this task: (i) a few-shot NLI classifier, (ii) a relation induction approach
based on handcrafted patterns expressing the semantics of lexical inference,
and (iii) a variant of (ii) with patterns that were automatically extracted
from a corpus. All our approaches outperform the previous state of the art,
showing the potential of pretrained LMs for LIiC. In an extensive analysis, we
investigate factors of success and failure of our three approaches.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:08:22 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 08:33:24 GMT""}]","2021-04-28"
"2102.05332","Nikos Karachalios I","Dirk Hennig, Nikos I. Karachalios and Jes\'us Cuevas-Maraver","The closeness of the Ablowitz-Ladik lattice to the Discrete Nonlinear
  Schr\""odinger equation","13 pages, 3 figures","Journal of Differential Equations (2022)",,,"nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the Ablowitz-Ladik lattice is integrable, the Discrete Nonlinear
Schr\""odinger equation, which is more significant for physical applications, is
not. We prove closeness of the solutions of both systems in the sense of a
""continuous dependence"" on their initial data in the $l^2$ and $l^{\infty}$
metrics. The most striking relevance of the analytical results is that small
amplitude solutions of the Ablowitz-Ladik system persist in the Discrete
Nonlinear Schr\""odinger one. It is shown that the closeness results are also
valid in higher dimensional lattices as well as for generalised nonlinearities.
For illustration of the applicability of the approach, a brief numerical study
is included, showing that when the 1-soliton solution of the Ablowitz-Ladik
system is initiated in the Discrete Nonlinear Schr\""odinger system with cubic
and saturable nonlinearity, it persists for long-times. Thereby excellent
agreement of the numerical findings with the theoretical predicti ions is
obtained.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:09:36 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 11:49:11 GMT""}]","2022-02-01"
"2102.05333","Anastasios Papazafeiropoulos","Anastasios Papazafeiropoulos, Cunhua Pan, Pandelis Kourtessis, Symeon
  Chatzinotas, John M. Senior","Intelligent Reflecting Surface-assisted MU-MISO Systems with Imperfect
  Hardware: Channel Estimation, Beamforming Design","30 pages, 5 figures, accepted in IEEE TWC",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Most works in IRS-assisted systems have ignored the impact of the inevitable
residual hardware impairments (HWIs) at both the transceiver hardware and the
IRS while any relevant works have addressed only simple scenarios, e.g., with
single-antenna network nodes and/or without taking the randomness of phase
noise at the IRS into account. In this work, we aim at filling up this gap by
considering a general IRS-assisted multi-user (MU) multiple-input single-output
(MISO) system with imperfect CSI and correlated Rayleigh fading. In parallel,
we present a general computationally efficient methodology for IRS reflect
beamforming (RB) optimization. Specifically, we introduce an advantageous
channel estimation (CE) method for such systems accounting for the HWIs.
Moreover, we derive the uplink achievable spectral efficiency (SE) with
maximal-ratio combining (MRC) receiver, displaying three significant advantages
being: 1) its closed-form expression, 2) its dependence only on large-scale
statistics, and 3) its low training overhead. Notably, by exploiting the first
two benefits, we achieve to perform optimization with respect to the reflect
beamforming matrix (RBM) that can take place only at every several coherence
intervals, and thus, reduces significantly the computational cost compared to
other methods which require frequent phase optimization. Among the insightful
observations, we highlight that uncorrelated Rayleigh fading does not allow
optimization of the SE, which makes the application of an IRS ineffective.
Also, in the case that the phase drifts, describing the distortion of the
phases in the RBM, are uniformly distributed, the presence of an IRS provides
no advantage. The analytical results outperform previous works and are verified
by Monte-Carlo (MC) simulations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:13:02 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 13:51:31 GMT""},{""version"":""v3"",""created"":""Sat, 4 Sep 2021 09:49:45 GMT""}]","2021-09-07"
"2102.05334","Yael Mathov","Yael Mathov, Lior Rokach, Yuval Elovici","Enhancing Real-World Adversarial Patches through 3D Modeling of Complex
  Target Scenes",,,,,"cs.CV cs.AI cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Adversarial examples have proven to be a concerning threat to deep learning
models, particularly in the image domain. However, while many studies have
examined adversarial examples in the real world, most of them relied on 2D
photos of the attack scene. As a result, the attacks proposed may have limited
effectiveness when implemented in realistic environments with 3D objects or
varied conditions. There are few studies on adversarial learning that use 3D
objects, and in many cases, other researchers are unable to replicate the
real-world evaluation process. In this study, we present a framework that uses
3D modeling to craft adversarial patches for an existing real-world scene. Our
approach uses a 3D digital approximation of the scene as a simulation of the
real world. With the ability to add and manipulate any element in the digital
scene, our framework enables the attacker to improve the adversarial patch's
impact in real-world settings. We use the framework to create a patch for an
everyday scene and evaluate its performance using a novel evaluation process
that ensures that our results are reproducible in both the digital space and
the real world. Our evaluation results show that the framework can generate
adversarial patches that are robust to different settings in the real world.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:16:09 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 07:50:28 GMT""}]","2021-09-03"
"2102.05335","Nicolas Jacon","N Jacon (LMR)","Two maps on affine type A crystals and Hecke algebras",,,,,"math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the crystal isomorphisms of the Fock space to describe two maps on
partitions and multipartitions which naturally appear in the crystal basis
theory for quantum groups in affine type A and in the representation theory of
Hecke algebras of type G(l, l, n).
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:18:18 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 09:59:25 GMT""}]","2021-02-24"
"2102.05336","Yang Liu","Yang Liu","Understanding Instance-Level Label Noise: Disparate Impacts and
  Treatments","Accepted to ICML 2021 as a long talk paper",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper aims to provide understandings for the effect of an
over-parameterized model, e.g. a deep neural network, memorizing
instance-dependent noisy labels. We first quantify the harms caused by
memorizing noisy instances, and show the disparate impacts of noisy labels for
sample instances with different representation frequencies. We then analyze how
several popular solutions for learning with noisy labels mitigate this harm at
the instance level. Our analysis reveals that existing approaches lead to
disparate treatments when handling noisy instances. While higher-frequency
instances often enjoy a high probability of an improvement by applying these
solutions, lower-frequency instances do not. Our analysis reveals new
understandings for when these approaches work, and provides theoretical
justifications for previously reported empirical observations. This observation
requires us to rethink the distribution of label noise across instances and
calls for different treatments for instances in different regimes.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:19:11 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 08:53:10 GMT""}]","2021-07-14"
"2102.05337","Hongbin Cui","Xiaoxiang Jiao, Hongbin Cui and Jialin Xin","Area-minimizing Cones over Products of Grassmannian Manifolds",,"Calculus of Variations and Partial Differential Equations volume
  61, Article number: 205 (2022)",,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is the continuation of the previous one \cite{Cui2021}, where we
re-proved the area-minimization of cones over Grassmannians of $n$-planes
$G(n,m;\mathbb{F})(\mathbb{F}=\mathbb{R},\mathbb{C},\mathbb{H})$, Cayley plane
$\mathbb{O}P^2$ from the point view of Hermitian orthogonal projectors, and
gave area-minimizing cones associated to oriented real Grassmannians
$\widetilde{G}(n,m;\mathbb{R})$.
  In this paper, we make a further step on showing that the cones, of dimension
no less than $\mathbf{8}$, over minimal products of $G(n,m;\mathbb{F})$ are
area-minimizing. Moreover, those cones are very similar to the classical cones
over products of spheres, and for the critical situation -- the cones of
dimension $\mathbf{7}$ \cite{lawlor1991sufficient}, we gain more
area-minimizing cones by carefully computing the Jacobian
$inf_{v}det(I-tH^{v}_{ij})$. Certain minimizing cones among them had been found
from the perspective of $R$-spaces\cite{Ohno2021area}, or isoparametric
theory\cite{tang2020minimizing}, and others are completely new.
  We also prove that the cones over minimal product of
$\widetilde{G}(n,m;\mathbb{R})$ are area-minimizing.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:19:43 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 05:06:32 GMT""}]","2022-08-30"
"2102.05338","Santiago Garcia","Santiago Garcia","Group Quantization of Quadratic Hamiltonians in Finance",,,,,"q-fin.MF","http://creativecommons.org/licenses/by/4.0/","  The Group Quantization formalism is a scheme for constructing a functional
space that is an irreducible infinite dimensional representation of the Lie
algebra belonging to a dynamical symmetry group. We apply this formalism to the
construction of functional space and operators for quadratic potentials --
gaussian pricing kernels in finance. We describe the Black-Scholes theory, the
Ho-Lee interest rate model and the Euclidean repulsive and attractive
oscillators. The symmetry group used in this work has the structure of a
principal bundle with base (dynamical) group a semi-direct extension of the
Heisenberg-Weyl group by SL(2,R), and structure group (fiber) the positive real
line.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:22:32 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 13:22:34 GMT""}]","2021-02-18"
"2102.05339","Vassilis Metaftsis","V. Metaftsis and A.I. Papistas","The Formanek-Procesi group with base a right-angled Artin group:
  Residual nilpotence and Lie algebra","Improved exposition, clarification of various points, incorporates
  various referee suggestions",,,,"math.RA math.GR","http://creativecommons.org/licenses/by/4.0/","  We investigate the Lie algebra of the Formanek-Procesi group FP(H) with base
group H a right-angled Artin group. We show that the Lie algebra gr(FP(H)) has
a presentation that is dictated by the group presentation. As a result, we are
able to show that FP(H) is residually nilpotent.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:22:42 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 12:34:01 GMT""}]","2022-07-13"
"2102.05340","Minyoung Kim","Minyoung Kim","On PyTorch Implementation of Density Estimators for von Mises-Fisher and
  Its Mixture",,,,,"cs.LG cs.MS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The von Mises-Fisher (vMF) is a well-known density model for directional
random variables. The recent surge of the deep embedding methodologies for
high-dimensional structured data such as images or texts, aimed at extracting
salient directional information, can make the vMF model even more popular. In
this article, we will review the vMF model and its mixture, provide detailed
recipes of how to train the models, focusing on the maximum likelihood
estimators, in Python/PyTorch. In particular, implementation of vMF typically
suffers from the notorious numerical issue of the Bessel function evaluation in
the density normalizer, especially when the dimensionality is high, and we
address the issue using the MPMath library that supports arbitrary precision.
For the mixture learning, we provide both minibatch-based large-scale SGD
learning, as well as the EM algorithm which is a full batch estimator. For each
estimator/methodology, we test our implementation on some synthetic data, while
we also demonstrate the use case in a more realistic scenario of image
clustering. Our code is publicly available in
https://github.com/minyoungkim21/vmf-lib.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:26:56 GMT""}]","2021-02-11"
"2102.05341","Idriss Mazari","Idriss Mazari","Quantitative estimates for parabolic optimal control problems under
  $L^\infty$ and $L^1$ constraints in the ball:Quantifying parabolic
  isoperimetric inequalities","53 pages",,,,"math.OC math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we present two different approaches for obtaining
quantitative inequalities in the context of parabolic optimal control problems.
Our model consists of a linearly controlled heat equation with Dirichlet
boundary condition $(u_f)_t-\Delta u_f=f$, $f$ being the control. We seek to
maximise the functional $\mathcal J_T(f):=\frac12\int_{(0;T)\times \Omega}
u_f^2$ or, for some $\epsilon>0$, $\mathcal J_T^\epsilon
(f):=\frac12\int_{(0;T)\times \Omega} u_f^2+\epsilon \int_\Omega
u_f^2(T,\cdot)$ and to obtain quantitative estimates for these maximisation
problems. We offer two approaches in the case where the domain $\Omega$ is a
ball. In that case, if $f$ satisfies $L^1$ and $L^\infty$ constraints and does
not depend on time, we propose a shape derivative approach that shows that, for
any competitor $f=f(x)$ satisfying the same constraints, we have $\mathcal
J_T(f^*)-\mathcal J_T(f)\gtrsim \Vert f-f^*\Vert_{L^1(\Omega)}^2$, $f^*$ being
the maximiser. Through our proof of this time-independent case, we also show
how to obtain coercivity norms for shape hessians in such parabolic
optimisation problems. We also consider the case where $f=f(t,x)$ satisfies a
global $L^\infty$ constraint and, for every $t\in (0;T)$, an $L^1$ constraint.
In this case, assuming $\epsilon>0$, we prove an estimate of the form $\mathcal
J_T^\epsilon (f^*)-\mathcal J_T^\epsilon (f)\gtrsim\int_0^T a_\epsilon (t)
\Vert f(t,\cdot)-f^*(t,\cdot)\Vert_{L^1(\Omega)}^2$ where $a_\epsilon (t)>0$
for any $t\in (0;T)$. The proof of this result relies on a uniform bathtub
principle.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:29:23 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 09:25:45 GMT""}]","2021-03-02"
"2102.05342","Olivier Ley","Aris Daniilidis (CMM), Mounir Haddou (IRMAR), Olivier Ley (IRMAR)","A convex function satisfying the Lojasiewicz inequality but failing the
  gradient conjecture both at zero and infinity",,,,,"math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an example of a smooth convex function on the plane with a
strict minimum at zero, which is real analytic except at zero, for which Thom's
gradient conjecture fails both at zero and infinity. More precisely, the
gradient orbits of the function spiral around zero and at infinity. Besides,
the function satisfies the Lojasiewicz gradient inequality at zero.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:30:38 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 08:35:39 GMT""}]","2021-09-02"
"2102.05343","Tiago Espinha Gasiba","Tiago Espinha Gasiba, Ulrike Lechner, Maria Pinto-Albuquerque, Daniel
  Mendez","Is Secure Coding Education in the Industry Needed? An Investigation
  Through a Large Scale Survey","Preprint accepted for publication at the 43rd International
  Conference on Software Engineering",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Department of Homeland Security in the United States estimates that 90%
of software vulnerabilities can be traced back to defects in design and
software coding. The financial impact of these vulnerabilities has been shown
to exceed 380 million USD in industrial control systems alone. Since software
developers write software, they also introduce these vulnerabilities into the
source code. However, secure coding guidelines exist to prevent software
developers from writing vulnerable code. This study focuses on the human
factor, the software developer, and secure coding, in particular secure coding
guidelines. We want to understand the software developers' awareness and
compliance to secure coding guidelines and why, if at all, they aren't
compliant or aware. We base our results on a large-scale survey on secure
coding guidelines, with more than 190 industrial software developers. Our
work's main contribution motivates the need to educate industrial software
developers on secure coding guidelines, and it gives a list of fifteen
actionable items to be used by practitioners in the industry. We also make our
raw data openly available for further research.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:33:21 GMT""}]","2021-02-11"
"2102.05344","Anand Sawant","Chetan Balwe, Amit Hogadi, Anand Sawant","Geometric criteria for $\mathbb A^1$-connectedness and applications to
  norm varieties","v4: 17 pages, final version before page proofs, accepted for
  publication in Journal of Algebraic Geometry",,,,"math.AG math.AT math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that $\mathbb A^1$-connectedness of a large class of varieties over a
field $k$ can be characterized as the condition that their generic point can be
connected to a $k$-rational point using (not necessarily naive) $\mathbb
A^1$-homotopies. We also show that symmetric powers of $\mathbb A^1$-connected
varieties (over an arbitrary field), as well as smooth proper models of them
(over an algebraically closed field of characteristic $0$), are $\mathbb
A^1$-connected. As an application of these results, we show that the standard
norm varieties over a field $k$ of characteristic 0 become $\mathbb
A^1$-connected (and consequently, universally $R$-trivial) after base change to
an algebraic closure of $k$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:33:34 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 15:07:29 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 10:02:09 GMT""},{""version"":""v4"",""created"":""Thu, 19 Aug 2021 12:14:15 GMT""}]","2021-08-20"
"2102.05345","Tiago Espinha Gasiba","Tiago Espinha Gasiba and Ulrike Lechner and Maria Pinto-Albuquerque","CyberSecurity Challenges for Software Developer Awareness Training in
  Industrial Environments","Preprint accepted for publication at the 16th International
  Conference on Wirtschaftsinformatik",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Awareness of cybersecurity topics facilitates software developers to produce
secure code. This awareness is especially important in industrial environments
for the products and services in critical infrastructures. In this work, we
address how to raise awareness of software developers on the topic of secure
coding. We propose the ""CyberSecurity Challenges"", a serious game designed to
be used in an industrial environment and address software developers' needs.
Our work distils the experience gained in conducting these CyberSecurity
Challenges in an industrial setting. The main contributions are the design of
the CyberSecurity Challenges events, the analysis of the perceived benefits,
and practical advice for practitioners who wish to design or refine these
games.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:33:41 GMT""}]","2021-02-11"
"2102.05346","Michael K\""olle","Michael K\""olle, Dominik Laupheimer, Stefan Schmohl, Norbert Haala,
  Franz Rottensteiner, Jan Dirk Wegner, Hugo Ledoux","The Hessigheim 3D (H3D) Benchmark on Semantic Segmentation of
  High-Resolution 3D Point Clouds and Textured Meshes from UAV LiDAR and
  Multi-View-Stereo","H3D can be retrieved from
  https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx",,"10.1016/j.ophoto.2021.100001",,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Automated semantic segmentation and object detection are of great importance
in geospatial data analysis. However, supervised machine learning systems such
as convolutional neural networks require large corpora of annotated training
data. Especially in the geospatial domain, such datasets are quite scarce.
Within this paper, we aim to alleviate this issue by introducing a new
annotated 3D dataset that is unique in three ways: i) The dataset consists of
both an Unmanned Aerial Vehicle (UAV) laser scanning point cloud and a 3D
textured mesh. ii) The point cloud features a mean point density of about 800
pts/sqm and the oblique imagery used for 3D mesh texturing realizes a ground
sampling distance of about 2-3 cm. This enables the identification of
fine-grained structures and represents the state of the art in UAV-based
mapping. iii) Both data modalities will be published for a total of three
epochs allowing applications such as change detection. The dataset depicts the
village of Hessigheim (Germany), henceforth referred to as H3D. It is designed
to promote research in the field of 3D data analysis on one hand and to
evaluate and rank existing and emerging approaches for semantic segmentation of
both data modalities on the other hand. Ultimately, we hope that H3D will
become a widely used benchmark dataset in company with the well-established
ISPRS Vaihingen 3D Semantic Labeling Challenge benchmark (V3D). The dataset can
be downloaded from
https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:33:48 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 19:25:51 GMT""}]","2021-07-20"
"2102.05347","Nima Anari","Nima Anari and Thuy-Duong Vuong","From Sampling to Optimization on Discrete Domains with Applications to
  Determinant Maximization",,,,,"cs.LG cs.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show a connection between sampling and optimization on discrete domains.
For a family of distributions $\mu$ defined on size $k$ subsets of a ground set
of elements that is closed under external fields, we show that rapid mixing of
natural local random walks implies the existence of simple approximation
algorithms to find $\max \mu(\cdot)$. More precisely we show that if
(multi-step) down-up random walks have spectral gap at least inverse
polynomially large in $k$, then (multi-step) local search can find $\max
\mu(\cdot)$ within a factor of $k^{O(k)}$. As the main application of our
result, we show a simple nearly-optimal $k^{O(k)}$-factor approximation
algorithm for MAP inference on nonsymmetric DPPs. This is the first nontrivial
multiplicative approximation for finding the largest size $k$ principal minor
of a square (not-necessarily-symmetric) matrix $L$ with $L+L^\intercal\succeq
0$.
  We establish the connection between sampling and optimization by showing that
an exchange inequality, a concept rooted in discrete convex analysis, can be
derived from fast mixing of local random walks. We further connect exchange
inequalities with composable core-sets for optimization, generalizing recent
results on composable core-sets for DPP maximization to arbitrary distributions
that satisfy either the strongly Rayleigh property or that have a log-concave
generating polynomial.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:34:44 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 21:07:33 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 01:01:51 GMT""}]","2021-09-16"
"2102.05348","Benjia Zhou","Benjia Zhou, Yunan Li and Jun Wan","Regional Attention with Architecture-Rebuilt 3D Network for RGB-D
  Gesture Recognition","Accepted by AAAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human gesture recognition has drawn much attention in the area of computer
vision. However, the performance of gesture recognition is always influenced by
some gesture-irrelevant factors like the background and the clothes of
performers. Therefore, focusing on the regions of hand/arm is important to the
gesture recognition. Meanwhile, a more adaptive architecture-searched network
structure can also perform better than the block-fixed ones like Resnet since
it increases the diversity of features in different stages of the network
better. In this paper, we propose a regional attention with
architecture-rebuilt 3D network (RAAR3DNet) for gesture recognition. We replace
the fixed Inception modules with the automatically rebuilt structure through
the network via Neural Architecture Search (NAS), owing to the different shape
and representation ability of features in the early, middle, and late stage of
the network. It enables the network to capture different levels of feature
representations at different layers more adaptively. Meanwhile, we also design
a stackable regional attention module called dynamic-static Attention (DSA),
which derives a Gaussian guidance heatmap and dynamic motion map to highlight
the hand/arm regions and the motion information in the spatial and temporal
domains, respectively. Extensive experiments on two recent large-scale RGB-D
gesture datasets validate the effectiveness of the proposed method and show it
outperforms state-of-the-art methods. The codes of our method are available at:
https://github.com/zhoubenjia/RAAR3DNet.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:36:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 16:01:03 GMT""}]","2021-03-10"
"2102.05349","Ju-Jun Xie","Xi-Zhe Ling, Ming-Zhu Liu, Jun-Xu Lu, Li-Sheng Geng, and Ju-Jun Xie","Can the nature of $a_0(980)$ be tested in the $D_s^{+}\to \pi^{+}\pi^0
  \eta$ decay?","14 pages, 8 figures","Phys. Rev. D 103, 116016 (2021)","10.1103/PhysRevD.103.116016",,"hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by-sa/4.0/","  From the amplitude analysis of the $D^+_s \to \pi^+ \pi^0 \eta$ decay, the
BESIII Collaboration firstly observed the $D^+_s \to a_0(980)^+\pi^0$ and
$D^+_s \to a_0(980)^0\pi^+$ decay modes, which are expected to occur through
the pure $W$-annihilation processes. The measured branching fraction
$\mathcal{B}[D_{s}^{+}\to a_{0}(980)^{+(0)}\pi^{0(+)},a_{0}(980)^{+(0)}\to
\pi^{+(0)}\eta]$ is, however, found to be larger than those of known
$W$-annihilation decays by one order of magnitude. This apparent contradiction
can be reconciled if the two decays are induced by internal $W$-conversion or
external $W$-emission mechanisms instead of $W$-annihilation mechanism. In this
work, we propose that the $D^+_s$ decay proceeds via both the external and
internal $W$-emission instead of $W$-annihilation mechanisms. In such a
scenario, we perform a study of the $D^+_s \to \pi^+\pi^0\eta$ decay by taking
into account the contributions from the tree diagram $D^+_s \to \rho^+ \eta \to
\pi^+ \pi^0 \eta$ and the intermediate $\rho^+ \eta$ and
$K^*\bar{K}/K\bar{K}^*$ triangle diagrams. The intermediate $a_0(980)$ state
can be dynamically generated from the final state interactions of coupled $K
\bar{K}$ and $\pi \eta$ channels, and it is shown that the experimental data
can be described fairly well, which supports the interpretation of $a_0(980)$
as a molecular state.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:37:56 GMT""}]","2021-06-30"
"2102.05350","Daniel Barlet","Daniel Barlet (IUF, IECL)","Why (a,b)-modules, frescos and themes ?",,,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This text is an advocacy for the use of (a,b)-modules (formal Brieskorn
modules) in the study of the singularity of a holomorphic function on a complex
manifold. It gives a short an elementary overview on this simple algebraic
tool.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:45:49 GMT""}]","2021-02-11"
"2102.05351","Michael Felderer","Michael Felderer, Rudolf Ramler","Quality Assurance for AI-based Systems: Overview and Challenges",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The number and importance of AI-based systems in all domains is growing. With
the pervasive use and the dependence on AI-based systems, the quality of these
systems becomes essential for their practical usage. However, quality assurance
for AI-based systems is an emerging area that has not been well explored and
requires collaboration between the SE and AI research communities. This paper
discusses terminology and challenges on quality assurance for AI-based systems
to set a baseline for that purpose. Therefore, we define basic concepts and
characterize AI-based systems along the three dimensions of artifact type,
process, and quality characteristics. Furthermore, we elaborate on the key
challenges of (1) understandability and interpretability of AI models, (2) lack
of specifications and defined requirements, (3) need for validation data and
test input generation, (4) defining expected outcomes as test oracles, (5)
accuracy and correctness measures, (6) non-functional properties of AI-based
systems, (7) self-adaptive and self-learning characteristics, and (8) dynamic
and frequently changing environments.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:48:56 GMT""}]","2021-02-11"
"2102.05352","Maciej Ulas","Szabolcs Tengely, Maciej Ulas","Equal values of certain partition functions via Diophantine equations","21 pages, submitted",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $A\subset \N_{+}$ and by $P_{A}(n)$ denotes the number of partitions of
an integer $n$ into parts from the set $A$. The aim of this paper is to prove
several result concerning the existence of integer solutions of Diophantine
equations of the form $P_{A}(x)=P_{B}(y)$, where $A, B$ are certain finite
sets.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:49:02 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 06:30:09 GMT""}]","2021-09-27"
"2102.05353","Mariangela Bonavita","D. Mesa, S. Marino, M. Bonavita, C. Lazzoni, C. Fontanive, S. Perez,
  V. D'Orazi, S. Desidera, R. Gratton, N. Engler, T. Henning, M. Janson, Q.
  Kral, M. Langlois, S. Messina, J. Milli, N. Pawellek, C. Perrot, E. Rigliaco,
  E. Rickman, V. Squicciarini, A. Vigan, Z. Wahhaj, A. Zurlo, A. Boccaletti, M.
  Bonnefoy, G. Chauvin, V. De Caprio, M. Feldt, L. Gluck, J. Hagelberg, M.
  Keppler, A.-M. Lagrange, R. Launhardt, A.-L. Maire, M. Meyer, O.
  Moeller-Nilsson, A. Pavlov, M. Samland, T. Schmidt, L. Weber","Limits on the presence of planets in systems with debris disks: HD 92945
  and HD 107146","17 pages, 14 Figures, accepted for publication on MNRAS",,"10.1093/mnras/stab438",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations of resolved cold debris disks at tens of au have revealed
that gaps could be a common feature in these Kuiper belt analogues. Such gaps
could be evidence for the presence of planets within the gaps or closer-in near
the edges of the disk. We present SPHERE observations of HD 92945 and HD
107146, two systems with detected gaps. We constrained the mass of possible
companions responsible for the gap to 1-2 M Jup for planets located inside the
gap and to less than 5 M Jup for separations down to 20 au from the host star.
These limits allow us to exclude some of the possible configurations of the
planetary systems proposed to explain the shape of the disks around these two
stars. In order to put tighter limits on the mass at very short separations
from the star, where direct imaging data are less effective, we also combined
our data with astrometric measurements from Hipparcos and Gaia and radial
velocity measurements. We were able to limit the separation and the mass of the
companion potentially responsible for the proper motion anomaly of HD 107146 to
values of 2-7 au and 2-5 M Jup , respectively.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:53:02 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 14:44:04 GMT""},{""version"":""v3"",""created"":""Thu, 18 Feb 2021 09:43:14 GMT""}]","2023-05-03"
"2102.05354","Luca Oberto","Luca Oberto, Luciano Brunetti","RF/MW power standard realization without unitary efficiency assumption
  at dc/LF","5 pages, 3 figures","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 67, NO.
  4, APRIL 2018","10.1109/TIM.2018.2791205",,"physics.ins-det physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Thermoelectric power sensors are widely used in commercial power meters at RF
and microwaves, due to their superior robustness, stability, and accuracy if
compared with other types of power sensors. Furthermore, their electrical
architecture and related performance turned out to be very useful in the
realization of the broadband primary power standards as alternative to
resistive power sensors, i.e. bolometers. Hereby we present a comparison in
term of effective efficiency of a thermoelectric sensor calibrated by applying
two different methods of power substitution when used as thermal load in a
coaxial microcalorimeter at RF and microwaves. The aim is to test a technology
that could enable the realization of a primary RF/MW power standard
independently of the assumption of unitary efficiency at the dc (or LF)
reference power.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:53:40 GMT""}]","2021-02-12"
"2102.05355","Maciej Ulas","Maciej Ulas","Some observations and speculations on partitions into $d$-th powers","8 pages, revised version will appear in Bull. Aust. Math. Society",,"10.1017/S0004972721000034",,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  The aim of this note is to provoke discussion concerning arithmetic
properties of function $p_{d}(n)$ counting partitions of an positive integer
$n$ into $d$-th powers, where $d\geq 2$. Besides results concerning the
asymptotic behavior of $p_{d}(n)$ a little is known. In the first part of the
paper, we prove certain congruences involving functions counting various types
of partitions into $d$-th powers. The second part of the paper has experimental
nature and contains questions and conjectures concerning arithmetic behavior of
the sequence $(p_{d}(n))_{n\in\N}$. They based on our computations of
$p_{d}(n)$ for $n\leq 10^5$ in case of $d=2$, and $n\leq 10^{6}$ for $d=3, 4,
5$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:55:10 GMT""}]","2021-02-11"
"2102.05356","Qin-Tao Song","Zheng-Ya Li, De-Min Li, En Wang, Wen-Cheng Yan and Qin-Tao Song","Assignments of the $Y(2040)$, $\rho(1900)$, and $\rho(2150)$ in the
  quark model","9 pages, 5 figures, typos are corrected","Phys. Rev. D 104, 034013 (2021)","10.1103/PhysRevD.104.034013",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, the BESIII Collaboration reported a resonance $Y(2040)$ with
$M=2034\pm13\pm9$ MeV and $\Gamma=234\pm30\pm25$ MeV in the process of
$e^+e^-\rightarrow\omega\pi^0$. In addition, new measurements with much higher
precision for the $\rho(1900)$ and $\rho(2150)$ states are obtained by the
BESIII and BABAR Collaborations. In this work, we perform a systematic study on
the mass spectrum of the excited $\rho$ resonances using the modified
Godfrey-Isgur model, and the strong decays of $Y(2040)$, $\rho(1900)$, and
$\rho(2150)$ within the $^3P_0$ model.We find that $Y(2040)$, $\rho(1900)$, and
$\rho(2150)$ can be interpreted as the $\rho(2^3D_1)$, $\rho(3^3S_1)$, and
$\rho(4^3S_1)$ states, respectively. Meanwhile, the mass and strong decays of
the $\rho(3^3D_1)$ state are predicted as well, which could be helpful to
search for this state in future.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:55:50 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 07:38:30 GMT""},{""version"":""v3"",""created"":""Thu, 9 Sep 2021 02:57:05 GMT""}]","2021-09-10"
"2102.05357","Ciriaco Andrea D'Angelo","Giovanni Abramo, Ciriaco Andrea D'Angelo","The different responses of universities to introduction of
  performance-based research funding",,,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Governments and organizations design performance-based research funding
systems (PBFRS) for strategic aims, such as to selectively allocate scarce
resources and stimulate research efficiency. In this work we analyze the
relative change in research productivity of Italian universities after the
introduction of such a system, featuring financial and reputational incentives.
Using a bibliometric approach, we compare the relative research performance of
universities before and after introduction of PBFRS, at the overall, discipline
and field levels. The findings show convergence in the universities'
performance, due above all to the remarkable improvement of the lowest
performers. Geographically, the universities of the south (versus central and
northern Italy) achieved the greatest improvement in relative performance. The
methodology, and results, should be of use to university management and
policy-makers.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:58:24 GMT""}]","2021-02-11"
"2102.05358","Ciriaco Andrea D'Angelo","Giovanni Abramo, Ciriaco Andrea D'Angelo, Leonardo Grilli","The effects of citation-based research evaluation schemes on
  self-citation behavior",,,,,"cs.DL econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the changes in the self-citation behavior of Italian
professors following the introduction of a citation-based incentive scheme, for
national accreditation to academic appointments. Previous contributions on
self-citation behavior have either focused on small samples or relied on simple
models, not controlling for all confounding factors. The present work adopts a
complex statistics model implemented on bibliometric individual data for over
15,000 Italian professors. Controlling for a number of covariates (number of
citable papers published by the author; presence of international authors;
number of co-authors; degree of the professor's specialization), the average
increase in self-citation rates following introduction of the ASN is of 9.5%.
The increase is common to all disciplines and academic ranks, albeit with
diverse magnitude. Moreover, the increase is sensitive to the relative
incentive, depending on the status of the scholar with respect to the
scientific accreditation. A further analysis shows that there is much
heterogeneity in the individual patterns of self-citing behavior, albeit with
very few outliers.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:58:45 GMT""}]","2021-02-11"
"2102.05359","Luca Oberto","L. Oberto, M. Bisi, A. Kazemipour, A. Steiger, T. Kleine-Ostmann, T.
  Schrader","Measurement comparison among Time-Domain, FTIR and VNA-based
  spectrometers in the THz frequency range","11 pages, 6 figures, 8 tables","Metrologia, 54 (2017) 77-84","10.1088/1681-7575/aa54c2",,"physics.ins-det physics.app-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we present the outcome of the first international comparison in
the terahertz frequency range among three different kinds of spectrometers. A
Fourier-Transform infrared spectrometer, a Vector Network Analyzer and a
Time-Domain Spectrometer have been employed for measuring the complex
refractive index of three travelling standards made of selected dielectric
materials in order to offer a wide enough range of parameters to be measured.
The three spectrometers have been compared in terms of measurement capability
and uncertainty.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:59:02 GMT""}]","2021-02-12"
"2102.05360","Ciriaco Andrea D'Angelo","Giovanni Abramo, Ciriaco Andrea D'Angelo, Ida Mele","Gendered impact of COVID-19 pandemic on research production: a
  cross-country analysis",,,,,"cs.DL econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The massive shock of the COVID-19 pandemic is already showing its negative
effects on economies around the world, unprecedented in recent history.
COVID-19 infections and containment measures have caused a general slowdown in
research and new knowledge production. Because of the link between R&D spending
and economic growth, it is to be expected then that a slowdown in research
activities will slow in turn the global recovery from the pandemic. Many recent
studies also claim an uneven impact on scientific production across gender. In
this paper, we investigate the phenomenon across countries, analysing preprint
depositions. Differently from other works, that compare the number of preprint
depositions before and after the pandemic outbreak, we analyse the depositions
trends across geographical areas, and contrast after-pandemic depositions with
expected ones. Differently from common belief and initial evidence, in few
countries female scientists increased their scientific output while males
plunged.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:00:58 GMT""}]","2021-02-11"
"2102.05361","Stefan Krumpen","Stefan Krumpen, Reinhard Klein and Michael Weinmann","Towards Tangible Cultural Heritage Experiences -- Enriching VR-Based
  Object Inspection with Haptic Feedback",,,,,"cs.HC cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  VR/AR technology is a key enabler for new ways of immersively experiencing
cultural heritage artifacts based on their virtual counterparts obtained from a
digitization process. In this paper, we focus on enriching VR-based object
inspection by additional haptic feedback, thereby creating tangible cultural
heritage experiences. For this purpose, we present an approach for interactive
and collaborative VR-based object inspection and annotation. Our system
supports high-quality 3D models with accurate reflectance characteristics while
additionally providing haptic feedback regarding the object shape features
based on a 3D printed replica. The digital object model in terms of a printable
representation of the geometry as well as reflectance characteristics are
stored in a compact and streamable representation on a central server, which
streams the data to remotely connected users/clients. The latter can jointly
perform an interactive inspection of the object in VR with additional haptic
feedback through the 3D printed replica. Evaluations regarding system
performance, visual quality of the considered models as well as insights from a
user study indicate an improved interaction, assessment and experience of the
considered objects.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:01:21 GMT""}]","2021-02-11"
"2102.05362","Benjamin Brock","B. L. Brock, Juliang Li, S. Kanhirathingal, B. Thyagarajan, M. P.
  Blencowe, A. J. Rimberg","Fast and Ultrasensitive Electrometer Operating at the Single-Photon
  Level",,,"10.1103/PhysRevApplied.16.L051004",,"cond-mat.mes-hall cond-mat.supr-con quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate fast and ultrasensitive charge detection with a
cavity-embedded Cooper pair transistor (cCPT) via dispersive readout of its
Josephson inductance. We report a minimum charge sensitivity of $14$ $\mu
e/\sqrt{\mathrm{Hz}}$ with a detection bandwidth on the order of $1$ MHz using
$16$ attowatts of power, corresponding to the single-photon level of the
cavity. In addition, our measured sensitivities are within a factor of $5$ of
the quantum limit for this device. The single-photon-level sensitivity of the
cCPT is comparable to that of the rf-SET, which typically operates using
picowatts of power corresponding to hundreds of thousands of photons in its
tank circuit. Our results support the feasibility of using the cCPT to mediate
an optomechanical interaction that reaches the single-photon strong coupling
regime.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:02:38 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 22:47:46 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 00:06:56 GMT""}]","2021-12-14"
"2102.05363","Liwei Wang","Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang","Towards Certifying L-infinity Robustness using Neural Networks with
  L-inf-dist Neurons","Appearing at International Conference on Machine Learning (ICML) 2021",,,,"cs.LG cs.AI cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well-known that standard neural networks, even with a high
classification accuracy, are vulnerable to small $\ell_\infty$-norm bounded
adversarial perturbations. Although many attempts have been made, most previous
works either can only provide empirical verification of the defense to a
particular attack method, or can only develop a certified guarantee of the
model robustness in limited scenarios. In this paper, we seek for a new
approach to develop a theoretically principled neural network that inherently
resists $\ell_\infty$ perturbations. In particular, we design a novel neuron
that uses $\ell_\infty$-distance as its basic operation (which we call
$\ell_\infty$-dist neuron), and show that any neural network constructed with
$\ell_\infty$-dist neurons (called $\ell_{\infty}$-dist net) is naturally a
1-Lipschitz function with respect to $\ell_\infty$-norm. This directly provides
a rigorous guarantee of the certified robustness based on the margin of
prediction outputs. We then prove that such networks have enough expressive
power to approximate any 1-Lipschitz function with robust generalization
guarantee. We further provide a holistic training strategy that can greatly
alleviate optimization difficulties. Experimental results show that using
$\ell_{\infty}$-dist nets as basic building blocks, we consistently achieve
state-of-the-art performance on commonly used datasets: 93.09% certified
accuracy on MNIST ($\epsilon=0.3$), 35.42% on CIFAR-10 ($\epsilon=8/255$) and
16.31% on TinyImageNet ($\epsilon=1/255$).
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:03:58 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 04:57:54 GMT""},{""version"":""v3"",""created"":""Fri, 11 Jun 2021 08:01:16 GMT""},{""version"":""v4"",""created"":""Mon, 14 Jun 2021 10:40:48 GMT""}]","2021-06-15"
"2102.05364","Ciriaco Andrea D'Angelo","Giovanni Abramo, Francesca Apponi, Ciriaco Andrea D'Angelo","Do the propensity and drivers of academics' engagement in research
  collaboration with industry vary over time?",,,,,"econ.GN cs.DL q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study is about public-private research collaboration. In particular, we
want to measure how the propensity of academics to collaborate with their
colleagues from private firms varies over time and whether the typical profile
of such academics change. Furthermore, we investigate the change of the weights
of main drivers underlying the academics' propensity to collaborate with
industry. In order to achieve such goals, we apply an inferential model on a
dataset of professors working in Italian universities in two subsequent
periods, 2010-2013 and 2014-2017. Results can be useful for supporting the
definition of policies aimed at fostering public-private research
collaborations, and should be taken into account when assessing their
effectiveness afterwards.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:05:07 GMT""}]","2021-02-11"
"2102.05365","Francesco Loparco","P. Colangelo, F. De Fazio, F. Loparco","Role of $B_c^+ \to B_{s,d}^{(*)} \, \bar \ell \, \nu_\ell$ in the
  Standard Model and in the search for BSM signals","LaTex, 15 pages, 17 figures. Figures and references added, version to
  appear in PRD","Phys. Rev. D 103, 075019 (2021)","10.1103/PhysRevD.103.075019","BARI-TH/21-726","hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The decays $B_c^+ \to B_{a} \bar \ell \nu_\ell$ and $B_c^+ \to B_{a}^{*}(\to
B_a \gamma) \bar \ell \nu_\ell$, with $a=s,d$ and $\ell=e,\mu$, are studied in
the Standard Model (SM) and in the extension based on the low-energy
Hamiltonian comprising the full set of dimension-$6$ semileptonic $c \to s,d$
operators with left-handed neutrinos. Tests of $\mu/e$ universality are
investigated using such modes. The heavy quark spin symmetry is applied to
relate the relevant hadronic matrix elements and to exploit lattice QCD results
on $B_c$ form factors. Optimized observables are selected, and the pattern of
their correlations is studied to identify the effects of the various operators
in the extended low-energy Hamiltonian.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:06:36 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 13:35:14 GMT""}]","2021-04-28"
"2102.05366","Jan Sch\""utte-Engel","Jan Sch\""utte-Engel, David J. E. Marsh, Alexander J. Millar, Akihiko
  Sekine, Francesca Chadha-Day, Sebastian Hoof, Mazhar Ali, Kin-Chung Fong,
  Edward Hardy, and Libor \v{S}mejkal","Axion Quasiparticles for Axion Dark Matter Detection","78 pages + appendices, v2: reference list extended, added one more
  case to fig 23",,"10.1088/1475-7516/2021/08/066","IPPP/20/78, NORDITA-2021-007","hep-ph cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been suggested that certain antiferromagnetic topological insulators
contain axion quasiparticles (AQs), and that such materials could be used to
detect axion dark matter (DM). The AQ is a longitudinal antiferromagnetic spin
fluctuation coupled to the electromagnetic Chern-Simons term, which, in the
presence of an applied magnetic field, leads to mass mixing between the AQ and
the electric field. The electromagnetic boundary conditions and transmission
and reflection coefficients are computed. A model for including losses into
this system is presented, and the resulting linewidth is computed. It is shown
how transmission spectroscopy can be used to measure the resonant frequencies
and damping coefficients of the material, and demonstrate conclusively the
existence of the AQ. The dispersion relation and boundary conditions permit
resonant conversion of axion DM into THz photons in a material volume that is
independent of the resonant frequency, which is tuneable via an applied
magnetic field. A parameter study for axion DM detection is performed,
computing boost amplitudes and bandwidths using realistic material properties
including loss. The proposal could allow for detection of axion DM in the mass
range between 1 and 10 meV using current and near future technology.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:11:47 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 19:23:46 GMT""}]","2021-09-08"
"2102.05367","Pierre Marchand","Pierre Marchand and Jeffrey Galkowski and Alastair Spence and Euan A.
  Spence","Applying GMRES to the Helmholtz equation with strong trapping: how does
  the number of iterations depend on the frequency?",,,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider GMRES applied to discretisations of the high-frequency Helmholtz
equation with strong trapping; recall that in this situation the problem is
exponentially ill-conditioned through an increasing sequence of frequencies.
Under certain assumptions about the distribution of the eigenvalues, we prove
upper bounds on how the number of GMRES iterations grows with the frequency.
Our main focus is on boundary-integral-equation formulations of the exterior
Dirichlet and Neumann obstacle problems in 2- and 3-d; for these problems, we
investigate numerically the sharpness (in terms of dependence on frequency) of
both our bounds and various quantities entering our bounds. This paper is
therefore the first comprehensive study of the frequency-dependence of the
number of GMRES iterations for Helmholtz boundary-integral equations under
trapping.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:13:15 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 21:58:59 GMT""},{""version"":""v3"",""created"":""Fri, 12 Nov 2021 15:53:15 GMT""}]","2021-11-15"
"2102.05368","Thibault Maho","Thibault Maho, Beno\^it Bonnet, Teddy Furon, Erwan Le Merrer","RoBIC: A benchmark suite for assessing classifiers robustness","4 pages, accepted to ICIP 2021",,"10.1109/ICIP42928.2021.9506053",,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many defenses have emerged with the development of adversarial attacks.
Models must be objectively evaluated accordingly. This paper systematically
tackles this concern by proposing a new parameter-free benchmark we coin RoBIC.
RoBIC fairly evaluates the robustness of image classifiers using a new
half-distortion measure. It gauges the robustness of the network against white
and black box attacks, independently of its accuracy. RoBIC is faster than the
other available benchmarks. We present the significant differences in the
robustness of 16 recent models as assessed by RoBIC.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:13:39 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 15:21:10 GMT""}]","2023-03-23"
"2102.05369","Jeil Jung","David Andres Galeano Gonzalez, Bheema Lingam Chittari, Youngju Park,
  Jin-Hua Sun, Jeil Jung","Topological phases in N-layer ABC-graphene boron-nitride moire
  superlattices","9 pages, 6 figures","Phys. Rev. B 103, 165112 (2021)","10.1103/PhysRevB.103.165112",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Rhombohedral $N = 3$ trilayer graphene on hexagonal boron nitride (TLG/BN)
hosts gate-tunable, valley-contrasting, nearly flat topological bands that can
trigger spontaneous quantum Hall phases under appropriate conditions of the
valley and spin polarization. Recent experiments have shown signatures of C = 2
valley Chern bands at 1/4 hole filling, in contrast to the predicted value of C
= 3. We discuss the low-energy model for rhombohedral N-layer graphene (N = 1,
2, 3) aligned with hexagonal boron nitride (hBN) subject to off-diagonal moire
vector potential terms that can alter the valley Chern numbers. Our analysis
suggests that topological phase transitions of the flat bands can be triggered
by pseudomagnetic vector field potentials associated to moire strain patterns,
and that a nematic order with broken rotational symmetry can lead to valley
Chern numbers that are in agreement with recent Hall conductivity observations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:17:00 GMT""}]","2021-04-21"
"2102.05370","Carola Doerr","Anja Jankovic and Tome Eftimov and Carola Doerr","Towards Feature-Based Performance Regression Using Trajectory Data","To appear in the Proceedings of EvoAPP 2021",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black-box optimization is a very active area of research, with many new
algorithms being developed every year. This variety is needed, on the one hand,
since different algorithms are most suitable for different types of
optimization problems. But the variety also poses a meta-problem: which
algorithm to choose for a given problem at hand? Past research has shown that
per-instance algorithm selection based on exploratory landscape analysis (ELA)
can be an efficient mean to tackle this meta-problem. Existing approaches,
however, require the approximation of problem features based on a significant
number of samples, which are typically selected through uniform sampling or
Latin Hypercube Designs. The evaluation of these points is costly, and the
benefit of an ELA-based algorithm selection over a default algorithm must
therefore be significant in order to pay off. One could hope to by-pass the
evaluations for the feature approximations by using the samples that a default
algorithm would anyway perform, i.e., by using the points of the default
algorithm's trajectory.
  We analyze in this paper how well such an approach can work. Concretely, we
test how accurately trajectory-based ELA approaches can predict the final
solution quality of the CMA-ES after a fixed budget of function evaluations. We
observe that the loss of trajectory-based predictions can be surprisingly small
compared to the classical global sampling approach, if the remaining budget for
which solution quality shall be predicted is not too large. Feature selection,
in contrast, did not show any advantage in our experiments and rather led to
worsened prediction accuracy. The inclusion of state variables of CMA-ES only
has a moderate effect on the prediction accuracy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:19:13 GMT""}]","2021-02-11"
"2102.05371","N\'uria Armengol Urp\'i","N\'uria Armengol Urp\'i, Sebastian Curi, Andreas Krause","Risk-Averse Offline Reinforcement Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Training Reinforcement Learning (RL) agents in high-stakes applications might
be too prohibitive due to the risk associated to exploration. Thus, the agent
can only use data previously collected by safe policies. While previous work
considers optimizing the average performance using offline data, we focus on
optimizing a risk-averse criteria, namely the CVaR. In particular, we present
the Offline Risk-Averse Actor-Critic (O-RAAC), a model-free RL algorithm that
is able to learn risk-averse policies in a fully offline setting. We show that
O-RAAC learns policies with higher CVaR than risk-neutral approaches in
different robot control tasks. Furthermore, considering risk-averse criteria
guarantees distributional robustness of the average performance with respect to
particular distribution shifts. We demonstrate empirically that in the presence
of natural distribution-shifts, O-RAAC learns policies with good average
performance.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:27:49 GMT""}]","2021-02-11"
"2102.05372","Jin Sima","Jin Sima and Jehoshua Bruck","Trace Reconstruction with Bounded Edit Distance",,,,,"cs.IT math.CO math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The trace reconstruction problem studies the number of noisy samples needed
to recover an unknown string $\boldsymbol{x}\in\{0,1\}^n$ with high
probability, where the samples are independently obtained by passing
$\boldsymbol{x}$ through a random deletion channel with deletion probability
$q$. The problem is receiving significant attention recently due to its
applications in DNA sequencing and DNA storage. Yet, there is still an
exponential gap between upper and lower bounds for the trace reconstruction
problem. In this paper we study the trace reconstruction problem when
$\boldsymbol{x}$ is confined to an edit distance ball of radius $k$, which is
essentially equivalent to distinguishing two strings with edit distance at most
$k$. It is shown that $n^{O(k)}$ samples suffice to achieve this task with high
probability.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:28:35 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 13:50:08 GMT""}]","2021-04-15"
"2102.05373","David Aparicio","Catarina Oliveira, Jo\~ao Torres, Maria In\^es Silva, David
  Apar\'icio, Jo\~ao Tiago Ascens\~ao, Pedro Bizarro","GuiltyWalker: Distance to illicit nodes in the Bitcoin network","5 pages, 3 figures",,,,"cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Money laundering is a global phenomenon with wide-reaching social and
economic consequences. Cryptocurrencies are particularly susceptible due to the
lack of control by authorities and their anonymity. Thus, it is important to
develop new techniques to detect and prevent illicit cryptocurrency
transactions. In our work, we propose new features based on the structure of
the graph and past labels to boost the performance of machine learning methods
to detect money laundering. Our method, GuiltyWalker, performs random walks on
the bitcoin transaction graph and computes features based on the distance to
illicit transactions. We combine these new features with features proposed by
Weber et al. and observe an improvement of about 5pp regarding illicit
classification. Namely, we observe that our proposed features are particularly
helpful during a black market shutdown, where the algorithm by Weber et al. was
low performing.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:29:13 GMT""},{""version"":""v2"",""created"":""Wed, 21 Jul 2021 10:38:31 GMT""}]","2021-07-22"
"2102.05374","Pierre Le Bras","Tanya Howden, Pierre Le Bras, Thomas S. Methven, Stefano Padilla, Mike
  J. Chantler","Enhancing Reading Strategies by Exploring A Theme-based Approach to
  Literature Surveys",,,,,"cs.IR cs.CY cs.HC","http://creativecommons.org/licenses/by/4.0/","  Searching large digital repositories can be extremely frustrating, as common
list-based formats encourage users to adopt a convenience-sampling approach
that favours chance discovery and random search, over meaningful exploration.
We have designed a methodology that allows users to visually and thematically
explore corpora, while developing personalised holistic reading strategies. We
describe the results of a three-phase qualitative study, in which experienced
researchers used our interactive visualisation approach to analyse a set of
publications and select relevant themes and papers. Using in-depth
semi-structured interviews and stimulated recall, we found that users: (i)
selected papers that they otherwise would not have read, (ii) developed a more
coherent reading strategy, and (iii) understood the thematic structure and
relationships between papers more effectively. Finally, we make six design
recommendations to enhance current digital repositories that we have shown
encourage users to adopt a more holistic and thematic research approach.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:36:45 GMT""}]","2021-02-11"
"2102.05375","Liu Ziyin","Liu Ziyin, Kangqiao Liu, Takashi Mori, Masahito Ueda","Strength of Minibatch Noise in SGD","ICLR 2022 spotlight",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The noise in stochastic gradient descent (SGD), caused by minibatch sampling,
is poorly understood despite its practical importance in deep learning. This
work presents the first systematic study of the SGD noise and fluctuations
close to a local minimum. We first analyze the SGD noise in linear regression
in detail and then derive a general formula for approximating SGD noise in
different types of minima. For application, our results (1) provide insight
into the stability of training a neural network, (2) suggest that a large
learning rate can help generalization by introducing an implicit
regularization, (3) explain why the linear learning rate-batchsize scaling law
fails at a large learning rate or at a small batchsize and (4) can provide an
understanding of how discrete-time nature of SGD affects the recently
discovered power-law phenomenon of SGD.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:38:55 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 13:43:25 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 09:00:56 GMT""}]","2022-03-09"
"2102.05376","Viet Hung Nguyen","V. Hung Nguyen, D. Paszko, M. Lamparski, B. Van Troeye, V. Meunier,
  and J.-C. Charlier","Electronic localization in small-angle twisted bilayer graphene","8 pages, 5 figures, 1 SI document, revised for publication","2D Materials 2021","10.1088/2053-1583/ac044f",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Close to a magical angle, twisted bilayer graphene (TBLG) systems exhibit
isolated flat electronic bands and, accordingly, strong electron localization.
TBLGs have hence been ideal platforms to explore superconductivity, correlated
insulating states, magnetism, and quantized anomalous Hall states in reduced
dimension. Below a threshold twist angle ($\sim$ $1.1^\circ$), the TBLG
superlattice undergoes lattice reconstruction, leading to a periodic moir\'e
structure which presents a marked atomic corrugation. Using a tight-binding
framework, this research demonstrates that superlattice reconstruction affects
significantly the electronic structure of small-angle TBLGs. The first magic
angle at $\sim$ $1.1^\circ$ is found to be a critical case presenting globally
maximized electron localization, thus separating reconstructed TBLGs into two
classes with clearly distinct electronic properties. While low-energy Dirac
fermions are still preserved at large twist angles $> 1.1 ^\circ$, small-angle
($\lesssim 1.1^\circ$) TBLG systems present common features such as large
spatial variation and strong electron localization observed in unfavorable AA
stacking regions. However, for small twist angles below $1.1 ^\circ$, the
relative contribution of the local AA regions is progressively reduced, thus
precluding the emergence of further magic angles, in very good agreement with
existing experimental evidence.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:42:24 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 09:32:35 GMT""},{""version"":""v3"",""created"":""Sun, 21 Feb 2021 06:47:00 GMT""},{""version"":""v4"",""created"":""Wed, 17 Mar 2021 22:27:26 GMT""},{""version"":""v5"",""created"":""Sat, 8 May 2021 14:13:42 GMT""}]","2021-05-28"
"2102.05377","Dominique Vuillaume","Magatte N. Gueye, Alexandre Vercouter, R\'emy Jouclas, David Gu\'erin,
  Vincent Lemaur, Guillaume Schweicher, St\'ephane Lenfant, Aleandro Antidormi,
  Yves Geerts, Claudio Melis, J\'er\^ome Cornil and Dominique Vuillaume","Thermal conductivity of benzothieno-benzothiophene derivatives at the
  nanoscale","Nanoscale (2021)",,"10.1039/D0NR08619C",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study by scanning thermal microscopy the nanoscale thermal conductance of
films (40 to 400 nm thick) of [1]benzothieno[3,2-b][1]benzothiophene (BTBT) and
2,7-dioctyl[1]benzothieno[3,2-b][1]benzothiophene (C8-BTBT-C8). We demonstrate
that the out-of-plane thermal conductivity is significant along the interlayer
direction, larger for BTBT (0.63 +/- 0.12 W m-1 K-1) compared to C8-BTBT-C8
(0.25 +/- 0.13 W m-1 K-1). These results are supported by molecular dynamics
calculations (Approach to Equilibrium Molecular Dynamics method) performed on
the corresponding molecular crystals. The calculations point to significant
thermal conductivity (3D-like) values along the 3 crystalline directions, with
anisotropy factors between the crystalline directions below 1.8 for BTBT and
below 2.8 for C8-BTBT-C8, in deep contrast with the charge transport properties
featuring a two-dimensional character for these materials. In agreement with
the experiments, the calculations yield larger values in BTBT compared to
C8-BTBT-C8 (0.6-1.3 W m-1 K-1 versus 0.3-0.7 W m-1 K-1, respectively). The weak
thickness dependence of the nanoscale thermal resistance is in agreement with a
simple analytical model.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:47:30 GMT""}]","2021-02-11"
"2102.05378","Fan Feng","Qianying Chen, Fan Feng, Pengyu Lv, and Huiling Duan","Origami spring-inspired shape morphing for flexible robotics",,,"10.1089/soro.2021.0030",,"cs.RO cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Flexible robotics are capable of achieving various functionalities by shape
morphing, benefiting from their compliant bodies and reconfigurable structures.
Here we construct and study a class of origami springs generalized from the
known interleaved origami spring, as promising candidates for shape morphing in
flexible robotics. These springs are found to exhibit nonlinear stretch-twist
coupling and linear/nonlinear mechanical response in the compression/tension
region, analyzed by the demonstrated continuum mechanics models, experiments,
and finite element simulations. To improve the mechanical performance such as
the damage resistance, we establish an origami rigidization method by adding
additional creases to the spring system. Guided by the theoretical framework,
we experimentally realize three types of flexible robotics -- origami spring
ejectors, crawlers, and transformers. These robots show the desired
functionality and outstanding mechanical performance. The proposed concept of
origami-aided design is expected to pave the way to facilitate the diverse
shape morphing of flexible robotics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:04:09 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 13:46:14 GMT""},{""version"":""v3"",""created"":""Thu, 3 Jun 2021 10:38:55 GMT""}]","2022-01-19"
"2102.05379","Emiel Hoogeboom","Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr\'e, Max
  Welling","Argmax Flows and Multinomial Diffusion: Learning Categorical
  Distributions","Accepted at Neural Information Processing Systems (NeurIPS 2021)",,,,"stat.ML cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative flows and diffusion models have been predominantly trained on
ordinal data, for example natural images. This paper introduces two extensions
of flows and diffusion for categorical data such as language or image
segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined
by a composition of a continuous distribution (such as a normalizing flow), and
an argmax function. To optimize this model, we learn a probabilistic inverse
for the argmax that lifts the categorical data to a continuous space.
Multinomial Diffusion gradually adds categorical noise in a diffusion process,
for which the generative denoising process is learned. We demonstrate that our
method outperforms existing dequantization approaches on text modelling and
modelling on image segmentation maps in log-likelihood.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:04:17 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 14:18:43 GMT""},{""version"":""v3"",""created"":""Fri, 22 Oct 2021 13:44:01 GMT""}]","2021-10-25"
"2102.05380","Yibo Yang","Jian Liang, Andrei Alexandru, Yu-Jiang Bi, Terrence Draper, Keh-Fei
  Liu, and Yi-Bo Yang","Detecting flavor content of the vacuum using the Dirac operator spectrum","10 pages, 6 figures",,,,"hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  We compute the overlap Dirac spectrum on three ensembles generated using 2+1
flavor domain wall fermions. The spectral density is determined up to
$\lambda\sim$100 MeV with sub-percentage statistical uncertainty. The three
ensembles have different lattice spacings and two of them have quark masses
tuned to the physical point. We show that we can resolve the flavor content of
the sea quarks and constrain their masses using the Dirac spectral density. We
find that the density is close to a constant below $\lambda\le$ 20 MeV (but
10\% higher than that in the 2-flavor chiral limit) as predicted by chiral
perturbative theory ($\chi$PT), and then increases linearly due to the strange
quark mass. Using the next to leading order $\chi$PT, one can extract the light
and strange quark masses with $\sim$20\% uncertainties. Using the
non-perturbative RI/MOM renormalization, we obtain the chiral condensates at
$\overline{\textrm{MS}}$ 2 GeV as $\Sigma=(260.3(0.7)(1.3)(0.7)(0.8)\
\textrm{MeV})^3$ in the $N_f=2$ (keeping the strange quark mass at the physical
point) chiral limit and $\Sigma_0=(232.6(0.9)(1.2)(0.7)(0.8)\ \textrm{MeV})^3$
in the $N_f=3$ chiral limit, where the four uncertainties come from the
statistical fluctuation, renormalization constant, continuum extrapolation and
lattice spacing determination. Note that {$\Sigma/\Sigma_0=1.40(2)(2)$ is much
larger than 1} due to the strange quark mass effect.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:04:23 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 11:52:44 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jul 2021 15:33:19 GMT""}]","2021-07-09"
"2102.05381","Jerome Wenger","Quanbo Jiang, Jean-Beno\^it Claude, and J\'er\^ome Wenger","Plasmonic nano-optical trap stiffness measurements and design
  optimization",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Plasmonic nano-optical tweezers enable the non-invasive manipulation of
nano-objects under low illumination intensities, and have become a powerful
tool for nanotechnology and biophysics. However, measuring the trap stiffness
of nanotweezers remains a complicated task, which hinders the development of
plasmonic trapping. Here, we describe an experimental method to measure the
trap stiffness based on the temporal correlation of the fluorescence from the
trapped object. The method is applied to characterize the trap stiffness in
different double nanohole apertures and explore the influence of their design
parameters in relationship with numerical simulations. Optimizing the double
nanohole design achieves a trap stiffness 10x larger than the previous
state-of-the-art. The experimental method and the design guidelines discussed
here offer a simple and efficient way to improve the performance of
nano-optical tweezers.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:11:05 GMT""}]","2021-02-11"
"2102.05382","Hai Zhu","Hai Zhu, Francisco Martinez Claramunt, Bruno Brito and Javier
  Alonso-Mora","Learning Interaction-Aware Trajectory Predictions for Decentralized
  Multi-Robot Motion Planning in Dynamic Environments","8 pages, 5 figures, IEEE Robotics and Automation Letters",,,,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a data-driven decentralized trajectory optimization
approach for multi-robot motion planning in dynamic environments. When
navigating in a shared space, each robot needs accurate motion predictions of
neighboring robots to achieve predictive collision avoidance. These motion
predictions can be obtained among robots by sharing their future planned
trajectories with each other via communication. However, such communication may
not be available nor reliable in practice. In this paper, we introduce a novel
trajectory prediction model based on recurrent neural networks (RNN) that can
learn multi-robot motion behaviors from demonstrated trajectories generated
using a centralized sequential planner. The learned model can run efficiently
online for each robot and provide interaction-aware trajectory predictions of
its neighbors based on observations of their history states. We then
incorporate the trajectory prediction model into a decentralized model
predictive control (MPC) framework for multi-robot collision avoidance.
Simulation results show that our decentralized approach can achieve a
comparable level of performance to a centralized planner while being
communication-free and scalable to a large number of robots. We also validate
our approach with a team of quadrotors in real-world experiments.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:11:08 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 21:45:49 GMT""}]","2021-02-25"
"2102.05383","Robert Prevedel","Jakub Czuchnowski and Robert Prevedel","Cross-compensation of Zernike aberrations in Gaussian optics",,,"10.1364/OL.432098",,"physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Zernike polynomials are one of the most widely used mathematical descriptors
of optical aberrations in the fields of imaging and adaptive optics. Their
mathematical orthogonality as well as isomorphisms with experimentally
observable aberrations make them a very powerful tool in solving numerous
problems in beam optics. However, Zernike aberrations show cross-coupling
between individual modes when used in combination with Gaussian beams, an
effect that has not been extensively studied. Here we propose a novel framework
that is capable of explaining the fundamental cross-compensation of Zernike
type aberrations, both in low-aberration and high-aberration regimes. Our
approach is based on analysing the coupling between Zernike modes and different
classes of Laguerre-Gauss modes which allows investigating aberrated beams not
only on a single plane but also during their 3D propagation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:23:02 GMT""}]","2021-08-04"
"2102.05384","Beno\^it Seignovert","Beno\^it Seignovert, Pascal Rannou, Robert A. West, Sandrine Vinatier","Haze seasonal variations of Titan's upper atmosphere during the Cassini
  Mission",,"ApJ 907 36 (2021)","10.3847/1538-4357/abcd3b",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This study presents a 13 years survey of haze UV extinction profiles,
monitoring the temporal evolution of the detached haze layer (DHL) in Titan's
upper atmosphere (350-600 km). As reported by West et al. 2011 (GRL vol.38,
L06204) at the equator, we show that the DHL is present at all latitudes below
55{\deg}N during the northern winter (2004-2009). Then, it globally sunk and
disappeared in 2012. No permanent DHL was observed between 2012 and 2015. It's
only in late-2015, that a new structure emerged from the Northern hemisphere
and propagated to the equator. This new DHL is not as pronounced as in 2004 and
is much more complex than the one observed earlier. In one specific sequence,
in 2005, we were able to investigate the short time scale variability of the
DHL and no major changes was observed. When both side of the limb were visible
(dawn/dusk), we notice that the extinction of the DHL is slightly higher on the
dawn side. Additionally, during a polar flyby in 2009, we observed the
longitudinal variability of the DHL and spotted some local inhomogeneities.
Finally, comparisons with UVIS stellar occultations and General Climate Models
(GCMs) are both consistent with our findings. However, we noticed that the
timing of the DHL main pattern predicted by the GMCs can be off by up to
30{\deg} in solar longitude. All these observations bring new perspectives on
the seasonal cycle of Titan's upper atmosphere, the evolution of the DHL and
its interaction with the dynamics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:24:24 GMT""}]","2021-02-11"
"2102.05385","Shreya Tayade","Shreya Tayade, Peter Rost, Andreas Maeder","Error Convergence Analysis and Stability of a Cloud Control AGV",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a cloud based Automated Guided vehicle (AGV)
control system. A controller in an Edge cloud sends the control inputs to an
AGV to follow a predefined reference track over a wireless channel. The AGV
feedback the position update via uplink channel. The objective of this paper is
to evaluate the stability criterion of an AGV control system in presence of an
uplink channel outages. Moreover, we also analyse the impact of feedback
control parameters on the error convergence. The results show error convergence
at higher rate with optimal selection of feedback parameters. The optimal
feedback parameters that converges the error with critical damping is evaluated
for two scenarios; with limited AGV velocity and without the limitation on AGV
velocity. Furthermore, the paper describe the discretization process of a
continuous control AGV system.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:34:59 GMT""}]","2021-02-11"
"2102.05386","Prajamitra Bhuyan Dr.","Shyamal Ghosh and Prajamitra Bhuyan and Maxim Finkelstein","On a Bivariate Copula for Modeling Negative Dependence: Application to
  New York Air Quality Data",,,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In many practical scenarios, including finance, environmental sciences,
system reliability, etc., it is often of interest to study the various notion
of negative dependence among the observed variables. A new bivariate copula is
proposed for modeling negative dependence between two random variables that
complies with most of the popular notions of negative dependence reported in
the literature. Specifically, the Spearman's rho and the Kendall's tau for the
proposed copula have a simple one-parameter form with negative values in the
full range. Some important ordering properties comparing the strength of
negative dependence with respect to the parameter involved are considered.
Simple examples of the corresponding bivariate distributions with popular
marginals are presented. Application of the proposed copula is illustrated
using a real data set on air quality in the New York City, USA.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:35:38 GMT""},{""version"":""v2"",""created"":""Sat, 5 Feb 2022 12:54:21 GMT""}]","2022-02-08"
"2102.05387","Sebastian Ziegler","Sebastian Ziegler, Thomas Scheel, Maxime Hubert, Jens Harting and
  Ana-Sun\v{c}ana Smith","Theoretical framework for pairwise microswimmer interactions","29 pages, 6 figures",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrodynamic interactions are crucial for determining the cooperative
behavior of microswimmers at low Reynolds numbers. Here we provide a
comprehensive analysis of the scaling and strength of the interactions in the
case of a pair of three-sphere swimmers with intrinsic elasticity. Both
stroke-based and force-based microswimmers are analyzed using an analytic
perturbative approach. Following a detailed analysis of the passive
interactions, as well as active translations and rotations, we find that the
mapping between the stroke-based and force-based swimmers is only possible in a
low driving frequency regime where the characteristic time scale is smaller
than the viscous one. Furthermore, we find that for swimmers separated by up to
hundreds of swimmer lengths, swimming in pairs speeds up the self propulsion,
due to the dominant quadrupolar hydrodynamic interactions. Finally, we find
that the long term behavior of the swimmers, while sensitive to initial
relative positioning, does not depend on the pusher or puller nature of the
swimmer.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:35:52 GMT""}]","2021-02-11"
"2102.05388","Xiangdong Chen","Xiangdong Chen and Xi Lin and Meng Li and Fang He","Network-level rhythmic control of heterogeneous automated traffic with
  buses",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Guaranteeing the quality of transit service is of great importance to promote
the attractiveness of buses and alleviate urban traffic issues such as
congestion and pollution. Emerging technologies of automated driving and V2X
communication have the potential to enable the accurate control of vehicles and
the efficient organization of traffic to enhance both the schedule adherence of
buses and the overall network mobility. This study proposes an innovative
network-level control scheme for heterogeneous automated traffic composed of
buses and private cars under a full connected and automated environment.
Inheriting the idea of network-level rhythmic control proposed by Lin et al.
(2020), an augmented rhythmic control scheme for heterogeneous traffic, i.e.,
RC-H, is established to organize the mixed traffic in a rhythmic manner.
Realized virtual platoons are designed for accommodating vehicles to pass
through the network, including dedicated virtual platoons for buses to provide
exclusive right-of-ways (ROWs) on their trips and regular virtual platoons for
private cars along with an optimal assignment plan to minimize the total travel
cost. A mixed-integer linear program (MILP) is formulated to optimize the RC-H
scheme and a bilevel heuristic solution method is designed to relieve the
computational burden of MILP. Numerical examples and simulation experiments are
conducted to evaluate the performance of the RC-H scheme under different
scenarios. The results show that the bus operation can be guaranteed and the
travel delay can be minimized under various demand levels with transit
priority. Moreover, compared with traffic signal control strategies, the RC-H
scheme has significant advantages in handling massive traffic demand, in terms
of both vehicle delay and network throughput.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:37:09 GMT""}]","2021-02-11"
"2102.05389","Afsaneh Gharouni","Afsaneh Gharouni, Peter Rost, Andreas Maeder, Hans Schotten","Impact of Bit Allocation Strategies on Machine Learning Performance in
  Rate Limited Systems","In 2022 version, only kNN is replaced with NN (which is the correct
  model) in caption of Fig.3",,"10.1109/LWC.2021.3058893",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intelligent entities such as self-driving vehicles, with their data being
processed by machine learning units (MLU), are developing into an intertwined
part of networks. These units handle distorted input but their sensitivity to
noisy observations varies for different input attributes. Since blind transport
of massive data burdens the system, identifying and delivering relevant
information to MLUs leads in improved system performance and efficient resource
utilization. Here, we study the integer bit allocation problem for quantizing
multiple correlated sources providing input of a MLU with a bandwidth
constraint.
  Unlike conventional distance measures between original and quantized input
attributes, a new Kullback-Leibler divergence based distortion measure is
defined to account for accuracy of MLU decisions. The proposed criterion is
applicable to many practical cases with no prior knowledge on data statistics
and independent of selected MLU instance. Here, we examine an inverted pendulum
on a cart with a neural network controller assuming scalar quantization.
Simulation results present a significant performance gain, particularly for
regions with smaller available bandwidth. Furthermore, the pattern of
successful rate allocations demonstrates higher relevancy of some features for
the MLU and the need to quantize them with higher accuracy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:43:13 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 09:20:48 GMT""}]","2022-05-19"
"2102.05390","Michele Pizzochero","Michele Pizzochero and Efthimios Kaxiras","Imprinting Tunable ${\pi}$-Magnetism in Graphene Nanoribbons via Edge
  Extensions",,"J. Phys. Chem. Lett. 12, 1214 (2021)","10.1021/acs.jpclett.0c03677",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Magnetic carbon nanostructures are currently under scrutiny for a wide
spectrum of applications. Here, we theoretically investigate armchair graphene
nanoribbons patterned with asymmetric edge extensions consisting of laterally
fused naphtho groups, as recently fabricated via on-surface synthesis. We show
that an individual edge extension acts as a spin-$\frac{1}{2}$ center and
develops a sizable spin-polarization of the conductance around the band edges.
The Heisenberg exchange coupling between a pair of edge extensions is dictated
by the position of the second naphtho group in the carbon backbone, thus
enabling ferromagnetic, antiferromagnetic, or non-magnetic states. The periodic
arrangement of edge extensions yields full spin-polarization at the band
extrema, and the accompanying ferromagnetic ground state can be driven into
non-magnetic or antiferromagnetic phases through external stimuli. Overall, our
work reveals precise tunability of the ${\pi}$-magnetism in graphene
nanoribbons induced by naphtho groups, thereby establishing these
one-dimensional architectures as suitable platforms for logic spintronics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:43:45 GMT""}]","2021-02-11"
"2102.05391","Wen-Biao Han","Chen Zhang, Wen-Biao Han, Xing-Yu Zhong, Gang Wang","Geometrized effective-one-body formalism for extreme-mass-ratio limits:
  Generic orbits","22 pages, 18figures","Phys. Rev. D 104, 024050 (2021)","10.1103/PhysRevD.104.024050",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact objects inspiraling into supermassive black holes, known as
extreme-mass-ratio inspirals, are an important source for future space-borne
gravitational-wave detectors. When constructing waveform templates, usually the
adiabatic approximation is employed to treat the compact object as a test
particle for a short duration, and the radiation reaction is reflected in the
changes of the constants of motion. However, the mass of the compact object
should have contributions to the background. In the present paper, employing
the effective-one-body formalism, we analytically calculate the trajectories of
a compact object around a massive Kerr black hole with generally
three-dimensional orbits and express the fundamental orbital frequencies in
explicit forms. In addition, by constructing an approximate ""constant"" similar
to the Carter constant, we transfer the dynamical quantities such as energy,
angular momentum, and the ""Carter constant"" to the semilatus rectum,
eccentricity, and orbital inclination with mass-ratio corrections. The linear
mass-ratio terms in the formalism may not be sufficient for accurate waveforms,
but our analytical method for solving the equations of motion could be useful
in various approaches to building waveform models.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:45:43 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 15:36:09 GMT""}]","2021-08-04"
"2102.05392","Daniele Guido","Valeriano Aiello, Daniele Guido, Tommaso Isola","Spectral triples on irreversible $C^*$-dynamical systems","25 pages, to appear in the International Journal of Mathematics","Internat. J. Math. 33 (2022) No. 01, 2250005","10.1142/S0129167X22500057",,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a spectral triple on a $C^*$-algebra $\mathcal A$ together with a
unital injective endomorphism $\alpha$, the problem of defining a suitable
crossed product $C^*$-algebra endowed with a spectral triple is addressed. The
proposed construction is mainly based on the works of Cuntz and of Hawkins,
Skalski, White and Zacharias, and on our previous papers. The embedding of
$\alpha(\mathcal A)$ in $\mathcal A$ can be considered as the dual form of a
covering projection between noncommutative spaces. A main assumption is the
expansiveness of the endomorphism, which takes the form of the local
isometricity of the covering projection and is expressed via the compatibility
of the Lip-norms on $\mathcal A$ and $\alpha(\mathcal A)$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:46:00 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 12:58:11 GMT""}]","2022-04-25"
"2102.05393","Laure Dumaz","Laure Dumaz and Cyril Labb\'e","The delocalized phase of the Anderson Hamiltonian in $1$-d","31 pages, 1 figure",,,,"math.PR cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a random differential operator, that we call the
$\mathtt{CS}_\tau$ operator, whose spectrum is given by the $\mbox{Sch}_\tau$
point process introduced by Kritchevski, Valk\'o and Vir\'ag (2012) and whose
eigenvectors match with the description provided by Rifkind and Vir\'ag (2018).
This operator acts on $\mathbf{R}^2$-valued functions from the interval $[0,1]$
and takes the form: $$ 2 \begin{pmatrix} 0 & -\partial_t \\ \partial_t & 0
\end{pmatrix} + \sqrt{\tau} \begin{pmatrix} d\mathcal{B} + \frac1{\sqrt 2}
d\mathcal{W}_1 & \frac1{\sqrt 2} d\mathcal{W}_2\\ \frac1{\sqrt 2}
d\mathcal{W}_2 & d\mathcal{B} - \frac1{\sqrt 2} d\mathcal{W}_1\end{pmatrix}\,,
$$ where $d\mathcal{B}$, $d\mathcal{W}_1$ and $d\mathcal{W}_2$ are independent
white noises. Then, we investigate the high part of the spectrum of the
Anderson Hamiltonian $\mathcal{H}_L := -\partial_t^2 + dB$ on the segment
$[0,L]$ with white noise potential $dB$, when $L\to\infty$. We show that the
operator $\mathcal{H}_L$, recentred around energy levels $E \sim L/\tau$ and
unitarily transformed, converges in law as $L\to\infty$ to $\mathtt{CS}_\tau$
in an appropriate sense. This allows to answer a conjecture of Rifkind and
Vir\'ag (2018) on the behavior of the eigenvectors of $\mathcal{H}_L$. Our
approach also explains how such an operator arises in the limit of
$\mathcal{H}_L$. Finally we show that at higher energy levels, the Anderson
Hamiltonian matches (asymptotically in $L$) with the unperturbed Laplacian
$-\partial_t^2$. In a companion paper, it is shown that at energy levels much
smaller than $L$, the spectrum is localized with Poisson statistics: the
present paper therefore identifies the delocalized phase of the Anderson
Hamiltonian.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:46:00 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 16:19:48 GMT""}]","2021-02-22"
"2102.05394","Alessandro Ciallella","Alessandro Ciallella, Mario Pulvirenti and Sergio Simonella","Inhomogeneities in Boltzmann-SIR models",,"Math. Mech. Compl. Sys. 9 (2021) 273-292","10.2140/memocs.2021.9.273",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate, by means of numerical simulations, the qualitative properties
of a Boltzmann equation for three species of particles introduced in previous
work, capturing some features of epidemic spread.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:53:33 GMT""}]","2022-02-09"
"2102.05395","Na Yogesh","Yogesh, D. Chakrabarty, and N. Srivastava","Evidence for distinctive changes in the solar wind helium abundance in
  cycle 24",,,"10.1093/mnrasl/slab016",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relative abundance of alpha particles with respect to proton, usually
expressed as $A_{He}$ = ($n_\alpha/n_p$)*100, is known to respond to solar
activity although changes in its behaviour in the last four solar cycles are
not known. In this letter, by systematically analysing inter-calibrated
$A_{He}$ data obtained from the first Lagrangian point of the Sun-Earth system,
we show that $A_{He}$ variations are distinctively different in solar cycle 24
as compared to the last three cycles. The frequency of $A_{He}$ = 2-3% events
is significantly higher in slow/intermediate solar winds in cycle 24 as opposed
to the dominance of the typical $A_{He}$ = 4-5% events in the previous three
cycles. Further, the occurrence of $A_{He}$ $\geq$ 10% events is significantly
reduced in cycle 24. Not only that, the changes in delay of $A_{He}$ with
respect to peak sunspot numbers are less sensitive to changes in solar wind
velocity in cycle 24. The investigation suggests that the coronal magnetic
field configuration started undergoing systematic changes starting from cycle
23 and this altered magnetic field configuration affected the way helium got
processed and depleted in the solar atmosphere.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:59:44 GMT""}]","2021-02-24"
"2102.05396","Wooyeong Song","WooYeong Song, Junghee Ryu, Kyunghyun Baek and Jeongho Bang","Average fidelity and fidelity deviation in noisy quantum teleportation",,"Journal of the Korean Physical Society, 78(6), 496-503 (2021)","10.1007/s40042-021-00097-z",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We analyze the average fidelity (say, F) and the fidelity deviation (say, D)
in noisy-channel quantum teleportation. Here, F represents how well
teleportation is performed on average and D quantifies whether the
teleportation is performed impartially on the given inputs, that is, the
condition of universality. Our analysis results prove that the achievable
maximum average fidelity ensures zero fidelity deviation, that is, perfect
universality. This structural trait of teleportation is distinct from those of
other limited-fidelity probabilistic quantum operations, for instance,
universal-NOT or quantum cloning. This feature is confirmed again based on a
tighter relationship between F and D in the qubit case. We then consider
another realistic noise model where F decreases and D increases due to
imperfect control. To alleviate such deterioration, we propose a
machine-learning-based algorithm. We demonstrate by means of numerical
simulations that the proposed algorithm can stabilize the system. Notably, the
recovery process consists solely of the maximization of F, which reduces the
control time, thus leading to a faster cure cycle.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:00:56 GMT""}]","2021-03-23"
"2102.05397","Preeti Sahu","Preeti Sahu, J. M. Schwarz and M. Lisa Manning","Geometric signatures of tissue surface tension in a three-dimensional
  model of confluent tissue","16 pages, 14 figures",,"10.1088/1367-2630/ac23f1",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  In dense biological tissues, cell types performing different roles remain
segregated by maintaining sharp interfaces. To better understand the mechanisms
for such sharp compartmentalization, we study the effect of an imposed
heterotypic tension at the interface between two distinct cell types in a fully
3D model for confluent tissues. We find that cells rapidly sort and
self-organize to generate a tissue-scale interface between cell types, and
cells adjacent to this interface exhibit signature geometric features including
nematic-like ordering, bimodal facet areas, and registration, or alignment, of
cell centers on either side of the two-tissue interface. The magnitude of these
features scales directly with the magnitude of imposed tension, suggesting that
biologists can estimate the magnitude of tissue surface tension between two
tissue types simply by segmenting a 3D tissue. To uncover the underlying
physical mechanisms driving these geometric features, we develop two minimal,
ordered models using two different underlying lattices that identify an
energetic competition between bulk cell shapes and tissue interface area. When
the interface area dominates, changes to neighbor topology are costly and occur
less frequently, which generates the observed geometric features.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:07:48 GMT""}]","2021-10-27"
"2102.05398","Souhir Ben Amor","Souhir Ben Amor, Michael Althof, Wolfgang Karl H\""ardle","FRM Financial Risk Meter for Emerging Markets","47 pages, 35 figures, submitted in SoFie Conference",,,,"q-fin.PM","http://creativecommons.org/licenses/by/4.0/","  The fast-growing Emerging Market (EM) economies and their improved
transparency and liquidity have attracted international investors. However, the
external price shocks can result in a higher level of volatility as well as
domestic policy instability. Therefore, an efficient risk measure and hedging
strategies are needed to help investors protect their investments against this
risk. In this paper, a daily systemic risk measure, called FRM (Financial Risk
Meter) is proposed. The FRM-EM is applied to capture systemic risk behavior
embedded in the returns of the 25 largest EMs FIs, covering the BRIMST (Brazil,
Russia, India, Mexico, South Africa, and Turkey), and thereby reflects the
financial linkages between these economies. Concerning the Macro factors, in
addition to the Adrian and Brunnermeier (2016) Macro, we include the EM
sovereign yield spread over respective US Treasuries and the above-mentioned
countries currencies. The results indicated that the FRM of EMs FIs reached its
maximum during the US financial crisis following by COVID 19 crisis and the
Macro factors explain the BRIMST FIs with various degrees of sensibility. We
then study the relationship between those factors and the tail event network
behavior to build our policy recommendations to help the investors to choose
the suitable market for in-vestment and tail-event optimized portfolios. For
that purpose, an overlapping region between portfolio optimization strategies
and FRM network centrality is developed. We propose a robust and
well-diversified tail-event and cluster risk-sensitive portfolio allocation
model and compare it to more classical approaches
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:08:27 GMT""}]","2021-02-11"
"2102.05399","Murari Mandal","Prateek Garg, Murari Mandal, Pratik Narang","Improving Aerial Instance Segmentation in the Dark with Self-Supervised
  Low Light Enhancement","Accepted at AAAI Conference on Artificial Intelligence (AAAI),
  Student Abstract, 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low light conditions in aerial images adversely affect the performance of
several vision based applications. There is a need for methods that can
efficiently remove the low light attributes and assist in the performance of
key vision tasks. In this work, we propose a new method that is capable of
enhancing the low light image in a self-supervised fashion, and sequentially
apply detection and segmentation tasks in an end-to-end manner. The proposed
method occupies a very small overhead in terms of memory and computational
power over the original algorithm and delivers superior results. Additionally,
we propose the generation of a new low light aerial dataset using GANs, which
can be used to evaluate vision based networks for similar adverse conditions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:24:40 GMT""}]","2021-02-11"
"2102.05400","Carsten Wiecher","Carsten Wiecher, Joel Greenyer, Carsten Wolff, Harald Anacker, Roman
  Dumitrescu","Iterative and Scenario-based Requirements Specification in a System of
  Systems Context",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  [Context&Motivation]Due to the managerial ,operational and evolutionary
independence of constituent systems (CSs) in a System of Systems (SoS) context,
top-down and linear requirements engineering (RE) approaches are insufficient.
RE techniques for SoS must support iterating, changing, synchronizing, and
communicating requirements across different abstraction and hierarchy levels as
well as scopes of responsibility. [Question/Problem] We address the challenge
of SoS requirements specification, where requirements can describe the SoS
behavior, but also the behavior of CSs that are developed independently.
[Principal Ideas] To support the requirements specification in an SoS
environment, we propose a scenario-based and iterative specification technique.
This allows requirements engineers to continuously model and jointly execute
and test the system behavior for the SoS and the CS in order to detect
contradictions in the requirement specifications at an early stage.
[Contribution] In this paper, we describe an extension for the
scenario-modeling language for Kotlin (SMLK) to continuously and formally model
requirements on SoS and CS level. To support the iterative requirements
specification and modeling we combine SMLK with agile development techniques.
We demonstrate the applicability of our approach with the help of an example
from the field of e-mobility.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:30:20 GMT""}]","2021-02-11"
"2102.05401","Fatemeh Sharifizadeh","Fatemeh Sharifizadeh, Mohammad Ganjtabesh, Abbas Nowzari-Dalini","Enhancing efficiency of object recognition in different categorization
  levels by reinforcement learning in modular spiking neural networks","16 pages, 8 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The human visual system contains a hierarchical sequence of modules that take
part in visual perception at superordinate, basic, and subordinate
categorization levels. During the last decades, various computational models
have been proposed to mimic the hierarchical feed-forward processing of visual
cortex, but many critical characteristics of the visual system, such actual
neural processing and learning mechanisms, are ignored. Pursuing the line of
biological inspiration, we propose a computational model for object recognition
in different categorization levels, in which a spiking neural network equipped
with the reinforcement learning rule is used as a module at each categorization
level. Each module solves the object recognition problem at each categorization
level, solely based on the earliest spike of class-specific neurons at its last
layer, without using any external classifier. According to the required
information at each categorization level, the relevant band-pass filtered
images are utilized. The performance of our proposed model is evaluated by
various appraisal criteria with three benchmark datasets and significant
improvement in recognition accuracy of our proposed model is achieved in all
experiments.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:33:20 GMT""}]","2021-02-11"
"2102.05402","Ziang Ren","Ren Liu, Ziang Ren","Application of Yolo on Mask Detection Task","7 pages, 4 figures, submitted to The 13th International Conference on
  Computer Research and Development (ICCRD 2021)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  2020 has been a year marked by the COVID-19 pandemic. This event has caused
disruptions to many aspects of normal life. An important aspect in reducing the
impact of the pandemic is to control its spread. Studies have shown that one
effective method in reducing the transmission of COVID-19 is to wear masks.
Strict mask-wearing policies have been met with not only public sensation but
also practical difficulty. We cannot hope to manually check if everyone on a
street is wearing a mask properly. Existing technology to help automate mask
checking uses deep learning models on real-time surveillance camera footages.
The current dominant method to perform real-time mask detection uses Mask-RCNN
with ResNet as the backbone. While giving good detection results, this method
is computationally intensive and its efficiency in real-time face mask
detection is not ideal. Our research proposes a new approach to mask detection
by replacing Mask-R-CNN with a more efficient model ""YOLO"" to increase the
processing speed of real-time mask detection and not compromise on accuracy.
Besides, given the small volume as well as extreme imbalance of the mask
detection datasets, we adopt a latest progress made in few-shot visual
classification, simple CNAPs, to improve the classification performance.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:34:47 GMT""}]","2021-02-11"
"2102.05403","Sungwook Hong E","Sungwook E. Hong, Sangnam Park, M. James Jee, Dongsu Bak, Sangjun Cha","Weak-lensing Mass Reconstruction of Galaxy Clusters with Convolutional
  Neural Network","18 pages, 13 figures, ApJ accepted","ApJ 923, 266 (2021)","10.3847/1538-4357/ac3090",,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We introduce a novel method for reconstructing the projected matter
distributions of galaxy clusters with weak-lensing (WL) data based on
convolutional neural network (CNN). Training datasets are generated with
ray-tracing through cosmological simulations. We control the noise level of the
galaxy shear catalog such that it mimics the typical properties of the existing
ground-based WL observations of galaxy clusters. We find that the mass
reconstruction by our multi-layered CNN with the architecture of alternating
convolution and trans-convolution filters significantly outperforms the
traditional reconstruction methods. The CNN method provides better
pixel-to-pixel correlations with the truth, restores more accurate positions of
the mass peaks, and more efficiently suppresses artifacts near the field edges.
In addition, the CNN mass reconstruction lifts the mass-sheet degeneracy when
applied to our projected cluster mass estimation from sufficiently large
fields. This implies that this CNN algorithm can be used to measure cluster
masses in a model-independent way for future wide-field WL surveys.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:35:34 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 05:47:13 GMT""}]","2021-12-30"
"2102.05404","S\'ergio Marcelino","S\'ergio Marcelino","An unexpected Boolean connective","19 pages, Am\'ilcar Sernadas Logic Prize 2021",,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a 2-valued non-deterministic connective $\wedge \hskip-5.5pt
\vee$ defined by the table resulting from the entry-wise union of the tables of
conjunction and disjunction. Being half conjunction and half disjunction we
named it platypus. The value of $\wedge \hskip-5.5pt \vee$ is not completely
determined by the input, contrasting with usual notion of Boolean connective.
We call non-deterministic Boolean connective any connective based on
multi-functions over the Boolean set. In this way, non-determinism allows for
an extended notion of truth-functional connective. Unexpectedly, this very
simple connective and the logic it defines, illustrate various key advantages
in working with generalized notions of semantics (by incorporating
non-determinism), calculi (by allowing multiple-conclusion rules) and even of
logic (moving from Tarskian to Scottian consequence relations). We show that
the associated logic cannot be characterized by any finite set of finite
matrices, whereas with non-determinism two values suffice. Furthermore, this
logic is not finitely axiomatizable using single-conclusion rules, however we
provide a very simple analytical multiple-conclusion axiomatization using only
two rules. Finally, deciding the associated multiple-conclusion logic is
coNP-complete, but deciding its single-conclusion fragment is in P.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:36:02 GMT""}]","2021-02-11"
"2102.05405","Andrea Vandin","Andrea Vandin, Daniele Giachini, Francesco Lamperti, Francesca
  Chiaromonte","Automated and Distributed Statistical Analysis of Economic Agent-Based
  Models",,,,,"econ.GN cs.MA cs.PF q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel approach to the statistical analysis of simulation models
and, especially, agent-based models (ABMs). Our main goal is to provide a fully
automated and model-independent tool-kit to inspect simulations and perform
counterfactual analysis. Our approach: (i) is easy-to-use by the modeller, (ii)
improves reproducibility of results, (iii) optimizes running time given the
modeller's machine, (iv) automatically chooses the number of required
simulations and simulation steps to reach user-specified statistical
confidence, and (v) automatically performs a variety of statistical tests. In
particular, our framework is designed to distinguish the transient dynamics of
the model from its steady-state behaviour (if any), estimate properties of the
model in both ""phases"", and provide indications on the ergodic (or non-ergodic)
nature of the simulated processes -- which, in turns allows one to gauge the
reliability of a steady-state analysis. Estimates are equipped with statistical
guarantees, allowing for robust comparisons across computational experiments.
To demonstrate the effectiveness of our approach, we apply it to two models
from the literature: a large scale macro-financial ABM and a small scale
prediction market model. Compared to prior analyses of these models, we obtain
new insights and we are able to identify and fix some erroneous conclusions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:39:34 GMT""}]","2021-02-11"
"2102.05406","Chen-Yu Wei","Chen-Yu Wei, Haipeng Luo","Non-stationary Reinforcement Learning without Prior Knowledge: An
  Optimal Black-box Approach",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  We propose a black-box reduction that turns a certain reinforcement learning
algorithm with optimal regret in a (near-)stationary environment into another
algorithm with optimal dynamic regret in a non-stationary environment,
importantly without any prior knowledge on the degree of non-stationarity. By
plugging different algorithms into our black-box, we provide a list of examples
showing that our approach not only recovers recent results for (contextual)
multi-armed bandits achieved by very specialized algorithms, but also
significantly improves the state of the art for (generalized) linear bandits,
episodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most
cases our algorithm achieves the optimal dynamic regret
$\widetilde{\mathcal{O}}(\min\{\sqrt{LT}, \Delta^{1/3}T^{2/3}\})$ where $T$ is
the number of rounds and $L$ and $\Delta$ are the number and amount of changes
of the world respectively, while previous works only obtain suboptimal bounds
and/or require the knowledge of $L$ and $\Delta$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:43:31 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 18:57:04 GMT""},{""version"":""v3"",""created"":""Sun, 5 Sep 2021 22:30:51 GMT""}]","2021-09-07"
"2102.05407","V\'ictor Elvira","V\'ictor Elvira and Luca Martino","Advances in Importance Sampling",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Importance sampling (IS) is a Monte Carlo technique for the approximation of
intractable distributions and integrals with respect to them. The origin of IS
dates from the early 1950s. In the last decades, the rise of the Bayesian
paradigm and the increase of the available computational resources have
propelled the interest in this theoretically sound methodology. In this paper,
we first describe the basic IS algorithm and then revisit the recent advances
in this methodology. We pay particular attention to two sophisticated lines.
First, we focus on multiple IS (MIS), the case where more than one proposal is
available. Second, we describe adaptive IS (AIS), the generic methodology for
adapting one or more proposals.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:50:38 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 09:40:29 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 16:00:14 GMT""}]","2022-04-01"
"2102.05408","David Sabate Barbera","David Sabate Barbera, Mark Huckvale, Victoria Fleming, Emily Upton,
  Henry Coley-Fisher, Catherine Doogan, Ian Shaw, William Latham, Alexander P.
  Leff, Jenny Crinion","NUVA: A Naming Utterance Verifier for Aphasia Treatment","Under review",,"10.1016/j.csl.2021.101221",,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Anomia (word-finding difficulties) is the hallmark of aphasia, an acquired
language disorder most commonly caused by stroke. Assessment of speech
performance using picture naming tasks is a key method for both diagnosis and
monitoring of responses to treatment interventions by people with aphasia
(PWA). Currently, this assessment is conducted manually by speech and language
therapists (SLT). Surprisingly, despite advancements in automatic speech
recognition (ASR) and artificial intelligence with technologies like deep
learning, research on developing automated systems for this task has been
scarce. Here we present NUVA, an utterance verification system incorporating a
deep learning element that classifies 'correct' versus' incorrect' naming
attempts from aphasic stroke patients. When tested on eight native
British-English speaking PWA the system's performance accuracy ranged between
83.6% to 93.6%, with a 10-fold cross-validation mean of 89.5%. This performance
was not only significantly better than a baseline created for this study using
one of the leading commercially available ASRs (Google speech-to-text service)
but also comparable in some instances with two independent SLT ratings for the
same dataset.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:00:29 GMT""}]","2021-04-01"
"2102.05409","Minglei Cai","M.-L. Cai, Z.-D. Liu, W.-D. Zhao, Y.-K. Wu, Q.-X. Mei, Y. Jiang, L.
  He, X. Zhang, Z.-C. Zhou, L.-M. Duan","Observation of a quantum phase transition in the quantum Rabi model with
  a single trapped ion","15 pages, 9 figures",,"10.1038/s41467-021-21425-8",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum phase transitions (QPTs) are usually associated with many-body
systems with large degrees of freedom approaching the thermodynamic limit. In
such systems, the many-body ground state shows abrupt changes at zero
temperature when the control parameter of the Hamiltonian is scanned across a
quantum critical point. Recently it has been realized that a QPT can also occur
in a simple system composed of only a two-level atom and a single-mode bosonic
field, described by the quantum Rabi model (QRM). Here we report the first
experimental demonstration of a QPT in the QRM using a single trapped ion. We
measure the average spin-up state population of the ion and the average phonon
number in its spatial oscillation mode as two order parameters and observe the
clear evidences of the phase transition via slow quench of the coupling between
the ion and its spatial motion. An experimental probe of the phase transitions
in a fundamental quantum optics model without imposing the thermodynamic limit
opens up a new window for the controlled study of QPTs and quantum critical
phenomena.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:03:37 GMT""}]","2021-04-14"
"2102.05410","Lise du Buisson","Lise du Buisson, Sara E. Motta, Rob P. Fender","Very low-frequency oscillations from the 11 Hz pulsar in Terzan 5:
  frame-dragging back on the table","9 pages, 4 figures, 2 tables",,"10.1093/mnras/stab422",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a re-analysis of 47 Rossi X-ray Timing Explorer observations of
the 11Hz accreting pulsar IGR J17480-2446 in Terzan 5 during its 2010 outburst.
We studied the fast-time variability properties of the source and searched for
quasi-periodic oscillations (QPOs) in a large frequency range. General
Relativity predicts that frame-dragging occurs in the vicinity of a spinning
compact object and induces the precession of matter orbiting said object. The
relativistic precession model predicts that this frame-dragging can be observed
as QPOs with a characteristic frequency in the light curves of accreting
compact objects. Such QPOs have historically been classified as horizontal
branch oscillations in neutron star systems, and for a neutron star spinning at
11 Hz these oscillations are expected at frequencies below 1 Hz. However,
previous studies of IGR J17480-2446 have classified QPOs at 35-50 Hz as
horizontal branch oscillations, thus casting doubts on the frame-dragging
nature of such QPOs. Here we report the detection of seven very low-frequency
QPOs, previously undetected, with centroid frequencies below 0.3 Hz, and which
can be ascribed to frame-dragging. We also discuss the possible nature of the
QPOs detected at 35-50 Hz in this alternative scenario.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:05:38 GMT""}]","2021-02-11"
"2102.05411","Vladim\'ir Hol\'y","Vladim\'ir Hol\'y and Tom\'a\v{s} Evan","The Role of a Nation's Culture in the Country's Governance: Stochastic
  Frontier Analysis",,"Hol\'y, V. & Evan, T. (2022). The Role of a Nation's Culture in
  the Country's Governance: Stochastic Frontier Analysis. Central European
  Journal of Operations Research, 30(2), 507-520","10.1007/s10100-021-00754-5",,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  What role does culture play in determining institutions in a country? This
paper argues that the establishment of institutions is a process originating
predominantly in a nation's culture and tries to discern the role of a cultural
background in the governance of countries. We use the six Hofstede's Cultural
Dimensions and the six Worldwide Governance Indicators to test the strength of
the relationship on 94 countries between 1996 and 2019. We find that the
strongest cultural characteristics are Power Distance with negative effect on
governance and Long-Term Orientation with positive effect. We also determine
how well countries transform their cultural characteristics into institutions
using stochastic frontier analysis.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:09:22 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 15:37:30 GMT""}]","2022-11-23"
"2102.05412","Yuhei Nakayama","Masahiro Ibe, Shin Kobayashi, Yuhei Nakayama, Satoshi Shirai","On Stability of Fermionic Superconducting Current in Cosmic String","24 pages, 7 figures",,"10.1007/JHEP05(2021)217","IPMU21-0008","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the chiral superconductivity of the cosmic string in the axion
model has gathered attention. The superconductive nature can alter the standard
understanding of the cosmology of the axion model. For example, a string loop
with a sizable superconducting current can become a stable configuration, which
is called a Vorton. The superconductive nature can also affect the cosmological
evolution of the string network. In this paper, we study the stability of the
superconducting current in the string. We find the superconductivity is indeed
stable for a straight string or infinitely small string core size, even if the
carrier particles are unstable in the vacuum. However we also find that the
carrier particle decays in a curved string in typical axion models, if the
carrier particles are unstable in the vacuum. Accordingly, the lifetime of the
Vorton is not far from that of the carrier particle in the vacuum.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:09:27 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 10:27:31 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 02:32:35 GMT""}]","2023-01-11"
"2102.05413","Alois Pichler","Alois Pichler, Michael Weinhardt","Nested Sinkhorn Divergence To Compute The Nested Distance",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  The nested distance builds on the Wasserstein distance to quantify the
difference of stochastic processes, including also the information modelled by
filtrations. The Sinkhorn divergence is a relaxation of the Wasserstein
distance, which can be computed considerably faster. For this reason we employ
the Sinkhorn divergence and take advantage of the related (fixed point)
iteration algorithm. Furthermore, we investigate the transition of the entropy
throughout the stages of the stochastic process and provide an
entropy-regularized nested distance formulation, including a characterization
of its dual. Numerical experiments affirm the computational advantage and
supremacy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:11:00 GMT""}]","2021-02-11"
"2102.05414","Florian Kennel-Maushart","Florian Kennel-Maushart, Roi Poranne, Stelian Coros","Manipulability optimization for multi-arm teleoperation","Accepted for presentation at IEEE ICRA 2021, published in the
  conference proceedings","2021 IEEE International Conference on Robotics and Automation
  (ICRA), 2021, pp. 3956-3962","10.1109/ICRA48506.2021.9561105",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Teleoperation provides a way for human operators to guide robots in
situations where full autonomy is challenging or where direct human
intervention is required. It can also be an important tool to teach robots in
order to achieve autonomous behaviour later on. The increased availability of
collaborative robot arms and Virtual Reality (VR) devices provides ample
opportunity for development of novel teleoperation methods. Since robot arms
are often kinematically different from human arms, mapping human motions to a
robot in real-time is not trivial. Additionally, a human operator might steer
the robot arm toward singularities or its workspace limits, which can lead to
undesirable behaviour. This is further accentuated for the orchestration of
multiple robots. In this paper, we present a VR interface targeted to multi-arm
payload manipulation, which can closely match real-time input motion. Allowing
the user to manipulate the payload rather than mapping their motions to
individual arms we are able to simultaneously guide multiple collaborative
arms. By releasing a single rotational degree of freedom, and by using a local
optimization method, we can improve each arm's manipulability index, which in
turn lets us avoid kinematic singularities and workspace limitations. We apply
our approach to predefined trajectories as well as real-time teleoperation on
different robot arms and compare performance in terms of end effector position
error and relevant joint motion metrics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:14:20 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 09:43:10 GMT""}]","2021-11-15"
"2102.05415","Eva Benckiser","Y. E. Suyolcu, K. F\""ursich, M. Hepting, Z. Zhong, Y. Lu, Y. Wang, G.
  Christiani, G. Logvenov, P. Hansmann, M. Minola, B. Keimer, P. A. van Aken,
  and E. Benckiser","Control of the metal-insulator transition in NdNiO$_3$ thin films
  through the interplay between structural and electronic properties","9 pages, 5 figures","Phys. Rev. Materials 5, 045001 (2021)","10.1103/PhysRevMaterials.5.045001",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heteroepitaxy offers a new type of control mechanism for the crystal
structure, the electronic correlations, and thus the functional properties of
transition-metal oxides. Here, we combine electrical transport measurements,
high-resolution scanning transmission electron microscopy (STEM), and density
functional theory (DFT) to investigate the evolution of the metal-to-insulator
transition (MIT) in NdNiO$_3$ films as a function of film thickness and
NdGaO$_3$ substrate crystallographic orientation. We find that for two
different substrate facets, orthorhombic (101) and (011), modifications of the
NiO$_6$ octahedral network are key for tuning the transition temperature
$T_{\text{MIT}}$ over a wide temperature range. A comparison of films of
identical thickness reveals that growth on [101]-oriented substrates generally
results in a higher $T_{\text{MIT}}$, which can be attributed to an enhanced
bond-disproportionation as revealed by the DFT+$U$ calculations, and a tendency
of [011]-oriented films to formation of structural defects and stabilization of
non-equilibrium phases. Our results provide insights into the
structure-property relationship of a correlated electron system and its
evolution at microscopic length scales and give new perspectives for the
epitaxial control of macroscopic phases in metal-oxide heterostructures.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:15:36 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 10:05:53 GMT""}]","2021-04-07"
"2102.05416","Norihiro Oyama","Norihiro Oyama, Takeshi Kawasaki, and Kuniyasu Saitoh","Dynamic susceptibilities in dense soft athermal spheres under a
  finite-rate shear","10 pages, 9 figures",,"10.3389/fphy.2021.667103",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The mechanical responses of dense packings of soft athermal spheres under a
finite-rate shear are studied by means of molecular dynamics simulations. We
investigate the volume fraction and shear rate dependence of the fluctuations
in the shear stress and the interparticle contact number. In particular, we
quantify them by defining the susceptibility as the ratio of the global to
local fluctuations. The obtained susceptibilities form ridges on the volume
fraction-shear rate plane, which are reminiscent of the Widom lines around the
critical point in an equilibrium phase transition.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:20:41 GMT""}]","2022-03-23"
"2102.05417","Nihal \""Ozg\""ur","Nihal \""Ozg\""ur and Nihal Ta\c{s}","Geometric Properties of Fixed Points and Simulation Functions","21 pages",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometric properties of the fixed point set $Fix(f)$ of a self-mapping $f$ on
a metric or a generalized metric space is an attractive issue. The set $Fix(f)$
can contain a geometric figure (a circle, an ellipse, etc.) or it can be a
geometric figure. In this paper, we consider the set of simulation functions
for geometric applications in the fixed point theory both on metric and some
generalized metric spaces ($S$-metric spaces and $b$-metric spaces). The main
motivation of this paper is to investigate the geometric properties of non
unique fixed points of self-mappings via simulation functions.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:23:50 GMT""}]","2021-02-11"
"2102.05418","Murari Mandal","Harsh Sinha, Aditya Mehta, Murari Mandal, Pratik Narang","Learning to Enhance Visual Quality via Hyperspectral Domain Mapping","Accepted at AAAI Conference on Artificial Intelligence (AAAI),
  Student Abstract, 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning based methods have achieved remarkable success in image
restoration and enhancement, but most such methods rely on RGB input images.
These methods fail to take into account the rich spectral distribution of
natural images. We propose a deep architecture, SpecNet, which computes
spectral profile to estimate pixel-wise dynamic range adjustment of a given
image. First, we employ an unpaired cycle-consistent framework to generate
hyperspectral images (HSI) from low-light input images. HSI is further used to
generate a normal light image of the same scene. We incorporate a
self-supervision and a spectral profile regularization network to infer a
plausible HSI from an RGB image. We evaluate the benefits of optimizing the
spectral profile for real and fake images in low-light conditions on the LOL
Dataset.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:27:34 GMT""}]","2021-02-11"
"2102.05419","S\'ergio Marcelino","Carlos Caleiro and S\'ergio Marcelino","On axioms and rexpansions","30 pages, preprint (accepted in OCL volume dedicated to Arnon Avron)",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the general problem of strengthening the logic of a given (partial)
(non-deterministic) matrix with a set of axioms, using the idea of rexpansion.
We obtain two characterization methods: a very general but not very effective
one, and then an effective method which only applies under certain restrictions
on the given semantics and the shape of the axioms. We show that this second
method covers a myriad of examples in the literature. Finally, we illustrate
how to obtain analytic multiple-conclusion calculi for the resulting logics.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:29:45 GMT""}]","2021-02-11"
"2102.05420","Emma Louden","Emma M. C. Louden and Joel D. Hartman","HATS-34b and HATS-46b: Re-characterisation Using TESS and Gaia",,"Monthly Notices of the Royal Astronomical Society, Volume 501,
  Issue 4, pp.5393-5407 2021","10.1093/mnras/staa3995",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a revised characterisation of the previously discovered transiting
planet systems HATS-34 and HATS-46. We make use of the newly available
space-based light curves from the NASA TESS mission and high-precision parallax
and absolute photometry measurements from the ESA Gaia mission to determine the
mass and radius of the planets and host stars with dramatically increased
precision and accuracy compared to published values, with the uncertainties in
some parameters reduced by as much as a factor of seven. Using an isochrone
based fit, for HATS-34 we measure a revised host star mass and radius of
$0.952_{-0.02}^{+0.04}M_S$ and of $0.9381\pm0.0080R_S$, respectively, and a
revised mass and radius for the transiting planet of $0.951\pm0.050 M_J$ and
$1.282 \pm0.064 R_J$ respectively. Similarly, for HATS-46 we measure a revised
mass and radius for the host star of $0.869\pm0.023M_S$, and $0.894\pm0.010
R_S$, respectively, and a revised mass and radius for the planet of $0.158
\pm0.042 M_J$, and $0.951 \pm 0.029 R_J$, respectively. The uncertainties that
we determine on the stellar and planetary masses and radii are also
substantially lower than re-determinations that incorporate the Gaia results
without performing a full re-analysis of the light curves and other
observational data. We argue that, in light of Gaia and TESS, a full
re-analysis of previously discovered transiting planets is warranted.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:30:18 GMT""}]","2021-02-11"
"2102.05421","S\'ergio Marcelino","S\'ergio Marcelino and Umberto Rivieccio","Finite axiomatizability of logics of distributive lattices with negation","preprint, 21 pages",,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on order-preserving logics defined from varieties of
distributive lattices with negation, and in particular on the problem of
whether these can be axiomatized by means of finite Hilbert calculi. On the
side of negative results, we provide a syntactic condition on the equational
presentation of a variety that entails failure of finite axiomatizability for
the corresponding logic. An application of this result is that the logic of all
distributive lattices with negation is not finitely axiomatizable; likewise, we
establish that the order-preserving logic of the variety of all Ockham algebras
is also not finitely axiomatizable. On the positive side, we show that an
arbitrary subvariety of semi-De Morgan algebras is axiomatized by a finite
number of equations if and only if the corresponding order-preserving logic is
axiomatized by a finite Hilbert calculus. This equivalence also holds for every
subvariety of a Berman variety of Ockham algebras. We obtain, as a corollary, a
new proof that the implication-free fragment of intuitionistic logic is
finitely axiomatizable, as well as a new Hilbert calculus for it. Our proofs
are constructive in that they allow us to effectively convert an equational
presentation of a variety of algebras into a Hilbert calculus for the
corresponding order-preserving logic, and vice versa. We also consider the
assertional logics associated to the above-mentioned varieties, showing in
particular that the assertional logics of finitely axiomatizable subvarieties
of semi-De Morgan algebras are finitely axiomatizable as well.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:34:39 GMT""}]","2021-02-11"
"2102.05422","Maximiliano Cristia","Maximiliano Cristi\'a and Gianfranco Rossi","Integrating Cardinality Constraints into Constraint Logic Programming
  with Sets","Under consideration in Theory and Practice of Logic Programming
  (TPLP)",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Formal reasoning about finite sets and cardinality is an important tool for
many applications, including software verification, where very often one needs
to reason about the size of a given data structure and not only about what its
elements are. The Constraint Logic Programming tool {log} provides a decision
procedure for deciding the satisfiability of formulas involving very general
forms of finite sets, without cardinality. In this paper we adapt and integrate
a decision procedure for a theory of finite sets with cardinality into {log}.
The proposed solver is proved to be a decision procedure for its formulas.
Besides, the new CLP instance is implemented as part of the {log} tool. In
turn, the implementation uses Howe and King's Prolog SAT solver and Prolog's
CLP(Q) library, as an integer linear programming solver. The empirical
evaluation of this implementation based on +250 real verification conditions
shows that it can be useful in practice.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:38:49 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 14:53:16 GMT""}]","2021-10-06"
"2102.05423","L. A. Razo-Lopez","L.A. Razo-L\'opez, and Azriel Z. Genack, and Victor A. Gopar","Statistics of coherent waves inside media with L\'evy disorder","6 pages, 5 figures, minor changes","L. A. Razo-L\'opez, A. Z. Genack, and V. A. Gopar, Statistics of
  coherent waves inside media with L\'evy disorder, Phys. Rev. Res. 3, 023035
  (2021)","10.1103/PhysRevResearch.3.023035",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Structures with heavy-tailed distributions of disorder occur widely in
nature. The evolution of such systems, as in foraging for food or the
occurrence of earthquakes is generally analyzed in terms of an incoherent
series of events. But the study of wave propagation or lasing in such systems
requires the consideration of coherent scattering. We consider the distribution
of wave energy inside 1D random media in which the spacing between scatterers
follow a L\'evy $\alpha$-stable distribution characterized by a power-law decay
with exponent $\alpha$. We show that the averages of the intensity and
logarithmic intensity are given in terms of the average of the logarithm of
transmission and the depth into the sample raised to the power $\alpha$.
Mapping the depth into the sample to the number of scattering elements yields
intensity statistics that are identical to those found for Anderson
localization in standard random media. This allows for the separation for the
impacts of disorder distribution and wave coherence in random media.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:45:17 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 16:23:27 GMT""}]","2021-04-13"
"2102.05424","Jintai Chen","Jintai Chen, Bohan Yu, Biwen Lei, Ruiwei Feng, Danny Z. Chen, Jian Wu","Doctor Imitator: Hand-Radiography-based Bone Age Assessment by Imitating
  Scoring Methods","Original Title: ""Doctor Imitator: A Graph-based Bone Age Assessment
  Framework Using Hand Radiographs"" @inproceedings{chen2020doctor,
  title={Doctor imitator: A graph-based bone age assessment framework using
  hand radiographs}, author={Chen, Jintai and Yu, Bohan and Lei, Biwen and
  Feng, Ruiwei and Chen, Danny Z and Wu, Jian}, booktitle={MICCAI}, year={2020}
  }","International Conference on Medical Image Computing and
  Computer-Assisted Intervention (MICCAI-2020)","10.1007/978-3-030-59725-2_74",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bone age assessment is challenging in clinical practice due to the
complicated bone age assessment process. Current automatic bone age assessment
methods were designed with rare consideration of the diagnostic logistics and
thus may yield certain uninterpretable hidden states and outputs. Consequently,
doctors can find it hard to cooperate with such models harmoniously because it
is difficult to check the correctness of the model predictions. In this work,
we propose a new graph-based deep learning framework for bone age assessment
with hand radiographs, called Doctor Imitator (DI). The architecture of DI is
designed to learn the diagnostic logistics of doctors using the scoring methods
(e.g., the Tanner-Whitehouse method) for bone age assessment. Specifically, the
convolutions of DI capture the local features of the anatomical regions of
interest (ROIs) on hand radiographs and predict the ROI scores by our proposed
Anatomy-based Group Convolution, summing up for bone age prediction. Besides,
we develop a novel Dual Graph-based Attention module to compute
patient-specific attention for ROI features and context attention for ROI
scores. As far as we know, DI is the first automatic bone age assessment
framework following the scoring methods without fully supervised hand
radiographs. Experiments on hand radiographs with only bone age supervision
verify that DI can achieve excellent performance with sparse parameters and
provide more interpretability.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:45:39 GMT""},{""version"":""v2"",""created"":""Sun, 18 Sep 2022 09:23:21 GMT""},{""version"":""v3"",""created"":""Mon, 24 Apr 2023 14:42:59 GMT""}]","2023-04-25"
"2102.05425","E. A. Stepanov","V. Harkov, M. Vandelli, S. Brener, A. I. Lichtenstein, E. A. Stepanov","Impact of partially bosonized collective fluctuations on electronic
  degrees of freedom",,"Phys. Rev. B 103, 245123 (2021)","10.1103/PhysRevB.103.245123",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we present a comprehensive analysis of collective electronic
fluctuations and their effect on single-particle properties of the Hubbard
model. Our approach is based on a standard dual fermion/boson scheme with the
interaction truncated at the two-particle level. Within this framework we
compare various approximations that differ in the set of diagrams (ladder vs
exact diagrammatic Monte Carlo), and/or in the form of the four-point
interaction vertex (exact vs partially bosonized). This allows to evaluate the
effect of all components of the four-point vertex function on the electronic
self-energy. In particular, we observe that contributions that are not
accounted for by the partially bosonized approximation for the vertex have only
a minor effect on electronic degrees of freedom in a broad range of model
parameters. In addition, we find that in the regime, where the ladder dual
fermion approximation provides an accurate solution of the problem, the leading
contribution to the self-energy is given by the longitudional bosonic modes.
This can be explained by the fact that contributions of transverse
particle-hole and particle-particle modes partially cancel each other. Our
results justify the applicability of the recently introduced dual triply
irreducible local expansion (D-TRILEX) method that represents one of the
simplest consistent diagrammatic extensions of the dynamical mean-field theory.
We find that the self-consistent D-TRILEX approach is reasonably accurate also
in challenging regimes of the Hubbard model, even where the dynamical
mean-field theory does not provide the optimal local reference point (impurity
problem) for the diagrammatic expansion.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:45:55 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 16:54:08 GMT""}]","2021-06-15"
"2102.05426","Yuhang Li","Yuhang Li, Ruihao Gong, Xu Tan, Yang Yang, Peng Hu, Qi Zhang, Fengwei
  Yu, Wei Wang, Shi Gu","BRECQ: Pushing the Limit of Post-Training Quantization by Block
  Reconstruction",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the challenging task of neural network quantization without
end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually
requires a small subset of training data but produces less powerful quantized
models than Quantization-Aware Training (QAT). In this work, we propose a novel
PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to
INT2 for the first time. BRECQ leverages the basic building blocks in neural
networks and reconstructs them one-by-one. In a comprehensive theoretical study
of the second-order error, we show that BRECQ achieves a good balance between
cross-layer dependency and generalization error. To further employ the power of
quantization, the mixed precision technique is incorporated in our framework by
approximating the inter-layer and intra-layer sensitivity. Extensive
experiments on various handcrafted and searched neural architectures are
conducted for both image classification and object detection tasks. And for the
first time we prove that, without bells and whistles, PTQ can attain 4-bit
ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster
production of quantized models. Codes are available at
https://github.com/yhhhli/BRECQ.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:46:16 GMT""},{""version"":""v2"",""created"":""Sun, 25 Jul 2021 09:34:39 GMT""}]","2021-07-27"
"2102.05427","Alice Vanel","Lorenzo Baldassari and Pierre Millien and Alice L. Vanel","Modal approximation for plasmonic resonators in the time domain: the
  scalar case",,,,,"math-ph math.AP math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the electromagnetic field scattered by a metallic nanoparticle with
dispersive material parameters in a resonant regime. We consider the particle
placed in a homogeneous medium in a low-frequency regime. We define modes for
the non-Hermitian problem as perturbations of electrostatic modes, and obtain a
modal approximation of the scattered field in the frequency domain. The poles
of the expansion correspond to the eigenvalues of a singular boundary integral
operator and are shown to lie in a bounded region near the origin of the
lower-half complex plane. Finally, we show that this modal representation gives
a very good approximation of the field in the time domain. We present numerical
simulations in two dimensions to corroborate our results.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:49:03 GMT""}]","2021-02-11"
"2102.05428","Spyridon Mouselinos","Spyridon Mouselinos, Kyriakos Polymenakos, Antonis Nikitakis,
  Konstantinos Kyriakopoulos","MAIN: Multihead-Attention Imputation Networks","8 pages, 7 figures",,"10.1109/IJCNN52387.2021",,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The problem of missing data, usually absent incurated and
competition-standard datasets, is an unfortunate reality for most machine
learning models used in industry applications. Recent work has focused on
understanding the nature and the negative effects of such phenomena, while
devising solutions for optimal imputation of the missing data, using both
discriminative and generative approaches. We propose a novel mechanism based on
multi-head attention which can be applied effortlessly in any model and
achieves better downstream performance without the introduction of the full
dataset in any part of the modeling pipeline. Our method inductively models
patterns of missingness in the input data in order to increase the performance
of the downstream task. Finally, after evaluating our method against baselines
for a number of datasets, we found performance gains that tend to be larger in
scenarios of high missingness.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:50:02 GMT""}]","2022-01-25"
"2102.05429","XInlei He","Xinlei He and Rui Wen and Yixin Wu and Michael Backes and Yun Shen and
  Yang Zhang","Node-Level Membership Inference Attacks Against Graph Neural Networks",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Many real-world data comes in the form of graphs, such as social networks and
protein structure. To fully utilize the information contained in graph data, a
new family of machine learning (ML) models, namely graph neural networks
(GNNs), has been introduced. Previous studies have shown that machine learning
models are vulnerable to privacy attacks. However, most of the current efforts
concentrate on ML models trained on data from the Euclidean space, like images
and texts. On the other hand, privacy risks stemming from GNNs remain largely
unstudied.
  In this paper, we fill the gap by performing the first comprehensive analysis
of node-level membership inference attacks against GNNs. We systematically
define the threat models and propose three node-level membership inference
attacks based on an adversary's background knowledge. Our evaluation on three
GNN structures and four benchmark datasets shows that GNNs are vulnerable to
node-level membership inference even when the adversary has minimal background
knowledge. Besides, we show that graph density and feature similarity have a
major impact on the attack's success. We further investigate two defense
mechanisms and the empirical results indicate that these defenses can reduce
the attack performance but with moderate utility loss.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:51:54 GMT""}]","2021-02-11"
"2102.05431","Thorsten Eisenhofer","Thorsten Eisenhofer, Lea Sch\""onherr, Joel Frank, Lars Speckemeier,
  Dorothea Kolossa, Thorsten Holz","Dompteur: Taming Audio Adversarial Examples","Accepted at USENIX Security Symposium 2021",,,,"cs.CR cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial examples seem to be inevitable. These specifically crafted inputs
allow attackers to arbitrarily manipulate machine learning systems. Even worse,
they often seem harmless to human observers. In our digital society, this poses
a significant threat. For example, Automatic Speech Recognition (ASR) systems,
which serve as hands-free interfaces to many kinds of systems, can be attacked
with inputs incomprehensible for human listeners. The research community has
unsuccessfully tried several approaches to tackle this problem. In this paper
we propose a different perspective: We accept the presence of adversarial
examples against ASR systems, but we require them to be perceivable by human
listeners. By applying the principles of psychoacoustics, we can remove
semantically irrelevant information from the ASR input and train a model that
resembles human perception more closely. We implement our idea in a tool named
DOMPTEUR and demonstrate that our augmented system, in contrast to an
unmodified baseline, successfully focuses on perceptible ranges of the input
signal. This change forces adversarial examples into the audible range, while
using minimal computational overhead and preserving benign performance. To
evaluate our approach, we construct an adaptive attacker that actively tries to
avoid our augmentations and demonstrate that adversarial examples from this
attacker remain clearly perceivable. Finally, we substantiate our claims by
performing a hearing test with crowd-sourced human listeners.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:53:32 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 12:46:05 GMT""}]","2021-06-04"
"2102.05432","Oleg Gritsenko","Oleg Gritsenko","On strongly regular graph with parameters (65; 32; 15; 16)",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a strongly regular graph with the parameters (65; 32; 15; 16).
The idea is to search for an adjacency matrix that consists of circulant
blocks. Equations with such matrices can be reduced to congruences with
polynomials matrices of smaller orders. We can consider these congruences over
different moduli for a more efficient computational approach.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:53:43 GMT""}]","2021-02-11"
"2102.05433","Nicolas Gillis","Le Thi Khanh Hien, Duy Nhat Phan, Nicolas Gillis","A Framework of Inertial Alternating Direction Method of Multipliers for
  Non-Convex Non-Smooth Optimization","35 pages, several parts of the paper clarified, additional
  experiments on a regularized NMF problem","Computational Optimization and Applications 83, pp. 247-285, 2022","10.1007/s10589-022-00394-8",,"math.OC cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an algorithmic framework, dubbed inertial
alternating direction methods of multipliers (iADMM), for solving a class of
nonconvex nonsmooth multiblock composite optimization problems with linear
constraints. Our framework employs the general minimization-majorization (MM)
principle to update each block of variables so as to not only unify the
convergence analysis of previous ADMM that use specific surrogate functions in
the MM step, but also lead to new efficient ADMM schemes. To the best of our
knowledge, in the nonconvex nonsmooth setting, ADMM used in combination with
the MM principle to update each block of variables, and ADMM combined with
\emph{inertial terms for the primal variables} have not been studied in the
literature. Under standard assumptions, we prove the subsequential convergence
and global convergence for the generated sequence of iterates. We illustrate
the effectiveness of iADMM on a class of nonconvex low-rank representation
problems.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:55:28 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jun 2022 04:15:16 GMT""}]","2023-01-26"
"2102.05434","I. S. Burmistrov","E. S. Andriyakhina and I. S. Burmistrov","Interaction of a Neel-type skyrmion and a superconducting vortex","16 pages, 4 figures, 1 table","Phys. Rev. B 103, 174519 (2021)","10.1103/PhysRevB.103.174519",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconductor-ferromagnet heterostructures hosting vortices and skyrmions
are new area of an interplay between superconductivity and magnetism. We study
an interaction of a Neel-type skyrmion and a Pearl vortex in thin
heterostructures due to stray fields. Surprisingly, we find that it can be
energetically favorable for the Pearl vortex to be situated at some nonzero
distance from the center of the Neel-type skyrmion. The presence of a
vortex-antivortex pair is found to result in increase of the skyrmion radius.
Our theory predicts that a spontaneous generation of a vortex-anti-vortex pair
is possible under some conditions in the presence of a Neel-type skyrmion.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:59:19 GMT""},{""version"":""v2"",""created"":""Sat, 24 Apr 2021 18:22:12 GMT""},{""version"":""v3"",""created"":""Tue, 18 May 2021 18:34:48 GMT""}]","2021-06-01"
"2102.05435","Yuan Li","Yuan Li, Frank Ingram and Huaming Zhang","Certificate complexity and symmetry of nested canalizing functions","This paper is a new version of arXiv:2001.09094. We need to resubmit
  it as a replacement. Otherwise, I can not finish the resubmission to the
  journal ""Discrete Mathematics and Theoretical Computer Science""",,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boolean nested canalizing functions (NCFs) have important applications in
molecular regulatory networks, engineering and computer science. In this paper,
we study their certificate complexity. For both Boolean values $b\in\{0,1\}$,
we obtain a formula for $b$-certificate complexity and consequently, we develop
a direct proof of the certificate complexity formula of an NCF. Symmetry is
another interesting property of Boolean functions and we significantly simplify
the proofs of some recent theorems about partial symmetry of NCFs. We also
describe the algebraic normal form of $s$-symmetric NCFs. We obtain the general
formula of the cardinality of the set of $n$-variable $s$-symmetric Boolean
NCFs for $s=1,\dots,n$. In particular, we enumerate the strongly asymmetric
Boolean NCFs.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:59:22 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 16:29:55 GMT""}]","2021-02-15"
"2102.05436","Mohammed AlSharif","Mohammed H. AlSharif, Mohamed Saad, Mohamed Siala, Mohanad Ahmed, and
  Tareq Y. Al-Naffouri","Range Estimation of a Moving Target Using Ultrasound Differential
  Zadoff-Chu Codes",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High accuracy range estimation is an essential tool required in many modern
applications and technologies. However, continuous range estimation of a moving
target is a challenging task, especially under Doppler effects. This paper
presents a novel signal design, which we name differential Zadoff-Chu (DZC).
Under Doppler effects, DZC sequences improve the performance of the maximum
likelihood (ML)-based range estimation compared to its performance when using
regular ZC sequences. Moreover, a reduced-complexity ranging algorithm is
proposed utilizing DZC sequences and is shown to outperform the regular ZC
ML-based range estimation. The proposed system is evaluated in a typical indoor
environment, using low-cost ultrasound hardware. Under a low signal to noise
ratio (-10 dB SNR), more than 90% of the range estimates are in less than 1.6
mm error, with a movement range from $0.2$ m to 2.2 m and a maximum velocity of
0.5 m/s. For the same movement range, the system provides range estimates with
a root mean square error (RMSE) less than 0.76 mm in a high SNR scenario (10
dB), and an MSE less than 0.85 mm in a low SNR scenario (-10 dB). For a larger
movement range from 1.8 m to 4.2 m with a maximum velocity of 1.91 m/s, the
proposed system provides range estimates with RMSE less than 7.70 mm at 10 dB
SNR.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:59:43 GMT""}]","2021-02-11"
"2102.05437","Hojjat Salehinejad","Hojjat Salehinejad and Shahrokh Valaee","Pruning of Convolutional Neural Networks Using Ising Energy Model","This paper is accepted for presentation at IEEE International
  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2021",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pruning is one of the major methods to compress deep neural networks. In this
paper, we propose an Ising energy model within an optimization framework for
pruning convolutional kernels and hidden units. This model is designed to
reduce redundancy between weight kernels and detect inactive kernels/hidden
units. Our experiments using ResNets, AlexNet, and SqueezeNet on CIFAR-10 and
CIFAR-100 datasets show that the proposed method on average can achieve a
pruning rate of more than $50\%$ of the trainable parameters with approximately
$<10\%$ and $<5\%$ drop of Top-1 and Top-5 classification accuracy,
respectively.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:00:39 GMT""}]","2021-02-11"
"2102.05440","Hong-Ming Ding","Yue-wen Yin, Yan-jing Sheng, Min Wang, Song-di Ni, Hong-ming Ding,
  Yu-qiang Ma","Protein corona critically affects the bio-behaviors of SARS-CoV-2","18 pages, 7 figures",,,,"physics.bio-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outbreak of the coronavirus disease 2019 (COVID-19) caused by severe
acute respiratory syndrome coronavirus-2 (SARS-CoV-2) has become a worldwide
public health crisis. When the SARS-CoV-2 enters the biological fluids in the
human body, different types of biomolecules (in particular proteins) may adsorb
on its surface and alter its infection ability. Although great efforts have
recently been devoted to the interaction of the specific antibodies with the
SARS-CoV-2, it still remains largely unknown how the other serum proteins
affect the infection of the SARS-CoV-2. In this work, we systematically
investigate the interaction of serum proteins with the SARS-CoV-2 RBD by the
molecular docking and the all-atom molecular dynamics simulations. It is found
that the non-specific immunoglobulin (Ig) indeed cannot effectively bind to the
SARS-CoV-2 RBD while the human serum albumin (HSA) may have some potential of
blocking its infection (to ACE2). More importantly, we find that the RBD can
cause the significant structural change of the Apolipoprotein E (ApoE), by
which SARS-CoV-2 may hijack the metabolic pathway of the ApoE to facilitate its
cell entry. The present study enhances the understanding of the role of protein
corona in the bio-behaviors of SARS-CoV-2, which may aid the more precise and
personalized treatment for COVID-19 infection in the clinic.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:02:20 GMT""}]","2021-02-11"
"2102.05441","Lei Liu","Lei Liu, Chulong Liang, Junjie Ma, and Li Ping","Capacity Optimality of AMP in Coded Systems","Accepted by IEEE ISIT 2021. arXiv admin note: text overlap with
  arXiv:1901.09559",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper studies a large random matrix system (LRMS) model involving an
arbitrary signal distribution and forward error control (FEC) coding. We
establish an area property based on the approximate message passing (AMP)
algorithm. Under the assumption that the state evolution for AMP is correct for
the coded system, the achievable rate of AMP is analyzed. We prove that AMP
achieves the constrained capacity of the LRMS with an arbitrary signal
distribution provided that a matching condition is satisfied. We provide
related numerical results of binary signaling using irregular low-density
parity-check (LDPC) codes. We show that the optimized codes demonstrate
significantly better performance over un-matched ones under AMP. For quadrature
phase shift keying (QPSK) modulation, bit error rate (BER) performance within 1
dB from the constrained capacity limit is observed.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:02:21 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 03:41:53 GMT""}]","2021-06-07"
"2102.05444","Nicolas Heist","Nicolas Heist and Heiko Paulheim","Information Extraction From Co-Occurring Similar Entities","Preprint of a paper accepted for the research track of the Web
  Conference (WWW'21), April 19-23, 2021, Ljubljana, Slovenia",,"10.1145/3442381.3449836",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Knowledge about entities and their interrelations is a crucial factor of
success for tasks like question answering or text summarization. Publicly
available knowledge graphs like Wikidata or DBpedia are, however, far from
being complete. In this paper, we explore how information extracted from
similar entities that co-occur in structures like tables or lists can help to
increase the coverage of such knowledge graphs. In contrast to existing
approaches, we do not focus on relationships within a listing (e.g., between
two entities in a table row) but on the relationship between a listing's
subject entities and the context of the listing. To that end, we propose a
descriptive rule mining approach that uses distant supervision to derive rules
for these relationships based on a listing's context. Extracted from a suitable
data corpus, the rules can be used to extend a knowledge graph with novel
entities and assertions. In our experiments we demonstrate that the approach is
able to extract up to 3M novel entities and 30M additional assertions from
listings in Wikipedia. We find that the extracted information is of high
quality and thus suitable to extend Wikipedia-based knowledge graphs like
DBpedia, YAGO, and CaLiGraph. For the case of DBpedia, this would result in an
increase of covered entities by roughly 50%.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:03:59 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 09:23:03 GMT""},{""version"":""v3"",""created"":""Mon, 15 Feb 2021 10:17:09 GMT""}]","2021-02-16"
"2102.05445","Ciro Cattuto","Vittoria Colizza, Eva Grill, Rafael Mikolajczyk, Ciro Cattuto, Adam
  Kucharski, Steven Riley, Michelle Kendall, Katrina Lythgoe, Lucie
  Abeler-D\""orner, Chris Wymant, David Bonsall, Luca Ferretti, Christophe
  Fraser","Epidemiological and public health requirements for COVID-19 contact
  tracing apps and their evaluation","9 pages",,,,"cs.CY cs.SI physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Digital contact tracing is a public health intervention. It should be
integrated with local health policy, provide rapid and accurate notifications
to exposed individuals, and encourage high app uptake and adherence to
quarantine. Real-time monitoring and evaluation of effectiveness of app-based
contact tracing is key for improvement and public trust.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:08:34 GMT""}]","2021-02-11"
"2102.05446","Sophie Stevens","Sophie Stevens and Audie Warren","On sum sets of convex functions","16 pages plus appendix",,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  In this paper we prove new bounds for sums of convex or concave functions.
Specifically, we prove that for all $A,B \subseteq \mathbb R$ finite sets, and
for all $f,g$ convex or concave functions, we have
  $$|A + B|^{38}|f(A) + g(B)|^{38} \gtrsim |A|^{49}|B|^{49}.$$
  This result can be used to obtain bounds on a number of two-variable
expanders of interest, as well as to the asymmetric sum-product problem. We
also adjust our technique to also prove the three-variable expansion result
  \[
  |AB+A|\gtrsim |A|^{\frac32 +\frac3{170}}\,.
  \]
  Our methods follow a series of recent developments in the sum-product
literature, presenting a unified picture. Of particular interest is an
adaptation of a regularisation technique of Xue, that enables us to find
positive proportion subsets with certain desirable properties.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:08:55 GMT""}]","2021-02-11"
"2102.05447","Jianzhu Guo","Xiaqing Xu, Qiang Meng, Yunxiao Qin, Jianzhu Guo, Chenxu Zhao, Feng
  Zhou, and Zhen Lei","Searching for Alignment in Face Recognition","Accepted by AAAI 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A standard pipeline of current face recognition frameworks consists of four
individual steps: locating a face with a rough bounding box and several
fiducial landmarks, aligning the face image using a pre-defined template,
extracting representations and comparing. Among them, face detection, landmark
detection and representation learning have long been studied and a lot of works
have been proposed. As an essential step with a significant impact on
recognition performance, the alignment step has attracted little attention. In
this paper, we first explore and highlight the effects of different alignment
templates on face recognition. Then, for the first time, we try to search for
the optimal template automatically. We construct a well-defined searching space
by decomposing the template searching into the crop size and vertical shift,
and propose an efficient method Face Alignment Policy Search (FAPS). Besides, a
well-designed benchmark is proposed to evaluate the searched policy.
Experiments on our proposed benchmark validate the effectiveness of our method
to improve face recognition performance.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:09:16 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 15:03:10 GMT""}]","2021-03-18"
"2102.05449","Tiansheng Huang","Tiansheng Huang, Weiwei Lin, Xiaobin Hong, Xiumin Wang, Qingbo Wu, Rui
  Li, Ching-Hsien Hsu, and Albert Y. Zomaya","Adaptive Processor Frequency Adjustment for Mobile Edge Computing with
  Intermittent Energy Supply",,,,,"eess.SY cs.AI cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With astonishing speed, bandwidth, and scale, Mobile Edge Computing (MEC) has
played an increasingly important role in the next generation of connectivity
and service delivery. Yet, along with the massive deployment of MEC servers,
the ensuing energy issue is now on an increasingly urgent agenda. In the
current context, the large scale deployment of renewable-energy-supplied MEC
servers is perhaps the most promising solution for the incoming energy issue.
Nonetheless, as a result of the intermittent nature of their power sources,
these special design MEC server must be more cautious about their energy usage,
in a bid to maintain their service sustainability as well as service standard.
Targeting optimization on a single-server MEC scenario, we in this paper
propose NAFA, an adaptive processor frequency adjustment solution, to enable an
effective plan of the server's energy usage. By learning from the historical
data revealing request arrival and energy harvest pattern, the deep
reinforcement learning-based solution is capable of making intelligent
schedules on the server's processor frequency, so as to strike a good balance
between service sustainability and service quality. The superior performance of
NAFA is substantiated by real-data-based experiments, wherein NAFA demonstrates
up to 20% increase in average request acceptance ratio and up to 50% reduction
in average request processing time.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:12:10 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 14:15:37 GMT""},{""version"":""v3"",""created"":""Sat, 9 Oct 2021 15:10:17 GMT""}]","2021-10-12"
"2102.05450","Sriprabha Ramanarayanan","Madhu Mithra K K, Sriprabha Ramanarayanan, Keerthi Ram, Mohanasankar
  Sivaprakasam","Reference-based Texture transfer for Single Image Super-resolution of
  Magnetic Resonance images","Accepted at ISBI 2021",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Magnetic Resonance Imaging (MRI) is a valuable clinical diagnostic modality
for spine pathologies with excellent characterization for infection, tumor,
degenerations, fractures and herniations. However in surgery, image-guided
spinal procedures continue to rely on CT and fluoroscopy, as MRI slice
resolutions are typically insufficient. Building upon state-of-the-art single
image super-resolution, we propose a reference-based, unpaired multi-contrast
texture-transfer strategy for deep learning based in-plane and across-plane MRI
super-resolution. We use the scattering transform to relate the texture
features of image patches to unpaired reference image patches, and additionally
a loss term for multi-contrast texture. We apply our scheme in different
super-resolution architectures, observing improvement in PSNR and SSIM for 4x
super-resolution in most of the cases.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:12:48 GMT""}]","2021-02-11"
"2102.05451","Yaron Strauch","Yaron Strauch (University of Southampton), Jo Grundy (University of
  Southampton)","Two Novel Performance Improvements for Evolving CNN Topologies","Accepted to AAAI-21 Workshop W17: Learning Network Architecture
  during Training. 5 pages, 4 figures",,,,"cs.CV cs.AI cs.LG cs.NE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for
the processing of images. However the configuration and training of these
networks is a complex task requiring deep domain knowledge, experience and much
trial and error. Using genetic algorithms, competitive CNN topologies for image
recognition can be produced for any specific purpose, however in previous work
this has come at high computational cost. In this work two novel approaches are
presented to the utilisation of these algorithms, effective in reducing
complexity and training time by nearly 20%. This is accomplished via
regularisation directly on training time, and the use of partial training to
enable early ranking of individual architectures. Both approaches are validated
on the benchmark CIFAR10 data set, and maintain accuracy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:17:51 GMT""}]","2021-02-11"
"2102.05452","Nitai Bar","Nitai Bar, Jonathan A. Sobel, Thomas Penzel, Yosi Shamay, Joachim A.
  Behar","From sleep medicine to medicine during sleep: A clinical perspective",,,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sleep has a profound influence on the physiology of body systems and
biological processes. Molecular studies have shown circadian-regulated shifts
in protein expression patterns across human tissues, further emphasizing the
unique functional, behavioral and pharmacokinetic landscape of sleep. Thus,
many pathological processes are also expected to exhibit sleep-specific
manifestations. Nevertheless, sleep is seldom utilized for the study, detection
and treatment of non-sleep-specific pathologies. Modern advances in biosensor
technologies have enabled remote, non-invasive recording of a growing number of
physiologic parameters and biomarkers. Sleep is an ideal time frame for the
collection of long and clean physiological time series data which can then be
analyzed using data-driven algorithms such as deep learning. In this
perspective paper, we aim to highlight the potential of sleep as an auspicious
time for diagnosis, management and therapy of nonsleep-specific pathologies. We
introduce key clinical studies in selected medical fields, which leveraged
novel technologies and the advantageous period of sleep to diagnose, monitor
and treat pathologies. We then discuss possible opportunities to further
harness this new paradigm and modern technologies to explore human health and
disease during sleep and to advance the development of novel clinical
applications: From sleep medicine to medicine during sleep.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 18:45:42 GMT""}]","2021-02-11"
"2102.05453","Chengfa Wu","Jianhua Zheng, Chengfa Wu","Iterates of Meromorphic Functions on Escaping Fatou Components",,,,,"math.CV math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove that the ratio of the modulus of the iterates of two
points in an escaping Fatou component may be bounded even if the orbit of the
component contains an infinite modulus annulus sequence and this case cannot
happen when the maximal modulus of the meromorphic function is large enough.
Therefore, we extend the related results for entire functions to ones for
meromorphic functions with infinitely many poles. And we investigate the fast
escaping Fatou components of meromorphic functions defined in [44] in terms of
the Nevanlinna characteristic instead of the maximal modulus in [12] and show
that the multiply-connected wandering domain is a part of the fast escaping set
under a growth condition of the maximal modulus. Finally we give examples of
wandering domains escaping at arbitrary fast rate and slow rate.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:21:47 GMT""},{""version"":""v2"",""created"":""Fri, 2 Dec 2022 10:29:23 GMT""}]","2022-12-05"
"2102.05455","S\'ergio Marcelino","S\'ergio Marcelino and Umberto Rivieccio","Logics of involutive Stone algebras","preprint, 20 pages",,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An involutive Stone algebra (IS-algebra) is a structure that is
simultaneously a De Morgan algebra and a Stone algebra (i.e. a
pseudo-complemented distributive lattice satisfying the well-known Stone
identity ~xv~~x=1). IS-algebras have been studied algebraically and
topologically since the 1980's, but a corresponding logic (here denoted
IS$\leq$) has been introduced only very recently. The logic IS$\leq$ is the
departing point for the present study, which we then extend to a wide family of
previously unknown logics defined from IS-algebras. We show that IS$\leq$ is a
conservative expansion of the Belnap-Dunn four-valued logic (i.e. the
order-preserving logic of the variety of De Morgan algebras), and we give a
finite Hilbert-style axiomatization for it. More generally, we introduce a
method for expanding conservatively every super-Belnap logic so as to obtain an
extension of IS$\leq$. We show that every logic thus defined can be axiomatized
by adding a fixed finite set of rule schemata to the corresponding super-Belnap
base logic. We also consider a few sample extensions of IS$\leq$ that cannot be
obtained in the above-described way, but can nevertheless be axiomatized
finitely by other methods. Most of our axiomatization results are obtained in
two steps: through a multiple-conclusion calculus first, which we then reduce
to a traditional one. The multiple-conclusion axiomatizations introduced in
this process, being analytic, are of independent interest from a
proof-theoretic standpoint. Our results entail that the lattice of super-Belnap
logics (which is known to be uncountable) embeds into the lattice of extensions
of IS$\leq$. Indeed, as in the super-Belnap case, we establish that the
finitary extensions of IS$\leq$ are already uncountably many.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:22:48 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 15:08:28 GMT""}]","2021-03-15"
"2102.05457","Huanyu Zhang","Huanyu Zhang and Ziping Zhao","Joint Design of Transmit Waveforms and Receive Filters for MIMO Radar
  via Manifold Optimization",,,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The problem of joint design of transmit waveforms and receive filters is
desirable in many application scenarios of multiple-input multiple-output
(MIMO) radar systems. In this paper, the joint design problem is investigated
under the signal-to-interference-plus-noise ratio (SINR) performance metric, in
which case the problem is formulated to maximize the SINR at the receiver side
subject to some practical transmit waveform constraints. A numerical algorithm
is proposed for problem resolution based on the manifold optimization method,
which has been shown to be powerful and flexible to address nonconvex
constrained optimization problems in many engineering applications. The
proposed algorithm is able to efficiently solve the SINR maximization problem
with different waveform constraints under a unified framework. Numerical
experiments show that the proposed algorithm outperforms the existing
benchmarks in terms of computation efficiency and achieves comparable SINR
performance.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:24:02 GMT""}]","2021-02-11"
"2102.05458","Chandra Singh Dr.","Toru Okuda, Chandra B. Singh","Radiative Shocks around Super-Eddington Accreting Black Holes","9 pages, 8 figures, Accepted for publication in the MNRAS main
  journal",,"10.1093/mnras/stab428",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We examine radiative standing shocks in advective accretion flows around
stellar-mass black holes by 2D radiation hydrodynamic simulations, focusing on
the super-Eddington accreting flow. Under a set of input flow parameters
responsible for the standing shock, the shock location on the equator decreases
toward the event horizon with an increasing accretion rate. The optically thin
and hot gas in the narrow funnel region along the rotational axis changes
gradually into a dense and optically thick state with the increasingly dense
gas transported from the base of the radiative shock near the equator. As a
result, the luminosity becomes as high as ~ $10^{40}$ erg $s^{-1}$, and the
radiation shows a strongly anisotropic distribution around the rotational axis
and then very low edge-on luminosity as ~ $10^{36}$ erg $s^{-1}$. The mass
outflow rate from the outer boundary is high as ~ $10^{-5}$ and $10^{-4}$
$M_{\odot} yr^{-1}$ but most of the outflow is originated through the radial
outer boundary and may be observed over a wide wind region. The models show
approximately black body spectra with a temperature of $5 \times 10^{6} - 3
\times 10^{7}$ K at the vertical outer boundary surface. The radiative shock
models with the super-Eddington luminosities show a possible model for the
superaccretor SS 433 and Ultraluminous X-ray sources with stellar-mass black
holes.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:25:22 GMT""}]","2021-02-24"
"2102.05459","Olivier Rivoire","Anton S Zadorin, Olivier Rivoire","Sex as information processing: optimality and evolution",,"Phys. Rev. E 103, 062413 (2021)","10.1103/PhysRevE.103.062413",,"q-bio.PE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The long-term growth rate of populations in varying environments quantifies
the evolutionary value of processing the information that biological
individuals inherit from their ancestors and acquire from their environment.
Previous models were limited to asexual reproduction with inherited information
coming from a single parent with no recombination. We present a general
extension to sexual reproduction and an analytical solution for a particular
but important case, the infinitesimal model of quantitative genetics which
assumes traits to be normally distributed. We study with this model the
conditions under which sexual reproduction is advantageous and can evolve in
the context of autocorrelated or directionally varying environments, mutational
biases, spatial heterogeneities and phenotypic plasticity. Our results
generalize and unify previous analyses. We also examine the proposal made by
Geodakyan that the presence of two phenotypically distinct sexes permits an
optimal adaptation to varying environments. We verify that conditions exists
where sexual dimorphism is adaptive but find that its evolutionary value does
not generally compensate for the two-fold cost of males.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:26:35 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 09:33:12 GMT""}]","2021-06-30"
"2102.05460","Juliana Ferreira J","Juliana Jansen Ferreira and Mateus Monteiro","The human-AI relationship in decision-making: AI explanation to support
  people on justifying their decisions","Pre-print of paper accepted in Workshop on Transparency And
  Explanations In Smart Systems (TEXSS) held in conjunction with ACM
  Intelligent User Interfaces (IUI) (April 2021)",,,,"cs.HC cs.AI","http://creativecommons.org/licenses/by/4.0/","  The explanation dimension of Artificial Intelligence (AI) based system has
been a hot topic for the past years. Different communities have raised concerns
about the increasing presence of AI in people's everyday tasks and how it can
affect people's lives. There is a lot of research addressing the
interpretability and transparency concepts of explainable AI (XAI), which are
usually related to algorithms and Machine Learning (ML) models. But in
decision-making scenarios, people need more awareness of how AI works and its
outcomes to build a relationship with that system. Decision-makers usually need
to justify their decision to others in different domains. If that decision is
somehow based on or influenced by an AI-system outcome, the explanation about
how the AI reached that result is key to building trust between AI and humans
in decision-making scenarios. In this position paper, we discuss the role of
XAI in decision-making scenarios, our vision of Decision-Making with AI-system
in the loop, and explore one case from the literature about how XAI can impact
people justifying their decisions, considering the importance of building the
human-AI relationship for those scenarios.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:28:34 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 14:27:15 GMT""}]","2021-02-23"
"2102.05461","Tobias Alexander Kampmann","Tobias A. Kampmann, David M\""uller, Clemens Franz Vorsmann, Lukas Paul
  Weise, Jan Kierfeld","Event-Chain Monte-Carlo Simulations of Dense Soft Matter Systems","accepted for publication in frontiers in physics","Front. Phys. 9:635886 (2021)","10.3389/fphy.2021.635886",,"cond-mat.soft physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We discuss the rejection-free event-chain Monte-Carlo algorithm and several
applications to dense soft matter systems. Event-chain Monte-Carlo is an
alternative to standard local Markov-chain Monte-Carlo schemes, which are based
on detailed balance, for example the well-known Metropolis-Hastings algorithm.
Event-chain Monte-Carlo is a Markov chain Monte-Carlo scheme that uses
so-called lifting moves to achieve global balance without rejections (maximal
global balance). It has been originally developed for hard sphere systems but
is applicable to many soft matter systems and particularly suited for dense
soft matter systems with hard core interactions, where it gives significant
performance gains compared to a local Monte-Carlo simulation. The algorithm can
be generalized to deal with soft interactions and with three-particle
interactions, as they naturally arise, for example, in bead-spring models of
polymers with bending rigidity. We present results for polymer melts, where the
event-chain algorithm can be used for an efficient initialization. We then move
on to large systems of semiflexible polymers that form bundles by attractive
interactions and can serve as model systems for actin filaments in the
cytoskeleton. The event chain algorithm shows that these systems form networks
of bundles which coarsen similar to a foam. Finally, we present results on
liquid crystal systems, where the event-chain algorithm can equilibrate large
systems containing additional colloidal disks very efficiently, which reveals
the parallel chaining of disks.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:31:42 GMT""}]","2021-04-29"
"2102.05462","Philipp Herholz","Katja Wolff, Philipp Herholz, Verena Ziegler, Frauke Link, Nico
  Br\""ugel and Olga Sorkine-Hornung","Designing Personalized Garments with Body Movement","13 pages, 14 figures",,,,"cs.GR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The standardized sizes used in the garment industry do not cover the range of
individual differences in body shape for most people, leading to ill-fitting
clothes, high return rates and overproduction. Recent research efforts in both
industry and academia therefore focus on virtual try-on and on-demand
fabrication of individually fitting garments. We propose an interactive design
tool for creating custom-fit garments based on 3D body scans of the intended
wearer. Our method explicitly incorporates transitions between various body
poses to ensure a better fit and freedom of movement. The core of our method
focuses on tools to create a 3D garment shape directly on an avatar without an
underlying sewing pattern, and on the adjustment of that garment's rest shape
while interpolating and moving through the different input poses. We alternate
between cloth simulation and rest shape adjustment based on stretch to achieve
the final shape of the garment. At any step in the real-time process, we allow
for interactive changes to the garment. Once the garment shape is finalized for
production, established techniques can be used to parameterize it into a 2D
sewing pattern or transform it into a knitting pattern.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:33:47 GMT""},{""version"":""v2"",""created"":""Mon, 19 Sep 2022 19:27:53 GMT""}]","2022-09-21"
"2102.05464","Jan Brand","J. Brand, A. Giannetti, F. Massi, J.G.A. Wouterloot, C. Verdirame","A possible far-ultraviolet flux-dependent core mass function in NGC 6357","16 pages, 18 figures, 3 tables (1 only at CDS); accepted by Astronomy
  & Astrophysics","A&A 647, A154 (2021)","10.1051/0004-6361/202039506",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To derive the properties of the dense cores in the galactic star-forming
complex NGC6357 and to investigate the effects of an intense far-UV radiation
field on their properties, we mapped the region at 450 and 850 micron, and in
the CO(3-2) line with the JCMT. We also made use of the Herschel Hi-GAL data at
70 and 160 micron. We used Gaussclumps to retrieve 686 compact cores embedded
in the diffuse sub-mm emission and constructed their SED from 70 to 850 micron,
from which we derived mass and temperature. The estimated mass completeness
limit is ~5Mo. We divided the observed area in an 'active' region, exposed to
the far-UV radiation from the more massive members of three star clusters (411
cores), and a 'quiescent' region, less affected by far-UV radiation (275
cores). We also attempted to select a sample of pre-stellar cores based on
cross-correlation with 70 micron emission and red WISE point sources. Most of
the cores above the mass completeness limit are likely to be gravitationally
bound. The fraction of gas in dense cores is very low, 1.4%. We found a
mass-size relation log(M/Mo) ~ (2.0-2.4) x log (D/arcsec), depending on the
precise selection of the sample. The temperature distributions in the two
sub-regions are clearly different, peaking at ~25K in the quiescent region and
at ~35K in the active region. The core mass functions are different as well, at
a 2sigma level, consistent with a Salpeter IMF in the quiescent region and
flatter than that in the active region. The dense cores lying close to the HII
regions are consistent with pre-existing cores being gradually engulfed by a
PDR and photoevaporating. We attribute the different global properties of dense
cores in the two sub-regions to the influence of the far-UV radiation field.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:34:24 GMT""}]","2021-03-31"
"2102.05465","Genly Le\'on","Genly Leon, Esteban Gonz\'alez, Samuel Lepe, Claudio Michea, and
  Alfredo D. Millano","Averaging Generalized Scalar Field Cosmologies I: Locally Rotationally
  Symmetric Bianchi III and open Friedmann-Lema\^itre-Robertson-Walker models","Research Program Averaging Generalized Scalar Field Cosmologies, part
  I. 48 pages, 24 compound figures. Minor revision. References added",,"10.1140/epjc/s10052-021-09185-7",,"gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scalar field cosmologies with a generalized harmonic potential and a matter
fluid with a barotropic Equation of State (EoS) with barotropic index $\gamma$
for Locally Rotationally Symmetric (LRS) Bianchi III metric and open
Friedmann-Lema\^itre-Robertson-Walker (FLRW) metric are investigated. Methods
from the theory of averaging of nonlinear dynamical systems are used to prove
that time-dependent systems and their corresponding time-averaged versions have
the same late-time dynamics. Therefore, simple time-averaged systems determine
the future asymptotic behavior. Depending on values of barotropic index
$\gamma$ late-time attractors of physical interests for LRS Bianchi III metric
are Bianchi III flat spacetime, matter dominated FLRW universe (mimicking de
Sitter, quintessence or zero acceleration solutions) and matter-curvature
scaling solution. For open FLRW metric late-time attractors are a matter
dominated FLRW universe and Milne solution. With this approach, oscillations
entering nonlinear system through Klein-Gordon (KG) equation can be controlled
and smoothed out as the Hubble factor $H$ - acting as a time-dependent
perturbation parameter - tends monotonically to zero. Numerical simulations are
presented as evidence of such behaviour.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:41:30 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 21:48:14 GMT""},{""version"":""v3"",""created"":""Tue, 30 Mar 2021 17:29:38 GMT""},{""version"":""v4"",""created"":""Fri, 23 Apr 2021 00:58:41 GMT""}]","2021-06-03"
"2102.05466","Ke Sun","Ke Sun, Vijay Kumar","Belief Space Planning for Mobile Robots with Range Sensors using iLQG","Accepted by Robotics and Automation Letters",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we use iterative Linear Quadratic Gaussian (iLQG) to plan
motions for a mobile robot with range sensors in belief space. We address two
limitations that prevent applications of iLQG to the considered robotic system.
First, iLQG assumes a differentiable measurement model, which is not true for
range sensors. We show that iLQG only requires the differentiability of the
belief dynamics. We propose to use a derivative-free filter to approximate the
belief dynamics, which does not require explicit differentiability of the
measurement model. Second, informative measurements from a range sensor are
sparse. Uninformative measurements produce trivial gradient information, which
prevent iLQG optimization from converging to a local minimum. We densify the
informative measurements by introducing additional parameters in the
measurement model. The parameters are iteratively updated in the optimization
to ensure convergence to the true measurement model of a range sensor. We show
the effectiveness of the proposed modifications through an ablation study. We
also apply the proposed method in simulations of large scale real world
environments, which show superior performance comparing to the state-of-the-art
methods that either assume the separation principle or maximum likelihood
measurements.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:45:16 GMT""}]","2021-02-11"
"2102.05467","Patrick Winkert","Csaba Farkas and Alessio Fiscella and Patrick Winkert","Singular Finsler double phase problems with nonlinear boundary condition",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study a singular Finsler double phase problem with a
nonlinear boundary condition and perturbations that have a type of critical
growth, even on the boundary. Based on variational methods in combination with
truncation techniques we prove the existence of at least one weak solution for
this problem under very general assumptions. Even in the case when the Finsler
manifold reduces to the Euclidean norm, our work is the first one dealing with
a singular double phase problem and nonlinear boundary condition.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:46:24 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 10:00:06 GMT""}]","2021-07-23"
"2102.05468","Alexander Studenikin","Alexander Studenikin","Electromagnetic neutrino properties: new constraints and new effects","6 pages in LaTex, based on the presentation at the 40th International
  Conference on High Energy Physics (ICHEP 2020), Prague, Czech Republic, 28
  July - 6 August 2020. arXiv admin note: substantial text overlap with
  arXiv:1912.12497, arXiv:1912.12501","PoS(ICHEP2020)180",,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The electromagnetic properties of neutrinos have attracted considerable
attention from researchers for many decades (see [1] for a review). However,
until recently, there was no indication in favour of nonzero electromagnetic
properties of neutrinos either from laboratory experiments with ground-based
neutrino sources or from observations of astrophysical neutrino fluxes. The
situation changed after the XENON collaboration reported [2] results of the
search for new physics with low-energy electronic recoil data recorded with the
XENON1T detector. The results show an excess of events over the known
backgrounds in the recoil energy which, as one of the possible explanations,
admit the presence of a sizable neutrino magnetic moment, the value of which is
of the order of the existing laboratory limitations. In these short notes we
give a brief introduction to neutrino electromagnetic properties and focus on
the most important constraints on neutrino magnetic moments, charge radii and
millicharges from the terrestrial experiments and astrophysical considerations.
The promising new possibilities for constraining neutrino electromagnetic
properties in future experiments are also discussed.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:48:09 GMT""}]","2021-02-11"
"2102.05469","Yunhan Huang","Yunhan Huang and Quanyan Zhu","A Pursuit-Evasion Differential Game with Strategic Information
  Acquisition",,,,,"eess.SY cs.GT cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies a two-person linear-quadratic-Gaussian pursuit-evasion
differential game with costly but controlled information. One player can decide
when to observe the other player's state. However, one observation of another
player's state comes with two costs: the direct cost of observing and the
implicit cost of exposing his state. We call games of this type a
Pursuit-Evasion-Exposure-Concealment (PEEC) game. The PEEC game constitutes two
types of strategies: The control strategies and the observation strategies. We
fully characterize the Nash control strategies of the PEEC game using
techniques such as completing squares and the calculus of variations. We show
that the derivation of the Nash observation strategies and the Nash control
strategies can be decoupled. We develop a set of necessary conditions that
facilitate the numerical computation of the Nash observation strategies. We
show, in theory, that players with less maneuverability prefer concealment to
exposure. We also show that when the game's horizon goes to infinity, the Nash
observation strategy is to observe periodically, and the expected distance
between the pursuer and the evader goes to zero with a bounded second moment.
We conducted a series of numerical experiments to study the proposed PEEC game.
We illustrate the numerical results using both figures and animation. Numerical
results show that the pursuer can maintain high-grade performance even when the
number of observations is limited. We also show that an evader with low
maneuverability can still escape if the evader increases his stealthiness.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:51:27 GMT""},{""version"":""v2"",""created"":""Sun, 24 Apr 2022 17:39:57 GMT""}]","2022-04-26"
"2102.05470","Alberto Bracci","Alberto Bracci, Matthieu Nadini, Maxwell Aliapoulios, Damon McCoy, Ian
  Gray, Alexander Teytelboym, Angela Gallo, Andrea Baronchelli","The illicit trade of COVID-19 vaccines on the dark web","For the ""before the vaccine"" report see
  https://doi.org/10.1140/epjds/s13688-021-00259-w",,,,"cs.CY cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Early analyses revealed that dark web marketplaces (DWMs) started offering
COVID-19 related products (e.g., masks and COVID-19 tests) as soon as the
COVID-19 pandemic started, when these goods were in shortage in the traditional
economy. Here, we broaden the scope and depth of previous investigations by
analysing 194 DWMs until July 2021, including the crucial period in which
vaccines became available, and by considering the wider impact of the pandemic
on DWMs. First, we focus on vaccines. We find 250 listings offering approved
vaccines, like Pfizer/BioNTech and AstraZeneca, as well as vendors offering
fabricated proofs of vaccination and COVID-19 passports. Second, we consider
COVID-19 related products. We reveal that, as the regular economy has become
able to satisfy the demand of these goods, DWMs have decreased their offer.
Third, we analyse the profile of vendors of COVID-19 related products and
vaccines. We find that most of them are specialized in a single type of
listings and are willing to ship worldwide. Finally, we consider a broader set
of listings mentioning COVID-19 as proxy for the general impact of the pandemic
on these DWMs . Among 10,330 such listings, we show that recreational drugs are
the most affected among traditional DWMs product, with COVID-19 mentions
steadily increasing since March 2020. We anticipate that our effort is of
interest to researchers, practitioners, and law enforcement agencies focused on
the study and safeguard of public health.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:52:54 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 11:10:24 GMT""},{""version"":""v3"",""created"":""Mon, 10 May 2021 14:58:09 GMT""},{""version"":""v4"",""created"":""Tue, 10 Aug 2021 17:48:12 GMT""},{""version"":""v5"",""created"":""Mon, 4 Apr 2022 16:59:58 GMT""}]","2022-04-05"
"2102.05471","Faustino Martelli Dr.","Aswathi K Sivan, Lorenzo Di Mario, Yunyan Zhang, Daniele Catone,
  Patrick OKeeffe, Stefano Turchini, Valentina Mussi, Huiyun Liu, Faustino
  Martelli","Diameter dependence of the temperature dynamics of hot carriers in
  photoexcited GaAsP nanowires",,"Phys. Rev. B 104, 045423 (2021)","10.1103/PhysRevB.104.045423",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Nanowires (NWs) with their quasi-one-dimensionality often present different
structural and opto-electronic properties than their thin-film counterparts.
The thinner they are the larger these differences are, in particular in the
carrier-phonon scattering and thermal conductivity. In this work, we present
femtosecond transient absorbance measurements on GaAs0.8P0.2 NWs of two
different diameters, 36 and 51 nm. The results show that thinner NWs sustain
the hot-carriers at a higher temperature for longer times than thicker NWs. We
explain the observation suggesting that in thinner NWs, the build-up of a
hot-phonon bottleneck is easier than in thicker NWs because of the increased
phonon scattering at the NW sidewalls which facilitates the build-up of a large
phonon density. The large number of optical phonons emitted during the carrier
relaxation processes generate a non-equilibrium population of acoustic phonons
that propagates less efficiently in thin NWs. This makes the possible
acoustic-to-optical phonon up-conversion process easier, which prolongs the LO
phonon lifetime resulting in the slowdown of the carrier cooling. The important
observation that the carrier temperature in thin NWs is higher than in thick
NWs already at the beginning of the hot carrier regime suggests that the
phonon-mediated scattering processes in the non-thermal regime play a major
role at least for the carrier densities investigated here (8x1018-4x1019 cm-3).
Our results also suggest that the boundary scattering of phonons at crystal
defects is negligible compared to the surface scattering at the NW sidewalls.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:54:34 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 10:06:51 GMT""}]","2021-07-28"
"2102.05472","Marina Garrote-L\'opez","Marta Casanellas, Marina Garrote-L\'opez and Piotr Zwiernik","Robust estimation of tree structured models",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider the problem of learning undirected graphical models on trees from
corrupted data. Recently Katiyar et al. showed that it is possible to recover
trees from noisy binary data up to a small equivalence class of possible trees.
Their other paper on the Gaussian case follows a similar pattern. By framing
this as a special phylogenetic recovery problem we largely generalize these two
settings. Using the framework of linear latent tree models we discuss tree
identifiability for binary data under a continuous corruption model. For the
Ising and the Gaussian tree model we also provide a characterisation of when
the Chow-Liu algorithm consistently learns the underlying tree from the noisy
data.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 14:58:40 GMT""}]","2021-02-11"
"2102.05473","Erich Gr\""adel","Erich Gr\""adel and Lovro Mrkonji\'c","Elementary equivalence versus isomorphism in semiring semantics","21 pages",,,,"math.LO cs.DB cs.LO","http://creativecommons.org/licenses/by/4.0/","  We study the first-order axiomatisability of finite semiring interpretations
or, equivalently, the question whether elementary equivalence and isomorphism
coincide for valuations of atomic facts over a finite universe into a
commutative semiring. Contrary to the classical case of Boolean semantics,
where every finite structure can obviously be axiomatised up to isomorphism by
a first-order sentence, the situation in semiring semantics is rather
different, and strongly depends on the underlying semiring. We prove that for a
number of important semirings, including min-max semirings, and the semirings
of positive Boolean expressions, there exist finite semiring interpretations
that are elementarily equivalent but not isomorphic. The same is true for the
polynomial semirings that are universal for the classes of absorptive,
idempotent, and fully idempotent semirings, respectively. On the other side, we
prove that for other, practically relevant, semirings such as the Viterby
semiring, the tropical semiring, the natural semiring and the universal
polynomial semiring N[X], all finite semiring interpretations are first-order
axiomatisable (and thus elementary equivalence implies isomorphism), although
some of the axiomatisations that we exhibit use an infinite set of axioms.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:00:01 GMT""}]","2021-02-11"
"2102.05474","Zhuosheng Zhang","Zhuosheng Zhang, Junlong Li, Hai Zhao","Multi-turn Dialogue Reading Comprehension with Pivot Turns and Knowledge","The early version accepted by IEEE/ACM Transactions on Audio, Speech,
  and Language Processing (TASLP)",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-turn dialogue reading comprehension aims to teach machines to read
dialogue contexts and solve tasks such as response selection and answering
questions. The major challenges involve noisy history contexts and especial
prerequisites of commonsense knowledge that is unseen in the given material.
Existing works mainly focus on context and response matching approaches. This
work thus makes the first attempt to tackle the above two challenges by
extracting substantially important turns as pivot utterances and utilizing
external knowledge to enhance the representation of context. We propose a
pivot-oriented deep selection model (PoDS) on top of the Transformer-based
language models for dialogue comprehension. In detail, our model first picks
out the pivot utterances from the conversation history according to the
semantic matching with the candidate response or question, if any. Besides,
knowledge items related to the dialogue context are extracted from a knowledge
graph as external knowledge. Then, the pivot utterances and the external
knowledge are combined with a well-designed mechanism for refining predictions.
Experimental results on four dialogue comprehension benchmark tasks show that
our proposed model achieves great improvements on baselines. A series of
empirical comparisons are conducted to show how our selection strategies and
the extra knowledge injection influence the results.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:00:12 GMT""}]","2021-02-11"
"2102.05475","Grzegorz G{\l}uch","Grzegorz G{\l}uch, R\""udiger Urbanke","Adversarial Robustness: What fools you makes you stronger","15 pages, 1 figure [V2 - fixed typos]",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an exponential separation for the sample complexity between the
standard PAC-learning model and a version of the Equivalence-Query-learning
model. We then show that this separation has interesting implications for
adversarial robustness. We explore a vision of designing an adaptive defense
that in the presence of an attacker computes a model that is provably robust.
In particular, we show how to realize this vision in a simplified setting.
  In order to do so, we introduce a notion of a strong adversary: he is not
limited by the type of perturbations he can apply but when presented with a
classifier can repetitively generate different adversarial examples. We explain
why this notion is interesting to study and use it to prove the following.
There exists an efficient adversarial-learning-like scheme such that for every
strong adversary $\mathbf{A}$ it outputs a classifier that (a) cannot be
strongly attacked by $\mathbf{A}$, or (b) has error at most $\epsilon$. In both
cases our scheme uses exponentially (in $\epsilon$) fewer samples than what the
PAC bound requires.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:00:24 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 16:27:32 GMT""}]","2021-02-19"
"2102.05476","Arturs Vrublevskis","A. Vrublevskis (1), B. I. Ryabov (1), S. M. White (2) ((1) Ventspils
  International Radio Astronomy Centre and Ventspils University of Applied
  Sciences, (2) Space Vehicles Directorate, Air Force Research Laboratory,
  Kirtland AFB)","Reduced Microwave Brightness Temperature in a Sunspot Atmosphere due to
  Open Magnetic Fields","26 pages, 12 figures. [v1] replaced to include journal reference
  after publication. This preprint has not undergone peer review or any
  post-submission improvements or corrections. The Version of Record of this
  article is published in Solar Physics, and is available online at
  https://doi.org/10.1007/s11207-021-01891-5","Sol Phys 296, 144 (2021)","10.1007/s11207-021-01891-5",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motivated by dark coronal lanes in SOHO / EIT 284 {\AA} EUV observations we
construct and optimize an atmosphere model of the AR 8535 sunspot by adding a
cool and dense component in the volume of plasma along open field lines
determined using the Potential Field Source Surface (PFSS) extrapolation. Our
model qualitatively reproduces the observed reduced microwave brightness
temperature in the northern part of the sunspot in the VLA observations from 13
May 1999 and provides a physical explanation for the coronal dark lanes. We
propose application of this method to other sunspots with such observed dark
regions in EUV or soft X-rays and with concurrent microwave observations to
determine the significance of open field regions. The connection between open
fields and the resulting plasma temperature and density change is of relevance
for slow solar wind source investigations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:02:13 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 13:45:18 GMT""}]","2021-10-06"
"2102.05477","Corrado Monti","Gianmarco De Francisci Morales, Corrado Monti, Michele Starnini","No Echo in the Chambers of Political Interactions on Reddit",,"Scientific Reports volume 11, Article number: 2818 (2021)","10.1038/s41598-021-81531-x",,"physics.soc-ph cs.SI","http://creativecommons.org/licenses/by/4.0/","  Echo chambers in online social networks, whereby users' beliefs are
reinforced by interactions with like-minded peers and insulation from others'
points of view, have been decried as a cause of political polarization. Here,
we investigate their role in the debate around the 2016 US elections on Reddit,
a fundamental platform for the success of Donald Trump. We identify Trump vs
Clinton supporters and reconstruct their political interaction network. We
observe a preference for cross-cutting political interactions between the two
communities rather than within-group interactions, thus contradicting the echo
chamber narrative. Furthermore, these interactions are asymmetrical: Clinton
supporters are particularly eager to answer comments by Trump supporters.
Beside asymmetric heterophily, users show assortative behavior for activity,
and disassortative, asymmetric behavior for popularity. Our findings are tested
against a null model of random interactions, by using two different approaches:
a network rewiring which preserves the activity of nodes, and a logit
regression which takes into account possible confounding factors. Finally, we
explore possible socio-demographic implications. Users show a tendency for
geographical homophily and a small positive correlation between
cross-interactions and voter abstention. Our findings shed light on public
opinion formation on social media, calling for a better understanding of the
social dynamics at play in this context.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:05:17 GMT""}]","2021-02-11"
"2102.05478","Matteo Bonini","Matteo Bonini, Massimiliano Sala, Lara Vicino","Rational points on cubic surfaces and AG codes from the Norm-Trace curve",,,"10.1007/s10231-022-01237-3",,"math.AG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give a complete characterization of the intersections
between the Norm-Trace curve over $\mathbb{F}_{q^3}$ and the curves of the form
$y=ax^3+bx^2+cx+d$, generalizing a previous result by Bonini and Sala,
providing more detailed information about the weight spectrum of one-point AG
codes arising from such curve. We also derive, with explicit computations, some
general bounds for the number of rational points on a cubic surface defined
over $\mathbb{F}_{q}$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:06:43 GMT""}]","2022-07-05"
"2102.05479","Anna Miriam Benini","Leandro Arosio, Anna Miriam Benini, John Erik Forn{\ae}ss, Han Peters","Dynamics of transcendental H\'enon maps III: Infinite entropy",,,,,"math.DS math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very little is currently known about the dynamics of non-polynomial entire
maps in several complex variables. The family of transcendental H\'enon maps
offers the potential of combining ideas from transcendental dynamics in one
variable, and the dynamics of polynomial H\'enon maps in two. Here we show that
these maps all have infinite topological and measure theoretic entropy. The
proof also implies the existence of infinitely many periodic orbits of any
order greater than two.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:08:38 GMT""}]","2021-02-11"
"2102.05480","Sungjin Kim","Sungjin Kim","On the distribution of lcm of k-tuples and related problems","18 pages, the previous version had an error on page 6. Now it is
  fixed",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We study the distribution of the least common multiple of positive integers
in N\cap [1, x] and related problems. We refine some results of Hilberdink and
T\'{o}th (2016). We also give a partial result toward a conjecture of
Hilberdink, Luca, and T\'{o}th (2020).
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:09:04 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 17:02:30 GMT""},{""version"":""v3"",""created"":""Sat, 23 Jul 2022 03:36:15 GMT""},{""version"":""v4"",""created"":""Wed, 3 Aug 2022 17:35:06 GMT""}]","2022-08-04"
"2102.05481","Diego Hidalgo Tecay","Fabrizio Canfora, Adolfo Cisterna, Diego Hidalgo, Julio Oliva","Exact \textit{pp}-waves, (A)dS waves and Kundt spaces in the
  Abelian-Higgs model","14 pages. This corresponds to the published version in Physical
  Review D (Vol. 103, No. 8)","Phys. Rev. D 103, 085007 (2021)","10.1103/PhysRevD.103.085007",,"hep-th gr-qc","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We find new exact solutions of the Abelian-Higgs model coupled to General
Relativity, characterized by a non-vanishing superconducting current. The
solutions correspond to \textit{pp}-waves, AdS waves, and Kundt spaces, for
which both the Maxwell field and the gradient of the phase of the scalar are
aligned with the null direction defining these spaces. In the Kundt family, the
geometry of the two-dimensional surfaces orthogonal to the superconducting
current is determined by the solutions of the two-dimensional Liouville
equation, and in consequence, these surfaces are of constant curvature, as it
occurs in a vacuum. The solution to the Liouville equation also acts as a
potential for the Maxwell field, which we integrate into a closed-form. Using
these results, we show that the combined effects of the gravitational and
scalar interactions can confine the electromagnetic field within a bounded
region in the surfaces transverse to the current.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:11:17 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 17:44:56 GMT""}]","2021-04-28"
"2102.05482","Alexander Raymond","Alexander W. Raymond, Daniel Palumbo, Scott N. Paine, Lindy Blackburn,
  Rodrigo C\'ordova Rosado, Sheperd S. Doeleman, Joseph R. Farah, Michael D.
  Johnson, Freek Roelofs, Remo P.J. Tilanus, Jonathan Weintroub","Evaluation of New Submillimeter VLBI Sites for the Event Horizon
  Telescope",,,"10.3847/1538-3881/abc3c3",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Event Horizon Telescope (EHT) is a very long baseline interferometer
built to image supermassive black holes on event-horizon scales. In this paper,
we investigate candidate sites for an expanded EHT array with improved imaging
capabilities. We use historical meteorology and radiative transfer analysis to
evaluate site performance. Most of the existing sites in the EHT array have
median zenith opacity less than 0.2 at 230 GHz during the March/April observing
season. Seven of the existing EHT sites have 345 GHz opacity less than 0.5
during observing months. Out of more than forty candidate new locations
analyzed, approximately half have 230 GHz opacity comparable to the existing
EHT sites, and at least seventeen of the candidate sites would be comparably
good for 345 GHz observing. A group of new sites with favorable transmittance
and geographic placement leads to greatly enhanced imaging and science on
horizon scales.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:12:17 GMT""}]","2021-02-17"
"2102.05483","Denis Dalmazi","D. Dalmazi","Self-dual models in $D=2+1$ from dimensional reduction","15 pages, no figures, one added ref., added paragraph at the end of
  section 2, accepted in Annals Of Physics",,"10.1016/j.aop.2021.168653",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we perform a Kaluza-Klein dimensional reduction of Vasiliev's
first-order description of massless spin-s particles from $D=3+1$ to $D=2+1$
and derive first-order self-dual models describing particles with helicities
$\pm s$ for the cases $s=1,2,3$. In the first two cases we recover known
(parity singlets) self-dual models. In the spin-3 case we derive a new first
order self-dual model with a local Weyl symmetry which lifts the traceless
restriction on the rank-3 tensor. A gauge fixed version of this model
corresponds to a known spin-3 self-dual model. We conjecture that our procedure
can be generalized to arbitrary integer spins.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:16:46 GMT""},{""version"":""v2"",""created"":""Sat, 16 Oct 2021 17:08:42 GMT""}]","2021-11-17"
"2102.05484","Juan Manuel Pacheco Arias","J. M. Pacheco-Arias, C. R. Carvajal-Bohorquez, Juan C. B. Pineda and
  L. A. N\'u\~nez","Systematic effects on the diversity of dwarf galaxies rotation curves","4 pages, 2 figures, conference",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmological simulations of structure formation are invaluable to study the
evolution of the Universe and the development of galaxies in it successfully
reproducing many observations in the context of the cosmological paradigm
$\Lambda$CDM. However, there are remarkable discrepancies with observations
that are a matter of debate. One of the most recently reported is the diversity
of shapes in the rotation curves of dwarf galaxies in the local Universe which
is in contrast to the apparent homogeneity of rotation curves in cosmological
hydrodynamic simulations. Previous studies on similar problems have shown that
sometimes can be alleviated by accounting for the impact of observational
effects in the comparison. For this reason, in this work we present a set of
controlled experiments to measure the impact that some systematic effects,
associated with modeling the observation process in a realistic way, have on
the diversity of synthetic rotation curves. Our results demonstrate that
factors such as spectral power, spatial resolution and inclination angle, can
naturally induce noticeable fluctuations on the shape of the rotation curves,
reproducing up to $47\%$ of the diversity reported in the observations. This is
remarkable, especially considering that we limited the sample to
highly-symmetric disks simulated in isolation. This shows that a more realistic
modeling of synthetic rotation curves may alleviate the reported tension
between simulations and observations, without posing a challenge to the
standard cosmological model of cold dark matter.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:19:05 GMT""}]","2021-02-11"
"2102.05485","Yufeng Zhang","Yufeng Zhang, Wanwei Liu, Zhenbang Chen, Ji Wang, Kenli Li","On the Properties of Kullback-Leibler Divergence Between Multivariate
  Gaussian Distributions","arXiv admin note: text overlap with arXiv:2002.03328",,,,"cs.IT cs.AI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kullback-Leibler (KL) divergence is one of the most important divergence
measures between probability distributions. In this paper, we prove several
properties of KL divergence between multivariate Gaussian distributions. First,
for any two $n$-dimensional Gaussian distributions $\mathcal{N}_1$ and
$\mathcal{N}_2$, we give the supremum of $KL(\mathcal{N}_1||\mathcal{N}_2)$
when $KL(\mathcal{N}_2||\mathcal{N}_1)\leq \varepsilon\ (\varepsilon>0)$. For
small $\varepsilon$, we show that the supremum is $\varepsilon +
2\varepsilon^{1.5} + O(\varepsilon^2)$. This quantifies the approximate
symmetry of small KL divergence between Gaussians. We also find the infimum of
$KL(\mathcal{N}_1||\mathcal{N}_2)$ when $KL(\mathcal{N}_2||\mathcal{N}_1)\geq
M\ (M>0)$. We give the conditions when the supremum and infimum can be
attained. Second, for any three $n$-dimensional Gaussians $\mathcal{N}_1$,
$\mathcal{N}_2$, and $\mathcal{N}_3$, we find an upper bound of
$KL(\mathcal{N}_1||\mathcal{N}_3)$ if $KL(\mathcal{N}_1||\mathcal{N}_2)\leq
\varepsilon_1$ and $KL(\mathcal{N}_2||\mathcal{N}_3)\leq \varepsilon_2$ for
$\varepsilon_1,\varepsilon_2\ge 0$. For small $\varepsilon_1$ and
$\varepsilon_2$, we show the upper bound is
$3\varepsilon_1+3\varepsilon_2+2\sqrt{\varepsilon_1\varepsilon_2}+o(\varepsilon_1)+o(\varepsilon_2)$.
This reveals that KL divergence between Gaussians follows a relaxed triangle
inequality. Importantly, all the bounds in the theorems presented in this paper
are independent of the dimension $n$. Finally, We discuss the applications of
our theorems in explaining counterintuitive phenomenon of flow-based model,
deriving deep anomaly detection algorithm, and extending one-step robustness
guarantee to multiple steps in safe reinforcement learning.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:21:53 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 04:12:30 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 10:39:20 GMT""},{""version"":""v4"",""created"":""Tue, 24 May 2022 02:58:32 GMT""},{""version"":""v5"",""created"":""Mon, 23 Jan 2023 03:17:54 GMT""}]","2023-01-24"
"2102.05486","Pengfei Liu","Zihuiwen Ye, Pengfei Liu, Jinlan Fu, Graham Neubig","Towards More Fine-grained and Reliable NLP Performance Prediction","Accepted by EACL 2021",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performance prediction, the task of estimating a system's performance without
performing experiments, allows us to reduce the experimental burden caused by
the combinatorial explosion of different datasets, languages, tasks, and
models. In this paper, we make two contributions to improving performance
prediction for NLP tasks. First, we examine performance predictors not only for
holistic measures of accuracy like F1 or BLEU but also fine-grained performance
measures such as accuracy over individual classes of examples. Second, we
propose methods to understand the reliability of a performance prediction model
from two angles: confidence intervals and calibration. We perform an analysis
of four types of NLP tasks, and both demonstrate the feasibility of
fine-grained performance prediction and the necessity to perform reliability
analysis for performance prediction methods in the future. We make our code
publicly available: \url{https://github.com/neulab/Reliable-NLPPP}
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:23:20 GMT""}]","2021-02-11"
"2102.05487","Ciaran Williams","Roberto Mondini and Ciaran Williams","Bottom-induced contributions to Higgs plus jet at
  next-to-next-to-leading order","24 pages, 9 figures",,"10.1007/JHEP05(2021)045",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a next-to-next-to-leading order (NNLO) QCD calculation of the
bottom-induced contributions to the production of a Higgs boson plus a jet,
i.e. the process $p p \rightarrow H +j$ to $\mathcal{O}(y_b^2 \alpha_s^3)$. We
work in the five-flavor scheme (5FS) in which the bottom quark mass is retained
only in the coupling to the Higgs boson. Our calculation uses $N$-jettiness
slicing to regulate infrared divergences, allowing for fully-differential
predictions for collider observables. After extensively validating the
methodology, we present results for the 13 TeV LHC. Our NNLO predictions show a
marked improvement in the overall renormalization and factorization scale
dependence, the latter of which proves to be particularly troublesome for 5FS
calculations at lower orders. In addition, using the same methodology we
present a NNLO computation of $b\overline{b} \rightarrow H$. Our results are
implemented into MCFM.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:25:06 GMT""}]","2021-05-26"
"2102.05488","Jun Peng","Jun Peng, Minyong Guo and Xing-Hui Feng","Observational Signature and Additional Photon Rings of Asymmetric
  Thin-shell Wormhole","12 pages, 7 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, a distinct shadow mechanism was proposed by Wang et al. from the
asymmetric thin-shell wormhole (ATW) in [Phys. Lett. B 811 (2020) 135930]. On
the other hand, Gralla et al's work [Phys. Rev. D 100 (2019) 2, 024018]
represented a nice description of photon rings in the presence of an accretion
disk around a black hole. In this paper, we are inspired to thoroughly
investigate the observational appearance of an accretion disk around the ATW.
Although the spacetime outside an ATW with a throat could be identical to that
containing a black hole with its event horizon, we show evident additional
photon rings from the ATW spacetime. Moreover, a potential lensing band between
two highly demagnified photon rings is found. Our analysis provides an
optically observational signature to distinguish ATWs from black holes.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:28:06 GMT""}]","2021-02-11"
"2102.05489","Jan Lotze","Jan Lotze, Maria Daghofer","Suppression of effective spin-orbit coupling by thermal fluctuations in
  spin-orbit coupled antiferromagnets","8 pages, 7 figures","Phys. Rev. B 104, 045125 (2021)","10.1103/PhysRevB.104.045125",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the finite-temperature variational cluster approach to a strongly
correlated and spin-orbit coupled model for four electrons (i.e. two holes) in
the $t_{2g}$ subshell. We focus on parameters suitable for antiferromagnetic
Mott insulators, in particular Ca$_2$RuO$_4$, and identify a crossover from the
low-temperature regime, where spin-orbit coupling is essential, to the
high-temperature regime where it leaves few signatures. The crossover is seen
in one-particle spectra, where $xz$ and $yz$ spectra are almost one dimensional
(as expected for weak spin-orbit coupling) at high temperature. At lower
temperature, where spin-orbit coupling mixes all three orbitals, they become
more two dimensional. However, stronger effects are seen in two-particle
observables like the weight in states with definite onsite angular momentum. We
thus identify the enigmatic intermediate-temperature 'orbital-order phase
transition', which has been reported in various X-ray diffraction and
absorption experiments at $T\approx 260\;K$, as the signature of the onset of
spin-orbital correlations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:28:50 GMT""}]","2021-07-21"
"2102.05490","Bingzhuo Zhong","Bingzhuo Zhong, Abolfazl Lavaei, Hongpeng Cao, Majid Zamani and Marco
  Caccamo","Safe-visor Architecture for Sandboxing (AI-based) Unverified Controllers
  in Stochastic Cyber-Physical Systems",,,"10.1016/j.nahs.2021.101110",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High performance but unverified controllers, e.g., artificial
intelligence-based (a.k.a. AI-based) controllers, are widely employed in
cyber-physical systems (CPSs) to accomplish complex control missions. However,
guaranteeing the safety and reliability of CPSs with this kind of controllers
is currently very challenging, which is of vital importance in many real-life
safety-critical applications. To cope with this difficulty, we propose in this
work a Safe-visor architecture for sandboxing unverified controllers in CPSs
operating in noisy environments (a.k.a. stochastic CPSs). The proposed
architecture contains a history-based supervisor, which checks inputs from the
unverified controller and makes a compromise between functionality and safety
of the system, and a safety advisor that provides fallback when the unverified
controller endangers the safety of the system. Both the history-based
supervisor and the safety advisor are designed based on an approximate
probabilistic relation between the original system and its finite abstraction.
By employing this architecture, we provide formal probabilistic guarantees on
preserving the safety specifications expressed by accepting languages of
deterministic finite automata (DFA). Meanwhile, the unverified controllers can
still be employed in the control loop even though they are not reliable. We
demonstrate the effectiveness of our proposed results by applying them to two
(physical) case studies.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:29:26 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 20:21:05 GMT""}]","2021-10-28"
"2102.05491","Malgorzata Lekka","Katarzyna Herman (1), Joanna Zem{\l}a (2), Arkadiusz Ptak (1) and
  Ma{\l}gorzata Lekka (2) ((1) Institute of Physics, Faculty of Materials
  Engineering and Technical Physics, Poznan University of Technology, Poznan,
  Poland, (2) Department of Biophysical Microstructures, Institute of Nuclear
  Physics, Polish Academy of Sciences Krak\'ow, Poland)","Single-molecule force spectroscopy reveals structural differences of
  heparan sulfate chains during binding to vitronectin","9 pages, 6 figures","Phys. Rev. E 104, 024409 (2021)","10.1103/PhysRevE.104.024409",,"physics.bio-ph physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The syndecans represent an ongoing research field focused on their regulatory
roles in normal and pathological conditions. Syndecan's role in cancer
progression becomes well-documented, implicating their importance in diagnosis
and even proposing various cancer potential treatments. Thus, the
characterization of the unbinding properties at the single molecules level will
appeal to their use as targets for therapeutics. In our study, syndecan-1 and
syndecan-4 were measured during the interaction with the vitronectin HEP II
binding site. Our findings show that syndecans are calcium ion-dependent
molecules that reveal distinct, unbinding properties indicating the alterations
in heparin sulfate chain structure, possibly in the chain sequence or sulfation
pattern. In that way, we suppose that HS chain affinity to ECM proteins may
govern cancer invasion by altering syndecan ability to interact with
cancer-related receptors present in the tumor microenvironment, thereby
promoting the activation of various signaling cascades regulating tumor cell
behavior.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:30:59 GMT""}]","2021-08-18"
"2102.05492","Jerome Beugnon","Y.-Q. Zou, \'E. Le Cerf, B. Bakkali-Hassani, C. Maury, G. Chauveau,
  P.C.M. Castilho, R. Saint-Jalm, S. Nascimbene, J. Dalibard, J. Beugnon","Optical control of the density and spin spatial profiles of a planar
  Bose gas",,"J. Phys. B: At. Mol. Opt. Phys. 54 08LT01 (2021)","10.1088/1361-6455/abf298",,"cond-mat.quant-gas physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate the arbitrary control of the density profile of a
two-dimensional Bose gas by shaping the optical potential applied to the atoms.
We use a digital micromirror device (DMD) directly imaged onto the atomic cloud
through a high resolution imaging system. Our approach relies on averaging the
response of many pixels of the DMD over the diffraction spot of the imaging
system, which allows us to create an optical potential with arbitrary grey
levels and with micron-scale resolution. The obtained density distribution is
optimized with a feedback loop based on the measured absorption images of the
cloud. Using the same device, we also engineer arbitrary spin distributions
thanks to a two-photon Raman transfer between internal ground states.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:32:21 GMT""}]","2021-05-20"
"2102.05493","Arjan van der Schaft","Arjan van der Schaft","Liouville geometry of classical thermodynamics","27 pages",,"10.1016/j.geomphys.2021.104365",,"math-ph math.DG math.MP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the contact-geometric formulation of classical thermodynamics distinction
is made between the energy and entropy representation, which can be resolved by
taking homogeneous coordinates for the intensive variables. This results in a
geometric formulation on the cotangent bundle of the manifold of extensive
variables, where all geometric objects are homogeneous in the cotangent
variables. The resulting geometry is studied in-depth. Additional homogeneity
with respect to the extensive variables, corresponding to the classical
Gibbs-Duhem relation, is treated within the same geometric framework.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:32:53 GMT""}]","2021-09-22"
"2102.05494","Jinpeng Guo","Jinpeng Guo, Ilias Zenelis, Xiaozhe Wang and Boon-Teck Ooi","WAMS-Based Model-Free Wide-Area Damping Control by Voltage Source
  Converters",,,"10.1109/TPWRS.2020.3012917",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, a novel model-free wide-area damping control (WADC) method is
proposed, which can achieve full decoupling of modes and damp multiple critical
inter-area oscillations simultaneously using grid-connected voltage source
converters (VSCs). The proposed method is purely measurement based and requires
no knowledge of the network topology and the dynamic model parameters. Hence,
the designed controller using VSCs can update the control signals online as the
system operating condition varies. Numerical studies in the modified IEEE
68-bus system with grid-connected VSCs show that the proposed method can
estimate the system dynamic model accurately and can damp inter-area
oscillations effectively under different working conditions and network
topologies.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:32:59 GMT""}]","2021-02-11"
"2102.05495","Genly Le\'on","Genly Leon, Sebasti\'an Cu\'ellar, Esteban Gonz\'alez, Samuel Lepe,
  Claudio Michea and Alfredo D. Millano","Averaging Generalized Scalar Field Cosmologies II: Locally Rotationally
  Symmetric Bianchi I and flat Friedmann-Lema\^itre-Robertson-Walker models","Research Program Averaging Generalized Scalar Field Cosmologies, part
  II. 27 pages, 7 compound figures. Minor revision. References updated.
  Discussion improved",,"10.1140/epjc/s10052-021-09230-5",,"gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scalar field cosmologies with a generalized harmonic potential and a matter
fluid with a barotropic Equation of State (EoS) with barotropic index $\gamma$
for the Locally Rotationally Symmetric (LRS) Bianchi I and flat
Friedmann-Lema\^itre-Robertson-Walker (FLRW) metrics are investigated. Methods
from the theory of averaging of nonlinear dynamical systems are used to prove
that time-dependent systems and their corresponding time-averaged versions have
the same late-time dynamics. Therefore, the simplest time-averaged system
determines the future asymptotic behavior. Depending on the values of $\gamma$,
the late-time attractors of physical interests are flat quintessence dominated
FLRW universe and Einstein-de Sitter solution. With this approach, the
oscillations entering the system through the Klein-Gordon (KG) equation can be
controlled and smoothed out as the Hubble parameter $H$ - acting as
time-dependent perturbation parameter - tends monotonically to zero. Numerical
simulations are presented as evidence of such behavior.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:35:17 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 23:23:15 GMT""},{""version"":""v3"",""created"":""Wed, 31 Mar 2021 03:55:41 GMT""},{""version"":""v4"",""created"":""Tue, 27 Apr 2021 17:48:48 GMT""}]","2021-06-03"
"2102.05496","Tiago Saraiva","T. T. Saraiva and A. A. Shanenko and A. Vagov and A. S. Vasenko","Multiband mechanism of the pair fluctuation screening",,,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent chain-like structured materials have shown a robust superconducting
phase. These materials exhibit the presence of quasi-one-dimensional bands
(q1D) coupled to conventional higher-dimensional bands. On the mean-field level
such systems have a high critical temperature when the chemical potential is
close to the edge of a q1D band and the related Lifshitz transition is
approached. However, the impact of the pair fluctuations compromises the
mean-field results. Recently it has been demonstrated that these fluctuations
can be suppressed (screened) by a specific multiband mechanism based on the
pair-exchange coupling of the q1D condensate to a stable higher-dimensional
one. In the present work we demonstrate that strikingly enough, this mechanism
is not very sensitive to the basic parameters of the stable condensate such as
its strength and dimensionality. For example, even the presence of a passive
higher-dimensional band, which does not exhibit any superconducting
correlations when taken as a separate superconductor, results in suppression of
the pair fluctuations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:36:42 GMT""}]","2021-02-11"
"2102.05497","Thomas Beckers","Thomas Beckers","An Introduction to Gaussian Process Models",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Within the past two decades, Gaussian process regression has been
increasingly used for modeling dynamical systems due to some beneficial
properties such as the bias variance trade-off and the strong connection to
Bayesian mathematics. As data-driven method, a Gaussian process is a powerful
tool for nonlinear function regression without the need of much prior
knowledge. In contrast to most of the other techniques, Gaussian Process
modeling provides not only a mean prediction but also a measure for the model
fidelity. In this article, we give an introduction to Gaussian processes and
its usage in regression tasks of dynamical systems. Try Gaussian process
regression yourself: https://gpr.tbeckers.com
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:40:18 GMT""}]","2021-02-11"
"2102.05498","Enzo Tartaglione","Daniele Perlo, Enzo Tartaglione, Luca Bertero, Paola Cassoni, Marco
  Grangetto","Dysplasia grading of colorectal polyps through CNN analysis of WSI",,,"10.1007/978-981-16-3880-0_34",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Colorectal cancer is a leading cause of cancer death for both men and women.
For this reason, histopathological characterization of colorectal polyps is the
major instrument for the pathologist in order to infer the actual risk for
cancer and to guide further follow-up. Colorectal polyps diagnosis includes the
evaluation of the polyp type, and more importantly, the grade of dysplasia.
This latter evaluation represents a critical step for the clinical follow-up.
The proposed deep learning-based classification pipeline is based on
state-of-the-art convolutional neural network, trained using proper
countermeasures to tackle WSI high resolution and very imbalanced dataset. The
experimental results show that one can successfully classify adenomas dysplasia
grade with 70% accuracy, which is in line with the pathologists' concordance.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:40:27 GMT""}]","2022-12-29"
"2102.05499","Thales Silva","Thales Silva, Bedros Afeyan, Luis O. Silva","Weibel instability beyond bi-Maxwellian anisotropy",,"Phys. Rev. E 104, 035201 (2021)","10.1103/PhysRevE.104.035201",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The shape of the anisotropic velocity distribution function, beyond the realm
of strict Maxwellians can play a significant role in determining the evolution
of the Weibel instability dictating the dynamics of self-generated magnetic
fields. For non-Maxwellian distribution functions, we show that the direction
of the maximum growth rate wavevector changes with shape. We investigate
different laser-plasma interaction model distributions which show that their
Weibel generated magnetic fields may require closer scrutiny beyond the second
moment (temperature) anisotropy ratio characterization.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:41:54 GMT""},{""version"":""v2"",""created"":""Sat, 21 Aug 2021 13:01:19 GMT""},{""version"":""v3"",""created"":""Tue, 7 Sep 2021 15:26:05 GMT""}]","2021-09-08"
"2102.05500","Florian Angermeir","Florian Angermeir, Markus Voggenreiter, Fabiola Moy\'on, Daniel Mendez","Enterprise-Driven Open Source Software: A Case Study on Security
  Automation","To be published in: Proceedings of the 43rd International Conference
  on Software Engineering: Software Engineering in Practice (SEIP)",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Agile and DevOps are widely adopted by the industry. Hence, integrating
security activities with industrial practices, such as continuous integration
(CI) pipelines, is necessary to detect security flaws and adhere to regulators'
demands early. In this paper, we analyze automated security activities in CI
pipelines of enterprise-driven open source software (OSS). This shall allow us,
in the long-run, to better understand the extent to which security activities
are (or should be) part of automated pipelines. In particular, we mine publicly
available OSS repositories and survey a sample of project maintainers to better
understand the role that security activities and their related tools play in
their CI pipelines. To increase transparency and allow other researchers to
replicate our study (and to take different perspectives), we further disclose
our research artefacts. Our results indicate that security activities in
enterprise-driven OSS projects are scarce and protection coverage is rather
low. Only 6.83% of the analyzed 8,243 projects apply security automation in
their CI pipelines, even though maintainers consider security to be rather
important. This alerts industry to keep the focus on vulnerabilities of 3rd
Party software and it opens space for other improvements of practice which we
outline in this manuscript.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:42:03 GMT""}]","2021-02-11"
"2102.05501","Yanis Bahroun","Yanis Bahroun and Dmitri B. Chklovskii","A Neural Network with Local Learning Rules for Minor Subspace Analysis",,,,,"cs.NE cs.AI q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  The development of neuromorphic hardware and modeling of biological neural
networks requires algorithms with local learning rules. Artificial neural
networks using local learning rules to perform principal subspace analysis
(PSA) and clustering have recently been derived from principled objective
functions. However, no biologically plausible networks exist for minor subspace
analysis (MSA), a fundamental signal processing task. MSA extracts the
lowest-variance subspace of the input signal covariance matrix. Here, we
introduce a novel similarity matching objective for extracting the minor
subspace, Minor Subspace Similarity Matching (MSSM). Moreover, we derive an
adaptive MSSM algorithm that naturally maps onto a novel neural network with
local learning rules and gives numerical results showing that our method
converges at a competitive rate.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:44:27 GMT""}]","2021-02-11"
"2102.05502","Richard Combes","Raymond Zhang and Richard Combes","On the Suboptimality of Thompson Sampling in High Dimensions","Neurips 2021 - 34 pages",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider Thompson Sampling (TS) for combinatorial
semi-bandits. We demonstrate that, perhaps surprisingly, TS is sub-optimal for
this problem in the sense that its regret scales exponentially in the ambient
dimension, and its minimax regret scales almost linearly. This phenomenon
occurs under a wide variety of assumptions including both non-linear and linear
reward functions, with Bernoulli distributed rewards and uniform priors. We
also show that including a fixed amount of forced exploration to TS does not
alleviate the problem. We complement our theoretical results with numerical
results and show that in practice TS indeed can perform very poorly in some
high dimensional situations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:44:43 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 12:37:39 GMT""}]","2021-10-22"
"2102.05503","Yanis Bahroun","Yanis Bahroun and Anirvan M. Sengupta and Dmitri B. Chklovskii","A Similarity-preserving Neural Network Trained on Transformed Images
  Recapitulates Salient Features of the Fly Motion Detection Circuit","Body and supplementary materials of NeurIPS 2019 paper",,,,"cs.NE cs.AI q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Learning to detect content-independent transformations from data is one of
the central problems in biological and artificial intelligence. An example of
such problem is unsupervised learning of a visual motion detector from pairs of
consecutive video frames. Rao and Ruderman formulated this problem in terms of
learning infinitesimal transformation operators (Lie group generators) via
minimizing image reconstruction error. Unfortunately, it is difficult to map
their model onto a biologically plausible neural network (NN) with local
learning rules. Here we propose a biologically plausible model of motion
detection. We also adopt the transformation-operator approach but, instead of
reconstruction-error minimization, start with a similarity-preserving objective
function. An online algorithm that optimizes such an objective function
naturally maps onto an NN with biologically plausible learning rules. The
trained NN recapitulates major features of the well-studied motion detector in
the fly. In particular, it is consistent with the experimental observation that
local motion detectors combine information from at least three adjacent pixels,
something that contradicts the celebrated Hassenstein-Reichardt model.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:45:40 GMT""}]","2021-02-11"
"2102.05504","Joaquim Silva","Joaquim Silva, Eduardo R.B. Marques, Lu\'is M.B Lopes, Fernando Silva","Energy-Aware Adaptive Offloading of Soft Real-Time Jobs in Mobile Edge
  Clouds",,,,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a model for measuring the impact of offloading soft real-time jobs
over multi-tier cloud infrastructures. The jobs originate in mobile devices and
offloading strategies may choose to execute them locally, in neighbouring
devices, in cloudlets or in infrastructure cloud servers. Within this
specification, we put forward several such offloading strategies characterised
by their differential use of the cloud tiers with the goal of optimizing
execution time and/or energy consumption. We implement an instance of the model
using Jay, a software framework for adaptive computation offloading in hybrid
edge clouds. The framework is modular and allows the model and the offloading
strategies to be seamlessly implemented while providing the tools to make
informed runtime offloading decisions based on system feedback, namely through
a built-in system profiler that gathers runtime information such as workload,
energy consumption and available bandwidth for every participating device or
server. The results show that offloading strategies sensitive to runtime
conditions can effectively and dynamically adjust their offloading decisions to
produce significant gains in terms of their target optimization functions,
namely, execution time, energy consumption and fulfillment of job deadlines.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:47:25 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 10:05:40 GMT""}]","2021-06-03"
"2102.05505","Olof Troeng","Olof Troeng","Modeling same-order modes of multicell cavities",,,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  We derive the transfer function of a multicell cavity with parasitic
same-order modes (from power coupler to pickup probe). The derived model is
discussed and compared to measurement data.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:47:34 GMT""}]","2021-02-11"
"2102.05506","Beibei Li","Anindya Ghose, Xitong Guo, Beibei Li, Yuanyuan Dang","Empowering Patients Using Smart Mobile Health Platforms: Evidence From A
  Randomized Field Experiment","Forthcoming at MIS Quarterly (2021)",,,,"econ.GN cs.HC q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  With today's technological advancements, mobile phones and wearable devices
have become extensions of an increasingly diffused and smart digital
infrastructure. In this paper, we examine mobile health (mHealth) platforms and
their health and economic impacts on the outcomes of chronic disease patients.
We partnered with a major mHealth firm that provides one of the largest mHealth
apps in Asia specializing in diabetes care. We designed a randomized field
experiment based on detailed patient health activities (e.g., exercises, sleep,
food intake) and blood glucose values from 1,070 diabetes patients over several
months. We find the adoption of the mHealth app leads to an improvement in
health behavior, which leads to both short term metrics (reduction in patients'
blood glucose and glycated hemoglobin levels) and longer-term metrics (hospital
visits and medical expenses). Patients who adopted the mHealth app undertook
more exercise, consumed healthier food, walked more steps and slept for longer
times. They also were more likely to substitute offline visits with telehealth.
A comparison of mobile vs. PC version of the same app demonstrates that mobile
has a stronger effect than PC in helping patients make these behavioral
modifications with respect to diet, exercise and lifestyle, which leads to an
improvement in their healthcare outcomes. We also compared outcomes when the
platform facilitates personalized health reminders to patients vs. generic
reminders. Surprisingly, we find personalized mobile messages with
patient-specific guidance can have an inadvertent (smaller) effect on patient
app engagement and lifestyle changes, leading to a lower health improvement.
However, they are more like to encourage a substitution of offline visits by
telehealth. Overall, our findings indicate the massive potential of mHealth
technologies and platform design in achieving better healthcare outcomes.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:48:09 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 16:44:47 GMT""}]","2021-02-18"
"2102.05507","Simon Bing","Simon Bing, Vincent Fortuin, Gunnar R\""atsch","On Disentanglement in Gaussian Process Variational Autoencoders",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex multivariate time series arise in many fields, ranging from computer
vision to robotics or medicine. Often we are interested in the independent
underlying factors that give rise to the high-dimensional data we are
observing. While many models have been introduced to learn such disentangled
representations, only few attempt to explicitly exploit the structure of
sequential data. We investigate the disentanglement properties of Gaussian
process variational autoencoders, a class of models recently introduced that
have been successful in different tasks on time series data. Our model exploits
the temporal structure of the data by modeling each latent channel with a GP
prior and employing a structured variational distribution that can capture
dependencies in time. We demonstrate the competitiveness of our approach
against state-of-the-art unsupervised and weakly-supervised disentanglement
methods on a benchmark task. Moreover, we provide evidence that we can learn
meaningful disentangled representations on real-world medical time series data.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:49:27 GMT""}]","2021-02-11"
"2102.05508","Gianluigi Liva","Gianluigi Liva and Enrico Paolini and Marco Chiani","Optimum Detection of Defective Elements in Non-Adaptive Group Testing","To be presented at the special session on Data Science for COVID-19
  at CISS 2021",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the problem of deriving a posteriori probabilities of being
defective for the members of a population in the non-adaptive group testing
framework. Both noiseless and noisy testing models are addressed. The
technique, which relies of a trellis representation of the test constraints,
can be applied efficiently to moderate-size populations. The complexity of the
approach is discussed and numerical results on the false positive probability
vs. false negative probability trade-off are presented.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:52:08 GMT""}]","2021-02-11"
"2102.05509","Sebastian Cygert","Sebastian Cygert, Andrzej Czy\.zewski","Robustness in Compressed Neural Networks for Object Detection","2021 International Joint Conference on Neural Networks (IJCNN),
  https://ieeexplore.ieee.org/document/9533773",,"10.1109/IJCNN52387.2021.9533773",,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model compression techniques allow to significantly reduce the computational
cost associated with data processing by deep neural networks with only a minor
decrease in average accuracy. Simultaneously, reducing the model size may have
a large effect on noisy cases or objects belonging to less frequent classes. It
is a crucial problem from the perspective of the models' safety, especially for
object detection in the autonomous driving setting, which is considered in this
work. It was shown in the paper that the sensitivity of compressed models to
different distortion types is nuanced, and some of the corruptions are heavily
impacted by the compression methods (i.e., additive noise), while others (blur
effect) are only slightly affected. A common way to improve the robustness of
models is to use data augmentation, which was confirmed to positively affect
models' robustness, also for highly compressed models. It was further shown
that while data imbalance methods brought only a slight increase in accuracy
for the baseline model (without compression), the impact was more striking at
higher compression rates for the structured pruning. Finally, methods for
handling data imbalance brought a significant improvement of the pruned models'
worst-detected class accuracy.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:52:11 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 21:14:27 GMT""},{""version"":""v3"",""created"":""Mon, 27 Sep 2021 10:06:23 GMT""}]","2021-09-28"
"2102.05510","Ignacio Ruiz","I. Ruiz Simo and I.D. Kakorin and V.A. Naumov and K.S. Kuzmin and J.E.
  Amaro","Analysis of the kinematic boundaries of the quasi-elastic
  neutrino-nucleus cross section in the superscaling model with a relativistic
  effective mass","28 pages, 20 figures, two appendices. A full reorganization of the
  whole manuscript has been carried out with respect to the previous version.
  This version matches published version in Physical Review D. Title and
  abstract has been changed a bit with respect to the previous version as well",,,,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we obtain the analytical expressions for the boundaries of the
charged current quasi-elastic double differential cross section in terms of
dimensionless energy and momentum transfers, for the Relativistic Fermi Gas
(RFG) and the Super-Scaling approach with relativistic effective mass (SuSAM*)
models, within the scaling formalism. In addition, we show that this double
differential cross section in the scaling formalism has very good properties to
be implemented in the Monte Carlo (MC) neutrino event generators, particularly
because its peak is almost flat with the (anti)neutrino energy. This makes it
especially well-suited for the event generation by the acceptance-rejection
method usually used in the neutrino generators. Finally, we analyze the total
charged current quasi-elastic (CCQE) cross section $\sigma(E_{\nu})$ for both
models and attribute the enhancement observed in the SuSAM* total cross section
to the high-momentum components which are present, in a phenomenological way,
in its scaling function, while these are absent in the RFG model.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:54:17 GMT""},{""version"":""v2"",""created"":""Fri, 31 Dec 2021 17:44:33 GMT""}]","2022-01-03"
"2102.05511","Kubra Yeter Aydeniz","K\""ubra Yeter-Aydeniz, Bryan T. Gard, Jacek Jakowski, Swarnadeep
  Majumder, George S. Barron, George Siopsis, Travis Humble, and Raphael C.
  Pooser","Benchmarking Quantum Chemistry Computations with Variational, Imaginary
  Time Evolution, and Krylov Space Solver Algorithms",,,,,"quant-ph physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The rapid progress of noisy intermediate-scale quantum (NISQ) computing
underscores the need to test and evaluate new devices and applications. Quantum
chemistry is a key application area for these devices, and therefore serves as
an important benchmark for current and future quantum computer performance.
Previous benchmarks in this field have focused on variational methods for
computing ground and excited states of various molecules, including a
benchmarking suite focused on performance of computing ground states for
alkali-hydrides under an array of error mitigation methods. Here, we outline
state of the art methods to reach chemical accuracy in hybrid quantum-classical
electronic structure calculations of alkali hydride molecules on NISQ devices
from IBM. We demonstrate how to extend the reach of variational eigensolvers
with new symmetry preserving Ans\""atze. Next, we outline how to use quantum
imaginary time evolution and Lanczos as a complementary method to variational
techniques, highlighting the advantages of each approach. Finally, we
demonstrate a new error mitigation method which uses systematic error
cancellation via hidden inverse gate constructions, improving the performance
of typical variational algorithms. These results show that electronic structure
calculations have advanced rapidly, to routine chemical accuracy for simple
molecules, from their inception on quantum computers a few short years ago, and
they point to further rapid progress to larger molecules as the power of NISQ
devices grows.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:54:55 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 20:48:11 GMT""}]","2021-02-18"
"2102.05512","Maria Elena Gonzalez Herrero","Maria Elena Gonzalez Herrero and Christian Kuehn","A qualitative mathematical model of the immune response under the effect
  of stress","8 pages, 2 figures","Chaos 31, 061104 (2021)","10.1063/5.0055784",,"q-bio.QM math.DS nlin.PS","http://creativecommons.org/licenses/by/4.0/","  In the last decades, the interest to understand the connection between brain
and body has grown notably. For example, in psychoneuroimmunology many studies
associate stress, arising from many different sources and situations, to
changes in the immune system from the medical or immunological point of view as
well as from the biochemical one. In this paper we identify important
behaviours of this interplay between the immune system and stress from medical
studies and seek to represent them qualitatively in a paradigmatic, yet simple,
mathematical model. To that end we develop a differential equation model with
two equations for infection level and immune system, which integrates the
effects of stress as an additional parameter. We are able to reproduce a stable
healthy state for little stress, an oscillatory state between healthy and
infected states for high stress, and a ""burn-out"" or stable sick state for
extremely high stress. The mechanism between the different dynamics is
controlled by two saddle-node in cycle (SNIC) bifurcations. Furthermore, our
model is able to capture an induced infection upon dropping from moderate to
low stress, and it predicts increasing infection periods upon increasing before
eventually reaching a burn-out state.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:55:02 GMT""}]","2022-07-27"
"2102.05513","Th\'eophile Dolmaire","Th\'eophile Dolmaire","About Lanford's theorem in the half-space with specular reflection","46 pages, 8 figures",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present article proposes a rigorous derivation of the Boltzmann equation
in the half-space. We show an analog of the Lanford's theorem in this domain,
with specular reflection boundary condition, stating the convergence in the low
density limit of the first marginal of the density function of a system of N
hard spheres towards the solution of the Boltzmann equation associated to the
initial data corresponding to the initial state of the one-particle-density
function. The original contributions of this work consist in two main points:
the rigorous definition of the collision operator and of the functional space
in which the BBGKY hierarchy is solved in a strong sense; and the adaptation to
the case of the half-space of the control of the recollisions performed by
Gallagher, Saint-Raymond and Texier, which is a crucial step to obtain the
Lanford's theorem.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:58:11 GMT""}]","2021-02-11"
"2102.05514","Erika Palmerio","Erika Palmerio, Emilia K. J. Kilpua, Olivier Witasse, David Barnes,
  Beatriz S\'anchez-Cano, Andreas J. Weiss, Teresa Nieves-Chinchilla, Christian
  M\""ostl, Lan K. Jian, Marilena Mierla, Andrei N. Zhukov, Jingnan Guo, Luciano
  Rodriguez, Patrick J. Lowrance, Alexey Isavnin, Lucile Turc, Yoshifumi
  Futaana, Mats Holmstr\""om","CME Magnetic Structure and IMF Preconditioning Affecting SEP Transport","50 pages, 14 figures, 2 tables, accepted for publication in Space
  Weather",,"10.1029/2020SW002654",,"astro-ph.SR astro-ph.EP physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Coronal mass ejections (CMEs) and solar energetic particles (SEPs) are two
phenomena that can cause severe space weather effects throughout the
heliosphere. The evolution of CMEs, especially in terms of their magnetic
structure, and the configuration of the interplanetary magnetic field (IMF)
that influences the transport of SEPs are currently areas of active research.
These two aspects are not necessarily independent of each other, especially
during solar maximum when multiple eruptive events can occur close in time.
Accordingly, we present the analysis of a CME that erupted on 2012 May 11
(SOL2012-05-11) and an SEP event following an eruption that took place on 2012
May 17 (SOL2012-05-17). After observing the May 11 CME using remote-sensing
data from three viewpoints, we evaluate its propagation through interplanetary
space using several models. Then, we analyse in-situ measurements from five
predicted impact locations (Venus, Earth, the Spitzer Space Telescope, the Mars
Science Laboratory en route to Mars, and Mars) in order to search for CME
signatures. We find that all in-situ locations detect signatures of an SEP
event, which we trace back to the May 17 eruption. These findings suggest that
the May 11 CME provided a direct magnetic connectivity for the efficient
transport of SEPs. We discuss the space weather implications of CME evolution,
regarding in particular its magnetic structure, and CME-driven IMF
preconditioning that facilitates SEP transport. Finally, this work remarks the
importance of using data from multiple spacecraft, even those that do not
include space weather research as their primary objective.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:58:42 GMT""}]","2021-02-11"
"2102.05515","Sindre W. Haugland","Sindre W. Haugland","The changing notion of chimera states, a critical review","Review paper. 10 pages, 5 figures. Significantly expanded
  introduction since the first version, added a few references on solitary
  states and scroll-ring chimeras as well as a sentence in the concluding
  remarks","J. Phys. Complex. 2 032001 (2021)","10.1088/2632-072X/ac0810",,"nlin.AO nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chimera states, states of coexistence of synchronous and asynchronous motion,
have been a subject of extensive research since they were first given a name in
2004. Increased interest has lead to their discovery in ever new settings, both
theoretical and experimental. Less well-discussed is the fact that successive
results have also broadened the notion of what actually constitutes a chimera
state. In this article, we critically examine how the results for different
model types and coupling schemes, as well as varying implicit interpretations
of terms such as coexistence, synchrony and incoherence, have influenced the
common understanding of what constitutes a chimera. We cover both theoretical
and experimental systems, address various chimera-derived terms that have
emerged over the years and finally reflect on the question of chimera states in
real-world contexts.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:59:04 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 15:24:23 GMT""}]","2021-07-06"
"2102.05516","Roland Bacon","Roland Bacon, David Mary, Thibault Garel, Jeremy Blaizot, Michael
  Maseda, Joop Schaye, Lutz Wisotzki, Simon Conseil, Jarle Brinchmann, Floriane
  Leclercq, Valentina Abril-Melgarejo, Leindert Boogaard, Nicolas Bouch\'e,
  Thierry Contini, Anna Feltre, Bruno Guiderdoni, Christian Herenz, Wolfram
  Kollatschny, Haruka Kusakabe, Jorryt Matthee, L\'eo Michel-Dansac, Themiya
  Nanayakkara, Johan Richard, Martin Roth, Kasper B. Schmidt, Matthias
  Steinmetz, Laurence Tresse, Tanya Urrutia, Anne Verhamme, Peter M.
  Weilbacher, Johannes Zabl and Sebastiaan L. Zoutendijk","The MUSE Extremely Deep Field: the Cosmic Web in Emission at High
  Redshift","28 pages, 19 figures","A&A 647, A107 (2021)","10.1051/0004-6361/202039887",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of diffuse extended Ly-alpha emission from redshift
3.1 to 4.5, tracing cosmic web filaments on scales of 2.5-4 comoving Mpc. These
structures have been observed in overdensities of Ly-alpha emitters in the MUSE
Extremely Deep Field, a 140 hour deep MUSE observation located in the Hubble
Ultra Deep Field. Among the 22 overdense regions identified, 5 are likely to
harbor very extended Ly-alpha emission at high significance with an average
surface brightness of $\mathrm{5 \times 10^{-20} erg s^{-1} cm^{-2}
arcsec^{-2}}$. Remarkably, 70% of the total Ly-alpha luminosity from these
filaments comes from beyond the circumgalactic medium of any identified
Ly-alpha emitters. Fluorescent Ly-alpha emission powered by the cosmic UV
background can only account for less than 34% of this emission at z$\approx$3
and for not more than 10% at higher redshift. We find that the bulk of this
diffuse emission can be reproduced by the unresolved Ly-alpha emission of a
large population of ultra low luminosity Ly-alpha emitters ($\mathrm{<10^{40}
erg s^{-1}}$), provided that the faint end of the Ly-alpha luminosity function
is steep ($\alpha \lessapprox -1.8$), it extends down to luminosities lower
than $\mathrm{10^{38} - 10^{37} erg s^{-1}}$ and the clustering of these
Ly-alpha emitters is significant (filling factor $< 1/6$). If these Ly-alpha
emitters are powered by star formation, then this implies their luminosity
function needs to extend down to star formation rates $\mathrm{< 10^{-4}
M_\odot yr^{-1}}$. These observations provide the first detection of the cosmic
web in Ly-alpha emission in typical filamentary environments and the first
observational clue for the existence of a large population of ultra low
luminosity Ly-alpha emitters at high redshift.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:59:28 GMT""}]","2021-03-24"
"2102.05650","Konstantin Stankevich","Konstantin Kouzakov, Fedor Lazarev, Vadim Shakhov, Konstantin
  Stankevich and Alexander Studenikin","Astrophysical neutrino oscillations accounting for neutrino charge radii","3 pages in LaTex, based on the presentation at the 40th International
  Conference on High Energy Physics (ICHEP 2020), 28 July - 6 August 2020,
  Prague, Czech Republic","Proceedings of Science ICHEP2020 217","10.22323/1.390.0217",,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We derive for the first time an effective neutrino evolution Hamiltonian
accounting for neutrino interactions with external magnetic field due to
neutrino charge radii and anapole moment. The results are interesting for
possible applications in astrophysics.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:07:08 GMT""}]","2021-02-12"
"2102.05651","Kayoomars Karami","Milad Solbi, Kayoomars Karami","Primordial black holes and induced gravitational waves in $k$-inflation","17 pages, 4 figures, 2 tables","JCAP 08 (2021) 056","10.1088/1475-7516/2021/08/056",,"astro-ph.CO gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Recent observational constraints indicate that primordial black holes (PBHs)
with the mass scale $\sim 10^{-12}M_{\odot}$ can explain most of dark matter in
the Universe. To produce this kind of PBHs, we need an enhance in the
primordial scalar curvature perturbations to the order of
${\mathcal{O}(10^{-2})}$ at the scale $ k \sim 10^{12}~\rm Mpc^{-1}$. Here, we
investigate the production of PBHs and induced gravitational waves (GWs) in the
framework of \textbf{$k$-inflation}. We solve numerically the Mukhanov-Sasaki
equation to obtain the primordial scalar power spectrum. In addition, we
estimate the PBHs abundance $f_{\text{PBH}}^{\text{peak}}$ as well as the
energy density parameter $\Omega_{\rm GW,0}$ of induced GWs. Interestingly
enough is that for a special set of model parameters, we estimate the mass
scale and the abundance of PBHs as $\sim{\cal O}(10^{-13})M_{\odot}$ and
$f_{\text{PBH}}^{\text{peak}}=0.96$, respectively. This confirms that the
mechanism of PBHs production in our inflationary model can justify most of dark
matter. Furthermore, we evaluate the GWs energy density parameter and conclude
that it behaves like a power-law function $\Omega_{\rm GW}\sim (f/f_c)^n$ where
in the infrared limit $f\ll f_{c}$, the power index reads $n=3-2/\ln(f_c/f)$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:27:25 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 15:52:52 GMT""},{""version"":""v3"",""created"":""Sun, 29 Aug 2021 14:41:36 GMT""}]","2021-08-31"
"2102.05652","SeHo Kim","Ruksan Nadarajah, Shabbir Tahir, Joachim Landers, David Koch, Anna S.
  Semisalova, Jonas Wiemeler, Ayman El-Zoka, Se-Ho Kim, Detlef Utzat, Rolf
  Moller, Baptiste Gault, Heiko Wende, Michael Farle, Bilal Gokce","Controlling the oxidation of magnetic and electrically conductive
  solid-solution iron-rhodium nanoparticles synthesized by Laser Ablation in
  Liquids",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study focuses on the synthesis of FeRh nanoparticles via pulsed laser
ablation in liquid and on controlling the oxidation of the synthesized
nanoparticles. Formation of monomodal {\gamma}-FeRh nanoparticles was confirmed
by transmission electron microscopy (TEM) and their composition confirmed by
atom probe tomography (APT). On these particles, three major contributors to
oxidation were analysed: 1) dissolved oxygen in the organic solvents, 2) the
bound oxygen in the solvent and 3) oxygen in the atmosphere above the solvent.
The decrease of oxidation for optimized ablation conditions was confirmed
through energy-dispersive X-ray (EDX) and M\""ossbauer spectroscopy.
Furthermore, the time dependence of oxidation was monitored for dried FeRh
nanoparticles powders using ferromagnetic resonance spectroscopy (FMR). By
magnetophoretic separation, B2-FeRh nanoparticles could be extracted from the
solution and characteristic differences of nanostrand formation between
{\gamma}-FeRh and B2-FeRh nanoparticles were observed.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:43:46 GMT""}]","2021-02-12"
"2102.06015","Sylvain Chevallier","Marie-Constance Corsi, Florian Yger, Sylvain Chevallier and Camille
  No\^us","RIGOLETTO -- RIemannian GeOmetry LEarning: applicaTion To cOnnectivity.
  A contribution to the Clinical BCI Challenge -- WCCI2020","7 pages, 7 figures, submitted to ICASSP conference",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This short technical report describes the approach submitted to the Clinical
BCI Challenge-WCCI2020. This submission aims to classify motor imagery task
from EEG signals and relies on Riemannian Geometry, with a twist. Instead of
using the classical covariance matrices, we also rely on measures of functional
connectivity. Our approach ranked 1st on the task 1 of the competition.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 23:25:25 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 09:55:44 GMT""}]","2021-03-12"
"2102.06016","Elizabeth Bismut","Elizabeth Bismut and Daniel Straub","Optimal adaptive inspection and maintenance planning for deteriorating
  structural systems",,"Reliab.Eng.Syst.Saf. 215 (2021) 107891","10.1016/j.ress.2021.107891",,"eess.SY cs.SY math.OC stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimizing inspection and maintenance (I&M) plans for a large deteriorating
structure is a computationally challenging task, in particular if one considers
interdependences among its components. This is due to the sheer number of
possible decision alternatives over the lifetime of the structure and the
uncertainty surrounding the deterioration processes, the structural performance
and the outcomes of inspection and maintenance actions. To address this
challenge, Luque and Straub (2019) proposed a heuristic approach in which I&M
plans for structural systems are defined through a set of simple decision
rules. Here, we formalize the optimization of these decision rules and extend
the approach to enable adaptive planning. The initially optimal I&M plan is
successively adapted throughout the service life, based on past inspection and
monitoring results. The proposed methodology uses stochastic deterioration
models and accounts for the interdependence among structural components. The
heuristic-based adaptive planning is illustrated for a structural frame
subjected to fatigue.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:59:25 GMT""}]","2021-07-14"
"2102.06019","Anav Mehta","Anav Mehta","Reinforcement Learning For Constraint Satisfaction Game Agents
  (15-Puzzle, Minesweeper, 2048, and Sudoku)",,"Canadian Science Fair Journal Volume 4 Issue 1
  https://csfjournal.com/volume-4-issue-1-1/2021/9/24/reinforcement-learning-for-constraint-satisfaction-game-agents-15-puzzle-minesweeper-2048-and-sudoku",,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In recent years, reinforcement learning has seen interest because of deep
Q-Learning, where the model is a convolutional neural network. Deep Q-Learning
has shown promising results in games such as Atari and AlphaGo. Instead of
learning the entire Q-table, it learns an estimate of the Q function that
determines a state's policy action. We use Q-Learning and deep Q-learning, to
learn control policies of four constraint satisfaction games (15-Puzzle,
Minesweeper, 2048, and Sudoku). 15-Puzzle is a sliding permutation puzzle and
provides a challenge in addressing its large state space. Minesweeper and
Sudoku involve partially observable states and guessing. 2048 is also a sliding
puzzle but allows for easier state representation (compared to 15-Puzzle) and
uses interesting reward shaping to solve the game. These games offer unique
insights into the potential and limits of reinforcement learning. The Q agent
is trained with no rules of the game, with only the reward corresponding to
each state's action. Our unique contribution is in choosing the reward
structure, state representation, and formulation of the deep neural network.
For low shuffle, 15-Puzzle, achieves a 100% win rate, the medium and high
shuffle achieve about 43% and 22% win rates respectively. On a standard 16x16
Minesweeper board, both low and high-density boards achieve close to 45% win
rate, whereas medium density boards have a low win rate of 15%. For 2048, the
1024 win rate was achieved with significant ease (100%) with high win rates for
2048, 4096, 8192 and 16384 as 40%, 0.05%, 0.01% and 0.004% , respectively. The
easy Sudoku games had a win rate of 7%, while medium and hard games had 2.1%
and 1.2% win rates, respectively. This paper explores the environment
complexity and behavior of a subset of constraint games using reward structures
which can get us closer to understanding how humans learn.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:29:29 GMT""}]","2021-10-08"
"2102.06020","Chuan Guo","Ruihan Wu, Chuan Guo, Felix Wu, Rahul Kidambi, Laurens van der Maaten,
  Kilian Q. Weinberger","Making Paper Reviewing Robust to Bid Manipulation Attacks",,,,,"cs.CR cs.GT cs.LG","http://creativecommons.org/licenses/by/4.0/","  Most computer science conferences rely on paper bidding to assign reviewers
to papers. Although paper bidding enables high-quality assignments in days of
unprecedented submission numbers, it also opens the door for dishonest
reviewers to adversarially influence paper reviewing assignments. Anecdotal
evidence suggests that some reviewers bid on papers by ""friends"" or colluding
authors, even though these papers are outside their area of expertise, and
recommend them for acceptance without considering the merit of the work. In
this paper, we study the efficacy of such bid manipulation attacks and find
that, indeed, they can jeopardize the integrity of the review process. We
develop a novel approach for paper bidding and assignment that is much more
robust against such attacks. We show empirically that our approach provides
robustness even when dishonest reviewers collude, have full knowledge of the
assignment system's internal workings, and have access to the system's inputs.
In addition to being more robust, the quality of our paper review assignments
is comparable to that of current, non-robust assignment approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 21:24:16 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 17:07:04 GMT""}]","2021-03-23"
"2102.06028","Shoma Matsui","Shoma Matsui and St\'ephane Lafortune","Synthesis of Winning Attacks on Communication Protocols using
  Supervisory Control Theory: Two Case Studies","31 pages, 16 figures",,"10.1007/s10626-022-00369-1",,"cs.CR cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is an increasing need to study the vulnerability of communication
protocols in distributed systems to malicious attacks that attempt to violate
properties such as safety or nonblockingness. In this paper, we propose a
common methodology for formal synthesis of successful attacks against two
well-known protocols, the Alternating Bit Protocol (ABP) and the Transmission
Control Protocol (TCP), where the attacker can always eventually win, called
For-all attacks. This generalizes previous work on the synthesis of
There-exists attacks for TCP, where the attacker can sometimes win. We model
the ABP and TCP protocols and system architecture by finite-state automata and
employ the supervisory control theory of discrete event systems to pose and
solve the synthesis of For-all attacks, where the attacker has partial
observability and controllability of the system events. We consider several
scenarios of person-in-themiddle attacks against ABP and TCP and present the
results of attack synthesis using our methodology for each case.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:47:13 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 23:34:54 GMT""},{""version"":""v3"",""created"":""Tue, 11 Oct 2022 13:41:53 GMT""}]","2022-10-24"
"2102.06029","Kailong Liu","Kailong Liu, Xiaosong Hu, Huiyu Zhou, Lei Tong, W. Dhammika Widanage,
  James Marco","Feature Analyses and Modelling of Lithium-ion Batteries Manufacturing
  based on Random Forest Classification",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Lithium-ion battery manufacturing is a highly complicated process with
strongly coupled feature interdependencies, a feasible solution that can
analyse feature variables within manufacturing chain and achieve reliable
classification is thus urgently needed. This article proposes a random forest
(RF)-based classification framework, through using the out of bag (OOB)
predictions, Gini changes as well as predictive measure of association (PMOA),
for effectively quantifying the importance and correlations of battery
manufacturing features and their effects on the classification of electrode
properties. Battery manufacturing data containing three intermediate product
features from the mixing stage and one product parameter from the coating stage
are analysed by the designed RF framework to investigate their effects on both
the battery electrode active material mass load and porosity. Illustrative
results demonstrate that the proposed RF framework not only achieves the
reliable classification of electrode properties but also leads to the effective
quantification of both manufacturing feature importance and correlations. This
is the first time to design a systematic RF framework for simultaneously
quantifying battery production feature importance and correlations by three
various quantitative indicators including the unbiased feature importance (FI),
gain improvement FI and PMOA, paving a promising solution to reduce model
dimension and conduct efficient sensitivity analysis of battery manufacturing.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:56:52 GMT""}]","2021-02-12"
"2102.06041","Ayan Banerjee","Sudan Hansraj, Megandhren Govender, Ayan Banerjee and Njabulo Mkhize","All Conformally Flat Einstein--Gauss--Bonnet static Metrics","23 pages, 9 figures, accepted for publication in Class.Quant.Grav",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the standard Schwarzschild interior metric is conformally
flat and generates a constant density sphere in any spacetime dimension in
Einstein and Einstein--Gauss--Bonnet gravity. This motivates the questions: In
EGB does the conformal flatness criterion yield the Schwarzschild metric? Does
the assumption of constant density generate the Schwarzschild interior
spacetime? The answer to both questions turn out in the negative in general. In
the case of the constant density sphere, a generalised Schwarzschild metric
emerges. When we invoke the conformal flatness condition the Schwarschild
interior solution is obtained as one solution and another metric which does not
yield a constant density hypersphere in EGB theory is found. For the latter
solution one of the gravitational metrics is obtained explicitly while the
other is determined up to quadratures in 5 and 6 dimensions. The physical
properties of these new solutions are studied with the use of numerical methods
and a parameter space is located for which both models display pleasing
physical behaviour.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 09:18:40 GMT""}]","2021-02-12"
"2102.06042","Yiqin Yang","Xiaoteng Ma, Yiqin Yang, Chenghao Li, Yiwen Lu, Qianchuan Zhao, Yang
  Jun","Modeling the Interaction between Agents in Cooperative Multi-Agent
  Reinforcement Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Value-based methods of multi-agent reinforcement learning (MARL), especially
the value decomposition methods, have been demonstrated on a range of
challenging cooperative tasks. However, current methods pay little attention to
the interaction between agents, which is essential to teamwork in games or real
life. This limits the efficiency of value-based MARL algorithms in the two
aspects: collaborative exploration and value function estimation. In this
paper, we propose a novel cooperative MARL algorithm named as interactive
actor-critic~(IAC), which models the interaction of agents from the
perspectives of policy and value function. On the policy side, a multi-agent
joint stochastic policy is introduced by adopting a collaborative exploration
module, which is trained by maximizing the entropy-regularized expected return.
On the value side, we use the shared attention mechanism to estimate the value
function of each agent, which takes the impact of the teammates into
consideration. At the implementation level, we extend the value decomposition
methods to continuous control tasks and evaluate IAC on benchmark tasks
including classic control and multi-agent particle environments. Experimental
results indicate that our method outperforms the state-of-the-art approaches
and achieves better performance in terms of cooperation.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:58:28 GMT""}]","2021-02-12"
"2102.06043","Minh Ho\`ang H\`a","Minh Ho\`ang H\`a, Dinh Quy Ta, Trung Thanh Nguyen","Exact Algorithms for Scheduling Problems on Parallel Identical Machines
  with Conflict Jobs",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Machine scheduling problems involving conflict jobs can be seen as a
constrained version of the classical scheduling problem, in which some jobs are
conflict in the sense that they cannot be proceeded simultaneously on different
machines. This conflict constraint naturally arises in several practical
applications and has recently received considerable attentions in the research
community. In fact, the problem is typically NP-hard (even for approximation)
and most of algorithmic results achieved so far have heavily relied on special
structures of the underlying graph used to model the conflict-job relation. Our
focus is on three objective functions: minimizing the makespan, minimizing the
weighted summation of the jobs' completion time, and maximizing the total
weights of completed jobs; the first two of which have been intensively studied
in the literature. For each objective function considered, we present several
mixed integer linear programming models and a constraint programming model,
from which we can solve the problems to optimality using dedicated solvers.
Binary search-based algorithms are also proposed to solve the makespan problem.
The results of numerical experiments performed on randomly generated data sets
with up to 32 jobs and 6 machines are reported and analysed to verify the
performance of the proposed methods.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:50:42 GMT""}]","2021-02-12"
"2102.06045","Rajendra Joshi Mr.","Rajendra P. Joshi and Neeraj Kumar","Artificial Intelligence based Autonomous Molecular Design for Medical
  Therapeutic: A Perspective",,,,,"cs.LG cs.AI q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:43:46 GMT""}]","2021-02-12"
"2102.06046","Theo Schaad","Theo P. Schaad and Peter Stampfli","A Quasiperiodic Tiling With 12-Fold Rotational Symmetry and Inflation
  Factor 1 + Sqrt(3)","16 pages, 10 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how we found substitution rules for a quasiperiodic tiling with local
rotational symmetry and inflation factor 1 + sqrt(3). The base tiles are a
square, a rhomb with an acute angle of 30 degrees, and equilateral triangles
that are cut in half. These half-triangles follow three different substitution
rules and can be recombined into equilateral triangles in nine different ways
to make minor variations of the tiling. The tiling contains quasiperiodically
repeated 12-fold rosettes. A central rosette can be enlarged to make an
arbitrarily large tiling with 12-fold rotational symmetry. An online computer
program is provided that allows the user to explore the tiling.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:29:17 GMT""}]","2021-02-12"
"2102.06126","Evangelos Papoutsellis","Evangelos Papoutsellis, Evelina Ametova, Claire Delplancke, Gemma
  Fardell, Jakob S. J{\o}rgensen, Edoardo Pasca, Martin Turner, Ryan Warr,
  William R. B. Lionheart, Philip J. Withers","Core Imaging Library -- Part II: Multichannel reconstruction for dynamic
  and spectral tomography",,,"10.1098/rsta.2020.0193",,"physics.med-ph cs.MS math.OC","http://creativecommons.org/licenses/by/4.0/","  The newly developed Core Imaging Library (CIL) is a flexible plug and play
library for tomographic imaging with a specific focus on iterative
reconstruction. CIL provides building blocks for tailored regularised
reconstruction algorithms and explicitly supports multichannel tomographic
data. In the first part of this two-part publication, we introduced the
fundamentals of CIL. This paper focuses on applications of CIL for multichannel
data, e.g., dynamic and spectral. We formalise different optimisation problems
for colour processing, dynamic and hyperspectral tomography and demonstrate
CIL's capabilities for designing state of the art reconstruction methods
through case studies and code snapshots.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:21:34 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 16:30:38 GMT""}]","2021-08-04"
"2102.06127","Ronald Brown","Ron Brown","The natural density of some sets of square-free numbers","8 pages, 0 figures. Two submission were rejected this morning because
  of excessive overlap. I think there was good reason to do both, but it now
  seems unnecessary so I am only resubmitting the longer one",,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $P$ and $T$ be disjoint sets of prime numbers with $T$ finite. A simple
formula is given for the natural density of the set of square-free numbers
which are divisible by all of the primes in $T$ and by none of the primes in
$P$. If $P$ is the set of primes congruent to $r$ modulo $m$ (where $m$ and $r$
are relatively prime numbers), then this natural density is shown to be $0$.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 20:02:22 GMT""}]","2021-02-12"
"2102.06128","Rafael Teixeira De Lima","Rafael Teixeira de Lima","Sequence-based Machine Learning Models in Jet Physics","To appear in Artificial Intelligence for Particle Physics, World
  Scientific Publishing",,,,"physics.data-an cs.LG hep-ex","http://creativecommons.org/licenses/by/4.0/","  Sequence-based modeling broadly refers to algorithms that act on data that is
represented as an ordered set of input elements. In particular, Machine
Learning algorithms with sequences as inputs have seen successfull applications
to important problems, such as Natural Language Processing (NLP) and speech
signal modeling. The usage this class of models in collider physics leverages
their ability to act on data with variable sequence lengths, such as
constituents inside a jet. In this document, we explore the application of
Recurrent Neural Networks (RNNs) and other sequence-based neural network
architectures to classify jets, regress jet-related quantities and to build a
physics-inspired jet representation, in connection to jet clustering
algorithms. In addition, alternatives to sequential data representations are
briefly discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:04:33 GMT""}]","2021-02-12"
"2102.06526","Luca Pasquini","Luca Pasquini, Antonio Napolitano, Martina Lucignani, Emanuela
  Tagliente, Francesco Dellepiane, Maria Camilla Rossi-Espagnet, Matteo
  Ritrovato, Antonello Vidiri, Veronica Villani, Giulio Ranazzi, Antonella
  Stoppacciaro, Andrea Romano, Alberto Di Napoli, Alessandro Bozzao","Comparison of Machine Learning Classifiers to Predict Patient Survival
  and Genetics of GBM: Towards a Standardized Model for Clinical Implementation",,,,,"q-bio.QM cs.LG q-bio.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radiomic models have been shown to outperform clinical data for outcome
prediction in glioblastoma (GBM). However, clinical implementation is limited
by lack of parameters standardization. We aimed to compare nine machine
learning classifiers, with different optimization parameters, to predict
overall survival (OS), isocitrate dehydrogenase (IDH) mutation,
O-6-methylguanine-DNA-methyltransferase (MGMT) promoter methylation, epidermal
growth factor receptor (EGFR) VII amplification and Ki-67 expression in GBM
patients, based on radiomic features from conventional and advanced MR. 156
adult patients with pathologic diagnosis of GBM were included. Three tumoral
regions were analyzed: contrast-enhancing tumor, necrosis and non-enhancing
tumor, selected by manual segmentation. Radiomic features were extracted with a
custom version of Pyradiomics, and selected through Boruta algorithm. A Grid
Search algorithm was applied when computing 4 times K-fold cross validation
(K=10) to get the highest mean and lowest spread of accuracy. Once optimal
parameters were identified, model performances were assessed in terms of Area
Under The Curve-Receiver Operating Characteristics (AUC-ROC). Metaheuristic and
ensemble classifiers showed the best performance across tasks. xGB obtained
maximum accuracy for OS (74.5%), AB for IDH mutation (88%), MGMT methylation
(71,7%), Ki-67 expression (86,6%), and EGFR amplification (81,6%). Best
performing features shed light on possible correlations between MR and tumor
histology.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:10:37 GMT""}]","2021-02-15"
"2102.06528","Liu Wang","Liu Wang, Haoyu Wang, Yi Wang, Gareth Tyson, Fei Lyu","A Tale of Two Countries: A Longitudinal Cross-Country Study of Mobile
  Users' Reactions to the COVID-19 Pandemic Through the Lens of App Popularity",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ongoing COVID-19 pandemic has profoundly impacted people's life around
the world, including how they interact with mobile technologies. In this paper,
we seek to develop an understanding of how the dynamic trajectory of a pandemic
shapes mobile phone users' experiences. Through the lens of app popularity, we
approach this goal from a cross-country perspective. We compile a dataset
consisting of six-month daily snapshots of the most popular apps in the iOS App
Store in China and the US, where the pandemic has exhibited distinct
trajectories. Using this longitudinal dataset, our analysis provides detailed
patterns of app ranking during the pandemic at both category and individual app
levels. We reveal that app categories' rankings are correlated with the
pandemic, contingent upon country-specific development trajectories. Our work
offers rich insights into how the COVID-19, a typical global public health
crisis, has influence people's day-to-day interaction with the Internet and
mobile technologies.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:12:23 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 08:11:48 GMT""}]","2021-03-31"
"2102.06530","Jorge Berger","Jorge Berger and Jacob Rubinstein","A flexible anatomical set of mechanical models for the organ of Corti","A similar version was posted in bioRxiv","R. Soc. Open Sci. 8 (2021) 210016","10.1098/rsos.210016",,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  We built a flexible platform to study the mechanical operation of the organ
of Corti (OoC) in the transduction of basilar membrane (BM) vibrations to
oscillations of an inner hair cell bundle (IHB). The anatomical components that
we consider are the outer hair cells (OHCs), the outer hair cell bundles,
Deiters cells, Hensen cells, the IHB and various sections of the reticular
lamina. In each of the components we apply Newton's equations of motion. The
components are coupled to each other and are further coupled to the endolymph
fluid motion in the subtectorial gap. This allows us to obtain the forces
acting on the IHB, and thus study its motion as a function of the parameters of
the different components. Some of the components include a nonlinear mechanical
response. We found that slight bending of the apical ends of the OHCs can have
a significant impact on the passage of motion from the BM to the IHB, including
critical oscillator behaviour. In particular, our model implies that the
components of the OoC could cooperate to enhance frequency selectivity,
amplitude compression and signal to noise ratio in the passage from the BM to
the IHB. Since the model is modular, it is easy to modify the assumptions and
parameters for each component.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:26:54 GMT""}]","2021-09-21"
"2102.06686","Hamide Imal","H. Imal, R. Ogul","Theoretical Study of Isotope Production in The Peripheral Heavy-ion
  Collision 136Xe + Pb at 1 GeV/nucleon","12 pages, 2 figures and one table. arXiv admin note: text overlap
  with arXiv:0806.3455, arXiv:1912.09277, arXiv:nucl-th/0510081 by other
  authors",,"10.1016/j.nuclphysa.2021.122261",,"nucl-th nucl-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We have studied the fragment yields emitted from the fragmentation of excited
projectile nuclei in peripheral collisions of 136Xe+Pb at 1 GeV/nucleon, and
measured with the high-resolution magnetic spectrometer, the Fragment Separator
(FRS) of GSI. The mass, charge and isotope distributions of nuclear fragments
formed in the reactions were calculated within a statistical ensemble approach
and compared to the experimental data. The ensemble of excited projectilelike
source nuclei were created in the framework of a previous analysis of similar
reactions performed at 600 MeV/nucleon (ALADIN-experiments, GSI). In addition,
the ensemble of the low-excited compound nuclei is involved in the analysis.
The overall agreement between theory and experiment was very satisfactory in
reproducing the experimental data of isotope yields measured in the heavy-ion
collisions. It is confirmed that a broad range of elements can be reproduced
within a universal statistical disintegration of the excited projectile
residues.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 12:19:33 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 10:54:52 GMT""}]","2021-07-14"
"2102.07618","Michael V. Davidovich","Michael V. Davidovich","Casimir-Lifshitz forces and plasmons in a structure of two dielectric
  rods: Green's function method of electrodynamics","19 pages, 1 figure",,,,"physics.class-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new model for calculating the Casimir-Lifshitz force per unit length for
two dielectric rods is proposed, based on the Green function method of
classical electrodynamics and the Lorentz model for permittivity.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:23:51 GMT""}]","2021-02-16"
"2102.07631","Ilya Safro","Ilya Tyagin and Ankit Kulshrestha and Justin Sybrandt and Krish Matta
  and Michael Shtutman and Ilya Safro","Accelerating COVID-19 research with graph mining and transformer-based
  learning",,,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  In 2020, the White House released the, ""Call to Action to the Tech Community
on New Machine Readable COVID-19 Dataset,"" wherein artificial intelligence
experts are asked to collect data and develop text mining techniques that can
help the science community answer high-priority scientific questions related to
COVID-19. The Allen Institute for AI and collaborators announced the
availability of a rapidly growing open dataset of publications, the COVID-19
Open Research Dataset (CORD-19). As the pace of research accelerates,
biomedical scientists struggle to stay current. To expedite their
investigations, scientists leverage hypothesis generation systems, which can
automatically inspect published papers to discover novel implicit connections.
We present an automated general purpose hypothesis generation systems AGATHA-C
and AGATHA-GP for COVID-19 research. The systems are based on graph-mining and
the transformer model. The systems are massively validated using retrospective
information rediscovery and proactive analysis involving human-in-the-loop
expert analysis. Both systems achieve high-quality predictions across domains
(in some domains up to 0.97% ROC AUC) in fast computational time and are
released to the broad scientific community to accelerate biomedical research.
In addition, by performing the domain expert curated study, we show that the
systems are able to discover on-going research findings such as the
relationship between COVID-19 and oxytocin hormone.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:11:36 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 19:07:16 GMT""}]","2021-10-01"
"2102.07654","Yassine Himeur","Yassine Himeur, Abdullah Alsalemi, Ayman Al-Kababji, Faycal Bensaali,
  Abbes Amira, Christos Sardianos, George Dimitrakopoulos, Iraklis Varlamis","A survey of recommender systems for energy efficiency in buildings:
  Principles, challenges and prospects","35 pages, 11 figures, 1 table","Information Fusion 2021",,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems have significantly developed in recent years in parallel
with the witnessed advancements in both internet of things (IoT) and artificial
intelligence (AI) technologies. Accordingly, as a consequence of IoT and AI,
multiple forms of data are incorporated in these systems, e.g. social,
implicit, local and personal information, which can help in improving
recommender systems' performance and widen their applicability to traverse
different disciplines. On the other side, energy efficiency in the building
sector is becoming a hot research topic, in which recommender systems play a
major role by promoting energy saving behavior and reducing carbon emissions.
However, the deployment of the recommendation frameworks in buildings still
needs more investigations to identify the current challenges and issues, where
their solutions are the keys to enable the pervasiveness of research findings,
and therefore, ensure a large-scale adoption of this technology. Accordingly,
this paper presents, to the best of the authors' knowledge, the first timely
and comprehensive reference for energy-efficiency recommendation systems
through (i) surveying existing recommender systems for energy saving in
buildings; (ii) discussing their evolution; (iii) providing an original
taxonomy of these systems based on specified criteria, including the nature of
the recommender engine, its objective, computing platforms, evaluation metrics
and incentive measures; and (iv) conducting an in-depth, critical analysis to
identify their limitations and unsolved issues. The derived challenges and
areas of future implementation could effectively guide the energy research
community to improve the energy-efficiency in buildings and reduce the cost of
developed recommender systems-based solutions.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:38:13 GMT""}]","2021-02-16"
"2102.08148","Jintai Chen","Jintai Chen, Hongyun Yu, Ruiwei Feng, Danny Z. Chen, Jian Wu","Flow-Mixup: Classifying Multi-labeled Medical Images with Corrupted
  Labels",,"2020 IEEE International Conference on Bioinformatics and
  Biomedicine","10.1109/BIBM49941.2020.9313408",,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In clinical practice, medical image interpretation often involves
multi-labeled classification, since the affected parts of a patient tend to
present multiple symptoms or comorbidities. Recently, deep learning based
frameworks have attained expert-level performance on medical image
interpretation, which can be attributed partially to large amounts of accurate
annotations. However, manually annotating massive amounts of medical images is
impractical, while automatic annotation is fast but imprecise (possibly
introducing corrupted labels). In this work, we propose a new regularization
approach, called Flow-Mixup, for multi-labeled medical image classification
with corrupted labels. Flow-Mixup guides the models to capture robust features
for each abnormality, thus helping handle corrupted labels effectively and
making it possible to apply automatic annotation. Specifically, Flow-Mixup
decouples the extracted features by adding constraints to the hidden states of
the models. Also, Flow-Mixup is more stable and effective comparing to other
known regularization methods, as shown by theoretical and empirical analyses.
Experiments on two electrocardiogram datasets and a chest X-ray dataset
containing corrupted labels verify that Flow-Mixup is effective and insensitive
to corrupted labels.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 16:04:26 GMT""}]","2021-02-17"
"2102.08186","A. Christian Silva","A. Christian Silva and Fernando F. Ferreira","Surrogate Monte Carlo","2 columns, 6 pages, 6 figures",,,,"q-fin.CP q-fin.GN","http://creativecommons.org/licenses/by/4.0/","  This article proposes an artificial data generating algorithm that is simple
and easy to customize. The fundamental concept is to perform random permutation
of Monte Carlo generated random numbers which conform to the unconditional
probability distribution of the original real time series. Similar to
constraint surrogate methods, random permutations are only accepted if a given
objective function is minimized. The objective function is selected in order to
describe the most important features of the stochastic process. The algorithm
is demonstrated by producing simulated log-returns of the S\&P 500 stock index.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 11:02:49 GMT""}]","2021-02-17"
"2102.08187","Tetsuya Takaishi","T. Takaishi","Power-Law Return-Volatility Cross Correlations of Bitcoin","10 pages, 5 figures","EPL, 129 (2020) 28001","10.1209/0295-5075/129/28001",,"q-fin.ST","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the return-volatility asymmetry of Bitcoin. We find
that the cross correlations between return and volatility (squared return) are
mostly insignificant on a daily level. In the high-frequency region, we find
thata power-law appears in negative cross correlation between returns and
future volatilities, which suggests that the cross correlation is
\revision{long ranged}. We also calculate a cross correlation between returns
and the power of absolute returns, and we find that the strength of
\revision{the cross correlations} depends on the value of the power.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 08:44:46 GMT""}]","2021-02-17"
"2102.08188","Absos Ali Shaikh Absos","Absos Ali Shaikh, Chandan Kumar Mondal and Prosenjit Mandal","Existence of finite global norm of potential vector field in a Ricci
  soliton","8 pages",,,,"math.GM","http://creativecommons.org/licenses/by-sa/4.0/","  In this article, we investigate global norm of potential vector field in
Ricci soliton. In particular, we have deduced certain conditions so that the
potential vector field has finite global norm in expanding Ricci soliton. We
have also showed that if the potential vector field has finite global norm in
complete non-compact Ricci soliton having finite volume, then the scalar
curvature becomes constant.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:41:22 GMT""}]","2021-02-17"
"2102.08200","Weiqiang Wang","Xinhong Chen, Gail Letzter, Ming Lu, Weiqiang Wang","Serre-Lusztig relations for $\imath$quantum groups II","v2, 12 pages, new coauthor and references added, a section on a
  universality property expanded, accepted by LMP","Lett. Math. Phys. 112 (2022), Paper No. 5, 15 pp","10.1007/s11005-021-01497-9",,"math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $\imath$Serre relations and the corresponding Serre-Lusztig relations are
formulated and established for arbitrary $\imath$quantum groups arising from
quantum symmetric pairs of Kac-Moody type.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:04:48 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 01:56:56 GMT""}]","2022-02-17"
"2102.08303","SeHo Kim","Se-Ho Kim, Kyuseon Jang, Phil Woong Kang, Jae-Pyoung Ahn, Jae-Bok
  Seol, Chang-Min Kwak, Constantinos Hatzoglou, Francois Vurpillot, Pyuck-Pa
  Choi","Characterization of Pd and Pd@Au core-shell nanoparticles using atom
  probe tomography and field evaporation simulation",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on atom probe tomography analyses of Pd and Pd@Au nanoparticles
embedded in a Ni matrix and the effects of local evaporation field variations
on the atom probe data. In order to assess the integrity of the reconstructed
atom maps, we performed numerical simulations of the field evaporation
processes and compared the simulated datasets with experimentally acquired
data. The distortions seen in the atom maps for both Pd and Pd@Au nanoparticles
could be mostly ascribed to local variations in chemical composition and
elemental evaporation fields. The evaporation field values for Pd and Ni, taken
from the image hump model and assumed in the simulations, yielded a good
agreement between experimental and simulation results. In contrast, the
evaporation field for Au, as predicted from the image hump model, appeared to
be substantially overestimated and resulted in a large discrepancy between
experiments and simulations.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:33:57 GMT""}]","2021-02-17"
"2102.08462","Mridul Agarwal","Mridul Agarwal, Vaneet Aggarwal, Kamyar Azizzadenesheli","Multi-Agent Multi-Armed Bandits with Limited Communication",,,,,"cs.LG cs.AI cs.MA","http://creativecommons.org/licenses/by/4.0/","  We consider the problem where $N$ agents collaboratively interact with an
instance of a stochastic $K$ arm bandit problem for $K \gg N$. The agents aim
to simultaneously minimize the cumulative regret over all the agents for a
total of $T$ time steps, the number of communication rounds, and the number of
bits in each communication round. We present Limited Communication
Collaboration - Upper Confidence Bound (LCC-UCB), a doubling-epoch based
algorithm where each agent communicates only after the end of the epoch and
shares the index of the best arm it knows. With our algorithm, LCC-UCB, each
agent enjoys a regret of $\tilde{O}\left(\sqrt{({K/N}+ N)T}\right)$,
communicates for $O(\log T)$ steps and broadcasts $O(\log K)$ bits in each
communication step. We extend the work to sparse graphs with maximum degree
$K_G$, and diameter $D$ and propose LCC-UCB-GRAPH which enjoys a regret bound
of $\tilde{O}\left(D\sqrt{(K/N+ K_G)DT}\right)$. Finally, we empirically show
that the LCC-UCB and the LCC-UCB-GRAPH algorithm perform well and outperform
strategies that communicate through a central node
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 06:28:37 GMT""}]","2021-02-18"
"2102.09604","Timour Igamberdiev","Timour Igamberdiev and Ivan Habernal","Privacy-Preserving Graph Convolutional Networks for Text Classification","Accepted at LREC 2022",,,,"cs.SI cs.CL cs.CR cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Graph convolutional networks (GCNs) are a powerful architecture for
representation learning on documents that naturally occur as graphs, e.g.,
citation or social networks. However, sensitive personal information, such as
documents with people's profiles or relationships as edges, are prone to
privacy leaks, as the trained model might reveal the original input. Although
differential privacy (DP) offers a well-founded privacy-preserving framework,
GCNs pose theoretical and practical challenges due to their training specifics.
We address these challenges by adapting differentially-private gradient-based
training to GCNs and conduct experiments using two optimizers on five NLP
datasets in two languages. We propose a simple yet efficient method based on
random graph splits that not only improves the baseline privacy bounds by a
factor of 2.7 while retaining competitive F1 scores, but also provides strong
privacy guarantees of epsilon = 1.0. We show that, under certain modeling
choices, privacy-preserving GCNs perform up to 90% of their non-private
variants, while formally guaranteeing strong privacy measures.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:27:38 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 14:11:40 GMT""},{""version"":""v3"",""created"":""Mon, 2 May 2022 09:44:31 GMT""}]","2022-05-03"
"2102.11131","Tatyana Kaltman","I. V. Kudryavtsev (1), T. I. Kaltman (2) ((1) Ioffe Institute, Saint
  Petersburg, Russia, (2) Special Astrophysical Observatory of the Russian
  Academy of Sciences, Saint Petersburg, Russia)","On the influence of Langmuir wave spectra on the spectra of
  electromagnetic waves generated in solar plasma with double plasma frequency","15 pages, 5 figures, Accepted in MNRAS",,"10.1093/mnras/stab377",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the spectral dependences of transverse
electromagnetic waves generated in solar plasma at coalescence of Langmuir
waves. It is shown that different spectra of Langmuir waves lead to
characteristic types of transversal electromagnetic wave spectra, what makes it
possible to diagnose the features of the spectra of Langmuir waves generated in
solar plasma.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 15:10:50 GMT""}]","2021-02-23"
"2103.03174","Luca Magri","Alberto Racca and Luca Magri","Robust Optimization and Validation of Echo State Networks for learning
  chaotic dynamics","29 pages, 25 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An approach to the time-accurate prediction of chaotic solutions is by
learning temporal patterns from data. Echo State Networks (ESNs), which are a
class of Reservoir Computing, can accurately predict the chaotic dynamics well
beyond the predictability time. Existing studies, however, also showed that
small changes in the hyperparameters may markedly affect the network's
performance. The aim of this paper is to assess and improve the robustness of
Echo State Networks for the time-accurate prediction of chaotic solutions. The
goal is three-fold. First, we investigate the robustness of routinely used
validation strategies. Second, we propose the Recycle Validation, and the
chaotic versions of existing validation strategies, to specifically tackle the
forecasting of chaotic systems. Third, we compare Bayesian optimization with
the traditional Grid Search for optimal hyperparameter selection. Numerical
tests are performed on two prototypical nonlinear systems that have both
chaotic and quasiperiodic solutions. Both model-free and model-informed Echo
State Networks are analysed. By comparing the network's robustness in learning
chaotic versus quasiperiodic solutions, we highlight fundamental challenges in
learning chaotic solutions. The proposed validation strategies, which are based
on the dynamical systems properties of chaotic time series, are shown to
outperform the state-of-the-art validation strategies. Because the strategies
are principled-they are based on chaos theory such as the Lyapunov time-they
can be applied to other Recurrent Neural Networks architectures with little
modification. This work opens up new possibilities for the robust design and
application of Echo State Networks, and Recurrent Neural Networks, to the
time-accurate prediction of chaotic systems.
","[{""version"":""v1"",""created"":""Tue, 9 Feb 2021 22:24:00 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 10:26:37 GMT""}]","2021-03-16"
"2103.10934","Kabir Suara","Anusmriti Ghosh, K. A. Suara, Scott W. McCue, Richard J. Brown","Sensitivity and robustness of Lagrangian coherent structures in coastal
  water systems","33 Pages, 18 figure, Under review",,,,"physics.ao-ph physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In coastal water systems, horizontal chaotic dispersion plays a significant
role in the distribution and fate of pollutants. Lagrangian Coherent Structures
(LCSs) provide useful tools to approach the problem of the transport of
pollutants and have only recently been applied to coastal waters. While the
fundamentals of the LCS approach using idealised analytical flow fields are
well established in the literature, there are limited studies on their
practical implementations in coastal waters where effects of boundaries and
bathymetry frequently become significant. Due to their complex bathymetry and
boundaries, unstructured grid systems are commonly used in modelling of coastal
waters. For convenient derivation of LCS diagnostics, structured grids are
commonly used. Here we examine the effect of mesh resolution, interpolation
schemes and additive random noise on the LCS diagnostics in relation to coastal
waters. Two kinematic model flows, the double gyre and the meandering jet, as
well as validated outputs of a hydrodynamic model of Moreton Bay, Australia, on
unstructured grids are used. The results show that LCSs are quite robust to the
errors from interpolation schemes used in the data conversion from unstructured
to structured grid. Attributed to the divergence in the underlying flow field,
the results show that random errors in the order of 1-10 % cause a break down
in the continuity of ridges of maximum finite time Lyapunov exponents and
closed orbit elliptic LCSs. The result has significant implications on the
suitability of applying LCS formulations based on a deterministic flow field to
diffusive coastal waters.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 01:37:25 GMT""}]","2021-03-22"
"2103.12626","Sang Hoon Lee","Daekyung Lee, Sang Hoon Lee, Beom Jun Kim, Heetae Kim","Consistency landscape of network communities","12 pages, 11 figures","Phys. Rev. E 103, 052306 (2021)","10.1103/PhysRevE.103.052306",,"physics.soc-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The concept of community detection has long been used as a key device for
handling the mesoscale structures in networks. Suitably conducted community
detection reveals various embedded informative substructures of network
topology. However, regarding the practical usage of community detection, it has
always been a tricky problem to assign a reasonable community resolution for
networks of interest. Because of the absence of the unanimously accepted
criterion, most of the previous studies utilized rather ad hoc heuristics to
decide the community resolution. In this work, we harness the concept of
consistency in community structures of networks to provide the overall
community resolution landscape of networks, which we eventually take to
quantify the reliability of detected communities for a given resolution
parameter. More precisely, we exploit the ambiguity in the results of
stochastic detection algorithms and suggest a method that denotes the relative
validity of community structures in regard to their stability of global and
local inconsistency measures using multiple detection processes. Applying our
framework to synthetic and real networks, we confirm that it effectively
displays insightful fundamental aspects of community structures.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 00:48:55 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 01:37:45 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 03:19:51 GMT""}]","2021-05-28"
"2103.13298","Jianyu Zhao","Jianyu Zhao, Chenyang Yang","Deep Reinforcement Learning with Symmetric Prior for Predictive Power
  Allocation to Mobile Users",,,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep reinforcement learning has been applied for a variety of wireless tasks,
which is however known with high training and inference complexity. In this
paper, we resort to deep deterministic policy gradient (DDPG) algorithm to
optimize predictive power allocation among K mobile users requesting video
streaming, which minimizes the energy consumption of the network under the
no-stalling constraint of each user. To reduce the sampling complexity and
model size of the DDPG, we exploit a kind of symmetric prior inherent in the
actor and critic networks: permutation invariant and equivariant properties, to
design the neural networks. Our analysis shows that the free model parameters
of the DDPG can be compressed by 2/K^2. Simulation results demonstrate that the
episodes required by the learning model with the symmetric prior to achieve the
same performance as the vanilla policy reduces by about one third when K = 10.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 10:24:59 GMT""}]","2021-03-25"
"2103.13306","Jie Chen","Dibyajyoti Guha, Jie Chen, Abhijit Dutta Banik, Biplab Sikdar","Delay and Power consumption Analysis for Queue State Dependent Service
  Rate Control in WirelessHart System",,,,,"cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  To solve the problem of power supply limitation of machines working in
wireless industry automation, we evaluated the workload aware service rate
control design implanted in the medium access control component of these small
devices and proposed a bio-intelligence based algorithm to optimise the design
regarding the delay constraint while minimizing power consumption. To achieve
this, we provide an accurate analysis of the delay cost of this design and for
the first time pinpoint an exact departure process model in order to evaluate
the overall delay cost in consideration of the medium access time.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 13:49:34 GMT""}]","2021-03-25"
"2104.02591","Dachun Yang","Jun Cao, Yu Liu and Dachun Yang","Corrigendum to ""Hardy Spaces $H_{\mathcal L}^1({\mathbb R}^n)$
  Associated to Schr\""odinger Type Operators $(-\Delta)^2+V^2$"" [Houston J.
  Math 36 (4) (2010), 1067-1095]","3 pages",,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We rectify an incorrect citation of the reference in obtaining the Gaussian
upper bound for heat kernels of the Schr\""odinger type operators
$(-\Delta)^2+V^2$.
","[{""version"":""v1"",""created"":""Wed, 10 Feb 2021 02:12:38 GMT""}]","2021-04-07"

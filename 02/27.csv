"2102.13559","Carsten Henkel","Carsten Henkel","Heat transfer and entanglement -- non-equilibrium correlation spectra of
  two quantum oscillators","27 pages, 9 figures","Ann. Phys. (Berlin) 533 (2021) 2100089","10.1002/andp.202100089",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The non-equilibrium state of two oscillators with a mutual interaction and
coupled to separate heat baths is discussed. Bosonic baths are considered, and
an exact spectral representation for the elements of the covariance matrix is
provided analytically. A wide class of spectral densities for the relevant bath
modes is allowed for. The validity of the fluctuation-dissipation theorem is
established for global equilibrium (both baths at the same temperature) in the
stationary state. Spectral measures of entanglement are suggested by comparing
to the equilibrium spectrum of zero-point fluctuations. No rotating-wave
approximation is applied, and anomalous heat transport from cold to hot bath,
as reported in earlier work, is demonstrated not to occur.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:00:43 GMT""}]","2021-12-03"
"2102.13560","Josef Tiggesb\""aumker","D. Komar and L. Kazak and K.-H. Meiwes-Broerand and J. Tiggesb\""aumker","Development of ion recoil energy distributions in the Coulomb explosion
  of argon clusters resolved by charge-state selective ion energy spectroscopy","15 pages, 5 figures",,"10.1140/epjs/s11734-021-00108-x",,"physics.atom-ph physics.atm-clus","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The laser intensity dependence of the recoil energies from the Coulomb
explosion of small argon clusters has been investigated by resolving the
contributions of the individual charge states to the ion recoil energy spectra.
Between $10^{14}$ and $10^{15}$ W/cm$^2$ the high-energy tail of the ion energy
spectra changes its shape and develops into the well-known knee feature, which
results from the cluster size distribution, laser focal averaging, and
ionization saturation. Resolving the contributions of the different charge
states to the recoil energies, the experimental data reveal that the basic
assumption of an exploding homogeneously charged sphere cannot be maintained in
general. In fact, the energy spectra of the high-$q$ show distinct gaps in the
yields at low kinetic energies, which hints at more complex radial ion charge
distributions developing during the laser pulse impact.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:03:05 GMT""}]","2021-06-16"
"2102.13561","Pinaki Roy","Axel Schulze-Halberg and Pinaki Roy","Dirac systems with magnetic field and position dependent mass: Darboux
  transformations and equivalence with generalized Dirac oscillators",,,"10.1016/j.aop.2021.168534",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a Darboux transformation for a class of two-dimensional Dirac
systems at zero energy. Our starting equation features a position-dependent
mass, a matrix potential, and an additional degree of freedom that can be
interpreted either as a magnetic field perpendicular to the plane or a
generalized Dirac oscillator interaction. We obtain a number of
Darbouxtransformed Dirac equations for which the zero energy solutions are
exactly known.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:04:42 GMT""}]","2021-07-07"
"2102.13562","Ludovic Renou","Alp Atakan and Mehmet Ekmekci and Ludovic Renou","Cross-verification and Persuasive Cheap Talk",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a cheap-talk game where two experts first choose what information to
acquire and then offer advice to a decision-maker whose actions affect the
welfare of all. The experts cannot commit to reporting strategies. Yet, we show
that the decision-maker's ability to cross-verify the experts' advice acts as a
commitment device for the experts. We prove the existence of an equilibrium,
where an expert's equilibrium payoff is equal to what he would obtain if he
could commit to truthfully revealing his information.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:04:44 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 13:05:06 GMT""}]","2021-04-08"
"2102.13563","Niklas Falstad","N. Falstad, S. Aalto, S. K\""onig, K. Onishi, S. Muller, M. Gorski, M.
  Sato, F. Stanley, F. Combes, E. Gonz\'alez-Alfonso, J. G. Mangum, A. S.
  Evans, L. Barcos-Mu\~noz, G. C. Privon, S. T. Linden, T. D\'iaz-Santos, S.
  Mart\'in, K. Sakamoto, N. Harada, G. A. Fuller, J. S. Gallagher, P. P. van
  der Werf, S. Viti, T. R. Greve, S. Garc\'ia-Burillo, C. Henkel, M. Imanishi,
  T. Izumi, Y. Nishimura, C. Ricci, and S. M\""uhle","CON-quest: Searching for the most obscured galaxy nuclei","16 pages, 11 figures, Accepted for publication in Astronomy and
  Astrophysics","A&A 649, A105 (2021)","10.1051/0004-6361/202039291",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some luminous and ultraluminous infrared galaxies (LIRGs and ULIRGs) host
extremely compact and dusty nuclei. The intense infrared radiation arising from
warm dust in these sources is prone to excite vibrational levels of molecules
such as HCN. This results in emission from the rotational transitions of
vibrationally excited HCN (HCN-vib), with the brightest emission found in
compact obscured nuclei (CONs). We aim to establish how common CONs are in the
local Universe, and whether their prevalence depends on the luminosity or other
properties of the host galaxy. We have conducted an Atacama Large
Millimeter/submillimeter Array (ALMA) survey of the rotational J=3-2 transition
of HCN-vib in a sample of 46 far-infrared luminous galaxies. Compact obscured
nuclei are identified in 38 percent of ULIRGs, 21 percent of LIRGs, and 0
percent of lower luminosity galaxies. We find no dependence on the inclination
of the host galaxy, but strong evidence of lower IRAS 25 to 60 {\mu}m flux
density ratios (f25/f60) in CONs compared to the rest of the sample.
Furthermore, we find that CONs have stronger silicate features (s9.7{\mu}m) but
similar PAH equivalent widths (EQW6.2{\mu}m) compared to other galaxies. In the
local Universe, CONs are primarily found in (U)LIRGs. High resolution continuum
observations of the individual nuclei are required to determine if the CON
phenomenon is related to the inclinations of the nuclear disks. The lower
f25/f60 ratios in CONs as well as the results for the mid-infrared diagnostics
investigated are consistent with large dust columns shifting the nuclear
radiation to longer wavelengths, making the mid- and far-infrared
""photospheres"" significantly cooler than the interior regions. To assess the
importance of CONs in the context of galaxy evolution, it is necessary to
extend this study to higher redshifts where (U)LIRGs are more common.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:07:42 GMT""}]","2021-05-26"
"2102.13564","Martin Suda","Martin Suda","Improving ENIGMA-Style Clause Selection While Learning From History","16 page",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We re-examine the topic of machine-learned clause selection guidance in
saturation-based theorem provers. The central idea, recently popularized by the
ENIGMA system, is to learn a classifier for recognizing clauses that appeared
in previously discovered proofs. In subsequent runs, clauses classified
positively are prioritized for selection. We propose several improvements to
this approach and experimentally confirm their viability. For the
demonstration, we use a recursive neural network to classify clauses based on
their derivation history and the presence or absence of automatically supplied
theory axioms therein. The automatic theorem prover Vampire guided by the
network achieves a 41% improvement on a relevant subset of SMT-LIB in a real
time evaluation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:13:45 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 17:46:50 GMT""}]","2021-04-15"
"2102.13565","Johan Bjorck","Johan Bjorck, Xiangyu Chen, Christopher De Sa, Carla P. Gomes, Kilian
  Q. Weinberger","Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half
  Precision",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-precision training has become a popular approach to reduce compute
requirements, memory footprint, and energy consumption in supervised learning.
In contrast, this promising approach has not yet enjoyed similarly widespread
adoption within the reinforcement learning (RL) community, partly because RL
agents can be notoriously hard to train even in full precision. In this paper
we consider continuous control with the state-of-the-art SAC agent and
demonstrate that a na\""ive adaptation of low-precision methods from supervised
learning fails. We propose a set of six modifications, all straightforward to
implement, that leaves the underlying agent and its hyperparameters unchanged
but improves the numerical stability dramatically. The resulting modified SAC
agent has lower memory and compute requirements while matching full-precision
rewards, demonstrating that low-precision training can substantially accelerate
state-of-the-art RL without parameter tuning.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:16:28 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 19:42:54 GMT""}]","2021-06-07"
"2102.13566","Borjan Geshkovski","Carlos Esteve-Yag\""ue and Borjan Geshkovski","Sparsity in long-time control of neural ODEs",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the neural ODE and optimal control perspective of supervised
learning, with $\ell^1$-control penalties, where rather than only minimizing a
final cost (the \emph{empirical risk}) for the state, we integrate this cost
over the entire time horizon. We prove that any optimal control (for this cost)
vanishes beyond some positive stopping time. When seen in the discrete-time
context, this result entails an \emph{ordered} sparsity pattern for the
parameters of the associated residual neural network: ordered in the sense that
these parameters are all $0$ beyond a certain layer. Furthermore, we provide a
polynomial stability estimate for the empirical risk with respect to the time
horizon. This can be seen as a \emph{turnpike property}, for nonsmooth dynamics
and functionals with $\ell^1$-penalties, and without any smallness assumptions
on the data, both of which are new in the literature.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:23:02 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 10:32:57 GMT""},{""version"":""v3"",""created"":""Thu, 8 Sep 2022 16:02:48 GMT""}]","2022-09-09"
"2102.13567","Scott Moroch","Scott B. Moroch, Timothy W. Koeth, Bruce E. Carlsten","Space-charge effects in low-energy flat-beam transforms","16 pages, 16 figures",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Flat-beam transforms (FBTs) provide a technique for controlling the emittance
partitioning between the beam's two transverse dimensions. To date, nearly all
FBT studies have been in regimes where the beam's own space-charge effects can
be ignored, such as in applications with high-brightness electron linacs where
the transform occurs at high, relativistic, energies. Additionally, FBTs may
provide a revolutionary path to high power generation at high frequencies in
vacuum electron devices where the beam emittance is currently becoming a
limiting factor, which is the focus of this paper. Electron beams in vacuum
electron devices operate both at a much lower energy and a much higher current
than in accelerators and the beam's space charge forces can no longer be
ignored. Here we analyze the effects of space-charge in FBTs and show there are
both linear and nonlinear forces and effects. The linear effects can be
compensated by retuning the FBT and by adding additional quadrupole elements.
The nonlinear effects lead to an ultimate dilution of the lower recovered
emittance and will lead to an eventual power limitation for high-frequency
traveling-wave tubes and other vacuum electron devices.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:24:51 GMT""}]","2021-03-01"
"2102.13568","Bodan Arsovski","Bodan Arsovski","On the reductions of certain two-dimensional crystalline
  representations, III","Part III, previously was part of 1808.03224, should have some overlap
  with ""On the reductions of certain two-dimensional crystalline
  representations, II"". arXiv admin note: substantial text overlap with
  arXiv:1808.03224",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A conjecture of Breuil, Buzzard, and Emerton says that the slopes of certain
reducible $p$-adic Galois representations must be integers. In previous work we
showed this conjecture for representations that lie over certain non-subtle
components of weight space. This article is a continuation of that work in
which we also show the conjecture for the subtle components for slopes less
than $\frac{p-1}{2}$.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:26:03 GMT""}]","2021-03-01"
"2102.13569","Facundo Molina","Facundo Molina, Pablo Ponzio, Nazareno Aguirre and Marcelo Frias","EvoSpex: An Evolutionary Algorithm for Learning Postconditions",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software reliability is a primary concern in the construction of software,
and thus a fundamental component in the definition of software quality.
Analyzing software reliability requires a specification of the intended
behavior of the software under analysis, and at the source code level, such
specifications typically take the form of assertions. Unfortunately, software
many times lacks such specifications, or only provides them for
scenario-specific behaviors, as assertions accompanying tests. This issue
seriously diminishes the analyzability of software with respect to its
reliability.
  In this paper, we tackle this problem by proposing a technique that, given a
Java method, automatically produces a specification of the method's current
behavior, in the form of postcondition assertions. This mechanism is based on
generating executions of the method under analysis to obtain valid pre/post
state pairs, mutating these pairs to obtain (allegedly) invalid ones, and then
using a genetic algorithm to produce an assertion that is satisfied by the
valid pre/post pairs, while leaving out the invalid ones. The technique, which
targets in particular methods of reference-based class implementations, is
assessed on a benchmark of open source Java projects, showing that our genetic
algorithm is able to generate post-conditions that are stronger and more
accurate, than those generated by related automated approaches, as evaluated by
an automated oracle assessment tool. Moreover, our technique is also able to
infer an important part of manually written rich postconditions in verified
classes, and reproduce contracts for methods whose class implementations were
automatically synthesized from specifications.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:27:24 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 13:12:49 GMT""}]","2021-03-02"
"2102.13570","Alexander N. Manashov","Sergey \'E. Derkachov, Karol K. Kozlowski and Alexander N. Manashov","Completeness of SoV Representation for $\mathrm{SL}(2,\mathbb R)$ Spin
  Chains",,"SIGMA 17 (2021), 063, 26 pages","10.3842/SIGMA.2021.063","DESY-21-024","math-ph hep-th math.MP nlin.SI","http://creativecommons.org/licenses/by-sa/4.0/","  This work develops a new method, based on the use of Gustafson's integrals
and on the evaluation of singular integrals, allowing one to establish the
unitarity of the separation of variables transform for infinite-dimensional
representations of rank one quantum integrable models. We examine in detail the
case of the $\mathrm{SL}(2,\mathbb R)$ spin chains.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:28:25 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 06:35:08 GMT""}]","2021-06-28"
"2102.13571","Amlan Kusum Roy","Sangita Majumdar and Amlan K. Roy","Shannon entropy in confined He-like ions within a density functional
  formalism",,"Quantum Reports 2 (1), 189-207 (2020)",,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Shannon entropy in position ($S_{\rvec}$) and momentum ($S_{\pvec}$) spaces,
along with their sum ($S_t$) are presented for unit-normalized densities of He,
Li$^+$ and Be$^{2+}$ ions, spatially confined at the center of an impenetrable
spherical enclosure defined by a radius $r_c$. Both ground as well as some
selected low-lying singly excited states, \emph{viz.,} 1sns (n $=$ 2-4) $^3$S,
1snp (n $=$ 2-3) $^3$P, 1s3d $^3$D are considered within a density functional
methodology that makes use of a work-function-based exchange potential along
with two correlation potentials (local Wigner-type parametrized functional as
well as the more involved non-linear gradient- and Laplacian-dependent
Lee-Yang-Parr functional). The radial Kohn-Sham (KS) equation is solved using
an optimal spatial discretization scheme via the generalized pseudospectral
(GPS) method. A detailed systematic analysis of the confined system (relative
to corresponding free system) has been performed for these quantities with
respect to $r_c$ in tabular and graphical forms, \emph{with and without}
electron correlation. Due to compression, the pattern of entropy in
aforementioned states gets characterized by various crossovers at intermediate
and lower $r_c$ regions. The impact of electron correlation is more pronounced
in weaker confinement limit, and appears to decay with rise in confinement
strength. The exchange-only results are quite good to provide a decent
qualitative discussion. The lower-bounds provided by entropic uncertainty
relation holds good in all cases. Several other new interesting features are
observed.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:29:07 GMT""}]","2021-03-01"
"2102.13572","Hung Tran","Noel Brady and Hung Cong Tran","Superexponential Dehn functions inside CAT(0) groups","38 pages, 7 figures, 1 table. Version 2 incorporates the referee's
  comments. To appear in Israel Journal of Mathematics",,,,"math.GR math.GT","http://creativecommons.org/licenses/by/4.0/","  We construct 4-dimensional CAT(0) groups containing finitely presented
subgroups whose Dehn functions are $\exp^{(n)}(x^m)$ for integers $n, m \geq 1$
and 6-dimensional CAT(0) groups containing finitely presented subgroups whose
Dehn functions are $\exp^{(n)}(x^\alpha)$ for integers $n \geq 1$ and $\alpha$
dense in $[1,\infty)$. This significantly expands the known geometric behavior
of subgroups of CAT(0) groups.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:31:05 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 12:11:28 GMT""}]","2022-07-07"
"2102.13573","George Pappas Dr","Kostas Glampedakis and George Pappas","Can supermassive black hole shadows test the Kerr metric?","5 pages, 1 figure, accepted for publication as a Letter in Physical
  Review D","Phys. Rev. D 104, L081503 (2021)","10.1103/PhysRevD.104.L081503",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unprecedented image of the M87* supermassive black hole has sparked some
controversy over its usefulness as a test of the general relativistic Kerr
metric. The criticism is mainly related to the black hole's quasi-circular
shadow and advocates that its radius depends not only on the black hole's true
spacetime properties but also on the poorly known physics of the illuminating
accretion flow. In this paper we take a sober view of the problem and argue
that our ability to probe gravity with a black hole shadow is only partially
impaired by the matter degrees of freedom and the number of non-Kerr parameters
used in the model. As we show here, a more intriguing situation arises from the
mass scaling of the dimensional coupling constants that typically appear in
non-GR theories of gravity. Existing limits from gravitational wave
observations imply that supermassive systems like the M87* black hole would
suffer a suppression of all non-GR deviation parameters in their metric, making
the spacetime and the produced shadow virtually Kerr. Therefore, a supermassive
black hole shadow is likely to probe only those extensions of General
Relativity which are endowed with dimensionless coupling constants or other
special cases with a screening mechanism for black holes or certain types of
spontaneous scalarisation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:31:32 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 14:34:43 GMT""},{""version"":""v3"",""created"":""Mon, 11 Oct 2021 10:28:48 GMT""}]","2021-10-22"
"2102.13574","Lars Niemann","Lars Niemann and Thorsten Schmidt","A conditional version of the second fundamental theorem of asset pricing
  in discrete time",,,,,"q-fin.MF math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a financial market in discrete time and study pricing and hedging
conditional on the information available up to an arbitrary point in time. In
this conditional framework, we determine the structure of arbitrage-free
prices. Moreover, we characterize attainability and market completeness. We
derive a conditional version of the second fundamental theorem of asset
pricing, which, surprisingly, is not available up to now. The main tool we use
are time consistency properties of dynamic nonlinear expectations, which we
apply to the super- and subhedging prices. The results obtained extend existing
results in the literature, where the conditional setting is considered in most
cases only on finite probability spaces.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:35:02 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 07:18:10 GMT""}]","2023-05-15"
"2102.13575","Ying Wang","Ying Wang, Xu Xu, Wenxia Zhao, Nan Li, Samuel A. McDonald, Yuan Chai,
  Michael Atkinson, Katherine J. Dobson, Stefan Michalik, Yingwei Fan, Philip
  J. Withers, Xiaorong Zhou and Timothy L. Burnett","Damage accumulation during high temperature fatigue of Ti/SiC$_f$ metal
  matrix composites under different stress amplitudes",,,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The damage mechanisms and load redistribution of high strength TC17 titanium
alloy/unidirectional SiC fibre composite (fibre diameter = 100 $\mu$m) under
high temperature (350 {\deg}C) fatigue cycling have been investigated in situ
using synchrotron X-ray computed tomography (CT) and X-ray diffraction (XRD)
for high cycle fatigue (HCF) under different stress amplitudes. The
three-dimensional morphology of the crack and fibre fractures has been mapped
by CT. During stable growth, matrix cracking dominates with the crack
deflecting (by 50-100 $\mu$m in height) when bypassing bridging fibres. A small
number of bridging fibres have fractured close to the matrix crack plane
especially under relatively high stress amplitude cycling. Loading to the peak
stress led to rapid crack growth accompanied by a burst of fibre fractures.
Many of the fibre fractures occurred 50-300 $\mu$m from the matrix crack plane
during rapid growth, in contrast to that in the stable growth stage, leading to
extensive fibre pull-out on the fracture surface. The changes in fibre loading,
interfacial stress, and the extent of fibre-matrix debonding in the vicinity of
the crack have been mapped for the fatigue cycle and after the rapid growth by
high spatial resolution XRD. The fibre/matrix interfacial sliding extends up to
600 $\mu$m (in the stable growth zone) or 700 $\mu$m (in the rapid growth zone)
either side of the crack plane. The direction of interfacial shear stress
reverses with the loading cycle, with the maximum frictional sliding stress
reaching ~55 MPa in both the stable growth and rapid growth regimes.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:35:45 GMT""}]","2021-03-01"
"2102.13576","Amlan Kusum Roy","Neetik Mukherjee and Amlan K. Roy","Analysis of Compton profile through information theory in H-like atoms
  inside impenetrable sphere","25 pages, 3 tables, 5 figures","Journal of Physics B: Atomic, Molecular and Optical Physics 53
  (23), 235002 (2020)",,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Confinement of atoms inside various cavities has been studied for nearly
eight decades. However, the Compton profile for such systems has not yet been
investigated. Here we construct the Compton profile (CP) for a H atom radially
confined inside a \emph{hard} spherical enclosure, as well as in \emph{free
condition}. Some exact analytical relations for the CP's of circular or
nodeless states of free atom is presented. By means of a scaling idea, this has
been further extended to the study of an H-like atom trapped inside an
impenetrable cavity. The accuracy of these constructed CP has been confirmed by
computing various momentum moments. Apart from that, several information
theoretical measures, like Shannon entropy ($S$) and Onicescu energy ($E$) have
been exploited to characterize these profiles. Exact closed form expressions
are derived for $S$ and $E$ using the ground state CP in free H-like atoms. A
detailed study reveals that, increase in confinement inhibits the rate of
dissipation of kinetic energy. At a fixed $\ell$, this rate diminishes with
rise in $n$. However, at a certain $n$, this rate accelerates with progress in
$\ell$. A similar analysis on the respective free counterpart displays an
exactly opposite trend as that in confined system. However, in both free and
confined environments, CP generally gets broadened with rise in $Z$.
Representative calculations are done numerically for low-lying states of the
confined systems, taking two forms of position-space wave functions: (a) exact
(b) highly accurate eigenfunctions through a generalized pseudospectral method.
In essence, CPs are reported for confined H atom (and isoelectronic series) and
investigated adopting an information-theoretic framework.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:38:15 GMT""}]","2021-03-01"
"2102.13577","Felix Schl\""uter","Felix Schl\""uter and Tim Huege","Expected performance of air-shower measurements with the
  radio-interferometric technique",,"JINST 16 P07048 (2021)","10.1088/1748-0221/16/07/P07048",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interferometric measurements with arrays of radio antennas are a powerful and
widely used technique in astronomy. Recently, this technique has been revisited
for the reconstruction of extensive air showers [1]. This radio-interferometric
technique exploits the coherence in the radio emission emitted by billions of
secondary shower particles to reconstruct the shower parameters, in particular
the shower axis and depth of the shower maximum $X_\mathrm{max}$. The accuracy
previously demonstrated on simulations with an idealized detector is very
promising. In this article we evaluate the potential of interferometric
$X_\mathrm{max}$ measurements using (simulated) inclined air showers with
sparse antenna arrays under realistic conditions. To determine prerequisites
for the application of the radio-interferometric technique with various antenna
arrays, the influence of inaccuracies in the time synchronisation between
antennas and its inter-dependency with the antenna density is investigated in
detail. We find a strong correlation between the antenna multiplicity (per
event) and the maximum acceptable time jitter, i.e., inaccuracy in the time
synchronisation. For data recorded with a time synchronisation accurate to
within 1 ns in the commonly used frequency band of 30 to 80 MHz, an antenna
multiplicity of $> 50$ is needed to achieve an $X_\mathrm{max}$ resolution of
$\sigma_{X_\mathrm{max}} \lesssim 20$ g cm$^{-2}$. For data recorded with 2 ns
accuracy, already $\gtrsim 200$ antennas are needed to achieve this
$X_\mathrm{max}$ resolution. Furthermore, we find no advantage reconstructing
$X_\mathrm{max}$ from data simulated at higher observation frequencies, i.e.,
up to several hundred MHz. Finally, we provide a generalisation of our results
from very inclined air showers to vertical geometries.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:38:16 GMT""}]","2022-12-16"
"2102.13578","K{\aa}re Gjaldb{\ae}k","Madeline Brandt and K{\aa}re Schou Gjaldb{\ae}k","Classification of Quadratic Packing Polynomials on Sectors of
  $\mathbb{R}^2$","18 pages, 9 figures",,,,"math.NT math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study quadratic polynomials giving bijections from the integer lattice
points of sectors of $\mathbb{R}^2$ onto $\mathbb{N}_0$ , called packing
polynomials. We determine all quadratic packing polynomials on rational
sectors. This generalizes results of Stanton, Nathanson, and Fueter and
P\'olya.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:40:00 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 18:46:18 GMT""}]","2023-06-09"
"2102.13579","Amlan Kusum Roy","Abhisek Ghosal, Tarun Gupta, Kishalay Mahato and Amlan K. Roy","Excitation energies through Becke's exciton model within a
  Cartesian-grid KS DFT",,"Theoretical Chemistry Accounts 140 (1), 1-9 (2021)",,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Photon-induced electronic excitations are ubiquitously observed in organic
chromophore. In this context, we present a simple, alternative time-independent
DFT procedure, for computation of single-particle excitation energies, in
particular, the lower bound excited singlet states, which are of primary
interest in photochemistry. This takes inspiration from recently developed
Becke's exciton model, where a key step constitutes the accurate evaluation of
correlated singlet-triplet splitting energy. It introduces a non-empirical
model, both from ""adiabatic connection theorem"" and ""virial theorem"" to analyze
the role of 2e$^-$ integral in such calculations. The latter quantity is
efficiently mapped onto a real grid and computed accurately using a purely
numerical strategy. Illustrative calculations are performed on 10
$\pi$-electron organic chromophores within a Cartesian-grid implementation of
pseudopotential Kohn-Sham (KS) DFT, developed in our laboratory, taking
SBKJC-type basis functions within B3LYP approximation. The triplet and singlet
excitation energies corresponding to first singly excited configuration, are
found to be in excellent agreement with TD-B3LYP calculations. Further, we
perform the same for a set of larger molecular systems using the asymptotically
corrected LC-BLYP, in addition to B3LYP. A systematic comparison with
theoretical best estimates demonstrates the viability and suitability of
current approach in determining optical gaps, combining predictive accuracy
with moderate computational cost.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:46:24 GMT""}]","2021-03-01"
"2102.13580","V. O. Nesterenko","V.O. Nesterenko, P.I. Vishnevskiy, J. Kvasil, A. Repko and W. Kleinig","Microscopic analysis of low-energy spin and orbital magnetic dipole
  excitations in deformed nuclei","15 pages, 13 figures","Physical Review C 103, 064313 (2021)","10.1103/PhysRevC.103.064313",,"nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  A low-energy magnetic dipole $(M1)$ spin-scissors resonance (SSR) located
just below the ordinary orbital scissors resonance (OSR) was recently predicted
in deformed nuclei within the Wigner Function Moments (WFM) approach. We
analyze this prediction using fully self-consistent Skyrme Quasiparticle Random
Phase Approximation (QRPA) method. Skyrme forces SkM*, SVbas and SG2 are
implemented to explore SSR and OSR in $^{160,162,164}$Dy and $^{232}$Th.
Accuracy of the method is justified by a good description of M1 spin-flip giant
resonance. The calculations show that isotopes $^{160,162,164}$Dy indeed have
at 1.5-2.4 MeV (below OSR) $I^{\pi}K=1^+1$ states with a large $M1$ spin
strength ($K$ is the projection of the total nuclear moment to the symmetry
z-axis). These states are almost fully exhausted by $pp[411\uparrow,
411\downarrow]$ and $nn[521\uparrow, 521\downarrow]$ spin-flip configurations
corresponding to $pp[2d_{3/2}, 2d_{5/2}]$ and $nn[2f_{5/2}, 2f_{7/2}]$
structures in the spherical limit. So the predicted SSR is actually reduced to
low-orbital (l=2,3) spin-flip states. Following our analysis and in
contradiction with WFM spin-scissors picture, deformation is not the principle
origin of the low-energy spin $M1$ states but only a factor affecting their
features. The spin and orbital strengths are generally mixed and exhibit the
interference: weak destructive in SSR range and strong constructive in OSR
range. In $^{232}$Th, the $M1$ spin strength is found very small. Two groups of
$I^{\pi}=1^+$ states observed experimentally at 2.4-4 MeV in $^{160,162,164}$Dy
and at 2-4 MeV in $^{232}$Th are mainly explained by fragmentation of the
orbital strength. Distributions of nuclear currents in QRPA states partly
correspond to the isovector orbital-scissors flow but not to spin-scissors one.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:47:01 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 08:45:58 GMT""}]","2021-07-05"
"2102.13581","Russell McKenna","Matteo DAndrea, Mario Garzon Gonzalez, Russell McKenna","Synergies in offshore energy: a roadmap for the Danish sector","Feasibility study funded by the DHRTC",,,,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This study sets out to analyze future synergies between the O&G and
renewables sectors and explore how exploiting these synergies could lead to
economic and environmental benefits. By firstly reviewing and highlighting
relevant technologies and related projects, this report synthesizes the state
of the art in offshore energy system integration, by focusing on three key
technologies in electrification/floating wind, electrolysis/hydrogen production
and Carbon Capture and Storage (CCS). With a timeframe out to 2050 and model
scope including all North Sea neighbouring countries, this analysis explores a
total of nine future scenarios for the North Sea energy system. The main
results include an immediate electrification of all operational DUC platforms
by linking them to the shore and/or a planned Danish energy island. These
measures result in cost and CO2 emissions savings compared to a BAU scenario of
72% and 85% respectively. When these platforms cease production, this is
followed by the repurposing of the platforms into hydrogen generators with up
to 3.6 GW of electrolysers and the development of up to 5.8 GW of floating
wind. The generated hydrogen is assumed to power the future transport sector,
and is delivered to shore in existing and/or new purpose-built pipelines. The
contribution of the O&G sector to this hydrogen production amounts to around 19
TWh, which represents about 2% of total European hydrogen demand for transport
in 2050. The levelized costs (LCOE) of producing this hydrogen in 2050 are
around 4 euro2012/kg H2, which is around twice those expected in similar
studies. But this does not account for energy policies that may incentivize
green hydrogen production in the future, which would serve to reduce this LCOE
to a level that is more competitive with other sources.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:47:20 GMT""}]","2021-03-01"
"2102.13582","Jing Zhu","Jing Zhu, Xingyu Lu, Mark Heimann, Danai Koutra","Node Proximity Is All You Need: Unified Structural and Positional Node
  and Graph Embedding","SDM 2021",,,,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While most network embedding techniques model the relative positions of nodes
in a network, recently there has been significant interest in structural
embeddings that model node role equivalences, irrespective of their distances
to any specific nodes. We present PhUSION, a proximity-based unified framework
for computing structural and positional node embeddings, which leverages
well-established methods for calculating node proximity scores. Clarifying a
point of contention in the literature, we show which step of PhUSION produces
the different kinds of embeddings and what steps can be used by both. Moreover,
by aggregating the PhUSION node embeddings, we obtain graph-level features that
model information lost by previous graph feature learning and kernel methods.
In a comprehensive empirical study with over 10 datasets, 4 tasks, and 35
methods, we systematically reveal successful design choices for node and
graph-level machine learning with embeddings.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:48:39 GMT""}]","2021-03-01"
"2102.13583","Andrei Popescu","Rene Poncelet, Andrei Popescu","NNLO QCD study of polarised $W^+ W^-$ production at the LHC","corrected typos, added a reference, amended and clarified discussion
  with comments on top-quark loop effects, etc; matches JHEP published version","JHEP07(2021)023","10.1007/JHEP07(2021)023","CAVENDISH--HEP--21/03","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Longitudinal polarisation of the weak bosons is a direct consequence of
Electroweak symmetry breaking mechanism providing an insight into its nature,
and is instrumental in searches for physics beyond the Standard Model. We
perform a polarisation study of the diboson production in the $p p \to
e^+\nu_e\mu^-\bar\nu_\mu$ process at NNLO QCD in the fiducial setup inspired by
experimental measurements at ATLAS. This is the first polarisation study at
NNLO. We employ the double-pole approximation framework for the polarised
calculation, and investigate NNLO effects arising in differential
distributions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:49:23 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 09:45:20 GMT""}]","2021-07-07"
"2102.13584","Italo Valcy Da Silva Brito","Italo V S Brito","NDVR: NDN Distance Vector Routing",,,,,"cs.NI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Ad hoc mobile scenarios desire a lightweight routing protocol to propagate
rapidly changing data reachability information in a highly dynamic environment.
We are developing a distance-vector routing protocol that enables each node to
selectively propagate a data reachability vector containing the named-data
prefixes current reachable to their neighbors. In this report, we describe the
implementation of NDVR (NDN Distance Vector Routing), discuss the rationale for
the protocol design choices, and demonstrate a use case for the protocol to
illustrate how the routing protocol can help NDN applications, especially in
mobile ad-hoc scenarios.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:49:24 GMT""}]","2021-03-01"
"2102.13585","Brant M. Johnson","U.A. Acharya, C. Aidala, Y. Akiba, M. Alfred, V. Andrieux, N. Apadula,
  H. Asano, B. Azmoun, V. Babintsev, N.S. Bandara, K.N. Barish, S. Bathe, A.
  Bazilevsky, M. Beaumier, R. Belmont, A. Berdnikov, Y. Berdnikov, L. Bichon,
  B. Blankenship, D.S. Blau, J.S. Bok, M.L. Brooks, J. Bryslawskyj, V.
  Bumazhnov, S. Campbell, V. Canoa Roman, R. Cervantes, C.Y. Chi, M. Chiu, I.J.
  Choi, J.B. Choi, Z. Citron, M. Connors, R. Corliss, Y. Corrales N. Cronin, M.
  Csan\'ad, T. Cs\""org\H{o}, T.W. Danley, M.S. Daugherity, G. David, K.
  DeBlasio, K. Dehmelt, A. Denisov, A. Deshpande, E.J. Desmond, A. Dion, D.
  Dixit, J.H. Do, A. Drees, K.A. Drees, J.M. Durham, A. Durum, A. Enokizono, H.
  En'yo, R. Esha, S. Esumi, B. Fadem, W. Fan, N. Feege, D.E. Fields, M. Finger,
  M. Finger, Jr., D. Fitzgerald, S.L. Fokin, J.E. Frantz, A. Franz, A.D.
  Frawley, Y. Fukuda, C. Gal, P. Gallus, P. Garg, H. Ge, M. Giles, F. Giordano,
  Y. Goto, N. Grau, S.V. Greene, M. Grosse Perdekamp, T. Gunji, H. Guragain, T.
  Hachiya, J.S. Haggerty, K.I. Hahn, H. Hamagaki, H.F. Hamilton, S.Y. Han, J.
  Hanks, M. Harvey, S. Hasegawa, T.O.S. Haseler, X. He, T.K. Hemmick, J.C.
  Hill, K. Hill, A. Hodges, R.S. Hollis, K. Homma, B. Hong, T. Hoshino, N.
  Hotvedt, J. Huang, S. Huang, K. Imai, M. Inaba, A. Iordanova, D. Isenhower,
  D. Ivanishchev, B.V. Jacak, M. Jezghani, Z. Ji, X. Jiang, B.M. Johnson, D.
  Jouan, D.S. Jumper, J.H. Kang, D. Kapukchyan, S. Karthas, D. Kawall, A.V.
  Kazantsev, V. Khachatryan, A. Khanzadeev, A. Khatiwada, C. Kim, E.-J. Kim, M.
  Kim, D. Kincses, A. Kingan, E. Kistenev, J. Klatsky, P. Kline, T. Koblesky,
  D. Kotov, S. Kudo, B. Kurgyis, K. Kurita, Y. Kwon, J.G. Lajoie, D. Larionova,
  A. Lebedev, S. Lee, S.H. Lee, M.J. Leitch, Y.H. Leung, N.A. Lewis, X. Li,
  S.H. Lim, M.X. Liu, V.-R. Loggins, S. L\""ok\""os, D.A. Loomis, K. Lovasz, D.
  Lynch, T. Majoros, Y.I. Makdisi, M. Makek, V.I. Manko, E. Mannel, M.
  McCumber, P.L. McGaughey, D. McGlinchey, C. McKinney, M. Mendoza, A.C.
  Mignerey, A. Milov, D.K. Mishra, J.T. Mitchell, Iu. Mitrankov, M. Mitrankova,
  G. Mitsuka, S. Miyasaka, S. Mizuno, M.M. Mondal, P. Montuenga, T. Moon, D.P.
  Morrison, B. Mulilo, T. Murakami, J. Murata, K. Nagai, K. Nagashima, T.
  Nagashima, J.L. Nagle, M.I. Nagy, I. Nakagawa, K. Nakano, C. Nattrass, S.
  Nelson, T. Niida, R. Nouicer, T. Nov\'ak, N. Novitzky, G. Nukazuka, A.S.
  Nyanin, E. O'Brien, C.A. Ogilvie, J.D. Orjuela Koop, J.D. Osborn, A.
  Oskarsson, G.J. Ottino, K. Ozawa, V. Pantuev, V. Papavassiliou, J.S. Park, S.
  Park, S.F. Pate, M. Patel, W. Peng, D.V. Perepelitsa, G.D.N. Perera, D.Yu.
  Peressounko, C.E. PerezLara, J. Perry, R. Petti, M. Phipps, C. Pinkenburg,
  R.P. Pisani, M. Potekhin, A. Pun, M.L. Purschke, P.V. Radzevich, N.
  Ramasubramanian, K.F. Read, D. Reynolds, V. Riabov, Y. Riabov, D. Richford,
  T. Rinn, S.D. Rolnick, M. Rosati, Z. Rowan, J. Runchey, A.S. Safonov, T.
  Sakaguchi, H. Sako, V. Samsonov, M. Sarsour, S. Sato, B. Schaefer, B.K.
  Schmoll, K. Sedgwick, R. Seidl, A. Sen, R. Seto, A. Sexton, D Sharma, D.
  Sharma, I. Shein, T.-A. Shibata, K. Shigaki, M. Shimomura, T. Shioya, P.
  Shukla, A. Sickles, C.L. Silva, D. Silvermyr, B.K. Singh, C.P. Singh, V.
  Singh, M. Slune\v{c}ka, K.L. Smith, M. Snowball, R.A. Soltz, W.E. Sondheim,
  S.P. Sorensen, I.V. Sourikova, P.W. Stankus, S.P. Stoll, T. Sugitate, A.
  Sukhanov, T. Sumita, J. Sun, Z. Sun, J. Sziklai, K. Tanida, M.J. Tannenbaum,
  S. Tarafdar, A. Taranenko, G. Tarnai, R. Tieulent, A. Timilsina, T. Todoroki,
  M. Tom\'a\v{s}ek, C.L. Towell, R.S. Towell, I. Tserruya, Y. Ueda, B. Ujvari,
  H.W. van Hecke, J. Velkovska, M. Virius, V. Vrba, N. Vukman, X.R. Wang, Y.S.
  Watanabe, C.P. Wong, C.L. Woody, C. Xu, Q. Xu, L. Xue, S. Yalcin, Y.L.
  Yamaguchi, H. Yamamoto, A. Yanovich, J.H. Yoo, I. Yoon, H. Yu, I.E.
  Yushmanov, W.A. Zajc, A. Zelenski, S. Zharko, L. Zou","Probing gluon spin-momentum correlations in transversely polarized
  protons through midrapidity isolated direct photons in $p^\uparrow+p$
  collisions at $\sqrt{s}=200$ GeV","312 authors from 68 institutions, 8 pages, 2 figures, 1 table, 2015
  data. v2 is version accepted by Physical Review Letters. Plain text data
  tables for the points plotted in figures for this and previous PHENIX
  publications are (or will be) publicly available at
  http://www.phenix.bnl.gov/papers.html",,"10.1103/PhysRevLett.127.162001",,"hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Studying spin-momentum correlations in hadronic collisions offers a glimpse
into a three-dimensional picture of proton structure. The transverse
single-spin asymmetry for midrapidity isolated direct photons in $p^\uparrow+p$
collisions at $\sqrt{s}=200$ GeV is measured with the PHENIX detector at the
Relativistic Heavy Ion Collider (RHIC). Because direct photons in particular
are produced from the hard scattering and do not interact via the strong force,
this measurement is a clean probe of initial-state spin-momentum correlations
inside the proton and is in particular sensitive to gluon interference effects
within the proton. This is the first time direct photons have been used as a
probe of spin-momentum correlations at RHIC. The uncertainties on the results
are a fifty-fold improvement with respect to those of the one prior measurement
for the same observable, from the Fermilab E704 experiment. These results
constrain gluon spin-momentum correlations in transversely polarized protons.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:50:39 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 14:27:58 GMT""}]","2021-10-27"
"2102.13586","Francesco Fanelli","Dimitri Cobb, Francesco Fanelli","Symmetry breaking in ideal magnetohydrodynamics: the role of the
  velocity","Submitted",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ideal magnetohydrodynamic equations are, roughly speaking, a quasi-linear
symmetric hyperbolic system of PDEs, but not all the unknowns play the same
role in this system. Indeed, in the regime of small magnetic fields, the
equations are close to the incompressible Euler equations. In the present
paper, we adopt this point of view to study questions linked with the lifespan
of strong solutions to the ideal magnetohydrodynamic equations. First of all,
we prove a continuation criterion in terms of the velocity field only.
Secondly, we refine the explicit lower bound for the lifespan of $2$-D flows
found in [11], by relaxing the regularity assumptions on the initial magnetic
field.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:51:37 GMT""}]","2021-03-01"
"2102.13587","Jos\'e Lu\'is da Silva Dr.","Jos\'e L. da Silva and Yuri G. Kondratiev","Cesaro Limits for Fractional Dynamics","19 pages",,,,"math.PR math.DS","http://creativecommons.org/licenses/by/4.0/","  We study the asymptotic behavior of random time changes of dynamical systems.
As random time changes we propose three classes which exhibits different
patterns of asymptotic decays. The subordination principle may be applied to
study the asymptotic behavior of the random time dynamical systems. It turns
out that for the special case of stable subordinators explicit expressions for
the subordination are known and its asymptotic behavior are derived. For more
general classes of random time changes explicit calculations are essentially
more complicated and we reduce our study to the asymptotic behavior of the
corresponding Cesaro limit.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:53:34 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 15:07:19 GMT""}]","2021-03-11"
"2102.13588","Shuai Yu","Shuai Yu, Jianyang Xie, Jinkui Hao, Yalin Zheng, Jiong Zhang, Yan Hu,
  Jiang Liu, Yitian Zhao","3D Vessel Reconstruction in OCT-Angiography via Depth Map Estimation",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Optical Coherence Tomography Angiography (OCTA) has been increasingly used in
the management of eye and systemic diseases in recent years. Manual or
automatic analysis of blood vessel in 2D OCTA images (en face angiograms) is
commonly used in clinical practice, however it may lose rich 3D spatial
distribution information of blood vessels or capillaries that are useful for
clinical decision-making. In this paper, we introduce a novel 3D vessel
reconstruction framework based on the estimation of vessel depth maps from OCTA
images. First, we design a network with structural constraints to predict the
depth of blood vessels in OCTA images. In order to promote the accuracy of the
predicted depth map at both the overall structure- and pixel- level, we combine
MSE and SSIM loss as the training loss function. Finally, the 3D vessel
reconstruction is achieved by utilizing the estimated depth map and 2D vessel
segmentation results. Experimental results demonstrate that our method is
effective in the depth prediction and 3D vessel reconstruction for OCTA
images.% results may be used to guide subsequent vascular analysis
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:53:39 GMT""}]","2021-03-01"
"2102.13589","Mathilde Veron","Mathilde Veron, Sophie Rosset, Olivier Galibert, Guillaume Bernard","Evaluate On-the-job Learning Dialogue Systems and a Case Study for
  Natural Language Understanding","Accepted to NeurIPS 2020 Human in the Loop Dialogue Systems Workshop",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  On-the-job learning consists in continuously learning while being used in
production, in an open environment, meaning that the system has to deal on its
own with situations and elements never seen before. The kind of systems that
seem to be especially adapted to on-the-job learning are dialogue systems,
since they can take advantage of their interactions with users to collect
feedback to adapt and improve their components over time. Some dialogue systems
performing on-the-job learning have been built and evaluated but no general
methodology has yet been defined. Thus in this paper, we propose a first
general methodology for evaluating on-the-job learning dialogue systems. We
also describe a task-oriented dialogue system which improves on-the-job its
natural language component through its user interactions. We finally evaluate
our system with the described methodology.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:54:16 GMT""}]","2021-03-01"
"2102.13590","Samuel Walsh","Robin Ming Chen, Samuel Walsh","Orbital stability of internal waves","39 pages, 2 figures",,"10.1007/s00220-022-04332-x",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the nonlinear stability of capillary-gravity waves
propagating along the interface dividing two immiscible fluid layers of finite
depth. The motion in both regions is governed by the incompressible and
irrotational Euler equations, with the density of each fluid being constant but
distinct. A diverse collection of small-amplitude solitary wave solutions for
this system have been constructed by several authors in the case of strong
surface tension (as measured by the Bond number) and slightly subcritical
Froude number. We prove that all of these waves are (conditionally) orbitally
stable in the natural energy space. Moreover, the trivial solution is shown to
be conditionally stable when the Bond and Froude numbers lie in a certain
unbounded parameter region. For the near critical surface tension regime, we
prove that one can infer conditional orbital stability or orbital instability
of small-amplitude traveling waves solutions to the full Euler system from
considerations of a dispersive PDE model equation.
  These results are obtained by reformulating the problem as an
infinite-dimensional Hamiltonian system, then applying a version of the
Grillakis--Shatah--Strauss method recently introduced by Varholm, Wahl\'en, and
Walsh. A key part of the analysis consists of computing the spectrum of the
linearized augmented Hamiltonian at a shear flow or small-amplitude wave. For
this, we generalize an idea used by Mielke to treat capillary-gravity water
waves beneath vacuum.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:57:17 GMT""}]","2022-03-09"
"2102.13591","Anastasia Doikou","Anastasia Doikou","Set theoretic Yang-Baxter equation, braces and Drinfeld twists","23 pages, LaTex. A few comments added","J. Phys. A 54 (2021) 415201","10.1088/1751-8121/ac219e",,"math-ph hep-th math.MP math.QA math.RA","http://creativecommons.org/licenses/by/4.0/","  We consider involutive, non-degenerate, finite set theoretic solutions of the
Yang-Baxter equation. Such solutions can be always obtained using certain
algebraic structures that generalize nil potent rings called braces. Our main
aim here is to express such solutions in terms of admissible Drinfeld twists
substantially extending recent preliminary results. We first identify the
generic form of the twists associated to set theoretic solutions and we show
that these twists are admissible, i.e. they satisfy a certain co-cycle
condition. These findings are also valid for Baxterized solutions of the
Yang-Baxter equation constructed from the set theoretical ones.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:57:20 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 14:23:33 GMT""},{""version"":""v3"",""created"":""Wed, 22 Sep 2021 07:08:31 GMT""}]","2021-09-23"
"2102.13592","Ajay Ratheesh","Ajay Ratheesh, A. R. Rao, N. P. S Mithun, Santosh V. Vadawale, Ajay
  Vibhute, Dipankar Bhattacharya, Priya Pradeep, S. Sreekumar and Varun
  Bhalerao","A generalized event selection algorithm for AstroSat CZT Imager data","Accepted for publication in JAA",,"10.1007/s12036-021-09716-4",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/publicdomain/zero/1.0/","  The Cadmium Zinc Telluride (CZT) Imager on board AstroSat is a hard X-ray
imaging spectrometer operating in the energy range of 20 $-$ 100 keV. It also
acts as an open hard X-ray monitor above 100 keV capable of detecting transient
events like the Gamma-ray Bursts (GRBs). Additionally, the instrument has the
sensitivity to measure hard X-ray polarization in the energy range of 100 $-$
400 keV for bright on-axis sources like Crab and Cygnus X-1 and bright GRBs. As
hard X-ray instruments like CZTI are sensitive to cosmic rays in addition to
X-rays, it is required to identify and remove particle induced or other noise
events and select events for scientific analysis of the data. The present CZTI
data analysis pipeline includes algorithms for such event selection, but they
have certain limitations. They were primarily designed for the analysis of data
from persistent X-ray sources where the source flux is much less than the
background and thus are not best suited for sources like GRBs. Here, we
re-examine the characteristics of noise events in CZTI and present a
generalized event selection method that caters to the analysis of data for all
types of sources. The efficacy of the new method is reviewed by examining the
Poissonian behavior of the selected events and the signal to noise ratio for
GRBs.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:59:31 GMT""}]","2021-06-23"
"2102.13593","Abhay Kumar","Abhay Kumar (1 and 2), Tanmoy Chattopadhyay (3), Santosh V Vadawale
  (1), A.R. Rao (4 and 5), Soumya Gupta (4), Mithun N.P.S. (1), Varun Bhalerao
  (6) and Dipankar Bhattacharya (4) ((1) Physical Research Laboratory,
  Navrangpura, Ahmedabad, India, (2) Indian Institute of Technology,
  Gandhinagar, India, (3) Kavli Institute of Astrophysics and Cosmology,
  Stanford, CA, USA, (4) The Inter-University Centre for Astronomy and
  Astrophysics, Pune, India, (5) Tata Institute of Fundamental Research,
  Mumbai, India, (6) Indian Institute of Technology Bombay, Mumbai, India)","Exploring Sub-MeV Sensitivity of AstroSat-CZTI for ON-axis Bright
  Sources","10 pages, 8 figures",,,,"astro-ph.IM astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Cadmium Zinc Telluride Imager (CZTI) onboard AstroSat is designed for
hard X-ray imaging and spectroscopy in the energy range of 20 - 100 keV. The
CZT detectors are of 5 mm thickness and hence have good efficiency for Compton
interactions beyond 100 keV. The polarisation analysis using CZTI relies on
such Compton events and have been verified experimentally. The same Compton
events can also be used to extend the spectroscopy up to 380 keV. Further, it
has been observed that about 20% pixels of the CZTI detector plane have low
gain, and they are excluded from the primary spectroscopy. If these pixels are
included, then the spectroscopic capability of CZTI can be extended up to 500
keV and further up to 700 keV with a better gain calibration in the future.
Here we explore the possibility of using the Compton events as well as the low
gain pixels to extend the spectroscopic energy range of CZTI for ON-axis bright
X-ray sources. We demonstrate this technique using Crab observations and
explore its sensitivity.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:00:03 GMT""}]","2021-03-01"
"2102.13594","Tanmoy Chattopadhyay","Tanmoy Chattopadhyay, Soumya Gupta, Vidushi Sharma, Shabnam Iyyani,
  Ajay Ratheesh, N. P. S. Mithun, E. Aarthy, Sourav Palit, Abhay Kumar, Santosh
  V Vadawale, A.R. Rao, Varun Bhalerao and Dipankar Bhattacharya","Sub-MeV spectroscopy with AstroSat-CZT Imager for Gamma Ray Bursts","Accepted for publication in Journal of Astrophysics and Astronomy, 5
  years of AstroSat special issue","Journal of Astrophysics and Astronomy, Volume 42, Issue 2, article
  id.82, year 2021","10.1007/s12036-021-09718-2",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Cadmium Zinc Telluride Imager (CZTI) onboard AstroSat has been a prolific
Gamma-Ray Burst (GRB) monitor. While the 2-pixel Compton scattered events (100
- 300 keV) are used to extract sensitive spectroscopic information, the
inclusion of the low-gain pixels (around 20% of the detector plane) after
careful calibration extends the energy range of Compton energy spectra to 600
keV. The new feature also allows single-pixel spectroscopy of the GRBs to the
sub-MeV range which is otherwise limited to 150 keV. We also introduced a new
noise rejection algorithm in the analysis ('Compton noise'). These new
additions not only enhances the spectroscopic sensitivity of CZTI, but the
sub-MeV spectroscopy will also allow proper characterization of the GRBs not
detected by Fermi. This article describes the methodology of single, Compton
event and veto spectroscopy in 100 - 600 keV for the GRBs detected in the first
year of operation. CZTI in last five years has detected around 20 bright GRBs.
The new methodologies, when applied on the spectral analysis for this large
sample of GRBs, has the potential to improve the results significantly and help
in better understanding the prompt emission mechanism.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:00:15 GMT""}]","2021-10-14"
"2102.13595","Nicolas Lodieu","N. Lodieu (1,2), N. C. Hambly (3), N. J. G. Cross (3) ((1) IAC,
  Tenerife, Spain, (2) ULL, Tenerife, Spain, (3) ROE, Edinburgh, Scotland)","Exploring the planetary-mass population in the Upper Scorpius
  association","14 pages, 8 figures, 3 tables, 1 appendix with 3 tables that will be
  public through Vizier at CDS, accepted by MNRAS",,"10.1093/mnras/stab401",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim at identifying very low-mass isolated planetary-mass member candidates
in the nearest OB association to the Sun, Upper Scorpius (145 pc; 5-10 Myr), to
constrain the form and shape of the luminosity function and mass spectrum in
this regime. We conducted a deep multi-band ($Y$=21.2, $J$=20.5, $Z$=22.0 mag)
photometric survey of six square degrees in the central region of Upper
Scorpius. We extend the current sequence of astrometric and spectroscopic
members by about two magnitudes in $Y$ and one magnitude in $J$, reaching
potentially T-type free-floating members in the association with predicted
masses below 5 Jupiter masses, well into the planetary-mass regime. We
extracted a sample of 57 candidates in this area and present infrared
spectroscopy confirming two of them as young L-type members with characteristic
spectral features of 10 Myr-old brown dwarfs. Among the 57 candidates, we
highlight 10 new candidates fainter than the coolest members previously
confirmed spectroscopically. We do not see any obvious sign of decrease in the
mass spectrum of the association, suggesting that star processes can form
substellar objects with masses down to 4-5 Jupiter masses.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:04:33 GMT""}]","2021-03-31"
"2102.13596","Muneer Alshowkan","Muneer Alshowkan, Brian P. Williams, Philip G. Evans, Nageswara S. V.
  Rao, Emma M. Simmerman, Hsuan-Hao Lu, Navin B. Lingaraju, Andrew M. Weiner,
  Claire E. Marvinney, Yun-Yi Pai, Benjamin J. Lawrie, Nicholas A. Peters,
  Joseph M. Lukens","A Reconfigurable Quantum Local Area Network Over Deployed Fiber",,"PRX Quantum 2, 040304 (2021)","10.1103/PRXQuantum.2.040304",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Practical quantum networking architectures are crucial for scaling the
connection of quantum resources. Yet quantum network testbeds have thus far
underutilized the full capabilities of modern lightwave communications, such as
flexible-grid bandwidth allocation. In this work, we implement flex-grid
entanglement distribution in a deployed network for the first time, connecting
nodes in three distinct campus buildings time-synchronized via the Global
Positioning System (GPS). We quantify the quality of the distributed
polarization entanglement via log-negativity, which offers a generic metric of
link performance in entangled bits per second. After demonstrating successful
entanglement distribution for two allocations of our eight dynamically
reconfigurable channels, we demonstrate remote state preparation -- the first
realization on deployed fiber -- showcasing one possible quantum protocol
enabled by the distributed entanglement network. Our results realize an
advanced paradigm for managing entanglement resources in quantum networks of
ever-increasing complexity and service demands.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:08:03 GMT""}]","2021-10-13"
"2102.13597","Andreia Sofia Teixeira","Andreia Sofia Teixeira, Francisco C. Santos, Alexandre P. Francisco,
  Fernando P. Santos","Evolution of collective fairness in complex networks through
  degree-based role assignment",,,,,"physics.soc-ph cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From social contracts to climate agreements, individuals engage in groups
that must collectively reach decisions with varying levels of equality and
fairness. These dilemmas also pervade Distributed Artificial Intelligence, in
domains such as automated negotiation, conflict resolution or resource
allocation. As evidenced by the well-known Ultimatum Game -- where a Proposer
has to divide a resource with a Responder -- payoff-maximizing outcomes are
frequently at odds with fairness. Eliciting equality in populations of
self-regarding agents requires judicious interventions. Here we use knowledge
about agents' social networks to implement fairness mechanisms, in the context
of Multiplayer Ultimatum Games. We focus on network-based role assignment and
show that preferentially attributing the role of Proposer to low-connected
nodes increases the fairness levels in a population. We evaluate the
effectiveness of low-degree Proposer assignment considering networks with
different average connectivity, group sizes, and group voting rules when
accepting proposals (e.g. majority or unanimity). We further show that
low-degree Proposer assignment is efficient, not only optimizing fairness, but
also the average payoff level in the population. Finally, we show that stricter
voting rules (i.e., imposing an accepting consensus as requirement for
collectives to accept a proposal) attenuates the unfairness that results from
situations where high-degree nodes (hubs) are the natural candidates to play as
Proposers. Our results suggest new routes to use role assignment and voting
mechanisms to prevent unfair behaviors from spreading on complex networks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:08:30 GMT""}]","2021-03-01"
"2102.13598","Venkat Kapil","Venkat Kapil and Edgar A Engel","A complete description of thermodynamic stabilities of molecular
  crystals",,,"10.1073/pnas.2111769119",,"cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Predictions of relative stabilities of (competing) molecular crystals are of
great technological relevance, most notably for the pharmaceutical industry.
However, they present a long-standing challenge for modeling, as often
minuscule free energy differences are sensitively affected by the description
of electronic structure, the statistical mechanics of the nuclei and the cell,
and thermal expansion. The importance of these effects has been individually
established, but rigorous free energy calculations for general molecular
compounds, which simultaneously account for all effects,have hitherto not been
computationally viable. Here we present an efficient ""end to end"" frame-work
that seamlessly combines state-of-the art electronic structure calculations,
machine-learning potentials, and advanced free energy methods to calculate ab
initio Gibbs free energies for general organic molecular materials. The facile
generation of machine-learning potentials for a diverse set of polymorphic
compounds, benzene, glycine, and succinic acid, and predictions of
thermodynamic stabilities in qualitative and quantitative agreement with
experiments highlights that predictive thermodynamic studies of
industrially-relevant molecular materials are no longer a daunting task.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:12:09 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 10:44:45 GMT""}]","2022-05-25"
"2102.13599","Marcos Miralles L\'opez","Marcos Miralles L\'opez (for the ATLAS Collaboration)","$t\bar{t}W$ Production: a very complex process","6 pages, 3 figures. 13th International Workshop on Top Quark Physics,
  Durham, UK (videoconference), 14--18 September, 2020",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  These Monte Carlo studies describe the impact of higher order effects in both
QCD and EW $t\bar{t}W$ production. Both next-to-leading inclusive and multileg
setups are studied for $t\bar{t}W$ QCD production.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:12:48 GMT""}]","2021-03-01"
"2102.13600","Benjamin F. Maier","Benjamin F. Maier, Angelique Burdinski, Annika H. Rose, Frank
  Schlosser, David Hinrichs, Cornelia Betsch, Lars Korn, Philipp Sprengholz,
  Michael Meyer-Hermann, Tanmay Mitra, Karl Lauterbach, Dirk Brockmann","Potential benefits of delaying the second mRNA COVID-19 vaccine dose","22 pages, 9 figures, 10 tables",,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vaccination against COVID-19 with the recently approved mRNA vaccines
BNT162b2 (BioNTech/Pfizer) and mRNA-1273 (Moderna) is currently underway in a
large number of countries. However, high incidence rates and rapidly spreading
SARS-CoV-2 variants are concerning. In combination with acute supply deficits
in Europe in early 2021, the question arises of whether stretching the vaccine,
for instance by delaying the second dose, can make a significant contribution
to preventing deaths, despite associated risks such as lower vaccine efficacy,
the potential emergence of escape mutants, enhancement, waning immunity,
reduced social acceptance of off-label vaccination, and liability shifts. A
quantitative epidemiological assessment of risks and benefits of non-standard
vaccination protocols remains elusive. To clarify the situation and to provide
a quantitative epidemiological foundation we develop a stochastic
epidemiological model that integrates specific vaccine rollout protocols into a
risk-group structured infectious disease dynamical model. Using the situation
and conditions in Germany as a reference system, we show that delaying the
second vaccine dose is expected to prevent deaths in the four to five digit
range, should the incidence resurge. We show that this considerable public
health benefit relies on the fact that both mRNA vaccines provide substantial
protection against severe COVID-19 and death beginning 12 to 14 days after the
first dose. The benefits of protocol change are attenuated should vaccine
compliance decrease substantially. To quantify the impact of protocol change on
vaccination adherence we performed a large-scale online survey. We find that,
in Germany, changing vaccination protocols may lead to small reductions in
vaccination intention. In sum, we therefore expect the benefits of a strategy
change to remain substantial and stable.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:16:18 GMT""}]","2021-03-01"
"2102.13601","ALICE Publications","ALICE Collaboration","Measurement of beauty and charm production in pp collisions at
  $\sqrt{s}=5.02$ TeV via non-prompt and prompt D mesons","36 pages, 13 captioned figures, 5 tables, authors from page 31,
  published version, figures at http://alice-publications.web.cern.ch/node/6833","JHEP 05 (2021) 220","10.1007/JHEP05(2021)220","CERN-EP-2021-034","nucl-ex hep-ex","http://creativecommons.org/licenses/by/4.0/","  The $p_\mathrm{T}$-differential production cross sections of prompt and
non-prompt (produced in beauty-hadron decays) D mesons were measured by the
ALICE experiment at midrapidity ($|y|<0.5$) in proton--proton collisions at
$\sqrt{s}=5.02~\mathrm{TeV}$. The data sample used in the analysis corresponds
to an integrated luminosity of $(19.3\pm0.4)~\mathrm{nb^{-1}}$. D mesons were
reconstructed from their decays $\mathrm{D^0 \to K^-\pi^+}$, $\mathrm{D^+\to
K^-\pi^+\pi^+}$, and $\mathrm{D_s^+\to \phi\pi^+\to K^-K^+\pi^+}$ and their
charge conjugates. Compared to previous measurements in the same rapidity
region, the cross sections of prompt $\mathrm{D^+}$ and $\mathrm{D_s^+}$ mesons
have an extended $p_\mathrm{T}$ coverage and total uncertainties reduced by a
factor ranging from 1.05 to 1.6, depending on $p_\mathrm{T}$, allowing for a
more precise determination of their $p_\mathrm{T}$-integrated cross sections.
The results are well described by perturbative QCD calculations. The
fragmentation fraction of heavy quarks to strange mesons divided by the one to
non-strange mesons, $f_\mathrm{s}/(f_\mathrm{u}+f_\mathrm{d})$, is compatible
for charm and beauty quarks and with previous measurements at different
centre-of-mass energies and collision systems. The $\mathrm{b\overline{b}}$
production cross section per rapidity unit at midrapidity, estimated from
non-prompt D-meson measurements, is
$\mathrm{d}\sigma_\mathrm{b\overline{b}}/\mathrm{d} y|_\mathrm{|y|<0.5} = 34.5
\pm 2.4 (\mathrm{stat.}) ^{+4.7}_{-2.9} (\mathrm{tot. syst.})~\mu\mathrm{b}$.
It is compatible with previous measurements at the same centre-of-mass energy
and with the cross section predicted by perturbative QCD calculations.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:17:49 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 08:26:24 GMT""}]","2021-08-27"
"2102.13602","Swaroopa Dola","Swaroopa Dola, Matthew B. Dwyer, Mary Lou Soffa","Distribution-Aware Testing of Neural Networks Using Generative Models",,,,,"cs.SE cs.LG","http://creativecommons.org/licenses/by/4.0/","  The reliability of software that has a Deep Neural Network (DNN) as a
component is urgently important today given the increasing number of critical
applications being deployed with DNNs. The need for reliability raises a need
for rigorous testing of the safety and trustworthiness of these systems. In the
last few years, there have been a number of research efforts focused on testing
DNNs. However the test generation techniques proposed so far lack a check to
determine whether the test inputs they are generating are valid, and thus
invalid inputs are produced. To illustrate this situation, we explored three
recent DNN testing techniques. Using deep generative model based input
validation, we show that all the three techniques generate significant number
of invalid test inputs. We further analyzed the test coverage achieved by the
test inputs generated by the DNN testing techniques and showed how invalid test
inputs can falsely inflate test coverage metrics.
  To overcome the inclusion of invalid inputs in testing, we propose a
technique to incorporate the valid input space of the DNN model under test in
the test generation process. Our technique uses a deep generative model-based
algorithm to generate only valid inputs. Results of our empirical studies show
that our technique is effective in eliminating invalid tests and boosting the
number of valid test inputs generated.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:18:21 GMT""}]","2021-03-01"
"2102.13603","Alexander Hill","Alexander D. Hill, Robert A. Crain, Juliana Kwan, Ian G. McCarthy","The morphology of star-forming gas and its alignment with galaxies and
  dark matter haloes in the EAGLE simulations","24 pages, 17 figures. Published in MNRAS",,"10.1093/mnras/stab1272",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present measurements of the morphology of star-forming gas in galaxies
from the EAGLE simulations, and its alignment relative to stars and dark matter
(DM). Imaging of such gas in the radio continuum enables weak lensing
experiments that complement traditional optical approaches. Star-forming gas is
typically more flattened than its associated stars and DM, particularly for
present-day subhaloes of total mass $\sim$$10^{ 12-12.5} \mathrm{M_{ \odot}}$,
which preferentially host star-forming galaxies with rotationally-supported
stellar discs. Such systems have oblate, spheroidal star-forming gas
distributions, but in both less- and more-massive subhaloes the distributions
tend to be prolate, and its morphology correlates positively and significantly
with that of its host galaxy's stars, both in terms of sphericity and
triaxiality. The minor axis of star-forming gas most commonly aligns with the
minor axis of its host subhalo's DM, but often aligns more closely with one of
the other two principal axes of the DM distribution in prolate subhaloes.
Star-forming gas aligns with DM less strongly than is the case for stars, but
its morphological minor axis aligns closely with its kinematic axis, affording
a route to observational identification of the unsheared morphological axis.
The projected ellipticities of star-forming gas in EAGLE are consistent with
shapes inferred from high-fidelity radio continuum images, and they exhibit
greater shape noise than is the case for images of the stars, owing to the
greater characteristic flattening of star-forming gas with respect to stars.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:19:36 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 19:00:08 GMT""}]","2022-01-14"
"2102.13604","Yulin Shao","Yulin Shao, Deniz Gunduz, Soung Chang Liew","Federated Edge Learning with Misaligned Over-The-Air Computation","16 pages, 12 figures",,,,"cs.IT cs.DC cs.LG eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over-the-air computation (OAC) is a promising technique to realize fast model
aggregation in the uplink of federated edge learning. OAC, however, hinges on
accurate channel-gain precoding and strict synchronization among the edge
devices, which are challenging in practice. As such, how to design the maximum
likelihood (ML) estimator in the presence of residual channel-gain mismatch and
asynchronies is an open problem. To fill this gap, this paper formulates the
problem of misaligned OAC for federated edge learning and puts forth a whitened
matched filtering and sampling scheme to obtain oversampled, but independent,
samples from the misaligned and overlapped signals. Given the whitened samples,
a sum-product ML estimator and an aligned-sample estimator are devised to
estimate the arithmetic sum of the transmitted symbols. In particular, the
computational complexity of our sum-product ML estimator is linear in the
packet length and hence is significantly lower than the conventional ML
estimator. Extensive simulations on the test accuracy versus the average
received energy per symbol to noise power spectral density ratio (EsN0) yield
two main results: 1) In the low EsN0 regime, the aligned-sample estimator can
achieve superior test accuracy provided that the phase misalignment is
non-severe. In contrast, the ML estimator does not work well due to the error
propagation and noise enhancement in the estimation process. 2) In the high
EsN0 regime, the ML estimator attains the optimal learning performance
regardless of the severity of phase misalignment. On the other hand, the
aligned-sample estimator suffers from a test-accuracy loss caused by phase
misalignment.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:19:56 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 02:34:27 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 16:43:06 GMT""}]","2021-09-09"
"2102.13605","Yigit Tuncel","Yigit Tuncel, Ganapati Bhat, Jaehyun Park, Umit Ogras","ECO: Enabling Energy-Neutral IoT Devices through Runtime Allocation of
  Harvested Energy",,,,,"eess.SY cs.AI cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Energy harvesting offers an attractive and promising mechanism to power
low-energy devices. However, it alone is insufficient to enable an
energy-neutral operation, which can eliminate tedious battery charging and
replacement requirements. Achieving an energy-neutral operation is challenging
since the uncertainties in harvested energy undermine the quality of service
requirements. To address this challenge, we present a runtime energy-allocation
framework that optimizes the utility of the target device under energy
constraints using a rollout algorithm, which is a sequential approach to solve
dynamic optimization problems. The proposed framework uses an efficient
iterative algorithm to compute initial energy allocations at the beginning of a
day. The initial allocations are then corrected at every interval to compensate
for the deviations from the expected energy harvesting pattern. We evaluate
this framework using solar and motion energy harvesting modalities and American
Time Use Survey data from 4772 different users. Compared to prior techniques,
the proposed framework achieves up to 35% higher utility even under
energy-limited scenarios. Moreover, measurements on a wearable device prototype
show that the proposed framework has 1000x smaller energy overhead than
iterative approaches with a negligible loss in utility.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:21:25 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 17:58:20 GMT""}]","2021-09-13"
"2102.13606","Akram Touil","Akram Touil, Bar{\i}\c{s} \c{C}akmak, Sebastian Deffner","Ergotropy from quantum and classical correlations","16 pages, 3 figures. Eq. 2 in the published version has a typo,
  please see the current arXiv version for the correct form","J. Phys. A: Math. Theor. 55, 025301 (2022)","10.1088/1751-8121/ac3eba",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is an established fact that quantum coherences have thermodynamic value.
The natural question arises, whether other genuine quantum properties such as
entanglement can also be exploited to extract thermodynamic work. In the
present analysis, we show that the ergotropy can be expressed as a function of
the quantum mutual information, which demonstrates the contributions to the
extractable work from classical and quantum correlations. More specifically, we
analyze bipartite quantum systems with locally thermal states, such that the
only contribution to the ergotropy originates in the correlations. Our findings
are illustrated for a two-qubit system collectively coupled to a thermal bath.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:23:58 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 14:54:00 GMT""}]","2021-12-23"
"2102.13607","Kiavash Satvat","Kiavash Satvat, Maliheh Shirvanian, Nitesh Saxena","PASSAT: Single Password Authenticated Secret-Shared Intrusion-Tolerant
  Storage with Server Transparency",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we introduce PASSAT, a practical system to boost the security
assurance delivered by the current cloud architecture without requiring any
changes or cooperation from the cloud service providers. PASSAT is an
application transparent to the cloud servers that allows users to securely and
efficiently store and access their files stored on public cloud storage based
on a single master password. Using a fast and light-weight XOR secret sharing
scheme, PASSAT secret-shares users' files and distributes them among n publicly
available cloud platforms. To access the files, PASSAT communicates with any k
out of n cloud platforms to receive the shares and runs a secret-sharing
reconstruction algorithm to recover the files. An attacker (insider or
outsider) who compromises or colludes with less than k platforms cannot learn
the user's files or modify the files stealthily. To authenticate the user to
multiple cloud platforms, PASSAT crucially stores the authentication
credentials, specific to each platform on a password manager, protected under
the user's master password. Upon requesting access to files, the user enters
the password to unlock the vault and fetches the authentication tokens using
which PASSAT can interact with cloud storage. Our instantiation of PASSAT based
on (2, 3)-XOR secret sharing of Kurihara et al., implemented with three popular
storage providers, namely, Google Drive, Box, and Dropbox, confirms that our
approach can efficiently enhance the confidentiality, integrity, and
availability of the stored files with no changes on the servers.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:26:05 GMT""}]","2021-03-01"
"2102.13608","Marco Viola","Valentina De Simone, Daniela di Serafino, Jacek Gondzio, Spyridon
  Pougkakiotis, Marco Viola","Sparse Approximations with Interior Point Methods","34 pages, 5 figures, 5 tables",,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale optimization problems that seek sparse solutions have become
ubiquitous. They are routinely solved with various specialized first-order
methods. Although such methods are often fast, they usually struggle with
not-so-well conditioned problems. In this paper, specialized variants of an
interior point-proximal method of multipliers are proposed and analyzed for
problems of this class. Computational experience on a variety of problems,
namely, multi-period portfolio optimization, classification of data coming from
functional Magnetic Resonance Imaging, restoration of images corrupted by
Poisson noise, and classification via regularized logistic regression, provides
substantial evidence that interior point methods, equipped with suitable linear
algebra, can offer a noticeable advantage over first-order approaches.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:26:50 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 06:51:48 GMT""},{""version"":""v3"",""created"":""Thu, 25 Nov 2021 15:33:45 GMT""}]","2021-11-29"
"2102.13609","Vasily Sotnikov","S. Abreu, F. Febres Cordero, H. Ita, B. Page, V. Sotnikov","Leading-Color Two-Loop QCD Corrections for Three-Jet Production at
  Hadron Colliders","Analytic results in ancillary files; link for numerical code in
  references. v3: matches the published version","J. High Energ. Phys. 2021, 95 (2021)","10.1007/JHEP07(2021)095","CERN-TH-2021-023, FR-PHENO-2021-06, MPP-2021-20","hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present the complete set of leading-color two-loop contributions required
to obtain next-to-next-to-leading-order (NNLO) QCD corrections to three-jet
production at hadron colliders. We obtain analytic expressions for a generating
set of finite remainders, valid in the physical region for three-jet
production. The analytic continuation of the known Euclidean-region results is
determined from a small set of numerical evaluations of the amplitudes. We
obtain analytic expressions that are suitable for phenomenological applications
and we present a C++ library for their efficient and stable numerical
evaluation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:27:12 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 18:16:47 GMT""},{""version"":""v3"",""created"":""Sat, 17 Jul 2021 22:25:47 GMT""}]","2021-07-20"
"2102.13610","Thomas Schuster","Rebecca Rothermel, Wladimir Panfilenko, Prateek Sharma, Anne Wald,
  Thomas Schuster, Anne Jung, and Stefan Diebels","A method for determining the parameters in a rheological model for
  viscoelastic materials by minimizing Tikhonov functionals","23 pages, 11 figures, 6 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mathematical models describing the behavior of viscoelastic materials are
often based on evolution equations that measure the change in stress depending
on its material parameters such as stiffness, viscosity or relaxation time. In
this article, we introduce a Maxwell-based rheological model, define the
associated forward operator and the inverse problem in order to determine the
number of Maxwell elements and the material parameters of the underlying
viscoelastic material. We perform a relaxation experiment by applying a strain
to the material and measure the generated stress. Since the measured data
varies with the number of Maxwell elements, the forward operator of the
underlying inverse problem depends on parts of the solution. By introducing
assumptions on the relaxation times, we propose a clustering algorithm to
resolve this problem. We provide the calculations that are necessary for the
minimization process and conclude with numerical results by investigating
unperturbed as well as noisy data. We present different reconstruction
approaches based on minimizing a least squares functional. Furthermore, we look
at individual stress components to analyze different displacement rates.
Finally, we study reconstructions with shortened data sets to obtain assertions
on how long experiments have to be performed to identify conclusive material
parameters.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:28:56 GMT""}]","2021-03-01"
"2102.13611","Raquel Pantojo de Souza","Raquel Pantojo de Souza Bachour, Eduardo Lopes Dias, George Cunha
  Cardoso","Skin color independent robust assessment of capillary refill time","14 pages, 6 figures",,,,"physics.bio-ph physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Capillary refill time (CRT) is a method for evaluating peripheral perfusion
by visual assessment. CRT is especially useful for quick evaluations in the
absence of sophisticated equipment. However, there are repeatability and
reproducibility limitations with CRT, especially for dark skin. To test the
limits of CRT repeatability and skin color independence, we developed a system
and method to perform simple and robust CRT measurements. The system consists
of an RGB camera and an LED lamp, with crossed circular polarizers imaging to
attenuate the light reflected by the superficial layer of the skin. The
capillary refill time is determined using an exponential regression on the
time-dependent green channel mean pixel intensity of the region of interest
after the compression is released. We limited this regression up to a
data-dependent cut-off time, after which we assume the exponential model is
invalid, and used the confidence interval of the uncertainty to develop a
criterion to flag and discard faulty measurements. We tested the system on
twenty-two volunteers with skin phototypes ranging from I to VI on the
Fitzpatrick scale, applying to their forearms a 7 kPa compression for 5 s.
After the release of measurements flagged as inadequate (about 20\% of
measurements) by our regressions, our results indicated good precision, with
high repeatability for all skin phototypes. Approximately 80\% of measurements
fall within $\pm 20\%$ of the individual's expected value for CRT (mean CRT
value). Our results suggest CRT can be used as a quantitative measurement and
encourages further developments for the implementation of a similar method on
smartphone cameras for quick and robust CRT measurements in patients' triage,
monitoring, and telehealth.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:30:02 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 12:59:03 GMT""}]","2022-10-12"
"2102.13612","David Milan","Aria Beaupr\'e, Anthony Dickson, David Milan, Christin Sum","On the inverse hull of a Markov shift","15 pages, 2 figures",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  In this paper we provide an abstract characterization of the inverse hulls of
semigroups associated with Markov shifts. As an application of the
characterization we give an example of Markov shifts that are not conjugate,
but have isomorphic inverse hulls.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:30:16 GMT""}]","2021-03-01"
"2102.13613","Bernhard Haslhofer","Bernhard Haslhofer and Rainer St\""utz and Matteo Romiti and Ross King","GraphSense: A General-Purpose Cryptoasset Analytics Platform",,,,,"cs.CR cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  There is currently an increasing demand for cryptoasset analysis tools among
cryptoasset service providers, the financial industry in general, as well as
across academic fields. At the moment, one can choose between commercial
services or low-level open-source tools providing programmatic access. In this
paper, we present the design and implementation of another option: the
GraphSense Cryptoasset Analytics Platform, which can be used for interactive
investigations of monetary flows and, more importantly, for executing advanced
analytics tasks using a standard data science tool stack. By providing a
growing set of open-source components, GraphSense could ultimately become an
instrument for scientific investigations in academia and a possible response to
emerging compliance and regulation challenges for businesses and organizations
dealing with cryptoassets.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:31:12 GMT""}]","2021-03-01"
"2102.13614","Pablo Spiga","Pablo Spiga","A generalization of Sims conjecture for finite primitive groups and two
  point stabilizers in primitive groups",,,,,"math.GR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a refinement of Sims conjecture concerning the
cardinality of the point stabilizers in finite primitive groups and we make
some progress towards this refinement.
  In this process, when dealing with primitive groups of diagonal type, we
construct a finite primitive group $G$ on $\Omega$ and two distinct points
$\alpha,\beta\in \Omega$ with $G_{\alpha\beta}\unlhd G_\alpha$ and
$G_{\alpha\beta}\ne 1$, where $G_{\alpha}$ is the stabilizer of $\alpha$ in $G$
and $G_{\alpha\beta}$ is the stabilizer of $\alpha$ and $\beta$ in $G$. In
particular, this example gives an answer to a question raised independently by
Peter Cameron and by Alexander Fomin.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:31:41 GMT""}]","2021-03-01"
"2102.13615","Erica Ipocoana","Erica Ipocoana","On a non-isothermal Cahn-Hilliard model for tumor growth",,,,,"math.AP q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce here a new diffuse interface thermodynamically consistent
non-isothermal model for tumor growth in presence of a nutrient in a domain
$\Omega \subset \mathbb{R}^3$. In particular our system describes the growth of
a tumor surrounded by healthy tissues, taking into account changes of
temperature, proliferation of cells, nutrient consumption and apoptosis. Our
aim consists in proving an existence result for weak entropy solutions to our
model.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:32:44 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 08:04:25 GMT""},{""version"":""v3"",""created"":""Fri, 16 Dec 2022 16:00:33 GMT""}]","2022-12-19"
"2102.13616","Tilman Enss","Richard Schmidt and Tilman Enss","Self-stabilized Bose polarons","10 pages, 5 figures","SciPost Phys. 13, 054 (2022)","10.21468/SciPostPhys.13.3.054",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mobile impurity in a Bose-Einstein condensate (BEC) is a paradigmatic
many-body problem. For weak interaction between the impurity and the BEC, the
impurity deforms the BEC only slightly and it is well described within the
Fr\""ohlich model and the Bogoliubov approximation. For strong local attraction
this standard approach, however, fails to balance the local attraction with the
weak repulsion between the BEC particles and predicts an instability where an
infinite number of bosons is attracted toward the impurity. Here we present a
solution of the Bose polaron problem beyond the Bogoliubov approximation which
includes the local repulsion between bosons and thereby stabilizes the Bose
polaron even near and beyond the scattering resonance. We show that the Bose
polaron energy remains bounded from below across the resonance and the size of
the polaron dressing cloud stays finite. Our results demonstrate how the
dressing cloud replaces the attractive impurity potential with an effective
many-body potential that excludes binding. We find that at resonance, including
the effects of boson repulsion, the polaron energy depends universally on the
effective range. Moreover, while the impurity contact is strongly peaked at
positive scattering length, it remains always finite. Our solution highlights
how Bose polarons are self-stabilized by repulsion, providing a mechanism to
understand quench dynamics and nonequilibrium time evolution at strong
coupling.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:35:00 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 16:01:30 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 20:12:28 GMT""},{""version"":""v4"",""created"":""Wed, 29 Jun 2022 14:45:41 GMT""}]","2022-09-14"
"2102.13617","Manabu Kanno","Manabu Kanno, Beno\^it Mignolet, Fran\c{c}oise Remacle, and Hirohiko
  Kono","Identification of an ultrafast internal conversion pathway of pyrazine
  by time-resolved vacuum ultraviolet photoelectron spectrum simulations","30 pages, 8 figures. This article has been submitted to The Journal
  of Chemical Physics",,"10.1063/5.0048900",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The internal conversion from the optically bright S$_2$
($^1$B$_{2\mathrm{u}}$, $\pi\pi^*$) state to the dark S$_1$
($^1$B$_{3\mathrm{u}}$, n$\pi^*$) state in pyrazine is a standard benchmark for
experimental and theoretical studies on ultrafast radiationless decay. Since
2008 a few theoretical groups have suggested significant contributions of other
dark states S$_3$ ($^1$A$_\mathrm{u}$, n$\pi^*$) and S$_4$
($^1$B$_{2\mathrm{g}}$, n$\pi^*$) to the decay of S$_2$. We have previously
reported the results of nuclear wave packet simulations [Phys. Chem. Chem.
Phys. 17, 2012 (2015)] and photoelectron spectrum calculations [Chem. Phys.
515, 704 (2018)] that support the conventional two-state picture. In this
article, the two different approaches, i.e., wave packet simulation and
photoelectron spectrum calculation are combined: We computed the time-resolved
vacuum ultraviolet photoelectron spectrum and photoelectron angular
distribution for the ionization of the wave packet transferred from S$_2$ to
S$_1$. The present results reproduce almost all the characteristic features of
the corresponding experimental time-resolved spectrum [T. Horio et al., J.
Chem. Phys. 145, 044306 (2016)] such as a rapid change from a three-band to
two-band structure. This further supports the existence and character of the
widely accepted pathway (S$_2$ $\rightarrow$ S$_1$) of ultrafast internal
conversion in pyrazine.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:37:23 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 10:41:53 GMT""}]","2021-06-30"
"2102.13618","Christiane Stefanie Lorenz","Christiane S. Lorenz, Lena Funcke, Matthias L\""offler, Erminia
  Calabrese","Reconstruction of the neutrino mass as a function of redshift","18 pages, 4 figures, includes updates to match the version accepted
  by Phys. Rev. D",,"10.1103/PhysRevD.104.123518",,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We reconstruct the neutrino mass as a function of redshift, z, from current
cosmological data using both standard binned priors and linear spline priors
with variable knots. Using cosmic microwave background temperature,
polarization and lensing data, in combination with distance measurements from
baryonic acoustic oscillations and supernovae, we find that the neutrino mass
is consistent with $\sum m_\nu(z)$ = const. We obtain a larger bound on the
neutrino mass at low redshifts coinciding with the onset of dark energy
domination, $\sum m_\nu(z = 0)$ < 1.46 eV (95% CL). This result can be
explained either by the well-known degeneracy between $\sum m_\nu$ and
$\Omega_\Lambda$ at low redshifts, or by models in which neutrino masses are
generated very late in the Universe. We finally convert our results into
cosmological limits for models with non-relativistic neutrino decay and find
$\sum m_\nu$ < 0.21 eV (95% CL), which would be out of reach for the KATRIN
experiment.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:38:15 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 10:14:26 GMT""}]","2021-12-22"
"2102.13619","Tim Zimmermann","Tim Zimmermann, Nico Schwersenz, Massimo Pietroni and Sandro Wimberger","One-Dimensional Fuzzy Dark Matter Models: Structure Growth and
  Asymptotic Dynamics","24 pages, 14 figures, accepted for publication in Physical Review D","Phys. Rev. D 103, 083018 (2021)","10.1103/PhysRevD.103.083018",,"astro-ph.CO cond-mat.quant-gas nlin.PS","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the feasibility of simulating Fuzzy Dark Matter (FDM)
with a reduced number of spatial dimensions. Our aim is to set up a realistic,
yet numerically inexpensive, toy model in $(1+1)$-dimensional space time, that
- under well controlled system conditions - is capable of realizing important
aspects of the full-fledged $(3+1)$-FDM phenomenology by means of
one-dimensional analogues. Based on the coupled, nonlinear and nonlocal
$(3+1)$-Schr\""odinger-Poisson equation under periodic boundary conditions, we
derive two distinct one-dimensional models that differ in their transversal
matter distribution and consequently in their nonlocal interaction along the
single dimension of interest. We show that these discrepancies change the
relaxation process of initial states as well as the asymptotic, i.e.,
thermalized and virialized, equilibrium state. Our investigation includes the
dynamical evolution of artificial initial conditions for non-expanding space,
as well as cosmological initial conditions in expanding space. The findings of
this work are relevant for the interpretation of numerical simulation data
modelling nonrelativistic fuzzy cold dark matter in reduced dimensions, in the
quest for testing such models and for possible laboratory implementations of
them.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:38:43 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 14:10:20 GMT""}]","2021-04-28"
"2102.13620","Himabindu Lakkaraju","Sohini Upadhyay, Shalmali Joshi, Himabindu Lakkaraju","Towards Robust and Reliable Algorithmic Recourse",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  As predictive models are increasingly being deployed in high-stakes decision
making (e.g., loan approvals), there has been growing interest in post hoc
techniques which provide recourse to affected individuals. These techniques
generate recourses under the assumption that the underlying predictive model
does not change. However, in practice, models are often regularly updated for a
variety of reasons (e.g., dataset shifts), thereby rendering previously
prescribed recourses ineffective. To address this problem, we propose a novel
framework, RObust Algorithmic Recourse (ROAR), that leverages adversarial
training for finding recourses that are robust to model shifts. To the best of
our knowledge, this work proposes the first solution to this critical problem.
We also carry out detailed theoretical analysis which underscores the
importance of constructing recourses that are robust to model shifts: 1) we
derive a lower bound on the probability of invalidation of recourses generated
by existing approaches which are not robust to model shifts. 2) we prove that
the additional cost incurred due to the robust recourses output by our
framework is bounded. Experimental evaluation on multiple synthetic and
real-world datasets demonstrates the efficacy of the proposed framework and
supports our theoretical findings.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:38:52 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 14:56:24 GMT""}]","2021-07-14"
"2102.13621","Dante Kalise","Young-Pil Choi, Dante Kalise, Andr\'es A. Peters","Collisionless and Decentralized Formation Control for Strings",,,,,"math.OC cs.MA math.DS nlin.AO","http://creativecommons.org/licenses/by-sa/4.0/","  A decentralized feedback controller for multi-agent systems, inspired by
vehicle platooning, is proposed. The closed-loop resulting from the
decentralized control action has three distinctive features: the generation of
collision-free trajectories, flocking of the system towards a consensus state
in velocity, and asymptotic convergence to a prescribed pattern of distances
between agents. For each feature, a rigorous dynamical analysis is provided,
yielding a characterization of the set of parameters and initial configurations
where collision avoidance, flocking, and pattern formation is guaranteed.
Numerical tests assess the theoretical results presented.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:39:32 GMT""}]","2021-03-01"
"2102.13622","Joshua Spear Mr","Pavithra Rajendran, Alexandros Zenonos, Josh Spear, Rebecca Pope","A Meta-embedding-based Ensemble Approach for ICD Coding Prediction",,,"10.1007/978-3-030-93733-1_26",,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  International Classification of Diseases (ICD) are the de facto codes used
globally for clinical coding. These codes enable healthcare providers to claim
reimbursement and facilitate efficient storage and retrieval of diagnostic
information. The problem of automatically assigning ICD codes has been
approached in literature as a multilabel classification, using neural models on
unstructured data. Our proposed approach enhances the performance of neural
models by effectively training word vectors using routine medical data as well
as external knowledge from scientific articles. Furthermore, we exploit the
geometric properties of the two sets of word vectors and combine them into a
common dimensional space, using meta-embedding techniques. We demonstrate the
efficacy of this approach for a multimodal setting, using unstructured and
structured information. We empirically show that our approach improves the
current state-of-the-art deep learning architectures and benefits ensemble
models.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:49:58 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 12:15:24 GMT""}]","2022-02-22"
"2102.13623","\c{S}aban G\""uven\c{c}","\c{S}aban G\""uven\c{c}","Magnetic Curves in $C$-manifolds",,"International Electronic Journal of Geometry, 15 (1), 145-152,
  (2022)","10.36890/iejg.948817",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study normal magnetic curves in $C$-manifolds. We prove
that magnetic trajectories with respect to the contact magnetic fields are
indeed $\theta_{\alpha }$-slant curves with certain curvature functions. Then,
we give the parametrizations of normal magnetic curves in $\mathbb{R}^{2n+s}$
with its structures as a $C$-manifold.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:52:34 GMT""}]","2022-05-04"
"2102.13624","Jonas Geiping","Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael
  Moeller, Tom Goldstein","What Doesn't Kill You Makes You Robust(er): How to Adversarially Train
  against Data Poisoning","25 pages, 15 figures",,,,"cs.LG cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data poisoning is a threat model in which a malicious actor tampers with
training data to manipulate outcomes at inference time. A variety of defenses
against this threat model have been proposed, but each suffers from at least
one of the following flaws: they are easily overcome by adaptive attacks, they
severely reduce testing performance, or they cannot generalize to diverse data
poisoning threat models. Adversarial training, and its variants, are currently
considered the only empirically strong defense against (inference-time)
adversarial attacks. In this work, we extend the adversarial training framework
to defend against (training-time) data poisoning, including targeted and
backdoor attacks. Our method desensitizes networks to the effects of such
attacks by creating poisons during training and injecting them into training
batches. We show that this defense withstands adaptive attacks, generalizes to
diverse threat models, and incurs a better performance trade-off than previous
defenses such as DP-SGD or (evasion) adversarial training.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:54:36 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 21:53:59 GMT""}]","2022-02-21"
"2102.13625","Haofeng Zhang","Haoxian Chen, Ziyi Huang, Henry Lam, Huajie Qian, Haofeng Zhang","Learning Prediction Intervals for Regression: Generalization and
  Calibration",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the generation of prediction intervals in regression for uncertainty
quantification. This task can be formalized as an empirical constrained
optimization problem that minimizes the average interval width while
maintaining the coverage accuracy across data. We strengthen the existing
literature by studying two aspects of this empirical optimization. First is a
general learning theory to characterize the optimality-feasibility tradeoff
that encompasses Lipschitz continuity and VC-subgraph classes, which are
exemplified in regression trees and neural networks. Second is a calibration
machinery and the corresponding statistical theory to optimally select the
regularization parameter that manages this tradeoff, which bypasses the
overfitting issues in previous approaches in coverage attainment. We
empirically demonstrate the strengths of our interval generation and
calibration algorithms in terms of testing performances compared to existing
benchmarks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 17:55:30 GMT""}]","2021-03-01"
"2102.13626","Noe Caruso","Noe Angelo Caruso, Alessandro Michelangeli","Krylov solvability under perturbations of abstract inverse linear
  problems",,,,,"math.FA cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a solution to an abstract inverse linear problem on Hilbert space is
approximable by finite linear combinations of vectors from the cyclic subspace
associated with the datum and with the linear operator of the problem, the
solution is said to be a Krylov solution, i.e., it belongs to the Krylov
subspace of the problem. Krylov solvability of the inverse problem allows for
solution approximations that, in applications, correspond to the very efficient
and popular Krylov subspace methods. We study here the possible behaviours of
persistence, gain, or loss of Krylov solvability under suitable small
perturbations of the inverse problem -- the underlying motivations being the
stability or instability of Krylov methods under small noise or uncertainties,
as well as the possibility to decide a priori whether an inverse problem is
Krylov solvable by investigating a potentially easier, perturbed problem. We
present a whole scenario of occurrences in the first part of the work. In the
second, we exploit the weak gap metric induced, in the sense of Hausdorff
distance, by the Hilbert weak topology, in order to conveniently monitor the
distance between perturbed and unperturbed Krylov subspaces.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:00:23 GMT""}]","2021-03-01"
"2102.13627","Andrii Gudyma Dr.","Andrii Gudyma, Iurii Gudyma","1D Spin-Crossover Molecular Chain with Degenerate States","9 pages, 6 figures","Journal of Applied Physics 129, 123905 (2021)","10.1063/5.0042465",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  A study of the one-dimensional molecular chain (MC) with two single-particle
degenerate states is presented. We establish connection of the MC with the
Ising model with phononic interactions and investigate properties of the model
using a transfer matrix method. The transfer matrix method offers a promising
pathway for simulating such materials properties. The role of degeneracy of
states and phononic interaction being made explicit. We analyze regimes of the
system and parameters of the occurring crossover. Here, we present exact
results for the magnetization per spin, the correlation function and the
effective volume of the system. We demonstrate possibility of existence of two
peaks in the specific heat capacity thermal behavior.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:04:02 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 17:57:39 GMT""}]","2021-03-30"
"2102.13628","Urko Reinosa","Jean-Paul Blaizot, Jan M. Pawlowski, Urko Reinosa","Functional renormalization group and 2PI effective action formalism","80 pages, 22 figures",,"10.1016/j.aop.2021.168549",,"hep-th cond-mat.other cond-mat.str-el hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine two non-perturbative approaches, one based on the
two-particle-irreducible (2PI) action, the other on the functional
renormalization group (fRG), in an effort to develop new non-perturbative
approximations for the field theoretical description of strongly coupled
systems. In particular, we exploit the exact 2PI relations between the
two-point and four-point functions in order to truncate the infinite hierarchy
of equations of the functional renormalization group. The truncation is ""exact""
in two ways. First, the solution of the resulting flow equation is independent
of the choice of the regulator. Second, this solution coincides with that of
the 2PI equations for the two-point and the four-point functions, for any
selection of two-skeleton diagrams characterizing a so-called $\Phi$-derivable
approximation. The transformation of the equations of the 2PI formalism into
flow equations offers new ways to solve these equations in practice, and
provides new insight on certain aspects of their renormalization. It also opens
the possibility to develop approximation schemes going beyond the strict
$\Phi$-derivable ones, as well as new truncation schemes for the fRG hierarchy.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:05:34 GMT""}]","2021-07-14"
"2102.13629","Eanna E. Flanagan","Eanna E Flanagan","Infrared Effects in the Late Stages of Black Hole Evaporation","41 pages, 1 figure",,"10.1007/JHEP07(2021)137",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a black hole evaporates, each outgoing Hawking quantum carries away some
of the black holes asymptotic charges associated with the extended
Bondi-Metzner-Sachs group. These include the Poincar\'e charges of energy,
linear momentum, intrinsic angular momentum, and orbital angular momentum or
center-of-mass charge, as well as extensions of these quantities associated
with supertranslations and super-Lorentz transformations, namely supermomentum,
superspin and super center-of-mass charges (also known as soft hair). Since
each emitted quantum has fluctuations that are of order unity, fluctuations in
the black hole's charges grow over the course of the evaporation. We estimate
the scale of these fluctuations using a simple model. The results are, in
Planck units: (i) The black hole position has a uncertainty of $\sim M_i^2$ at
late times, where $M_i$ is the initial mass (previously found by Page). (ii)
The black hole mass $M$ has an uncertainty of order the mass $M$ itself at the
epoch when $M \sim M_i^{2/3}$, well before the Planck scale is reached.
Correspondingly, the time at which the evaporation ends has an uncertainty of
order $\sim M_i^2$. (iii) The supermomentum and superspin charges are not
independent but are determined from the Poincare charges and the super
center-of-mass charges. (iv) The supertranslation that characterizes the super
center-of-mass charges has fluctuations at multipole orders $l$ of order unity
that that are of order unity in Planck units. At large $l$, there is a power
law spectrum of fluctuations that extends up to $l \sim M_i^2/M$, beyond which
the fluctuations fall off exponentially, with corresponding total rms shear
tensor fluctuations $\sim M_i M^{-3/2}$.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:09:45 GMT""}]","2021-08-04"
"2102.13630","Leela Ganesh Chandra Lakkaraju","Leela Ganesh Chandra Lakkaraju, Shiladitya Mal, Aditi Sen De","Randomness Amplification under Simulated PT-symmetric Evolution","7 + epsilon pages, 3 figures",,,,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  PT-symmetric quantum theory does not require the Hermiticity property of
observables and hence allows a rich class of dynamics. Based on PT-symmetric
quantum theory, various counter-intuitive phenomena like faster evolution than
that allowed in standard quantum mechanics, single-shot discrimination of
nonorthogonal states has been reported invoking Gedanken experiments. By
exploiting open-system experimental set-up as well as by computing the
probability of distinguishing two states, we prove here that if a source
produces an entangled state shared between two parties, Alice and Bob, situated
in a far-apart location, the information about the operations performed by
Alice whose subsystem evolves according to PT-symmetric Hamiltonian can be
gathered by Bob, if the density matrix is in complex Hilbert space. Employing
quantum simulation of PT-symmetric evolution, feasible with currently available
technologies, we also propose a scheme of sharing quantum random bit-string
between two parties when one of them has access to a source generating
pseudo-random numbers. We find evidence that the task becomes more efficient
with the increase of dimension.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:10:01 GMT""}]","2021-03-01"
"2102.13631","Zhaozhuo Xu","Zhaozhuo Xu, Aditya Desai, Menal Gupta, Anu Chandran, Antoine
  Vial-Aussavy, Anshumali Shrivastava","Beyond Convolutions: A Novel Deep Learning Approach for Raw Seismic Data
  Ingestion",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional seismic processing workflows (SPW) are expensive, requiring over
a year of human and computational effort. Deep learning (DL) based data-driven
seismic workflows (DSPW) hold the potential to reduce these timelines to a few
minutes. Raw seismic data (terabytes) and required subsurface prediction
(gigabytes) are enormous. This large-scale, spatially irregular time-series
data poses seismic data ingestion (SDI) as an unconventional yet fundamental
problem in DSPW. Current DL research is limited to small-scale simplified
synthetic datasets as they treat seismic data like images and process them with
convolution networks. Real seismic data, however, is at least 5D. Applying 5D
convolutions to this scale is computationally prohibitive. Moreover, raw
seismic data is highly unstructured and hence inherently non-image like. We
propose a fundamental shift to move away from convolutions and introduce SESDI:
Set Embedding based SDI approach. SESDI first breaks down the mammoth task of
large-scale prediction into an efficient compact auxiliary task. SESDI
gracefully incorporates irregularities in data with its novel model
architecture. We believe SESDI is the first successful demonstration of
end-to-end learning on real seismic data. SESDI achieves SSIM of over 0.8 on
velocity inversion task on real proprietary data from the Gulf of Mexico and
outperforms the state-of-the-art U-Net model on synthetic datasets.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:12:53 GMT""}]","2021-03-01"
"2102.13632","Maksim Dolgopolik","M.V. Dolgopolik","Exact penalty functions with multidimensional penalty parameter and
  adaptive penalty updates","In the second version, a number of small mistakes found in the paper
  was corrected","Optimization Letters, 16:4 (2022) 1281-1300","10.1007/s11590-021-01777-2",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general theory of exact penalty functions with vectorial
(multidimensional) penalty parameter for optimization problems in infinite
dimensional spaces. In comparison with the scalar case, the use of vectorial
penalty parameters provides much more flexibility, allows one to adaptively and
independently take into account the violation of each constraint during an
optimization process, and often leads to a better overall performance of an
optimization method using an exact penalty function. We obtain sufficient
conditions for the local and global exactness of penalty functions with
vectorial penalty parameters and study convergence of global exact penalty
methods with several different penalty updating strategies. In particular, we
present a new algorithmic approach to an analysis of the global exactness of
penalty functions, which contains a novel characterisation of the global
exactness property in terms of behaviour of sequences generated by certain
optimization methods.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:14:01 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 13:09:16 GMT""},{""version"":""v3"",""created"":""Wed, 5 Oct 2022 23:35:19 GMT""}]","2022-10-07"
"2102.13633","Volker Karle","Volker Karle, Maksym Serbyn, Alexios A. Michailidis","Area-law entangled eigenstates from nullspaces of local Hamiltonians",,"Phys. Rev. Lett. 127, 060602 (2021)","10.1103/PhysRevLett.127.060602",,"quant-ph cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Eigenstate thermalization in quantum many-body systems implies that
eigenstates at high energy are similar to random vectors. Identifying systems
where at least some eigenstates are non-thermal is an outstanding question. In
this work we show that interacting quantum models that have a nullspace -- a
degenerate subspace of eigenstates at zero energy (zero modes), which
corresponds to infinite temperature, provide a route to non-thermal
eigenstates. We analytically show the existence of a zero mode which can be
represented as a matrix product state for a certain class of local
Hamiltonians. In the more general case we use a subspace disentangling
algorithm to generate an orthogonal basis of zero modes characterized by
increasing entanglement entropy. We show evidence for an area-law entanglement
scaling of the least entangled zero mode in the broad parameter regime, leading
to a conjecture that all local Hamiltonians with the nullspace feature zero
modes with area-law entanglement scaling, and as such, break the strong
thermalization hypothesis. Finally, we find zero-modes in constrained models
and propose setup for observing their experimental signatures.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:17:18 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 15:07:09 GMT""}]","2021-09-21"
"2102.13634","L\'eonard Von Niederh\""ausern","Luce Brotcorne, S\'ebastien Lepaul and L\'eonard von Niederh\""ausern","A Rolling Horizon Approach for a Bilevel Stochastic Pricing Problem for
  Demand-Side Management","40 pages, 15 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  To guarantee the well-functioning of electricity distribution networks, it is
crucial to constantly ensure the demand-supply balance. To do this, one can
control the means of production, but also influence the demand: demand-side
management becomes more and more popular as the demand keeps increasing and
getting more chaotic. In this work, we propose a bilevel model involving an
energy supplier and a smart grid operator (SGO): the supplier induces shifts of
the load controlled by the SGO by offering time-dependent prices. We assume
that the SGO has contracts with consumers and decides their consumption
schedule, guaranteeing that the inconvenience induced by the load shifts will
not overcome the related financial benefits. Furthermore, we assume that the
SGO manages a source of renewable energy (RE), which leads us to consider a
stochastic bilevel model, as the generation of RE is by nature highly
unpredictable. To cope with the issue of large problem sizes, we design a
rolling horizon algorithm that can be applied in a real context.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:18:15 GMT""}]","2021-03-01"
"2102.13635","Issam Hammad","Issam Hammad, Ryan Simpson, Hippolyte Djonon Tsague, and Sarah Hall","Using Deep Learning to Automate the Detection of Flaws in Nuclear Fuel
  Channel UT Scans",,,"10.1109/TUFFC.2021.3112078",,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Nuclear reactor inspections are critical to ensure the safety and reliability
of a nuclear facility's operation. In Canada, Ultrasonic Testing (UT) is used
to inspect the health of pressure tubes which are part of Canada's Deuterium
Uranium (CANDU) reactor's fuel channels. Currently, analysis of UT scans is
performed by manual visualization and measurement to locate, characterize, and
disposition flaws. Therefore, there is motivation to develop an automated
method that is fast and accurate. In this paper, a proof of concept (PoC) that
automates the detection of flaws in nuclear fuel channel UT scans using a
convolutional neural network (CNN) is presented. The CNN model was trained
after constructing a dataset using historical UT scans and the corresponding
inspection results. The requirement for this prototype was to identify the
location of at least a portion of each flaw in UT scans while minimizing false
positives (FPs). The proposed CNN model achieves this target by automatically
identifying at least a portion of each flaw where further manual analysis is
performed to identify the width, the length, and the type of the flaw.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:19:07 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 00:43:27 GMT""}]","2021-10-08"
"2102.13636","Georg Krempl","Thomas T. Kok and Rachel M. Brouwer and Rene M. Mandl and Hugo G.
  Schnack and Georg Krempl","Active Selection of Classification Features","Accepted for publication at the 19th Intelligent Data Analysis
  Symposium, 2021. The final authenticated publication will be made available
  online at springer.com",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Some data analysis applications comprise datasets, where explanatory
variables are expensive or tedious to acquire, but auxiliary data are readily
available and might help to construct an insightful training set. An example is
neuroimaging research on mental disorders, specifically learning a
diagnosis/prognosis model based on variables derived from expensive Magnetic
Resonance Imaging (MRI) scans, which often requires large sample sizes.
Auxiliary data, such as demographics, might help in selecting a smaller sample
that comprises the individuals with the most informative MRI scans. In active
learning literature, this problem has not yet been studied, despite promising
results in related problem settings that concern the selection of instances or
instance-feature pairs.
  Therefore, we formulate this complementary problem of Active Selection of
Classification Features (ASCF): Given a primary task, which requires to learn a
model f: x-> y to explain/predict the relationship between an
expensive-to-acquire set of variables x and a class label y. Then, the
ASCF-task is to use a set of readily available selection variables z to select
these instances, that will improve the primary task's performance most when
acquiring their expensive features z and including them to the primary training
set.
  We propose two utility-based approaches for this problem, and evaluate their
performance on three public real-world benchmark datasets. In addition, we
illustrate the use of these approaches to efficiently acquire MRI scans in the
context of neuroimaging research on mental disorders, based on a simulated
study design with real MRI data.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:19:08 GMT""}]","2021-03-01"
"2102.13637","Gabriel Hetet","M. Perdriat, P. Huillery, C. Pellet-Mary, G. H\'etet","Angle Locking of a Levitating Diamond using Spin-Diamagnetism","13 pages",,"10.1103/PhysRevLett.128.117203",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The negatively charged nitrogen-vacancy (NV) center in nano- or micro-
diamonds has emerged as a promising magnetic field sensor, as a candidate for
hyper-polarizing paramagnetic species, as well as a tool for spin-mechanics at
the nanoscale. However, NV-doped diamonds are presently not straightforwardly
employable for these applications in a liquid or when levitating under
atmospheric pressures due to the random angular Brownian motion which tends to
rotate the NV quantization axis over the course of the measurments. Here, we
report on angle locking of the crystalline axis of a trapped micro-diamond
along an external magnetic field. Specifically, we use spin population
inversion after a ground state level crossing of the NV center to turn the
diamond into a diamagnet. The diamond crystalline axis naturally aligns to the
magnetic field with high precision and in the absence of micro-wave, offering
bright prospects for applications in biology and spin-mechanical platforms.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:30:04 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 07:38:20 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 17:32:11 GMT""}]","2022-04-06"
"2102.13638","Marinho Bertanha","Marinho Bertanha, EunYi Chung","Permutation Tests at Nonparametric Rates","One PDF file contains main paper (35 pages) plus supplement (64
  pages)",,,,"econ.EM math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical two-sample permutation tests for equality of distributions have
exact size in finite samples, but they fail to control size for testing
equality of parameters that summarize each distribution. This paper proposes
permutation tests for equality of parameters that are estimated at root-$n$ or
slower rates. Our general framework applies to both parametric and
nonparametric models, with two samples or one sample split into two subsamples.
Our tests have correct size asymptotically while preserving exact size in
finite samples when distributions are equal. They have no loss in local
asymptotic power compared to tests that use asymptotic critical values. We
propose confidence sets with correct coverage in large samples that also have
exact coverage in finite samples if distributions are equal up to a
transformation. We apply our theory to four commonly-used hypothesis tests of
nonparametric functions evaluated at a point. Lastly, simulations show good
finite sample properties, and two empirical examples illustrate our tests in
practice.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:30:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 01:46:36 GMT""},{""version"":""v3"",""created"":""Wed, 20 Apr 2022 23:04:43 GMT""}]","2022-04-22"
"2102.13639","Bronson Lim","Bronson Lim and Franco Rota","Motivic Semiorthogonal Decompositions for Abelian Varieties","21 pages, comments welcome!",,,,"math.AG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Suppose $G$ is a finite group acting on an Abelian variety $A$ such that the
coarse moduli $A/G$ is smooth. Using the recent classification result due to
Auffarth, Lucchini, and Quezada, we construct a motivic semiorthogonal
decomposition for $\mathcal{D}[A/G]$ provided $G = T\rtimes H$ with $T$ a
subgroup of translations and $H$ is a subgroup of group automorphisms.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:32:07 GMT""}]","2021-03-01"
"2102.13640","Jakob Heiss","Jakob Heiss, Jakob Weissteiner, Hanna Wutte, Sven Seuken, Josef
  Teichmann","NOMU: Neural Optimization-based Model Uncertainty","9 pages + appendix","Proceedings of the 39th International Conference on Machine
  Learning, PMLR 162:8708-8758, 2022",,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study methods for estimating model uncertainty for neural networks (NNs)
in regression. To isolate the effect of model uncertainty, we focus on a
noiseless setting with scarce training data. We introduce five important
desiderata regarding model uncertainty that any method should satisfy. However,
we find that established benchmarks often fail to reliably capture some of
these desiderata, even those that are required by Bayesian theory. To address
this, we introduce a new approach for capturing model uncertainty for NNs,
which we call Neural Optimization-based Model Uncertainty (NOMU). The main idea
of NOMU is to design a network architecture consisting of two connected
sub-NNs, one for model prediction and one for model uncertainty, and to train
it using a carefully-designed loss function. Importantly, our design enforces
that NOMU satisfies our five desiderata. Due to its modular architecture, NOMU
can provide model uncertainty for any given (previously trained) NN if given
access to its training data. We evaluate NOMU in various regressions tasks and
noiseless Bayesian optimization (BO) with costly evaluations. In regression,
NOMU performs at least as well as state-of-the-art methods. In BO, NOMU even
outperforms all considered benchmarks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:34:43 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 16:53:19 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 22:00:03 GMT""},{""version"":""v4"",""created"":""Sat, 23 Jul 2022 20:29:03 GMT""},{""version"":""v5"",""created"":""Sat, 11 Mar 2023 21:27:41 GMT""}]","2023-03-14"
"2102.13641","Kevin Kellinsky-Gonzalez","Ricardo Estrada and Kevin Kellinsky-Gonzalez","Distributional Point Values and Delta Sequences","17 Pages",,,,"math.FA","http://creativecommons.org/publicdomain/zero/1.0/","  Recently Sasane defined a notion of evaluating a distribution at a point
using delta sequences. In this paper, we explore the relationship between
generalizations of his definition and the standard definition of distributional
point values. This allows us to obtain a description of distributional point
values via delta sequences and a characterization of when a distribution is
actually a regular distribution given by bounded function. We also give a
characterization of limits in a continuous variable by the existence of the
limits of certain sequences.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:38:41 GMT""}]","2021-03-01"
"2102.13642","Matthias Bentert","Matthias Bentert, Robert Bredereck, P\'eter Gy\""orgyi, Andrzej
  Kaczmarczyk, Rolf Niedermeier","A Multivariate Complexity Analysis of the Material Consumption
  Scheduling Problem","Accepted for publication in The Thirty-Fifth AAAI Conference on
  Artificial Intelligence (AAAI-21)",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The NP-hard MATERIAL CONSUMPTION SCHEDULING Problem and closely related
problems have been thoroughly studied since the 1980's. Roughly speaking, the
problem deals with minimizing the makespan when scheduling jobs that consume
non-renewable resources. We focus on the single-machine case without
preemption: from time to time, the resources of the machine are (partially)
replenished, thus allowing for meeting a necessary pre-condition for processing
further jobs, each of which having individual resource demands. We initiate a
systematic exploration of the parameterized (exact) complexity landscape of the
problem, providing parameterized tractability as well as intractability
results. Doing so, we mainly investigate how parameters related to the resource
supplies influence the computational solvability. Thereby, we get a deepened
understanding of the algorithmic complexity of this fundamental scheduling
problem.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:40:21 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 18:15:03 GMT""}]","2021-03-15"
"2102.13643","Chaobing Song","Chaobing Song, Stephen J. Wright and Jelena Diakonikolas","Variance Reduction via Primal-Dual Accelerated Dual Averaging for
  Nonsmooth Convex Finite-Sums","33 pages, 18 figures",,,,"math.OC cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study structured nonsmooth convex finite-sum optimization that appears
widely in machine learning applications, including support vector machines and
least absolute deviation. For the primal-dual formulation of this problem, we
propose a novel algorithm called \emph{Variance Reduction via Primal-Dual
Accelerated Dual Averaging (\vrpda)}. In the nonsmooth and general convex
setting, \vrpda~has the overall complexity $O(nd\log\min \{1/\epsilon, n\} +
d/\epsilon )$ in terms of the primal-dual gap, where $n$ denotes the number of
samples, $d$ the dimension of the primal variables, and $\epsilon$ the desired
accuracy. In the nonsmooth and strongly convex setting, the overall complexity
of \vrpda~becomes $O(nd\log\min\{1/\epsilon, n\} + d/\sqrt{\epsilon})$ in terms
of both the primal-dual gap and the distance between iterate and optimal
solution. Both these results for \vrpda~improve significantly on
state-of-the-art complexity estimates, which are $O(nd\log \min\{1/\epsilon,
n\} + \sqrt{n}d/\epsilon)$ for the nonsmooth and general convex setting and
$O(nd\log \min\{1/\epsilon, n\} + \sqrt{n}d/\sqrt{\epsilon})$ for the nonsmooth
and strongly convex setting, in a much more simple and straightforward way.
Moreover, both complexities are better than \emph{lower} bounds for general
convex finite sums that lack the particular (common) structure that we
consider. Our theoretical results are supported by numerical experiments, which
confirm the competitive performance of \vrpda~compared to state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:40:58 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 16:37:05 GMT""}]","2021-04-08"
"2102.13644","Aneeq Zia","Aneeq Zia, Kiran Bhattacharyya, Xi Liu, Ziheng Wang, Satoshi Kondo,
  Emanuele Colleoni, Beatrice van Amsterdam, Razeen Hussain, Raabid Hussain,
  Lena Maier-Hein, Danail Stoyanov, Stefanie Speidel, and Anthony Jarc","Surgical Visual Domain Adaptation: Results from the MICCAI 2020
  SurgVisDom Challenge","Results from SurgVisDom 2020 challenge held at MICCAI 2020",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Surgical data science is revolutionizing minimally invasive surgery by
enabling context-aware applications. However, many challenges exist around
surgical data (and health data, more generally) needed to develop context-aware
models. This work - presented as part of the Endoscopic Vision (EndoVis)
challenge at the Medical Image Computing and Computer Assisted Intervention
(MICCAI) 2020 conference - seeks to explore the potential for visual domain
adaptation in surgery to overcome data privacy concerns. In particular, we
propose to use video from virtual reality (VR) simulations of surgical
exercises in robotic-assisted surgery to develop algorithms to recognize tasks
in a clinical-like setting. We present the performance of the different
approaches to solve visual domain adaptation developed by challenge
participants. Our analysis shows that the presented models were unable to learn
meaningful motion based features form VR data alone, but did significantly
better when small amount of clinical-like data was also made available. Based
on these results, we discuss promising methods and further work to address the
problem of visual domain adaptation in surgical data science. We also release
the challenge dataset publicly at https://www.synapse.org/surgvisdom2020.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:45:28 GMT""}]","2021-03-01"
"2102.13645","Davood Karimi","Davood Karimi, Serge Vasylechko, Ali Gholipour","Convolution-Free Medical Image Segmentation using Transformers",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Like other applications in computer vision, medical image segmentation has
been most successfully addressed using deep learning models that rely on the
convolution operation as their main building block. Convolutions enjoy
important properties such as sparse interactions, weight sharing, and
translation equivariance. These properties give convolutional neural networks
(CNNs) a strong and useful inductive bias for vision tasks. In this work we
show that a different method, based entirely on self-attention between
neighboring image patches and without any convolution operations, can achieve
competitive or better results. Given a 3D image block, our network divides it
into $n^3$ 3D patches, where $n=3 \text{ or } 5$ and computes a 1D embedding
for each patch. The network predicts the segmentation map for the center patch
of the block based on the self-attention between these patch embeddings. We
show that the proposed model can achieve segmentation accuracies that are
better than the state of the art CNNs on three datasets. We also propose
methods for pre-training this model on large corpora of unlabeled images. Our
experiments show that with pre-training the advantage of our proposed network
over CNNs can be significant when labeled training data is small.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:49:13 GMT""},{""version"":""v2"",""created"":""Sun, 3 Apr 2022 16:30:11 GMT""}]","2022-04-05"
"2102.13646","Ievgen Arkhipov","Ievgen I. Arkhipov, Fabrizio Minganti, Adam Miranowicz, Franco Nori","Generating high-order quantum exceptional points in synthetic dimensions","14 pages","Phys. Rev. A 104, 012205 (2021)","10.1103/PhysRevA.104.012205",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, there has been intense research in proposing and developing various
methods for constructing high-order exceptional points (EPs) in dissipative
systems. These EPs can possess a number of intriguing properties related to,
e.g., chiral transport and enhanced sensitivity. Previous proposals to realize
non-Hermitian Hamiltonians (NHHs) with high-order EPs have been mainly based on
either direct construction of spatial networks of coupled modes or utilization
of synthetic dimensions, e.g., of mapping spatial lattices to time or
photon-number space. Both methods rely on the construction of effective NHHs
describing classical or postselected quantum fields, which neglect the effects
of quantum jumps, and which, thus, suffer from a scalability problem in the
{\it quantum regime}, when the probability of quantum jumps increases with the
number of excitations and dissipation rate. Here, by considering the full
quantum dynamics of a quadratic Liouvillian superoperator, we introduce a
simple and effective method for engineering NHHs with high-order quantum EPs,
derived from evolution matrices of system operators moments. That is, by
quantizing higher-order moments of system operators, e.g., of a quadratic
two-mode system, the resulting evolution matrices can be interpreted as
alternative NHHs describing, e.g., a spatial lattice of coupled resonators,
where spatial sites are represented by high-order field moments in the
synthetic space of field moments. As an example, we consider a $U(1)$-symmetric
quadratic Liouvillian describing a {\it bimodal} cavity with incoherent mode
coupling, which can also possess anti-$\cal PT$-symmetry, whose field moment
dynamics can be mapped to an NHH governing a spatial {\it network} of coupled
resonators with high-order EPs.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:50:21 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 07:14:57 GMT""}]","2021-07-12"
"2102.13647","Sebastian Weichwald","Alexander G. Reisach, Christof Seiler, Sebastian Weichwald","Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy To
  Game","accepted at the 35th Conference on Neural Information Processing
  Systems (NeurIPS), 2021; cf. https://openreview.net/forum?id=wEOlVzVhMW_",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulated DAG models may exhibit properties that, perhaps inadvertently,
render their structure identifiable and unexpectedly affect structure learning
algorithms. Here, we show that marginal variance tends to increase along the
causal order for generically sampled additive noise models. We introduce
varsortability as a measure of the agreement between the order of increasing
marginal variance and the causal order. For commonly sampled graphs and model
parameters, we show that the remarkable performance of some continuous
structure learning algorithms can be explained by high varsortability and
matched by a simple baseline method. Yet, this performance may not transfer to
real-world data where varsortability may be moderate or dependent on the choice
of measurement scales. On standardized data, the same algorithms fail to
identify the ground-truth DAG or its Markov equivalence class. While
standardization removes the pattern in marginal variance, we show that data
generating processes that incur high varsortability also leave a distinct
covariance pattern that may be exploited even after standardization. Our
findings challenge the significance of generic benchmarks with independently
drawn parameters. The code is available at
https://github.com/Scriddie/Varsortability.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:52:27 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 14:55:06 GMT""},{""version"":""v3"",""created"":""Wed, 10 Nov 2021 14:10:12 GMT""}]","2021-11-11"
"2102.13648","The CMS Collaboration","CMS Collaboration","Study of Drell-Yan dimuon production in proton-lead collisions at
  $\sqrt{s_\mathrm{NN}} =$ 8.16 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/HIN-18-003
  (CMS Public Pages)","JHEP 05 (2021) 182","10.1007/JHEP05(2021)182","CMS-HIN-18-003, CERN-EP-2021-028","hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Differential cross sections for the Drell-Yan process, including Z boson
production, using the dimuon decay channel are measured in proton-lead (pPb)
collisions at a nucleon-nucleon centre-of-mass energy of 8.16 TeV. A data
sample recorded with the CMS detector at the LHC is used, corresponding to an
integrated luminosity of 173 nb$^{-1}$. The differential cross section as a
function of the dimuon mass is measured in the range 15-600 GeV, for the first
time in proton-nucleus collisions. It is also reported as a function of dimuon
rapidity over the mass ranges 15-60 GeV and 60-120 GeV, and ratios for the
p-going over the Pb-going beam directions are built. In both mass ranges, the
differential cross sections as functions of the dimuon transverse momentum
$p_\mathrm{T}$ and of a geometric variable $\phi^*$ are measured, where
$\phi^*$ highly correlates with $p_\mathrm{T}$ but is determined with higher
precision. In the Z mass region, the rapidity dependence of the data indicate a
modification of the distribution of partons within a lead nucleus as compared
to the proton case. The data are more precise than predictions based upon
current models of parton distributions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:53:47 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 13:14:29 GMT""}]","2021-06-01"
"2102.13649","Kirti Prakash","Kirti Prakash, Benedict Diederich, Stefanie Reichelt, Rainer
  Heintzmann, Lothar Schermelleh","Super-resolution structured illumination microscopy: past, present and
  future",,,"10.1098/rsta.2020.0143",,"physics.optics q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Structured illumination microscopy (SIM) has emerged as an essential
technique for 3D and live-cell super-resolution imaging. However, to date,
there has not been a dedicated workshop or journal issue covering the various
aspects of SIM, from bespoke hardware and software development and the use of
commercial instruments to biological applications. This special issue aims to
recap recent developments as well as outline future trends. In addition to SIM,
we cover related topics such as complementary super-resolution microscopy
techniques, computational imaging, visualisation and image processing methods.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:54:00 GMT""}]","2021-05-12"
"2102.13650","Benedict von Harling","Yann Cado, Benedict von Harling, Eduard Masso, Mariano Quiros","Baryogenesis via gauge field production from a relaxing Higgs","35 pages, 10 figures, 2 tables; v2: small improvements, added
  comments and references, matches published version",,"10.1088/1475-7516/2021/07/049",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the baryon asymmetry of the universe can be explained in models
where the Higgs couples to the Chern-Simons term of the hypercharge group and
is away from the late-time minimum of its potential during inflation. The Higgs
then relaxes toward this minimum once inflation ends which leads to the
production of (hyper)magnetic helicity. We discuss the conditions under which
this helicity can be approximately conserved during its joint evolution with
the thermal plasma. At the electroweak phase transition the helicity is then
converted into a baryon asymmetry by virtue of the chiral anomaly in the
standard model. We propose a simple model which realizes this mechanism and
show that the observed baryon asymmetry of the universe can be reproduced.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:56:56 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 15:51:12 GMT""}]","2021-09-07"
"2102.13651","Baohe Zhang","Baohe Zhang, Raghu Rajan, Luis Pineda, Nathan Lambert, Andr\'e
  Biedenkapp, Kurtland Chua, Frank Hutter, Roberto Calandra","On the Importance of Hyperparameter Optimization for Model-based
  Reinforcement Learning","19 pages, accepted by AISTATS 2021",,,,"cs.LG cs.AI cs.NE cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Model-based Reinforcement Learning (MBRL) is a promising framework for
learning control in a data-efficient manner. MBRL algorithms can be fairly
complex due to the separate dynamics modeling and the subsequent planning
algorithm, and as a result, they often possess tens of hyperparameters and
architectural choices. For this reason, MBRL typically requires significant
human expertise before it can be applied to new problems and domains. To
alleviate this problem, we propose to use automatic hyperparameter optimization
(HPO). We demonstrate that this problem can be tackled effectively with
automated HPO, which we demonstrate to yield significantly improved performance
compared to human experts. In addition, we show that tuning of several MBRL
hyperparameters dynamically, i.e. during the training itself, further improves
the performance compared to using static hyperparameters which are kept fixed
for the whole training. Finally, our experiments provide valuable insights into
the effects of several hyperparameters, such as plan horizon or learning rate
and their influence on the stability of training and resulting rewards.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:57:47 GMT""}]","2021-03-01"
"2102.13652","Niko Koivunen","Juan Carlos Criado, Abdelhak Djouadi, Niko Koivunen, Martti Raidal,
  Hardi Veerm\""ae","Higher-spin particles at high-energy colliders","Published version. 38 pages, 6 figures. Comments welcome",,"10.1007/JHEP05(2021)254",,"hep-ph hep-ex hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using an effective field theory approach for higher-spin fields, we derive
the interactions of colour singlet and electrically neutral particles with a
spin higher than unity, concentrating on the spin-3/2, spin-2, spin-5/2 and
spin-3 cases. We compute the decay rates and production cross sections in the
main channels for spin-3/2 and spin-2 states at both electron-positron and
hadron colliders, and identify the most promising novel experimental signatures
for discovering such particles at the LHC. The discussion is qualitatively
extended to the spin-5/2 and spin-3 cases. Higher-spin particles exhibit a rich
phenomenology and have signatures that often resemble the ones of
supersymmetric and extra-dimensional theories. To enable further studies of
higher-spin particles at collider and beyond, we collect the relevant Feynman
rules and other technical details.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:58:07 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 10:28:29 GMT""}]","2021-06-16"
"2102.13653","Ali Ramezani-Kebrya","Ali Ramezani-Kebrya, Ashish Khisti, Ben Liang","On the Generalization of Stochastic Gradient Descent with Momentum","This entry is redundant and was created in error. See
  arXiv:1809.04564 for the latest version",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While momentum-based methods, in conjunction with stochastic gradient descent
(SGD), are widely used when training machine learning models, there is little
theoretical understanding on the generalization error of such methods. In this
work, we first show that there exists a convex loss function for which
algorithmic stability fails to establish generalization guarantees when SGD
with standard heavy-ball momentum (SGDM) is run for multiple epochs. Then, for
smooth Lipschitz loss functions, we analyze a modified momentum-based update
rule, i.e., SGD with early momentum (SGDEM), and show that it admits an
upper-bound on the generalization error. Thus, our results show that machine
learning models can be trained for multiple epochs of SGDEM with a guarantee
for generalization. Finally, for the special case of strongly convex loss
functions, we find a range of momentum such that multiple epochs of standard
SGDM, as a special form of SGDEM, also generalizes. Extending our results on
generalization, we also develop an upper-bound on the expected true risk, in
terms of the number of training steps, the size of the training set, and the
momentum parameter. Experimental evaluations verify the consistency between the
numerical results and our theoretical bounds and the effectiveness of SGDEM for
smooth Lipschitz loss functions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:58:29 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 18:22:12 GMT""}]","2021-09-27"
"2102.13654","Nicholas Chornay","N. Chornay, N.A. Walton","One star, two star, red star, blue star: an updated planetary nebula
  central star distance catalogue from Gaia EDR3","Accepted for publication in A&A. Main text: 5 pages, 4 figures.
  Appendix contains catalogue with subset of columns; full catalogue to be
  published on CDS","A&A 656, A110 (2021)","10.1051/0004-6361/202142008",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. Planetary nebulae (PNe) are a brief but important phase of stellar
evolution. The study of Galactic PNe has historically been hampered by
uncertain distances, but the parallaxes of PN central stars (CSPNe) measured by
Gaia are improving the situation. Aims. Gaia's Early Data Release 3 (EDR3)
offers higher astrometric precision and greater completeness compared to
previous releases. Taking advantage of these improvements requires that the
CSPNe in the catalogue be accurately identified. Methods. We applied our
automated technique based on the likelihood ratio method to cross match known
PNe with sources in Gaia EDR3, using an empirically derived position and colour
distribution to score candidate matches. Results. We present a catalogue of
over 2000 sources in Gaia EDR3 that our method has identified as likely CSPNe
or compact nebula detections. We show how the more precise parallaxes of these
sources compare to previous PN statistical distances and introduce an approach
to combining them to produce tighter distance constraints. We also discuss
Gaia's handling of close companions and bright nebulae. Conclusions. Gaia is
unlocking new avenues for the study of PNe. The catalogue presented here will
remain valid for the upcoming Gaia Data Release 3 (DR3) and thus provide a
valuable resource for years to come.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:59:16 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 17:55:08 GMT""}]","2021-12-11"
"2102.13655","Martin Wolfgang Winkler","Katherine Freese, Martin Wolfgang Winkler","Chain Early Dark Energy: Solving the Hubble Tension and Explaining
  Today's Dark Energy","20 pages, 6 figures",,"10.1103/PhysRevD.104.083533","UTTG-02-2021, NORDITA-2021-020","astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new model of Early Dark Energy (EDE) as a solution to the Hubble
tension in cosmology, the apparent discrepancy between local measurements of
the Hubble constant $H_0\simeq 74$ km s$^{-1}$ Mpc$^{-1}$ and $H_0\simeq 67$ km
s$^{-1}$ Mpc$^{-1}$ inferred from the Cosmic Microwave Background (CMB). In
Chain EDE, the Universe undergoes a series of first order phase transitions,
starting at a high energy vacuum in a potential, and tunneling down through a
chain of every lower energy metastable minima. As in all EDE models, the
contribution of the vacuum energy to the total energy density of the universe
is initially negligible, but reaches $\sim 10\%$ around matter-radiation
equality, before cosmological data require it to redshift away quickly -- at
least as fast as radiation. We indeed obtain this required behavior with a
series of $N$ tunneling events, and show that for $N>600$ the phase transitions
are rapid enough to allow fast percolation and thereby avoid large scale
anisotropies in the CMB. We construct a specific example of Chain EDE featuring
a scalar field in a quasiperiodic potential (a tilted cosine), which is
ubiquitous in axion physics and, therefore, carries strong theoretical
motivation. Interestingly, the energy difference between vacua can be roughly
the size of today's Dark Energy (meV scale). Therefore, the end result of Chain
EDE could provide a natural explanation of Dark Energy, if the tunneling
becomes extremely slow in the final step before the field reaches zero (or
negative) energy. We discuss a simple mechanism which can stop the scalar field
in the desired minimum. Thus Chain EDE offers the exciting prospect to explain
EDE and Dark Energy by the same scalar field.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:59:27 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 15:53:05 GMT""}]","2021-11-03"
"2102.13656","Allen Scheie","A. Scheie, M. Sanders, Yiming Qiu, T.R. Prisk, R.J. Cava, C. Broholm","Beyond magnons in Nd2ScNbO7: An Ising pyrochlore antiferromagnet with
  all in all out order and random fields","Main text: 11 pages, 9 figures. Appendices: 6 pages and 7 figures","Phys. Rev. B 104, 134418 (2021)","10.1103/PhysRevB.104.134418",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the low temperature magnetic properties of Nd$^{3+}$ pyrochlore
$\rm Nd_2ScNbO_7$. Susceptibility and magnetization show an easy-axis moment,
and heat capacity reveals a phase transition to long range order at
$T_N=371(2)$ mK with a fully recovered $\Delta S = R \ln(2)$, 53\% of it
recovered for $T>T_N$. Elastic neutron scattering shows a long-range
all-in-all-out magnetic order with low-$Q$ diffuse elastic scattering.
Inelastic neutron scattering shows a low-energy flat-band, indicating a
magnetic Hamiltonian similar to $\rm Nd_2Zr_2O_7$. Nuclear hyperfine
excitations measured by ultra-high-resolution neutron backscattering indicates
a distribution of static electronic moments below $T_N$, which may be due to
B-site disorder influencing Nd crystal electric fields. Analysis of heat
capacity data shows an unexpected $T$-linear or $T^{3/2}$ term which is
inconsistent with conventional magnon quasiparticles, but is consistent with
fractionalized spinons or gapless local spin excitations. We use legacy data to
show similar behavior in $\rm Nd_2Zr_2O_7$. Comparing local static moments also
reveals a suppression of the nuclear Schottky anomaly in temperature,
evidencing a fraction of Nd sites with nearly zero static moment, consistent
with exchange-disorder-induced random singlet formation. Taken together, these
measurements suggest an unusual fluctuating magnetic ground state which mimics
a spin-liquid -- but may not actually be one.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:59:58 GMT""}]","2022-08-11"
"2103.00001","Longlong Wu","Longlong Wu, Shinjae Yoo, Ana F. Suzana, Tadesse A. Assefa, Jiecheng
  Diao, Ross J. Harder, Wonsuk Cha, Ian K. Robinson","Three-dimensional Coherent X-ray Diffraction Imaging via Deep
  Convolutional Neural Networks",,"npj Comput Mater 7, 175 (2021)","10.1038/s41524-021-00644-z",,"eess.IV cond-mat.dis-nn cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  As a critical component of coherent X-ray diffraction imaging (CDI), phase
retrieval has been extensively applied in X-ray structural science to recover
the 3D morphological information inside measured particles. Despite meeting all
the oversampling requirements of Sayre and Shannon, current phase retrieval
approaches still have trouble achieving a unique inversion of experimental data
in the presence of noise. Here, we propose to overcome this limitation by
incorporating a 3D Machine Learning (ML) model combining (optional) supervised
learning with transfer learning. The trained ML model can rapidly provide an
immediate result with high accuracy which could benefit real-time experiments,
and the predicted result can be further refined with transfer learning. More
significantly, the proposed ML model can be used without any prior training to
learn the missing phases of an image based on minimization of an appropriate
'loss function' alone. We demonstrate significantly improved performance with
experimental Bragg CDI data over traditional iterative phase retrieval
algorithms.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:47:14 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 23:04:15 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 18:50:02 GMT""}]","2021-10-29"
"2103.00007","Daniel Waddington","Daniel Waddington and Clem Dickey and Moshik Hershcovitch and
  Sangeetha Seshadri","An Architecture for Memory Centric Active Storage (MCAS)","Revision 1.2",,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  The advent of CPU-attached persistent memory technology, such as Intel's
Optane Persistent Memory Modules (PMM), has brought with it new opportunities
for storage. In 2018, IBM Research Almaden began investigating and developing a
new enterprise-grade storage solution directly aimed at this emerging
technology. MCAS (Memory Centric Active Storage) defines an evolved
network-attached key-value store that offers both near-data compute and the
ability to layer enterprise-grade data management services on shared persistent
memory. As a converged memory-storage tier, MCAS moves towards eliminating the
traditional separation of compute and storage, and thereby unifying the data
space. This paper provides an in-depth review of the MCAS architecture and
implementation, as well as general performance results.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 18:12:41 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 01:56:24 GMT""},{""version"":""v3"",""created"":""Fri, 21 May 2021 20:31:04 GMT""}]","2021-05-25"
"2103.00008","Julian May-Mann","Julian May-Mann and Taylor L. Hughes","Topological Dipole Conserving Insulators and Multipolar Responses","28 pages, 16 figures","Phys. Rev. B 104, 085136 (2021)","10.1103/PhysRevB.104.085136",,"cond-mat.str-el hep-th","http://creativecommons.org/licenses/by/4.0/","  Higher order topological insulators (HOTIs) are a novel form of insulating
quantum matter, which are characterized by having gapped boundaries that are
separated by gapless corner or hinge states. Recently, it has been proposed
that the essential features of a large class of HOTIs are captured by
topological multipolar response theories. In this work, we show that these
multipolar responses can be realized in interacting lattice models, which
conserve both charge and dipole. In this work we study several models in both
the strongly interacting and mean-field limits. In $2$D we consider a
ring-exchange model which exhibits a quadrupole response, and can be tuned to a
$C_4$ symmetric higher order topological phase with half-integer quadrupole
moment, as well as half-integer corner charges. We then extend this model to
develop an analytic description of adiabatic dipole pumping in an interacting
lattice model. The quadrupole moment changes during this pumping process, and
if the process is periodic, we show the total change in the quadrupole moment
is quantized as an integer. We also consider two interacting $3$D lattice
models with chiral hinge modes. We show that the chiral hinge modes are heralds
of a recently proposed ""dipolar Chern-Simons"" response, which is related to the
quadrupole response by dimensional reduction. Interestingly, we find that in
the mean field limit, both the $2$D and $3$D interacting models we consider
here are equivalent to known models of non-interacting HOTIs (or boundary
obstructed versions). The self-consistent mean-field theory treatment provides
insight into the connection between free-fermion (mean-field) theories having
vanishing polarization and interacting models where dipole moments are
microscopically conserved.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:00 GMT""}]","2021-08-25"
"2103.00009","Yuber F. Perez-Gonzalez","Kevin J. Kelly, Pedro A. N. Machado, Alberto Marchionni, Yuber F.
  Perez-Gonzalez","LEvEL: Low-Energy Neutrino Experiment at the LHC","30 pages, 15 figures, added clarifying comments, further discussion
  on systematics and other possible detector technologies. Version accepted for
  publication in the JHEP","JHEP08(2021)087","10.1007/JHEP08(2021)087","FERMILAB-PUB-21-046-T, NUHEP-TH/21-01","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We propose the operation of \textbf{LEvEL}, the Low-Energy Neutrino
Experiment at the LHC, a neutrino detector near the Large Hadron Collider Beam
Dump. Such a detector is capable of exploring an intense, low-energy neutrino
flux and can measure neutrino cross sections that have previously never been
observed. These cross sections can inform other future neutrino experiments,
such as those aiming to observe neutrinos from supernovae, allowing such
measurements to accomplish their fundamental physics goals. We perform detailed
simulations to determine neutrino production at the LHC beam dump, as well as
neutron and muon backgrounds. Measurements at a few to ten percent precision of
neutrino-argon charged current and neutrino-nucleus coherent scattering cross
sections are attainable with 100~ton-year and 1~ton-year exposures at LEvEL,
respectively, concurrent with the operation of the High Luminosity LHC. We also
estimate signal and backgrounds for an experiment exploiting the forward
direction of the LHC beam dump, which could measure neutrinos above 100 GeV.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 23:13:11 GMT""}]","2021-09-06"
"2103.00010","Dylan Keating","Dylan Keating and Nicolas B. Cowan","Atmospheric characterization of hot Jupiters using hierarchical models
  of Spitzer observations","11 pages, 7 figures. Accepted for publication by MNRAS. Updated
  analysis to use the correctly calculated brightness temperature uncertainties
  from Baxter (2020). Conclusions in second half of paper changed slightly
  compared to previous version to reflect the new analysis",,"10.1093/mnras/stab2941",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The field of exoplanet atmospheric characterization is trending towards
comparative studies involving many planetary systems, and using Bayesian
hierarchical modelling is a natural next step. Here we demonstrate two use
cases. We first use hierarchical modelling to quantify variability in repeated
observations by reanalyzing a suite of ten Spitzer secondary eclipse
observations of the hot Jupiter XO-3b. We compare three models: one where we
fit ten separate eclipse depths, one where we use a single eclipse depth for
all ten observations, and a hierarchical model. By comparing the Widely
Applicable Information Criterion of each model, we show that the hierarchical
model is preferred over the others. The hierarchical model yields less scatter
across the suite of eclipse depths -- and higher precision on the individual
eclipse depths -- than does fitting the observations separately. We find that
the hierarchical eclipse depth uncertainty is larger than the uncertainties on
the individual eclipse depths, which suggests either slight astrophysical
variability or that single eclipse observations underestimate the true eclipse
depth uncertainty. Finally, we fit a suite of published dayside brightness
measurements for 37 planets using a hierarchical model of brightness
temperature vs irradiation temperature. The hierarchical model gives tighter
constraints on the individual brightness temperatures than the non-hierarchical
model. Although we tested hierarchical modelling on Spitzer eclipse data of hot
Jupiters, it is applicable to observations of smaller planets like hot neptunes
and super earths, as well as for photometric and spectroscopic transit or phase
curve observations.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 20:11:47 GMT""}]","2021-10-20"
"2103.00011","Amit Jamadagni Gangapuram","Amit Jamadagni and Hendrik Weimer","Error-correction properties of an interacting topological insulator","5 pages, 3 figures",,"10.1103/PhysRevB.106.115133",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the phase diagram of a topological insulator model including
antiferromagnetic interactions in the form of an extended Su-Schrieffer Heeger
model. To this end, we employ a recently introduced operational definition of
topological order based on the ability of a system to perform topological error
correction. We show that the necessary error correction statistics can be
obtained efficiently using a Monte-Carlo sampling of a matrix product state
representation of the ground state wave function. Specifically, we identify two
distinct symmetry-protected topological phases corresponding to two different
fully dimerized reference states. Finally, we extend the notion of error
correction to classify thermodynamic phases to those exhibiting local order
parameters, finding a topologically trivial antiferromagnetic phase for
sufficiently strong interactions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:01 GMT""}]","2022-10-05"
"2103.00012","J. Drew Hogg","J. Drew Hogg, Laura Blecha, Christopher S. Reynolds, Krista Lynne
  Smith, and Lisa M. Winter","2MASX J00423991+3017515: An offset active galactic nucleus in an
  interacting system","17 pages, 10 figures, 4 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab576",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a spectroscopic and imaging study of an abnormal active galactic
nucleus (AGN), 2MASX J00423991+3017515. This AGN is newly identified in the
hard X-rays by the Swift BAT All-Sky survey and found in an edge-on disk galaxy
interacting with a nearby companion. Here, we analyze the first optical spectra
obtained for this system (taken in 2011 and 2016), high-resolution imaging
taken with the Hubble Space Telescope and Chandra X-ray Observatory, and 1""
imaging with the Very Large Array. Two unique properties are revealed: the
peaks of the broad Balmer emission lines (associated with gas orbiting very
near the supermassive black hole) are blue shifted from the corresponding
narrow line emission and host galaxy absorption by 1540 km/s, and the AGN is
spatially displaced from the apparent center of its host galaxy by 3.8 kpc. We
explore several scenarios to explain these features, along with other
anomalies, and propose that 2MASX J00423991+3017515 may be an AGN with an
unusually strong wind residing in a uniquely configured major merger, or that
it is an AGN recoiling from either a gravitational ""slingshot"" in a three-body
interaction or from a kick due to the asymmetric emission of gravitational
waves following the coalescence of two progenitor supermassive black holes.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:01 GMT""}]","2021-03-17"
"2103.00013","Barnab\'as Deme","Barnab\'as Deme, Bence Kocsis","A canonical transformation to eliminate resonant perturbations I","Some minor errors have been corrected. Published in AJ",,"10.3847/1538-3881/abfb6d",,"nlin.CD astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study dynamical systems which admit action-angle variables at leading
order which are subject to nearly resonant perturbations. If the frequencies
characterizing the unperturbed system are not in resonance, the long-term
dynamical evolution may be integrated by orbit-averaging over the
high-frequency angles, thereby evolving the orbit-averaged effect of the
perturbations. It is well known that such integrators may be constructed via a
canonical transformation, which eliminates the high frequency variables from
the orbit-averaged quantities. An example of this algorithm in celestial
mechanics is the von Zeipel transformation. However if the perturbations are
inside or close to a resonance, i.e. the frequencies of the unperturbed system
are commensurate, these canonical transformations are subject to divergences.
We introduce a canonical transformation which eliminates the high frequency
phase variables in the Hamiltonian without encountering divergences. This leads
to a well-behaved symplectic integrator. We demonstrate the algorithm through
two examples: a resonantly perturbed harmonic oscillator and the gravitational
three-body problem in mean motion resonance.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 08:29:57 GMT""}]","2022-06-28"
"2103.00014","Christopher Harrison","M.E. Jarvis (MPA/ESO/LMU), C.M. Harrison (Newcastle University), V.
  Mainieri, D.M. Alexander, F. Arrigoni Battaia, G. Calistro Rivera, C.
  Circosta, T. Costa, C. De Breuck, A.C. Edge, A. Girdhar, D. Kakkad, P. Kharb,
  G.B. Lansbury, S.J. Molyneux, D. Mukherjee, J.R. Mullaney, E.P. Farina, Silpa
  S., A.P. Thomson, S.R. Ward","The Quasar Feedback Survey: Discovering hidden Radio-AGN and their
  connection to the host galaxy ionised gas","Accepted for publication in MNRAS. Data products from this paper and
  the survey pilot papers are available through our website:
  https://blogs.ncl.ac.uk/quasarfeedbacksurvey/. The extensive supplementary
  material (containing additional figures and information on individual
  targets) is available for download under ""Ancillary files"" or by downloading
  the source file listed under ""Other formats""",,"10.1093/mnras/stab549",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the first results from the Quasar Feedback Survey, a sample of 42
z<0.2, [O III] luminous AGN (L[O III]>10^42.1 ergs/s) with moderate radio
luminosities (i.e. L(1.4GHz)>10^23.4 W/Hz; median L(1.4GHz)=5.9x10^23 W/Hz).
Using high spatial resolution (~0.3-1 arcsec), 1.5-6 GHz radio images from the
Very Large Array, we find that 67 percent of the sample have spatially extended
radio features, on ~1-60 kpc scales. The radio sizes and morphologies suggest
that these may be lower radio luminosity versions of compact, radio-loud AGN.
By combining the radio-to-infrared excess parameter, spectral index, radio
morphology and brightness temperature, we find radio emission in at least 57
percent of the sample that is associated with AGN-related processes (e.g. jets,
quasar-driven winds or coronal emission). This is despite only 9.5-21 percent
being classified as radio-loud using traditional criteria. The origin of the
radio emission in the remainder of the sample is unclear. We find that both the
established anti-correlation between radio size and the width of the [O III]
line, and the known trend for the most [O III] luminous AGN to be associated
with spatially-extended radio emission, also hold for our sample of moderate
radio luminosity quasars. These observations add to the growing evidence of a
connection between the radio emission and ionised gas in quasar host galaxies.
This work lays the foundation for deeper investigations into the drivers and
impact of feedback in this unique sample.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:03 GMT""}]","2021-03-17"
"2103.00015","Andrew Pierce","Andrew T. Pierce, Yonglong Xie, Seung Hwan Lee, Patrick R. Forrester,
  Di S. Wei, Kenji Watanabe, Takashi Taniguchi, Bertrand I. Halperin, Amir
  Yacoby","Thermodynamics of free and bound magnons in graphene",,,"10.1038/s41567-021-01421-x",,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetry-broken electronic phases support neutral collective excitations. For
example, monolayer graphene in the quantum Hall regime hosts a nearly ideal
ferromagnetic phase at filling factor $\nu=1$ that spontaneously breaks spin
rotation symmetry. This ferromagnet has been shown to support spin-wave
excitations known as magnons which can be generated and detected electrically.
While long-distance magnon propagation has been demonstrated via transport
measurements, important thermodynamic properties of such magnon
populations--including the magnon chemical potential and density--have thus far
proven out of reach of experiments. Here, we present local measurements of the
electron compressibility under the influence of magnons, which reveal a
reduction of the $\nu=1$ gap by up to 20%. Combining these measurements with
estimates of the temperature, our analysis reveals that the injected magnons
bind to electrons and holes to form skyrmions, and it enables extraction of the
free magnon density, magnon chemical potential, and average skyrmion spin. Our
methods furnish a novel means of probing the thermodynamic properties of
charge-neutral excitations that is applicable to other symmetry-broken
electronic phases.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:03 GMT""}]","2022-02-09"
"2103.00016","Francesco Bollati","Francesco Bollati, Giuseppe Lodato, Daniel J. Price, Christophe Pinte","The theory of kinks -- I. A semi-analytic model of velocity
  perturbations due to planet-disc interaction","Submission to MNRAS Accepted",,"10.1093/mnras/stab1145",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  A new technique to detect protoplanets is by observing the kinematics of the
surrounding gas. Gravitational perturbations from a planet produce peculiar
`kinks' in channel maps of different gas species. In this paper, we show that
such kinks can be reproduced using semi-analytic models for the velocity
perturbation induced by a planet. In doing so we i) confirm that the observed
kinks are consistent with the planet-induced wake; ii) show how to quantify the
planet mass from the kink amplitude; in particular, we show that the kink
amplitude scales with the square root of the planet mass for channels far from
the planet velocity, steepening to linear as the channels approach the planet;
iii) show how to extend the theory to include the effect of damping, which may
be needed in order to have localized kinks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:04 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 13:43:38 GMT""}]","2021-05-12"
"2103.00017","Adam Ingram Dr","Adam Ingram, Sara Motta, Suzanne Aigrain, Aris Karastergiou","A self-lensing binary massive black hole interpretation of
  quasi-periodic eruptions","Accepted for publication in MNRAS",,"10.1093/mnras/stab609",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary supermassive black hole (SMBH) systems result from galaxy mergers, and
will eventually coalesce due to gravitational wave (GW) emission if the binary
separation can be reduced to $\lesssim 0.1$ pc by other mechanisms. Here, we
explore a gravitational self-lensing binary SMBH model for the sharp (duration
$\sim 1$ hr), quasi-regular X-ray flares -- dubbed quasi-periodic eruptions --
recently observed from two low mass active galactic nuclei: GSN 069 and RX
J1301.9+2747. In our model, the binary is observed $\sim$edge-on, such that
each SMBH gravitationally lenses light from the accretion disc surrounding the
other SMBH twice per orbital period. The model can reproduce the flare spacings
if the current eccentricity of RX J1301.9+2747 is $\epsilon_0 \gtrsim 0.16$,
implying a merger within $\sim 1000$ yrs. However, we cannot reproduce the
observed flare profiles with our current calculations. Model flares with the
correct amplitude are $\sim 2/5$ the observed duration, and model flares with
the correct duration are $\sim 2/5$ the observed amplitude. Our modelling
yields three distinct behaviours of self-lensing binary systems that can be
searched for in current and future X-ray and optical time-domain surveys: i)
periodic lensing flares, ii) partial eclipses (caused by occultation of the
background mini-disc by the foreground mini-disc), and iii) partial eclipses
with a very sharp in-eclipse lensing flare. Discovery of such features would
constitute very strong evidence for the presence of a supermassive binary, and
monitoring of the flare spacings will provide a measurement of periastron
precession.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:00:12 GMT""}]","2021-03-17"
"2103.00018","Hailong Fu","Hailong Fu, Ke Huang, Kenji Watanabe, Takashi Taniguchi, Jun Zhu","Gapless Spin Wave Transport through a Quantum Canted-Antiferromagnet","17 figures. To appear in PRX","Phys. Rev. X 11, 021012 (2021)","10.1103/PhysRevX.11.021012",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  In the Landau levels of a two-dimensional electron system or when flat bands
are present, e.g. in twisted van der Waals bilayers, strong electron-electron
interaction gives rise to quantum Hall ferromagnetism with spontaneously broken
symmetries in the spin and isospin sectors. Quantum Hall ferromagnets support a
rich variety of low-energy collective excitations that are instrumental to
understand the nature of the magnetic ground states and are also potentially
useful as carriers of quantum information. Probing such collective excitations,
especially their dispersion {\omega}(k), has been experimentally challenging
due to small sample size and measurement constraints. In this work, we
demonstrate an all-electrical approach that integrates a Fabry-P\'erot cavity
with non-equilibrium transport to achieve the excitation, wave vector selection
and detection of spin waves in graphene heterostructures. Our experiments
reveal gapless, linearly dispersed spin wave excitations in the E = 0 Landau
level of bilayer graphene, thus providing direct experimental evidence for a
predicted canted antiferromagnetic order. We show that the gapless spin wave
mode propagates with a high group velocity of several tens of km/s and
maintains phase coherence over a distance of many micrometers. Its dependence
on the magnetic field and temperature agree well with the hydrodynamic theory
of spin waves. These results lay the foundation for the quest of spin
superfluidity in this high-quality material. The resonant cavity technique we
developed offers a powerful and timely method to explore the collective
excitation of many spin and isospin-ordered many-body ground states in van der
Waals heterostructures and open the possibility of engineering magnonic
devices.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:01:36 GMT""}]","2021-05-05"
"2103.00019","Anatole Ertul","Anatole Ertul","Cutoff for the Fredrickson-Andersen one spin facilitated model",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  The Fredrickson-Andersen one spin facilitated model belongs to the class of
Kinetically Constrained Spin Models. It is a non attractive process with
positive spectral gap. In this paper we give a precise result on the relaxation
for this process on an interval $[1,L]$ starting from any initial
configuration. A consequence of this result is that this process exhibits
cutoff at time $L/(2v)$ with window $O(\sqrt{L})$ for a certain positive
constant $v$. The key ingredient is the study of the evolution of the leftmost
empty site in a filled infinite half-line called the front. In the process of
the proof, we improve recent results about the front motion by showing that it
evolves at speed $v$ according to a uniform central limit theorem.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:03:22 GMT""},{""version"":""v2"",""created"":""Sat, 20 Nov 2021 14:39:55 GMT""}]","2021-11-23"
"2103.00020","Jong Wook Kim","Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel
  Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack
  Clark, Gretchen Krueger, Ilya Sutskever","Learning Transferable Visual Models From Natural Language Supervision",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art computer vision systems are trained to predict a fixed set
of predetermined object categories. This restricted form of supervision limits
their generality and usability since additional labeled data is needed to
specify any other visual concept. Learning directly from raw text about images
is a promising alternative which leverages a much broader source of
supervision. We demonstrate that the simple pre-training task of predicting
which caption goes with which image is an efficient and scalable way to learn
SOTA image representations from scratch on a dataset of 400 million (image,
text) pairs collected from the internet. After pre-training, natural language
is used to reference learned visual concepts (or describe new ones) enabling
zero-shot transfer of the model to downstream tasks. We study the performance
of this approach by benchmarking on over 30 different existing computer vision
datasets, spanning tasks such as OCR, action recognition in videos,
geo-localization, and many types of fine-grained object classification. The
model transfers non-trivially to most tasks and is often competitive with a
fully supervised baseline without the need for any dataset specific training.
For instance, we match the accuracy of the original ResNet-50 on ImageNet
zero-shot without needing to use any of the 1.28 million training examples it
was trained on. We release our code and pre-trained model weights at
https://github.com/OpenAI/CLIP.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:04:58 GMT""}]","2021-03-02"
"2103.00021","Carmen Romo-Luque","Carmen Romo-Luque","PETALO: a Time-of-Flight PET with liquid xenon","Proceedings, 4 pages, 4 figures","Nuclear Instruments and Methods in Physics Research Section A:
  Accelerators, Spectrometers, Detectors and Associated Equipment, Volume 958,
  2020, 162397, ISSN 0168-9002","10.1016/j.nima.2019.162397",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid xenon offers several features, which make it suitable for applications
in nuclear medicine, such as high scintillation yield and fast scintillation
decay time. Moreover, being a continuous medium with a uniform response, liquid
xenon allows one to avoid most of the geometrical distortions of conventional
detectors based on scintillating crystals. In this paper, we describe how these
properties have motivated the development of a novel concept for positron
emission tomography scanners with Time-Of-Flight measurement, which combines a
liquid xenon scintillating volume and silicon photomultipliers as sensors. A
Monte Carlo investigation has pointed out that this technology would provide an
excellent intrinsic time resolution, down to 70 ps. Also, the transparency of
liquid xenon to UV and blue wavelengths opens the possibility of exploiting
both scintillation and Cherenkov light for a high-sensitivity positron emission
tomography scanner with Time-Of-Flight capabilities. Monte Carlo simulations
point to a time resolution of 30-50 ps obtained using Cherenkov light. A
prototype is being built to demonstrate the high resolution in energy, time and
reconstruction of spatial coordinates of this concept, using a ring of 30 cm
internal diameter and a depth of 3 cm instrumented with VUV-sensitive silicon
photomultipliers.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:05:43 GMT""}]","2021-03-02"
"2103.00022","Qiongwen Xu","Qiongwen Xu, Michael D. Wong, Tanvi Wagle, Srinivas Narayana, Anirudh
  Sivaraman","Synthesizing Safe and Efficient Kernel Extensions for Packet Processing",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Extended Berkeley Packet Filter (BPF) has emerged as a powerful method to
extend packet-processing functionality in the Linux operating system. BPF
allows users to write code in high-level languages (like C or Rust) and execute
them at specific hooks in the kernel, such as the network device driver. To
ensure safe execution of a user-developed BPF program in kernel context, Linux
uses an in-kernel static checker. The checker allows a program to execute only
if it can prove that the program is crash-free, always accesses memory within
safe bounds, and avoids leaking kernel data.
  BPF programming is not easy. One, even modest-sized BPF programs are deemed
too large to analyze and rejected by the kernel checker. Two, the kernel
checker may incorrectly determine that a BPF program exhibits unsafe behaviors.
Three, even small performance optimizations to BPF code (e.g., 5% gains) must
be meticulously hand-crafted by expert developers. Traditional optimizing
compilers for BPF are often inadequate since the kernel checker's safety
constraints are incompatible with rule-based optimizations.
  We present K2, a program-synthesis-based compiler that automatically
optimizes BPF bytecode with formal correctness and safety guarantees. K2
produces code with 6--26% reduced size, 1.36%--55.03% lower average
packet-processing latency, and 0--4.75% higher throughput (packets per second
per core) relative to the best clang-compiled program, across benchmarks drawn
from Cilium, Facebook, and the Linux kernel. K2 incorporates several
domain-specific techniques to make synthesis practical by accelerating
equivalence-checking of BPF programs by 6 orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:09:04 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 18:09:06 GMT""}]","2021-07-16"
"2103.00023","George H. Choueiri","George H. Choueiri, Jose M. Lopez, Atul Varshney, Sarath Sankar, and
  Bj\""orn Hof","Experimental observation of the origin and structure of elasto-inertial
  turbulence",,,"10.1073/pnas.2102350118",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Turbulence generally arises in shear flows if velocities and hence inertial
forces are sufficiently large. In striking contrast, viscoelastic fluids can
exhibit disordered motion even at vanishing inertia. Intermediate between these
cases, a novel state of chaotic motion, `elasto-inertial turbulence' (EIT), has
been observed in a narrow Reynolds number interval. We here determine the
origin of EIT in experiments and show that characteristic EIT structures can be
detected across an unexpectedly wide range of parameters. Close to onset a
pattern of chevron shaped streaks emerges in excellent agreement with linear
theory. However, the instability can be traced to far lower Reynolds numbers
than permitted by theory. For increasing inertia, a secondary instability gives
rise to a wall mode composed of inclined near wall streaks and shear layers.
This mode persists to what is known as the `maximum drag reduction limit' and
overall EIT is found to dominate viscoelastic flows across more than three
orders of magnitude in Reynolds number.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:09:52 GMT""}]","2022-01-05"
"2103.00024","Kentaro Heya","Kentaro Heya, Naoki Kanazawa","Cross cross resonance gate",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implementation of high-fidelity swapping operations is of vital importance to
execute quantum algorithms on a quantum processor with limited connectivity. We
present an efficient pulse control technique, cross-cross resonance (CCR) gate,
to implement iSWAP and SWAP operations with dispersively-coupled
fixed-frequency transmon qubits. The key ingredient of the CCR gate is
simultaneously driving both of the coupled qubits at the frequency of another
qubit, wherein the fast two-qubit interaction roughly equivalent to the XY
entangling gates is realized without strongly driving the qubits. We develop
the calibration technique for the CCR gate and evaluate the performance of
iSWAP and SWAP gates The CCR gate shows roughly two-fold improvement in the
average gate error and more than 10~\% reduction in gate times from the
conventional decomposition based on the cross resonance gate.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:11:35 GMT""}]","2021-03-02"
"2103.00025","Peide Li","Peide Li and Rejaul Karim and Tapabrata Maiti","TEC: Tensor Ensemble Classifier for Big Data",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor (multidimensional array) classification problem has become very
popular in modern applications such as image recognition and high dimensional
spatio-temporal data analysis. Support Tensor Machine (STM) classifier, which
is extended from the support vector machine, takes CANDECOMP / Parafac (CP)
form of tensor data as input and predicts the data labels. The
distribution-free and statistically consistent properties of STM highlight its
potential in successfully handling wide varieties of data applications.
Training a STM can be computationally expensive with high-dimensional tensors.
However, reducing the size of tensor with a random projection technique can
reduce the computational time and cost, making it feasible to handle large size
tensors on regular machines. We name an STM estimated with randomly projected
tensor as Random Projection-based Support Tensor Machine (RPSTM). In this work,
we propose a Tensor Ensemble Classifier (TEC), which aggregates multiple RPSTMs
for big tensor classification. TEC utilizes the ensemble idea to minimize the
excessive classification risk brought by random projection, providing
statistically consistent predictions while taking the computational advantage
of RPSTM. Since each RPSTM can be estimated independently, TEC can further take
advantage of parallel computing techniques and be more computationally
efficient. The theoretical and numerical results demonstrate the decent
performance of TEC model in high-dimensional tensor classification problems.
The model prediction is statistically consistent as its risk is shown to
converge to the optimal Bayes risk. Besides, we highlight the trade-off between
the computational cost and the prediction risk for TEC model. The method is
validated by extensive simulation and a real data example. We prepare a python
package for applying TEC, which is available at our GitHub.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:15:01 GMT""}]","2021-03-02"
"2103.00026","Jamie Bamber","Jamie Bamber, Oliver J. Tattersall, Katy Clough and Pedro G. Ferreira","The quasi normal modes of growing dirty black holes","14 pages, 1 figure","Phys. Rev. D 103, 124013 (2021)","10.1103/PhysRevD.103.124013",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ringdown of a perturbed black hole contains fundamental information about
space-time in the form of Quasi Normal Modes (QNM). Modifications to general
relativity, or extended profiles of other fields surrounding the black hole, so
called ""black hole hair"", can perturb the QNM frequencies. Previous works have
examined the QNM frequencies of spherically symmetric ""dirty"" black holes -
that is black holes surrounded by arbitrary matter fields. Such analyses were
restricted to static systems, making the assumption that the metric
perturbation was independent of time. However, in most physical cases such
black holes will actually be growing dynamically due to accretion of the
surrounding matter. Here we develop a perturbative analytic method that allows
us to compute for the first time the time dependent QNM deviations of such
growing dirty black holes. Whilst both are small, we show that the change in
QNM frequency due to the accretion can be of the same order or larger than the
change due to the static matter distribution itself, and therefore should not
be neglected in such calculations. We present the case of spherically symmetric
accretion of a complex scalar field as an illustrative example, but the method
has the potential to be extended to more complicated cases.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:15:24 GMT""}]","2021-06-16"
"2103.00027","Luiz Gustavo De Andrade Alves","Hyojun A. Lee and Luiz G. A. Alves and Lu\'is A. Nunes Amaral","Spreader events and the limitations of projected networks for capturing
  dynamics on multipartite networks","14 pages, 6 figures, published in Phys. Rev. E (2021)","Phys. Rev. E 103, 022320 (2021)","10.1103/PhysRevE.103.022320",,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Many systems of scientific interest can be conceptualized as multipartite
networks. Examples include the spread of sexually transmitted infections,
scientific collaborations, human friendships, product recommendation systems,
and metabolic networks. In practice, these systems are often studied after
projection onto a single class of nodes, losing crucial information. Here, we
address a significant knowledge gap by comparing transmission dynamics on
temporal multipartite networks and on their time-aggregated unipartite
projections to determine the impact of the lost information on our ability to
predict the systems' dynamics. We show that the dynamics of transmission models
can be dramatically dissimilar on multipartite networks and on their
projections at three levels: final outcome, the magnitude of the variability
from realization to realization, and overall shape of the temporal trajectory.
We find that the ratio of the number of nodes to the number of active edges
over the time aggregation scale determines the ability of projected networks to
capture the dynamics on the multipartite network. Finally, we explore which
properties of a multipartite network are crucial in generating synthetic
networks that better reproduce the dynamical behavior observed in real
multipartite networks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:23:12 GMT""}]","2021-03-02"
"2103.00028","Tom Klose","Peter K. Friz and Tom Klose","Precise Laplace asymptotics for singular stochastic PDEs: The case of 2D
  gPAM","To appear in Journal of Functional Analysis. In the accepted version,
  we omitted some of the proofs and only sketched some arguments, both to
  streamline the presentation. This arXiv article is the extended version of
  the accepted manuscript and provides all the left out details and complete
  proofs. 85 pages, 3 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We implement a Laplace method for the renormalised solution to the
generalised 2D Parabolic Anderson Model (gPAM) driven by a small spatial white
noise. Our work rests upon Hairer's theory of regularity structures which
allows to generalise classical ideas of Azencott and Ben Arous on path space as
well as Aida and Inahama and Kawabi on rough path space to the space of models.
The technical cornerstone of our argument is a Taylor expansion of the solution
in the noise intensity parameter: We prove precise bounds for its terms and the
remainder and use them to estimate asymptotically irrevelant terms to arbitrary
order. While most of our arguments are not specific to gPAM, we also outline
how to adapt those that are.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:27:07 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 17:12:39 GMT""}]","2022-03-22"
"2103.00029","Michael Schmiedeberg","Matthias Gimperlein and Michael Schmiedeberg","Structural and dynamical properties of gel networks","9 pages, 11 figures","Journal of Chemical Physics 154, 244903 (2021)","10.1063/5.0048816",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The competition of depletion attractions and longer-ranged repulsions between
colloidal particles in colloid-polymer mixtures leads to the formation of
heterogeneous gel-like structures. For instance, gel networks, i.e., states
where the colloids arrange in thin strands that span the whole system occur at
low packing fractions for attractions that are stronger than those at the
binodal line of equilibrium liquid-fluid phase separation. By using Brownian
dynamics simulations we explore the formation, structure, and ageing dynamics
of gel networks. We determine reduced network that focus on the essential
connections in a gel network. We compare the observed properties to those of
bulky gels or cluster fluids. Our results demonstrate that both the structure
as well as the (often slow) dynamics of the stable or meta-stable heterogenous
states in colloid-polymer mixtures possess distinct features on various length
and time scales and thus are richly divers.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:36:50 GMT""}]","2021-06-24"
"2103.00030","Soumyabrata Dev","Mayank Jain, Tarek AlSkaif and Soumyabrata Dev","Validating Clustering Frameworks for Electric Load Demand Profiles","Published in IEEE Transactions on Industrial Informatics 2021",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale deployment of smart meters has made it possible to collect
sufficient and high-resolution data of residential electric demand profiles.
Clustering analysis of these profiles is important to further analyze and
comment on electricity consumption patterns. Although many clustering
techniques have been proposed in the literature over the years, it is often
noticed that different techniques fit best for different datasets. To identify
the most suitable technique, standard clustering validity indices are often
used. These indices focus primarily on the intrinsic characteristics of the
clustering results. Moreover, different indices often give conflicting
recommendations which can only be clarified with heuristics about the dataset
and/or the expected cluster structures -- information that is rarely available
in practical situations. This paper presents a novel scheme to validate and
compare the clustering results objectively. Additionally, the proposed scheme
considers all the steps prior to the clustering algorithm, including the
pre-processing and dimensionality reduction steps, in order to provide
recommendations over the complete framework. Accordingly, the proposed strategy
is shown to provide better, unbiased, and uniform recommendations as compared
to the standard Clustering Validity Indices.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:48:15 GMT""}]","2021-03-02"
"2103.00031","Dominik Aumayr","Dominik Aumayr, Stefan Marr, Sophie Kaleba, Elisa Gonzalez Boix,
  Hanspeter M\""ossenb\""ock","Capturing High-level Nondeterminism in Concurrent Programs for Practical
  Concurrency Model Agnostic Record & Replay",,"The Art, Science, and Engineering of Programming, 2021, Vol. 5,
  Issue 3, Article 14","10.22152/programming-journal.org/2021/5/14",,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With concurrency being integral to most software systems, developers combine
high-level concurrency models in the same application to tackle each problem
with appropriate abstractions. While languages and libraries offer a wide range
of concurrency models, debugging support for applications that combine them has
not yet gained much attention. Record & replay aids debugging by
deterministically reproducing recorded bugs, but is typically designed for a
single concurrency model only. This paper proposes a practical
concurrency-model-agnostic record & replay approach for multi-paradigm
concurrent programs, i.e. applications that combine concurrency models. Our
approach traces high-level nondeterministic events by using a uniform
model-agnostic trace format and infrastructure. This enables orderingbased
record & replay support for a wide range of concurrency models, and thereby
enables debugging of applications that combine them. In addition, it allows
language implementors to add new concurrency models and reuse the
model-agnostic record & replay support. We argue that a
concurrency-model-agnostic record & replay is practical and enables advanced
debugging support for a wide range of concurrency models. The evaluation shows
that our approach is expressive and flexible enough to support record & replay
of applications using threads & locks, communicating event loops, communicating
sequential processes, software transactional memory and combinations of those
concurrency models. For the actor model, we reach recording performance
competitive with an optimized special-purpose record & replay solution. The
average recording overhead on the Savina actor benchmark suite is 10% (min. 0%,
max. 23%). The performance for other concurrency models and combinations
thereof is at a similar level. We believe our concurrency-model-agnostic
approach helps developers of applications that mix and match concurrency
models. We hope that this substrate inspires new tools and languages making
building and maintaining of multi-paradigm concurrent applications simpler and
safer.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:48:15 GMT""}]","2021-03-02"
"2103.00032","Janice Chin","Janice Chin, David Pearce","Finding Bugs with Specification-Based Testing is Easy!",,"The Art, Science, and Engineering of Programming, 2021, Vol. 5,
  Issue 3, Article 13","10.22152/programming-journal.org/2021/5/13",,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated specification-based testing has a long history with several notable
tools having emerged. For example, QuickCheck for Haskell focuses on testing
against user-provided properties. Others, such as JMLUnit, use specifications
in the form of pre- and post-conditions to drive testing. An interesting (and
under-explored) question is how effective this approach is at finding bugs in
practice. In general, one would assume automated testing is less effective at
bug finding than static verification. But, how much less effective? To shed
light on this question, we consider automated testing of programs written in
Whiley -- a language with first-class support for specifications. Whilst
originally designed with static verification in mind, we have anecdotally found
automated testing for Whiley surprisingly useful and cost-effective. For
example, when an error is detected with automated testing, a counterexample is
always provided. This has motivated the more rigorous empirical examination
presented in this paper. To that end, we provide a technical discussion of the
implementation behind an automated testing tool for Whiley. Here, a key
usability concern is the ability to parameterise the input space, and we
present novel approaches for references and lambdas. We then report on several
large experiments investigating the tool's effectiveness at bug finding using a
range of benchmarks, including a suite of 1800+ mutants. The results indicate
the automated testing is effective in many cases, and that sampling offers
useful performance benefits with only modest reductions in bug-finding
capability. Finally, we report on some real-world uses of the tool where it has
proved effective at finding bugs (such as in the standard library).
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:49:48 GMT""}]","2021-03-02"
"2103.00033","Sebastian Burckhardt","Sebastian Burckhardt, Chris Gillum, David Justo, Konstantinos Kallas,
  Connor McMahon, Christopher S. Meiklejohn","Serverless Workflows with Durable Functions and Netherite","This paper was written in September 2020, and the content has not
  been edited after October 10, 2020",,,,"cs.DC cs.PL cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Serverless is an increasingly popular choice for service architects because
it can provide elasticity and load-based billing with minimal developer effort.
A common and important use case is to compose serverless functions and cloud
storage into reliable workflows. However, existing solutions for authoring
workflows provide a rudimentary experience compared to writing standard code in
a modern programming language. Furthermore, executing workflows reliably in an
elastic serverless environment poses significant performance challenges.
  To address these, we propose Durable Functions, a programming model for
serverless workflows, and Netherite, a distributed execution engine to execute
them efficiently. Workflows in Durable Functions are expressed as task-parallel
code in a host language of choice. Internally, the workflows are translated to
fine-grained stateful communicating processes, which are load-balanced over an
elastic cluster. The main challenge is to minimize the cost of reliably
persisting progress to storage while supporting elastic scale. Netherite solves
this by introducing partitioning, recovery logs, asynchronous snapshots, and
speculative communication.
  Our results show that Durable Functions simplifies the expression of complex
workflows, and that Netherite achieves lower latency and higher throughput than
the prevailing approaches for serverless workflows in Azure and AWS, by orders
of magnitude in some cases.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 19:51:58 GMT""}]","2021-03-02"
"2103.00034","Hunter Lang","Hunter Lang, Aravind Reddy, David Sontag, Aravindan Vijayaraghavan","Beyond Perturbation Stability: LP Recovery Guarantees for MAP Inference
  on Noisy Stable Instances","25 pages, 2 figures, 2 tables. To appear in AISTATS 2021",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several works have shown that perturbation stable instances of the MAP
inference problem in Potts models can be solved exactly using a natural linear
programming (LP) relaxation. However, most of these works give few (or no)
guarantees for the LP solutions on instances that do not satisfy the relatively
strict perturbation stability definitions. In this work, we go beyond these
stability results by showing that the LP approximately recovers the MAP
solution of a stable instance even after the instance is corrupted by noise.
This ""noisy stable"" model realistically fits with practical MAP inference
problems: we design an algorithm for finding ""close"" stable instances, and show
that several real-world instances from computer vision have nearby instances
that are perturbation stable. These results suggest a new theoretical
explanation for the excellent performance of this LP relaxation in practice.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:01:44 GMT""}]","2021-03-02"
"2103.00035","G. P. Zhang","G. P. Zhang and Y. H. Bai","Harmonic generation predominantly from a single spin channel in a half
  metal","18 pages and four figures, Accepted to Physical Review B",,"10.1103/PhysRevB.103.L100407",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Harmonic generation in atoms and molecules has reshaped our understanding of
ultrafast phenomena beyond the traditional nonlinear optics and has launched
attosecond physics. Harmonics from solids represent a new frontier, where both
majority and minority spin channels contribute to harmonics.} This is true even
in a ferromagnet whose electronic states are equally available to optical
excitation. Here, we demonstrate that harmonics can be generated {mostly} from
a single spin channel in half metallic chromium dioxide. {An energy gap in the
minority channel greatly reduces the harmonic generation}, so harmonics
predominantly emit from the majority channel, with a small contribution from
the minority channel. However, this is only possible when the incident photon
energy is well below the energy gap in the minority channel, so all the
transitions in the minority channel are virtual. The onset of the photon energy
is determined by the transition energy between the dipole-allowed transition
between the O-$2p$ and Cr-$3d$ states. Harmonics {mainly} from a single spin
channel can be detected, regardless of laser field strength, as far as the
photon energy is below the minority band energy gap. This prediction should be
tested experimentally.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:05:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 16:58:36 GMT""}]","2021-09-01"
"2103.00036","Eugenia Diaz-Gimenez","Eugenia Diaz-Gimenez (1), Ariel Zandivarez (1), Gary Mamon (2) ((1)
  OAC/UNC - IATE/CONICET/UNC - (2) IAP)","Compact groups from semi-analytical models of galaxy formation -- II:
  Different assembly channels","14 pages, 11 figures, 3 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab535",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the formation of over 6000 compact groups (CGs) of galaxies
identified in mock redshift-space galaxy catalogues built from semi-analytical
models of galaxy formation (SAMs) run on the Millennium Simulations. We select
CGs of 4 members in our mock SDSS galaxy catalogues and, for each CG, we trace
back in time the real-space positions of the most massive progenitors of their
4 galaxies. By analysing the evolution of the distance of the galaxy members to
the centre of mass of the group, we identify 4 channels of CG formation. The
classification of these assembly channels is performed with an automatic recipe
inferred from a preliminary visual inspection and based on the orbit of the
galaxy with the fewest number of orbits. Most CGs show late assembly, with the
last galaxy arriving on its first or second passage, while only 10-20 per cent
form by the gradual contraction of their orbits by dynamical friction, and only
a few per cent forming early with little subsequent contraction. However, a SAM
from a higher resolution simulation leads to earlier assembly. Assembly
histories of CGs also depend on cosmological parameters. At similar resolution,
CGs assemble later in SAMs built on parent cosmological simulations of high
density parameter. Several observed properties of mock CGs correlate with their
assembly history: early-assembling CGs are smaller, with shorter crossing
times, and greater magnitude gaps between their brightest two members, and
their brightest galaxies have smaller spatial offsets and are more passive.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:07:39 GMT""}]","2021-03-24"
"2103.00037","Nicolas LaLone","John Dunham, Konstantinos Papangelis, Nicolas LaLone, Yihong Wang","Casual and Hardcore Player Traits and Gratifications of Pok\'emon GO,
  Harry Potter: Wizards Unite, Ingress","39 Tables, 9 Figures, TOCHI Submission",,,,"cs.HC","http://creativecommons.org/publicdomain/zero/1.0/","  Location-based games (LBG) impose virtual spaces on top of physical
locations. Studies have explored LBG from various perspectives. However, a
comprehensive study of who these players are, their traits, their
gratifications, and the links between them is conspicuously absent from the
literature. In this paper, we aim to address this lacuna through a series of
surveys with 2390 active LBG players utilizing Tondello's Player Traits Model
and Scale of Game playing Preferences, and Hamari's scale of LBG
gratifications. Our findings (1) illustrate an association between player
satisfaction and social aspects of the studied games, (2) explicate how the
core-loops of the studied games impact the expressed gratifications and the
affine traits of players, and (3) indicate a strong distinction between
hardcore and casual players based on both traits and gratifications. Overall
our findings shed light into the players of LBG, their traits, and
gratifications they derive from playing LBGs.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:09:08 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 02:55:41 GMT""}]","2021-03-08"
"2103.00038","Leon Takhtajan","Leon A. Takhtajan","Trace formulas for the modified Mathieu equation","Minor changes, references added",,,,"math.SP","http://creativecommons.org/licenses/by/4.0/","  For the radial and one-dimensional Schr\""{o}dinger operator $H$ with growing
potential $q(x)$ we outline a method of obtaining the trace identities - an
asymptotic expansion of the Fredholm determinant $\mathrm{det}_{F}(H-\lambda
I)$ as $\lambda\to-\infty$. As an illustrating example, we consider
Schr\""{o}dinger operator with the potential $q(x)=2\cosh 2x$, associated with
the modified Mathieu equation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:13:31 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 22:16:41 GMT""}]","2021-03-12"
"2103.00039","Shuang Song","Peter Kairouz, Brendan McMahan, Shuang Song, Om Thakkar, Abhradeep
  Thakurta, Zheng Xu","Practical and Private (Deep) Learning without Sampling or Shuffling",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  We consider training models with differential privacy (DP) using mini-batch
gradients. The existing state-of-the-art, Differentially Private Stochastic
Gradient Descent (DP-SGD), requires privacy amplification by sampling or
shuffling to obtain the best privacy/accuracy/computation trade-offs.
Unfortunately, the precise requirements on exact sampling and shuffling can be
hard to obtain in important practical scenarios, particularly federated
learning (FL). We design and analyze a DP variant of
Follow-The-Regularized-Leader (DP-FTRL) that compares favorably (both
theoretically and empirically) to amplified DP-SGD, while allowing for much
more flexible data access patterns. DP-FTRL does not use any form of privacy
amplification.
  The code is available at
https://github.com/google-research/federated/tree/master/dp_ftrl and
https://github.com/google-research/DP-FTRL .
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:16:26 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 23:45:09 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 05:30:36 GMT""}]","2021-12-13"
"2103.00040","G. P. Zhang","G. P. Zhang, Y. H. Bai and Thomas F. George","Spin Berry points as crucial for ultrafast demagnetization","19 pages and nine figures, Invited paper to Modern Physics Letters B",,"10.1142/S0217984921502158",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Laser-induced ultrafast demagnetization has puzzled researchers around the
world for over two decades. Intrinsic complexity in electronic, magnetic, and
phononic subsystems is difficult to understand microscopically. So far it is
not possible to explain demagnetization using a single mechanism, which
suggests a crucial piece of information still missing. In this paper, we return
to a fundamental aspect of physics: spin and its change within each band in the
entire Brillouin zone. We employ fcc Ni as an example and use an extremely
dense {\bf k} mesh to map out spin changes for every band close to the Fermi
level along all the high symmetry lines. To our surprise, spin angular momentum
at some special {\bf k} points abruptly changes from $\pm \hbar/2$ to $\mp
\hbar/2$ simply by moving from one crystal momentum point to the next. This
explains why intraband transitions, which the spin superdiffusion model is
based upon, can induce a sharp spin moment reduction, and why electric current
can change spin orientation in spintronics. These special {\bf k} points, which
are called spin Berry points, are not random and appear when several bands are
close to each other, so the Berry potential of spin majority states is
different from that of spin minority states. Although within a single band,
spin Berry points jump, when we group several neighboring bands together, they
form distinctive smooth spin Berry lines. It is the band structure that
disrupts those lines. Spin Berry points are crucial to laser-induced ultrafast
demagnetization and spintronics.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:16:33 GMT""}]","2021-05-19"
"2103.00041","Gabor Pataki","G\'abor Pataki, Aleksandr Touzov","How do exponential size solutions arise in semidefinite programming?",,,,,"math.OC cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a classic example of Khachiyan shows, some semidefinite programs (SDPs)
have solutions whose size -- the number of bits necessary to describe them --
is exponential in the size of the input. Exponential size solutions are the
main obstacle to solve a long standing open problem: can we decide feasibility
of SDPs in polynomial time?
  We prove that large solutions are actually quite common in SDPs: a linear
change of variables transforms every strictly feasible SDP into a Khachiyan
type SDP, in which the leading variables are large. As to ""how large"", that
depends on the singularity degree of a dual problem. Further, we present some
SDPs in which large solutions appear naturally, without any change of
variables. We also partially answer the question: how do we represent such
large solutions in polynomial space?
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:32:10 GMT""}]","2021-03-02"
"2103.00042","Ying Zong","Ying Zong","Weierstrass models",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Elliptic K3 admit contraction to plane models, the Weierstrass models. We
define a higher dimensional notion of Weierstrass models, show that they are
compactification of torsors in a unique form, and propose an application to the
kahler geometry of a class of lagrangian fibrations on irreducible symplectic
manifolds.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:32:31 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 15:03:43 GMT""},{""version"":""v3"",""created"":""Sun, 2 May 2021 23:21:15 GMT""}]","2021-05-04"
"2103.00043","Walter Lambrecht","Amol Ratnaparkhe, Santosh Kumar Radha and Walter R. L. Lambrecht","Calculated phonon modes, infrared and Raman spectra in orthorhombic
  $\alpha$-MoO$_3$ and monolayer MoO$_3$","13 pages, 13 figures, 14 tables","Journal of Applied Physics 130, 104302 (2021)","10.1063/5.0060718",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Orhorhombic $\alpha$-MoO$_3$ is a layered oxide with various applications and
with excellent potential to be exfoliated as a 2D ultrathin film or monolayer.
In this paper, we present a first-principles computational study of its
vibrational properties. Our focus is on the zone center modes which can be
measured by a combination of infared and Raman spectroscopy. The polarization
dependent spectra are simulated. Calculations are also performed for a
monolayer form in which ""double layers"" of Mo$_2$O$_6$ which are weakly van der
Waals bonded in the $\alpha$-structure are isolated. Shift in phonon
frequencies are analyzed.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:33:18 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 18:06:42 GMT""}]","2021-09-20"
"2103.00044","Georgios Bakirtzis","Georgios Bakirtzis, Fabrizio Genovese, Cody H. Fleming","Yoneda Hacking: The Algebra of Attacker Actions",,,,,"cs.CR cs.SY eess.SY math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our work focuses on modeling the security of systems from their
component-level designs. Towards this goal, we develop a categorical formalism
to model attacker actions. Equipping the categorical formalism with algebras
produces two interesting results for security modeling. First, using the Yoneda
lemma, we can model attacker reconnaissance missions. In this context, the
Yoneda lemma shows us that if two system representations, one being complete
and the other being the attacker's incomplete view, agree at every possible
test, they behave the same. The implication is that attackers can still
successfully exploit the system even with incomplete information. Second, we
model the potential changes to the system via an exploit. An exploit either
manipulates the interactions between system components, such as providing the
wrong values to a sensor, or changes the components themselves, such as
controlling a global positioning system (GPS). One additional benefit of using
category theory is that mathematical operations can be represented as formal
diagrams, helpful in applying this analysis in a model-based design setting. We
illustrate this modeling framework using an unmanned aerial vehicle (UAV)
cyber-physical system model. We demonstrate and model two types of attacks (1)
a rewiring attack, which violates data integrity, and (2) a rewriting attack,
which violates availability.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:34:08 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 20:41:07 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 16:20:38 GMT""}]","2022-04-14"
"2103.00045","Yevgeny Tsodikovich","Yevgeny Tsodikovich, Xavier Venel, Anna Zseleva","Repeated Games with Switching Costs: Stationary vs History Independent
  Strategies",,,,,"math.OC econ.TH","http://creativecommons.org/licenses/by/4.0/","  We study zero-sum repeated games where the minimizing player has to pay a
certain cost each time he changes his action. Our contribution is twofold.
First, we show that the value of the game exists in stationary strategies,
depending solely on the previous action of the minimizing player, not the
entire history. We provide a full characterization of the value and the optimal
strategies. The strategies exhibit a robustness property and typically do not
change with a small perturbation of the switching costs. Second, we consider a
case where the minimizing player is limited to playing simpler strategies that
are completely history-independent. Here too, we provide a full
characterization of the (minimax) value and the strategies for obtaining it.
Moreover, we present several bounds on the loss due to this limitation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:39:32 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 11:48:34 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 17:38:47 GMT""}]","2021-10-29"
"2103.00046","Dvira Segal","Na'im Kalantar, Bijay Kumar Agarwalla, Dvira Segal","Harmonic chains and the thermal diode effect",,"Phys. Rev. E 103, 052130 (2021)","10.1103/PhysRevE.103.052130",,"quant-ph cond-mat.mes-hall cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Harmonic oscillator chains connecting two harmonic reservoirs at different
constant temperatures cannot act as thermal diodes, irrespective of structural
asymmetry. However, here we prove that perfectly harmonic junctions can rectify
heat once the reservoirs (described by white Langevin noise) are placed under
temperature gradients, which are asymmetric at the two sides, an effect that we
term ""temperature-gradient harmonic oscillator diodes"". This nonlinear diode
effect results from the additional constraint -- the imposed thermal gradient
at the boundaries. We demonstrate the rectification behavior based on the exact
analytical formulation of steady state heat transport in harmonic systems
coupled to Langevin baths, which can describe quantum and classical transport,
both regimes realizing the diode effect under the involved boundary conditions.
Our study shows that asymmetric harmonic systems, such as room-temperature
hydrocarbon molecules with varying side groups and end groups, or a linear
lattice of trapped ions may rectify heat by going beyond simple boundary
conditions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:39:58 GMT""}]","2021-06-02"
"2103.00047","Abhijat Biswas","Abhijat Biswas, Allan Wang, Gustavo Silvera, Aaron Steinfeld, Henny
  Admoni","SocNavBench: A Grounded Simulation Testing Framework for Evaluating
  Social Navigation","Associated code and benchmark available at
  https://github.com/CMU-TBD/SocNavBench ; Accepted to ACM Transactions on
  Human-Robot Interaction",,,,"cs.RO cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The human-robot interaction (HRI) community has developed many methods for
robots to navigate safely and socially alongside humans. However, experimental
procedures to evaluate these works are usually constructed on a per-method
basis. Such disparate evaluations make it difficult to compare the performance
of such methods across the literature. To bridge this gap, we introduce
SocNavBench, a simulation framework for evaluating social navigation
algorithms. SocNavBench comprises a simulator with photo-realistic capabilities
and curated social navigation scenarios grounded in real-world pedestrian data.
We also provide an implementation of a suite of metrics to quantify the
performance of navigation algorithms on these scenarios. Altogether,
SocNavBench provides a test framework for evaluating disparate social
navigation methods in a consistent and interpretable manner. To illustrate its
use, we demonstrate testing three existing social navigation methods and a
baseline method on SocNavBench, showing how the suite of metrics helps infer
their performance trade-offs. Our code is open-source, allowing the addition of
new scenarios and metrics by the community to help evolve SocNavBench to
reflect advancements in our understanding of social navigation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:40:25 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 05:33:32 GMT""}]","2021-07-29"
"2103.00048","You Qi","Ben Elias, You Qi","Actions of sl_2 on algebras appearing in categorification","50 pages, many figures. V2 contains updates from referee reports.
  Comments welcome. To appear in Quantum Topology",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that many of the recently-constructed algebras and categories which
appear in categorification can be equipped with an action of $\mathfrak{sl}_2$
by derivations. The $\mathfrak{sl}_2$ representations which appear are filtered
by tensor products of coverma modules. In a future paper, we will address the
implications of the $\mathfrak{sl}_2$ structure for categorification.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:58:54 GMT""},{""version"":""v2"",""created"":""Fri, 22 Apr 2022 21:18:12 GMT""}]","2022-04-26"
"2103.00049","Amartya Banerjee","Hsuan Ming Yu and Amartya S. Banerjee","Density functional theory method for twisted geometries with application
  to torsional deformations in group-IV nanotubes",,,"10.1016/j.jcp.2022.111023",,"cond-mat.mtrl-sci physics.comp-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a real-space formulation and implementation of Kohn-Sham Density
Functional Theory suited to twisted geometries, and apply it to the study of
torsional deformations of X (X = C, Si, Ge, Sn) nanotubes. Our formulation is
based on higher order finite difference discretization in helical coordinates,
uses ab intio pseudopotentials, and naturally incorporates rotational (cyclic)
and screw operation (i.e., helical) symmetries. We discuss several aspects of
the computational method, including the form of the governing equations,
details of the numerical implementation, as well as its convergence, accuracy
and efficiency properties.
  The technique presented here is particularly well suited to the first
principles simulation of quasi-one-dimensional structures and their
deformations, and many systems of interest can be investigated using small
simulation cells containing just a few atoms. We apply the method to
systematically study the properties of single-wall zigzag and armchair group-IV
nanotubes, as they undergo twisting. For the range of deformations considered,
the mechanical behavior of the tubes is found to be largely consistent with
isotropic linear elasticity, with the torsional stiffness varying as the cube
of the nanotube radius. Furthermore, for a given tube radius, this quantity is
seen to be highest for carbon nanotubes and the lowest for those of tin, while
nanotubes of silicon and germanium have intermediate values close to each
other. We also describe different aspects of the variation in electronic
properties of the nanotubes as they are twisted. In particular, we find that
akin to the well known behavior of armchair carbon nanotubes, armchair
nanotubes of silicon, germanium and tin also exhibit bandgaps that vary
periodically with imposed rate of twist, and that the periodicity of the
variation scales in an inverse quadratic manner with the tube radius.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:00:36 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 04:50:28 GMT""},{""version"":""v3"",""created"":""Thu, 10 Feb 2022 06:29:30 GMT""},{""version"":""v4"",""created"":""Mon, 18 Apr 2022 22:16:21 GMT""}]","2022-04-20"
"2103.00050","\c{S}aban G\""uven\c{c}","\c{S}aban G\""uven\c{c}","Legendre Trajectories of Trans-$S$-Manifolds",,"Bull. Korean Math. Soc. 59 (2022), No. 1, pp. 227-239","10.4134/BKMS.b210244",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider Legendre trajectories of trans-$S$-manifolds. We
obtain curvature characterizations of these curves and give a classification
theorem. We also investigate Legendre curves whose Frenet frame fields are
linearly dependent with certain combination of characteristic vector fields of
the trans-$S$-manifold.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:04:21 GMT""}]","2022-02-01"
"2103.00051","Andreas St\""ockel","Andreas St\""ockel","Constructing Dampened LTI Systems Generating Polynomial Bases","15 pages, 3 figures",,,"CTN-TR-20210226-017","eess.SY cs.LG cs.NE cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an alternative derivation of the LTI system underlying the
Legendre Delay Network (LDN). To this end, we first construct an LTI system
that generates the Legendre polynomials. We then dampen the system by
approximating a windowed impulse response, using what we call a ""delay
re-encoder"". The resulting LTI system is equivalent to the LDN system. This
technique can be applied to arbitrary polynomial bases, although there
typically is no closed-form equation that describes the state-transition
matrix.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:14:19 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 18:36:59 GMT""}]","2021-03-10"
"2103.00052","P.A. Kalozoumis","A. Katsaris, P.A. Kalozoumis, and F.K. Diakonos","Generalized Continuity Equations for Schr\""odinger and Dirac Equations","10 pages, 2 figures, 1 table",,,,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The concept of the generalized continuity equation (GCE) was recently
introduced in [J. Phys. A: Math. and Theor. {\bf 52}, 1552034 (2019)], and was
derived in the context of $N$ independent Schr\""{o}dinger systems. The GCE is
induced by a symmetry transformation which mixes the states of these systems,
even though the $N$-system Lagrangian does not. As the $N$-system
Schr\""{o}dinger Lagrangian is not invariant under such a transformation, the
GCE will involve source terms which, under certain conditions vanish and lead
to conserved currents. These conditions may hold globally or locally in a
finite domain, leading to globally or locally conserved currents, respectively.
In this work, we extend this idea to the case of arbitrary
$SU(N)$-transformations and we show that a similar GCE emerges for $N$ systems
in the Dirac dynamics framework. The emerging GCEs and the conditions which
lead to the attendant conservation laws provide a rich phenomenology and
potential use for the preparation and control of fermionic states.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:15:37 GMT""}]","2021-03-02"
"2103.00053","Reyhan Kevser Keser","Reyhan Kevser Keser, Aydin Ayanzadeh, Omid Abdollahi Aghdam, Caglar
  Kilcioglu, Behcet Ugur Toreyin, Nazim Kemal Ure","PURSUhInT: In Search of Informative Hint Points Based on Layer
  Clustering for Knowledge Distillation","Our codes are published on Code Ocean, where the link to our codes
  is: https://codeocean.com/capsule/4245746/tree/v1","Expert Systems with Applications, Volume 213, Part B, March 2023,
  119040","10.1016/j.eswa.2022.119040",,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  One of the most efficient methods for model compression is hint distillation,
where the student model is injected with information (hints) from several
different layers of the teacher model. Although the selection of hint points
can drastically alter the compression performance, conventional distillation
approaches overlook this fact and use the same hint points as in the early
studies. Therefore, we propose a clustering based hint selection methodology,
where the layers of teacher model are clustered with respect to several metrics
and the cluster centers are used as the hint points. Our method is applicable
for any student network, once it is applied on a chosen teacher network. The
proposed approach is validated in CIFAR-100 and ImageNet datasets, using
various teacher-student pairs and numerous hint distillation methods. Our
results show that hint points selected by our algorithm results in superior
compression performance compared to state-of-the-art knowledge distillation
algorithms on the same student models and datasets.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:18:34 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 20:50:30 GMT""},{""version"":""v3"",""created"":""Thu, 3 Nov 2022 22:41:42 GMT""}]","2022-11-07"
"2103.00054","Prathamesh Muzumdar","Prathamesh Muzumdar, Ganga Prasad Basyal, Piyush Vyas","Moderating effects of retail operations and hard-sell sales techniques
  on salesperson's interpersonal skills and customer repurchase intention",,,,,"stat.AP","http://creativecommons.org/publicdomain/zero/1.0/","  Salesperson's interpersonal skills have always played an important role in
influencing various stages of customer's purchase decision. With the increase
in retail outlets and merchandisers, retail operations have taken a pivotal
role in influencing the salesperson's sales practices and customer's purchase
decisions.This study tries to examine the influence of retail operations and
hard-selling startegies on the relationship between salesperson's interpersonal
skills and customer repurchase intention. Salesperson's interpersonal skills
are the trained and tacit competencies that a salesperson employs to improve
customer relationship and sales performance. Many organizations prefer skill
training fails to attract repetitive purchases due to unavoidable extraneous
factors. It has become a necessity to understand the role of extraneous factors
like retail operations on the relationship between salesperson's interpersonal
skills and customer repurchase intention. The findings suggest that retail
operations significantly moderate the relationship between salesperson's
interpersonal skills and customer repurchase intention. We also find that
hard-sell sales techniques play a significant moderating role in negatively
infleuncing customer repurchase intention . This study has important
implications for retailers and sales managers.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:21:25 GMT""}]","2021-03-02"
"2103.00055","Shiyu Feng","Shiyu Feng, Zixuan Wu, Yipu Zhao, Patricio A. Vela","Image-Based Trajectory Tracking through Unknown Environments without
  Absolute Positioning","to be published in IEEE/ASME Transactions on Mechatronics",,"10.1109/TMECH.2022.3175819",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper describes a stereo image-based visual servoing system for
trajectory tracking by a non-holonomic robot without externally derived pose
information nor a known visual map of the environment. It is called trajectory
servoing. The critical component is a feature-based, indirect Simultaneous
Localization And Mapping (SLAM) method to provide a pool of available features
with estimated depth, so that they may be propagated forward in time to
generate image feature trajectories for visual servoing. Short and long
distance experiments show the benefits of trajectory servoing for navigating
unknown areas without absolute positioning. Empirically, trajectory servoing
has better trajectory tracking performance than pose-based feedback when both
rely on the same underlying SLAM system.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:22:28 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 03:25:36 GMT""},{""version"":""v3"",""created"":""Tue, 14 Jun 2022 04:04:09 GMT""}]","2022-06-15"
"2103.00056","Aizaz Chaudhry","Aizaz U. Chaudhry, Halim Yanikomeroglu","Laser Inter-Satellite Links in a Starlink Constellation",,,,,"eess.SP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Laser inter-satellite links (LISLs) are envisioned between satellites in
upcoming satellite constellations, such as Phase I of SpaceX's Starlink. Within
a constellation, satellites can establish LISLs with other satellites in the
same orbital plane or in different orbital planes. We present a classification
of LISLs based on the location of satellites within a constellation and the
duration of LISLs. Then, using satellite constellation for Phase I of Starlink,
we study the effect of varying a satellite's LISL range on the number of
different types of LISLs it can establish with other satellites. In addition to
permanent LISLs, we observe a significant number of temporary LISLs between
satellites in crossing orbital planes. Such LISLs can play a vital role in
achieving low-latency paths within next-generation optical wireless satellite
networks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:23:25 GMT""}]","2021-03-02"
"2103.00057","Arkajyoti Maity","Arkajyoti Maity, Arunava Chakrabarti","Engineering insulator-metal transition in a class of decorated aperiodic
  lattices: a quantum dynamical study","9 pages,8 figures",,"10.1016/j.physleta.2021.127452",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the quantum dynamics of wave packets in a class of decorated
lattices, both quasiperiodic and random, where a nominal quasi-one
dimensionality is introduced at local levels, bringing in a deterministic or
even random variations in the distribution of the coordination number
throughout the system. We show that certain correlations in the numerical
values of the system Hamiltonian can cause a drastic change in the dynamical
evolution of the wave packet, revealing a complete delocalization, independent
of the energy of the travelling particle, even in the absence of any
translational invariance. We use an exact decimation of a selected subset of
the degrees of freedom, and an analysis of the commutation of the $2 \times 2$
transfer matrices on a renormalized version of the parent systems within a
tight binding framework. An in-depth analysis of the mean square displacement,
temporal autocorrelation function and the inverse participation ratio
establishes the gross change in the behaviour of the wave packet dynamics. The
consequence is the occurrence of a parameter-driven insulator-metal transition
over the full (or a major) range of the energy spectrum in each case. In
certain cases, inclusion of an external magnetic flux enables us to control the
transition. The observation is general, and, to our mind, can inspire
experiments involving photonics or matter wave localization.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:27:44 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 17:22:06 GMT""}]","2021-05-27"
"2103.00058","Harel Yedidsion","Jiaxun Cui, William Macke, Harel Yedidsion, Daniel Urieli, Peter Stone","Scalable Multiagent Driving Policies For Reducing Traffic Congestion","Accepted as a full paper to the International Conference on
  Autonomous Agents and Multi Agent Systems (AAMAS). 2021",,,,"cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic congestion is a major challenge in modern urban settings. The
industry-wide development of autonomous and automated vehicles (AVs) motivates
the question of how can AVs contribute to congestion reduction. Past research
has shown that in small scale mixed traffic scenarios with both AVs and
human-driven vehicles, a small fraction of AVs executing a controlled
multiagent driving policy can mitigate congestion. In this paper, we scale up
existing approaches and develop new multiagent driving policies for AVs in
scenarios with greater complexity. We start by showing that a congestion metric
used by past research is manipulable in open road network scenarios where
vehicles dynamically join and leave the road. We then propose using a different
metric that is robust to manipulation and reflects open network traffic
efficiency. Next, we propose a modular transfer reinforcement learning
approach, and use it to scale up a multiagent driving policy to outperform
human-like traffic and existing approaches in a simulated realistic scenario,
which is an order of magnitude larger than past scenarios (hundreds instead of
tens of vehicles). Additionally, our modular transfer learning approach saves
up to 80% of the training time in our experiments, by focusing its data
collection on key locations in the network. Finally, we show for the first time
a distributed multiagent policy that improves congestion over human-driven
traffic. The distributed approach is more realistic and practical, as it relies
solely on existing sensing and actuation capabilities, and does not require
adding new communication infrastructure.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:29:55 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 20:37:48 GMT""}]","2022-07-08"
"2103.00059","Britta Johnson","Britta Ann Johnson and Nandini Ananth","A Skew Dividing Surface for Accurate Nonadiabatic Mean-Field Ring
  Polymer Rates",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Mean-Field Ring Polymer Molecular Dynamics (MF-RPMD) is a powerful,
efficient, and accurate method for approximate quantum dynamic simulations of
multi-level system dynamics. Initial efforts to compute nonadiabatic reaction
rates using MF-RPMD were not successful; recent work showed that this can be
remedied by including a simple, if adhoc, correction term that accounts for the
formation of `kinked' or mixed electronic state ring polymer configurations.
Here, we build on this idea, introducing a electronic state population based
reaction coordinate and novel skew dividing surface that constrains nuclear
positions to configurations where the reactant and product state potentials are
near-degenerate and that samples kinked electronic state configurations. We
then demonstrate the numerical accuracy of this method in computing rates for a
series of nonadiabatic model systems.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:33:39 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 17:58:24 GMT""}]","2021-04-29"
"2103.00060","Alessandro Casini","Federico Belotti, Alessandro Casini, Leopoldo Catania, Stefano Grassi
  and Pierre Perron","Simultaneous Bandwidths Determination for DK-HAC Estimators and Long-Run
  Variance Estimation in Nonparametric Settings",,,,,"econ.EM math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the derivation of data-dependent simultaneous bandwidths for
double kernel heteroskedasticity and autocorrelation consistent (DK-HAC)
estimators. In addition to the usual smoothing over lagged autocovariances for
classical HAC estimators, the DK-HAC estimator also applies smoothing over the
time direction. We obtain the optimal bandwidths that jointly minimize the
global asymptotic MSE criterion and discuss the trade-off between bias and
variance with respect to smoothing over lagged autocovariances and over time.
Unlike the MSE results of Andrews (1991), we establish how nonstationarity
affects the bias-variance trade-o?. We use the plug-in approach to construct
data-dependent bandwidths for the DK-HAC estimators and compare them with the
DK-HAC estimators from Casini (2021) that use data-dependent bandwidths
obtained from a sequential MSE criterion. The former performs better in terms
of size control, especially with stationary and close to stationary data.
Finally, we consider long-run variance estimation under the assumption that the
series is a function of a nonparametric estimator rather than of a
semiparametric estimator that enjoys the usual T^(1/2) rate of convergence.
Thus, we also establish the validity of consistent long-run variance estimation
in nonparametric parameter estimation settings.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:38:32 GMT""}]","2021-03-10"
"2103.00061","Graziano Stivaletta","Marco Di Francesco, Graziano Stivaletta","The one-sided Lipschitz condition in the follow-the-leader approximation
  of scalar conservation laws",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the follow-the-leader particle approximation scheme for a $1d$
scalar conservation law with nonnegative $L^\infty_c$ initial datum and with a
$C^1$ concave flux, which is known to provide convergence towards the entropy
solution $\rho$ to the corresponding Cauchy problem. We provide two novel
contributions to this theory. First, we prove that the one-sided Lipschitz
condition satisfied by the approximating density $\rho^n$ is a discrete version
of an entropy condition; more precisely, under fairly general assumptions on
$f$ (which imply concavity of $f$) we prove that the continuum version
$\left(f(\rho)/\rho\right)_x\leq 1/t$ of said condition allows to select a
unique weak solution, despite $\left(f(\rho)/\rho\right)_x\leq 1/t$ is
apparently weaker than the classical Oleinik-Hoff one-sided Lipschitz condition
$f'(\rho)_x\leq 1/t$. Said result relies on an improved version of Hoff's
uniqueness proof. A byproduct of it is that the entropy condition is encoded in
the particle scheme prior to the many-particle limit, which was never proven
before. Second, we prove that in case $f(\rho)=\rho(A-\rho^\gamma)$ the
one-sided Lipschitz condition can be improved to a discrete version of the
classical (and sharp) Oleinik-Hoff condition. In order to make the paper
self-contained, we provide proofs (in some cases alternative ones) of all steps
of the convergence of the particle scheme.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:49:16 GMT""}]","2021-03-02"
"2103.00062","Ekrem Murat Esmer","Ekrem M. Esmer, \""Ozg\""ur Ba\c{s}t\""urk, Tobias C. Hinse, Selim O.
  Selam, Alexandre C. M. Correia","Revisiting the analysis of HW Vir eclipse timing data I. A frequentist
  data modeling approach and a dynamical stability analysis",,"A&A 648, A85 (2021)","10.1051/0004-6361/202038640",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  HW Vir is a short-period binary that presents eclipse timing variations.
Circumbinary planets have been proposed as a possible explanation, although the
properties of the planets differ in each new study. Our aim is to perform
robust model selection methods for eclipse timing variations (ETV) and error
calculation techniques based on a frequentist approach for the case of the HW
Vir system. We initially performed simultaneous light and radial velocity curve
analysis to derive the masses of the binary. We then analyzed the eclipse
timing variation of the system by fitting multiple models. To select the best
model, we searched the confidence levels for the best model by creating an
$\chi^2$ surface grid and bootstrap methods for each pair of parameters. We
searched for stable orbital configurations for our adopted ETV model. The
masses of the binary are found as 0.413 $\pm$ 0.008 $M_\odot$ and 0.128 $\pm$
0.004 $M_\odot$. Under the assumption of two light time effects superimposed on
a secular change, the minimum masses of the circumbinary objects are calculated
as $25.0_{-2.2}^{+3.5} \ M_{Jup}$ and $13.9_{-0.45}^{+0.60}\ M_{Jup}$. The
projected semi-major axes are found to be $7.8_{-1.0}^{+1.4}\ au$ and
$4.56_{-0.22}^{+0.27}\ au$ in respective order. We find that this configuration
is unstable within a 3$\sigma$ range on the semi-major axis and eccentricity of
the outer circumbinary object.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:50:44 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 16:39:03 GMT""}]","2021-04-21"
"2103.00063","Yikun Ban","Yikun Ban, Jingrui He","Local Clustering in Contextual Multi-Armed Bandits","13 pages",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study identifying user clusters in contextual multi-armed bandits (MAB).
Contextual MAB is an effective tool for many real applications, such as content
recommendation and online advertisement. In practice, user dependency plays an
essential role in the user's actions, and thus the rewards. Clustering similar
users can improve the quality of reward estimation, which in turn leads to more
effective content recommendation and targeted advertising. Different from
traditional clustering settings, we cluster users based on the unknown bandit
parameters, which will be estimated incrementally. In particular, we define the
problem of cluster detection in contextual MAB, and propose a bandit algorithm,
LOCB, embedded with local clustering procedure. And, we provide theoretical
analysis about LOCB in terms of the correctness and efficiency of clustering
and its regret bound. Finally, we evaluate the proposed algorithm from various
aspects, which outperforms state-of-the-art baselines.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 21:59:29 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 04:21:21 GMT""},{""version"":""v3"",""created"":""Fri, 24 Mar 2023 15:05:00 GMT""}]","2023-03-27"
"2103.00064","Austin Hounsel","J. Nathan Matias, Austin Hounsel, Nick Feamster","Software-Supported Audits of Decision-Making Systems: Testing Google and
  Facebook's Political Advertising Policies","To be presented at CSCW '22",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  How can society understand and hold accountable complex human and algorithmic
decision-making systems whose systematic errors are opaque to the public? These
systems routinely make decisions on individual rights and well-being, and on
protecting society and the democratic process. Practical and statistical
constraints on external audits--such as dimensional complexity--can lead
researchers and regulators to miss important sources of error in these complex
decision-making systems. In this paper, we design and implement a
software-supported approach to audit studies that auto-generates audit
materials and coordinates volunteer activity. We implemented this software in
the case of political advertising policies enacted by Facebook and Google
during the 2018 U.S. election. Guided by this software, a team of volunteers
posted 477 auto-generated ads and analyzed the companies' actions, finding
systematic errors in how companies enforced policies. We find that software can
overcome some common constraints of audit studies, within limitations related
to sample size and volunteer capacity.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:04:53 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 22:15:14 GMT""}]","2021-11-01"
"2103.00065","Jeremy Cohen","Jeremy M. Cohen, Simran Kaur, Yuanzhi Li, J. Zico Kolter, Ameet
  Talwalkar","Gradient Descent on Neural Networks Typically Occurs at the Edge of
  Stability","ICLR 2021. v3 moves several figures from the appendix into the main
  text, and adds more discussion regarding Jastrz\k{e}bski et al (2020):
  https://doi.org/10.48550/arXiv.2002.09572",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We empirically demonstrate that full-batch gradient descent on neural network
training objectives typically operates in a regime we call the Edge of
Stability. In this regime, the maximum eigenvalue of the training loss Hessian
hovers just above the numerical value $2 / \text{(step size)}$, and the
training loss behaves non-monotonically over short timescales, yet consistently
decreases over long timescales. Since this behavior is inconsistent with
several widespread presumptions in the field of optimization, our findings
raise questions as to whether these presumptions are relevant to neural network
training. We hope that our findings will inspire future efforts aimed at
rigorously understanding optimization at the Edge of Stability. Code is
available at https://github.com/locuslab/edge-of-stability.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:08:19 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 20:35:21 GMT""},{""version"":""v3"",""created"":""Wed, 23 Nov 2022 18:09:57 GMT""}]","2022-11-24"
"2103.00066","Vojt\u{e}ch Dvo\v{r}\'ak","Vojt\v{e}ch Dvo\v{r}\'ak","Waiter-Client Triangle-Factor Game on the Edges of the Complete Graph","9 pages","European Journal of Combinatorics 96 (2021) 103356",,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Consider the following game played by two players, called Waiter and Client,
on the edges of $K_n$ (where $n$ is divisible by $3$). Initially, all the edges
are unclaimed. In each round, Waiter picks two yet unclaimed edges. Client then
chooses one of these two edges to be added to Waiter's graph and one to be
added to Client's graph. Waiter wins if she forces Client to create a
$K_3$-factor in Client's graph at some point, while if she does not manage to
do that, Client wins.
  It is not difficult to see that for large enough $n$, Waiter has a winning
strategy. The question considered by Clemens et al. is how long the game will
last if Waiter aims to win as soon as possible, Client aims to delay her as
much as possible, and both players play optimally. Denote this optimal number
of rounds by $\tau_{WC}(\mathcal{F}_{n,K_3-\text{fac}},1 ) $. Clemens et al.
proved that $\frac{13}{12}n \leq \tau_{WC}(\mathcal{F}_{n,K_3-\text{fac}},1 )
\leq \frac{7}{6}n+o(n) $, and conjectured that
$\tau_{WC}(\mathcal{F}_{n,K_3-\text{fac}},1 ) = \frac{7}{6}n+o(n) $. In this
note, we verify their conjecture.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:13:00 GMT""}]","2021-05-10"
"2103.00067","Jakob Meldgaard Kj{\ae}r","Jakob Meldgaard Kj{\ae}r, Lasse Kristensen, Mads Alberg Christensen","Partitioned Graph Convolution Using Adversarial and Regression Networks
  for Road Travel Speed Prediction","This thesis was completed 2020-06-12 and defended 2020-06-26",,,,"cs.LG cs.AI cs.DM","http://creativecommons.org/licenses/by/4.0/","  Access to quality travel time information for roads in a road network has
become increasingly important with the rising demand for real-time travel time
estimation for paths within road networks. In the context of the Danish road
network (DRN) dataset used in this paper, the data coverage is sparse and
skewed towards arterial roads, with a coverage of 23.88% across 850,980 road
segments, which makes travel time estimation difficult. Existing solutions for
graph-based data processing often neglect the size of the graph, which is an
apparent problem for road networks with a large amount of connected road
segments. To this end, we propose a framework for predicting road segment
travel speed histograms for dataless edges, based on a latent representation
generated by an adversarially regularized convolutional network. We apply a
partitioning algorithm to divide the graph into dense subgraphs, and then train
a model for each subgraph to predict speed histograms for the nodes. The
framework achieves an accuracy of 71.5% intersection and 78.5% correlation on
predicting travel speed histograms using the DRN dataset. Furthermore,
experiments show that partitioning the dataset into clusters increases the
performance of the framework. Specifically, partitioning the road network
dataset into 100 clusters, with approximately 500 road segments in each
cluster, achieves a better performance than when using 10 and 20 clusters.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:16:48 GMT""}]","2021-03-02"
"2103.00068","Isaac Johnson","Isaac Johnson, Martin Gerlach and Diego S\'aez-Trumper","Language-agnostic Topic Classification for Wikipedia","Accepted to WikiWorkshop at The Web Conference 2021",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  A major challenge for many analyses of Wikipedia dynamics -- e.g., imbalances
in content quality, geographic differences in what content is popular, what
types of articles attract more editor discussion -- is grouping the very
diverse range of Wikipedia articles into coherent, consistent topics. This
problem has been addressed using various approaches based on Wikipedia's
category network, WikiProjects, and external taxonomies. However, these
approaches have always been limited in their coverage: typically, only a small
subset of articles can be classified, or the method cannot be applied across
(the more than 300) languages on Wikipedia. In this paper, we propose a
language-agnostic approach based on the links in an article for classifying
articles into a taxonomy of topics that can be easily applied to (almost) any
language and article on Wikipedia. We show that it matches the performance of a
language-dependent approach while being simpler and having much greater
coverage.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:17:50 GMT""}]","2021-03-02"
"2103.00069","Edouard Ollier","Edouard Ollier, Pierre Blanchard, Gw\'ena\""el Le Teuff, Stefan
  Michiels","Penalized Poisson model for network meta-analysis of individual patient
  time-to-event data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network meta-analysis (NMA) allows the combination of direct and indirect
evidence from a set of randomized clinical trials. Performing NMA using
individual patient data (IPD) is considered as a ""gold standard"" approach as it
provides several advantages over NMA based on aggregate data. For example, it
allows to perform advanced modelling of covariates or covariate-treatment
interactions. An important issue in IPD NMA is the selection of influential
parameters among terms that account for inconsistency, covariates,
covariate-by-treatment interactions or non-proportionality of treatments effect
for time to event data. This issue has not been deeply studied in the
literature yet and in particular not for time-to-event data. A major difficulty
is to jointly account for between-trial heterogeneity which could have a major
influence on the selection process. The use of penalized generalized mixed
effect model is a solution, but existing implementations have several
shortcomings and an important computational cost that precludes their use for
complex IPD NMA. In this article, we propose a penalized Poisson regression
model to perform IPD NMA of time-to-event data. It is based only on fixed
effect parameters which improve its computational cost over the use of random
effects. It could be easily implemented using existing penalized regression
package. Computer code is shared for implementation. The methods were applied
on simulated data to illustrate the importance to take into account between
trial heterogeneity during the selection procedure. Finally, it was applied to
an IPD NMA of overall survival of chemotherapy and radiotherapy in
nasopharyngeal carcinoma.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:18:04 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 20:01:19 GMT""}]","2021-10-22"
"2103.00070","Jiaoyan Chen","Jiaoyan Chen and Yuxia Geng and Zhuo Chen and Ian Horrocks and Jeff Z.
  Pan and Huajun Chen","Knowledge-aware Zero-Shot Learning: Survey and Perspective","Accepted by IJCAI'21 Survey Track",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero-shot learning (ZSL) which aims at predicting classes that have never
appeared during the training using external knowledge (a.k.a. side information)
has been widely investigated. In this paper we present a literature review
towards ZSL in the perspective of external knowledge, where we categorize the
external knowledge, review their methods and compare different external
knowledge. With the literature review, we further discuss and outlook the role
of symbolic knowledge in addressing ZSL and other machine learning sample
shortage issues.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:18:09 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 17:45:26 GMT""},{""version"":""v3"",""created"":""Mon, 10 May 2021 08:35:41 GMT""}]","2021-05-11"
"2103.00071","Gert de Cooman","Gert de Cooman and Jasper De Bock","Randomness is inherently imprecise","49 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1703.00931",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the martingale-theoretic approach of game-theoretic probability to
incorporate imprecision into the study of randomness. In particular, we define
several notions of randomness associated with interval, rather than precise,
forecasting systems, and study their properties. The richer mathematical
structure that thus arises lets us, amongst other things, better understand and
place existing results for the precise limit. When we focus on constant
interval forecasts, we find that every sequence of binary outcomes has an
associated filter of intervals it is random for. It may happen that none of
these intervals is precise -- a single real number -- which justifies the title
of this paper. We illustrate this by showing that randomness associated with
non-stationary precise forecasting systems can be captured by a constant
interval forecast, which must then be less precise: a gain in model simplicity
is thus paid for by a loss in precision. But imprecise randomness can't always
be explained away as a result of oversimplification: we show that there are
sequences that are random for a constant interval forecast, but never random
for any {\comp} (more) precise forecasting system. We also show that the set of
sequences that are random for a non-vacuous interval forecasting system is
meagre, as it is for precise forecasting systems.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:22:31 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 13:50:51 GMT""}]","2021-06-24"
"2103.00072","Gabriel Goldberg","Gabriel Goldberg","A note on cardinal preserving embeddings","4 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the consistency of the theory ZFC + there is a strongly compact
cardinal from the existence of a cardinal preserving embedding from the
universe into an inner model. The proof almost shows that under SCH, every
cardinal preserving embedding preserves the cofinality and continuum functions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:28:03 GMT""}]","2021-03-02"
"2103.00073","Nan Jiang","Nan Jiang, Thibaud Lutellier, Lin Tan","CURE: Code-Aware Neural Machine Translation for Automatic Program Repair","This paper is accepted by 2021 IEEE/ACM 43rd International Conference
  on Software Engineering (ICSE)",,"10.1109/ICSE43902.2021.00107",,"cs.SE cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Automatic program repair (APR) is crucial to improve software reliability.
Recently, neural machine translation (NMT) techniques have been used to fix
software bugs automatically. While promising, these approaches have two major
limitations. Their search space often does not contain the correct fix, and
their search strategy ignores software knowledge such as strict code syntax.
Due to these limitations, existing NMT-based techniques underperform the best
template-based approaches.
  We propose CURE, a new NMT-based APR technique with three major novelties.
First, CURE pre-trains a programming language (PL) model on a large software
codebase to learn developer-like source code before the APR task. Second, CURE
designs a new code-aware search strategy that finds more correct fixes by
focusing on compilable patches and patches that are close in length to the
buggy code. Finally, CURE uses a subword tokenization technique to generate a
smaller search space that contains more correct fixes.
  Our evaluation on two widely-used benchmarks shows that CURE correctly fixes
57 Defects4J bugs and 26 QuixBugs bugs, outperforming all existing APR
techniques on both benchmarks.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:30:28 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 02:31:23 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 04:41:33 GMT""},{""version"":""v4"",""created"":""Thu, 2 Sep 2021 13:55:34 GMT""}]","2021-09-03"
"2103.00074","Bianca Thompson","Zo\""e Bell, Jasmine Camero, Karina Cho, Trevor Hyde, Chieh-Mi Lu,
  Rebecca Miller, Bianca Thompson, Eric Zhu","Density of Periodic Points for Latt\`es maps over Finite Fields","13 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $L_d$ be the Latt\`es map associated to the multiplication-by-$d$
endomorphism of an elliptic curve $E$ defined over a finite field
$\mathbb{F}_q$. We determine the density $\delta(L_d,q)$ of periodic points for
$L_d$ in $\mathbb{P}^1(\mathbb{F}_q)$. We show that the periodic point
densities $\delta(L_d,q^n)$ converge as $n \rightarrow \infty$ along certain
arithmetic progressions, and compute simple explicit formulas for
$\delta(L_\ell,q)$ when $\ell$ is a prime and $E$ belongs to a special family
of supersingular elliptic curves.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:34:38 GMT""}]","2021-03-02"
"2103.00075","Xinyan Li","Yingxue Zhou, Xinyan Li, Arindam Banerjee","Noisy Truncated SGD: Optimization and Generalization",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent empirical work on stochastic gradient descent (SGD) applied to
over-parameterized deep learning has shown that most gradient components over
epochs are quite small. Inspired by such observations, we rigorously study
properties of Truncated SGD (T-SGD), that truncates the majority of small
gradient components to zeros. Considering non-convex optimization problems, we
show that the convergence rate of T-SGD matches the order of vanilla SGD. We
also establish the generalization error bound for T-SGD. Further, we propose
Noisy Truncated SGD (NT-SGD), which adds Gaussian noise to the truncated
gradients. We prove that NT-SGD has the same convergence rate as T-SGD for
non-convex optimization problems. We demonstrate that with the help of noise,
NT-SGD can provably escape from saddle points and requires less noise compared
to previous related work. We also prove that NT-SGD achieves better
generalization error bound compared to T-SGD because of the noise. Our
generalization analysis is based on uniform stability and we show that
additional noise in the gradient update can boost the stability. Our
experiments on a variety of benchmark datasets (MNIST, Fashion-MNIST, CIFAR-10,
and CIFAR-100) with various networks (VGG and ResNet) validate the theoretical
properties of NT-SGD, i.e., NT-SGD matches the speed and accuracy of vanilla
SGD while effectively working with sparse gradients, and can successfully
escape poor local minima.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:39:41 GMT""},{""version"":""v2"",""created"":""Sun, 17 Oct 2021 23:24:44 GMT""}]","2021-10-19"
"2103.00076","Haitao Wang","Haitao Wang","An Optimal Deterministic Algorithm for Geodesic Farthest-Point Voronoi
  Diagrams in Simple Polygons","To appear in SoCG 2021",,,,"cs.CG cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a set $S$ of $m$ point sites in a simple polygon $P$ of $n$ vertices,
we consider the problem of computing the geodesic farthest-point Voronoi
diagram for $S$ in $P$. It is known that the problem has an $\Omega(n+m\log m)$
time lower bound. Previously, a randomized algorithm was proposed [Barba, SoCG
2019] that can solve the problem in $O(n+m\log m)$ expected time. The previous
best deterministic algorithms solve the problem in $O(n\log \log n+ m\log m)$
time [Oh, Barba, and Ahn, SoCG 2016] or in $O(n+m\log m+m\log^2 n)$ time [Oh
and Ahn, SoCG 2017]. In this paper, we present a deterministic algorithm of
$O(n+m\log m)$ time, which is optimal. This answers an open question posed by
Mitchell in the Handbook of Computational Geometry two decades ago.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:45:00 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 03:32:13 GMT""}]","2021-05-25"
"2103.00077","Jorge Vila","Jorge A. Vila","Thoughts on the Proteins Native State","10 pages, 1 figure",,,,"q-bio.BM q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  The presence of metamorphism in the protein's native state is not yet fully
understood. In an attempt to throw light on this issue here we present an
assessment, in terms of the amide hydrogen exchange protection factor, that
aims to determine the likely existence of structural fluctuations in the
native-state consistent with both the upper bound marginal stability of
proteins and the metamorphism presence. The preliminary results enable us to
conclude that the native-state metamorphism is, indeed, more probable than
thought.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:47:27 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 15:33:10 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 12:12:28 GMT""}]","2021-05-21"
"2103.00078","Couvreur Alain","Anne Canteaut, Alain Couvreur, L\'eo Perrin","Recovering or Testing Extended-Affine Equivalence",,,,,"cs.CR cs.DM cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Extended Affine (EA) equivalence is the equivalence relation between two
vectorial Boolean functions $F$ and $G$ such that there exist two affine
permutations $A$, $B$, and an affine function $C$ satisfying $G = A \circ F
\circ B + C$. While the problem has a simple formulation, it is very difficult
in practice to test whether two functions are EA-equivalent. This problem has
two variants: {\em EA-partitioning} deals with partitioning a set of functions
into disjoint EA-equivalence classes, and \emph{EA-recovery} is about
recovering the tuple $(A,B,C)$ if it exists.
  In this paper, we present a new algorithm that efficiently solves the
EA-recovery problem for quadratic functions. Although its worst-case complexity
occurs when dealing with APN functions, it supersedes, in terms of performance,
all previously known algorithms for solving this problem for all quadratic
functions and in any dimension, even in the case of APN functions. This
approach is based on the Jacobian matrix of the functions, a tool whose study
in this context can be of independent interest.
  The best approach for EA-partitioning in practice mainly relies on class
invariants. We provide an overview of the known invariants along with a new one
based on the \emph{ortho-derivative}. This new invariant is applicable to
quadratic APN functions, a specific type of functions that is of great
interest, and of which tens of thousands need to be sorted into distinct
EA-classes. Our ortho-derivative-based invariant is very fast to compute, and
it practically always distinguishes between EA-inequivalent quadratic APN
functions.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 22:52:29 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 15:47:13 GMT""},{""version"":""v3"",""created"":""Mon, 16 May 2022 14:27:51 GMT""}]","2022-05-17"
"2103.00079","Weilin Li","C. Sinan G\""unt\""urk, Weilin Li","Quantization for spectral super-resolution","29 pages, 2 figures, to appear in Constructive Approximation",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the method of distributed noise-shaping beta-quantization offers
superior performance for the problem of spectral super-resolution with
quantization whenever there is redundancy in the number of measurements. More
precisely, we define the oversampling ratio $\lambda$ as the largest integer
such that $\lfloor M/\lambda\rfloor - 1\geq 4/\Delta$, where $M$ denotes the
number of Fourier measurements and $\Delta$ is the minimum separation distance
associated with the atomic measure to be resolved. We prove that for any number
$K\geq 2$ of quantization levels available for the real and imaginary parts of
the measurements, our quantization method combined with either TV-min/BLASSO or
ESPRIT guarantees reconstruction accuracy of order $O(M^{1/4}\lambda^{5/4} K^{-
\lambda/2})$ and $O(M^{3/2} \lambda^{1/2} K^{- \lambda})$ respectively, where
the implicit constants are independent of $M$, $K$ and $\lambda$. In contrast,
naive rounding or memoryless scalar quantization for the same alphabet offers a
guarantee of order $O(M^{-1}K^{-1})$ only, regardless of the reconstruction
algorithm.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:00:59 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 20:20:24 GMT""}]","2022-03-02"
"2103.00080","Jes\'us A. Maytorena","D. Morachis Galindo, F. Rojas, Jes\'us A. Maytorena","Topological Uhlmann phase transitions for a spin-j particle in a
  magnetic field",,"Phys. Rev. A 103, 042221 (2021)","10.1103/PhysRevA.103.042221",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The generalization of the geometric phase to the realm of mixed states is
known as Uhlmann phase. Recently, applications of this concept to the field of
topological insulators have been made and an experimental observation of a
characteristic critical temperature at which the topological Uhlmann phase
disappears has also been reported. Surprisingly, to our knowledge, the Uhlmann
phase of such a paradigmatic system as the spin-$j$ particle in presence of a
slowly rotating magnetic field has not been reported to date. Here we study the
case of such a system in a thermal ensemble. We find that the Uhlmann phase is
given by the argument of a complex valued second kind Chebyshev polynomial of
order $2j$. Correspondingly, the Uhlmann phase displays $2j$ singularities,
occurying at the roots of such polynomials which define critical temperatures
at which the system undergoes topological order transitions. Appealing to the
argument principle of complex analysis each topological order is characterized
by a winding number, which happen to be $2j$ for the ground state and decrease
by unity each time increasing temperature passes through a critical value. We
hope this study encourages experimental verification of this phenomenon of
thermal control of topological properties, as has already been done for the
spin-$1/2$ particle.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:01:00 GMT""}]","2021-05-05"
"2103.00081","Krishna Kumar","Xiang Sun, Kenichi Soga, Alp Cinar, Zhenxiang Su, Kecheng Chen,
  Krishna Kumar, Patrick F. Dobson, Peter S. Nico","An HPC-Based Hydrothermal Finite Element Simulator for Modeling
  Underground Response to Community-Scale Geothermal Energy Production","46th Workshop on Geothermal Reservoir Engineering Stanford
  University, Stanford, California, February 15-17, 2021",,,,"cs.DC physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Geothermal heat, as renewable energy, shows great advantage with respect to
its environmental impact due to its significantly lower CO2 emissions than
conventional fossil fuel. Open and closed-loop geothermal heat pumps, which
utilize shallow geothermal systems, are an efficient technology for cooling and
heating buildings, especially in urban areas. Integrated use of geothermal
energy technologies for district heating, cooling, and thermal energy storage
can be applied to optimize the subsurface for communities to provide them with
multiple sustainable energy and community resilience benefits. The utilization
of the subsurface resources may lead to a variation in the underground
environment, which might further impact local environmental conditions.
However, very few simulators can handle such a highly complex set of coupled
computations on a regional or city scale. We have developed high-performance
computing (HPC) based hydrothermal finite element (FE) simulator that can
simulate the subsurface and its hydrothermal conditions at a scale of tens of
km. The HPC simulator enables us to investigate the subsurface thermal and
hydrologic response to the built underground environment (such as basements and
subways) at the community scale. In this study, a coupled hydrothermal
simulator is developed based on the open-source finite element library deal.II.
The HPC simulator was validated by comparing the results of a benchmark case
study against COMSOL Multiphysics, in which Aquifer Thermal Energy Storage
(ATES) is modeled and a process of heat injection into ATES is simulated. The
use of an energy pile system at the Treasure Island redevelopment site (San
Francisco, CA, USA) was selected as a case study to demonstrate the HPC
capability of the developed simulator. The simulator is capable of modeling
multiple city-scale geothermal scenarios in a reasonable amount of time.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:06:46 GMT""}]","2021-03-02"
"2103.00082","Michael Cochez","Leandro Eichenberger, Michael Cochez, Benjamin Heitmann, Stefan Decker","Secure Evaluation of Knowledge Graph Merging Gain",,,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding out the differences and commonalities between the knowledge of two
parties is an important task. Such a comparison becomes necessary, when one
party wants to determine how much it is worth to acquire the knowledge of the
second party, or similarly when two parties try to determine, whether a
collaboration could be beneficial. When these two parties cannot trust each
other (for example, due to them being competitors) performing such a comparison
is challenging as neither of them would be willing to share any of their
assets. This paper addresses this problem for knowledge graphs, without a need
for non-disclosure agreements nor a third party during the protocol.
  During the protocol, the intersection between the two knowledge graphs is
determined in a privacy preserving fashion. This is followed by the computation
of various metrics, which give an indication of the potential gain from
obtaining the other parties knowledge graph, while still keeping the actual
knowledge graph contents secret. The protocol makes use of blind signatures and
(counting) Bloom filters to reduce the amount of leaked information. Finally,
the party who wants to obtain the other's knowledge graph can get a part of
such in a way that neither party is able to know beforehand which parts of the
graph are obtained (i.e., they cannot choose to only get or share the good
parts). After inspection of the quality of this part, the Buyer can decide to
proceed with the transaction.
  The analysis of the protocol indicates that the developed protocol is secure
against malicious participants. Further experimental analysis shows that the
resource consumption scales linear with the number of statements in the
knowledge graph.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:19:53 GMT""}]","2021-03-02"
"2103.00083","Rasool Fakoor","Rasool Fakoor, Taesup Kim, Jonas Mueller, Alexander J. Smola, Ryan J.
  Tibshirani","Flexible Model Aggregation for Quantile Regression","Accepted at JMLR 2023",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantile regression is a fundamental problem in statistical learning
motivated by a need to quantify uncertainty in predictions, or to model a
diverse population without being overly reductive. For instance,
epidemiological forecasts, cost estimates, and revenue predictions all benefit
from being able to quantify the range of possible values accurately. As such,
many models have been developed for this problem over many years of research in
statistics, machine learning, and related fields. Rather than proposing yet
another (new) algorithm for quantile regression we adopt a meta viewpoint: we
investigate methods for aggregating any number of conditional quantile models,
in order to improve accuracy and robustness. We consider weighted ensembles
where weights may vary over not only individual models, but also over quantile
levels, and feature values. All of the models we consider in this paper can be
fit using modern deep learning toolkits, and hence are widely accessible (from
an implementation point of view) and scalable. To improve the accuracy of the
predicted quantiles (or equivalently, prediction intervals), we develop tools
for ensuring that quantiles remain monotonically ordered, and apply conformal
calibration methods. These can be used without any modification of the original
library of base models. We also review some basic theory surrounding quantile
aggregation and related scoring rules, and contribute a few new results to this
literature (for example, the fact that post sorting or post isotonic regression
can only improve the weighted interval score). Finally, we provide an extensive
suite of empirical comparisons across 34 data sets from two different benchmark
repositories.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:21:16 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 01:23:59 GMT""},{""version"":""v3"",""created"":""Fri, 23 Jul 2021 17:11:29 GMT""},{""version"":""v4"",""created"":""Thu, 14 Jul 2022 19:03:55 GMT""},{""version"":""v5"",""created"":""Sat, 15 Apr 2023 08:40:57 GMT""}]","2023-04-18"
"2103.00084","Xinyi Huang","Xinyi Huang, Naman Jain, Mahdi Abkar, Robert Kunz, Xiang Yang","Determining a priori a RANS model's applicable range via global
  epistemic uncertainty quantification",,,"10.1016/j.compfluid.2021.105113",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Calibrating a Reynolds-averaged Navier-Stokes (RANS) model against data leads
to an improvement. Determining {\it a priori} if such an improvement
generalizes to flows outside the calibration data is an outstanding challenge.
This work attempts to address this challenge via global epistemic Uncertainty
Quantification (UQ). Unlike the available epistemic UQ methods that are local
and tell us a model's uncertainty at one specific flow condition, the global
epistemic UQ method presented in this work tells us also whether a perturbation
of the original model would generalize. Specifically, the global epistemic UQ
method evaluates a potential improvement in terms of its ""effectiveness"" and
""inconsistency"". Any improvement can be put in one of the following four
quadrants: first, high effectiveness, low inconsistency; second, high
effectiveness, high inconsistency; third, low effectiveness, low inconsistency;
and fourth, low effectiveness, high inconsistency. An improvement would
generalize if and only if it is in the high effectiveness and low inconsistency
quadrant. To demonstrate the concept, we apply the global epistemic UQ to full
Reynolds stress modeling of a stratified shear layer. The global epistemic UQ
results point to a model coefficient in the pressure-strain correlation closure
(among others) as effective and consistent for predicting the quantity of
interest of shear layer's growth. We calibrate the model coefficient such that
our RANS matches direct numerical simulation data at one flow condition. We
show that the calibrated model generalizes to several other test flow
conditions. On the other hand, when calibrating a high inconsistency term, we
get a model that works at only the calibrated condition.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:32:13 GMT""}]","2023-03-07"
"2103.00085","Alexander R. Pruss","Alexander R. Pruss","Necessary and Sufficient Conditions for Domination Results for Proper
  Scoring Rules",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scoring rules measure the deviation between a probabilistic forecast and
reality. Strictly proper scoring rules have the property that for any forecast,
the mathematical expectation of the score of a forecast p by the lights of p is
strictly better than the mathematical expectation of any other forecast q by
the lights of p. Probabilistic forecasts need not satisfy the axioms of the
probability calculus, but Predd, et al. (2009) have shown that given a finite
sample space and any strictly proper additive and continuous scoring rule, the
score for any forecast that does not satisfy the axioms of probability is
strictly dominated by the score for some probabilistically consistent forecast.
Recently, this result has been extended to non-additive continuous scoring
rules. In this paper, a condition weaker than continuity is given that suffices
for the result, and the condition is proved to be optimal.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:33:42 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 19:08:15 GMT""},{""version"":""v3"",""created"":""Tue, 27 Sep 2022 17:34:20 GMT""}]","2022-09-28"
"2103.00086","Moshiur R Farazi","Ce Wang, Moshiur Farazi, Nick Barnes","Recursive Training for Zero-Shot Semantic Segmentation",,"2021 International Joint Conference on Neural Networks (IJCNN)","10.1109/IJCNN52387.2021.9534049",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  General purpose semantic segmentation relies on a backbone CNN network to
extract discriminative features that help classify each image pixel into a
'seen' object class (ie., the object classes available during training) or a
background class. Zero-shot semantic segmentation is a challenging task that
requires a computer vision model to identify image pixels belonging to an
object class which it has never seen before. Equipping a general purpose
semantic segmentation model to separate image pixels of 'unseen' classes from
the background remains an open challenge. Some recent models have approached
this problem by fine-tuning the final pixel classification layer of a semantic
segmentation model for a Zero-Shot setting, but struggle to learn
discriminative features due to the lack of supervision. We propose a recursive
training scheme to supervise the retraining of a semantic segmentation model
for a zero-shot setting using a pseudo-feature representation. To this end, we
propose a Zero-Shot Maximum Mean Discrepancy (ZS-MMD) loss that weighs high
confidence outputs of the pixel classification layer as a pseudo-feature
representation, and feeds it back to the generator. By closing-the-loop on the
generator end, we provide supervision during retraining that in turn helps the
model learn a more discriminative feature representation for 'unseen' classes.
We show that using our recursive training and ZS-MMD loss, our proposed model
achieves state-of-the-art performance on the Pascal-VOC 2012 dataset and
Pascal-Context dataset.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:44:16 GMT""}]","2021-10-06"
"2103.00087","Domenico Gatti","Haikal Abdulah, Benjamin Huber, Sinan Lal, Hassan Abdallah, Luigi L.
  Palese, Hamid Soltanian-Zadeh, Domenico L. Gatti","CXR-Net: An Artificial Intelligence Pipeline for Quick Covid-19
  Screening of Chest X-Rays","16 pages, 14 figures. arXiv admin note: substantial text overlap with
  arXiv:2011.08655",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  CXR-Net is a two-module Artificial Intelligence pipeline for the quick
detection of SARS-CoV-2 from chest X-rays (CXRs). Module 1 was trained on a
public dataset of 6395 CXRs with radiologist annotated lung contours to
generate masks of the lungs that overlap the heart and large vasa. Module 2 is
a hybrid convnet in which the first convolutional layer with learned
coefficients is replaced by a layer with fixed coefficients provided by the
Wavelet Scattering Transform (WST). Module 2 takes as inputs the patients CXRs
and corresponding lung masks calculated by Module 1, and produces as outputs a
class assignment (Covid vs. non-Covid) and high resolution heat maps that
identify the SARS associated lung regions. Module 2 was trained on a dataset of
CXRs from non-Covid and RT-PCR confirmed Covid patients acquired at the Henry
Ford Health System (HFHS) Hospital in Detroit. All non-Covid CXRs were from
pre-Covid era (2018-2019), and included images from both normal lungs and lungs
affected by non-Covid pathologies. Training and test sets consisted of 2265
CXRs (1417 Covid negative, 848 Covid positive), and 1532 CXRs (945 Covid
negative, 587 Covid positive), respectively. Six distinct cross-validation
models, each trained on 1887 images and validated against 378 images, were
combined into an ensemble model that was used to classify the CXR images of the
test set with resulting Accuracy = 0.789, Precision = 0.739, Recall = 0.693, F1
score = 0.715, ROC(AUC) = 0.852.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:45:15 GMT""}]","2021-03-02"
"2103.00088","Rui Ma","Jun Hu, Yizhou Liang and Rui Ma","Conforming finite element DIVDIV complexes and the application for the
  linearized Einstein-Bianchi system",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  This paper presents the first family of conforming finite element divdiv
complexes on tetrahedral grids in three dimensions. In these complexes, finite
element spaces of $H(\text{divdiv},\Omega;\mathbb{S})$ are from a current
preprint [Chen and Huang, arXiv: 2007.12399, 2020] while finite element spaces
of both $H(\text{symcurl},\Omega;\mathbb{T})$ and $H^1(\Omega;\mathbb{R}^3)$
are newly constructed here. It is proved that these finite element complexes
are exact. As a result, they can be used to discretize the linearized
Einstein-Bianchi system within the dual formulation.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:50:49 GMT""}]","2021-03-02"
"2103.00089","Lat\'evi Mohamed Lawson","Lat\'evi Mohamed Lawson","Thermodynamics of ideal gas at Planck scale with strong quantum gravity
  measurement","18. arXiv admin note: text overlap with arXiv:2012.10551",,,,"hep-th math-ph math.MP quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  More recently in [J. Phys. A: Math. Theor. 53, 115303 (2020)], we have
introduced a set of noncommutative algebra that describes the space-time at the
Planck scale. The interesting significant result we found is that the
generalized uncertainty principle induced a maximal length of quantum gravity
which has different physical implications to the one of generalized uncertainty
principle with minimal length. The emergence of a maximal length in this theory
revealed strong quantum gravitational effects at this scale and predicted the
detection of gravity particles with low energies. To make evidence of these
predictions, we study the dynamics of a free particle confined in an infinite
square well potential in one dimension of this space. Since the effects of
quantum gravity are strong in this space, we show that the energy spectrum of
this system is weakly proportional to the ordinary one of quantum mechanics
free of the theory of gravity. The states of this particle exhibit proprieties
similar to the standard coherent states which are consequences of quantum
fluctuation at this scale. Then, with the spectrum of this system at hand, we
analyze the thermodynamic quantities within the canonical and microcanonical
ensembles of an ideal gas made up of $N$ indistinguishable particles at the
Planck scale. The results show a complete consistency between both statistical
descriptions. Furthermore, a comparison with the results obtained in the
context of minimal length scenarios and black hole theories indicates that the
maximal length in this theory induces logarithmic corrections of deformed
parameters which are consequences of a strong quantum gravitational effect.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:57:23 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 22:40:35 GMT""}]","2021-03-30"
"2103.00090","Flash Sheridan","Flash Sheridan","A Naive View of the Russell Paradox","17 pages. Revised version of unpublished article referenced in
  Logique et Analyse, Vol 59, No 233 (2016)
  http://www.logic-center.be/Publications/Bibliotheque/SheridanVariantChurch.pdf",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two types of approximation to the paradoxical Russell Set are presented, one
approximating it from below, one from above. It is shown that any lower
approximation gives rise to a better approximation containing it, and that any
upper approximation contains a distinct better approximation. The Russell
Paradox is then seen to be the claim that two of these processes of better
approximations stop, and at the same set. I claim that this shows the
unrestricted Axiom of Comprehension to be, not a coherent intuition worthy of
rescue from a mysterious paradox, but simply wishful thinking, a confusion of
sets as extensional objects with classes defined by a property.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:57:26 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 23:30:45 GMT""},{""version"":""v3"",""created"":""Tue, 1 Mar 2022 02:39:28 GMT""}]","2022-03-02"
"2103.00091","Matteo Turilli","Andre Merzky, Matteo Turilli, Mikhail Titov, Aymen Al-Saadi, Shantenu
  Jha","Design and Performance Characterization of RADICAL-Pilot on
  Leadership-class Platforms","arXiv admin note: text overlap with arXiv:1801.01843",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many extreme scale scientific applications have workloads comprised of a
large number of individual high-performance tasks. The Pilot abstraction
decouples workload specification, resource management, and task execution via
job placeholders and late-binding. As such, suitable implementations of the
Pilot abstraction can support the collective execution of large number of tasks
on supercomputers. We introduce RADICAL-Pilot (RP) as a portable, modular and
extensible pilot-enabled runtime system. We describe RP's design, architecture
and implementation. We characterize its performance and show its ability to
scalably execute workloads comprised of tens of thousands heterogeneous tasks
on DOE and NSF leadership-class HPC platforms. Specifically, we investigate
RP's weak/strong scaling with CPU/GPU, single/multi core, (non)MPI tasks and
Python functions when using most of ORNL Summit and TACC Frontera.
RADICAL-Pilot can be used stand-alone, as well as the runtime for third-party
workflow systems.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:57:47 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 17:17:53 GMT""}]","2021-11-03"
"2103.00092","Md Kamran Chowdhury Shisher","Md Kamran Chowdhury Shisher, Heyang Qin, Lei Yang, Feng Yan, and Yin
  Sun","The Age of Correlated Features in Supervised Learning based Forecasting",,,,,"cs.LG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we analyze the impact of information freshness on supervised
learning based forecasting. In these applications, a neural network is trained
to predict a time-varying target (e.g., solar power), based on multiple
correlated features (e.g., temperature, humidity, and cloud coverage). The
features are collected from different data sources and are subject to
heterogeneous and time-varying ages. By using an information-theoretic
approach, we prove that the minimum training loss is a function of the ages of
the features, where the function is not always monotonic. However, if the
empirical distribution of the training data is close to the distribution of a
Markov chain, then the training loss is approximately a non-decreasing age
function. Both the training loss and testing loss depict similar growth
patterns as the age increases. An experiment on solar power prediction is
conducted to validate our theory. Our theoretical and experimental results
suggest that it is beneficial to (i) combine the training data with different
age values into a large training dataset and jointly train the forecasting
decisions for these age values, and (ii) feed the age value as a part of the
input feature to the neural network.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 00:10:49 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 21:21:07 GMT""}]","2021-04-09"
"2103.00093","Haowei Xu","Haowei Xu, Hua Wang, Jian Zhou, Yunfan Guo, Jing Kong and Ju Li","Colossal switchable photocurrents in topological Janus transition metal
  dichalcogenides",,"npj Computational Materials 7, 31 (2021)","10.1038/s41524-021-00499-4",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Nonlinear optical properties, such as bulk photovoltaic effects, possess
great potential in energy harvesting, photodetection, rectification, etc. To
enable efficient light-current conversion, materials with strong
photo-responsivity are highly desirable. In this work, we predict that
monolayer Janus transition metal dichalcogenides (JTMDs) in the 1T' phase
possess colossal nonlinear photoconductivity owing to their topological band
mixing, strong inversion symmetry breaking, and small electronic bandgap. 1T'
JTMDs have inverted bandgaps on the order of 10 meV and are exceptionally
responsive to light in the terahertz (THz) range. By first-principles
calculations, we reveal that 1T' JTMDs possess shift current (SC) conductivity
as large as $2300 ~\rm nm \cdot \mu A / V^2$, equivalent to a
photo-responsivity of $2800 ~\rm mA/W$. The circular current (CC) conductivity
of 1T' JTMDs is as large as $10^4~ \rm nm \cdot \mu A / V^2$. These remarkable
photo-responsivities indicate that the 1T' JTMDs can serve as efficient
photodetectors in the THz range. We also find that external stimuli such as the
in-plane strain and out-of-plane electric field can induce topological phase
transitions in 1T' JTMDs and that the SC can abruptly flip their directions.
The abrupt change of the nonlinear photocurrent can be used to characterize the
topological transition and has potential applications in 2D optomechanics and
nonlinear optoelectronics.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 00:42:44 GMT""}]","2021-03-02"
"2103.00094","Kevin Coulembier","Kevin Coulembier, Pavel Etingof, Victor Ostrik and Bregje Pauwels","Monoidal Abelian Envelopes with a quotient property",,,,,"math.CT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study abelian envelopes for pseudo-tensor categories with the property
that every object in the envelope is a quotient of an object in the
pseudo-tensor category. We establish an intrinsic criterion on pseudo-tensor
categories for the existence of an abelian envelope satisfying this quotient
property. This allows us to interpret the extension of scalars and Deligne
tensor product of tensor categories as abelian envelopes, and to enlarge the
class of tensor categories for which all extensions of scalars and tensor
products are known to remain tensor categories. For an affine group scheme G,
we show that pseudo-tensor subcategories of RepG have abelian envelopes with
the quotient property, and we study many other such examples. This leads us to
conjecture that all abelian envelopes satisfy the quotient property.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 00:50:18 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 07:10:13 GMT""},{""version"":""v3"",""created"":""Sat, 15 Oct 2022 22:10:07 GMT""}]","2022-10-18"
"2103.00095","Romeo A. Saldana-Vazquez","Maria Eugenia Ibarraran, Romeo A. Saldana-Vazquez, Tamara Perez-Garcia","The Cost of Pollution in the Upper Atoyac River Basin: A Systematic
  Review","14 pages, 6 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-sa/4.0/","  The Atoyac River is among the two most polluted in Mexico. Water quality in
the Upper Atoyac River Basin (UARB) has been devastated by industrial and
municipal wastewater, as well as from effluents from local dwellers, that go
through little to no treatment, affecting health, production, ecosystems and
property value. We did a systematic review and mapping of the costs that
pollution imposes on different sectors and localities in the UARB, and
initially found 358 studies, of which 17 were of our particular interest. We
focus on estimating the cost of pollution through different valuation methods
such as averted costs, hedonic pricing, and contingent valuation, and for that
we only use 10 studies. Costs range from less than a million to over $16
million dollars a year, depending on the sector, with agriculture, industry and
tourism yielding the highest costs. This exercise is the first of its kind in
the UARB that maps costs for sectors and localities affected, and sheds light
on the need of additional research to estimate the total cost of pollution
throughout the basin. This information may help design further research needs
in the region.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:07:05 GMT""}]","2021-03-02"
"2103.00096","Bin Sun","Bin Sun, Benjamin Richstein, Patrick Liebisch, Thorben Frahm, Stefan
  Scholz, Jens Trommer, Thomas Mikolajick, Joachim Knoch","On the Performance of Dual-Gate Reconfigurable Nanowire Transistors","5 pages","IEEE Transactions on Electron Devices, vol. 68, no. 7, pp.
  3684-3689, 2021","10.1109/TED.2021.3081527","RWTH-2021-06848","physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the operation of dual-gate reconfigurable field-effect
transistor (RFET) in the programgate at drain (PGAD) and program-gate at source
(PGAS) configurations. To this end, dual-gate silicon nanowire (SiNW) FETs are
fabricated based on anisotropic wet chemical silicon etching and nickel
silicidation yielding silicide-SiNW Schottky junctions at source and drain.
Whereas in PGAD-configuration ambipolar operation is suppressed, switching is
deteriorated due to the injection through a Schottky-barrier. Operating the
RFET in PGAS configuration yields a switching behavior close to a conventional
MOSFET. This, howewer, needs to be traded off against strongly non-linear
output characteristics for small bias.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:10:06 GMT""}]","2021-08-05"
"2103.00097","Parth Sane","Parth Sane","A Brief Survey of Current Software Engineering Practices in Continuous
  Integration and Automated Accessibility Testing","IEEE Conference WiSPNET 2021 Accepted Preprint",,,,"cs.SE cs.CY cs.HC cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It's long been accepted that continuous integration (CI) in software
engineering increases the code quality of enterprise projects when adhered to
by it's practitioners. But is any of that effort to increase code quality and
velocity directed towards improving software accessibility accommodations? What
are the potential benefits quoted in literature? Does it fit with the modern
agile way that teams operate in most enterprises? This paper attempts to map
the current scene of the software engineering effort spent on improving
accessibility via continuous integration and it's hurdles to adoption as quoted
by researchers. We also try to explore steps that agile teams may take to train
members on how to implement accessibility testing and introduce key diagrams to
visualize processes to implement CI based accessibility testing procedures in
the software development lifecycle.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:13:43 GMT""}]","2021-03-02"
"2103.00098","Hongchang Zhang","Hongchang Zhang, Jianzhun Shao, Yuhang Jiang, Shuncheng He, Xiangyang
  Ji","Reducing Conservativeness Oriented Offline Reinforcement Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In offline reinforcement learning, a policy learns to maximize cumulative
rewards with a fixed collection of data. Towards conservative strategy, current
methods choose to regularize the behavior policy or learn a lower bound of the
value function. However, exorbitant conservation tends to impair the policy's
generalization ability and degrade its performance, especially for the mixed
datasets. In this paper, we propose the method of reducing conservativeness
oriented reinforcement learning. On the one hand, the policy is trained to pay
more attention to the minority samples in the static dataset to address the
data imbalance problem. On the other hand, we give a tighter lower bound of
value function than previous methods to discover potential optimal actions.
Consequently, our proposed method is able to tackle the skewed distribution of
the provided dataset and derive a value function closer to the expected value
function. Experimental results demonstrate that our proposed method outperforms
the state-of-the-art methods in D4RL offline reinforcement learning evaluation
tasks and our own designed mixed datasets.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:21:01 GMT""}]","2021-03-02"
"2103.00099","Yan Xingjie","Haining Fan, Zhaosheng Feng, Xingjie Yan","Positive solutions for the fractional Schr\""{o}dinger equations with
  logarithmic and critical nonlinearities","40 pages",,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study a class of fractional Schr\""{o}dinger equations
involving logarithmic and critical nonlinearities on an unbounded domain, and
show that such an equation with positive or sign-changing weight potentials
admits at least one positive ground state solution and the associated energy is
positive (or negative). By applying the Nehari manifold method and
Ljusternik-Schnirelmann category, we deeply investigate how the weight
potential affects the multiplicity of positive solutions, and obtain the
relationship between the number of positive solutions and the category of some
sets related to the weight potential.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:29:11 GMT""}]","2021-03-02"
"2103.00100","Kazuyuki Ogata","Kazuyuki Ogata, Tokuro Fukui, Yuki Kamiya, and Akira Ohnishi","Effect of deuteron breakup on the deuteron-$\Xi$ correlation function","13 pages, 12 figures","Phys. Rev. C 103, 065205 (2021)","10.1103/PhysRevC.103.065205",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hadron-deuteron correlation function has attracted many interests as a
potential method to access the three-hadron interactions. However, the
weakly-bound nature of deuteron has not been considered in the preceding
studies. In this study, the breakup effect of deuteron on the deuteron-$\Xi^-$
($d$-$\Xi^-$) correlation function $C_{d\Xi^-}$ is investigated. The
$d$-$\Xi^-$ scattering is described by a nucleon-nucleon-$\Xi$ three-body
reaction model. The continuum-discretized coupled-channels method, which is a
fully quantum-mechanical and non-perturbative reaction model, is adopted.
$C_{d\Xi^-}$ turns out to be sensitive to the strong interaction and enhanced
by the deuteron breakup effect by 6--8 % for the $d$-$\Xi^-$ relative momentum
below about 70 MeV/$c$. Low-lying neutron-neutron continuum states are
responsible for this enhancement. Within the adopted model, the deuteron
breakup effect on $C_{d\Xi^-}$ is found to be appreciable but not very
significant. Except for the enhancement by several percent, studies on
$C_{d\Xi^-}$ without the deuteron breakup effect can be justified.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:33:20 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 00:23:05 GMT""}]","2021-07-07"
"2103.00101","Yasuhiro Kishimoto","Y. Kishimoto, Y. Suzuki, I. Ogawa, Y. Mori, and M. Yamashita","Development of a cavity with photonic crystal structure for axion
  searches","15 pages, 9 figures, 3 tables","Prog Theor Exp Phys (2021)","10.1093/ptep/ptab051",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two cavities in different size with the photonic crystal structure have been
developed for axion searches. In the cavities, the dispersion relation in the
photonic crystal is utilised, and so was named to ""DRiPC cavities"". The size of
the smaller one is 100 mm x 100 mm x 10 mm, where 16 cylindrical metal poles
with a diameter of 4 mm are introduced in a 4x4 grid at 20 mm intervals. In
this study, the grid interval in x direction in the small size cavity, Lx, was
changed to investigate resonance frequency, Q-value, and electric field profile
at each Lx. The lowest three frequencies have been compared with the ones
simulated by the finite element method to be found in excellent agreement. The
lowest frequency mode could be tuned from 5.10 GHz (Lx = 25.0 mm) to 6.72 GHz
(13.9 mm), centering on 5.87 GHz at Lx = 20 mm. This wide range tunability,
27.7%, was suitable for a search with a modest Q-value. By examining the
electric field distributions with the bead pull method, the lowest frequency
mode at Lx = 16.0 - 25.0 mm were TM010-like. This mode was also obtained in a
larger size cavity (180 mm x 180 mm x 20 mm x 2) with the same photonic crystal
structure. These results led us to conclude a DRiPC cavity has the noble
features for future axion search experiments.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:54:08 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 09:16:37 GMT""},{""version"":""v3"",""created"":""Wed, 14 Apr 2021 06:22:36 GMT""}]","2021-06-23"
"2103.00102","Rodrigo Hern\'andez Guti\'errez","Rodrigo Hern\'andez-Guti\'errez, Alfredo Zaragoza","A characterization of the product of the rational numbers and complete
  Erd\H{o}s space",,"Canadian Mathematical Bulletin, 2022","10.4153/S0008439522000091",,"math.GN","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Erd\H{o}s space $\mathfrak{E}$ and complete Erd\H{o}s space $\mathfrak{E}_c$
have been previously shown to have topological characterizations. In this
paper, we provide a topological characterization of the topological space
$\mathbb{Q}\times\mathfrak{E}_c$, where $\mathbb{Q}$ is the space of rational
numbers. As a corollary, we show that the Vietoris hyperspace of finite sets
$\mathcal{F}(\mathfrak{E}_c)$ is homeomorphic to
$\mathbb{Q}\times\mathfrak{E}_c$. We also characterize the factors of
$\mathbb{Q}\times\mathfrak{E}_c$. An interesting open question that is left
open is whether $\sigma{\mathfrak{E}_c}^\omega$, the $\sigma$-product of
countably many copies of $\mathfrak{E}_c$, is homeomorphic to
$\mathbb{Q}\times\mathfrak{E}_c$.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 01:57:01 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 18:28:35 GMT""}]","2022-02-01"
"2103.00103","Rodrigo de Lamare","Z. Shao, L. Landau and R. de Lamare","Dynamic Oversampling Tecniques for 1-Bit ADCs in Large-Scale MIMO
  Systems","11 figures, 12 pages",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we investigate dynamic oversampling techniques for large-scale
multiple-antenna systems equipped with low-cost and low-power 1-bit
analog-to-digital converters at the base stations. To compensate for the
performance loss caused by the coarse quantization, oversampling is applied at
the receiver. Unlike existing works that use uniform oversampling, which
samples the signal at a constant rate, a novel dynamic oversampling scheme is
proposed. The basic idea is to perform time-varying nonuniform oversampling,
which selects samples with nonuniform patterns that vary over time. We consider
two system design criteria: a design that maximizes the achievable sum rate and
another design that minimizes the mean square error of detected symbols.
Dynamic oversampling is carried out using a dimension reduction matrix
$\mathbf{\Delta}$, which can be computed by the generalized eigenvalue
decomposition or by novel submatrix-level feature selection algorithms.
Moreover, the proposed scheme is analyzed in terms of convergence,
computational complexity and power consumption at the receiver. Simulations
show that systems with the proposed dynamic oversampling outperform those with
uniform oversampling in terms of computational cost, achievable sum rate and
symbol error rate performance.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:02:19 GMT""}]","2021-03-02"
"2103.00104","Victor Manuel Bastidas Valencia","A. Sakurai, V. M. Bastidas, W. J. Munro, and Kae Nemoto","Chimera Time-Crystalline order in quantum spin networks","5 pages, 4 Figures and supplemental material. Accepted for
  Publication in Physical Review Letters. Comments are welcome","Phys. Rev. Lett. 126, 120606 (2021)","10.1103/PhysRevLett.126.120606",,"quant-ph cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetries are well known to have had a profound role in our understanding of
nature and are a critical design concept for the realization of advanced
technologies. In fact, many symmetry-broken states associated with different
phases of matter appear in a variety of quantum technology applications. Such
symmetries are normally broken in spatial dimension, however they can also be
broken temporally leading to the concept of discrete time symmetries and their
associated crystals. Discrete time crystals (DTCs) are a novel state of matter
emerging in periodically-driven quantum systems. Typically, they have been
investigated assuming individual control operations with uniform rotation
errors across the entire system. In this work we explore a new paradigm arising
from non-uniform rotation errors, where two dramatically different phases of
matter coexist in well defined regions of space. We consider a quantum spin
network possessing long-range interactions where different driving operations
act on different regions of that network. What results from its inherent
symmetries is a system where one region is a DTC, while the second is
ferromagnetic. We envision our work to open a new avenue of research on
Chimera-like phases of matter where two different phases coexist in space.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:14:55 GMT""}]","2021-04-01"
"2103.00105","Ian Convy","Ian Convy, William Huggins, Haoran Liao, K. Birgitta Whaley","Mutual Information Scaling for Tensor Network Machine Learning","29 pages, 10 figures","Mach. Learn.: Sci. Technol. 3 015017 (2022)","10.1088/2632-2153/ac44a9",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor networks have emerged as promising tools for machine learning,
inspired by their widespread use as variational ansatze in quantum many-body
physics. It is well known that the success of a given tensor network ansatz
depends in part on how well it can reproduce the underlying entanglement
structure of the target state, with different network designs favoring
different scaling patterns. We demonstrate here how a related correlation
analysis can be applied to tensor network machine learning, and explore whether
classical data possess correlation scaling patterns similar to those found in
quantum states which might indicate the best network to use for a given
dataset. We utilize mutual information as measure of correlations in classical
data, and show that it can serve as a lower-bound on the entanglement needed
for a probabilistic tensor network classifier. We then develop a logistic
regression algorithm to estimate the mutual information between bipartitions of
data features, and verify its accuracy on a set of Gaussian distributions
designed to mimic different correlation patterns. Using this algorithm, we
characterize the scaling patterns in the MNIST and Tiny Images datasets, and
find clear evidence of boundary-law scaling in the latter. This
quantum-inspired classical analysis offers insight into the design of tensor
networks which are best suited for specific learning tasks.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:17:51 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 22:24:08 GMT""}]","2022-03-02"
"2103.00106","Lie Qian","Lie Qian","Ordinarity of Local Galois Representation Arising from Dwork Motives",,,,,"math.NT math.AG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove that for suitably chosen Dwork motives, the local
Galois representation arising from middle cohomology of fibers over a point
with $p$-adic valuation $<0$ on the base is regular and ordinary. The result
will be crucial in the forthcoming work Potential Automorphy for $GL_n$. The
proof consists of the construction of a semistable blowup and a use of
Hyodo-Kato's log crystalline cohomology theory.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:20:18 GMT""}]","2021-03-02"
"2103.00107","Tadashi Kozuno","Tadashi Kozuno, Yunhao Tang, Mark Rowland, R\'emi Munos, Steven
  Kapturowski, Will Dabney, Michal Valko, David Abel","Revisiting Peng's Q($\lambda$) for Modern Reinforcement Learning","26 pages, 7 figures, 2 tables",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Off-policy multi-step reinforcement learning algorithms consist of
conservative and non-conservative algorithms: the former actively cut traces,
whereas the latter do not. Recently, Munos et al. (2016) proved the convergence
of conservative algorithms to an optimal Q-function. In contrast,
non-conservative algorithms are thought to be unsafe and have a limited or no
theoretical guarantee. Nonetheless, recent studies have shown that
non-conservative algorithms empirically outperform conservative ones. Motivated
by the empirical results and the lack of theory, we carry out theoretical
analyses of Peng's Q($\lambda$), a representative example of non-conservative
algorithms. We prove that it also converges to an optimal policy provided that
the behavior policy slowly tracks a greedy policy in a way similar to
conservative policy iteration. Such a result has been conjectured to be true
but has not been proven. We also experiment with Peng's Q($\lambda$) in complex
continuous control tasks, confirming that Peng's Q($\lambda$) often outperforms
conservative algorithms despite its simplicity. These results indicate that
Peng's Q($\lambda$), which was thought to be unsafe, is a theoretically-sound
and practically effective algorithm.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:29:01 GMT""}]","2021-03-02"
"2103.00108","Daniela Perez","Daniela P\'erez, Santiago E. Perez Bergliaffa, Gustavo E. Romero","Dynamical black hole in a bouncing universe","13 pages, 19 figures, accepted for publication in Physical Review D",,"10.1103/PhysRevD.103.064019",,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We analyze the causal structure of McVittie spacetime for a classical
bouncing cosmological model. In particular, we compute the trapping horizons of
the metric and integrate the trajectories of radial null geodesics before,
during, and after the bounce takes place. In the contracting phase up to the
occurrence of the bounce, a dynamical black hole is present. When the universe
reaches a certain minimum scale, the trapping horizons disappear and the black
hole ceases to exist. After the bounce, the central weak singularity becomes
naked. In the expanding phase, for large positive values of the cosmic time,
the behaviour of null geodesics indicates that the solution contains a black
hole. These results suggest that neither a contracting nor an expanding
universe can accommodate a black hole at all times.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:36:58 GMT""}]","2021-03-24"
"2103.00109","Ye Zhang","Ye Zhang, Yuan Cao, Mahdis Mahdieh, Jeffrey Zhao, Yonghui Wu","Improving Longer-range Dialogue State Tracking","10 pages",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Dialogue state tracking (DST) is a pivotal component in task-oriented
dialogue systems. While it is relatively easy for a DST model to capture belief
states in short conversations, the task of DST becomes more challenging as the
length of a dialogue increases due to the injection of more distracting
contexts. In this paper, we aim to improve the overall performance of DST with
a special focus on handling longer dialogues. We tackle this problem from three
perspectives: 1) A model designed to enable hierarchical slot status
prediction; 2) Balanced training procedure for generic and task-specific
language understanding; 3) Data perturbation which enhances the model's ability
in handling longer conversations. We conduct experiments on the MultiWOZ
benchmark, and demonstrate the effectiveness of each component via a set of
ablation tests, especially on longer conversations.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:44:28 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 21:19:59 GMT""}]","2021-05-07"
"2103.00110","Yichong Leng","Yichong Leng, Xu Tan, Sheng Zhao, Frank Soong, Xiang-Yang Li, Tao Qin","MBNet: MOS Prediction for Synthesized Speech with Mean-Bias Network","Accepted by ICASSP 2021",,,,"cs.SD eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Mean opinion score (MOS) is a popular subjective metric to assess the quality
of synthesized speech, and usually involves multiple human judges to evaluate
each speech utterance. To reduce the labor cost in MOS test, multiple methods
have been proposed to automatically predict MOS scores. To our knowledge, for a
speech utterance, all previous works only used the average of multiple scores
from different judges as the training target and discarded the score of each
individual judge, which did not well exploit the precious MOS training data. In
this paper, we propose MBNet, a MOS predictor with a mean subnet and a bias
subnet to better utilize every judge score in MOS datasets, where the mean
subnet is used to predict the mean score of each utterance similar to that in
previous works, and the bias subnet to predict the bias score (the difference
between the mean score and each individual judge score) and capture the
personal preference of individual judges. Experiments show that compared with
MOSNet baseline that only leverages mean score for training, MBNet improves the
system-level spearmans rank correlation co-efficient (SRCC) by 2.9% on VCC 2018
dataset and 6.7% on VCC 2016 dataset.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:48:26 GMT""}]","2021-03-02"
"2103.00111","Yixin Liu","Yixin Liu, Ming Jin, Shirui Pan, Chuan Zhou, Yu Zheng, Feng Xia,
  Philip S. Yu","Graph Self-Supervised Learning: A Survey","26 pages, 9 figures, 9 tables","IEEE Transactions on Knowledge and Data Engineering (TKDE), 2022","10.1109/TKDE.2022.3172903",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning on graphs has attracted significant interests recently.
However, most of the works have focused on (semi-) supervised learning,
resulting in shortcomings including heavy label reliance, poor generalization,
and weak robustness. To address these issues, self-supervised learning (SSL),
which extracts informative knowledge through well-designed pretext tasks
without relying on manual labels, has become a promising and trending learning
paradigm for graph data. Different from SSL on other domains like computer
vision and natural language processing, SSL on graphs has an exclusive
background, design ideas, and taxonomies. Under the umbrella of graph
self-supervised learning, we present a timely and comprehensive review of the
existing approaches which employ SSL techniques for graph data. We construct a
unified framework that mathematically formalizes the paradigm of graph SSL.
According to the objectives of pretext tasks, we divide these approaches into
four categories: generation-based, auxiliary property-based, contrast-based,
and hybrid approaches. We further describe the applications of graph SSL across
various research fields and summarize the commonly used datasets, evaluation
benchmark, performance comparison and open-source codes of graph SSL. Finally,
we discuss the remaining challenges and potential future directions in this
research field.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:04:21 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 11:52:26 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 08:46:25 GMT""},{""version"":""v4"",""created"":""Fri, 18 Feb 2022 12:02:52 GMT""},{""version"":""v5"",""created"":""Wed, 4 May 2022 13:18:56 GMT""}]","2022-05-05"
"2103.00112","Kai Han","Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, Yunhe Wang","Transformer in Transformer","Accepted by NeurIPS 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer is a new kind of neural architecture which encodes the input data
as powerful features via the attention mechanism. Basically, the visual
transformers first divide the input images into several local patches and then
calculate both representations and their relationship. Since natural images are
of high complexity with abundant detail and color information, the granularity
of the patch dividing is not fine enough for excavating features of objects in
different scales and locations. In this paper, we point out that the attention
inside these local patches are also essential for building visual transformers
with high performance and we explore a new architecture, namely, Transformer iN
Transformer (TNT). Specifically, we regard the local patches (e.g.,
16$\times$16) as ""visual sentences"" and present to further divide them into
smaller patches (e.g., 4$\times$4) as ""visual words"". The attention of each
word will be calculated with other words in the given visual sentence with
negligible computational costs. Features of both words and sentences will be
aggregated to enhance the representation ability. Experiments on several
benchmarks demonstrate the effectiveness of the proposed TNT architecture,
e.g., we achieve an 81.5% top-1 accuracy on the ImageNet, which is about 1.7%
higher than that of the state-of-the-art visual transformer with similar
computational cost. The PyTorch code is available at
https://github.com/huawei-noah/CV-Backbones, and the MindSpore code is
available at https://gitee.com/mindspore/models/tree/master/research/cv/TNT.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:12:16 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 03:31:05 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 02:24:24 GMT""}]","2021-10-27"
"2103.00113","Yixin Liu","Yixin Liu, Zhao Li, Shirui Pan, Chen Gong, Chuan Zhou, George Karypis","Anomaly Detection on Attributed Networks via Contrastive Self-Supervised
  Learning","15 pages, 5 figures, 6 tables. Published in IEEE Transactions on
  Neural Networks and Learning Systems (TNNLS)","IEEE Transactions on Neural Networks and Learning Systems (TNNLS),
  2021","10.1109/TNNLS.2021.3068344",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Anomaly detection on attributed networks attracts considerable research
interests due to wide applications of attributed networks in modeling a wide
range of complex systems. Recently, the deep learning-based anomaly detection
methods have shown promising results over shallow approaches, especially on
networks with high-dimensional attributes and complex structures. However,
existing approaches, which employ graph autoencoder as their backbone, do not
fully exploit the rich information of the network, resulting in suboptimal
performance. Furthermore, these methods do not directly target anomaly
detection in their learning objective and fail to scale to large networks due
to the full graph training mechanism. To overcome these limitations, in this
paper, we present a novel contrastive self-supervised learning framework for
anomaly detection on attributed networks. Our framework fully exploits the
local information from network data by sampling a novel type of contrastive
instance pair, which can capture the relationship between each node and its
neighboring substructure in an unsupervised way. Meanwhile, a well-designed
graph neural network-based contrastive learning model is proposed to learn
informative embedding from high-dimensional attributes and local structure and
measure the agreement of each instance pairs with its outputted scores. The
multi-round predicted scores by the contrastive learning model are further used
to evaluate the abnormality of each node with statistical estimation. In this
way, the learning model is trained by a specific anomaly detection-aware
target. Furthermore, since the input of the graph neural network module is
batches of instance pairs instead of the full network, our framework can adapt
to large networks flexibly. Experimental results show that our proposed
framework outperforms the state-of-the-art baseline methods on all seven
benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:17:20 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 03:15:36 GMT""}]","2021-05-07"
"2103.00114","L\^e V\v{a}n Th\`anh","Vu Thi Ngoc Anh, Nguyen Thi Thanh Hien, L\^e V\v{a}n Th\`anh, Vo Thi
  Hong Van","The Marcinkiewicz--Zygmund-Type Strong Law of Large Numbers with General
  Normalizing Sequences","Final version in Journal of Theoretical Probability",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  This paper establishes complete convergence for weighted sums and the
Marcinkiewicz--Zygmund-type strong law of large numbers for sequences of
negatively associated and identically distributed random variables
$\{X,X_n,n\ge1\}$ with general normalizing constants under a moment condition
that $ER(X)<\infty$, where $R(\cdot)$ is a regularly varying function. The
result is new even when the random variables are independent and identically
distributed (i.i.d.), and a special case of this result comes close to a
solution to an open question raised by Chen and Sung (Statist Probab Lett
92:45--52, 2014). The proof exploits some properties of slowly varying
functions and the de Bruijin conjugates. A counterpart of the main result
obtained by Martikainen (J Math Sci 75(5):1944-1946, 1995) on the
Marcinkiewicz--Zygmund-type strong law of large numbers for pairwise i.i.d.
random variables is also presented. Two illustrated examples are provided,
including a strong law of large numbers for pairwise negatively dependent
random variables which have the same distribution as the random variable
appearing in the St. Petersburg game.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:41:18 GMT""}]","2021-03-02"
"2103.00115","Bihai Sun","Bihai Sun, Muhammad Shehzad, Daniel Jovic, Christophe Cuvier,
  Christian Willert, Yasar Ostovan, Jean-Marc Foucaut, Callum Atkinson, Julio
  Soria","Distortion correction of two-component - two-dimensional PIV using a
  large imaging sensor with application to measurements of a turbulent boundary
  layer flow at $Re_{\tau} = 2386$",,"Exp Fluids 62, 183 (2021)","10.1007/s00348-021-03273-w",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decade, advances in electronics technology have made larger
imaging sensors available to the experimental fluid mechanics community. These
advancements have enabled the measurement of 2-component 2-dimensional (2C-2D)
velocity fields using particle image velocimetry (PIV) with much higher spatial
resolution than previously possible. However, due to the large size of the
sensor, the lens distortion needs to be taken into account as it will now have
a more significant effect on the measurement quality that must be corrected to
ensure accurate high-fidelity 2C-2D velocity field measurements. In this paper,
two dewarping models, a second-order rational function (R2) and a bicubic
polynomial (P3) are investigated with regards to 2C-2D PIV measurements of a
turbulent boundary layer (TBL) using a large imaging sensor. Two approaches are
considered and compared: (i) dewarping the images prior to the PIV
cross-correlation analysis and (ii) undertaking the PIV cross-correlation
analysis using the original recorded distorted images then followed by using
the mapping functions derived for image dewarping to provide the correct
spatial location of the velocity measurement point. The results demonstrate
that the use of P3 dewarping model to correct lens distortion yields better
results than the R2 dewarping model. Furthermore, both approaches for the P3
dewarping model yield results which are statistically indistinguishable.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:41:21 GMT""}]","2021-08-20"
"2103.00116","Matthias Wuttig","Christoph Persch, Maximilian J. M\""uller, Aakash Yadav, Julian Pries,
  Natalie Honn\'e, Peter Kerres, Shuai Wei, Hajime Tanaka, Paolo Fantini,
  Enrico Varesi, Fabio Pellizzer, Matthias Wuttig","Crystallization and Vitrification Kinetics by Design: The Role of
  Chemical Bonding",,,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Controlling a state of material between its crystalline and glassy phase has
fostered many real-world applications. Nevertheless, design rules for
crystallization and vitrification kinetics still lack predictive power. Here,
we identify stoichiometry trends for these processes in phase change materials,
i.e. along the GeTe-GeSe, GeTe-SnTe, and GeTe-Sb2Te3 pseudo-binary lines
employing a pump-probe laser setup and calorimetry. We discover a clear
stoichiometry dependence of crystallization speed along a line connecting
regions characterized by two fundamental bonding types, metallic and covalent
bonding. Increasing covalency slows down crystallization by six orders of
magnitude and promotes vitrification. The stoichiometry dependence is
correlated with material properties, such as the optical properties of the
crystalline phase and a bond indicator, the number of electrons shared between
adjacent atoms. A quantum-chemical map explains these trends and provides a
blueprint to design crystallization kinetics.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:42:49 GMT""}]","2021-03-02"
"2103.00117","Xiaojun Zheng","Xiaojun Zheng, Simon Mak, Yao Xie","Online High-Dimensional Change-Point Detection using Topological Data
  Analysis",,,,,"stat.ME math.AT stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological Data Analysis (TDA) is a rapidly growing field, which studies
methods for learning underlying topological structures present in complex data
representations. TDA methods have found recent success in extracting useful
geometric structures for a wide range of applications, including protein
classification, neuroscience, and time-series analysis. However, in many such
applications, one is also interested in sequentially detecting changes in this
topological structure. We propose a new method called Persistence Diagram based
Change-Point (PD-CP), which tackles this problem by integrating the widely-used
persistence diagrams in TDA with recent developments in nonparametric
change-point detection. The key novelty in PD-CP is that it leverages the
distribution of points on persistence diagrams for online detection of
topological changes. We demonstrate the effectiveness of PD-CP in an
application to solar flare monitoring.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:43:57 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 22:10:54 GMT""}]","2021-03-09"
"2103.00118","Yang Yan","Yang Yan, Qiuyan Wang","ISHNE: Influence Self-attention for Heterogeneous Network Embedding",,,"10.1587/transinf.2021EDL8093",,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  In recent years, Graph Neural Networks has received enormous attention from
academia for its huge potential of modeling the network traits such as
macrostructure and single node attributes. However, prior mainstream works
mainly focus on homogeneous network and lack the capacity to characterize the
network heterogeneous property. Besides, most previous literature cannot model
the influence under microscope vision, making it infeasible to model the joint
relation between the heterogeneity and mutual interaction within multiple
relation type. In this paper, we propose an Influence Self-attention network to
address the difficulties mentioned above. To model heterogeneity and mutual
interaction, we redesign attention mechanism with influence factor on the
single-type relation level, which learns the importance coefficient from its
adjacent neighbors under the same meta-path based patterns. To incorporate the
heterogeneous meta-path in a unified dimension, we developed a self-attention
based framework for meta-path relation fusion according to the learned
meta-path coefficient. Our experimental results demonstrate that our framework
not only achieve higher results than current state-of-the-art baselines, but
also show promising vision on depicting heterogeneous interactive relations
under complicated network structure.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:45:53 GMT""}]","2022-07-13"
"2103.00119","Ali Pourramezan Fard","Ali Pourramezan Fard, Hojjat Abdollahi, Mohammad Mahoor","ASMNet: a Lightweight Deep Neural Network for Face Alignment and Pose
  Estimation","Accepted at CVPR 2021 Biometrics Workshop, jointly with the Workshop
  on Analysis and Modeling of Faces and Gestures","Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops, 2021, pp. 1521-1530",,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Active Shape Model (ASM) is a statistical model of object shapes that
represents a target structure. ASM can guide machine learning algorithms to fit
a set of points representing an object (e.g., face) onto an image. This paper
presents a lightweight Convolutional Neural Network (CNN) architecture with a
loss function being assisted by ASM for face alignment and estimating head pose
in the wild. We use ASM to first guide the network towards learning a smoother
distribution of the facial landmark points. Inspired by transfer learning,
during the training process, we gradually harden the regression problem and
guide the network towards learning the original landmark points distribution.
We define multi-tasks in our loss function that are responsible for detecting
facial landmark points as well as estimating the face pose. Learning multiple
correlated tasks simultaneously builds synergy and improves the performance of
individual tasks. We compare the performance of our proposed model called
ASMNet with MobileNetV2 (which is about 2 times bigger than ASMNet) in both the
face alignment and pose estimation tasks. Experimental results on challenging
datasets show that by using the proposed ASM assisted loss function, the ASMNet
performance is comparable with MobileNetV2 in the face alignment task. In
addition, for face pose estimation, ASMNet performs much better than
MobileNetV2. ASMNet achieves an acceptable performance for facial landmark
points detection and pose estimation while having a significantly smaller
number of parameters and floating-point operations compared to many CNN-based
models.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:46:54 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 18:40:12 GMT""},{""version"":""v3"",""created"":""Fri, 7 May 2021 17:44:58 GMT""}]","2021-06-17"
"2103.00120","Takahiro Mizusaki","Takahiro Mizusaki and Peter Schuck","Symmetry projection to coupled-cluster singles and doubles wave function
  through the Monte Carlo method","6 pages, 4 figures, submitted to PRC","Phys. Rev. C 104, 031305 (2021)","10.1103/PhysRevC.104.L031305",,"nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A new method for calculating the symmetry-projected energy of coupled-cluster
singles and doubles (CCSD) wave function through the Monte Carlo method is
proposed. We present benchmark calculations in considering the three-level
Lipkin model which is a simple and minimal model with two phases: spherical and
deformed ones. It is demonstrated that this new method gives good ground state
energy and low-lying spectra.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 03:51:54 GMT""}]","2021-09-29"
"2103.00121","Mozhdeh Rouhsedaghat","Mozhdeh Rouhsedaghat, Masoud Monajatipoor, Zohreh Azizi, C.-C. Jay Kuo","Successive Subspace Learning: An Overview","4 pages, 1 figure",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Successive Subspace Learning (SSL) offers a light-weight unsupervised feature
learning method based on inherent statistical properties of data units (e.g.
image pixels and points in point cloud sets). It has shown promising results,
especially on small datasets. In this paper, we intuitively explain this
method, provide an overview of its development, and point out some open
questions and challenges for future research.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:03:45 GMT""}]","2021-03-02"
"2103.00122","Debayan Chakraborty","Debayan Chakraborty and Mauro Lorenzo Mugnai and D. Thirumalai","On the emergence of orientational order in folded proteins with
  implications for allostery",,,,,"cond-mat.soft q-bio.BM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The beautiful structures of single and multi-domain proteins are clearly
ordered in some fashion but cannot be readily classified using group theory
methods that are successfully used to describe periodic crystals. For this
reason, protein structures are considered to be aperiodic, and may have evolved
this way for functional purposes, especially in instances that require a
combination of softness and rigidity within the same molecule. By analyzing the
solved protein structures, we show that orientational symmetry is broken in the
aperiodic arrangement of the secondary structural elements (SSEs), which we
deduce by calculating the nematic order parameter, $P_{2}$. We find that the
folded structures are nematic droplets with a broad distribution of $P_{2}$. We
argue that non-zero values of $P_{2}$, leads to an arrangement of the SSEs that
can resist mechanical forces, which is a requirement for allosteric proteins.
Such proteins, which resist mechanical forces in some regions while being
flexible in others, transmit signals from one region of the protein to another
(action at a distance) in response to binding of ligands (oxygen, ATP or other
small molecules).
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:08:44 GMT""}]","2021-03-02"
"2103.00123","Krishnateja Killamsetty","Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan,
  Abir De, Rishabh Iyer","GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient
  Deep Model Training","To appear in Proceedings of the 38 th International Conference on
  Machine Learning, PMLR 139, 2021",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The great success of modern machine learning models on large datasets is
contingent on extensive computational resources with high financial and
environmental costs. One way to address this is by extracting subsets that
generalize on par with the full data. In this work, we propose a general
framework, GRAD-MATCH, which finds subsets that closely match the gradient of
the training or validation set. We find such subsets effectively using an
orthogonal matching pursuit algorithm. We show rigorous theoretical and
convergence guarantees of the proposed algorithm and, through our extensive
experiments on real-world datasets, show the effectiveness of our proposed
framework. We show that GRAD-MATCH significantly and consistently outperforms
several recent data-selection algorithms and achieves the best
accuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS
toolkit: \url{https://github.com/decile-team/cords}.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:09:32 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 22:08:29 GMT""}]","2021-06-15"
"2103.00124","Muhammad Usman","Muhammad Usman, Yannic Noller, Corina Pasareanu, Youcheng Sun, Divya
  Gopinath","NEUROSPF: A tool for the Symbolic Analysis of Neural Networks",,,,,"cs.LG cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents NEUROSPF, a tool for the symbolic analysis of neural
networks. Given a trained neural network model, the tool extracts the
architecture and model parameters and translates them into a Java
representation that is amenable for analysis using the Symbolic PathFinder
symbolic execution tool. Notably, NEUROSPF encodes specialized peer classes for
parsing the model's parameters, thereby enabling efficient analysis. With
NEUROSPF the user has the flexibility to specify either the inputs or the
network internal parameters as symbolic, promoting the application of program
analysis and testing approaches from software engineering to the field of
machine learning. For instance, NEUROSPF can be used for coverage-based testing
and test generation, finding adversarial examples and also constraint-based
repair of neural networks, thus improving the reliability of neural networks
and of the applications that use them. Video URL: https://youtu.be/seal8fG78LI
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:28:11 GMT""}]","2021-03-02"
"2103.00125","Nitin Jonathan Myers","Yuyang Wang, Nitin Jonathan Myers, Nuria Gonz\'alez-Prelcic, Robert W.
  Heath Jr","Deep Learning-based Compressive Beam Alignment in mmWave Vehicular
  Systems","Submitted to the IEEE Transactions on Wireless Communications.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"eess.SP cs.AI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter wave vehicular channels exhibit structure that can be exploited
for beam alignment with fewer channel measurements compared to exhaustive beam
search. With fixed layouts of roadside buildings and regular vehicular moving
trajectory, the dominant path directions of channels will likely be among a
subset of beam directions instead of distributing randomly over the whole
beamspace. In this paper, we propose a deep learning-based technique to design
a structured compressed sensing (CS) matrix that is well suited to the
underlying channel distribution for mmWave vehicular beam alignment. The
proposed approach leverages both sparsity and the particular spatial structure
that appears in vehicular channels. We model the compressive channel
acquisition by a two-dimensional (2D) convolutional layer followed by dropout.
We design fully-connected layers to optimize channel acquisition and beam
alignment. We incorporate the low-resolution phase shifter constraint during
neural network training by using projected gradient descent for weight updates.
Furthermore, we exploit channel spectral structure to optimize the power
allocated for different subcarriers. Simulations indicate that our deep
learning-based approach achieves better beam alignment than standard CS
techniques which use random phase shift-based design. Numerical experiments
also show that one single subcarrier is sufficient to provide necessary
information for beam alignment.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:38:12 GMT""}]","2021-03-02"
"2103.00126","Di Zhang Dr.","Xuewan Zhang, Dalong Zhang, Liuqing Yang, Gangtao Han, Hsiao-Hwa Chen,
  Di Zhang","SCMA Codebook Design Based on Uniquely Decomposable Constellation Groups",,,"10.1109/TWC.2021.3062613",,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Sparse code multiple access (SCMA), which helps improve spectrum efficiency
(SE) and enhance connectivity, has been proposed as a non-orthogonal multiple
access (NOMA) scheme for 5G systems. In SCMA, codebook design determines system
overload ratio and detection performance at a receiver. In this paper, an SCMA
codebook design approach is proposed based on uniquely decomposable
constellation group (UDCG). We show that there are $N+1 (N \geq 1)$
constellations in the proposed UDCG, each of which has $M (M \geq 2)$
constellation points. These constellations are allocated to users sharing the
same resource. Combining the constellations allocated on multiple resources of
each user, we can obtain UDCG-based codebook sets. Bit error ratio (BER)
performance will be discussed in terms of coding gain maximization with
superimposed constellations and UDCG-based codebooks. Simulation results
demonstrate that the superimposed constellation of each resource has large
minimum Euclidean distance (MED) and meets uniquely decodable constraint. Thus,
BER performance of the proposed codebook design approach outperforms that of
the existing codebook design schemes in both uncoded and coded SCMA systems,
especially for large-size codebooks.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:45:14 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 07:39:36 GMT""}]","2021-03-09"
"2103.00127","Swaroop Panda","Swaroop Panda, V. Namboodiri, S.T. Roy","Visualizing Music Genres using a Topic Model","A version of this paper was published at the Sound and Music
  Computing Conference 2019, Malaga",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Music Genres serve as an important meta-data in the field of music
information retrieval and have been widely used for music classification and
analysis tasks. Visualizing these music genres can thus be helpful for music
exploration, archival and recommendation. Probabilistic topic models have been
very successful in modelling text documents. In this work, we visualize music
genres using a probabilistic topic model. Unlike text documents, audio is
continuous and needs to be sliced into smaller segments. We use simple MFCC
features of these segments as musical words. We apply the topic model on the
corpus and subsequently use the genre annotations of the data to interpret and
visualize the latent space.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:46:36 GMT""}]","2021-03-02"
"2103.00128","Suraj Kothawade","Suraj Kothawade, Vishal Kaushal, Ganesh Ramakrishnan, Jeff Bilmes,
  Rishabh Iyer","PRISM: A Rich Class of Parameterized Submodular Information Measures for
  Guided Subset Selection","To Appear In 36th AAAI Conference on Artificial Intelligence, AAAI
  2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With ever-increasing dataset sizes, subset selection techniques are becoming
increasingly important for a plethora of tasks. It is often necessary to guide
the subset selection to achieve certain desiderata, which includes focusing or
targeting certain data points, while avoiding others. Examples of such problems
include: i)targeted learning, where the goal is to find subsets with rare
classes or rare attributes on which the model is underperforming, and ii)guided
summarization, where data (e.g., image collection, text, document or video) is
summarized for quicker human consumption with specific additional user intent.
Motivated by such applications, we present PRISM, a rich class of PaRameterIzed
Submodular information Measures. Through novel functions and their
parameterizations, PRISM offers a variety of modeling capabilities that enable
a trade-off between desired qualities of a subset like diversity or
representation and similarity/dissimilarity with a set of data points. We
demonstrate how PRISM can be applied to the two real-world problems mentioned
above, which require guided subset selection. In doing so, we show that PRISM
interestingly generalizes some past work, therein reinforcing its broad
utility. Through extensive experiments on diverse datasets, we demonstrate the
superiority of PRISM over the state-of-the-art in targeted learning and in
guided image-collection summarization
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:53:47 GMT""},{""version"":""v2"",""created"":""Fri, 3 Dec 2021 00:12:58 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 21:58:24 GMT""}]","2022-03-10"
"2103.00129","Swaroop Panda","Swaroop Panda, S.T.Roy","Music Genre Bars","A version of this paper was presented at IEEE VIS 2020","IEEE VIS 2020 posters",,,"cs.HC cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Music Genres, as a popular meta-data of music, are very useful to organize,
explore or search music datasets. Soft music genres are weighted multiple-genre
annotations to songs. In this initial work, we propose horizontally stacked bar
charts to represent a music dataset annotated by these soft music genres. For
this purpose, we take an example of a toy dataset consisting of songs labelled
with help of three music genres; Blues, Jazz and Country. We demonstrate how
such a stacked bar chart can be used as a slider for user-input in an
interface. We implement this by embedding this genre bar in a streaming
application prototype and show its utility in choosing playlists. We finally
conclude by proposing further work and future explorations on our proposed
preliminary research.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:05:12 GMT""}]","2021-04-13"
"2103.00130","Sihuan Li","Sihuan Li, Jianyu Huang, Ping Tak Peter Tang, Daya Khudia, Jongsoo
  Park, Harish Dattatraya Dixit, Zizhong Chen","Efficient Soft-Error Detection for Low-precision Deep Learning
  Recommendation Models",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Soft error, namely silent corruption of signal or datum in a computer system,
cannot be caverlierly ignored as compute and communication density grow
exponentially. Soft error detection has been studied in the context of
enterprise computing, high-performance computing and more recently in
convolutional neural networks related to autonomous driving. Deep learning
recommendation systems (DLRMs) have by now become ubiquitous and serve billions
of users per day. Nevertheless, DLRM-specific soft error detection methods are
hitherto missing. To fill the gap, this paper presents the first set of
soft-error detection methods for low-precision quantized-arithmetic operators
in DLRM including general matrix multiplication (GEMM) and EmbeddingBag. A
practical method must detect error and do so with low overhead lest reduced
inference speed degrades user experience. Exploiting the characteristics of
both quantized arithmetic and the operators, we achieved more than 95%
detection accuracy for GEMM with an overhead below 20%. For EmbeddingBag, we
achieved 99% effectiveness in significant-bit-flips detection with less than
10% of false positives, while keeping overhead below 26%.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:07:20 GMT""}]","2021-03-02"
"2103.00131","Isayiyas Nigatu Tiba","Isayiyas Nigatu Tiba, Quan Zhang, Jing Jiang and Yongchao Wang","A Low-Complexity ADMM-based Massive MIMO Detectors via Deep Neural
  Networks",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  An alternate direction method of multipliers (ADMM)-based detectors can
achieve good performance in both small and large-scale multiple-input
multiple-output (MIMO) systems. However, due to the difficulty of choosing the
optimal penalty parameters, their performance is limited. This paper presents a
deep neural network (DNN)-based massive MIMO detection method which can
overcome the above limitation. It exploits the unfolding technique and learns
to estimate the penalty parameters. Additionally, a computationally cheaper
detector is also proposed. The proposed methods can handle the higher-order
modulation signals. Numerical results are presented to demonstrate the
performances of the proposed methods compared with the existing works.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:29:37 GMT""}]","2021-03-02"
"2103.00132","Zafer Dursunkaya","Osman Akdag and Yigit Akkus and Barbaros Cetin and Zafer Dursunkaya","Interplay of transport mechanisms during the evaporation of a pinned
  sessile water droplet",,"Phys. Rev. Fluids 6, 073605 (2021)","10.1103/PhysRevFluids.6.073605",,"physics.flu-dyn physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Droplet evaporation has been intensively investigated in past decades owing
to its emerging applications in diverse fields of science and technology. Yet
the role transport mechanisms has been the subject of a heated debate,
especially the presence of Marangoni flow in water droplets. This work aims to
draw a clear picture of the switching transport mechanisms inside a drying
pinned sessile water droplet in both the presence and absence of
thermocapillarity by developing a comprehensive model that accounts for all
pertinent physics in both phases as well as interfacial phenomena at the
interface. The model reveals a hitherto unexplored mixed radial and buoyant
flow by shedding light on the transition from buoyancy induced Rayleigh flow to
the radial flow causing coffee ring effect. Predictions of the model
excellently match previous experimental results across varying substrate
temperatures only in the absence of Marangoni flow. When thermocapillarity is
accounted for, strong surface flows shape the liquid velocity field during most
of the droplet lifetime and the model starts to overestimate evaporation rates
with increasing substrate temperature.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:30:52 GMT""}]","2021-08-04"
"2103.00133","Yang Li","Lei Wang, Pengcheng Xu, Zhaoyang Qu, Xiaoyong Bo, Yunchang Dong,
  Zhenming Zhang, Yang Li","Coordinated Cyber-Attack Detection Model of Cyber-Physical Power System
  Based on the Operating State Data Link","Accepted by Frontiers in Energy Research","Frontiers in Energy Research 9 (2021) 666130","10.3389/fenrg.2021.666130",,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Existing coordinated cyber-attack detection methods have low detection
accuracy and efficiency and poor generalization ability due to difficulties
dealing with unbalanced attack data samples, high data dimensionality, and
noisy data sets. This paper proposes a model for cyber and physical data fusion
using a data link for detecting attacks on a Cyber-Physical Power System
(CPPS). Two-step principal component analysis (PCA) is used for classifying the
system's operating status. An adaptive synthetic sampling algorithm is used to
reduce the imbalance in the categories' samples. The loss function is improved
according to the feature intensity difference of the attack event, and an
integrated classifier is established using a classification algorithm based on
the cost-sensitive gradient boosting decision tree (CS-GBDT). The simulation
results show that the proposed method provides higher accuracy, recall, and
F-Score than comparable algorithms.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:36:21 GMT""}]","2021-08-03"
"2103.00134","Erfan Nozari","Erfan Nozari, Robert Planas, Jorge Cortes","Structural Characterization of Oscillations in Brain Networks with Rate
  Dynamics",,,,,"eess.SY cs.SY math.DS q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among the versatile forms of dynamical patterns of activity exhibited by the
brain, oscillations are one of the most salient and extensively studied, yet
are still far from being well understood. In this paper, we provide various
structural characterizations of the existence of oscillatory behavior in neural
networks using a classical neural mass model of mesoscale brain activity called
linear-threshold dynamics. Exploiting the switched-affine nature of this
dynamics, we obtain various necessary and/or sufficient conditions on the
network structure and its external input for the existence of oscillations in
(i) two-dimensional excitatory-inhibitory networks (E-I pairs), (ii) networks
with one inhibitory but arbitrary number of excitatory nodes, (iii) purely
inhibitory networks with an arbitrary number of nodes, and (iv) networks of E-I
pairs. Throughout our treatment, and given the arbitrary dimensionality of the
considered dynamics, we rely on the lack of stable equilibria as a system-based
proxy for the existence of oscillations, and provide extensive numerical
results to support its tight relationship with the more standard, signal-based
definition of oscillations in computational neuroscience.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 05:43:36 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 00:34:00 GMT""}]","2021-08-12"
"2103.00135","Fengqiu Wang","Anran Wang, Yuhan Wang, Jianfei Li, Ning Xu, Songlin Li, Xinran Wang,
  Yi Shi, and Fengqiu Wang","Controlling relaxation dynamics of excitonic states in monolayer
  transition metal dichalcogenides WS2 through interface engineering","12 pages",,"10.1063/5.0043758",,"cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Transition metal dichalcogenides (TMDs) are known to support complex
excitonic states. Revealing the differences in relaxation dynamics among
different excitonic species and elucidating the transition dynamics between
them may provide important guidelines for designing TMD-based excitonic
devices. Combining photoluminescence (PL) and reflectance contrast measurements
with ultrafast pump-probe spectroscopy under cryogenic temperatures, we herein
study the relaxation dynamics of neutral and charged excitons in a
back-gate-controlled monolayer device. Pump-probe results reveal quite
different relaxation dynamics of excitonic states under different interfacial
conditions: while neutral excitons experience much longer lifetime than trions
in monolayer WS2, the opposite is true in the WS2/h-BN heterostructure. It is
found that the insertion of h-BN layer between the TMD monolayer and the
substrate has a great influence on the lifetimes of different excitonic states.
The h-BN flakes can not only screen the effects of impurities and defects at
the interface, but also help establish a non-radiative transition from neutral
excitons to trions to be the dominant relaxation pathway, under cryogenic
temperature. Our findings highlight the important role interface may play in
governing the transient properties of carriers in 2D semiconductors, and may
also have implications for designing light-emitting and photo-detecting devices
based on TMDs.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:01:14 GMT""}]","2021-04-07"
"2103.00136","Takeshi Teshima","Takeshi Teshima and Masashi Sugiyama","Incorporating Causal Graphical Prior Knowledge into Predictive Modeling
  via Simple Data Augmentation","29 pages, 5 figures, 2 tables. Camera-ready version of the paper
  accepted at the Thirty-seventh Conference on Uncertainty in Artificial
  Intelligence (UAI 2021)",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Causal graphs (CGs) are compact representations of the knowledge of the data
generating processes behind the data distributions. When a CG is available,
e.g., from the domain knowledge, we can infer the conditional independence (CI)
relations that should hold in the data distribution. However, it is not
straightforward how to incorporate this knowledge into predictive modeling. In
this work, we propose a model-agnostic data augmentation method that allows us
to exploit the prior knowledge of the CI encoded in a CG for supervised machine
learning. We theoretically justify the proposed method by providing an excess
risk bound indicating that the proposed method suppresses overfitting by
reducing the apparent complexity of the predictor hypothesis class. Using
real-world data with CGs provided by domain experts, we experimentally show
that the proposed method is effective in improving the prediction accuracy,
especially in the small-data regime.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:13:59 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 07:41:36 GMT""}]","2021-08-18"
"2103.00137","Debmalya Mandal","Debmalya Mandal, Sourav Medya, Brian Uzzi, and Charu Aggarwal","Meta-Learning with Graph Neural Networks: Methods and Applications",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Graph Neural Networks (GNNs), a generalization of deep neural networks on
graph data have been widely used in various domains, ranging from drug
discovery to recommender systems. However, GNNs on such applications are
limited when there are few available samples. Meta-learning has been an
important framework to address the lack of samples in machine learning, and in
recent years, researchers have started to apply meta-learning to GNNs. In this
work, we provide a comprehensive survey of different meta-learning approaches
involving GNNs on various graph problems showing the power of using these two
approaches together. We categorize the literature based on proposed
architectures, shared representations, and applications. Finally, we discuss
several exciting future research directions and open problems.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:19:11 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 08:11:44 GMT""},{""version"":""v3"",""created"":""Sat, 6 Nov 2021 12:46:00 GMT""}]","2021-11-09"
"2103.00138","Yu-Yang Songsheng","Yu-Yang Songsheng, Yan-Rong Li, Pu Du and Jian-Min Wang","Geometric Distances of Quasars Measured by Spectroastrometry and
  Reverberation Mapping:Monte Carlo Simulations","20 pages, 13 figures, accepted by ApJS",,"10.3847/1538-4365/abe539",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Recently, GRAVITY onboard the Very Large Telescope Interferometer (VLTI)
first spatially resolved the structure of the quasar 3C 273 with an
unprecedented resolution of $\sim 10\mu$as. A new method of measuring parallax
distances has been successfully applied to the quasar through joint analysis of
spectroastrometry (SA) and reverberation mapping (RM) observation of its broad
line region (BLR). The uncertainty of this SA and RM (SARM) measurement is
about $16\%$ from real data, showing its great potential as a powerful tool for
precision cosmology. In this paper, we carry out detailed analyses of mock data
to study impacts of data qualities of SA observations on distance measurements
and establish a quantitative relationship between statistical uncertainties of
distances and relative errors of differential phases. We employ a circular disk
model of BLR for the SARM analysis. We show that SARM analyses of observations
generally generate reliable quasar distances, even for relatively poor SA
measurements with error bars of $40\%$ at peaks of phases. Inclinations and
opening angles of BLRs are the major parameters governing distance
uncertainties. It is found that BLRs with inclinations $\gtrsim 10^{\circ}$ and
opening angles $\lesssim 40^{\circ}$ are the most reliable regimes from SARM
analysis for distance measurements. Through analysis of a mock sample of AGNs
generated by quasar luminosity functions, we find that if the GRAVITY/GRAVITY+
can achieve a phase error of $0.1^{\circ}$ per baseline for targets with
magnitudes $K \lesssim 11.5$, the SARM campaign can constrain $H_0$ to an
uncertainty of $2\%$ by observing $60$ targets.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:23:24 GMT""}]","2021-04-21"
"2103.00139","Pooyan Jamshidi","Mohammad Ali Javidian, Om Pandey, Pooyan Jamshidi","Scalable Causal Domain Adaptation",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most critical problems in transfer learning is the task of domain
adaptation, where the goal is to apply an algorithm trained in one or more
source domains to a different (but related) target domain. This paper deals
with domain adaptation in the presence of covariate shift while invariances
exist across domains. One of the main limitations of existing causal inference
methods for solving this problem is scalability. To overcome this difficulty,
we propose SCTL, an algorithm that avoids an exhaustive search and identifies
invariant causal features across source and target domains based on Markov
blanket discovery. SCTL does not require having prior knowledge of the causal
structure, the type of interventions, or the intervention targets. There is an
intrinsic locality associated with SCTL that makes it practically scalable and
robust because local causal discovery increases the power of computational
independence tests and makes the task of domain adaptation computationally
tractable. We show the scalability and robustness of SCTL for domain adaptation
using synthetic and real data sets in low-dimensional and high-dimensional
settings.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:25:06 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 20:34:33 GMT""},{""version"":""v3"",""created"":""Tue, 7 Dec 2021 17:17:14 GMT""}]","2021-12-08"
"2103.00140","Fei Li","Fei Li, Xiangxu Li, Jun Luo, Shiwei Fan and Hongbo Zhang","Open-set Intersection Intention Prediction for Autonomous Driving","Accepted by ICRA, 2021",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intention prediction is a crucial task for Autonomous Driving (AD). Due to
the variety of size and layout of intersections, it is challenging to predict
intention of human driver at different intersections, especially unseen and
irregular intersections. In this paper, we formulate the prediction of
intention at intersections as an open-set prediction problem that requires
context specific matching of the target vehicle state and the diverse
intersection configurations that are in principle unbounded. We capture
map-centric features that correspond to intersection structures under a
spatial-temporal graph representation, and use two MAAMs (mutually auxiliary
attention module) that cover respectively lane-level and exitlevel intentions
to predict a target that best matches intersection elements in map-centric
feature space. Under our model, attention scores estimate the probability
distribution of the openset intentions that are contextually defined by the
structure of the current intersection. The proposed model is trained and
evaluated on simulated dataset. Furthermore, the model, trained on simulated
dataset and without any fine tuning, is directly validated on in-house
real-world dataset collected at 98 realworld intersections and exhibits
satisfactory performance,demonstrating the practical viability of our approach.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:38:26 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 01:42:48 GMT""}]","2021-03-10"
"2103.00141","Yuanrui Fan","Yuanrui Fan, Xin Xia, David Lo, Ahmed E. Hassan, Yuan Wang, Shanping
  Li","A Differential Testing Approach for Evaluating Abstract Syntax Tree
  Mapping Algorithms",,"International Conference on Software Engineering 2021",,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Abstract syntax tree (AST) mapping algorithms are widely used to analyze
changes in source code. Despite the foundational role of AST mapping
algorithms, little effort has been made to evaluate the accuracy of AST mapping
algorithms, i.e., the extent to which an algorihtm captures the evolution of
code. We observe that a program element often has only one best-mapped program
element. Based on this observation, we propose a hierarchical approach to
automatically compare the similarity of mapped statements and tokens by
different algorithms. By performing the comparison, we determine if each of the
compared algorithms generates inaccurate mappings for a statement or its
tokens. We invite 12 external experts to determine if three commonly used AST
mapping algorithms generate accurate mappings for a statement and its tokens
for 200 statements. Based on the experts' feedback,we observe that our approach
achieves a precision of 0.98--1.00 and a recall of 0.65--0.75. Furthermore, we
conduct a large-scale study with a dataset of ten Java projects, containing a
total of 263,165 file revisions. Our approach determines that GumTree, MTDiff
and IJM generate inaccurate mappings for 20%--29%, 25%--36% and 21%--30% of the
file revisions, respectively. Our experimental results show that state-of-art
AST mapping agorithms still need improvements.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:49:52 GMT""}]","2021-03-02"
"2103.00142","Tristan Aumentado-Armstrong","Tristan Aumentado-Armstrong, Stavros Tsogkas, Sven Dickinson, and
  Allan Jepson","Disentangling Geometric Deformation Spaces in Generative Latent Shape
  Models","Accepted to IJCV",,"10.1007/s11263-023-01750-9",,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A complete representation of 3D objects requires characterizing the space of
deformations in an interpretable manner, from articulations of a single
instance to changes in shape across categories. In this work, we improve on a
prior generative model of geometric disentanglement for 3D shapes, wherein the
space of object geometry is factorized into rigid orientation, non-rigid pose,
and intrinsic shape. The resulting model can be trained from raw 3D shapes,
without correspondences, labels, or even rigid alignment, using a combination
of classical spectral geometry and probabilistic disentanglement of a
structured latent representation space. Our improvements include more
sophisticated handling of rotational invariance and the use of a diffeomorphic
flow network to bridge latent and spectral space. The geometric structuring of
the latent space imparts an interpretable characterization of the deformation
space of an object. Furthermore, it enables tasks like pose transfer and
pose-aware retrieval without requiring supervision. We evaluate our model on
its generative modelling, representation learning, and disentanglement
performance, showing improved rotation invariance and intrinsic-extrinsic
factorization quality over the prior model.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:54:31 GMT""},{""version"":""v2"",""created"":""Sun, 19 Mar 2023 00:56:51 GMT""}]","2023-03-21"
"2103.00143","Mikhail Fedorov V.","M.V. Fedorov, S.S. Mernova, K.V. Sliporod","SPDC: once again on the parameters of transverse entanglement outside
  the near zone",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As known, the degree of entanglement of biphoton states with respect to the
transverse components of photon wave vectors (momenta) or coordinates can be
characterized either by the parameter K associated with the Schmidt
decompositions, or by the parameter R, defined as the ratio of the widths of
the unconditional and conditional single-particle distributions of biphoton
states. As entanglement is a fundamental characteristics of a state, it must be
independent of a choice of its different representations, i.e. its entanglement
parameters must be identical in the coordinate and momentum representations.
Likewise, entanglement itself and its characterization parameters must remain
constant along the photon propagation length. It's known, however, that only
the parameter K obeys these requirements, whereas the parameter R in the
coordinate representation deviates from K beyond the near zone and, thus,
becomes inapplicable as a measure of the degree of entablement. But, as shown
below, there is a way of saving the parameter R by means of modifying its
definition in such a way that the modified parameter R turns out to be as good
as the parameter K both in the momentum and coordinate representations, as well
as in the near and far zones and everywhere between them. We will discuss also
possible ways of measuring this newly defined parameter R experimentally.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:55:45 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 19:34:49 GMT""}]","2022-02-03"
"2103.00144","Ralf-Dieter Scholz","Ralf-Dieter Scholz","\textit{Gaia} EDR3 confirms a red dwarf companion of the nearby F1 star
  HD 105452 and reveals a new brown dwarf companion of the M4.5 dwarf SCR
  J1214-2345","3 pages, 1 figure, accepted by RNAAS",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are 88 stars which lack colours, but have measured parallaxes in
\textit{Gaia} EDR3 that place them within 20\,pc from the sun. Among them we
found two new common parallax and proper motion (CPPM) companions separated
from their primaries by about 3\,arcsec. The CPPM companion of a nearby
($d=14.98$\,pc) F1 star, \object{HD 105452 B}, was already imaged with the
\textit{Hubble Space Telescope} and is now confirmed with \textit{Gaia} data
and photometrically classified by us as M4 dwarf. The other CPPM companion,
\object{SCR J1214-2345 B} orbiting an M4.5 dwarf at $d=10.77$\,pc, represents
the faintest brown dwarf discovery made by \textit{Gaia} so far. It was also
imaged by the VISTA Hemisphere Survey and partly detected in the near-infrared.
Our photometric classification led to an uncertain spectal type of T1$\pm$3 and
needs to be confirmed by spectroscopic follow-up.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:58:18 GMT""}]","2021-03-02"
"2103.00145","Fei Li","Fei Li, Shiwei Fan, Pengzhen Chen, and Xiangxu Li","Pedestrian Motion State Estimation From 2D Pose",,"2020 IEEE Intelligent Vehicles Symposium (IV). IEEE, 1682-1687","10.1109/IV47402.2020.9304784",,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic violation and the flexible and changeable nature of pedestrians make
it more difficult to predict pedestrian behavior or intention, which might be a
potential safety hazard on the road. Pedestrian motion state (such as walking
and standing) directly affects or reflects its intention. In combination with
pedestrian motion state and other influencing factors, pedestrian intention can
be predicted to avoid unnecessary accidents. In this paper, pedestrian is
treated as non-rigid object, which can be represented by a set of
two-dimensional key points, and the movement of key point relative to the torso
is introduced as micro motion. Static and dynamic micro motion features, such
as position, angle and distance, and their differential calculations in time
domain, are used to describe its motion pattern. Gated recurrent neural network
based seq2seq model is used to learn the dependence of motion state transition
on previous information, finally the pedestrian motion state is estimated via a
softmax classifier. The proposed method only needs the previous hidden state of
GRU and current feature to evaluate the probability of current motion state,
and it is computation efficient to deploy on vehicles. This paper verifies the
proposed algorithm on the JAAD public dataset, and the accuracy is improved by
11.6% compared with the existing method.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:00:06 GMT""}]","2021-03-04"
"2103.00146","George Metcalfe","Almudena Colacito, Nikolaos Galatos, George Metcalfe, Simon Santschi","From distributive l-monoids to l-groups, and back again",,,,,"math.GR math.LO","http://creativecommons.org/licenses/by/4.0/","  We prove that an inverse-free equation is valid in the variety LG of
lattice-ordered groups (l-groups) if and only if it is valid in the variety DLM
of distributive lattice-ordered monoids (distributive l-monoids). This
contrasts with the fact that, as proved by Repnitskii, there exist inverse-free
equations that are valid in all Abelian l-groups but not in all commutative
distributive l-monoids, and, as we prove here, there exist inverse-free
equations that hold in all totally ordered groups but not in all totally
ordered monoids. We also prove that DLM has the finite model property and a
decidable equational theory, establish a correspondence between the validity of
equations in DLM and the existence of certain right orders on free monoids, and
provide an effective method for reducing the validity of equations in LG to the
validity of equations in DLM.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:20:19 GMT""},{""version"":""v2"",""created"":""Sun, 6 Mar 2022 14:57:39 GMT""}]","2022-03-08"
"2103.00147","Vinu Sankar Sadasivan","Vinu Sankar Sadasivan, Anirban Dasgupta","Statistical Measures For Defining Curriculum Scoring Function","Revision 1: Corrected minor typos, added link to open-sourced codes,
  fixed Figures 7 as per reviews",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Curriculum learning is a training strategy that sorts the training examples
by some measure of their difficulty and gradually exposes them to the learner
to improve the network performance. Motivated by our insights from implicit
curriculum ordering, we first introduce a simple curriculum learning strategy
that uses statistical measures such as standard deviation and entropy values to
score the difficulty of data points for real image classification tasks. We
empirically show its improvements in performance with convolutional and
fully-connected neural networks on multiple real image datasets. We also
propose and study the performance of a dynamic curriculum learning algorithm.
Our dynamic curriculum algorithm tries to reduce the distance between the
network weight and an optimal weight at any training step by greedily sampling
examples with gradients that are directed towards the optimal weight. Further,
we use our algorithms to discuss why curriculum learning is helpful.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:25:49 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 09:24:54 GMT""}]","2021-07-28"
"2103.00148","Andreas Hellander","Morgan Ekmefjord, Addi Ait-Mlouk, Sadi Alawadi, Mattias {\AA}kesson,
  Prashant Singh, Ola Spjuth, Salman Toor, Andreas Hellander","Scalable federated machine learning with FEDn",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  Federated machine learning has great promise to overcome the input privacy
challenge in machine learning. The appearance of several projects capable of
simulating federated learning has led to a corresponding rapid progress on
algorithmic aspects of the problem. However, there is still a lack of federated
machine learning frameworks that focus on fundamental aspects such as
scalability, robustness, security, and performance in a geographically
distributed setting. To bridge this gap we have designed and developed the FEDn
framework. A main feature of FEDn is to support both cross-device and
cross-silo training settings. This makes FEDn a powerful tool for researching a
wide range of machine learning applications in a realistic setting.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:30:31 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 12:14:11 GMT""}]","2022-04-05"
"2103.00149","Peng Gao","Peng Gao","Bounds for moments of Dirichlet $L$-functions to a fixed modulus","12 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We study the $2k$-th moment of central values of the family of Dirichlet
$L$-functions to a fixed prime modulus. We establish sharp lower bounds for all
real $k \geq 0$ and sharp upper bounds for $k$ in the range $0 \leq k \leq 1$.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:31:07 GMT""}]","2021-03-02"
"2103.00150","Dayasindhu Dey","Sambunath Das, Dayasindhu Dey, S. Ramasesha and Manoranjan Kumar","Quantum phases of spin-1 system on 3/4 and 3/5 skewed ladders","8 pages, 8 figures",,"10.1063/5.0048811",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We study the quantum phase transitions of frustrated antiferromagnetic
Heisenberg spin-1 systems on the 3/4 and 3/5 skewed two leg ladder geometries.
These systems can be viewed as arising by periodically removing rung bonds from
a zigzag ladder. We find that in large systems, the ground state (gs) of the
3/4 ladder switches from a singlet to a magnetic state for $J_1 \ge 1.82$; the
gs spin corresponds to ferromagnetic alignment of effective $S = 2$ objects on
each unit cell. The gs of antiferromagnetic exchange Heisenberg spin-1 system
on a 3/5 skewed ladder is highly frustrated and has spiral spin arrangements.
The amplitude of the spin density wave in the 3/5 ladder is significantly
larger compared to that in the magnetic state of the 3/4 ladder. The gs of the
system switches between singlet state and low spin magnetic states multiple
times on tuning $J_1$ in a finite size system. The switching pattern is
nonmonotonic as a function of $J_1$, and depends on the system size. It appears
to be the consequence of higher $J_1$ favoring higher spin magnetic state and
the finite system favoring a standing spin wave. For some specific parameter
values, the magnetic gs in the 3/5 system is doubly degenerate in two different
mirror symmetry subspaces. This degeneracy leads to spontaneous spin parity and
mirror symmetry breaking giving rise to spin current in the gs of the system.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:36:18 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 11:53:34 GMT""}]","2021-06-30"
"2103.00151","Georg Muntingh PhD","Juan Gerardo Alc\'azar, Georg Muntingh","Affine equivalences of surfaces of translation and minimal surfaces, and
  applications to symmetry detection and design","24 pages",,,,"math.AG cs.CG cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a characterization for affine equivalence of two surfaces of
translation defined by either rational or meromorphic generators. In turn, this
induces a similar characterization for minimal surfaces. In the rational case,
our results provide algorithms for detecting affine equivalence of these
surfaces, and therefore, in particular, the symmetries of a surface of
translation or a minimal surface of the considered types. Additionally, we
apply our results to designing surfaces of translation and minimal surfaces
with symmetries, and to computing the symmetries of the higher-order Enneper
surfaces.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:36:21 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 13:59:52 GMT""},{""version"":""v3"",""created"":""Fri, 17 Dec 2021 16:09:18 GMT""}]","2021-12-20"
"2103.00152","Kangtai Sun","Kangtai Sun, Zhibin Gao, and Jian-Sheng Wang","Phonon Hall effect with first-principles calculations","10 pages, 8 figures","Phys. Rev. B 103, 214301 (2021)","10.1103/PhysRevB.103.214301",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phonon Hall effect (PHE) has attracted a lot of attention in recent years
with many theoretical and experimental explorations published. While
experiments work on complicated materials, theoretical studies are still
hovering around the phenomenon-based models. Moreover, previous microscopic
theory was found unable to explain large thermal Hall conductivity obtained by
experiments in strontium titanate (STO). Therefore, as a first attempt to
bridge this gap, we implement first-principles calculations to explore the PHE
in real materials. Our work provides a new benchmark of the PHE in sodium
chloride (NaCl) under a large external magnetic field. Moreover, we demonstrate
our results in barium titanate (BTO), and discuss the results in STO in detail
about their deviation from experiments. As a possible future direction, we
further propose that the inner electronic Berry curvature plays an important
role in the PHE in STO.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:52:02 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 08:35:45 GMT""}]","2021-06-09"
"2103.00153","Arnav Arora","Arnav Arora, Preslav Nakov, Momchil Hardalov, Sheikh Muhammad Sarwar,
  Vibha Nayak, Yoan Dinkov, Dimitrina Zlatkova, Kyle Dent, Ameya Bhatawdekar,
  Guillaume Bouchard, Isabelle Augenstein","Detecting Harmful Content On Online Platforms: What Platforms Need Vs.
  Where Research Efforts Go","The paper has been accepted for publication to ACM Computing Surveys
  (CSUR)",,,,"cs.CL cs.SI","http://creativecommons.org/licenses/by/4.0/","  The proliferation of harmful content on online platforms is a major societal
problem, which comes in many different forms including hate speech, offensive
language, bullying and harassment, misinformation, spam, violence, graphic
content, sexual abuse, self harm, and many other. Online platforms seek to
moderate such content to limit societal harm, to comply with legislation, and
to create a more inclusive environment for their users. Researchers have
developed different methods for automatically detecting harmful content, often
focusing on specific sub-problems or on narrow communities, as what is
considered harmful often depends on the platform and on the context. We argue
that there is currently a dichotomy between what types of harmful content
online platforms seek to curb, and what research efforts there are to
automatically detect such content. We thus survey existing methods as well as
content moderation policies by online platforms in this light and we suggest
directions for future work.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:01:10 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 16:22:16 GMT""}]","2023-06-07"
"2103.00154","Dinuka De Zoysa","B.D.M. De Zoysa, Y.A.M.M.A. Ali, M.D.I. Maduranga, Indika Perera,
  Saliya Ekanayake, Anil Vullikanti","Parallel Algorithms for Densest Subgraph Discovery Using Shared Memory
  Model",,,,,"cs.IR cs.DC","http://creativecommons.org/licenses/by/4.0/","  The problem of finding dense components of a graph is a widely explored area
in data analysis, with diverse applications in fields and branches of study
including community mining, spam detection, computer security and
bioinformatics. This research project explores previously available algorithms
in order to study them and identify potential modifications that could result
in an improved version with considerable performance and efficiency leap.
Furthermore, efforts were also steered towards devising a novel algorithm for
the problem of densest subgraph discovery. This paper presents an improved
implementation of a widely used densest subgraph discovery algorithm and a
novel parallel algorithm which produces better results than a 2-approximation.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:07:39 GMT""}]","2021-03-02"
"2103.00155","Gianmassimo Tasinato","Gianmassimo Tasinato, Alice Garoffolo, Daniele Bertacca, Sabino
  Matarrese","Gravitational-wave cosmological distances in scalar-tensor theories of
  gravity","22 pages plus technical appendixes. 3 figures. V2: version published
  in JCAP",,"10.1088/1475-7516/2021/06/050",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the propagation of high-frequency gravitational waves (GW) in
scalar-tensor theories of gravity, with the aim of examining properties of
cosmological distances as inferred from GW measurements. By using symmetry
principles, we first determine the most general structure of the GW linearized
equations and of the GW energy momentum tensor, assuming that GW move with the
speed of light. Modified gravity effects are encoded in a small number of
parameters, and we study the conditions for ensuring graviton number
conservation in our covariant set-up. We then apply our general findings to the
case of GW propagating through a perturbed cosmological space-time, deriving
the expressions for the GW luminosity distance $d_L^{({\rm GW})}$ and the GW
angular distance $d_A^{({\rm GW})}$. We prove for the first time the validity
of Etherington reciprocity law $d_L^{({\rm GW})}\,=\,(1+z)^2\,d_A^{({\rm GW})}$
for a perturbed universe within a scalar-tensor framework. We find that besides
the GW luminosity distance, also the GW angular distance can be modified with
respect to General Relativity. We discuss implications of this result for
gravitational lensing, focussing on time-delays of lensed GW and lensed photons
emitted simultaneously during a multimessenger event. We explicitly show how
modified gravity effects compensate between different coefficients in the GW
time-delay formula: lensed GW arrive at the same time as their lensed
electromagnetic counterparts, in agreement with causality constraints.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:22:16 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 07:13:20 GMT""}]","2021-07-07"
"2103.00156","Hui Liu","Yanjie Jiang, Hui Liu, Nan Niu, Lu Zhang, Yamin Hu","Extracting Concise Bug-Fixing Patches from Human-Written Patches in
  Version Control Systems","ICSE 2021",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-quality and large-scale repositories of real bugs and their concise
patches collected from real-world applications are critical for research in
software engineering community. In such a repository, each real bug is
explicitly associated with its fix. Therefore, on one side, the real bugs and
their fixes} may inspire novel approaches for finding, locating, and repairing
software bugs; on the other side, the real bugs and their fixes are
indispensable for rigorous and meaningful evaluation of approaches for software
testing, fault localization, and program repair. To this end, a number of such
repositories, e.g., Defects4J, have been proposed. However, such repositories
are rather small because their construction involves expensive human
intervention. Although bug-fixing code commits as well as associated test cases
could be retrieved from version control systems automatically, existing
approaches could not yet automatically extract concise bug-fixing patches from
bug-fixing commits because such commits often involve bug-irrelevant changes.
In this paper, we propose an automatic approach, called BugBuilder, to
extracting complete and concise bug-fixing patches from human-written patches
in version control systems. It excludes refactorings by detecting refactorings
involved in bug-fixing commits, and reapplying detected refactorings on the
faulty version. It enumerates all subsets of the remaining part and validates
them on test cases. If none of the subsets has the potential to be a complete
bug-fixing patch, the remaining part as a whole is taken as a complete and
concise bug-fixing patch. Evaluation results on 809 real bug-fixing commits in
Defects4J suggest that BugBuilder successfully generated complete and concise
bug-fixing patches for forty percent of the bug-fixing commits, and its
precision (99%) was even higher than human experts.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:30:06 GMT""}]","2021-03-02"
"2103.00157","Kan Hatakeyama-Sato","Kan Hatakeyama-Sato and Kenichi Oyaizu","A Generative Model for Extrapolation Prediction in Materials Informatics",,,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a deep generative model for regression tasks in materials
informatics. The model is introduced as a component of a data imputer, and
predicts more than 20 diverse experimental properties of organic molecules. The
imputer is designed to predict material properties by ""imagining"" the missing
data in the database, enabling the use of incomplete material data. Even
removing 60% of the data does not diminish the prediction accuracy in a model
task. Moreover, the model excels at extrapolation prediction, where target
values of the test data are out of the range of the training data. Such
extrapolation has been regarded as an essential technique for exploring novel
materials, but has hardly been studied to date due to its difficulty. We
demonstrate that the prediction performance can be improved by >30% by using
the imputer compared with traditional linear regression and boosting models.
The benefit becomes especially pronounced with few records for an experimental
property (< 100 cases) when prediction would be difficult by conventional
methods. The presented approach can be used to more efficiently explore
functional materials and break through previous performance limits.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:31:02 GMT""}]","2021-03-02"
"2103.00158","Sergey Kulagin","S. A. Kulagin and V. V. Barinov","Hybrid model of proton structure functions","54 pages, 42 figures. Final version published in Phys. Rev. C
  including Supplemental Material","Phys. Rev. C 105 (2022) 045204","10.1103/PhysRevC.105.045204","INR-TH-2021-002","hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a ""hybrid"" model of the proton inelastic structure functions
applicable in a wide region of invariant mass of produced states $W$ and
invariant momentum transfer $Q$ including deep inelastic scattering (DIS),
nucleon resonance production as well as the region close to inelastic
threshold. DIS is described in terms of the parton distributions together with
higher-twist corrections from an available global QCD fit. The resonant part is
addressed in terms of the Breit-Wiegner contributions from five states
including the $\Delta(1232)$ resonance, the $N(1440)$ Roper resonance, and
three effective resonances describing the second and third resonance regions.
The couplings of the nucleon resonances to photon are described in terms of
helicity amplitudes. The nonresonant background is addressed in terms of DIS
structure functions smoothly extrapolated to low-$W$ and low-$Q$ values with
the proper behavior at the real photon limit $Q^2=0$ as well as near the
inelastic threshold. We independently treat the transverse $F_T$ and the
longitudinal $F_L$ structure function and fix the model parameters from a
global analysis of the world hydrogen electroproduction and photoproduction
cross-section data. We demonstrate a very good performance of the model by
comparing our predictions with data on differential cross sections and the
structure functions $F_2$ and $R=F_L/F_T$.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:32:55 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 14:47:27 GMT""},{""version"":""v3"",""created"":""Tue, 26 Apr 2022 12:08:31 GMT""}]","2022-05-03"
"2103.00159","Yuya Tanaka","Yuya Tanaka","Blow-up in a quasilinear parabolic-elliptic Keller-Segel system with
  logistic source",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the quasilinear parabolic-elliptic Keller-Segel system
with logistic source, \begin{align*}
  u_t=\Delta (u+1)^m - \chi \nabla \cdot (u(u+1)^{\alpha - 1} \nabla v)
  + \lambda(|x|) u - \mu(|x|) u^\kappa,
  \quad
  0=\Delta v - v + u,
  \quad x\in\Omega,\ t>0,
  \end{align*} where $\Omega:=B_{R}(0)\subset\mathbb{R}^n\ (n\ge3)$ is a ball
with some $R>0$; $m>0$, $\chi>0$, $\alpha>0$ and $\kappa\ge1$; $\lambda$ and
$\mu$ are spatially radial nonnegative functions. About this problem, Winkler
(Z. Angew. Math. Phys.; 2018; 69; Art. 69, 40) found the condition for $\kappa$
such that solutions blow up in finite time when $m=\alpha=1$. In the case that
$m=1$ and $\alpha\in(0,1)$ as well as $\lambda$ and $\mu$ are constant, some
conditions for $\alpha$ and $\kappa$ such that blow-up occurs were obtained in
a previous paper (Math. Methods Appl. Sci.; 2020; 43; 7372-7396). Moreover, in
the case that $m\ge1$ and $\alpha=1$ Black, Fuest and Lankeit
(arXiv:2005.12089[math.AP]) showed that there exists initial data such that
solutions blow up in finite time under some conditions for $m$ and $\kappa$.
The purpose of the present paper is to give conditions for $m\ge1$, $\alpha>0$
and $\kappa\ge1$ such that solutions blow up in finite time.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:36:38 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 02:56:01 GMT""}]","2021-04-02"
"2103.00160","Hirokazu Saito","Hirokazu Saito","Time-decay estimates for linearized two-phase Navier-Stokes equations
  with surface tension and gravity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to show time-decay estimates of solutions to
linearized two-phase Navier-Stokes equations with surface tension and gravity.
The original two-phase Navier-Stokes equations describe the two-phase
incompressible viscous flow with a sharp interface that is close to the
hyperplane $x_N=0$ in the $N$-dimensional Euclidean space, $N \geq 2$. It is
well-known that the Rayleigh-Taylor instability occurs when the upper fluid is
heavier than the lower one, while this paper assumes that the lower fluid is
heavier than the upper one and proves time-decay estimates of $L_p-L_q$ type
for the linearized equations. Our approach is based on solution formulas, given
by Shibata and Shimizu (2011), for a resolvent problem associated with the
linearized equations.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:50:27 GMT""}]","2021-03-02"
"2103.00161","Dinh Thao Nhu","Le Thi Ngoc Bao, Duong Dinh Phuoc, Le Thi Dieu Hien, and Dinh Nhu Thao","On the optical Stark effect of excitons in InGaAs prolate ellipsoidal
  quantum dots","27pages, 12 figures,to be published in Journal of Nanomaterials",,,,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the exciton absorption spectra in InGaAs prolate
ellipsoidal quantum dots when a strong pump laser resonant with electron
quantized levels is active. Our obtained results by renormalized wavefunction
theory show that, under suitable conditions, the initial exciton absorption
peak is split into two new peaks as the evidence of the existence of the
three-level optical Stark effect of excitons. We have suggested an explanation
of the origin of the effect as well as investigating the effect of pump field
energy, size, and geometric shape of the quantum dots on effect
characteristics. The comparison with the results obtained in the spherical
quantum dots implies the important role of geometric shape of the quantum
structures when we examine this effect.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:07:33 GMT""}]","2021-03-02"
"2103.00162","N. Asger Mortensen","N. Asger Mortensen, P. A. D. Gon\c{c}alves, Fedor A. Shuklin, Joel D.
  Cox, Christos Tserkezis, Masakazu Ichikawa, and Christian Wolff","Surface-response functions obtained from equilibrium electron-density
  profiles","Supplementary material is available upon request to authors","Nanophotonics 10, 3647 (2021)","10.1515/nanoph-2021-0084",,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  Surface-response functions are one of the most promising routes for bridging
the gap between fully quantum-mechanical calculations and phenomenological
models in quantum nanoplasmonics. Within all the currently available recipes
for obtaining such response functions, \emph{ab initio} calculations remain one
of the most predominant, wherein the surface-response function are retrieved
via the metal's non-equilibrium response to an external perturbation. Here, we
present a complementary approach where one of the most appealing
surface-response functions, namely the Feibelman $d$-parameters, yield a finite
contribution even in the case where they are calculated directly from the
equilibrium properties described under the local-response approximation (LRA),
but with a spatially varying equilibrium electron density. Using model
calculations that mimic both spill-in and spill-out of the equilibrium electron
density, we show that the obtained $d$-parameters are in qualitative agreement
with more elaborate, but also more computationally demanding, \emph{ab initio}
methods. The analytical work presented here illustrates how microscopic
surface-response functions can emerge out of entirely local electrodynamic
considerations.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:09:47 GMT""}]","2021-11-01"
"2103.00163","Renzhe Yu","Renzhe Yu, John Scott, Zachary A. Pardos","Unsupervised Representations Predict Popularity of Peer-Shared Artifacts
  in an Online Learning Environment",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  In online collaborative learning environments, students create content and
construct their own knowledge through complex interactions over time. To
facilitate effective social learning and inclusive participation in this
context, insights are needed into the correspondence between
student-contributed artifacts and their subsequent popularity among peers. In
this study, we represent student artifacts by their (a) contextual action logs
(b) textual content, and (c) set of instructor-specified features, and use
these representations to predict artifact popularity measures. Through a
mixture of predictive analysis and visual exploration, we find that the neural
embedding representation, learned from contextual action logs, has the
strongest predictions of popularity, ahead of instructor's knowledge, which
includes academic value and creativity ratings. Because this representation can
be learnt without extensive human labeling effort, it opens up possibilities
for shaping more inclusive student interactions on the fly in collaboration
with instructors and students alike.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:13:09 GMT""}]","2021-03-02"
"2103.00164","Menglin Yang","Menglin Yang, Ziqiao Meng, Irwin King","FeatureNorm: L2 Feature Normalization for Dynamic Graph Embedding","ICDM 2020;",,,,"cs.LG cs.CG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Dynamic graphs arise in a plethora of practical scenarios such as social
networks, communication networks, and financial transaction networks. Given a
dynamic graph, it is fundamental and essential to learn a graph representation
that is expected not only to preserve structural proximity but also jointly
capture the time-evolving patterns. Recently, graph convolutional network (GCN)
has been widely explored and used in non-Euclidean application domains. The
main success of GCN, especially in handling dependencies and passing messages
within nodes, lies in its approximation to Laplacian smoothing. As a matter of
fact, this smoothing technique can not only encourage must-link node pairs to
get closer but also push cannot-link pairs to shrink together, which
potentially cause serious feature shrink or oversmoothing problem, especially
when stacking graph convolution in multiple layers or steps. For learning
time-evolving patterns, a natural solution is to preserve historical state and
combine it with the current interactions to obtain the most recent
representation. Then the serious feature shrink or oversmoothing problem could
happen when stacking graph convolution explicitly or implicitly according to
current prevalent methods, which would make nodes too similar to distinguish
each other. To solve this problem in dynamic graph embedding, we analyze the
shrinking properties in the node embedding space at first, and then design a
simple yet versatile method, which exploits L2 feature normalization constraint
to rescale all nodes to hypersphere of a unit ball so that nodes would not
shrink together, and yet similar nodes can still get closer. Extensive
experiments on four real-world dynamic graph datasets compared with competitive
baseline models demonstrate the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:13:47 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 08:12:50 GMT""}]","2021-06-15"
"2103.00165","Zifeng Wang","Zifeng Wang, Yifan Yang, Rui Wen, Xi Chen, Shao-Lun Huang, and Yefeng
  Zheng","Lifelong Learning based Disease Diagnosis on Clinical Notes","Pacific-Asia Conference on Knowledge Discovery and Data Mining
  (PAKDD'21)",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current deep learning based disease diagnosis systems usually fall short in
catastrophic forgetting, i.e., directly fine-tuning the disease diagnosis model
on new tasks usually leads to abrupt decay of performance on previous tasks.
What is worse, the trained diagnosis system would be fixed once deployed but
collecting training data that covers enough diseases is infeasible, which
inspires us to develop a lifelong learning diagnosis system. In this work, we
propose to adopt attention to combine medical entities and context, embedding
episodic memory and consolidation to retain knowledge, such that the learned
model is capable of adapting to sequential disease-diagnosis tasks. Moreover,
we establish a new benchmark, named Jarvis-40, which contains clinical notes
collected from various hospitals. Our experiments show that the proposed method
can achieve state-of-the-art performance on the proposed benchmark.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:23:57 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 03:13:24 GMT""}]","2021-03-08"
"2103.00166","Yuya Tanaka","Yuya Tanaka, Giuseppe Viglialoro, Tomomi Yokota","Remarks on two connected papers about Keller-Segel systems with
  nonlinear production",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  These notes aim to provide a deeper insight on the specifics of two articles
dealing with chemotaxis models with nonlinear production. More precisely, we
are referring to the papers ""Boundedness of solutions to a quasilinear
parabolic-parabolic chemotaxis model with nonlinear signal production"" by X.
Tao, S. Zhou and M. Ding [J. Math. Anal. Appl. 474:1 (2019) 733-747] and
""Boundedness for a fully parabolic Keller-Segel model with sublinear
segregation and superlinear aggregation"" by S. Frassu and G. Viglialoro [Acta
Appl. Math. 171:1 (2021), 19]. These works, independently published in these
last years, present results leaving open room for further improvement. Indeed,
in the first a gap in the proof of the main claim appears, whereas the
cornerstone assumption in the second is not sharp. In these pages we give a
more complete picture to the relative underlying comprehension.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:32:27 GMT""}]","2021-03-02"
"2103.00167","Dirk Fahland","Dirk Fahland, Vadim Denisov, Wil. M.P. van der Aalst","Inferring Unobserved Events in Systems With Shared Resources and Queues","Final formatted version at Fundamenta Informatica","Fundamenta Informaticae, Volume 183, Issues 3-4: Petri Nets 2020
  (December 23, 2021) fi:8824",,,"cs.DC cs.AI cs.FL cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To identify the causes of performance problems or to predict process
behavior, it is essential to have correct and complete event data. This is
particularly important for distributed systems with shared resources, e.g., one
case can block another case competing for the same machine, leading to
inter-case dependencies in performance. However, due to a variety of reasons,
real-life systems often record only a subset of all events taking place. To
understand and analyze the behavior and performance of processes with shared
resources, we aim to reconstruct bounds for timestamps of events in a case that
must have happened but were not recorded by inference over events in other
cases in the system. We formulate and solve the problem by systematically
introducing multi-entity concepts in event logs and process models. We
introduce a partial-order based model of a multi-entity event log and a
corresponding compositional model for multi-entity processes. We define
PQR-systems as a special class of multi-entity processes with shared resources
and queues. We then study the problem of inferring from an incomplete event log
unobserved events and their timestamps that are globally consistent with a
PQR-system. We solve the problem by reconstructing unobserved traces of
resources and queues according to the PQR-model and derive bounds for their
timestamps using a linear program. While the problem is illustrated for
material handling systems like baggage handling systems in airports, the
approach can be applied to other settings where recording is incomplete. The
ideas have been implemented in ProM and were evaluated using both synthetic and
real-life event logs.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:34:01 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 08:30:23 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 15:24:15 GMT""}]","2022-03-14"
"2103.00168","Mazhar Ali","Mazhar Ali, Elena Gryazina, Anatoly Dymarsky, and Petr Vorobev","Voltage Feasibility Boundaries for Power System Security Assessment","This manuscript has been submitted to IEEE Transactions on Power
  Systems for possible publication",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Modern power systems face a grand challenge in grid management due to
increased electricity demand, imminent disturbances, and uncertainties
associated with renewable generation, which can compromise grid security. The
security assessment is directly connected to the robustness of the operating
condition and is evaluated by analyzing proximity to the power flow solution
space's boundary. Calculating location of such a boundary is a computationally
challenging task, linked to the power flow equations' non-linear nature,
presence of technological constraints, and complicated network topology. In
this paper we introduce a general framework to characterize points on the power
flow solution space boundary in terms of auxiliary variables subject to
algebraic constraints. Then we develop an adaptive continuation algorithm to
trace 1-dimensional sections of boundary curves which exhibits robust
performance and computational tractability. Implementation of the algorithm is
described in detail, and its performance is validated on different test
networks.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 09:49:50 GMT""}]","2021-03-02"
"2103.00169","Oleksandr Pylypovskyi","Oleksandr V. Pylypovskyi, Yelyzaveta A. Borysenko, J\""urgen
  Fassbender, Denis D. Sheka, Denys Makarov","Curvature-driven homogeneous Dzyaloshinskii-Moriya interaction and
  emergent weak ferromagnetism in anisotropic antiferromagnetic spin chains","5 pages, 3 figures, 1 table, 33 references, supplementary information","Appl. Phys. Lett. 118, 182405 (2021)","10.1063/5.0048823",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chiral antiferromagnets are currently considered for broad range of
applications in spintronics, spin-orbitronics and magnonics. In contrast to the
established approach relying on materials screening, the anisotropic and chiral
responses of low-dimensional antifferromagnets can be tailored relying on the
geometrical curvature. Here, we consider an achiral, anisotropic
antiferromagnetic spin chain and demonstrate that these systems possess
geometry-driven effects stemming not only from the exchange interaction but
also from the anisotropy. Peculiarly, the anisotropy-driven effects are
complementary to the curvature effects stemming from the exchange interaction
and rather strong as they are linear in curvature. These effects are
responsible for the tilt of the equilibrium direction of vector order
parameters and the appearance of the homogeneous Dzyaloshinskii-Moriya
interaction. The latter is a source of the geometry-driven weak ferromagnetism
emerging in curvilinear antiferromagnetic spin chains. Our findings provide a
deeper fundamental insight into the physics of curvilinear antiferromagnets
beyond the $\sigma$-model and offer an additional degree of freedom in the
design of spintronic and magnonic devices.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:02:01 GMT""}]","2022-06-16"
"2103.00170","Rodrigo Laigner","Rodrigo Laigner and Yongluan Zhou and Marcos Antonio Vaz Salles and
  Yijian Liu and Marcos Kalinowski","Data Management in Microservices: State of the Practice, Challenges, and
  Research Directions","Version accepted at VLDB '21",,,,"cs.DB cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Microservices have become a popular architectural style for data-driven
applications, given their ability to functionally decompose an application into
small and autonomous services to achieve scalability, strong isolation, and
specialization of database systems to the workloads and data formats of each
service. Despite the accelerating industrial adoption of this architectural
style, an investigation of the state of the practice and challenges
practitioners face regarding data management in microservices is lacking. To
bridge this gap, we conducted a systematic literature review of representative
articles reporting the adoption of microservices, we analyzed a set of popular
open-source microservice applications, and we conducted an online survey to
cross-validate the findings of the previous steps with the perceptions and
experiences of over 120 experienced practitioners and researchers.
  Through this process, we were able to categorize the state of practice of
data management in microservices and observe several foundational challenges
that cannot be solved by software engineering practices alone, but rather
require system-level support to alleviate the burden imposed on practitioners.
We discuss the shortcomings of state-of-the-art database systems regarding
microservices and we conclude by devising a set of features for
microservice-oriented database systems.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:08:32 GMT""},{""version"":""v2"",""created"":""Sun, 22 Aug 2021 08:53:50 GMT""}]","2021-08-24"
"2103.00171","Sanjay Mandal","Sanjay Mandal, Abhishek Parida, P.K. Sahoo","Observational constraints and some toy models in $f(Q)$ gravity with
  bulk viscous fluid","Universe accepted version","Universe, 8(4) (2022) 240","10.3390/universe8040240",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  The standard formulation of general relativity fails to describe some recent
interests in the universe. It impels us to go beyond the standard formulation
of gravity. The $f(Q)$ gravity theory is an interesting modified theory of
gravity, where the gravitational interaction is driven by the nonmetricity $Q$.
This study aims to examine the cosmological models with the presence of bulk
viscosity effect in the cosmological fluid within the framework of $f(Q)$
gravity. We construct three bulk viscous fluid models, i.e. (i) for the first
model, we assuming the Lagrangian $f(Q)$ as linear dependence on $Q$, (ii) for
the second model the Lagrangian $f(Q)$ as a polynomial functional form, and
(iii) the Lagrangian $f(Q)$ as a logarithmic dependence on $Q$. Furthermore, we
use 57 points of Hubble data and 1048 Pantheon dataset to constraint the model
parameters. Then, we discuss all the energy conditions for each model, which
helps us to test the self-consistency of our models. Finally, we present the
profiles of the equation of state parameters to test the models' present
status.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:17:02 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 15:34:17 GMT""},{""version"":""v3"",""created"":""Tue, 27 Jul 2021 09:42:36 GMT""},{""version"":""v4"",""created"":""Mon, 24 Jan 2022 10:26:08 GMT""},{""version"":""v5"",""created"":""Tue, 12 Apr 2022 08:22:04 GMT""}]","2022-04-14"
"2103.00172","Abubakr Awad","Abubakr Awad, Wei Pang, David Lusseau, George M. Coghill","A Survey on Physarum Polycephalum Intelligent Foraging Behaviour and
  Bio-Inspired Applications","arXiv admin note: text overlap with arXiv:1712.02910 by other authors",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years, research on Physarum polycephalum has become more popular
after Nakagaki et al. (2000) performed their famous experiment showing that
Physarum was able to find the shortest route through a maze. Subsequent
researches have confirmed the ability of Physarum-inspired algorithms to solve
a wide range of NP-hard problems. In contrast to previous reviews that either
focus on biological aspects or bio-inspired applications, here we present a
comprehensive review that highlights recent Physarum polycephalum biological
aspects, mathematical models, and Physarum bio-inspired algorithms and their
applications. The novelty of this review stems from our exploration of Physarum
intelligent behaviour in competition settings. Further, we have presented our
new model to simulate Physarum in competition, where multiple Physarum interact
with each other and with their environments. The bio-inspired Physarum in
competition algorithms proved to have great potentials for future research.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:19:41 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 10:49:13 GMT""},{""version"":""v3"",""created"":""Sat, 8 May 2021 10:22:14 GMT""}]","2021-05-11"
"2103.00173","Luyao Zhang","Yulin Liu, Luyao Zhang and Yinhong Zhao","Deciphering Bitcoin Blockchain Data by Cohort Analysis",,,,,"econ.GN cs.NA math.NA q-fin.CP q-fin.EC stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bitcoin is a peer-to-peer electronic payment system that has rapidly grown in
popularity in recent years. Usually, the complete history of Bitcoin blockchain
data must be queried to acquire variables with economic meaning. This task has
recently become increasingly difficult, as there are over 1.6 billion
historical transactions on the Bitcoin blockchain. It is thus important to
query Bitcoin transaction data in a way that is more efficient and provides
economic insights. We apply cohort analysis that interprets Bitcoin blockchain
data using methods developed for population data in the social sciences.
Specifically, we query and process the Bitcoin transaction input and output
data within each daily cohort. This enables us to create datasets and
visualizations for some key Bitcoin transaction indicators, including the daily
lifespan distributions of spent transaction output (STXO) and the daily age
distributions of the cumulative unspent transaction output (UTXO). We provide a
computationally feasible approach for characterizing Bitcoin transactions that
paves the way for future economic studies of Bitcoin.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:24:18 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 06:39:52 GMT""},{""version"":""v3"",""created"":""Sat, 15 Jan 2022 13:48:59 GMT""}]","2022-01-19"
"2103.00174","JuAe Song","Song JuAe","Realizations of automorphism groups of metric graphs induced by rational
  maps","14 pages",,,,"math.AG math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  For a rational map $\phi$ from a metric graph $\varGamma$ to a tropical
projective space $\boldsymbol{TP^n}$ defined by a ratio of rational functions
$f_1, \ldots, f_{n + 1}$, an automorphism $\sigma$ of $\varGamma$ induces a
permutation of the coordinates of $\boldsymbol{TP^n}$ if $\{ f_1, \ldots, f_{n
+ 1} \}$ is $\langle \sigma \rangle$-invariant. Through this description, we
can realize the automorphism group of $\Gamma$ as ambient automorphism group
such as tropical projective general linear group, tropical general linear group
and $\boldsymbol{Z}$-linear transformation group of Euclidean space.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:24:46 GMT""}]","2021-03-02"
"2103.00175","Yuta Wakasugi","Kimitoshi Tsutaya, Yuta Wakasugi","On heatlike lifespan of solutions of semilinear wave equations in
  Friedmann-Lema\^{i}tre-Robertson-Walker spacetime","16 pages","J. Math. Anal. Appl. 500 (2021), 125133","10.1016/j.jmaa.2021.125133",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a nonlinear wave equation for a massless scalar field with
self-interaction in the spatially flat Friedmann-Lema\^{i}tre-Robertson-Walker
spacetimes. We treat the so-called heatlike case where the critical exponent is
affected by the Fujita exponent. We show upper bounds of the lifespan of
blow-up solutions by distinguishing subcritical and critical cases.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:30:05 GMT""}]","2021-12-14"
"2103.00176","Mayank Gokarna","Mayank Gokarna","Reasons behind growing adoption of Cloud after Covid-19 Pandemic and
  Challenges ahead","10 pages including 27 references",,,,"cs.DC cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  There are many sectors which have moved to Cloud and are planning
aggressively to move their workloads to Cloud since the world entered Covid-19
pandemic. There are various reasons why Cloud is an essential irresistible
technology and serves as an ultimate solution to access IT software and
systems. It has become a new essential catalyst for Enterprise Organisations
which are looking for Digital Transformation. Remote working is a common
phenomenon now across all the IT companies making the services available all
the time. Covid-19 has made cloud adoption an immediate priority for
Organisation rather than a slowly approached future transformation. The
benefits of Cloud lies in the fact that employees rather engineers of an
enterprise are no more dependent on the closed hardware-based IT infrastructure
and hence eliminates the necessity of working from the networked office
premises. This has raised a huge demand for skilled Cloud specialist who can
manage and support the systems running on cloud across different regions of the
world. In this research, the reasons for growing Cloud adoption after pandemic
Covid-19 has been described and the challenges which Organization will face is
also explained. This study also details the most used cloud services during the
pandemic considering Amazon Web Services as the cloud provider.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:32:10 GMT""}]","2021-03-02"
"2103.00177","Sung Mook Lee","Dhong Yeon Cheong, Sung Mook Lee, and Seong Chan Park","Progress in Higgs inflation","9 pages, 4 figures, version published in JKPS. An invited review for
  the Korean Physical Society","Journal of the Korean Physical Society, 78(10), 897-906 (2021)","10.1007/s40042-021-00086-2",,"hep-ph astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the recent progress in Higgs inflation focusing on Higgs-$R^2$
inflation, primordial black hole production and the $R^3$ term.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:35:27 GMT""}]","2021-05-25"
"2103.00178","Suraj Sinha PhD","K. Jayaprakash, Prince Alex, A. Saravanan, M. Perumal, Thangjam
  Rishikanta Singh, and Suraj Kumar Sinha","Doubly Forced Anharmonic Oscillator Model for Floating Potential
  Fluctuations in DC Glow Discharge Plasma","11 pages, 7 figures",,"10.1016/j.physleta.2021.127521",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The Floating Potential Fluctuations (FPF) observed in a dc glow discharge
plasma powered with two sources is modeled using an anharmonic oscillator with
two forcing terms. In the discharge system, one of the electrode is biased to a
negative voltage source (i.e. cathode), and the second electrode is biased to a
positive voltage source (i.e. anode), while the stainless-steel vacuum chamber
is grounded. The dc glow discharge plasma is generated by the application of
negative voltage on the cathode with respect to the grounded chamber using one
of the power supplies. On the application of positive voltage to the anode
using second power supply results in formation of a potential structure on
achieving the triggering criteria. This potential structure is referred as
anodic double layer (ADL). The evolution of ADL is associated with FPF.
Therefore, FPF is analyzed to characterize the ADL's dynamical features. In
this work, the experimentally observed FPF compared with numerically obtained
oscillations using an anharmonic oscillator model with two forcing terms. Each
of these forcing terms are associated with the two power supplies used in the
experiment. The experimentally and numerically obtained oscillations from the
model are studied using phase-space plot, FFT, Largest Lyapunov exponent (LLE).
The dynamical features of oscillations obtained by the model show strong
agreement with the experiment and can be extended for a description of complex
systems driven by multiple forces.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:36:11 GMT""}]","2021-07-28"
"2103.00179","Kostas Kolomvatsos","Kostas Kolomvatsos, Christos Anagnostopoulos","A Soft Method for Outliers Detection at the Edge of the Network",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The combination of the Internet of Things and the Edge Computing gives many
opportunities to support innovative applications close to end users. Numerous
devices present in both infrastructures can collect data upon which various
processing activities can be performed. However, the quality of the outcomes
may be jeopardized by the presence of outliers. In this paper, we argue on a
novel model for outliers detection by elaborating on a `soft' approach. Our
mechanism is built upon the concepts of candidate and confirmed outliers. Any
data object that deviates from the population is confirmed as an outlier only
after the study of its sequence of magnitude values as new data are
incorporated into our decision making model. We adopt the combination of a
sliding with a landmark window model when a candidate outlier is detected to
expand the sequence of data objects taken into consideration. The proposed
model is fast and efficient as exposed by our experimental evaluation while a
comparative assessment reveals its pros and cons.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:36:24 GMT""}]","2021-03-02"
"2103.00180","Tirtharaj Dash","Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan","Incorporating Domain Knowledge into Deep Neural Networks","Submitted to IJCAI-2021 Survey Track (6+2 pages)",,,,"cs.NE cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a survey of ways in which domain-knowledge has been included when
constructing models with neural networks. The inclusion of domain-knowledge is
of special interest not just to constructing scientific assistants, but also,
many other areas that involve understanding data using human-machine
collaboration. In many such instances, machine-based model construction may
benefit significantly from being provided with human-knowledge of the domain
encoded in a sufficiently precise form. This paper examines two broad
approaches to encode such knowledge--as logical and numerical constraints--and
describes techniques and results obtained in several sub-categories under each
of these approaches.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:39:43 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 17:47:22 GMT""}]","2021-03-16"
"2103.00181","Lorenzo Zino","Lorenzo Zino and Ming Cao","Analysis, Prediction, and Control of Epidemics: A Survey from Scalar to
  Dynamic Network Models","38 pages, 11 figures. Accepted for publication in the IEEE Circuits
  and Systems Magazine (\c{opyright} 2021 IEEE)","IEEE Circuits and Systems Magazine, vol. 21, no. 4, pp. 4-23,
  Fourthquarter 2021","10.1109/MCAS.2021.3118100",,"math.DS cs.SI cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the ongoing COVID-19 pandemic, mathematical models of epidemic
spreading have emerged as powerful tools to produce valuable predictions of the
evolution of the pandemic, helping public health authorities decide which
intervention policies should be implemented. The study of these models --
grounded in the systems theory and often analyzed using control-theoretic tools
-- is an extremely important research area for many researchers from different
fields, including epidemiology, engineering, physics, mathematics, computer
science, sociology, economics, and management. In this survey, we review the
history and present the state of the art in the modeling, analysis, and control
of epidemic dynamics. We discuss different approaches to epidemic modeling,
either deterministic or stochastic, ranging from the first implementations of
scalar systems of differential equations to describing the epidemic spreading
at the population level, and to more recent models on dynamic networks, which
capture the spatial spread and the time-varying nature of human interactions.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:40:45 GMT""}]","2021-11-18"
"2103.00182","Cristina Curreli","Cristina Curreli (1,2), Francesco Pappalardo (3), Giulia Russo (3,4),
  Marzio Pennisi (5), Dimitrios Kiagias (6), Miguel Juarez (6), Marco Viceconti
  (1,2). ((1) Department of Industrial Engineering, Alma Mater Studiorum -
  University of Bologna (IT), (2) Medical Technology Lab, IRCCS Istituto
  Ortopedico Rizzoli, Bologna (IT), (3) Department of Drug Sciences, University
  of Catania (IT), (4) Mimesis srl, Catania (IT), (5) Computer Science
  Institute, DiSIT, University of Eastern Piedmont, Alessandria, Italy, (6)
  School of Mathematics & Statistics and Insigneo and Institute for in silico
  Medicine, University of Sheffield (UK))","Verification of an agent-based disease model of human mycobacterium
  tuberculosis infection",,,,,"q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Agent-Based Models are a powerful class of computational models widely used
to simulate complex phenomena in many different application areas. However, one
of the most critical aspects, poorly investigated in the literature, regards an
important step of the model credibility assessment: solution verification. This
study overcomes this limitation by proposing a general verification framework
for Agent-Based Models that aims at evaluating the numerical errors associated
with the model. A step-by-step procedure, which consists of two main
verification studies (deterministic and stochastic model verification), is
described in detail and applied to a specific mission critical scenario: the
quantification of the numerical approximation error for UISS-TB, an ABM of the
human immune system developed to predict the progression of pulmonary
tuberculosis. Results provide indications on the possibility to use the
proposed model verification workflow to systematically identify and quantify
numerical approximation errors associated with UISS-TB and, in general, with
any other ABMs.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:43:18 GMT""}]","2021-03-02"
"2103.00183","Roberto Casadio","Roberto Casadio","Geometry and thermodynamics of coherent quantum black holes","LaTeX, 16 pages, 6 graphs in 4 figures",,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We present a quantum description of black holes given by coherent states of
gravitons sourced by a matter core. The expected behaviour in the weak-field
region outside the horizon is recovered, with arbitrarily good approximation,
but the classical central singularity is not resolved because the coherent
states may not contain modes of arbitrarily short wavelength and the matter
core must therefore have finite size. Ensuing quantum corrections both in the
interior and exterior are also estimated by assuming the mean-field
approximation holds everywhere. These deviations from the classical black hole
geometry can be viewed as quantum hair and lead to a quantum corrected horizon
radius and thermodynamics.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:46:48 GMT""},{""version"":""v2"",""created"":""Sun, 25 Apr 2021 14:45:46 GMT""},{""version"":""v3"",""created"":""Sat, 4 Sep 2021 06:10:16 GMT""},{""version"":""v4"",""created"":""Tue, 1 Mar 2022 17:52:23 GMT""},{""version"":""v5"",""created"":""Thu, 8 Sep 2022 13:17:49 GMT""}]","2022-09-09"
"2103.00184","Ewe-Wei Saw","Ewe-Wei Saw, Xiaohui Meng","Intricate Relations Among Particle Collision, Relative Motion and
  Clustering in Turbulent Clouds: Computational Observation and Theory",,,"10.5194/acp-22-3779-2022",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Considering turbulent clouds containing small inertial particles, we
investigate the effect of particle collision, in particular
collision-coagulation, on particle clustering and particle relative motion. We
perform direct numerical simulation (DNS) of coagulating particles in isotropic
turbulent flow in the regime of small Stokes number ($St=0.001-0.54$) and find
that, due to collision-coagulation, the radial distribution functions (RDFs)
fall-off dramatically at scales $r \sim d\,\,$ (where $d$ is the particle
diameter) to small but finite values, while the mean radial-component of
particle relative velocities (MRV) increase sharply in magnitudes. Based on a
previously proposed Fokker-Planck (drift-diffusion) framework, we derive a
theoretical account of the relationship among particle collision-coagulation
rate, RDF and MRV. The theory includes contributions from
turbulent-fluctuations absent in earlier mean-field theories. We show
numerically that the theory accurately accounts for the DNS results (i.e.,
given an accurate RDF, the theory could produce an accurate MRV). Separately,
we also propose a phenomenological model that could directly predict MRV and
find that it is accurate when calibrated using fourth moments of the fluid
velocities. We use the model to derive a general solution of RDF. We uncover a
paradox: the past empirical success of the differential version of the theory
is theoretically unjustified. We see a further shape-preserving reduction of
the RDF (and MRV) when the gravitational settling parameter ($S_g$) is of order
$O(1)$. Our results demonstrate strong coupling between RDF and MRV and imply
that earlier isolated studies on either RDF or MRV have limited relevance for
predicting particle collision rate.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:48:00 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 10:12:39 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 13:35:46 GMT""},{""version"":""v4"",""created"":""Mon, 18 Oct 2021 14:38:16 GMT""},{""version"":""v5"",""created"":""Wed, 13 Jul 2022 16:55:47 GMT""}]","2022-07-14"
"2103.00185","Miel Sharf","Miel Sharf, Iliya Romm, Michael Palman, Daniel Zelazo, and Beni
  Cukurel","Economic Dispatch of a Single Micro-Gas Turbine Under CHP Operation with
  Uncertain Demands","16 pages, 8 figures",,,,"math.OC cs.DM cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work considers the economic dispatch problem for a single micro-gas
turbine, governed by a discrete state-space model, under combined heat and
power (CHP) operation and coupled with a utility. If the exact power and heat
demands are given, existing algorithms can be used to give a quick optimal
solution to the economic dispatch problem. However, in practice, the power and
heat demands can not be known deterministically, but are rather predicted,
resulting in an estimate and a bound on the estimation error. We consider the
case in which the power and heat demands are unknown, and present a robust
optimization-based approach for scheduling the turbine's heat and power
generation, in which the demand is assumed to be inside an uncertainty set. We
consider two different choices of the uncertainty set relying on the
$\ell^\infty$- and the $\ell^1$-norms, each with different advantages, and
consider the associated robust economic dispatch problems. We recast these as
robust shortest-path problems on appropriately defined graphs. For the first
choice, we provide an exact linear-time algorithm for the solution of the
robust shortest-path problem, and for the second, we provide an exact
quadratic-time algorithm and an approximate linear-time algorithm. The
efficiency and usefulness of the algorithms are demonstrated using a detailed
case study that employs real data on energy demand profiles and electricity
tariffs.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:03:21 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 16:13:17 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 11:40:14 GMT""}]","2021-11-05"
"2103.00186","Haide Wang","Ji Zhou, Chengkun Yang, Dawei Wang, Qi Sui, Haide Wang, Shecheng Gao,
  Yuanhua Feng, Weiping Liu, Yuelin Yan, Jianping Li, Changyuan Yu and Zhaohui
  Li","Burst-Error Propagation Suppression for Decision-Feedback Equalizer in
  Field-Trial Submarine Fiber-Optic Communications","Under review of Journal of Lightwave Techonlogy",,"10.1109/JLT.2021.3076822",,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a field-trial C-band 72Gbit/s optical on-off keying
(OOK) system over 18.8km dispersion-uncompensated submarine optical cable in
the South China Sea. Chromatic dispersion (CD) of 18.8km submarine optical
cable causes four spectral nulls on the 36GHz bandwidth of 72Gbit/s OOK signal,
which is the main obstacle for achieving an acceptable bit-error-rate (BER)
performance. Decision feedback equalizer (DFE) is effective to compensate for
the spectral nulls. However, DFE has a serious defect of burst-error
propagation when the burst errors emerge due to the unstable submarine
environment. Weighted DFE (WDFE) can be used to mitigate the burst-error
propagation, but it cannot fully compensate for the spectral nulls because only
a part of feedback symbols is directly decided. Fortunately, maximum likelihood
sequence estimation (MLSE) can be added after the WDFE to simultaneously
eliminate the resisting spectral distortions and implement optimal detection.
Compared to the joint DFE and MLSE algorithm, the joint WDFE and MLSE algorithm
can effectively suppress the burst-error propagation to obtain a maximum 2.9dB
improvement of $\boldsymbol{Q}$ factor and eliminate the phenomenon of BER
floor. In conclusion, the joint WDFE and MLSE algorithm can solve the
burst-error propagation for the field-trial fiber-optic communications.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:14:28 GMT""}]","2021-08-04"
"2103.00187","Michael Walton","Michael Walton, Viliam Lisy","Multi-agent Reinforcement Learning in OpenSpiel: A Reproduction Report",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this report, we present results reproductions for several core algorithms
implemented in the OpenSpiel framework for learning in games. The primary
contribution of this work is a validation of OpenSpiel's re-implemented search
and Reinforcement Learning algorithms against the results reported in their
respective originating works. Additionally, we provide complete documentation
of hyperparameters and source code required to reproduce these experiments
easily and exactly.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:16:09 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 03:41:22 GMT""}]","2021-03-03"
"2103.00188","Mengxi Liu","Mengxi Liu, Qian Shi, Andrea Marinoni, Da He, Xiaoping Liu, Liangpei
  Zhang","Super-resolution-based Change Detection Network with Stacked Attention
  Module for Images with Different Resolutions",,"IEEE Transactions on Geoscience and Remote Sensing. 2021","10.1109/TGRS.2021.3091758",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Change detection, which aims to distinguish surface changes based on
bi-temporal images, plays a vital role in ecological protection and urban
planning. Since high resolution (HR) images cannot be typically acquired
continuously over time, bi-temporal images with different resolutions are often
adopted for change detection in practical applications. Traditional
subpixel-based methods for change detection using images with different
resolutions may lead to substantial error accumulation when HR images are
employed; this is because of intraclass heterogeneity and interclass
similarity. Therefore, it is necessary to develop a novel method for change
detection using images with different resolutions, that is more suitable for HR
images. To this end, we propose a super-resolution-based change detection
network (SRCDNet) with a stacked attention module. The SRCDNet employs a super
resolution (SR) module containing a generator and a discriminator to directly
learn SR images through adversarial learning and overcome the resolution
difference between bi-temporal images. To enhance the useful information in
multi-scale features, a stacked attention module consisting of five
convolutional block attention modules (CBAMs) is integrated to the feature
extractor. The final change map is obtained through a metric learning-based
change decision module, wherein a distance map between bi-temporal features is
calculated. The experimental results demonstrate the superiority of the
proposed method, which not only outperforms all baselines -with the highest F1
scores of 87.40% on the building change detection dataset and 92.94% on the
change detection dataset -but also obtains the best accuracies on experiments
performed with images having a 4x and 8x resolution difference. The source code
of SRCDNet will be available at https://github.com/liumency/SRCDNet.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:17:40 GMT""}]","2021-06-24"
"2103.00189","Jiaqian Liu Mrs","JiaQian Liu","The $L_p$-Gaussian Minkowski problem","renew",,,,"math.PR math.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we extend the article that Minkowski problem in Gaussian
probability space of Huang et al. to $L_p$-Gaussian Minkowski problem, and
obtain the existence and uniqueness of $o$-symmetry weak solution in case of
$p\geq1$.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:18:54 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 03:37:06 GMT""},{""version"":""v3"",""created"":""Mon, 24 May 2021 13:03:17 GMT""}]","2021-05-25"
"2103.00190","Zhepei Wang","Zhepei Wang, Xin Zhou, Chao Xu and Fei Gao","Geometrically Constrained Trajectory Optimization for Multicopters","Accepted as regular paper in IEEE Transactions on Robotics (T-RO)",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an optimization-based framework for multicopter trajectory
planning subject to geometrical configuration constraints and user-defined
dynamic constraints. The basis of the framework is a novel trajectory
representation built upon our novel optimality conditions for unconstrained
control effort minimization. We design linear-complexity operations on this
representation to conduct spatial-temporal deformation under various planning
requirements. Smooth maps are utilized to exactly eliminate geometrical
constraints in a lightweight fashion. A variety of state-input constraints are
supported by the decoupling of dense constraint evaluation from sparse
parameterization, and backward differentiation of flatness map. As a result,
this framework transforms a generally constrained multicopter planning problem
into an unconstrained optimization that can be solved reliably and efficiently.
Our framework bridges the gaps among solution quality, planning efficiency, and
constraint fidelity for a multicopter with limited resources and maneuvering
capability. Its generality and robustness are both demonstrated by applications
to different flight tasks. Extensive simulations and benchmarks are also
conducted to show its capability of generating high-quality solutions while
retaining the computation speed against other specialized methods by orders of
magnitude. The source code of our framework is available at:
https://github.com/ZJU-FAST-Lab/GCOPTER
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:22:27 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 08:24:37 GMT""},{""version"":""v3"",""created"":""Fri, 11 Mar 2022 17:53:19 GMT""},{""version"":""v4"",""created"":""Thu, 14 Apr 2022 06:13:22 GMT""}]","2022-04-15"
"2103.00191","Senthil Yogamani","Anna Konrad, Ciar\'an Eising, Ganesh Sistu, John McDonald, Rudi
  Villing, Senthil Yogamani","FisheyeSuperPoint: Keypoint Detection and Description Network for
  Fisheye Images","Accepted for Presentation at International Conference on Computer
  Vision Theory and Applications (VISAPP 2022)",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Keypoint detection and description is a commonly used building block in
computer vision systems particularly for robotics and autonomous driving.
However, the majority of techniques to date have focused on standard cameras
with little consideration given to fisheye cameras which are commonly used in
urban driving and automated parking. In this paper, we propose a novel training
and evaluation pipeline for fisheye images. We make use of SuperPoint as our
baseline which is a self-supervised keypoint detector and descriptor that has
achieved state-of-the-art results on homography estimation. We introduce a
fisheye adaptation pipeline to enable training on undistorted fisheye images.
We evaluate the performance on the HPatches benchmark, and, by introducing a
fisheye based evaluation method for detection repeatability and descriptor
matching correctness, on the Oxford RobotCar dataset.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:26:34 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 17:22:56 GMT""}]","2021-11-30"
"2103.00192","Taito Tauchi","Taito Tauchi, Tsuyoshi Yoneda","Some positivity results of the curvature on the group corresponding to
  the incompressible Euler equation with Coriolis force",,,,,"math.DG math.AP physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we investigate the geometry of a central extension
$\widehat{\mathcal D}_{\mu}(S^{2})$ of the group of volume-preserving
diffeomorphisms of the 2-sphere equipped with the $L^{2}$-metric, whose
geodesics correspond solutions of the incompressible Euler equation with
Coriolis force. In particular, we calculate the Misiolek curvature of this
group. This value is related to the existence of a conjugate point and its
positivity directly implies the positivity of the sectional curvature.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:28:57 GMT""}]","2021-03-02"
"2103.00193","Peng Song","Peng Song, Zhufeng Hou, Pedro Baptista de Castro, Kousuke Nakano,
  Kenta Hongo, Kenta Hongo, Yoshihiko Takano and Ryo Maezono","High-$T_c$ ternary metal hydrides, YKH$_{12}$ and LaKH$_{12}$,
  discovered by machine learning","21 pages, 6 figures",,,,"cond-mat.supr-con physics.app-ph physics.comp-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  The search for hydride compounds that exhibit high $T_c$ superconductivity
has been extensively studied. Within the range of binary hydride compounds, the
studies have been developed well including data-driven searches as a topic of
interest. Toward the search for the ternary systems, the number of possible
combinations grows rapidly, and hence the power of data-driven search gets more
prominent. In this study, we constructed various regression models to predict
$T_c$ for ternary hydride compounds and found the extreme gradient boosting
(XGBoost) regression giving the best performance. The best performed regression
predicts new promising candidates realizing higher $T_c$, for which we further
identified their possible crystal structures. Confirming their lattice and
thermodynamical stabilities, we finally predicted new ternary hydride
superconductors, YKH$_{12}$ [$C2/m$ (No.12), $T_c$=143.2 K at 240 GPa] and
LaKH$_{12}$ [$R\bar{3}m$ (No.166), $T_c$=99.2 K at 140 GPa] from first
principles.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:32:58 GMT""}]","2021-03-11"
"2103.00194","Kingshuk Majumder","Kingshuk Majumder, Uday Bondhugula","HIR: An MLIR-based Intermediate Representation for Hardware Accelerator
  Description","14 pages, 3 figures",,,,"cs.AR cs.PL","http://creativecommons.org/licenses/by/4.0/","  The emergence of machine learning, image and audio processing on edge devices
has motivated research towards power efficient custom hardware accelerators.
Though FPGAs are an ideal target for energy efficient custom accelerators, the
difficulty of hardware design and the lack of vendor agnostic, standardized
hardware compilation infrastructure has hindered their adoption.
  This paper introduces HIR, an MLIR-based intermediate representation (IR) to
describe hardware accelerator designs. HIR combines high level language
features, such as loops and multi-dimensional tensors, with programmer defined
explicit scheduling, to provide a high-level IR suitable for DSL compiler
pipelines without compromising control over the micro-architecture of the
accelerator. HIR's explicit schedules allow it to express fine-grained,
synchronization-free parallelism and optimizations such as retiming and
pipelining. Built as a dialect in MLIR, it draws from best IR practices learnt
from communities like those of LLVM. While offering rich optimization
opportunities and a high level abstraction, HIR enables sharing of
optimizations, utilities and passes with software compiler infrastructure.
  Our implementation shows that the code generation time of the HIR code
generator is on average 1112x lower than that of Xilinx Vivado HLS on a range
of kernels without a compromise on the quality of the generated hardware. We
believe that these are significant steps forward in the design of IRs for
hardware synthesis and in equipping domain-specific languages with a productive
and performing compilation path to custom hardware acceleration.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:34:30 GMT""}]","2021-03-02"
"2103.00195","Francesco Cianfrani Dr","Francesco Cianfrani","Gravitational quantum states as finite representations of the Lorentz
  group","5 pages, to appear in Classical and Quantum Gravity",,"10.1088/1361-6382/ac33bd",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A manifestly Lorentz-covariant formulation of Loop Quantum Gravity (LQG) is
given in terms of finite-dimensional representations of the Lorentz group. The
formulation accounts for discrete symmetries, such as parity and time-reversal,
and it establishes a link with Wigner classification of particles. The
resulting quantum model can be seen as LQG with the internal $SU(2)\otimes
SU(2)$ group and it is free of the Immirzi parameter, while the scalar
constraint is just the Euclidean part.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:47:57 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 12:02:54 GMT""},{""version"":""v3"",""created"":""Sat, 6 Nov 2021 11:49:44 GMT""}]","2021-12-08"
"2103.00196","Thomas Preibisch","Thomas Preibisch, Stefan Flaischlen, Christiane G\""oppl, Barbara
  Ercolano, Veronica Roccatagliata","Detection of new O-type stars in the obscured stellar cluster Tr 16-SE
  in the Carina Nebula with KMOS","Accepted for publication in Astronomy & Astrophysics",,"10.1051/0004-6361/202039620",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Carina Nebula harbors a large population of high-mass stars, including at
least 75 O-type and Wolf-Rayet stars, but the current census is not complete
since further high-mass stars may be hidden in or behind the dense dark clouds
that pervade the association. With the aim of identifying optically obscured O-
and early B-type stars in the Carina Nebula, we performed the first infrared
spectroscopic study of stars in the optically obscured stellar cluster Tr
16-SE, located behind a dark dust lane south of eta Car. We used the
integral-field spectrograph KMOS at the ESO VLT to obtain H- and K-band spectra
with a resolution of R sim 4000 (Delta lambda sim 5 A) for 45 out of the 47
possible OB candidate stars in Tr 16-SE, and we derived spectral types for
these stars. We find 15 stars in Tr 16-SE with spectral types between O5 and B2
(i.e., high-mass stars with M >= 8 Msun, only two of which were known before.
An additional nine stars are classified as (Ae)Be stars (i.e.,
intermediate-mass pre-main-sequence stars), and most of the remaining targets
show clear signatures of being late-type stars and are thus most likely
foreground stars or background giants unrelated to the Carina Nebula. Our
estimates of the stellar luminosities suggest that nine of the 15 O- and early
B-type stars are members of Tr 16-SE, whereas the other six seem to be
background objects. Our study increases the number of spectroscopically
identified high-mass stars (M >= 8 Msun) in Tr 16-SE from two to nine and shows
that Tr 16-SE is one of the larger clusters in the Carina Nebula. Our
identification of three new stars with spectral types between O5 and O7 and
four new stars with spectral types O9 to B1 significantly increases the number
of spectroscopically identified O-type stars in the Carina Nebula.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:48:00 GMT""}]","2021-04-14"
"2103.00197","Anna Olofsson","Anna Olofsson, Emma Rose Simpson, Neven Ibrakovic, Samuel Bengtsson
  and Johan Mauritsson","Spatial control of extreme ultraviolet light with opto-optical phase
  modulation",,,"10.1364/OL.422049",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Extreme-ultraviolet (XUV) light is notoriously difficult to control due to
its strong interaction cross-section with media. We demonstrate a method to
overcome this problem by using Opto-Optical Modulation guided by a geometrical
model to shape XUV light. A bell-shaped infrared light pulse is shown to
imprint a trace of its intensity profile onto the XUV light in the far-field,
such that a change in the intensity profile of the infrared pulse leads to a
change in the shape of the far-field XUV light. The geometrical model assists
the user in predicting the effect of a specific intensity profile of the
infrared pulse, thus enabling a deterministic process.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:49:42 GMT""}]","2021-05-19"
"2103.00198","Jakub Gizbert-Studnicki","J. Ambj{\o}rn, Z. Drogosz, J. Gizbert-Studnicki, A. G\""orlich, J.
  Jurkiewicz, and D. N\'emeth","Matter-driven change of spacetime topology","5 pages, 5 figures",,"10.1103/PhysRevLett.127.161301",,"hep-th gr-qc hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using Monte-Carlo computer simulations, we study the impact of matter fields
on the geometry of a typical quantum universe in the CDT model of lattice
quantum gravity. The quantum universe has the size of a few Planck lengths and
the spatial topology of a three-torus. The matter fields are multi-component
scalar fields taking values in a torus with circumference $\delta$ in each
spatial direction, which acts as a new parameter in the CDT model. Changing
$\delta$, we observe a phase transition caused by the scalar field. This
discovery may have important consequences for quantum universes with
non-trivial topology, since the phase transition can change the topology to a
simply connected one.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 11:55:32 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 20:03:37 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 08:59:29 GMT""}]","2021-10-27"
"2103.00199","Abdul Hameed Azeemi","Abdul Hameed Azeemi, Adeel Waheed","COVID-19 Tweets Analysis through Transformer Language Models","5 pages, 5 figures",,,,"cs.CL cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Understanding the public sentiment and perception in a healthcare crisis is
essential for developing appropriate crisis management techniques. While some
studies have used Twitter data for predictive modelling during COVID-19,
fine-grained sentiment analysis of the opinion of people on social media during
this pandemic has not yet been done. In this study, we perform an in-depth,
fine-grained sentiment analysis of tweets in COVID-19. For this purpose, we
perform supervised training of four transformer language models on the
downstream task of multi-label classification of tweets into seven tone
classes: [confident, anger, fear, joy, sadness, analytical, tentative]. We
achieve a LRAP (Label Ranking Average Precision) score of 0.9267 through
RoBERTa. This trained transformer model is able to correctly predict, with high
accuracy, the tone of a tweet. We then leverage this model for predicting tones
for 200,000 tweets on COVID-19. We then perform a country-wise analysis of the
tone of tweets, and extract useful indicators of the psychological condition
about the people in this pandemic.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:06:33 GMT""}]","2021-03-02"
"2103.00200","Wenrui Gan","Wenrui Gan, Zhulin Liu, C. L. Philip Chen, Tong Zhang","Siamese Labels Auxiliary Learning",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In deep learning, auxiliary training has been widely used to assist the
training of models. During the training phase, using auxiliary modules to
assist training can improve the performance of the model. During the testing
phase, auxiliary modules can be removed, so the test parameters are not
increased. In this paper, we propose a novel auxiliary training method, Siamese
Labels Auxiliary Learning (SiLa). Unlike Deep Mutual Learning (DML), SiLa
emphasizes auxiliary learning and can be easily combined with DML. In general,
the main work of this paper include: (1) propose SiLa Learning, which improves
the performance of common models without increasing test parameters; (2)
compares SiLa with DML and proves that SiLa can improve the generalization of
the model; (3) SiLa is applied to Dynamic Neural Networks, and proved that SiLa
can be used for various types of network structures.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:07:30 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 13:26:46 GMT""},{""version"":""v3"",""created"":""Thu, 26 May 2022 23:51:19 GMT""}]","2022-05-30"
"2103.00201","Giambattista Gruosso","Giulia Crocioni, Giambattista Gruosso, Danilo Pau, Davide Denaro,
  Luigi Zambrano, Giuseppe di Giore","Characterization of Neural Networks Automatically Mapped on
  Automotive-grade Microcontrollers",,,,,"cs.LG cs.NE cs.PL cs.SY eess.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Nowadays, Neural Networks represent a major expectation for the realization
of powerful Deep Learning algorithms, which can determine several physical
systems' behaviors and operations. Computational resources required for model,
training, and running are large, especially when related to the amount of data
that Neural Networks typically need to generalize. The latest TinyML
technologies allow integrating pre-trained models on embedded systems, allowing
making computing at the edge faster, cheaper, and safer. Although these
technologies originated in the consumer and industrial worlds, many sectors can
greatly benefit from them, such as the automotive industry. In this paper, we
present a framework for implementing Neural Network-based models on a family of
automotive Microcontrollers, showing their efficiency in two case studies
applied to vehicles: intrusion detection on the Controller Area Network bus and
residual capacity estimation in Lithium-Ion batteries, widely used in Electric
Vehicles.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:16:50 GMT""}]","2021-03-02"
"2103.00202","Laia Domingo Colomer","Laia Domingo and Florentino Borondo","Deep learning methods for the computation of vibrational wavefunctions",,,"10.1016/j.cnsns.2021.105989",,"physics.chem-ph quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper we design and use two Deep Learning models to generate the
ground and excited wavefunctions of different Hamiltonians suitable for the
study the vibrations of molecular systems. The generated neural networks are
trained with Hamiltonians that have analytical solutions, and ask the network
to generalize these solutions to more complex Hamiltonian functions. This
approach allows to reproduce the excited vibrational wavefunctions of different
molecular potentials. All methodologies used here are data-driven, therefore
they do not assume any information about the underlying physical model of the
system. This makes this approach versatile, and can be used in the study of
multiple systems in quantum chemistry.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:26:40 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 16:18:29 GMT""}]","2021-11-24"
"2103.00203","Samuel Ma\~nas-Valero","Carla Boix-Constant, Samuel Ma\~nas-Valero, Rosa C\'ordoba, Eugenio
  Coronado","van der Waals heterostructures based on atomically-thin superconductors","18 pages, 5 figures","Advanced Electronic Materials 7, 7, 2000987 (2021)","10.1002/aelm.202000987",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Van der Waals heterostructures (vdWHs) allow the assembly of high-crystalline
two-dimensional (2D) materials in order to explore dimensionality effects in
strongly correlated systems and the emergence of potential new physical
scenarios. In this work, it is illustrated the feasibility to integrate 2D
materials in-between 2D superconductors. Particularly, it is presented the
fabrication and electrical characterization of vertical vdWHs based on
air-unstable atomically-thin transition metal dichalcogenides formed by
NbSe2/TaS2/NbSe2 stacks, with TaS2 being the insulator 1T-TaS2 or the metal
2H-TaS2. Phase transitions as 1T-TaS2 charge density wave and NbSe2
superconductivity are detected. An enhancement of the vdWH resistance due to
Andreev reflections is observed below the superconducting transition
temperature of the NbSe2 flakes. Moreover, in the NbSe2 superconducting state,
the field and temperature dependence of the normalized conductance is analyzed
within the Dynes' model and the overall behavior is consistent with the
Bardeen-Cooper-Schrieffer theory. This vdWH approach can be extended to other
2D materials, such as 2D magnets or topological insulators, with the aim of
exploring the new emergent properties that may arise from such combinations.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:51:25 GMT""}]","2021-07-13"
"2103.00204","Amit Goyal Dr","Harneet Kaur, Shailza Pathania, Amit Goyal, C. N. Kumar, Daniela
  Milovic","Phase modulated domain walls and dark solitons for surface gravity waves",,"Physics Letters A 395 (2021) 127227","10.1016/j.physleta.2021.127227",,"nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report theoretical prediction of exact localized solutions for dynamics of
surface gravity waves, at the critical point kh=1.363, modelled by higher-order
nonlinear Schrodinger equation. The model possess domain walls (kink solitons)
and dark solitons modulated through different phase profiles. The parametric
domains are delineated for the existence of soliton solutions. The effect of
wave parameters have been discussed on the amplitude of surface gravity waves.
Our work is motivated by Tsitoura et al. [1], on experimental and analytical
observation of phase domain walls for deep water surface gravity waves modelled
by nonlinear Schrodinger equation.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:52:13 GMT""}]","2021-03-02"
"2103.00205","Evgeny Burnaev","Evgeny Burnaev","Inversion formula for infinitely divisible distributions","2 pages","Russian Mathematical Surveys (2006), 61(4):772","10.1070/RM2006v061n04ABEH004346",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this note is to prove the inversion formula, which can be used to
compute the Levi measure of an infinitely divisible distribution from its
characteristic function. Obtained formula is similar to the well-known
inversion formula [2], which is used to compute the distribution function of a
random variable from the corresponding characteristic function.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:53:52 GMT""}]","2021-03-10"
"2103.00206","Alexander Tsirlin","Nazir Khan, Danil Prishchenko, Mary H. Upton, Vladimir G. Mazurenko,
  Alexander A. Tsirlin","Toward cubic symmetry for Ir$^{4+}$: structure and magnetism of
  antifluorite K$_2$IrBr$_6$","published version: 13 pages + Supplemental Material","Phys. Rev. B 103, 125158 (2021)","10.1103/PhysRevB.103.125158",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crystal structure, electronic state of Ir$^{4+}$, and magnetic properties of
the antifluorite compound K$_2$IrBr$_6$ are studied using high-resolution
synchrotron x-ray diffraction, resonant inelastic x-ray scattering (RIXS),
thermodynamic and transport measurements, and ab initio calculations. The
crystal symmetry is reduced from cubic at room temperature to tetragonal below
170 K and eventually to monoclinic below 122 K. These changes are tracked by
the evolution of the non-cubic crystal-field splitting $\Delta$ measured by
RIXS. Non-monotonic changes in $\Delta$ are ascribed to the competing effects
of the tilt, rotation, and deformation of the IrBr$_6$ octahedra as well as
tetragonal strain on the electronic levels of Ir$^{4+}$. The N\'eel temperature
of $T_N=11.9$ K exceeds that of the isostructural K$_2$IrCl$_6$, and the
magnitude of frustration on the fcc spin lattice decreases. We argue that the
replacement of Cl by Br weakens electronic correlations and enhances magnetic
couplings.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 12:59:01 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 21:37:15 GMT""}]","2021-04-02"
"2103.00207","Lifeng Xie","Lifeng Xie, Xiaowen Cao, Jie Xu, Rui Zhang","UAV-Enabled Wireless Power Transfer: A Tutorial Overview",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unmanned aerial vehicle (UAV)-enabled wireless power transfer (WPT) has
recently emerged as a promising technique to provide sustainable energy supply
for widely distributed low-power ground devices (GDs) in large-scale wireless
networks. Compared with the energy transmitters (ETs) in conventional WPT
systems which are deployed at fixed locations, UAV-mounted aerial ETs can fly
flexibly in the three-dimensional (3D) space to charge nearby GDs more
efficiently. This paper provides a tutorial overview on UAV-enabled WPT and its
appealing applications, in particular focusing on how to exploit UAVs'
controllable mobility via their 3D trajectory design to maximize the amounts of
energy transferred to all GDs in a wireless network with fairness. First, we
consider the single-UAV-enabled WPT scenario with one UAV wirelessly charging
multiple GDs at known locations. To solve the energy maximization problem in
this case, we present a general trajectory design framework consisting of three
innovative approaches to optimize the UAV trajectory, which are multi-location
hovering, successive-hover-and-fly, and time-quantization-based optimization,
respectively. Next, we consider the multi-UAV-enabled WPT scenario where
multiple UAVs cooperatively charge many GDs in a large area. Building upon the
single-UAV trajectory design, we propose two efficient schemes to jointly
optimize multiple UAVs' trajectories, based on the principles of UAV swarming
and GD clustering, respectively. Furthermore, we consider two important
extensions of UAV-enabled WPT, namely UAV-enabled wireless powered
communication networks (WPCN) and UAV-enabled wireless powered mobile edge
computing (MEC).
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:01:15 GMT""}]","2021-03-02"
"2103.00208","Hao Chen","Hao Chen, Zipeng Qi and Zhenwei Shi","Remote Sensing Image Change Detection with Transformers","14 pages, 8 figures. Accepted article by IEEE TGRS",,"10.1109/TGRS.2021.3095166",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern change detection (CD) has achieved remarkable success by the powerful
discriminative ability of deep convolutions. However, high-resolution remote
sensing CD remains challenging due to the complexity of objects in the scene.
Objects with the same semantic concept may show distinct spectral
characteristics at different times and spatial locations. Most recent CD
pipelines using pure convolutions are still struggling to relate long-range
concepts in space-time. Non-local self-attention approaches show promising
performance via modeling dense relations among pixels, yet are computationally
inefficient. Here, we propose a bitemporal image transformer (BIT) to
efficiently and effectively model contexts within the spatial-temporal domain.
Our intuition is that the high-level concepts of the change of interest can be
represented by a few visual words, i.e., semantic tokens. To achieve this, we
express the bitemporal image into a few tokens, and use a transformer encoder
to model contexts in the compact token-based space-time. The learned
context-rich tokens are then feedback to the pixel-space for refining the
original features via a transformer decoder. We incorporate BIT in a deep
feature differencing-based CD framework. Extensive experiments on three CD
datasets demonstrate the effectiveness and efficiency of the proposed method.
Notably, our BIT-based model significantly outperforms the purely convolutional
baseline using only 3 times lower computational costs and model parameters.
Based on a naive backbone (ResNet18) without sophisticated structures (e.g.,
FPN, UNet), our model surpasses several state-of-the-art CD methods, including
better than four recent attention-based methods in terms of efficiency and
accuracy. Our code is available at https://github.com/justchenhao/BIT\_CD.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:08:46 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 14:57:03 GMT""},{""version"":""v3"",""created"":""Sun, 11 Jul 2021 08:47:27 GMT""}]","2021-07-13"
"2103.00209","Yan Liu","Yan Liu, Masanobu Taniguchi and Hernando Ombao","Statistical Inference for Local Granger Causality","64 pages, 6 figures",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Granger causality has been employed to investigate causality relations
between components of stationary multiple time series. We generalize this
concept by developing statistical inference for local Granger causality for
multivariate locally stationary processes. Our proposed local Granger causality
approach captures time-evolving causality relationships in nonstationary
processes. The proposed local Granger causality is well represented in the
frequency domain and estimated based on the parametric time-varying spectral
density matrix using the local Whittle likelihood. Under regularity conditions,
we demonstrate that the estimators converge to multivariate normal in
distribution. Additionally, the test statistic for the local Granger causality
is shown to be asymptotically distributed as a quadratic form of a multivariate
normal distribution. The finite sample performance is confirmed with several
simulation studies for multivariate time-varying autoregressive models. For
practical demonstration, the proposed local Granger causality method uncovered
new functional connectivity relationships between channels in brain signals.
Moreover, the method was able to identify structural changes in financial data.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:08:56 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 12:36:38 GMT""}]","2021-08-05"
"2103.00210","Linlin Li","Steven X. Ding, Linlin Li, Dong Zhao, Chris Louen, Tianyu Liu","Application of the unified control and detection framework to detecting
  stealthy integrity cyber-attacks on feedback control systems",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This draft addresses issues of detecting stealthy integrity cyber-attacks on
automatic control systems in the unified control and detection framework. A
general form of integrity cyber-attacks that cannot be detected using the
well-established observer-based technique is first introduced as kernel
attacks. The well-known replay, zero dynamics and covert attacks are special
forms of the kernel attacks. Existence conditions for the kernel attacks are
presented. It is demonstrated, in the unified framework of control and
detection, that all kernel attacks can be structurally detected when not only
the observer-based residual, but also the control signal based residual signals
are generated and used for the detection purpose. Based on the analytical
results, two schemes for detecting the kernel attacks are then proposed, which
allow reliable attack detection without loss of control performance. While the
first scheme is similar to the well-established moving target method and
auxiliary system aided detection scheme, the second detector is realised with
encrypted transmissions of control and monitoring signals in the feedback
control system that prevents adversary to gain system knowledge by means of
eavesdropping attacks. Both schemes are illustrated by examples of detecting
replay, zero dynamics and covert attacks and an experimental study on a
three-tank control system.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:17:57 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 01:38:26 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 23:55:46 GMT""}]","2021-06-08"
"2103.00211","Evgeniya Egorova","E. S. Egorova, O. V. Egorov, A. V. Moiseev, A. S. Saburova, K. A.
  Grishin, I. V. Chilingarian","Search for gas accretion imprints in voids: II. The galaxy Ark 18 as a
  result of a dwarf-dwarf merger","19 pages, 13 figures, 5 tables. Submitted to MNRAS after minor
  revision, comments are welcome",,"10.1093/mnras/stab1192",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low-mass low-surface brightness (LSB) disc galaxy Arakelian 18 (Ark 18)
resides in the Eridanus void and because of its isolation represents an ideal
case to study the formation and evolution mechanisms of such a galaxy type. Its
complex structure consists of an extended blue LSB disc and a bright central
elliptically-shaped part hosting a massive off-centered star-forming clump. We
present the in-depth study of Ark 18 based on observations with the SCORPIO-2
long-slit spectrograph and a scanning Fabry-Perot interferometer at the Russian
6-m telescope complemented by archival multi-wavelength images and SDSS
spectra. Ark 18 appears to be a dark matter dominated gas-rich galaxy without a
radial metallicity gradient. The observed velocity field of the ionised gas is
well described by two circularly rotating components moderately inclined with
respect to each other and a possible warp in the outer disc. We estimated the
age of young stellar population in the galaxy centre to be ~140 Myr, while the
brightest star-forming clump appears to be much younger. We conclude that the
LSB disc is likely the result of a dwarf-dwarf merger with a stellar mass ratio
of the components at least ~5:1 that occurred earlier than 300 Myr ago. The
brightest star forming clump was likely formed later by accretion of a gas
cloud.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:22:43 GMT""}]","2021-05-12"
"2103.00212","Mohammad Javad Kazemi","Mohammad Javad Kazemi and Shehu AbdusSalam","Electroweak Phase Transition in an Inert Complex Triplet Model","Accepted by Physical Review D. New references are added","Phys. Rev. D 103, 075012 (2021)","10.1103/PhysRevD.103.075012",,"hep-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of electroweak phase transition in a simple extension
of the Standard Model where the Higgs sector is extended by adding an
$SU(2)_L$-triplet with hypercharge Y=2. By making random scans over the
parameters of the model, we show that there are regions consistent with
constraints from collider experiments and the requirement for a strong
first-order electroweak phase transition which is needed for electroweak
baryogenesis. Further, we also study the power spectrum of the gravitational
waves which can be generated due to the first-order phase transitions.
Moreover, the detectability of these gravitational waves, via future
space-based detectors, is discussed.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:33:53 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 12:30:30 GMT""}]","2021-04-21"
"2103.00213","Hyunseung Kim","Hyunseung Kim, Jonggeol Na, Won Bo Lee","Generative Chemical Transformer: Neural Machine Learning of Molecular
  Geometric Structures from Chemical Language via Attention",,"J. Chem. Inf. Model. 61 (2021) 5804","10.1021/acs.jcim.1c01289",,"cs.LG physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discovering new materials better suited to specific purposes is an important
issue in improving the quality of human life. Here, a neural network that
creates molecules that meet some desired conditions based on a deep
understanding of chemical language is proposed (Generative Chemical
Transformer, GCT). The attention mechanism in GCT allows a deeper understanding
of molecular structures beyond the limitations of chemical language itself
which cause semantic discontinuity by paying attention to characters sparsely.
It is investigated that the significance of language models for inverse
molecular design problems by quantitatively evaluating the quality of the
generated molecules. GCT generates highly realistic chemical strings that
satisfy both chemical and linguistic grammar rules. Molecules parsed from
generated strings simultaneously satisfy the multiple target properties and
vary for a single condition set. These advances will contribute to improving
the quality of human life by accelerating the process of desired material
discovery.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:34:36 GMT""},{""version"":""v2"",""created"":""Fri, 3 Dec 2021 07:38:19 GMT""}]","2022-02-15"
"2103.00214","Anton Zabrodin","V. Prokofev, A. Zabrodin","Elliptic solutions to Toda lattice hierarchy and elliptic
  Ruijsenaars-Schneider model","27 pages, no figures. arXiv admin note: text overlap with
  arXiv:1907.06621, arXiv:2102.03784",,"10.1134/S0040577921080080","ITEP-TH-06/21","nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider solutions of the 2D Toda lattice hierarchy which are elliptic
functions of the zeroth time t_0=x. It is known that their poles as functions
of t_1 move as particles of the elliptic Ruijsenaars-Schneider model. The goal
of this paper is to extend this correspondence to the level of hierarchies. We
show that the Hamiltonians which govern the dynamics of poles with respect to
the m-th hierarchical times t_m and \bar t_m of the 2D Toda lattice hierarchy
are obtained from expansion of the spectral curve for the Lax matrix of the
Ruijsenaars-Schneider model at the marked points.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:35:34 GMT""}]","2021-09-15"
"2103.00215","Ismael Gonzalez Yero","Martin Knor, Riste Skrekovski, Ismael G. Yero","A note on the metric and edge metric dimensions of 2-connected graphs","12 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a given graph $G$, the metric and edge metric dimensions of $G$,
$\dim(G)$ and ${\rm edim}(G)$, are the cardinalities of the smallest possible
subsets of vertices in $V(G)$ such that they uniquely identify the vertices and
the edges of $G$, respectively, by means of distances. It is already known that
metric and edge metric dimensions are not in general comparable. Infinite
families of graphs with pendant vertices in which the edge metric dimension is
smaller than the metric dimension are already known. In this article, we
construct a 2-connected graph $G$ such that $\dim(G)=a$ and ${\rm edim}(G)=b$
for every pair of integers $a,b$, where $4\le b<a$. For this we use
subdivisions of complete graphs, whose metric dimension is in some cases
smaller than the edge metric dimension. Along the way, we present an upper
bound for the metric and edge metric dimensions of subdivision graphs under
some special conditions.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:38:57 GMT""}]","2021-03-02"
"2103.00216","Nimish Shah","Nimish Shah, Laura I. Galindez Olascoaga, Wannes Meert and Marian
  Verhelst","ProbLP: A framework for low-precision probabilistic inference",,"Proceedings of the 56th Annual Design Automation Conference (DAC)
  2019","10.1145/3316781.3317885",,"cs.AR cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Bayesian reasoning is a powerful mechanism for probabilistic inference in
smart edge-devices. During such inferences, a low-precision arithmetic
representation can enable improved energy efficiency. However, its impact on
inference accuracy is not yet understood. Furthermore, general-purpose hardware
does not natively support low-precision representation. To address this, we
propose ProbLP, a framework that automates the analysis and design of
low-precision probabilistic inference hardware. It automatically chooses an
appropriate energy-efficient representation based on worst-case error-bounds
and hardware energy-models. It generates custom hardware for the resulting
inference network exploiting parallelism, pipelining and low-precision
operation. The framework is validated on several embedded-sensing benchmarks.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:41:16 GMT""}]","2021-03-02"
"2103.00217","Ion Vasile Vancea","Adina Crisan, Cresus Godinho and Ion Vancea","Gravitoelectromagnetic knot fields","22 pages. Published in the Special Issue ""Frame-Dragging and
  Gravitomagnetism""","Universe 2021, 7, 46","10.3390/universe7030046",,"gr-qc hep-th math-ph math.MP physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  We construct a class of knot solutions of the gravitoelectromagnetic (GEM)
equations in vacuum in the linearized gravity approximation by analogy with the
Ra\~{n}ada-Hopf fields. For these solutions, the dual metric tensors of the
bi-metric geometry of the gravitational vacuum with knot perturbations are
given and the geodesic equation as a function of two complex parameters of the
GEM knots are calculated. Finally, the Landau--Lifshitz pseudo-tensor and a
scalar invariant of the GEM knots are computed.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:44:59 GMT""}]","2021-03-02"
"2103.00218","Felix Juefei-Xu","Felix Juefei-Xu and Run Wang and Yihao Huang and Qing Guo and Lei Ma
  and Yang Liu","Countering Malicious DeepFakes: Survey, Battleground, and Horizon","49 pages. To appear in the International Journal of Computer Vision
  (IJCV), 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The creation or manipulation of facial appearance through deep generative
approaches, known as DeepFake, have achieved significant progress and promoted
a wide range of benign and malicious applications, e.g., visual effect
assistance in movie and misinformation generation by faking famous persons. The
evil side of this new technique poses another popular study, i.e., DeepFake
detection aiming to identify the fake faces from the real ones. With the rapid
development of the DeepFake-related studies in the community, both sides have
formed the relationship of battleground, pushing the improvements of each other
and inspiring new directions, e.g., the evasion of DeepFake detection.
Nevertheless, the overview of such battleground and the new direction is
unclear and neglected by recent surveys due to the rapid increase of related
publications, limiting the in-depth understanding of the tendency and future
works. To fill this gap, in this paper, we provide a comprehensive overview and
detailed analysis of the research work on the topic of DeepFake generation,
DeepFake detection as well as evasion of DeepFake detection, with more than 318
research papers carefully surveyed. We present the taxonomy of various DeepFake
generation methods and the categorization of various DeepFake detection
methods, and more importantly, we showcase the battleground between the two
parties with detailed interactions between the adversaries (DeepFake
generation) and the defenders (DeepFake detection). The battleground allows
fresh perspective into the latest landscape of the DeepFake research and can
provide valuable analysis towards the research challenges and opportunities as
well as research trends and future directions. We also elaborately design
interactive diagrams (http://www.xujuefei.com/dfsurvey) to allow researchers to
explore their own interests on popular DeepFake generators or detectors.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:48:54 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 23:42:40 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 02:51:21 GMT""}]","2022-03-24"
"2103.00219","Yong Guo","Yong Guo, Yaofo Chen, Yin Zheng, Qi Chen, Peilin Zhao, Jian Chen,
  Junzhou Huang, Mingkui Tan","Pareto-Frontier-aware Neural Architecture Generation for Diverse Budgets","8 pages",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Designing feasible and effective architectures under diverse computation
budgets incurred by different applications/devices is essential for deploying
deep models in practice. Existing methods often perform an independent
architecture search for each target budget, which is very inefficient yet
unnecessary. Moreover, the repeated independent search manner would inevitably
ignore the common knowledge among different search processes and hamper the
search performance. To address these issues, we seek to train a general
architecture generator that automatically produces effective architectures for
an arbitrary budget merely via model inference. To this end, we propose a
Pareto-Frontier-aware Neural Architecture Generator (NAG) which takes an
arbitrary budget as input and produces the Pareto optimal architecture for the
target budget. We train NAG by learning the Pareto frontier (i.e., the set of
Pareto optimal architectures) over model performance and computational cost
(e.g., latency). Extensive experiments on three platforms (i.e., mobile, CPU,
and GPU) show the superiority of the proposed method over existing NAS methods.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:59:17 GMT""}]","2021-03-02"
"2103.00220","Hong-Hao Zhang","Zexi Hu, Chengfeng Cai, Yi-Lei Tang, Zhao-Huan Yu, Hong-Hao Zhang","Vector dark matter from split SU(2) gauge bosons","25 pages, 5 figures",,"10.1007/JHEP07(2021)089",,"hep-ph astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  We propose a vector dark matter model with an exotic dark SU(2) gauge group.
Two Higgs triplets are introduced to spontaneously break the symmetry. All of
the dark gauge bosons become massive, and the lightest one is a viable vector
DM candidate. Its stability is guaranteed by a remaining Z_2 symmetry. We study
the parameter space constrained by the Higgs measurement data, the dark matter
relic density, and direct and indirect detection experiments. We find numerous
parameter points satisfying all the constraints, and they could be further
tested in future experiments. Similar methodology can be used to construct
vector dark matter models from an arbitrary SO(N) gauge group.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 13:59:44 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 07:51:03 GMT""}]","2021-07-28"
"2103.00221","Mahsa Ghorbani","Mahsa Ghorbani, Anees Kazi, Mahdieh Soleymani Baghshah, Hamid R.
  Rabiee, Nassir Navab","RA-GCN: Graph Convolutional Network for Disease Prediction Problems with
  Imbalanced Data",,,"10.1016/j.media.2021.102272",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Disease prediction is a well-known classification problem in medical
applications. GCNs provide a powerful tool for analyzing the patients' features
relative to each other. This can be achieved by modeling the problem as a graph
node classification task, where each node is a patient. Due to the nature of
such medical datasets, class imbalance is a prevalent issue in the field of
disease prediction, where the distribution of classes is skewed. When the class
imbalance is present in the data, the existing graph-based classifiers tend to
be biased towards the major class(es) and neglect the samples in the minor
class(es). On the other hand, the correct diagnosis of the rare positive cases
among all the patients is vital in a healthcare system. In conventional
methods, such imbalance is tackled by assigning appropriate weights to classes
in the loss function which is still dependent on the relative values of
weights, sensitive to outliers, and in some cases biased towards the minor
class(es). In this paper, we propose a Re-weighted Adversarial Graph
Convolutional Network (RA-GCN) to prevent the graph-based classifier from
emphasizing the samples of any particular class. This is accomplished by
associating a graph-based neural network to each class, which is responsible
for weighting the class samples and changing the importance of each sample for
the classifier. Therefore, the classifier adjusts itself and determines the
boundary between classes with more attention to the important samples. The
parameters of the classifier and weighting networks are trained by an
adversarial approach. We show experiments on synthetic and three publicly
available medical datasets. RA-GCN demonstrates the superiority compared to
recent methods in identifying the patient's status on all three datasets. The
detailed analysis is provided as quantitative and qualitative experiments on
synthetic datasets.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:06:27 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 11:54:28 GMT""},{""version"":""v3"",""created"":""Sun, 7 Nov 2021 15:36:09 GMT""}]","2021-11-09"
"2103.00222","Laurence Aitchison","Ali Unlu, Laurence Aitchison","Variational Laplace for Bayesian neural networks","Accidental resubmission of new version of arXiv:2011.10443",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop variational Laplace for Bayesian neural networks (BNNs) which
exploits a local approximation of the curvature of the likelihood to estimate
the ELBO without the need for stochastic sampling of the neural-network
weights. The Variational Laplace objective is simple to evaluate, as it is (in
essence) the log-likelihood, plus weight-decay, plus a squared-gradient
regularizer. Variational Laplace gave better test performance and expected
calibration errors than maximum a-posteriori inference and standard
sampling-based variational inference, despite using the same variational
approximate posterior. Finally, we emphasise care needed in benchmarking
standard VI as there is a risk of stopping before the variance parameters have
converged. We show that early-stopping can be avoided by increasing the
learning rate for the variance parameters.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:06:29 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 14:56:18 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 07:52:35 GMT""}]","2021-07-21"
"2103.00223","Andr\'as Kov\'acs","Andr\'as Kov\'acs","Generalized Universe Hierarchies and First-Class Universe Levels",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  In type theories, universe hierarchies are commonly used to increase the
expressive power of the theory while avoiding inconsistencies arising from size
issues. There are numerous ways to specify universe hierarchies, and theories
may differ in details of cumulativity, choice of universe levels, specification
of type formers and eliminators, and available internal operations on levels.
In the current work, we aim to provide a framework which covers a large part of
the design space. First, we develop syntax and semantics for cumulative
universe hierarchies, where levels may come from any set equipped with a
transitive well-founded ordering. In the semantics, we show that
induction-recursion can be used to model transfinite hierarchies, and also
support lifting operations on type codes which strictly preserve type formers.
Then, we consider a setup where universe levels are first-class types and
subject to arbitrary internal reasoning. This generalizes the bounded
polymorphism features of Coq and at the same time the internal level
computations in Agda.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:07:24 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 13:49:13 GMT""},{""version"":""v3"",""created"":""Sat, 5 Jun 2021 10:46:57 GMT""},{""version"":""v4"",""created"":""Fri, 29 Oct 2021 19:38:06 GMT""}]","2021-11-02"
"2103.00224","Marcos Dajczer","M. Dajczer, C.-R. Onti and Th. Vlachos","A class of Einstein submanifolds of Euclidean space",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give local and global parametric classifications of a class
of Einstein submanifolds of Euclidean space. The highlight is for submanifolds
of codimension two since in this case our assumptions are only of intrinsic
nature.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:10:43 GMT""},{""version"":""v2"",""created"":""Sun, 26 Sep 2021 08:05:11 GMT""}]","2021-09-28"
"2103.00225","Richard D. Gill","Richard D. Gill","Comment on ""Bell's Theorem Versus Local Realism in a Quaternionic Model
  of Physical Space""","6 pages. This is version 4 - the paper is yet again revised in
  response to a third round of refereeing by an unusually large number of
  referees many of whom disagree with one another","IEEE Access, vol. 9, pp. 154933-154937, 2021,
  https://ieeexplore.ieee.org/document/9622238","10.1109/ACCESS.2021.3127572",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I point out critical errors in the paper ""Bell's Theorem Versus Local Realism
in a Quaternionic Model of Physical Space"" by J. Christian, published in IEEE
Access. Christian's paper in fact contains several conflicting models. None of
them form counterexamples to Bell's theorem. Most of Christian's paper is
devoted to a model based on the detection loophole due to Pearle (1970).
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:12:07 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 07:28:04 GMT""},{""version"":""v3"",""created"":""Tue, 31 Aug 2021 17:59:30 GMT""},{""version"":""v4"",""created"":""Sat, 23 Oct 2021 12:55:25 GMT""},{""version"":""v5"",""created"":""Fri, 27 May 2022 08:49:05 GMT""}]","2022-05-30"
"2103.00226","Mahdi Alavi","Tohid Soleymani Aghdam, Seyed Mohammad Mahdi Alavi, Mehrdad Saif","Structural Identifiability of Impedance Spectroscopy Fractional-Order
  Equivalent Circuit Models With Two Constant Phase Elements",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Structural identifiability analysis of fractional-order equivalent circuit
models (FO-ECMs), obtained through electrochemical impedance spectroscopy (EIS)
is still a challenging problem. No peer-reviewed analytical or numerical proof
does exist showing that whether impedance spectroscopy FO-ECMs are structurally
identifiable or not, regardless of practical issues such as measurement noises
and the selection of excitation signals. By using the coefficient mapping
technique, this paper proposes novel computationally-efficient algebraic
equations for the numerical structural identifiability analysis of a widely
used FO-ECM with Gr\""{u}nwald-Letnikov fractional derivative approximation and
two constant phase elements (CPEs) including the Warburg term. The proposed
numerical structural identifiability analysis method is applied to an example
from batteries, and the results are discussed. Matlab codes are available on
github.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:23:52 GMT""}]","2021-03-02"
"2103.00227","Emadeldin Abbas Mazied Abdrabou","EmadElDin A Mazied, Lingjia Liu, Scott F. Midkiff","Towards Intelligent RAN Slicing for B5G: Opportunities and Challenges","9 pages, 5 figures, 1 table, 15 references, Magazine article",,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To meet the diverse demands for wireless communication, fifth-generation (5G)
networks and beyond (B5G) embrace the concept of network slicing by forging
virtual instances (slices) of its physical infrastructure. While network
slicing constitutes dynamic allocation of core network and radio access network
(RAN) resources, this article emphasizes RAN slicing (RAN-S) design. Forming
on-demand RAN-S that can be flexibly (re)-configured while ensuring slice
isolation is challenging. A variety of machine learning (ML) techniques have
been recently introduced for traffic forecasting and classification, resource
usage prediction, admission control, scheduling, and dynamic resource
allocation in RAN-S. Albeit these approaches grant opportunities towards
intelligent RAN-S design, they raise critical challenges that need to be
examined. This article underlines the opportunities and the challenges of
incorporating ML into RAN-S by reviewing the cutting-edge ML-based techniques
for RAN-S. It also draws few directions for future research towards intelligent
RAN-S (iRAN-S).
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:24:09 GMT""}]","2021-03-02"
"2103.00228","Sergey Goryainov V.","Sergey Goryainov, Leonid V. Shalaginov","Deza graphs: a survey and new results",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we survey existing results on Deza graphs and give some new
results. We present an introduction to Deza graphs for the reader who is
unfamiliar with the subject, and then give an overview of some developments in
the area of Deza graphs since the initial paper by five authors [M. Erickson,
S. Fernando, W. H. Haemers, D. Hardy, J. Hemmeter, Deza graphs: \emph{A
generalization of strongly regular graphs}, J. Comb. Designs. 7 (1999),
395--405.] was written. We then investigate 3-class cyclotomic schemes and give
necessary and sufficient conditions to get a Deza graph as a graph given by one
relation or the union of two relations. Finally, we prove that a strictly Deza
circulant on $2p$ vertices, where $p$ is prime, is isomorphic to the
lexicographical product of the Paley graph on $p$ vertices with an edge.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:26:00 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 11:49:53 GMT""}]","2021-06-02"
"2103.00229","Xing Tian","Chris Xing Tian, Haoliang Li, Xiaofei Xie, Yang Liu, Shiqi Wang","Neuron Coverage-Guided Domain Generalization","ACCEPTED TO TPAMI",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the domain generalization task where domain knowledge
is unavailable, and even worse, only samples from a single domain can be
utilized during training. Our motivation originates from the recent progresses
in deep neural network (DNN) testing, which has shown that maximizing neuron
coverage of DNN can help to explore possible defects of DNN (i.e.,
misclassification). More specifically, by treating the DNN as a program and
each neuron as a functional point of the code, during the network training we
aim to improve the generalization capability by maximizing the neuron coverage
of DNN with the gradient similarity regularization between the original and
augmented samples. As such, the decision behavior of the DNN is optimized,
avoiding the arbitrary neurons that are deleterious for the unseen samples, and
leading to the trained DNN that can be better generalized to
out-of-distribution samples. Extensive studies on various domain generalization
tasks based on both single and multiple domain(s) setting demonstrate the
effectiveness of our proposed approach compared with state-of-the-art baseline
methods. We also analyze our method by conducting visualization based on
network dissection. The results further provide useful evidence on the
rationality and effectiveness of our approach.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:26:53 GMT""},{""version"":""v2"",""created"":""Sat, 5 Mar 2022 05:53:31 GMT""}]","2022-03-08"
"2103.00230","Ronan Laker","R. Laker, T. S. Horbury, S. D. Bale, L. Matteini, T. Woolley, L. D.
  Woodham, J. E. Stawarz, E. E. Davies, J. P. Eastwood, M. J. Owens, H.
  O'Brien, V. Evans, V. Angelini, I. Richter, D. Heyner, C. J. Owen, P. Louarn,
  A. Federov","Multi-spacecraft Study of the Solar Wind at Solar Minimum: Dependence on
  Latitude and Transient Outflows","Accepted version","A&A 652, A105 (2021)","10.1051/0004-6361/202140679",,"physics.space-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent launches of Parker Solar Probe (PSP), Solar Orbiter (SO) and
BepiColombo, along with several older spacecraft, have provided the opportunity
to study the solar wind at multiple latitudes and distances from the Sun
simultaneously. We take advantage of this unique spacecraft constellation,
along with low solar activity across two solar rotations between May and July
2020, to investigate how the solar wind structure, including the Heliospheric
Current Sheet (HCS), varies with latitude. We visualise the sector structure of
the inner heliosphere by ballistically mapping the polarity and solar wind
speed from several spacecraft onto the Sun's source surface. We then assess the
HCS morphology and orientation with the in situ data and compare with a
predicted HCS shape. We resolve ripples in the HCS on scales of a few degrees
in longitude and latitude, finding that the local orientation of sector
boundaries were broadly consistent with the shape of the HCS but were steepened
with respect to a modelled HCS at the Sun. We investigate how several CIRs
varied with latitude, finding evidence for the compression region affecting
slow solar wind outside the latitude extent of the faster stream. We also
identified several transient structures associated with HCS crossings, and
speculate that one such transient may have disrupted the local HCS orientation
up to five days after its passage. We have shown that the solar wind structure
varies significantly with latitude, with this constellation providing context
for solar wind measurements that would not be possible with a single
spacecraft. These measurements provide an accurate representation of the solar
wind within $\pm 10^{\circ}$ latitude, which could be used as a more rigorous
constraint on solar wind models and space weather predictions. In the future,
this range of latitudes will increase as SO's orbit becomes more inclined.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:29:15 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 15:15:42 GMT""}]","2021-08-25"
"2103.00231","Andry Alamsyah","Andry Alamsyah, Fatma Saviera","A Comparison of Indonesia E-Commerce Sentiment Analysis for Marketing
  Intelligence Effort",,"The 8th International Conference on Sustainable Collaboration in
  Business, Technology, Information and Innovation, 2017",,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The rapid growth of the e-commerce market in Indonesia, making various
e-commerce companies appear and there has been high competition among them.
Marketing intelligence is an important activity to measure competitive
position. One element of marketing intelligence is to assess customer
satisfaction. Many Indonesian customers express their sense of satisfaction or
dissatisfaction towards the company through social media. Hence, using social
media data provides a new practical way to measure marketing intelligence
effort. This research performs sentiment analysis using the naive bayes
classifier classification method with TF-IDF weighting. We compare the
sentiments towards of top-3 e-commerce sites visited companies, are Bukalapak,
Tokopedia, and Elevenia. We use Twitter data for sentiment analysis because
it's faster, cheaper, and easier from both the customer and the researcher
side. The purpose of this research is to find out how to process the huge
customer sentiment Twitter to become useful information for the e-commerce
company, and which of those top-3 e-commerce companies has the highest level of
customer satisfaction. The experiment results show the method can be used to
classify customer sentiments in social media Twitter automatically and Elevenia
is the highest e-commerce with customer satisfaction.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:32:11 GMT""}]","2021-03-02"
"2103.00232","V\'it Novotn\'y","Eniafe Festus Ayetiran (1), Petr Sojka (1), V\'it Novotn\'y (1) ((1)
  Faculty of Informatics Masaryk University)","EDS-MEMBED: Multi-sense embeddings based on enhanced distributional
  semantic structures via a graph walk over word senses",,"Knowledge-Based Systems. 219 (2021) 106902","10.1016/j.knosys.2021.106902",,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several language applications often require word semantics as a core part of
their processing pipeline, either as precise meaning inference or semantic
similarity. Multi-sense embeddings (M-SE) can be exploited for this important
requirement. M-SE seeks to represent each word by their distinct senses in
order to resolve the conflation of meanings of words as used in different
contexts. Previous works usually approach this task by training a model on a
large corpus and often ignore the effect and usefulness of the semantic
relations offered by lexical resources. However, even with large training data,
coverage of all possible word senses is still an issue. In addition, a
considerable percentage of contextual semantic knowledge are never learned
because a huge amount of possible distributional semantic structures are never
explored. In this paper, we leverage the rich semantic structures in WordNet
using a graph-theoretic walk technique over word senses to enhance the quality
of multi-sense embeddings. This algorithm composes enriched texts from the
original texts. Furthermore, we derive new distributional semantic similarity
measures for M-SE from prior ones. We adapt these measures to word sense
disambiguation (WSD) aspect of our experiment. We report evaluation results on
11 benchmark datasets involving WSD and Word Similarity tasks and show that our
method for enhancing distributional semantic structures improves embeddings
quality on the baselines. Despite the small training data, it achieves
state-of-the-art performance on some of the datasets.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:36:55 GMT""}]","2021-03-04"
"2103.00233","Junru Luo","JunRu Luo, Hong Qiao and Bo Zhang","Learning with Smooth Hinge Losses",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to the non-smoothness of the Hinge loss in SVM, it is difficult to obtain
a faster convergence rate with modern optimization algorithms. In this paper,
we introduce two smooth Hinge losses $\psi_G(\alpha;\sigma)$ and
$\psi_M(\alpha;\sigma)$ which are infinitely differentiable and converge to the
Hinge loss uniformly in $\alpha$ as $\sigma$ tends to $0$. By replacing the
Hinge loss with these two smooth Hinge losses, we obtain two smooth support
vector machines(SSVMs), respectively. Solving the SSVMs with the Trust Region
Newton method (TRON) leads to two quadratically convergent algorithms.
Experiments in text classification tasks show that the proposed SSVMs are
effective in real-world applications. We also introduce a general smooth convex
loss function to unify several commonly-used convex loss functions in machine
learning. The general framework provides smooth approximation functions to
non-smooth convex loss functions, which can be used to obtain smooth models
that can be solved with faster convergent optimization algorithms.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:50:02 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 06:49:06 GMT""}]","2021-03-16"
"2103.00234","Shouguang Wang","Dan You, Shouguang Wang, Carla Seatzu","Generalized Current-State Opacity With Dynamically Changing Secrets",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Opacity, an information-flow property related to the privacy and security of
a system, has been extensively studied in the context of discrete event
systems. Although various notions of opacity have been proposed, in all cases
the considered secret was constant. This work focuses on current-state opacity,
considering a scenario where the secret changes dynamically with the system
evolution. In other words, we propose the new notion of generalized
current-state opacity (GCSO), which is with respect to a dynamic-secret model
rather than a constant secret. Moreover, we provide a method to verify GCSO
based on the construction of the GCSO-verifier. Finally, a practical example is
given to illustrate the proposed notion and the method for its verification.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:53:24 GMT""}]","2021-03-02"
"2103.00235","Mete \c{S}eref Ahunbay","Mete \c{S}eref Ahunbay and Adrian Vetta","Improved Two Sample Revenue Guarantees via Mixed-Integer Linear
  Programming","24 pages, 6 figures",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the performance of the Empirical Revenue Maximizing (ERM) mechanism
in a single-item, single-seller, single-buyer setting. We assume the buyer's
valuation is drawn from a regular distribution $F$ and that the seller has
access to {\em two} independently drawn samples from $F$. By solving a family
of mixed-integer linear programs (MILPs), the ERM mechanism is proven to
guarantee at least $.5914$ times the optimal revenue in expectation. Using
solutions to these MILPs, we also show that the worst-case efficiency of the
ERM mechanism is at most $.61035$ times the optimal revenue. These guarantees
improve upon the best known lower and upper bounds of $.558$ and $.642$,
respectively, of [Daskalakis & Zampetakis, '20].
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:55:25 GMT""}]","2021-03-02"
"2103.00236","Dayan Guan","Dayan Guan, Jiaxing Huang, Aoran Xiao, Shijian Lu, Yanpeng Cao","Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection","Accepted in the IEEE Transactions on Multimedia",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Unsupervised domain adaptive object detection aims to adapt detectors from a
labelled source domain to an unlabelled target domain. Most existing works take
a two-stage strategy that first generates region proposals and then detects
objects of interest, where adversarial learning is widely adopted to mitigate
the inter-domain discrepancy in both stages. However, adversarial learning may
impair the alignment of well-aligned samples as it merely aligns the global
distributions across domains. To address this issue, we design an
uncertainty-aware domain adaptation network (UaDAN) that introduces conditional
adversarial learning to align well-aligned and poorly-aligned samples
separately in different manners. Specifically, we design an uncertainty metric
that assesses the alignment of each sample and adjusts the strength of
adversarial learning for well-aligned and poorly-aligned samples adaptively. In
addition, we exploit the uncertainty metric to achieve curriculum learning that
first performs easier image-level alignment and then more difficult
instance-level alignment progressively. Extensive experiments over four
challenging domain adaptive object detection datasets show that UaDAN achieves
superior performance as compared with state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:04:07 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 13:14:13 GMT""}]","2021-05-20"
"2103.00237","Arata Yamamoto","Arata Yamamoto","Overview of external electromagnetism and rotation in lattice QCD","EPJA Topical Issue ""The QCD Phase Diagram in Strong Magnetic Fields""","Eur. Phys. J. A 57, 211 (2021)","10.1140/epja/s10050-021-00530-8",,"hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is an introductory review of lattice QCD with external fields. The study
of external magnetic fields is one of the greatest achievements in modern
lattice QCD. Large-scale simulations and detailed analyses have revealed
intriguing properties of QCD in the magnetic fields. The study of external
electric fields is more challenging because of a technical difficulty. We
overview the successes and challenges of the lattice simulations with the
electromagnetic fields. We also introduce a newly developing field, the lattice
simulation of rotating QCD matters.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:06:37 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 19:53:03 GMT""}]","2021-06-30"
"2103.00238","Artyom Grigoryan","Artyom M. Grigoryan and Sos S. Agaian","Color-Coded Symbology and New Computer Vision Tool to Predict the
  Historical Color Pallets of the Renaissance Oil Artworks","16 pages, 12 figures, 12 tables",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we discuss possible color palletes, prediction and analysis of
originality of the colors that Artists used on the Renaissance oil paintings.
This framework goal is to help to use the color symbology and image enhancement
tools, to predict the historical color palletes of the Renaissance oil
artworks. This work is only the start of a development to explore the
possibilities of prediction of color palletes of the Renaissance oil artworks.
We believe that framework might be very useful in the prediction of color
palletes of the Renaissance oil artworks and other artworks. The images in
number 105 have been taken from the paintings of three well-known artists,
Rafael, Leonardo Da Vinci, and Rembrandt that are available in the Olga's
Gallery. Images are processed in the frequency domain to enhance a quality of
images and ratios of primary colors are calculated and analyzed by using new
measurements of color-ratios.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:16:35 GMT""}]","2021-03-02"
"2103.00239","Floor Verhoeven","Floor Verhoeven, Amir Vaxman, Tim Hoffmann, Olga Sorkine-Hornung","Dev2PQ: Planar Quadrilateral Strip Remeshing of Developable Surfaces",,,,,"cs.GR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We introduce an algorithm to remesh triangle meshes representing developable
surfaces to planar quad dominant meshes. The output of our algorithm consists
of planar quadrilateral (PQ) strips that are aligned to principal curvature
directions and closely approximate the curved parts of the input developable,
and planar polygons representing the flat parts of the input. Developable
PQ-strip meshes are useful in many areas of shape modeling, thanks to the
simplicity of fabrication from flat sheet material. Unfortunately, they are
difficult to model due to their restrictive combinatorics and locking issues.
Other representations of developable surfaces, such as arbitrary triangle or
quad meshes, are more suitable for interactive freeform modeling, but generally
have non-planar faces or are not aligned to principal curvatures. Our method
leverages the modeling flexibility of non-ruling based representations of
developable surfaces, while still obtaining developable, curvature aligned
PQ-strip meshes. Our algorithm optimizes for a scalar function on the input
mesh, such that its level sets are extrinsically straight and align well to the
locally estimated ruling directions. The condition that guarantees straight
level sets is nonlinear of high order and numerically difficult to enforce in a
straightforward manner. We devise an alternating optimization method that makes
our problem tractable and practical to compute. Our method works automatically
on any developable input, including multiple patches and curved folds, without
explicit domain decomposition. We demonstrate the effectiveness of our approach
on a variety of developable surfaces and show how our remeshing can be used
alongside handle based interactive freeform modeling of developable shapes.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:21:52 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 15:15:12 GMT""}]","2021-06-28"
"2103.00240","Jean Cortissoz","Jean Cortissoz and C\'esar Reyes","On the one dimensional Logarithmic diffusion equation with nonlinear
  Robin boundary conditions",,,,,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we investigate the one dimensional (1D) logarithmic diffusion
equation with nonlinear Robin boundary conditions, namely, \[ \left\{
\begin{array}{l} \partial_t u=\partial_{xx} \log u\quad \mbox{in}\quad
\left[-l,l\right]\times \left(0, \infty\right)\\ \displaystyle \partial_x
u\left(\pm l, t\right)=\pm 2\gamma u^{p}\left(\pm l, t\right), \end{array}
\right. \] where $\gamma$ is a constant. Let $u_0>0$ be a smooth function
defined on $\left[-l,l\right]$, and which satisfies the compatibility condition
$$\partial_x \log u_0\left(\pm l\right)= \pm 2\gamma u_0^{p-1}\left(\pm
l\right).$$ We show that for $\gamma > 0$, $p\leq \frac{3}{2}$ solutions to the
logarithmic diffusion equation above with initial data $u_0$ are global and
blow-up in infinite time, and for $p>2$ there is finite time blow-up. Also, we
show that in the case of $\gamma<0$, $p\geq \frac{3}{2}$, solutions to the
logarithmic diffusion equation with initial data $u_0$ are global and blow-down
in infinite time, but if $p\leq 1$ there is finite time blow-down. For some of
the cases mentioned above, and some particular families of examples, we provide
blow-up and blow-down rates. Our approach is partly based on studying the Ricci
flow on a cylinder endowed with a $\mathbb{S}^1$-symmetric metric. Then, we
bring our ideas full circle by proving a new long time existence result for the
Ricci flow on a cylinder without any symmetry assumption. Finally, we show a
blow-down result for the logarithmic diffusion equation on a disc.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:24:00 GMT""}]","2021-03-02"
"2103.00241","Cat Le","Cat P. Le, Mohammadreza Soltani, Robert Ravier, Vahid Tarokh","Improved Automated Machine Learning from Transfer Learning",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a neural architecture search framework based on a
similarity measure between some baseline tasks and a target task. We first
define the notion of the task similarity based on the log-determinant of the
Fisher Information matrix. Next, we compute the task similarity from each of
the baseline tasks to the target task. By utilizing the relation between a
target and a set of learned baseline tasks, the search space of architectures
for the target task can be significantly reduced, making the discovery of the
best candidates in the set of possible architectures tractable and efficient,
in terms of GPU days. This method eliminates the requirement for training the
networks from scratch for a given target task as well as introducing the bias
in the initialization of the search space from the human domain.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:26:14 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 14:53:53 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 22:05:22 GMT""},{""version"":""v4"",""created"":""Wed, 11 Aug 2021 23:09:01 GMT""},{""version"":""v5"",""created"":""Thu, 7 Oct 2021 00:17:46 GMT""},{""version"":""v6"",""created"":""Sat, 29 Jan 2022 16:06:34 GMT""}]","2022-02-01"
"2103.00242","Momchil Hardalov","Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein","A Survey on Stance Detection for Mis- and Disinformation Identification","Accepted to NAACL-HLT 2022 (Findings)",,,,"cs.CL cs.SI","http://creativecommons.org/licenses/by/4.0/","  Understanding attitudes expressed in texts, also known as stance detection,
plays an important role in systems for detecting false information online, be
it misinformation (unintentionally false) or disinformation (intentionally
false information). Stance detection has been framed in different ways,
including (a) as a component of fact-checking, rumour detection, and detecting
previously fact-checked claims, or (b) as a task in its own right. While there
have been prior efforts to contrast stance detection with other related tasks
such as argumentation mining and sentiment analysis, there is no existing
survey on examining the relationship between stance detection and mis- and
disinformation detection. Here, we aim to bridge this gap by reviewing and
analysing existing work in this area, with mis- and disinformation in focus,
and discussing lessons learnt and future challenges.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:27:22 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 13:19:41 GMT""},{""version"":""v3"",""created"":""Sun, 8 May 2022 06:03:58 GMT""}]","2022-05-10"
"2103.00243","Boyan Gao","Boyan Gao, Henry Gouk, Timothy M. Hospedales","Searching for Robustness: Loss Learning for Noisy Classification Tasks",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a ""learning to learn"" approach for automatically constructing
white-box classification loss functions that are robust to label noise in the
training data. We parameterize a flexible family of loss functions using Taylor
polynomials, and apply evolutionary strategies to search for noise-robust
losses in this space. To learn re-usable loss functions that can apply to new
tasks, our fitness function scores their performance in aggregate across a
range of training dataset and architecture combinations. The resulting
white-box loss provides a simple and fast ""plug-and-play"" module that enables
effective noise-robust learning in diverse downstream tasks, without requiring
a special training procedure or network architecture. The efficacy of our
method is demonstrated on a variety of datasets with both synthetic and real
label noise, where we compare favourably to previous work.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:27:22 GMT""}]","2021-03-02"
"2103.00244","Evan Bray","Evan Bray, David N. Burrows, Sangwook Park, Aravind P. Ravi","High-cadence Dispersed Spectral Analysis of Supernova Remnant 1987A",,"The Astrophysical Journal, vol. 899, no. 1, 2020","10.3847/1538-4357/ab9c9e",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present an analysis of the dispersed spectral data from 11 epochs (March
2011 to September 2018) of supernova remnant (SNR) 1987A observations performed
with Chandra. These observations were performed with the High Energy
Transmission Grating (HETG) as part of our ongoing Chandra monitoring campaign
of SNR 1987A, whose 1st-order dispersed spectrum provides a significantly
greater energy resolution than the previously-published 0th-order spectrum. Our
data sets with moderate exposure times of ~50-70ks per epoch cover the time
period between deep Chandra HETG observations (with individual exposures
>200ks) taken in March 2011 and March 2018. These data have a much higher
cadence than the widely-spaced deep high-resolution spectra, at the expense of
total exposure time. While statistical uncertainties are large due to low
photon count statistics in the observed 1st-order spectra, we find that
spectral model parameters are generally in line with the shock wave propagating
into the medium beyond the dense inner ring, as suggested by Frank et al. 2016.
As the reverse shock begins ionizing the heavier elements of the supernova
ejecta interior to the equatorial ring, spectral fit parameters are expected to
change as the chemical makeup and physical properties of the shocked gas
evolve. Based on our broadband spectral model fits, we find that abundance
values appear to be constant in this time period. While our results are
somewhat limited due to photon statistics, we demonstrate the utility of the
dispersed HETG spectral analysis that can be performed with our regular Chandra
monitoring observations of SNR 1987A.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:30:47 GMT""}]","2021-03-02"
"2103.00245","Cleophas Kweyu PhD","Cleophas Kweyu, Lihong Feng, Matthias Stein and Peter Benner","Reduced basis method for the nonlinear Poisson-Boltzmann equation
  regularized by the range-separated canonical tensor format",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Poisson-Boltzmann equation (PBE) is a fundamental implicit solvent
continuum model for calculating the electrostatic potential of large ionic
solvated biomolecules. However, its numerical solution encounters severe
challenges arising from its strong singularity and nonlinearity. In [1,2], the
effect of strong singularities was eliminated by applying the range-separated
(RS) canonical tensor format [3,4] to construct a solution decomposition scheme
for the PBE. The RS tensor format allows to derive a smooth approximation to
the Dirac delta distribution in order to obtain a regularized PBE (RPBE) model.
However, solving the RPBE is still computationally demanding due to its high
dimension $\mathcal{N}$, where $\mathcal{N}$ is always in the millions. In this
study, we propose to apply the reduced basis method (RBM) and the (discrete)
empirical interpolation method ((D)EIM) to the RPBE in order to construct a
reduced order model (ROM) of low dimension $N \ll \mathcal{N}$, whose solution
accurately approximates the nonlinear RPBE. The long-range potential can be
obtained by lifting the ROM solution back to the $\mathcal{N}$-space while the
short-range potential is directly precomputed analytically, thanks to the RS
tensor format. The sum of both provides the total electrostatic potential. The
main computational benefit is the avoidance of computing the numerical
approximation of the singular electrostatic potential. We demonstrate in the
numerical experiments, the accuracy and efficacy of the reduced basis (RB)
approximation to the nonlinear RPBE (NRPBE) solution and the corresponding
computational savings over the classical nonlinear PBE (NPBE) as well as over
the RBM being applied to the classical NPBE.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:32:43 GMT""}]","2021-03-02"
"2103.00246","Matteo Cervetti","Matteo Cervetti","A generating tree with a single label for permutations avoiding the
  vincular pattern 1-32-4","14 pages, 6 figures",,,,"math.CO","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper we continue the study of permutations avoiding the vincular
pattern $1-32-4$ by constructing a generating tree with a single label for
these permutations. This construction finally provides a clearer explanation of
why a certain recursive formula found by Callan actually counts these
permutations, insofar as this formula was originally obtained only as a
consequence of a very intricated bijection with a certain class of ordered
rooted trees. This responds to a theoretical issue already raised by Duchi,
Guerrini and Rinaldi. As a byproduct, we also obtain an algorithm to generate
all these permutations and we refine their enumeration according to a simple
statistic, which is the number of right-to-left maxima to the right of 1.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:35:39 GMT""}]","2021-03-02"
"2103.00247","Silvia Noschese","Silvia Noschese and Lothar Reichel","Estimating and increasing the structural robustness of a network","18 pages, 5 figures",,,"Roma01.Math.NA","math.NA cs.NA cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The capability of a network to cope with threats and survive attacks is
referred to as its robustness. This paper discusses one kind of robustness,
commonly denoted structural robustness, which increases when the spectral
radius of the adjacency matrix associated with the network decreases. We
discuss computational techniques for identifying edges, whose removal may
significantly reduce the spectral radius. Nonsymmetric adjacency matrices are
studied with the aid of their pseudospectra. In particular, we consider
nonsymmetric adjacency matrices that arise when people seek to avoid being
infected by Covid-19 by wearing facial masks of different qualities.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:37:33 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 08:18:34 GMT""}]","2021-10-06"
"2103.00248","Anisa Bajkova","V. V. Bobylev, A. T. Bajkova, A. S. Rastorguev, and M. V. Zabolotskikh","Analysis of galaxy kinematics based on Cepheids from the Gaia DR2
  Catalogue","17 pages, 12 figures, 2 tables","MNRAS, 502, 4377-4391, 2021","10.1093/mnras/stab074",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To construct the rotation curve of the Galaxy, classical Cepheids with proper
motions, parallaxes and line-of-sight velocities from the Gaia DR2 Catalog are
used in large part. The working sample formed from literature data contains
about 800 Cepheids with estimates of their age. We determined that the linear
rotation velocity of the Galaxy at a solar distance is $V_0=240\pm3$~km
s$^{-1}$. In this case, the distance from the Sun to the axis of rotation of
the Galaxy is found to be $R_0=8.27\pm0.10$~kpc. A spectral analysis of radial
and residual tangential velocities of Cepheids younger than 120 Myr showed
close estimates of the parameters of the spiral density wave obtained from data
both at present time and in the past. So, the value of the wavelength
$\lambda_{R,\theta}$ is in the range of [2.4--3.0] kpc, the pitch angle
$i_{R,\theta}$ is in the range of [$-13^\circ$,$-10^\circ$] for a four-arm
pattern model, the amplitudes of the radial and tangential perturbations are
$f_R\sim12$~km s$^{-1}$ and $f_\theta\sim9$~km s$^{-1}$, respectively.
Velocities of Cepheids older than 120 Myr are currently giving a wavelength
$\lambda_{R,\theta}\sim5$~kpc. This value differs significantly from one that
we obtained from the samples of young Cepheids. An analysis of positions and
velocities of old Cepheids, calculated by integrating their orbits backward in
time, made it possible to determine significantly more reliable values of the
parameters of the spiral density wave: wavelength $\lambda_{R,\theta}=2.7$~kpc,
amplitudes of radial and tangential perturbations are $f_R=7.9$~km s$^{-1}$ and
$f_\theta=5$~km s$^{-1}$, respectively.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:37:44 GMT""}]","2021-03-02"
"2103.00249","Andrew Bruce J","Andrew James Bruce and Janusz Grabowski","Symplectic $\mathbb{Z}_2^n$-manifolds","19 pages, minor typos corrected and clarifying comments added. The
  exposition has been improved. Comments welcomed","Journal of Geometric Mechanics, 2021","10.3934/jgm.2021020",,"math-ph math.DG math.MP math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Roughly speaking, $\mathbb{Z}_2^n$-manifolds are `manifolds' equipped with
$\mathbb{Z}_2^n$-graded commutative coordinates with the sign rule being
determined by the scalar product of their $\mathbb{Z}_2^n$-degrees. We examine
the notion of a symplectic $\mathbb{Z}_2^n$-manifold, i.e., a
$\mathbb{Z}_2^n$-manifold equipped with a symplectic two-form that may carry
non-zero $\mathbb{Z}_2^n$-degree. We show that the basic notions and results of
symplectic geometry generalise to the `higher graded' setting, including a
generalisation of Darboux's theorem.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:39:50 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 14:09:24 GMT""}]","2021-09-01"
"2103.00250","Valentina Poggioni","A.E. Baia, G. Di Bari, V. Poggioni","Effective Universal Unrestricted Adversarial Attacks using a MOE
  Approach",,,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have shown that Deep Leaning models are susceptible to
adversarial examples, which are data, in general images, intentionally modified
to fool a machine learning classifier. In this paper, we present a
multi-objective nested evolutionary algorithm to generate universal
unrestricted adversarial examples in a black-box scenario. The unrestricted
attacks are performed through the application of well-known image filters that
are available in several image processing libraries, modern cameras, and mobile
applications. The multi-objective optimization takes into account not only the
attack success rate but also the detection rate. Experimental results showed
that this approach is able to create a sequence of filters capable of
generating very effective and undetectable attacks.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:43:06 GMT""}]","2021-03-02"
"2103.00251","Yuli Huang Dr","Rebekah Chua, Jun Zhou, Xiaojiang Yu, Wei Yu, Jian Gou, Rui Zhu, Lei
  Zhang, Mark B. H. Breese, Wei Chen, Kian Ping Loh, Yuan Ping Feng, Ming Yang,
  Yu Li Huang, Andrew T. S. Wee","Room temperature ferromagnetism of monolayer chromium telluride with
  perpendicular magnetic anisotropy",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The realization of long-range magnetic ordering in two-dimensional (2D)
systems can potentially revolutionize next-generation information technology.
Here, we report the successful fabrication of crystalline Cr3Te4 monolayers
with room temperature ferromagnetism. Using molecular beam epitaxy, the growth
of 2D Cr3Te4 films with monolayer thickness is demonstrated at low substrate
temperatures (~100C), compatible with Si CMOS technology. X-ray magnetic
circular dichroism measurements reveal a Curie temperature (Tc) of ~344 K for
the Cr3Te4 monolayer with an out-of-plane magnetic easy axis, which decreases
to ~240 K for the thicker film (~ 7 nm) with an in-plane easy axis. The
enhancement of ferromagnetic coupling and the magnetic anisotropy transition is
ascribed to interfacial effects, in particular the orbital overlap at the
monolayer Cr3Te4/graphite interface, supported by density-functional theory
calculations. This work sheds light on the low-temperature scalable growth of
2D nonlayered materials with room temperature ferromagnetism for new magnetic
and spintronic devices.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:43:39 GMT""}]","2021-03-02"
"2103.00252","Harsh Agarwal","Harsh Agarwal, Navyata Sanghvi, Vivek Roy, Kris Kitani","DeepBLE: Generalizing RSSI-based Localization Across Different Devices",,,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Accurate smartphone localization (< 1-meter error) for indoor navigation
using only RSSI received from a set of BLE beacons remains a challenging
problem, due to the inherent noise of RSSI measurements. To overcome the large
variance in RSSI measurements, we propose a data-driven approach that uses a
deep recurrent network, DeepBLE, to localize the smartphone using RSSI measured
from multiple beacons in an environment. In particular, we focus on the ability
of our approach to generalize across many smartphone brands (e.g., Apple,
Samsung) and models (e.g., iPhone 8, S10). Towards this end, we collect a
large-scale dataset of 15 hours of smartphone data, which consists of over
50,000 BLE beacon RSSI measurements collected from 47 beacons in a single
building using 15 different popular smartphone models, along with precise 2D
location annotations. Our experiments show that there is a very high
variability of RSSI measurements across smartphone models (especially across
brand), making it very difficult to apply supervised learning using only a
subset of smartphone models. To address this challenge, we propose a novel
statistic similarity loss (SSL) which enables our model to generalize to unseen
phones using a semi-supervised learning approach. For known phones, the iPhone
XR achieves the best mean distance error of 0.84 meters. For unknown phones,
the Huawei Mate20 Pro shows the greatest improvement, cutting error by over
38\% from 2.62 meters to 1.63 meters error using our semi-supervised adaptation
method.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:44:41 GMT""}]","2021-03-02"
"2103.00253","Olgur Celikbas","Tokuji Araya, Olgur Celikbas, Jesse Cook, Toshinori Kobayashi","On modules with finite reducing Gorenstein dimension","9 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If $M$ is a nonzero finitely generated module over a commutative Noetherian
local ring $R$ such that $M$ has finite injective dimension and finite
Gorenstein dimension, then it follows from a result of Holm that $M$ has finite
projective dimension, and hence a result of Foxby implies that $R$ is
Gorenstein. We investigate whether the same conclusion holds for nonzero
finitely generated modules that have finite injective dimension and finite
reducing Gorenstein dimension, where the reducing Gorenstein dimension is a
finer invariant than the classical Gorenstein dimension, in general.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:45:00 GMT""}]","2021-03-02"
"2103.00254","Thomas Moser","David Chaum, Christian Grothoff, Thomas Moser","How to Issue a Central Bank Digital Currency","Swiss National Bank Working Paper3/2021",,,,"econ.GN cs.CR q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the emergence of Bitcoin and recently proposed stablecoins from
BigTechs, such as Diem (formerly Libra), central banks face growing competition
from private actors offering their own digital alternative to physical cash. We
do not address the normative question whether a central bank should issue a
central bank digital currency (CBDC) or not. Instead, we contribute to the
current research debate by showing how a central bank could do so, if desired.
We propose a token-based system without distributed ledger technology and show
how earlier-deployed, software-only electronic cash can be improved upon to
preserve transaction privacy, meet regulatory requirements in a compelling way,
and offer a level of quantum-resistant protection against systemic privacy
risk. Neither monetary policy nor financial stability would be materially
affected because a CBDC with this design would replicate physical cash rather
than bank deposits.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:46:51 GMT""}]","2021-03-02"
"2103.00255","Armin Goudarzi","Armin Goudarzi, Carsten Spehr, Steffen Herbold","Expert Decision Support System for aeroacoustic source type
  identification using clustering","Preprint for JASA Journal",,"10.1121/10.0009322",,"cs.SD cs.AI cs.LG eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents an Expert Decision Support System for the identification
of time-invariant, aeroacoustic source types. The system comprises two steps:
first, acoustic properties are calculated based on spectral and spatial
information. Second, clustering is performed based on these properties. The
clustering aims at helping and guiding an expert for quick identification of
different source types, providing an understanding of how sources differ. This
supports the expert in determining similar or atypical behavior. A variety of
features are proposed for capturing the characteristics of the sources. These
features represent aeroacoustic properties that can be interpreted by both the
machine and by experts. The features are independent of the absolute Mach
number which enables the proposed method to cluster data measured at different
flow configurations. The method is evaluated on deconvolved beamforming data
from two scaled airframe half-model measurements. For this exemplary data, the
proposed support system method results in clusters that mostly correspond to
the source types identified by the authors. The clustering also provides the
mean feature values and the cluster hierarchy for each cluster and for each
cluster member a clustering confidence. This additional information makes the
results transparent and allows the expert to understand the clustering choices.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:47:59 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 17:55:22 GMT""}]","2022-03-09"
"2103.00256","Birgitta Dresp-Langley","Birgitta Dresp-Langley, John M. Wandeto","Human Symmetry Uncertainty Detected by a Self-Organizing Neural Network
  Map",,"Symmetry. 2021; 13(2):299","10.3390/sym13020299",,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetry in biological and physical systems is a product of self organization
driven by evolutionary processes, or mechanical systems under constraints.
Symmetry based feature extrac-tion or representation by neural networks may
unravel the most informative contents in large image databases. Despite
significant achievements of artificial intelligence in recognition and
classification of regular patterns, the problem of uncertainty remains a major
challenge in ambiguous data. In this study, we present an artificial neural
network that detects symmetry uncertainty states in human observers. To this
end, we exploit a neural network metric in the output of a biologically
inspired Self Organizing Map, the Quantization Error (SOM QE). Shape pairs with
perfect geometric mirror symmetry but a non-homogenous appearance, caused by
local variations in hue, saturation, or lightness within or across the shapes
in a given pair produce, as shown here, longer choice RT for yes responses
relative to symmetry. These data are consistently mirrored by the variations in
the SOM QE from unsupervised neural network analysis of the same stimulus
images. The neural network metric is thus capable of detecting and scaling
human symmetry uncertainty in response to patterns. Such capacity is tightly
linked to the metrics proven selectivity to local contrast and color variations
in large and highly complex image data.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:55:01 GMT""}]","2021-03-02"
"2103.00257","Hao Xu","Chen-Hao Wu, Ya-Peng Hu, Hao Xu","Hawking evaporation of Einstein-Gauss-Bonnet AdS black holes in
  $D\geqslant 4$ dimensions","14 pages, 8 figures; v2: references added, minor corrections,
  submitted to journal;v3: minor corrections, published in EPJC;v4: one typo in
  Eq(9) fixed","Eur. Phys. J. C 81, 351 (2021)","10.1140/epjc/s10052-021-09140-6",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  Einstein-Gauss-Bonnet theory is a string-generated gravity theory when
approaching the low energy limit. By introducing the higher order curvature
terms, this theory is supposed to help to solve the black hole singularity
problem. In this work, we investigate the evaporation of the static spherically
symmetric neutral AdS black holes in Einstein-Gauss-Bonnet gravity in various
spacetime dimensions with both positive and negative couping constant $\alpha$.
By summarizing the asymptotic behavior of the evaporation process, we find the
lifetime of the black holes is dimensional dependent. For $\alpha>0$, in
$D\geqslant6$ cases, the black holes will be completely evaporated in a finite
time, which resembles the Schwarzschild-AdS case in Einstein gravity. While in
$D=4,5$ cases, the black hole lifetime is always infinite, which means the
black hole becomes a remnant in the late time. Remarkably, the cases of
$\alpha>0, D=4,5$ will solve the terminal temperature divergent problem of the
Schwarzschild-AdS case. For $\alpha<0$, in all dimensions, the black hole will
always spend a finite time to a minimal mass corresponding to the smallest
horizon radius $r_{min}=\sqrt{2|\alpha|}$ which coincide with an additional
singularity. This implies that there may exist constraint conditions to the
choice of coupling constant.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:56:17 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 09:17:50 GMT""},{""version"":""v3"",""created"":""Sun, 25 Apr 2021 08:25:40 GMT""},{""version"":""v4"",""created"":""Mon, 21 Nov 2022 06:30:54 GMT""}]","2022-11-22"
"2103.01024","Davide Zorzenon","Davide Zorzenon, Jan Komenda, Joerg Raisch","Periodic trajectories in P-time event graphs and the non-positive
  circuit weight problem","Minor corrections",,"10.1109/LCSYS.2021.3085521",,"cs.DS cs.DM cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  P-time event graphs (P-TEGs) are specific timed discrete-event systems, in
which the timing of events is constrained by intervals. An important problem is
to check, for all natural numbers $d$, the existence of consistent $d$-periodic
trajectories for a given P-TEG. In graph theory, the
Proportional-Inverse-Constant-Non-positive Circuit weight Problem (PIC-NCP)
consists in finding all the values of a parameter such that a particular
parametric weighted directed graph does not contain circuits with positive
weight. In a related paper, we have proposed a strongly polynomial algorithm
that solves the PIC-NCP in lower worst-case complexity compared to other
algorithms reported in literature. In the present paper, we show that the first
problem can be formulated as an instance of the second; consequently, we prove
that the same algorithm can be used to find $d$-periodic trajectories in
P-TEGs. Moreover, exploiting the connection between the PIC-NCP and max-plus
algebra we prove that, given a P-TEG, the existence of a consistent 1-periodic
trajectory of a certain period is a necessary and sufficient condition for the
existence of a consistent $d$-periodic trajectory of the same period, for any
value of $d$.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:28:13 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 15:40:40 GMT""},{""version"":""v3"",""created"":""Fri, 21 May 2021 07:56:39 GMT""},{""version"":""v4"",""created"":""Mon, 7 Jun 2021 11:35:34 GMT""}]","2021-06-08"
"2103.01025","Piyush Shrivastava","Piyush Shrivastava","Neural Code Summarization","6 pages",,,,"cs.SE cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Code summarization is the task of generating readable summaries that are
semantically meaningful and can accurately describe the presumed task of a
software. Program comprehension has become one of the most tedious tasks for
knowledge transfer. As the codebase evolves over time, the description needs to
be manually updated each time with the changes made. An automatic approach is
proposed to infer such captions based on benchmarked and custom datasets with
comparison between the original and generated results.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 16:04:33 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 19:55:08 GMT""}]","2021-03-08"
"2103.01218","Luis Nieto-Barajas Dr.","Luis Nieto-Barajas and Eduardo Guti\'errez-Pe\~na","General dependence structures for some models based on exponential
  families with quadratic variance functions",,,,,"math.ST stat.ME stat.TH","http://creativecommons.org/licenses/by/4.0/","  We describe a procedure to introduce general dependence structures on a set
of random variables. These include order-$q$ moving average-type structures, as
well as seasonal, periodic, spatial and spatio-temporal dependences. The
invariant marginal distribution can be in any family that is conjugate to an
exponential family with quadratic variance function. Dependence is induced via
a set of suitable latent variables whose conditional distribution mirrors the
sampling distribution in a Bayesian conjugate analysis of such exponential
families. We obtain strict stationarity as a special case.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:00:40 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 17:29:54 GMT""}]","2021-10-15"
"2103.01219","Yuta Wakasugi","Kimitoshi Tsutaya, Yuta Wakasugi","Blow up of solutions of semilinear wave equations in accelerated
  expanding Friedmann-Lema\^{i}tre-Robertson-Walker spacetime","19 pages. arXiv admin note: substantial text overlap with
  arXiv:2103.00175","Reviews in Mathematical Physics 33 (2022), 2250003","10.1142/S0129055X22500039",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a nonlinear wave equation for a massless scalar field with
self-interaction in the spatially flat Friedmann-Lema\^{i}tre-Robertson-Walker
spacetimes. For the case of accelerated expansion, we show that blow-up in a
finite time occurs for the equation with arbitrary power nonlinearity as well
as upper bounds of the lifespan of blow-up solutions. Comparing to the case of
the Minkowski spacetime, we discuss how the scale factor affects the lifespan
of blow-up solutions of the equation.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 10:34:56 GMT""}]","2021-12-14"
"2103.01760","Hilmi Enes Egilmez","Hilmi E. Egilmez, Ankitesh K. Singh, Muhammed Coban, Marta Karczewicz,
  Yinhao Zhu, Yang Yang, Amir Said, Taco S. Cohen","Transform Network Architectures for Deep Learning based End-to-End
  Image/Video Coding in Subsampled Color Spaces","10 pages, accepted in IEEE Open Journal of Signal Processing (Special
  issue on Applied Artificial Intelligence and Machine Learning for Video
  Coding and Streaming)",,"10.1109/OJSP.2021.3092257",,"eess.IV cs.AI cs.CV cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the existing deep learning based end-to-end image/video coding (DLEC)
architectures are designed for non-subsampled RGB color format. However, in
order to achieve a superior coding performance, many state-of-the-art
block-based compression standards such as High Efficiency Video Coding
(HEVC/H.265) and Versatile Video Coding (VVC/H.266) are designed primarily for
YUV 4:2:0 format, where U and V components are subsampled by considering the
human visual system. This paper investigates various DLEC designs to support
YUV 4:2:0 format by comparing their performance against the main profiles of
HEVC and VVC standards under a common evaluation framework. Moreover, a new
transform network architecture is proposed to improve the efficiency of coding
YUV 4:2:0 data. The experimental results on YUV 4:2:0 datasets show that the
proposed architecture significantly outperforms naive extensions of existing
architectures designed for RGB format and achieves about 10% average BD-rate
improvement over the intra-frame coding in HEVC.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:47:27 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 07:44:13 GMT""}]","2021-08-30"
"2103.01767","Saugat Kandel","Saugat Kandel, S. Maddali, Youssef S G Nashed, Stephan O Hruszkewycz,
  Chris Jacobsen, Marc Allain","A matrix-free Levenberg-Marquardt algorithm for efficient ptychographic
  phase retrieval",,,,,"eess.IV eess.SP physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The phase retrieval problem, where one aims to recover a complex-valued image
from far-field intensity measurements, is a classic problem encountered in a
range of imaging applications. Modern phase retrieval approaches usually rely
on gradient descent methods in a nonlinear minimization framework. Calculating
closed-form gradients for use in these methods is tedious work, and formulating
second order derivatives is even more laborious. Additionally, second order
techniques often require the storage and inversion of large matrices of partial
derivatives, with memory requirements that can be prohibitive for data-rich
imaging modalities. We use a reverse-mode automatic differentiation (AD)
framework to implement an efficient matrix-free version of the
Levenberg-Marquardt (LM) algorithm, a longstanding method that finds popular
use in nonlinear least-square minimization problems but which has seen little
use in phase retrieval. Furthermore, we extend the basic LM algorithm so that
it can be applied for general constrained optimization problems beyond just the
least-square applications. Since we use AD, we only need to specify the
physics-based forward model for a specific imaging application; the derivative
terms are calculated automatically through matrix-vector products, without
explicitly forming any large Jacobian or Gauss-Newton matrices. We demonstrate
that this algorithm can be used to solve both the unconstrained ptychographic
object retrieval problem and the constrained ""blind"" ptychographic object and
probe retrieval problems, under both the Gaussian and Poisson noise models, and
that this method outperforms best-in-class first-order ptychographic
reconstruction methods: it provides excellent convergence guarantees with (in
many cases) a superlinear rate of convergence, all with a computational cost
comparable to, or lower than, the tested first-order algorithms.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 00:56:54 GMT""}]","2021-03-03"
"2103.02046","Andreas Adelmann","Tim Wyssling and Andreas Adelmann","On Boundary Conditions in the sub-mesh interaction of the
  Particle-Particle-Particle-Mesh Algorithm",,,,,"physics.comp-ph physics.acc-ph physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The Particle-Particle-Particle-Mesh algorithm elegantly extends the standard
Particle-In-Cell scheme by direct summation of interaction that happens over
distances below or around mesh size. Generally, this allows for a more accurate
description of Coulomb interactions and improves precision in the prediction of
key observables. Nevertheless, most implementations neglect electrostatic
boundary conditions for the short-ranged interaction that are directly summed.
In this paper a variational description of the Particle-Particle-Particle-Mesh
algorithm will be developed for the first time and subsequently used to derive
temporally and spatially discrete equations of motion. We show that the error
committed by neglecting boundary conditions on the short scale is directly tied
to the discretization error induced by the computational grid.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 14:48:42 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 19:50:08 GMT""}]","2021-04-19"
"2103.02427","Galamo Monkam","Galamo Monkam","The generalization of Schr\""oder's theorem (1871): The multinomial
  theorem for formal power series under composition","29 pages",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  We consider formal power series $ f(x) = a_1 x + a_2 x^2 + \cdots $ $(a_1
\neq 0)$, with coefficients in a field. We revisit the classical subject of
iteration of formal power series, the n-fold composition $f^{(n)}(x)=f(f(\cdots
(f(x)\cdots))=f^{(n-1)}(f(x))=\sum\limits_{k=1}^{\infty}f_k^{(n)}x^k$ for
$n=2,3,\ldots$, where $f^{(1)}(x)=f(x)$. The study of this was begun, and the
coefficients $f_k^{(n)}$ where calculated assuming $a_1=1$, by Schr\""oder in
1871. The major result of this paper, Theorem 7.1.1, generalizes Schr\""oder
[15]. It gives explicit formulas for the coefficients $f_k^{(n)}$ when $a_1
\neq 0$ and it is viewed as an analog to the $n^{th}$ Multinomial Theorem Under
Multiplication. We prove Schr\""oder's Theorem using a new and shorter
approach.The Recursion Lemma, Lemma 3.1.1,which sharpens Cohen's lemma (Lemma
2.4.2) is our key tool in the proof of Theorem 7.1.1 and it is one of the most
useful recurrence relations for the composition of formal power series. Along
the way we develop numerical formulas for $f_k^{(n)} {\rm where} 1\leq k\leq
5$.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 08:36:55 GMT""}]","2021-03-04"
"2103.02447","Raditya Bayu Rahadian","Suwarno and Raditya Bayu Rahadian","The Use of Fractional Blocks to Improve Mathematics for Second Grade
  Elementary School Students at South Bangka Indonesia","9 pages","International Journal of Innovative Science and Research
  Technology, Volume 5, Issue 12, December 2020",,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  This study aims to improve mathematics learning results in the second grade
of elementary school, especially the matter of fractions. The background of the
research is the low learning outcomes achieved by students due to the learning
carried out does not pay attention to the level of student development. This
research was classroom action research. The research subjects were 23 students.
The data collection instrument used the observation sheet and documentation.
Quantitative data analysis techniques with descriptive statistics were used in
this study to compare conditions before and after the action was carried out.
The results showed an increase in mathematics learning outcomes in the subject
of fractions. Student motivation shown in the implementation of learning in the
second cycle reached 3.91 (high category) with N-Gain reaching 46.49%. The
level of completeness has reached 100%. The average value obtained by students
in the second cycle was 80.2 and N-Gain reached 34.16%. This increase was due
to the learning carried out using fractional blocks. These results illustrate
that the use of fractional blocks can improve mathematics learning outcomes,
especially in the subject of fractions.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 02:21:33 GMT""}]","2021-03-04"
"2103.02592","Rajeev Singh Mr.","Rajeev Singh, Masoud Shokri, and Radoslaw Ryblewski","Spin polarization dynamics in the Bjorken-expanding resistive MHD
  background","12 pages, 6 figures; Accepted version; Comments are very much
  welcome!","Phys. Rev. D 103, 094034 (2021)","10.1103/PhysRevD.103.094034",,"hep-ph hep-th nucl-th","http://creativecommons.org/licenses/by/4.0/","  Evolution of spin polarization in the presence of external electric field is
studied for collision energies $\sqrt{s_{\rm NN}}=27\,{\rm GeV}$ and
$\sqrt{s_{\rm NN}}=200\,{\rm GeV}$. The numerical analysis is done in the
perfect-fluid Bjorken-expanding resistive magnetohydrodynamic background and
novel results are reported. In particular, we show that the electric field
plays a significant role in the competition between expansion and dissipation.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:05:05 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 06:45:42 GMT""}]","2021-06-02"
"2103.03359","Amol Kelkar","Amol Kelkar","Cognitive Homeostatic Agents","Accepted at AAMAS2021 Blue Sky Ideas Track","In Proc. of the 20th International Conference on Autonomous Agents
  and Multiagent Systems (AAMAS 2021), Online, May 3-7, 2021, IFAAMAS, 5 pages","10.5555/3461017.3461021",,"cs.AI cs.LG cs.MA cs.NE","http://creativecommons.org/licenses/by/4.0/","  Human brain has been used as an inspiration for building autonomous agents,
but it is not obvious what level of computational description of the brain one
should use. This has led to overly opinionated symbolic approaches and overly
unstructured connectionist approaches. We propose that using homeostasis as the
computational description provides a good compromise. Similar to how
physiological homeostasis is the regulation of certain homeostatic variables,
cognition can be interpreted as the regulation of certain 'cognitive
homeostatic variables'. We present an outline of a Cognitive Homeostatic Agent,
built as a hierarchy of physiological and cognitive homeostatic subsystems and
describe structures and processes to guide future exploration. We expect this
to be a fruitful line of investigation towards building sophisticated
artificial agents that can act flexibly in complex environments, and produce
behaviors indicating planning, thinking and feelings.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 07:29:43 GMT""}]","2021-05-04"
"2103.03838","Rohollah Bakhshandeh-Chamazkoti","Davood Farrokhi, Rohollah Bakhshandeh-Chamazkoti and Mehdi Nadjafikhah","On the invariance properties of Vaidya-Bonner geodesics via symmetry
  operators","This paper accepted for publication in International Journal of
  Nonlinear Analysis and Applications","International Journal of Nonlinear Analysis and Applications, 2020",,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In the present paper, we try to investigate the Noether symmetries and Lie
point symmetries of the Vaidya-Bonner geodesics. Classification of
one-dimensional subalgebras of Lie point symmetries are considered. In fact,
the collection of pairwise non-conjugate one-dimensional subalgebras that are
called the optimal system of subalgebras is determined. Moreover, as
illustrative examples, the symmetry analysis is implemented on two special
cases of the system.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 15:59:59 GMT""}]","2021-03-08"
"2103.05527","Rasoul Abazari","Rasoul Abazari","Statistical convergence in g-metric spaces",,,,,"math.GN math.MG","http://creativecommons.org/licenses/by/4.0/","  The purpose of this paper is to define statistically convergent sequences
with respect to the metrics on generalized metric spaces (g-metric spaces) and
investigate basic properties of this statistical form of convergence.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 20:57:59 GMT""}]","2021-03-10"
"2103.05760","Tarik A. Rashid","Hardi M. Mohammed, Zrar Kh. Abdul, Tarik A. Rashid, Abeer Alsadoon,
  Nebojsa Bacanin","A New K means Grey Wolf Algorithm for Engineering Problems","15 pages. World Journal of Engineering, 2021",,"10.1108/WJE-10-2020-0527",,"cs.AI cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Purpose: The development of metaheuristic algorithms has increased by
researchers to use them extensively in the field of business, science, and
engineering. One of the common metaheuristic optimization algorithms is called
Grey Wolf Optimization (GWO). The algorithm works based on imitation of the
wolves' searching and the process of attacking grey wolves. The main purpose of
this paper to overcome the GWO problem which is trapping into local optima.
  Design or Methodology or Approach: In this paper, the K-means clustering
algorithm is used to enhance the performance of the original Grey Wolf
Optimization by dividing the population into different parts. The proposed
algorithm is called K-means clustering Grey Wolf Optimization (KMGWO).
  Findings: Results illustrate the efficiency of KMGWO is superior to GWO. To
evaluate the performance of the KMGWO, KMGWO applied to solve 10 CEC2019
benchmark test functions. Results prove that KMGWO is better compared to GWO.
KMGWO is also compared to Cat Swarm Optimization (CSO), Whale Optimization
Algorithm-Bat Algorithm (WOA-BAT), and WOA, so, KMGWO achieves the first rank
in terms of performance. Statistical results proved that KMGWO achieved a
higher significant value compared to the compared algorithms. Also, the KMGWO
is used to solve a pressure vessel design problem and it has outperformed
results.
  Originality/value: Results prove that KMGWO is superior to GWO. KMGWO is also
compared to cat swarm optimization (CSO), whale optimization algorithm-bat
algorithm (WOA-BAT), WOA, and GWO so KMGWO achieved the first rank in terms of
performance. Also, the KMGWO is used to solve a classical engineering problem
and it is superior
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:29:07 GMT""}]","2021-03-11"
"2103.06140","Xishuang Dong","Lucy Nwosu, Xiangfang Li, Lijun Qian, Seungchan Kim, Xishuang Dong","Semi-supervised Learning for COVID-19 Image Classification via ResNet",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronavirus disease 2019 (COVID-19) is an ongoing global pandemic in over 200
countries and territories, which has resulted in a great public health concern
across the international community. Analysis of X-ray imaging data can play a
critical role in timely and accurate screening and fighting against COVID-19.
Supervised deep learning has been successfully applied to recognize COVID-19
pathology from X-ray imaging datasets. However, it requires a substantial
amount of annotated X-ray images to train models, which is often not applicable
to data analysis for emerging events such as COVID-19 outbreak, especially in
the early stage of the outbreak. To address this challenge, this paper proposes
a two-path semi-supervised deep learning model, ssResNet, based on Residual
Neural Network (ResNet) for COVID-19 image classification, where two paths
refer to a supervised path and an unsupervised path, respectively. Moreover, we
design a weighted supervised loss that assigns higher weight for the minority
classes in the training process to resolve the data imbalance. Experimental
results on a large-scale of X-ray image dataset COVIDx demonstrate that the
proposed model can achieve promising performance even when trained on very few
labeled training images.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 04:25:39 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 01:53:59 GMT""}]","2021-04-02"
"2103.06706","Dharam Vir Ahluwalia","Dharam Vir Ahluwalia","Elko and Mass Dimension One Fermions: Editorial",,"Eur. Phys. J. Special Topics 229, 1997-2001 (2020)","10.1140/epjst/e2020-000194-1",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  This editorial presents the quantum field theoretic ambiance in which Elko
and mass dimension one fermions come to exist. This may serve not only to
introduce Elko, and the associated quantum field, but it may also open a door
to a new class of spin one half fermions and bosons. These new particles, as it
will be argued in this volume, are first-principle candidates for dark matter.
","[{""version"":""v1"",""created"":""Sat, 27 Feb 2021 06:56:21 GMT""}]","2021-03-12"
"2103.15546","Richard Allmendinger","Richard Allmendinger and Joshua Knowles","Heterogeneous Objectives: State-of-the-Art and Future Research","20 pages, submitted for consideration to the MACODA book project",,,,"cs.NE cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiobjective optimization problems with heterogeneous objectives are
defined as those that possess significantly different types of objective
function components (not just incommensurable in units or scale). For example,
in a heterogeneous problem the objective function components may differ in
formal computational complexity, practical evaluation effort (time, costs, or
resources), determinism (stochastic vs deterministic), or some combination of
all three. A particularly challenging variety of heterogeneity may occur by the
combination of a time-consuming laboratory-based objective with other
objectives that are evaluated using faster computer-based calculations. Perhaps
more commonly, all objectives may be evaluated computationally, but some may
require a lengthy simulation process while others are computed from a
relatively simple closed-form calculation. In this chapter, we motivate the
need for more work on the topic of heterogeneous objectives (with reference to
real-world examples), expand on a basic taxonomy of heterogeneity types, and
review the state of the art in tackling these problems. We give special
attention to heterogeneity in evaluation time (latency) as this requires
sophisticated approaches. We also present original experimental work on
estimating the amount of heterogeneity in evaluation time expected in
many-objective problems, given reasonable assumptions, and survey related
research threads that could contribute to this area in future.
","[{""version"":""v1"",""created"":""Fri, 26 Feb 2021 23:30:13 GMT""}]","2021-03-30"

"2101.07137","Peng Xiao Dr","Peng Xiao, Lingji Xu, Liya Xu, Jianmin Yang and Qing Hu","Graph-based Matched Field Localization for an Underwater Source",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matched Field Processing (MFP) locates the underwater sources by matching the
received data with the replica vectors, which could be regarded as a
generalized beamformer. In this paper, the MFP method is combined with a
recently developed framework -- Graph Signal Processing (GSP) method. Following
the paradigm of GSP, a spatial adjacency matrix is constructed for the
arbitrary distributed sensors based on the Green's function, then the source is
located by utilizing the graph Fourier transform. The simulation results
illustrate that the Graph-based MFP outperforms the the conventional MFP
processors -- the Bartlett processor and the Minimum Variance processor -- for
its good accuracy and robustness.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:01:43 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 12:54:33 GMT""}]","2022-01-11"
"2101.07138","Yannis Papanikolaou","Yannis Papanikolaou","Teach me how to Label: Labeling Functions from Natural Language with
  Text-to-text Transformers",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Annotated data has become the most important bottleneck in training accurate
machine learning models, especially for areas that require domain expertise. A
recent approach to deal with the above issue proposes using natural language
explanations instead of labeling individual data points, thereby increasing
human annotators' efficiency as well as decreasing costs substantially. This
paper focuses on the task of turning these natural language descriptions into
Python labeling functions by following a novel approach to semantic parsing
with pre-trained text-to-text Transformers. In a series of experiments our
approach achieves a new state of the art on the semantic parsing benchmark
CoNaLa, surpassing the previous best approach by 3.7 BLEU points. Furthermore,
on a manually constructed dataset of natural language descriptions-labeling
functions pairs we achieve a BLEU of 0.39. Our approach can be regarded as a
stepping stone towards models that are taught how to label in natural language,
instead of being provided specific labeled samples. Our code, constructed
dataset and models are available at
https://github.com/ypapanik/t5-for-code-generation.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:04:15 GMT""}]","2021-01-19"
"2101.07139","Marius Bothe","Marius Bothe, Gunnar Pruessner","Field Theory of free Active Ornstein-Uhlenbeck Particles",,"Phys. Rev. E 103, 062105 (2021)","10.1103/PhysRevE.103.062105",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a Doi-Peliti field theory for free active Ornstein-Uhlenbeck
particles, or, equivalently, free inertial Brownian particles, and present a
way to diagonalise the Gaussian part of the action and calculate the
propagator. Unlike previous course-grained approaches this formulation
correctly tracks particle identity and yet can easily be expanded to include
potentials and arbitrary reactions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:04:43 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 11:49:02 GMT""}]","2021-06-09"
"2101.07140","Pradyumna Tambwekar","Pradyumna Tambwekar, Andrew Silva, Nakul Gopalan, Matthew Gombolay","Natural Language Specification of Reinforcement Learning Policies
  through Differentiable Decision Trees",,,,,"cs.LG cs.AI cs.CL cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human-AI policy specification is a novel procedure we define in which humans
can collaboratively warm-start a robot's reinforcement learning policy. This
procedure is comprised of two steps; (1) Policy Specification, i.e. humans
specifying the behavior they would like their companion robot to accomplish,
and (2) Policy Optimization, i.e. the robot applying reinforcement learning to
improve the initial policy. Existing approaches to enabling collaborative
policy specification are often unintelligible black-box methods, and are not
catered towards making the autonomous system accessible to a novice end-user.
In this paper, we develop a novel collaborative framework to allow humans to
initialize and interpret an autonomous agent's behavior. Through our framework,
we enable humans to specify an initial behavior model via unstructured, natural
language (NL), which we convert to lexical decision trees. Next, we leverage
these translated specifications, to warm-start reinforcement learning and allow
the agent to further optimize these potentially suboptimal policies. Our
approach warm-starts an RL agent by utilizing non-expert natural language
specifications without incurring the additional domain exploration costs. We
validate our approach by showing that our model is able to produce >80%
translation accuracy, and that policies initialized by a human can match the
performance of relevant RL baselines in two domains.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:07:00 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 16:10:05 GMT""},{""version"":""v3"",""created"":""Tue, 1 Feb 2022 22:42:50 GMT""},{""version"":""v4"",""created"":""Sat, 20 May 2023 21:13:00 GMT""}]","2023-05-23"
"2101.07141","Achim Zeileis","Susanne K\""oll, Ioannis Kosmidis, Christian Kleiber, Achim Zeileis","Bias Reduction as a Remedy to the Consequences of Infinite Estimates in
  Poisson and Tobit Regression","8 pages, 8 figures",,,,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  Data separation is a well-studied phenomenon that can cause problems in the
estimation and inference from binary response models. Complete or
quasi-complete separation occurs when there is a combination of regressors in
the model whose value can perfectly predict one or both outcomes. In such
cases, and such cases only, the maximum likelihood estimates and the
corresponding standard errors are infinite. It is less widely known that the
same can happen in further microeconometric models. One of the few works in the
area is Santos Silva and Tenreyro (2010) who note that the finiteness of the
maximum likelihood estimates in Poisson regression depends on the data
configuration and propose a strategy to detect and overcome the consequences of
data separation. However, their approach can lead to notable bias on the
parameter estimates when the regressors are correlated. We illustrate how
bias-reducing adjustments to the maximum likelihood score equations can
overcome the consequences of separation in Poisson and Tobit regression models.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:07:14 GMT""}]","2021-01-19"
"2101.07142","Omar Nagib","Omar Nagib","$\alpha$-decay half-lives of superheavy nuclei with $Z=122-125$","7 pages,1 figure (4 subfigures). published version","Phys. Rev. C 101, 014610 (2020)","10.1103/PhysRevC.101.014610",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $\alpha$ decay half-life calculations in this work, the Coulomb and
proximity potential model with a new semiempirical formula for diffuseness
parameter developed in previous work [Phys. Rev. C 100, 024601 (2019)] is used.
The present model in this work is compared with the generalized liquid-drop
model (GLDM), universal decay law (UDL), and experimental half-lives in the
region $Z=104-118$. Next, the predicted half-lives of 51 superheavy nuclei
(SHN) with $Z=122-125$ by the present model are compared with those of GLDM,
and UDL. The present model is revealed to be more accurate in reproducing
experimental half-lives compared to GLDM and UDL. Moreover, it is found that
the predictions of the present model and UDL are highly consistent while GLDM
largely deviates from the other two. A study of the competition between
$\alpha$ decay and spontaneous fission (SF) shows that $\alpha$ decay is the
dominant mode. Among the studied SHN with $Z=122-125$, ${}^{295-307}122$ and
${}^{314-320}125$ are identified as potential candidates whose half-lives are
relatively long enough to be experimentally detected in the future through
their $\alpha$-decay chains. The identified candidates are in good agreement
with other recent work.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:07:24 GMT""}]","2021-01-19"
"2101.07143","Engin Keles","Engin Keles","Spectral signature of atmospheric winds in high resolution transit
  observations","Accepted for publication",,"10.1093/mnras/stab099",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of exoplanet atmospheres showed large diversity compared to the
planets in our solar system. Especially Jupiter type exoplanets orbiting their
host star in close orbits, the so-called hot and ultra-hot Jupiters, have been
studied in detail due to their enhanced atmospheric signature. Due to their
tidally locked status, the temperature difference between the day- and
nightside triggers atmospheric winds which can lead to various fingerprints in
the observations. Spatially resolved absorption lines during transit such as
sodium (Na) could be a good tracer for such winds. Different works resolved the
Na$^-$ absorption lines on different exoplanets which show different line
widths. Assuming that this could be attributed to such zonal jet streams, this
work models the effect of such winds on synthetic absorption lines. For this,
transiting Jupiter type planets with rotational velocities similar to hot and
ultra-hot Jupiter are considered. The investigation shows that high wind
velocities could reproduce the broadening of Na-line profiles inferred in
different high-resolution transit observations. There is a tendency that the
broadening values decrease for planets with lower equilibrium temperature. This
could be explained by atmospheric drag induced by the ionization of alkali
lines which slow down the zonal jet streams, favoring their existence on hot
Jupiter rather than ultra-hot Jupiter.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:11:04 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 09:42:39 GMT""}]","2021-02-03"
"2101.07144","William Wallis","William Wallis and William Kavanagh and Alice Miller and Tim Storer","Designing a mobile game to generate player data -- lessons learned",,,,,"cs.MM cs.CY cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  User friendly tools have lowered the requirements of high-quality game design
to the point where researchers without development experience can release their
own games. However, there is no established best-practice as few games have
been produced for research purposes. Having developed a mobile game without the
guidance of similar projects, we realised the need to share our experience so
future researchers have a path to follow. Research into game balancing and
system simulation required an experimental case study, which inspired the
creation of ""RPGLite"", a multiplayer mobile game. In creating RPGLitewith no
development expertise we learned a series of lessons about effective amateur
game development for research purposes. In this paper we reflect on the entire
development process and present these lessons.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:16:58 GMT""}]","2021-01-19"
"2101.07145","Sergio Catal\'an G\'omez","Sergio Catal\'an-G\'omez, Nerea Dasilva-Villanueva, David Fuertes
  Marr\'on and Carlos del Ca\~nizo","Phosphorous Diffusion Gettering of Trapping Centers in Upgraded
  Metallurgical-Grade Solar Silicon","12 pages, 3 figures","physica status solidi: Rapid Research Letters, 2021, 2100054","10.1002/pssr.202100054",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Experimental evidence indicating the beneficial impact of a phosphorous
diffusion gettering (PDG) in the reduction of trapping centers is shown, as
observed by means of inductively coupled photoconductance (PC) decay and
lifetime measurements carried out on upgraded metallurgical-grade silicon
(UMG-Si) wafers. The presence of trapping species dominating the long time
range of the PC decay of UMG material (slow traps), which is effectively
removed after a PDG conducted at 780 Celsius, is detected. Notwithstanding, a
second trapping mechanism, characterized by a shorter time constant, still
governs the response at very low injection levels after the gettering.
Furthermore, the beneficial effect of the PDG is studied as a function of
processing time, showing minority carrier bulk lifetime improvements up to
18-fold, up to the range of 70 us. Thereby, the way for developing gettering
strategies capable of successfully removing trap centers and improving the bulk
lifetime of unconventional Si material is paved.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:19:35 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 10:44:19 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jan 2021 16:50:34 GMT""},{""version"":""v4"",""created"":""Tue, 20 Apr 2021 14:17:26 GMT""}]","2021-04-21"
"2101.07146","Saurabh Verma","V. Agrawal, T. Som and S. Verma","On bivariate fractal approximation","13 pages, Submitted for possible publication to a journal",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the notion of dimension preserving approximation for
real-valued bivariate continuous functions, defined on a rectangular domain
$\rectangle$, has been introduced and several results, similar to well-known
results of bivariate constrained approximation in terms of dimension preserving
approximants, have been established. Further, some clue for the construction of
bivariate dimension preserving approximants, using the concept of fractal
interpolation functions, has been added. In the last part, some multi-valued
fractal operators associated with bivariate $\alpha$-fractal functions are
defined and studied.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:19:52 GMT""}]","2021-01-19"
"2101.07147","Vladimir Khatsymovsky","V.M. Khatsymovsky","On the Kerr metric in a synchronous reference frame","9 pages, 1 figure","Int. J. Mod. Phys. D, Volume No. 30, Issue No. 10, Article No.
  2150071, Year 2021","10.1142/S0218271821500711",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Kerr metric is considered in a synchronous frame of reference obtained by
using proper time and initial conditions for particles that freely move along a
certain set of trajectories as coordinates. Modifying these coordinates in a
certain way (keeping their interpretation as initial values at large
distances), we still have a synchronous frame and the direct analogue of the
Lemaitre metric, the singularities of which are exhausted by the physical Kerr
singularity (the singularity ring).
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:28:23 GMT""}]","2021-08-26"
"2101.07149","Maximilian Probst Gutenberg","Aaron Bernstein, Maximilian Probst Gutenberg, Thatchaphol Saranurak","Deterministic Decremental SSSP and Approximate Min-Cost Flow in
  Almost-Linear Time",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the decremental single-source shortest paths problem, the goal is to
maintain distances from a fixed source $s$ to every vertex $v$ in an $m$-edge
graph undergoing edge deletions. In this paper, we conclude a long line of
research on this problem by showing a near-optimal deterministic data structure
that maintains $(1+\epsilon)$-approximate distance estimates and runs in
$m^{1+o(1)}$ total update time.
  Our result, in particular, removes the oblivious adversary assumption
required by the previous breakthrough result by Henzinger et al. [FOCS'14],
which leads to our second result: the first almost-linear time algorithm for
$(1-\epsilon)$-approximate min-cost flow in undirected graphs where capacities
and costs can be taken over edges and vertices. Previously, algorithms for max
flow with vertex capacities, or min-cost flow with any capacities required
super-linear time. Our result essentially completes the picture for approximate
flow in undirected graphs.
  The key technique of the first result is a novel framework that allows us to
treat low-diameter graphs like expanders. This allows us to harness expander
properties while bypassing shortcomings of expander decomposition, which almost
all previous expander-based algorithms needed to deal with. For the second
result, we break the notorious flow-decomposition barrier from the
multiplicative-weight-update framework using randomization.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:29:31 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 17:06:54 GMT""}]","2021-01-20"
"2101.07150","Michael Rauchensteiner","Christian Fiedler, Massimo Fornasier, Timo Klock, and Michael
  Rauchensteiner","Stable Recovery of Entangled Weights: Towards Robust Identification of
  Deep Neural Networks from Minimal Samples",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we approach the problem of unique and stable identifiability of
generic deep artificial neural networks with pyramidal shape and smooth
activation functions from a finite number of input-output samples. More
specifically we introduce the so-called entangled weights, which compose
weights of successive layers intertwined with suitable diagonal and invertible
matrices depending on the activation functions and their shifts. We prove that
entangled weights are completely and stably approximated by an efficient and
robust algorithm as soon as $\mathcal O(D^2 \times m)$ nonadaptive input-output
samples of the network are collected, where $D$ is the input dimension and $m$
is the number of neurons of the network. Moreover, we empirically observe that
the approach applies to networks with up to $\mathcal O(D \times m_L)$ neurons,
where $m_L$ is the number of output neurons at layer $L$. Provided knowledge of
layer assignments of entangled weights and of remaining scaling and shift
parameters, which may be further heuristically obtained by least squares, the
entangled weights identify the network completely and uniquely. To highlight
the relevance of the theoretical result of stable recovery of entangled
weights, we present numerical experiments, which demonstrate that multilayered
networks with generic weights can be robustly identified and therefore
uniformly approximated by the presented algorithmic pipeline. In contrast
backpropagation cannot generalize stably very well in this setting, being
always limited by relatively large uniform error. In terms of practical impact,
our study shows that we can relate input-output information uniquely and stably
to network parameters, providing a form of explainability. Moreover, our method
paves the way for compression of overparametrized networks and for the training
of minimal complexity networks.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:31:19 GMT""}]","2021-01-19"
"2101.07151","Katarzyna Mazowiecka","Francesca Da Lio, Katarzyna Mazowiecka, Armin Schikorra","A fractional version of Rivi\`ere's GL(N)-gauge","Revised version, accepted to AMPA",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that for antisymmetric vectorfield $\Omega$ with small $L^2$-norm
there exists a gauge $A \in L^\infty \cap \dot{W}^{1/2,2}(\mathbb{R}^1,GL(N))$
such that ${\rm div}_{\frac12} (A\Omega - d_{\frac{1}{2}} A) = 0$. This extends
a celebrated theorem by Rivi\`ere to the nonlocal case and provides
conservation laws for a class of nonlocal equations with antisymmetric
potentials, as well as stability under weak convergence.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:34:03 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 16:51:24 GMT""}]","2021-11-29"
"2101.07152","Ilie Sarpe","Ilie Sarpe, Fabio Vandin","PRESTO: Simple and Scalable Sampling Techniques for the Rigorous
  Approximation of Temporal Motif Counts","19 pages, 5 figures, to appear in SDM 2021",,,,"cs.SI cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The identification and counting of small graph patterns, called network
motifs, is a fundamental primitive in the analysis of networks, with
application in various domains, from social networks to neuroscience. Several
techniques have been designed to count the occurrences of motifs in static
networks, with recent work focusing on the computational challenges provided by
large networks. Modern networked datasets contain rich information, such as the
time at which the events modeled by the networks edges happened, which can
provide useful insights into the process modeled by the network. The analysis
of motifs in temporal networks, called temporal motifs, is becoming an
important component in the analysis of modern networked datasets. Several
methods have been recently designed to count the number of instances of
temporal motifs in temporal networks, which is even more challenging than its
counterpart for static networks. Such methods are either exact, and not
applicable to large networks, or approximate, but provide only weak guarantees
on the estimates they produce and do not scale to very large networks. In this
work we present an efficient and scalable algorithm to obtain rigorous
approximations of the count of temporal motifs. Our algorithm is based on a
simple but effective sampling approach, which renders our algorithm practical
for very large datasets. Our extensive experimental evaluation shows that our
algorithm provides estimates of temporal motif counts which are more accurate
than the state-of-the-art sampling algorithms, with significantly lower running
time than exact approaches, enabling the study of temporal motifs, of size
larger than the ones considered in previous works, on billion edges networks.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:35:12 GMT""}]","2021-01-19"
"2101.07153","Lyubov Amitonova","Matthias C. Velsink, Zhouping Lyu, Pepijn W. H. Pinkse and Lyubov V.
  Amitonova","Comparison of round- and square-core fibers for sensing, imaging and
  spectroscopy","9 pages, 5 figures","Optics Express 29, 6523-6531 (2021)","10.1364/OE.417021",,"physics.optics eess.IV","http://creativecommons.org/licenses/by/4.0/","  Multimode fibers (MMFs) show great promise as miniature probes for sensing,
imaging and spectroscopy applications. Different parameters of the fibers, such
as numerical aperture, refractive index profile and length, have been already
optimized for better performance. Here we investigate the role of the core
shape, in particular for wavefront shaping applications where a focus is formed
at the output of the MMF. We demonstrate that in contrast to a conventional
round-core MMF, a square-core design doesn't suffer from focus aberrations.
Moreover, we find that how the interference pattern behind a square-core fiber
decorrelates with the input frequency is largely independent of the input light
coupling. Finally, we demonstrate that a square core shape provides an
on-average uniform distribution of the output intensity, free from the
input-output correlations seen in round fibers, showing great promise for
imaging and spectroscopy applications.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:37:06 GMT""}]","2021-02-19"
"2101.07154","Luka C. Popovic","L.\v{C}. Popovi\'c, V. L. Afanasiev, E. S. Shablovinskaya, V. I.
  Ardilanov, Dj. Savi\'c","Spectroscopy and polarimetry of the gravitationally lensed quasar
  Q0957+561","accepted in AA","A&A 647, A98 (2021)","10.1051/0004-6361/202039914",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new spectroscopic and polarimetric observations of the first
discovered gravitational lens Q0957+561 obtained with the 6m telescope of the
Special Astrophysical Observatory (SAO, Russia). We explore spectropolarimetric
parameters of Q0957+561 A,B components to investigate the innermost structure
of the quasar, and explore the nature of polarization in lensed quasars.
Additionally, we compare their present-day spectral characteristics with
previous observations in order to study long-term spectral changes. We analyze
spectral characteristics of lensed quasar comparing spectra of A and B images,
as well as comparing previously observed image spectra with present-day ones.
The polarization parameters of A-B images are compared. We also model the
macro-lens influence on the polarization of the images representing the
gravitational lens with a singular isothermal elliptical potential.
  We find that the brightness and SED ratio of components A and B changed
during a long period. Polarization in broad lines of components A and B showed
that the equatorial scattering cannot be detected in this quasar. We find
wavelength-dependent polarization that may be explained as a combination of the
polarization from the disc and outflowing material. There is a significant
difference between polarization parameters of the A and B images: the B
component shows a higher polarization degree and polarization angle. However,
both polarization vectors are nearly perpendicular to the observed radio jet
projection. It indicates that the polarization in the continuum is coming from
the accretion disc. Our simple lensing model of a polarized source showed that
macro-lens can cause the observed differences in polarization parameters of
Q0957+561 A,B images. Using Mg II broad line and luminosity of component A we
estimated that the Q0957+561 black hole mass is M~(4.8-6.1) $10^8$ M$\odot$
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:40:01 GMT""}]","2021-03-17"
"2101.07155","Megha Khosla","Megha Khosla and Avishek Anand","Revisiting the Auction Algorithm for Weighted Bipartite Perfect
  Matchings",,,,,"cs.DS cs.DM math.CO","http://creativecommons.org/licenses/by/4.0/","  We study the classical weighted perfect matchings problem for bipartite
graphs or sometimes referred to as the assignment problem, i.e., given a
weighted bipartite graph $G = (U\cup V,E)$ with weights $w : E \rightarrow
\mathcal{R}$ we are interested to find the maximum matching in $G$ with the
minimum/maximum weight. In this work we present a new and arguably simpler
analysis of one of the earliest techniques developed for solving the assignment
problem, namely the auction algorithm. Using our analysis technique we present
tighter and improved bounds on the runtime complexity for finding an
approximate minumum weight perfect matching in $k$-left regular sparse
bipartite graphs.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:41:34 GMT""}]","2021-01-19"
"2101.07156","Max Cohen","Max Cohen and Calin Belta","Model-Based Reinforcement Learning for Approximate Optimal Control with
  Temporal Logic Specifications","To appear at the 24th ACM International Conference on Hybrid Systems:
  Computation and Control",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the problem of synthesizing optimal control policies
for uncertain continuous-time nonlinear systems from syntactically co-safe
linear temporal logic (scLTL) formulas. We formulate this problem as a sequence
of reach-avoid optimal control sub-problems. We show that the resulting hybrid
optimal control policy guarantees the satisfaction of a given scLTL formula by
constructing a barrier certificate. Since solving each optimal control problem
may be computationally intractable, we take a learning-based approach to
approximately solve this sequence of optimal control problems online without
requiring full knowledge of the system dynamics. Using Lyapunov-based tools, we
develop sufficient conditions under which our approximate solution maintains
correctness. Finally, we demonstrate the efficacy of the developed method with
a numerical example.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:45:11 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 22:54:23 GMT""}]","2021-04-16"
"2101.07157","Grigorios Loukides","Leqian Zheng and Hau Chan and Grigorios Loukides and Minming Li","Maximizing approximately k-submodular functions","To be published in SIAM International Conference on Data Mining (SDM)
  2021",,,,"cs.DS cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce the problem of maximizing approximately $k$-submodular functions
subject to size constraints. In this problem, one seeks to select $k$-disjoint
subsets of a ground set with bounded total size or individual sizes, and
maximum utility, given by a function that is ""close"" to being $k$-submodular.
The problem finds applications in tasks such as sensor placement, where one
wishes to install $k$ types of sensors whose measurements are noisy, and
influence maximization, where one seeks to advertise $k$ topics to users of a
social network whose level of influence is uncertain. To deal with the problem,
we first provide two natural definitions for approximately $k$-submodular
functions and establish a hierarchical relationship between them. Next, we show
that simple greedy algorithms offer approximation guarantees for different
types of size constraints. Last, we demonstrate experimentally that the greedy
algorithms are effective in sensor placement and influence maximization
problems.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:48:40 GMT""}]","2021-01-19"
"2101.07158","Roman Kovalchukov Mr","Roman Kovalchukov (1), Dmitri Moltchanov (1), Juho Pirskanen (2),
  Joonas Sae (1), Jussi Numminen (2), Yevgeni Koucheryavy (1), and Mikko
  Valkama (1) ((1) Tampere University, Finland, (2) Wirepas Oy, Finland)","DECT-2020 New Radio: The Next Step Towards 5G Massive Machine-Type
  Communications","Author-Submitted manuscript accepted for publication in the IEEE
  Communications Magazine, 7 pages, 5 figures, 1 table",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive machine type communications (mMTC) is one of the cornerstone services
that have to be supported by 5G systems. 3GPP has already introduced LTE-M and
NB-IoT, often referred to as cellular IoT, in 3GPP Releases 13, 14, and 15 and
submitted these technologies as part of 3GPP IMT-2020 (i.e., 5G) technology
submission to ITU-R. Even though NB-IoT and LTE-M have shown to satisfy 5G mMTC
requirements defined by ITU-R, it is expected that these cellular IoT solutions
will not address all aspects of IoT and ongoing digitalization, including the
support for direct communication between ""things"" with flexible deployments,
different business models, as well as support for even higher node densities
and enhanced coverage. In this paper, we introduce the DECT-2020 standard
recently published by ETSI for mMTC communications. We evaluate its performance
and compare it to the existing LPWAN solutions showing that it outperforms
those in terms of supported density of nodes while still keeping delay and loss
guarantees at the required level.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:49:56 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 21:08:53 GMT""},{""version"":""v3"",""created"":""Fri, 7 May 2021 16:51:39 GMT""},{""version"":""v4"",""created"":""Fri, 13 May 2022 11:44:45 GMT""}]","2022-05-16"
"2101.07159","Yifan Jia","Angela Capel and Yifan Jia","Comment on ""Generators of matrix algebras in dimension 2 and 3""","4 pages, 1 figure, comment",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theorem 7 in Ref. [Linear Algebra Appl., 430, 1-6, (2009)] states sufficient
conditions to determine whether a pair generates the algebra of 3x3 matrices
over an algebraically closed field of characteristic zero. In that case, an
explicit basis for the full algebra is provided, which is composed of words of
small length on such pair. However, we show that this theorem is wrong since it
is based on the validity of an identity which is not true in general.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:51:05 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 17:34:59 GMT""}]","2021-02-11"
"2101.07160","Johann Haidenbauer","J. Haidenbauer, G. Krein","Comment on ""$\Lambda_c N$ interaction in leading order covariant chiral
  effective field theory""","2 pages, 1 figure",,,,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Song et al. [Phys. Rev. C 102, 065208 (2020)] presented results for the
$\Lambda_c N$ interaction based on an extrapolation of lattice simulations by
the HAL QCD Collaboration at unphysical quark masses to the physical point via
covariant chiral effective field theory. We point out that their predictions
for the $^3D_1$ partial wave disagree with available lattice results. We
discuss the origin of that disagreement and present a comparison with
predictions from conventional (non-relativistic) chiral effective field theory.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:51:53 GMT""}]","2021-01-19"
"2101.07161","Jana Hofmann","Bernd Finkbeiner, Christopher Hahn, Jana Hofmann, Leander Tentrup","Realizing Omega-regular Hyperproperties","International Conference on Computer Aided Verification (CAV 2020)","=In: Lahiri S., Wang C. (eds) Computer Aided Verification. CAV
  2020. Lecture Notes in Computer Science, vol 12225","10.1007/978-3-030-53291-8_4",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied the hyperlogic HyperQPTL, which combines the concepts of trace
relations and $\omega$-regularity. We showed that HyperQPTL is very expressive,
it can express properties like promptness, bounded waiting for a grant,
epistemic properties, and, in particular, any $\omega$-regular property. Those
properties are not expressible in previously studied hyperlogics like HyperLTL.
At the same time, we argued that the expressiveness of HyperQPTL is optimal in
a sense that a more expressive logic for $\omega$-regular hyperproperties would
have an undecidable model checking problem. We furthermore studied the
realizability problem of HyperQPTL. We showed that realizability is decidable
for HyperQPTL fragments that contain properties like promptness. But still, in
contrast to the satisfiability problem, propositional quantification does make
the realizability problem of hyperlogics harder. More specifically, the
HyperQPTL fragment of formulas with a universal-existential propositional
quantifier alternation followed by a single trace quantifier is undecidable in
general, even though the projection of the fragment to HyperLTL has a decidable
realizability problem. Lastly, we implemented the bounded synthesis problem for
HyperQPTL in the prototype tool BoSy. Using BoSy with HyperQPTL specifications,
we have been able to synthesize several resource arbiters. The synthesis
problem of non-linear-time hyperlogics is still open. For example, it is not
yet known how to synthesize systems from specifications given in branching-time
hyperlogics like HyperCTL$^*$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:54:27 GMT""}]","2021-01-19"
"2101.07162","J. Maxwell Riestenberg","J. Maxwell Riestenberg","A quantified local-to-global principle for Morse quasigeodesics",,,,,"math.DG math.GT","http://creativecommons.org/licenses/by/4.0/","  In arXiv:1403.7671, Kapovich, Leeb and Porti gave several new
characterizations of Anosov representations $\Gamma \to G$, including one where
geodesics in the word hyperbolic group $\Gamma$ map to ""Morse quasigeodesics""
in the associated symmetric space $G/K$. In analogy with the negative curvature
setting, they prove a local-to-global principle for Morse quasigeodesics and
describe an algorithm which can verify the Anosov property of a given
representation in finite time. However, some parts of their proof involve
non-constructive compactness and limiting arguments, so their theorem does not
explicitly quantify the size of the local neighborhoods one needs to examine to
guarantee global Morse behavior. In this paper, we supplement their work with
estimates in the symmetric space to obtain the first explicit criteria for
their local-to-global principle. This makes their algorithm for verifying the
Anosov property effective. As an application, we demonstrate how to compute
explicit perturbation neighborhoods of Anosov representations with two
examples.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:58:27 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 21:03:43 GMT""}]","2021-03-15"
"2101.07163","Seyed Ali Hosseini","Q.Tan, S.A.Hosseini, A. Seidel-Morgenstern, D.Th\'evenin, H.Lorenz","Modeling ice crystal growth using the lattice Boltzmann method",,,"10.1063/5.0072542",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Given the multitude of growth habits, pronounced sensitivity to ambient
conditions and wide range of scales involved, snowflake crystals are one of the
most challenging systems to model. The present work focuses on the development
and validation of a coupled flow/species/phase solver based on the lattice
Boltzmann method. It is first shown that the model is able to correctly capture
species and phase growth coupling. Furthermore, through a study of crystal
growth subject to ventilation effects, it is shown that the model correctly
captures hydrodynamics-induced asymmetrical growth. The validated solver is
then used to model snowflake growth under different ambient conditions with
respect to humidity and temperature in the plate-growth regime section of the
Nakaya diagram. The resulting crystal habits are compared to both numerical and
experimental reference data available in the literature. The overall agreement
with experimental data shows that the proposed algorithm correctly captures
both the crystal shape and the onset of primary and secondary branching
instabilities. As a final part of the study the effects of forced convection on
snowflake growth are studied. It is shown, in agreement with observations in
the literature, that under such condition the crystal exhibits non-symmetrical
growth. The non-uniform humidity around the crystal due to forced convection
can even result in the coexistence of different growth modes on different sides
of the same crystal.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 16:59:13 GMT""}]","2022-01-26"
"2101.07164","Cong Xiao","Cong Xiao, Bangguo Xiong, and Qian Niu","Topological electric driving of magnetization dynamics in insulators","5 pages 4 figures; revised version with more references that are
  aware of by us only recently","Phys. Rev. B 104, 064433 (2021)","10.1103/PhysRevB.104.064433",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Established forms of electromagnetic coupling are usually conservative (in
insulators) or dissipative (in metals and semiconductors). Here we point out
the possibility of nondissipative electric driving of magnetization dynamics,
if the valence electronic states have nontrivial topology in the combined space
of crystal momentum and magnetization configuration. We provide a hybrid
insulator system to demonstrate that the topology-based nonconservative
electrical generalized force is capable of supporting sustained magnetization
motion in the presence of Gilbert damping, with quantized and steady energy
pumping into magnetization motion from the electric field. We also generalize
our results to magnetic textures, and discuss electric field induced
Dzyaloshinskii-Moriya interaction which can be nonconservative.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:00:30 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 02:34:48 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 15:28:22 GMT""}]","2021-08-25"
"2101.07165","Gianmario Broccia","Gianmario Broccia","Energy Production in Martian Environment -- Powering a Mars Direct-based
  Habitat","Paper from Master's Thesis",,,,"astro-ph.EP astro-ph.IM cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This thesis work aims to study the possibility of energy production on
Martian soil and, in particular, to establish what might be an optimal
configuration for an energy system. This goal has been contextualized in the
will to feed a scientific base, based the concept of ""Mars Direct"" (Robert
Zubrin, 1990). This habitat has been recreated in its thermal features, in
order to perform an analysis of the heat loss over a Martian year (1,88
terrestrial years). As part of this analysis, two possible scenarios have been
studied: clear sky with medium solar radiation (""sun season"") and sand storm
season (""storm season""). Subsequently, a basic life support system have been
simulated thanks to Aspen PLUS. Using the results of the thermal analysis, it
has been possible to obtain a thermal and electrical demand profile for the
Hab. After identifying every possible energy source (solar, wind, nuclear, fuel
cells, rtg), a calculation on Excel has been set with the purpose of finding
one of the configurations with the lowest possible mass and pave the way for a
further, more rigorous, optimization. It is indeed clear that shipping 1
kilogram to Mars has a cost of hundreds of thousand of dollars.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:02:21 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 21:02:31 GMT""}]","2021-05-04"
"2101.07166","K\""ur\c{s}at Tekb{\i}y{\i}k","K\""ur\c{s}at Tekb{\i}y{\i}k, G\""une\c{s} Karabulut Kurt, Halim
  Yanikomeroglu","Energy-Efficient RIS-Assisted Satellites for IoT Networks","9 pages, 6 figures",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The use of satellites to provide ubiquitous coverage and connectivity for
densely deployed Internet of Things (IoT) networks is expected to be a reality
in emerging 6G networks. Yet the low battery capacity of IoT nodes constitutes
a problem for their direct connectivity to satellites, which are located at
altitudes of up to 2000 km. In this paper, we propose a novel architecture
involving the use of reconfigurable intelligent surface (RIS) units to mitigate
the path loss associated with long transmission distances. These RIS units can
be placed on satellite reflectarrays, and, when used in broadcasting and
beamforming, they can provide significant gains in signal transmission. This
study shows that RIS-assisted satellites can provide up to 10^5 times higher
downlink and achievable uplink rates for IoT networks.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:04:08 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 07:33:45 GMT""}]","2021-05-24"
"2101.07167","Jordan Richards","Jordan Richards and Jennifer L. Wadsworth","Spatial deformation for non-stationary extremal dependence","41 pages, 10 figures","Environmetrics, e2671 (2021)","10.1002/env.2671",,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modelling the extremal dependence structure of spatial data is considerably
easier if that structure is stationary. However, for data observed over large
or complicated domains, non-stationarity will often prevail. Current methods
for modelling non-stationarity in extremal dependence rely on models that are
either computationally difficult to fit or require prior knowledge of
covariates. Sampson and Guttorp (1992) proposed a simple technique for handling
non-stationarity in spatial dependence by smoothly mapping the sampling
locations of the process from the original geographical space to a latent space
where stationarity can be reasonably assumed. We present an extension of this
method to a spatial extremes framework by considering least squares
minimisation of pairwise theoretical and empirical extremal dependence
measures. Along with some practical advice on applying these deformations, we
provide a detailed simulation study in which we propose three spatial processes
with varying degrees of non-stationarity in their extremal and central
dependence structures. The methodology is applied to Australian summer
temperature extremes and UK precipitation to illustrate its efficacy compared
to a naive modelling approach.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:16:47 GMT""}]","2021-03-04"
"2101.07168","Elena Guardo","Edoardo Ballico, Giuseppe Favacchio, Elena Guardo, Lorenzo Milazzo,
  Abu Chackalamannil Thomas","Steiner Configurations ideals: containment and colouring","15 pages, 1 figure, to be published in ""Mathematics"", Special Issue
  ""Advances in Design Theory and Applications in Combinatorial Algebraic
  Geometry""",,,,"math.AC math.AG math.CO","http://creativecommons.org/licenses/by/4.0/","  Given a homogeneous ideal $I \subseteq k[x_0,\dots,x_n]$, the Containment
problem studies the relation between symbolic and regular powers of $I$, that
is, it asks for which pair $m, r \in \mathbb{N}$, $I^{(m)} \subseteq I^r$
holds. In the last years, several conjectures have been posed on this problem,
creating an active area of current interests and ongoing investigations. In
this paper, we investigated the Stable Harbourne Conjecture and the Stable
Harbourne -- Huneke Conjecture and we show that they hold for the defining
ideal of a Complement of a Steiner configuration of points in
$\mathbb{P}^{n}_{k}$. We can also show that the ideal of a Complement of a
Steiner Configuration of points has expected resurgence, that is, its
resurgence is strictly less than its big height, and it also satisfies
Chudnovsky and Demailly's Conjectures. Moreover, given a hypergraph $H$, we
also study the relation between its colourability and the failure of the
containment problem for the cover ideal associated to $H$. We apply these
results in the case that $H$ is a Steiner System.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:17:01 GMT""}]","2021-01-19"
"2101.07169","Daniel Fernandes Gomes","Daniel Fernandes Gomes, Paolo Paoletti and Shan Luo","Generation of GelSight Tactile Images for Sim2Real Learning",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most current works in Sim2Real learning for robotic manipulation tasks
leverage camera vision that may be significantly occluded by robot hands during
the manipulation. Tactile sensing offers complementary information to vision
and can compensate for the information loss caused by the occlusion. However,
the use of tactile sensing is restricted in the Sim2Real research due to no
simulated tactile sensors being available. To mitigate the gap, we introduce a
novel approach for simulating a GelSight tactile sensor in the commonly used
Gazebo simulator. Similar to the real GelSight sensor, the simulated sensor can
produce high-resolution images by an optical sensor from the interaction
between the touched object and an opaque soft membrane. It can indirectly sense
forces, geometry, texture and other properties of the object and enables
Sim2Real learning with tactile sensing. Preliminary experimental results have
shown that the simulated sensor could generate realistic outputs similar to the
ones captured by a real GelSight sensor. All the materials used in this paper
are available at https://danfergo.github.io/gelsight-simulation.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:18:57 GMT""}]","2021-01-19"
"2101.07170","James Montaldi","Nataliya A. Balabanova, James Montaldi","Two body problem on a sphere in the presence of a uniform magnetic field","25 pages, 17 figs. This is a preprint of the Work accepted for
  publication in Regular and Chaotic Dynamics (2021). Copyright Pleiades
  Publishing Ltd, 2021",,"10.1134/S1560354721040043",,"math-ph math.DS math.MP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate the motion of one and two charged non-relativistic particles
on a sphere in the presence of a magnetic field of uniform strength. For one
particle, the motion is always circular, and determined by a simple relation
between the velocity and the radius of motion. For two identical particles,
interacting via a cotangent potential, we show there are two families of
relative equilibria, called Type I and Type II. The Type I relative equilibria
exist for all strengths of the magnetic field, while those of Type II exist
only if the field is sufficiently strong. The same is true if the particles are
of equal mass but opposite charge. We also determine the stability of the two
families of relative equilibria.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:19:10 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 12:28:27 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 15:05:12 GMT""}]","2021-09-01"
"2101.07171","Loretta del Mercato","Jenifer Pendiuk Gon\c{c}alves, Anderson Fraga da Cruz, Heloise Ribeiro
  de Barros, Beatriz Santana Borges, Lia Carolina Almeida Soares de Medeiros,
  Maurilio Jos\'e Soares, Mayara Padovan dos Santos, Marco Tadeu Grassi, Anil
  Chandra, Loretta Laureana del Mercato, Gustavo Rodrigues Rossi, Edvaldo da
  Silva Trindade, Izabel Cristina Riegel Vidotti, Carolina Camargo de Oliveira","Beyond gold nanoparticles cytotoxicity: potential to impair metastasis
  hallmarks","11 pages, 6 figures","European Journal of Pharmaceutics and Biopharmaceutics, Volume
  157, December 2020, Pages 221-232","10.1016/j.ejpb.2020.10.019",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study aimed to investigate the antitumor effect of ultrasmall gold
nanoparticles (AuNPs), around 3 nm, stabilized by the anionic polysaccharide
gum arabic (GA-AuNPs). The focus was downregulation of cancer hallmarks of
aggressive tumors, using a highly metastatic model of melanoma. We first
demonstrated that GA-AuNPs showed excellent stability under biological
environment. Non-cytotoxic concentrations to seven different cell lines,
including tumorigenic and non-tumorigenic cells, were determined by standard 2D
in vitro assays. Gold concentrations below 2.4 mg L-1 were non-cytotoxic and
therefore chosen for further analyses. Cells exposed to GA-AuNPs were uptaken
by melanoma cells through endocytic processes. Next, we described remarkable
biological properties using non-cytotoxic concentrations of this nanomaterial.
Invasion through an extracellular matrix barrier as well as 3D growth capacity
(anchorage-independent colony formation and spheroids growth) were negatively
affected by 2.4 mg L-1 GA-AuNPs. Additionally, exposed spheroids showed
morphological changes, suggesting that GA-AuNPs could penetrate into the
preformed tumor and affect its integrity. All together these results
demonstrate that side effects, such as cytotoxicity, can be avoided by choosing
the right concentration, nevertheless, preserving desirable effects such as
modulation of key tumor cell malignancy features.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:20:11 GMT""}]","2021-01-19"
"2101.07172","Chien-Hsiang Huang","Chien-Hsiang Huang, Hung-Yu Wu, and Youn-Long Lin","HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network
  that Achieves over 0.9 Mean Dice and 86 FPS",,,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a new convolution neural network called HarDNet-MSEG for polyp
segmentation. It achieves SOTA in both accuracy and inference speed on five
popular datasets. For Kvasir-SEG, HarDNet-MSEG delivers 0.904 mean Dice running
at 86.7 FPS on a GeForce RTX 2080 Ti GPU. It consists of a backbone and a
decoder. The backbone is a low memory traffic CNN called HarDNet68, which has
been successfully applied to various CV tasks including image classification,
object detection, multi-object tracking and semantic segmentation, etc. The
decoder part is inspired by the Cascaded Partial Decoder, known for fast and
accurate salient object detection. We have evaluated HarDNet-MSEG using those
five popular datasets. The code and all experiment details are available at
Github. https://github.com/james128333/HarDNet-MSEG
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:20:11 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 15:58:47 GMT""}]","2021-01-21"
"2101.07173","Ali Tajer","Ali Tajer and Avi Steiner and Shlomo Shamai (Shitz)","The Broadcast Approach in Communication Networks","149 pages, 37 figures",,"10.3390/e23010120",,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper reviews the theoretical and practical principles of the broadcast
approach to communication over state-dependent channels and networks in which
the transmitters have access to only the probabilistic description of the
time-varying states while remaining oblivious to their instantaneous
realizations. When the temporal variations are frequent enough, an effective
long-term strategy is adapting the transmission strategies to the system's
ergodic behavior. However, when the variations are infrequent, their temporal
average can deviate significantly from the channel's ergodic mode, rendering a
lack of instantaneous performance guarantees. To circumvent a lack of
short-term guarantees, the {\em broadcast approach} provides principles for
designing transmission schemes that benefit from both short- and long-term
performance guarantees. This paper provides an overview of how to apply the
broadcast approach to various channels and network models under various
operational constraints.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:22:31 GMT""}]","2021-01-19"
"2101.07174","Mohamed Wagdy Eldesouki Abdelghany","Mohamed Abdelghany and Sofiene Tahar","Formal FT-based Cause-Consequence Reliability Analysis using Theorem
  Proving","41 pages, 17 figures, 8 tables",,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  Cause-consequence Diagram (CCD) is widely used as a deductive safety analysis
technique for decision-making at the critical-system design stage. This
approach models the causes of subsystem failures in a highly-critical system
and their potential consequences using Fault Tree (FT) and Event Tree (ET)
methods, which are well-known dependability modeling techniques.
Paper-and-pencil-based approaches and simulation tools, such as the Monte-Carlo
approach, are commonly used to carry out CCD analysis, but lack the ability to
rigorously verify essential system reliability properties. In this work, we
propose to use formal techniques based on theorem proving for the formal
modeling and step-analysis of CCDs to overcome the inaccuracies of the
simulation-based analysis and the error-proneness of informal reasoning by
mathematical proofs. In particular, we use the HOL4 theorem prover, which is a
computer-based mathematical reasoning tool. To this end, we developed a
formalization of CCDs in Higher-Order Logic (HOL), based on the algebraic
approach, using HOL4. We demonstrate the practical effectiveness of the
proposed CCD formalization by performing the formal reliability analysis of the
IEEE 39-bus electrical power network. Also, we formally determine the Forced
Outage Rate (FOR) of the power generation units and the network reliability
index, i.e., System Average Interruption Duration Index (SAIDI). To assess the
accuracy of our proposed approach, we compare our results with those obtained
with MATLAB Monte-Carlo Simulation (MCS) as well as other state-of-the-art
approaches for subsystem-level reliability analysis.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:23:34 GMT""}]","2021-01-21"
"2101.07175","Wouter Caarls","Wouter Caarls","Deep Reinforcement Learning with Embedded LQR Controllers","This work has been accepted to IFAC for publication under a Creative
  Commons Licence CC-BY-NC-ND",,"10.1016/j.ifacol.2020.12.2261",,"cs.RO cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Reinforcement learning is a model-free optimal control method that optimizes
a control policy through direct interaction with the environment. For reaching
tasks that end in regulation, popular discrete-action methods are not well
suited due to chattering in the goal state. We compare three different ways to
solve this problem through combining reinforcement learning with classical LQR
control. In particular, we introduce a method that integrates LQR control into
the action set, allowing generalization and avoiding fixing the computed
control in the replay memory if it is based on learned dynamics. We also embed
LQR control into a continuous-action method. In all cases, we show that adding
LQR control can improve performance, although the effect is more profound if it
can be used to augment a discrete action set.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:28:48 GMT""}]","2021-06-23"
"2101.07177","Skyler Palatnick","Dana Jones (1), Skyler Palatnick (1), Richard Chen (1), Angus Beane
  (2), Adam Lidz (1) ((1) University of Pennsylvania department of Physics and
  Astronomy, (2) Harvard University and Smithsonian Center for Astrophysics)","Fuzzy Dark Matter and the 21cm Power Spectrum","15 pages, 12 figures, Accepted for publication to ApJ",,"10.3847/1538-4357/abf0a9",,"astro-ph.CO physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We model the 21cm power spectrum across the Cosmic Dawn and the Epoch of
Reionization (EoR) in fuzzy dark matter (FDM) cosmologies. The suppression of
small mass halos in FDM models leads to a delay in the onset redshift of these
epochs relative to cold dark matter (CDM) scenarios. This strongly impacts the
21cm power spectrum and its redshift evolution. The 21cm power spectrum at a
given stage of the EoR/Cosmic Dawn process is also modified: in general, the
amplitude of 21cm fluctuations is boosted by the enhanced bias factor of galaxy
hosting halos in FDM. We forecast the prospects for discriminating between CDM
and FDM with upcoming power spectrum measurements from HERA, accounting for
degeneracies between astrophysical parameters and dark matter properties. If
FDM constitutes the entirety of the dark matter and the FDM particle mass is
10-21eV, HERA can determine the mass to within 20 percent at 2-sigma
confidence.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:29:39 GMT""},{""version"":""v2"",""created"":""Sun, 21 Mar 2021 17:18:33 GMT""}]","2021-05-26"
"2101.07178","Sadegh Bolouki","Sadegh Arefizadeh, Sadjaad Ozgoli, Sadegh Bolouki, Tamer Ba\c{s}ar","Partial Observability Approach for the Optimal Transparency Problem in
  Multi-agent Systems","14 pages",,,,"math.DS cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers a network of agents, where each agent is assumed to take
actions optimally with respect to a predefined payoff function involving the
latest actions of the agent's neighbors. Neighborhood relationships stem from
payoff functions rather than actual communication channels between the agents.
A principal is tasked to optimize the network's performance by controlling the
information available to each agent with regard to other agents' latest
actions. The information control by the principal is done via a partial
observability approach, which comprises a static partitioning of agents into
blocks and making the mean of agents' latest actions within each block publicly
available. While the problem setup is general in terms of the payoff functions
and the network's performance metric, this paper has a narrower focus to
illuminate the problem and how it can be addressed in practice. In particular,
the performance metric is assumed to be a function of the steady-state behavior
of the agents. After conducting a comprehensive steady-state analysis of the
network, an efficient algorithm finding optimal partitions with respect to
various performance metrics is presented and validated via numerical examples.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:30:16 GMT""}]","2021-01-19"
"2101.07179","Luca Barberi","Luca Barberi and Martin Lenz","Twist-induced local curvature of filaments in DNA toroids",,,"10.1393/ncc/i2021-21123-5",,"cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  DNA toroidal bundles form upon condensation of one or multiple DNA filaments.
DNA filaments in toroidal bundles are hexagonally packed, and collectively
twist around the center line of the toroid. In a previous study, we and our
coworkers argue that the filaments' curvature locally correlates with their
density in the bundle, with the filaments less closely packed where their
curvature appears to be higher. We base our claim on the assumption that twist
has a negligible effect on the local curvature of filaments in DNA toroids.
However, this remains to be proven. We fill this gap here, by calculating the
distribution of filaments' curvature in a geometric model of twisted toroidal
bundle, which we use to describe DNA toroids by an appropriate choice of
parameters. This allows us to substantiate our previous study and suggest
directions for future experiments.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:32:51 GMT""}]","2023-01-24"
"2101.07180","D. Yogeshwaran Mr","G\""unter Last, Giovanni Peccati and D. Yogeshwaran","Phase transitions and noise sensitivity on the Poisson space via
  stopping sets and decision trees","63 pages. Some minor edits and typographical errors corrected",,,,"math.PR math-ph math.CO math.MP","http://creativecommons.org/licenses/by/4.0/","  Proofs of sharp phase transition and noise sensitivity in percolation have
been significantly simplified by the use of randomized algorithms, via the OSSS
inequality (proved by O'Donnell, Saks, Schramm and Servedio (2005)) and the
Schramm-Steif inequality for the Fourier-Walsh coefficients of functions
defined on the Boolean hypercube. In this article, we prove intrinsic versions
of the OSSS and Schramm-Steif inequalities for functionals of a general Poisson
process, and apply these new estimates to deduce sufficient conditions -
expressed in terms of randomized stopping sets - yielding sharp phase
transitions, quantitative noise sensitivity, exceptional times and bounds on
critical windows for monotonic Boolean Poisson functions. Our analysis is based
on a new general definition of `stopping set', not requiring any topological
property for the underlying measurable space, as well as on the new concept of
a `continuous-time decision tree', for which we establish several fundamental
properties. We apply our findings to the $k$-percolation of the Poisson Boolean
model and to the Poisson-based confetti percolation with bounded random grains.
In these two models, we reduce the proof of sharp phase transitions for
percolation, and of noise sensitivity for crossing events, to the construction
of suitable randomized stopping sets and the computation of one-arm
probabilities. This enables us to settle some open problem suggested by
Ahlberg, Tassion and Texeira (2018) on noise sensitivity of crossing events for
the planar Poisson Boolean model and also planar Confetti percolation model.
Further, we also prove that critical probability is $1/2$ in certain planar
confetti percolation models. A special case of this result was conjectured by
Benjamini and Schramm (1998) and proved by M\""uller (2017). Other special cases
were proven by Hirsch (2015) and Ghosh and Roy (2018).
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:33:13 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 12:26:05 GMT""},{""version"":""v3"",""created"":""Wed, 21 Sep 2022 12:03:28 GMT""}]","2022-09-22"
"2101.07181","Chao Lei","Chao Lei and Allan H. MacDonald","Gate-Tunable Quantum Anomalous Hall Effects in MnBi$_2$Te$_4$ Thin Films","13 pages, 3+6 figures","Phys. Rev. Materials 5, L051201 (2021)","10.1103/PhysRevMaterials.5.L051201",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum anomalous Hall (QAH) effect has recently been realized in thin
films of intrinsic magnetic topological insulators (IMTIs) like MnBi$_2$Te$_4$.
Here we point out that that the QAH gaps of these IMTIs can be optimized, and
that both axion insulator/semimetal and Chern insulator/semimetal transitions
can be driven by electrical gate fields on the $\sim 10$ meV/nm scale. This
effect is described by combining a simplified coupled-Dirac-cone model of
multilayer thin films with Schr{\""o}dinger-Poisson self-consistent-field
equations.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:37:04 GMT""}]","2021-10-20"
"2101.07182","Nathan Adams","N. J. Adams, R. A. A. Bowler, M. J. Jarvis, B. Hau{\ss}ler, C. D. P.
  Lagos","Evolution of the galaxy stellar mass function: evidence for an
  increasing $M^*$ from $z=2$ to the present day","19 pages, 7 figures, 8 tables, submitted to MNRAS. Updated to
  accepted version from journal",,"10.1093/mnras/stab1956",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Utilising optical and near-infrared broadband photometry covering $> 5\,{\rm
deg}^2$ in two of the most well-studied extragalactic legacy fields (COSMOS and
XMM-LSS), we measure the galaxy stellar mass function (GSMF) between $0.1 < z <
2.0$. We explore in detail the effect of two source extraction methods
(SExtractor and ProFound) in addition to the inclusion/exclusion of Spitzer
IRAC 3.6 and 4.5$\mu$m photometry when measuring the GSMF. We find that
including IRAC data reduces the number of massive ($\log_{10}(M/M_\odot) >
11.25$) galaxies found due to improved photometric redshift accuracy, but has
little effect on the more numerous lower-mass galaxies. We fit the resultant
GSMFs with double Schechter functions down to $\log_{10}(M/M_\odot)$ = 7.75
(9.75) at z = 0.1 (2.0) and find that the choice of source extraction software
has no significant effect on the derived best-fit parameters. However, the
choice of methodology used to correct for the Eddington bias has a larger
impact on the high-mass end of the GSMF, which can partly explain the spread in
derived $M^*$ values from previous studies. Using an empirical correction to
model the intrinsic GSMF, we find evidence for an evolving characteristic
stellar mass with $\delta \log_{10}(M^*/M_\odot)/\delta z$ = $-0.16\pm0.05 \,
(-0.11\pm0.05)$, when using SExtractor (ProFound). We argue that with widely
quenched star formation rates in massive galaxies at low redshift ($z<0.5$),
additional growth via mergers is required in order to sustain such an evolution
to a higher characteristic mass.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:37:34 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 13:41:31 GMT""}]","2021-08-18"
"2101.07183","Savvas Zannettou","Savvas Zannettou","""I Won the Election!"": An Empirical Analysis of Soft Moderation
  Interventions on Twitter","Accepted in the 15th AAAI Conference on Web and Social Media (ICWSM
  2021)",,,,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past few years, there is a heated debate and serious public concerns
regarding online content moderation, censorship, and the principle of free
speech on the Web. To ease these concerns, social media platforms like Twitter
and Facebook refined their content moderation systems to support soft
moderation interventions. Soft moderation interventions refer to warning labels
attached to potentially questionable or harmful content to inform other users
about the content and its nature while the content remains accessible, hence
alleviating concerns related to censorship and free speech. In this work, we
perform one of the first empirical studies on soft moderation interventions on
Twitter. Using a mixed-methods approach, we study the users who share tweets
with warning labels on Twitter and their political leaning, the engagement that
these tweets receive, and how users interact with tweets that have warning
labels. Among other things, we find that 72% of the tweets with warning labels
are shared by Republicans, while only 11% are shared by Democrats. By analyzing
content engagement, we find that tweets with warning labels had more engagement
compared to tweets without warning labels. Also, we qualitatively analyze how
users interact with content that has warning labels finding that the most
popular interactions are related to further debunking false claims, mocking the
author or content of the disputed tweet, and further reinforcing or resharing
false claims. Finally, we describe concrete examples of inconsistencies, such
as warning labels that are incorrectly added or warning labels that are not
added on tweets despite sharing questionable and potentially harmful
information.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:39:58 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 10:05:00 GMT""}]","2021-04-14"
"2101.07184","Liana David","Vicente Cort\'es and Liana David","T-duality for transitive Courant algebroids","70 pages, minor modifications with respect to the previous version",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theory of T-duality for transitive Courant algebroids. We show
that T-duality between transitive Courant algebroids E\rightarrow M and
\tilde{E}\rightarrow \tilde{M} induces a map between the spaces of sections of
the corresponding canonical weighted spinor bundles \mathbb{S}_{E} and
\mathbb{S}_{\tilde{E}} intertwining the canonical Dirac generating operators.
The map is shown to induce an isomorphism between the spaces of invariant
spinors, compatible with an isomorphism between the spaces of invariant
sections of the Courant algebroids. The notion of invariance is defined after
lifting the vertical parallelisms of the underlying torus bundles M\rightarrow
B and \tilde{M} \rightarrow B to the Courant algebroids and their spinor
bundles. We prove a general existence result for T-duals under assumptions
generalizing the cohomological integrality conditions for T-duality in the
exact case. Specializing our construction, we find that the T-dual of an exact
or a heterotic Courant algebroid is again exact or heterotic, respectively.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:41:19 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 15:45:22 GMT""}]","2021-11-24"
"2101.07185","Federico Cacciafesta","Federico Cacciafesta, \'Eric S\'er\'e, Junyong Zhang","Asymptotic estimates for the wave functions of the Dirac-Coulomb
  operator and applications","34 pages. Final version to appear in Communications in Partial
  Differential Equations",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove some uniform asymptotic estimates for confluent
hypergeometric functions making use of the steepest-descent method. As an
application, we obtain Strichartz estimates with loss of angular derivatives
for the massless Dirac-Coulomb equation in $3D$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:43:09 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 08:52:59 GMT""},{""version"":""v3"",""created"":""Sun, 27 Mar 2022 09:00:36 GMT""},{""version"":""v4"",""created"":""Thu, 23 Mar 2023 10:16:19 GMT""}]","2023-03-24"
"2101.07186","Juncheng Wei","Kelei Wang and Juncheng Wei","Refined blowup analysis and nonexistence of Type II blowups for an
  energy critical nonlinear heat equation","122 pages; comments are welcome",,,,"math.AP math.DG","http://creativecommons.org/licenses/by/4.0/","  We consider the energy critical semilinear heat equation $$
\left\{\begin{aligned} &\partial_t u-\Delta u =|u|^{\frac{4}{n-2}}u &\mbox{in }
{\mathbb R}^n\times(0,T),\\ &u(x,0)=u_0(x), \end{aligned}\right. $$ where $
n\geq 3$, $u_0\in L^\infty({\mathbb R}^n)$, and $T\in {\mathbb R}^+$ is the
first blow up time. We prove that if $ n \geq 7$ and $ u_0 \geq 0$, then any
blowup must be of Type I, i.e., \[\|u(\cdot, t)\|_{L^\infty({\mathbb R}^n)}\leq
C(T-t)^{-\frac{1}{p-1}}.\] A similar result holds for bounded convex domains.
The proof relies on a reverse inner-outer gluing mechanism and delicate
analysis of bubbling behavior (bubbling tower/cluster).
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:43:51 GMT""}]","2021-01-19"
"2101.07187","Alexandru Dimca","Alexandru Dimca, Brian Harbourne and Gabriel Sticlaru","On the Bounded Negativity Conjecture and singular plane curves","v.3. Substantially upgraded new version, having Brian Harbourne as a
  new co-author. All the results are now characteristic free, and there are new
  key examples",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are no known failures of Bounded Negativity in characteristic 0. In the
light of recent work showing the Bounded Negativity Conjecture fails in
positive characteristics for rational surfaces, we propose new characteristic
free conjectures as a replacement. We also develop bounds on numerical
characteristics of curves constraining their negativity. For example, we show
that the $H$-constant of a rational curve $C$ with at most $9$ singular points
satisfies $H(C)>-2$ regardless of the characteristic.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:44:49 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 16:54:35 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 16:16:26 GMT""}]","2021-03-23"
"2101.07188","Alan McLeay","Javier Aramayona, Christopher J. Leininger, Alan McLeay","Big mapping class groups and the co-Hopfian property","20 pages, 3 figures. Theorem 3 rephrased for clarity. Minor
  corrections",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  We study injective homomorphisms between big mapping class groups of
infinite-type surfaces. First, we construct (uncountably many) examples of
surfaces without boundary whose (pure) mapping class groups are not co-Hopfian;
these are the first examples of injective endomorphisms of mapping class groups
(of surfaces with empty boundary) that fail to be surjective.
  We then prove that, subject to some topological conditions on the domain
surface, any continuous injective homomorphism between (arbitrary) big mapping
class groups that sends Dehn twists to Dehn twists is induced by homeomorphism.
  Finally, we explore the extent to which, in stark contrast to the finite-type
case, superinjective maps between curve graphs impose no topological
restrictions on the underlying surfaces.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:48:03 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 23:27:15 GMT""},{""version"":""v3"",""created"":""Mon, 1 Mar 2021 18:03:48 GMT""}]","2021-03-02"
"2101.07189","Asbj{\o}rn Slagtern Fjellv{\aa}g","Asbjorn Slagtern Fjellvag, Oystein Slagtern Fjellvag, Yohann Breard
  and Anja Olafsen Sjastad","Structural disorder and antiferromagnetism in LaNi1-xPtxO3",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report on the B-site substitution of Pt in the system LaNi1-xPtxO3. The
system can only be synthesized for x <= 0.50, with LaNiO3 (x = 0.00) and the
stoichiometric double perovskite La2NiPtO6 (x = 0.50) as the end members.
Higher Pt-contents (x > 0.50) are unachievable due to the preference of Pt to
either be in oxidation state +IV in octahedral coordination. Upon introducing
Pt into LaNiO3, a phase transformation from rhombohedral (R-3c) to monoclinic
(P21/n) symmetry is observed for 0.075 <= x <= 0.125, where all monoclinic
samples are B-site ordered, and Pt show a strong preference for the Pt-site.
Powder X-ray diffraction analysis reveal disorder of the Pt-distribution in
several of the samples with a non-equimolar Ni/Pt ratio (0.20 <= x <= 0.40),
which point toward cluster formation with domains of high and low Pt-content
within each sample. La2NiPtO6 further show an antiferromagnetic transition at
approx. 40 K. A similar transition is observed for all monoclinic samples (x >=
0.20), however, the transition becomes weaker for lower x. This is explained in
light of the structural disorder, i.e. by the coexistence of antiferromagnetic
domains with long range order and paramagnetic domains dominated by short range
antiferromagnetic interactions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:48:27 GMT""}]","2021-01-19"
"2101.07190","Sadegh Bolouki","Mohammad-Mehdi Keramati, Elnaz Azizi, Hamidreza Momeni, Sadegh Bolouki","Incorporating Coincidental Water Data into Non-intrusive Load Monitoring","13 pages",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-intrusive load monitoring (NILM) as the process of extracting the usage
pattern of appliances from the aggregated power signal is among successful
approaches aiding residential energy management. In recent years, high volume
datasets on power profiles have become available, which has helped make
classification methods employed for the NILM purpose more effective and more
accurate. However, the presence of multi-mode appliances and appliances with
close power values have remained influential in worsening the computational
complexity and diminishing the accuracy of these algorithms. To tackle these
challenges, we propose an event-based classification process, in the first
phase of which the $K$-nearest neighbors method, as a fast classification
technique, is employed to extract power signals of appliances with exclusive
non-overlapping power values. Then, two deep learning models, which consider
the water consumption of some appliances as a novel signature in the network,
are utilized to distinguish between appliances with overlapping power values.
In addition to power disaggregation, the proposed process as well extracts the
water consumption profiles of specific appliances. To illustrate the proposed
process and validate its efficiency, seven appliances of the AMPds are
considered, with the numerical classification results showing marked
improvement with respect to the existing classification-based NILM techniques.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:49:39 GMT""}]","2021-01-19"
"2101.07191","Sadegh Bolouki","Elnaz Azizi, Mohammad T H Beheshti, Sadegh Bolouki","Quantification of Disaggregation Difficulty with Respect to the Number
  of Meters","13 pages",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A promising approach toward efficient energy management is non-intrusive load
monitoring (NILM), that is to extract the consumption profiles of appliances
within a residence by analyzing the aggregated consumption signal. Among
efficient NILM methods are event-based algorithms in which events of the
aggregated signal are detected and classified in accordance with the appliances
causing them. The large number of appliances and the presence of appliances
with close consumption values are known to limit the performance of event-based
NILM methods. To tackle these challenges, one could enhance the feature space
which in turn results in extra hardware costs, installation complexity, and
concerns regarding the consumer's comfort and privacy. This has led to the
emergence of an alternative approach, namely semi-intrusive load monitoring
(SILM), where appliances are partitioned into blocks and the consumption of
each block is monitored via separate power meters.
  While a greater number of meters can result in more accurate disaggregation,
it increases the monetary cost of load monitoring, indicating a trade-off that
represents an important gap in this field. In this paper, we take a
comprehensive approach to close this gap by establishing a so-called notion of
""disaggregation difficulty metric (DDM),"" which quantifies how difficult it is
to monitor the events of any given group of appliances based on both their
power values and the consumer's usage behavior. Thus, DDM in essence quantifies
how much is expected to be gained in terms of disaggregation accuracy of a
generic event-based algorithm by installing meters on the blocks of any
partition of the appliances. Experimental results based on the REDD dataset
illustrate the practicality of the proposed approach in addressing the
aforementioned trade-off.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:50:48 GMT""}]","2021-01-19"
"2101.07192","Marcos Curty","R\'obert Tr\'enyi, Marcos Curty","Zero-error attack against coherent-one-way quantum key distribution","12 pages, 7 figures","New J. Phys. 23, 093005 (2021)","10.1088/1367-2630/ac1e41",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent-one-way (COW) quantum key distribution (QKD) held the promise of
distributing secret keys over long distances with a simple experimental setup.
Indeed, this scheme is currently used in commercial applications. Surprisingly,
however, it has been recently shown that its secret key rate scales at most
quadratically with the system's transmittance and, thus, it is not appropriate
for long distance QKD transmission. Such pessimistic result was derived by
employing a so-called zero-error attack, in which the eavesdropper does not
introduce any error, but still the legitimate users of the system cannot
distill a secure key. Here, we present a zero-error attack against COW-QKD that
is essentially optimal, in the sense that no other attack can restrict further
its maximum achievable distance in the absence of errors. This translates into
an upper bound on its secret key rate that is more than an order of magnitude
lower than previously known upper bounds.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:51:19 GMT""}]","2021-09-22"
"2101.07193","Elena Garlatti","E. Garlatti, G. Allodi, S. Bordignon, L. Bordonali, G.A. Timco, R.E.P.
  Winpenny, A. Lascialfari, R. De Renzi, S. Carretta","Breaking the ring: $^{53}$Cr-NMR on the Cr$_{8}$Cd molecular nanomagnet",,"J. Phys.: Condens. Matter 32, 244003 (2020)","10.1088/1361-648X/ab7872",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An accurate experimental characterization of finite antiferromagnetic (AF)
spin chains is crucial for controlling and manipulating their magnetic
properties and quantum states for potential applications in spintronics or
quantum computation. In particular, finite AF chains are expected to show a
different magnetic behaviour depending on their length and topology. Molecular
AF rings are able to combine the quantum-magnetic behaviour of AF chains with a
very remarkable tunability of their topological and geometrical properties. In
this work we measure the $^{53}$Cr-NMR spectra of the Cr$_{8}$Cd ring to study
the local spin densities on the Cr sites. Cr$_{8}$Cd can in fact be considered
a model system of a finite AF open chain with an even number of spins. The NMR
resonant frequencies are in good agreement with the theoretical local spin
densities, by assuming a core polarization feld AC = -12.7 T/$\mu_B$. Moreover,
these NMR results confirm the theoretically predicted non-collinear spin
arrangement along the Cr$_{8}$Cd ring, which is typical of an even-open AF spin
chain.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:56:09 GMT""}]","2021-01-19"
"2101.07194","Katarzyna Gas","Katarzyna Gas, Janusz Sadowski, Maciej Sawicki","Magnetic properties of wurtzite (Ga,Mn)As","23 pages, 7 figures","Journal of Magnetism and Magnetic Materials 533 (2021) 168012","10.1016/j.jmmm.2021.168012",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Here we report on detailed studies of the magnetic properties of the wurtzite
(Ga,Mn)As cylindrical shells. Ga$_{0.94}$Mn$_{0.06}$As shells have been grown
by molecular beam epitaxy at low temperature as a part of multishell cylinders
overgrown on wurtzite (Ga,In)As nanowires cores, synthesized on GaAs (111)B
substrates. Our studies clearly indicate the presence of a low temperature
ferromagnetic coupling, which despite a reasonably high Mn contents of 6\% is
limited only to below 30~K. A set of dedicated measurements shows that despite
a high structural quality of the material the magnetic order has a granular
form, which gives rise to the dynamical slow-down characteristic to blocked
superparamagnets. The lack of the long range order has been assigned to a very
low hole density, caused primarily by numerous compensation donors, arsenic
antisites, formed in the material due to a specific geometry of the growth of
the shells on the nanowire template. The associated electrostatic disorder has
formed a patchwork of spontaneously magnetized (macrospin) and nonmagnetic
(paramagnetic) volumes in the material. Using high field results it has been
evaluated that the total volume taken by the macrospins constitute about 2/3 of
the volume of the (Ga,Mn)As whereas in the remaining 1/3 only paramagnetic Mn
ions reside. By establishing the number of the uncoupled ions the two
contributions were separated. The Arrott plot method applied to the
superparamagnetic part yielded the first experimental assessment of the
magnitude of the spin-spin coupling temperature within the macrospins in
(Ga,Mn)As, $T_{\mathrm{C}}=28$~K. In a broader view our results constitute an
important contribution to the still ongoing dispute on the true and the
dominant form(s) of the magnetism in this model dilute ferromagnetic
semiconductor.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:56:17 GMT""}]","2021-05-20"
"2101.07195","Sara Mardanisamani","Sara Mardanisamani, Zahra Karimi, Akram Jamshidzadeh, Mehran Yazdi,
  Melika Farshad, Amirmehdi Farshad","A New Approach for Automatic Segmentation and Evaluation of Pigmentation
  Lesion by using Active Contour Model and Speeded Up Robust Features",,,,,"eess.IV cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Digital image processing techniques have wide applications in different
scientific fields including the medicine. By use of image processing
algorithms, physicians have been more successful in diagnosis of different
diseases and have achieved much better treatment results. In this paper, we
propose an automatic method for segmenting the skin lesions and extracting
features that are associated to them. At this aim, a combination of Speeded-Up
Robust Features (SURF) and Active Contour Model (ACM), is used. In the
suggested method, at first region of skin lesion is segmented from the whole
skin image, and then some features like the mean, variance, RGB and HSV
parameters are extracted from the segmented region. Comparing the segmentation
results, by use of Otsu thresholding, our proposed method, shows the
superiority of our procedure over the Otsu theresholding method. Segmentation
of the skin lesion by the proposed method and Otsu thresholding compared the
results with physician's manual method. The proposed method for skin lesion
segmentation, which is a combination of SURF and ACM, gives the best result.
For empirical evaluation of our method, we have applied it on twenty different
skin lesion images. Obtained results confirm the high performance, speed and
accuracy of our method.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:57:42 GMT""}]","2021-01-19"
"2101.07198","Elza Bakhtigareeva","E.G.Bakhtigareeva, M.L.Goldman","Calculations of the norms for monotone operators on the cones of
  functions with monotonicity properties",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper is devoted to the problem of exact calculation of the norms in
ideal spaces for monotone operators on the cones of functions with monotonicity
properties. We implement a general approach to this problem that covers many
concrete variants of monotone operators in ideal spaces and different
monotonicity conditions for functions. As applications, we calculate the norms
of some integral operators on the cones, associate norms over some cones in
Lebesgue spaces, the norms of the dilation operator and embedding operators on
weighted Lorentz spaces with general weights. Under some more general
conditions, we present order sharp estimates for Hardy-type operators on the
cones.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:04:38 GMT""}]","2021-01-19"
"2101.07201","Andrej Pustogow","Andrej Pustogow, Yohei Saito, Anja L\""ohle, Miriam Sanz Alonso,
  Atsushi Kawamoto, Vladimir Dobrosavljevi\'c, Martin Dressel, and Simone
  Fratini","Rise and Fall of Landau's Quasiparticles While Approaching the Mott
  Transition","Main part: 8 pages, 4 figures; Supplement: 8 pages, 11 figures","Nature Communications 12, 1571 (2021)","10.1038/s41467-021-21741-z",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Landau suggested that the low-temperature properties of metals can be
understood in terms of long-lived quasiparticles with all complex interactions
included in Fermi-liquid parameters, such as the effective mass $m^{\star}$.
Despite its wide applicability, electronic transport in bad or strange metals
and unconventional superconductors is controversially discussed towards a
possible collapse of the quasiparticle concept. Here we explore the
electrodynamic response of correlated metals at half filling for varying
correlation strength upon approaching a Mott insulator. We reveal persistent
Fermi-liquid behavior with pronounced quadratic dependences of the optical
scattering rate on temperature and frequency, along with a puzzling elastic
contribution to relaxation. The strong increase of the resistivity beyond the
Ioffe-Regel-Mott limit is accompanied by a `displaced Drude peak' in the
optical conductivity. Our results, supported by a theoretical model for the
optical response, demonstrate the emergence of a bad metal from resilient
quasiparticles that are subject to dynamical localization and dissolve near the
Mott transition.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:05:16 GMT""}]","2021-03-11"
"2101.07203","Hoi Nguyen","Nicholas A. Cook and Hoi H. Nguyen","Universality of the minimum modulus for random trigonometric polynomials","46 pages, 2 figures; Discrete Analysis, October 2021",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  It has been shown in a recent work by Yakir-Zeitouni that the minimum modulus
of random trigonometric polynomials with Gaussian coefficients has a limiting
exponential distribution. We show this is a universal phenomenon. Our approach
relates the joint distribution of small values of the polynomial at a fixed
number $m$ of points on the circle to the distribution of a certain random walk
in a $4m$-dimensional phase space. Under Diophantine approximation conditions
on the angles, we obtain strong small ball estimates and a local central limit
theorem for the distribution of the walk.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:06:14 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 02:04:17 GMT""},{""version"":""v3"",""created"":""Tue, 5 Oct 2021 12:43:54 GMT""}]","2021-10-06"
"2101.07204","Alexei Pevtsov","Alexei A. Pevtsov (1), Yang Liu (2), Ilpo Virtanen (3), Luca Bertello
  (1), Kalevi Mursula (3), K.D. Leka (4,5), Anna L.H. Hughes (1) ((1) National
  Solar Observatory, 3665 Discovery Drive, 3rd Floor, Boulder, CO 80303 USA,
  (2) Stanford University, Stanford, CA, USA, (3) ReSoLVE Centre of Excellence,
  Space Climate research unit, University of Oulu, POB 3000, FIN-90014, Oulu,
  Finland, (4) NorthWest Research Associates, 3380 Mitchell Lane, Boulder, CO
  80301 USA, (5) Institute for Space-Earth Environmental Research, Nagoya
  University, Furo-cho Chikusa-ku Nagoya, Aichi 464-8601 Japan)","On a limitation of Zeeman polarimetry and imperfect instrumentation in
  representing solar magnetic fields with weaker polarization signal","13 pages, 5 figure, Journal of Space Weather and Space Climate,
  accepted, 2021",,"10.1051/swsc/2021003",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Full disk vector magnetic fields are used widely for developing better
understanding of large-scale structure, morphology, and patterns of the solar
magnetic field. The data are also important for modeling various solar
phenomena. However, observations of vector magnetic fields have one important
limitation that may affect the determination of the true magnetic field
orientation. This limitation stems from our ability to interpret the differing
character of the Zeeman polarization signals which arise from the photospheric
line-of-sight vs. the transverse components of the solar vector magnetic field,
and is likely exacerbated by unresolved structure (non-unity fill fraction) as
well as the disambiguation of the 180$^\circ$ degeneracy in the
transverse-field azimuth. Here we provide a description of this phenomenon, and
discuss issues, which require additional investigation.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:07:13 GMT""}]","2021-01-19"
"2101.07205","Jean-Baptiste Durrive","J.-B. Durrive, P. Lesaffre, T. Ghosh, B. Regaldo-Saint Blancard","A method to statistically characterize turbulent data with physically
  motivated parameters, illustrated on a centroid velocity map","15 pages, submitted to MNRAS",,,,"astro-ph.GA astro-ph.SR physics.flu-dyn physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the potential of a recently proposed model for 3D compressible
MHD turbulence (Chevillard et al. 2010; Durrive et al. 2021) to be used as a
tool to characterize statistically 2D and 3D turbulent data. This model is
parametrized by a dozen of free (intuitive, physically motivated) parameters,
which control the statistics of the fields (density, velocity and magnetic
fields). The present study is a proof of concept study: (i) we restrict
ourselves to the incompressible hydrodynamical part of the model, (ii) we
consider as data centroid velocity maps, and (iii) we let only three of the
free parameters vary (namely the correlation length, the Hurst parameter and
the intermittency parameter). Within this framework, we demonstrate that, given
a centroid velocity map, we can find in an automated manner (i.e. by a Markov
Chain Monte Carlo analysis) values of the parameters such that the model
resembles the given map, i.e. which reproduces its statistics fairly well.
Hence, thanks to this procedure, one may characterize statistically, and thus
compare, various turbulent data. In other words, we show how this model may be
used as a metric to compare observational or simulated data sets. In addition,
because this model is numerically particularly fast (nearly 500 times faster
than the numerical simulation we use to generate our reference data) it may be
used as a surrogate model. Finally, by this process we also initiate the first
systematic exploration of the parameter space of this model. Doing so, we show
how the parameters impact the visual and the statistical properties of centroid
velocity maps, and exhibit the correlations between the various parameters,
providing new insight into the model.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:08:56 GMT""}]","2021-01-19"
"2101.07207","Anastasia Sokolenko","Andres Aramburo Garcia, Kyrylo Bondarenko, Alexey Boyarsky, Dylan
  Nelson, Annalisa Pillepich, and Anastasia Sokolenko","Ultra-high energy cosmic rays deflection by the Intergalactic Magnetic
  Field",,,"10.1103/PhysRevD.104.083017",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The origin and composition of ultra-high energy cosmic rays (UHECRs) remain a
mystery. The common lore is that UHECRs are deflected from their primary
directions by the Galactic and extragalactic magnetic fields. Here we describe
an extragalactic contribution to the deflection of UHECRs that does not depend
on the strength and orientation of the initial seed field. Using the
IllustrisTNG simulations, we show that outflow-driven magnetic bubbles created
by feedback processes during galaxy formation deflect approximately half of all
$10^{20}$ eV protons by $1^{\circ}$ or more, and up to $20$-$30^{\circ}$. This
implies that the deflection in the intergalactic medium must be taken into
account in order to identify the sources of UHECRs.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:13:19 GMT""}]","2021-10-20"
"2101.07208","Frank Marsiglio","J. E. Hirsch and F. Marsiglio","Intrinsic hysteresis in the presumed superconducting transition of
  hydrides under high pressure","Paper withdrawn because we received additional information from the
  authors of Refs.[6] and [8] that supports their statements that the
  hysteresis is due to lack of thermal equilibration. Also the authors of
  Ref.[4] informed us that a diamond had cracked on or after the cooling cycle,
  resulting in an uncontrolled pressure shift that could explain the hysteresis
  in their Fig.3",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconducting transitions in the absence of magnetic field should be
non-hysteretic. Here we address the fact that the drops in electrical
resistance that have been interpreted as evidence of superconductivity in
several hydrides under high pressure (so-called ""superhydrides"") show
hysteresis. We argue that the experimental evidence shows that the observed
hysteresis cannot be attributed to experimental artifacts but is intrinsic to
the samples. Assuming that the drops in resistance signal a thermodynamic phase
transition, we argue that the presence of intrinsic thermal hysteresis
indicates that these are first order transitions, whereas for standard
superconductors the transition in the absence of applied magnetic field is
always second order. We conclude that this is another feature that
qualitatively distinguishes superhydrides from standard superconductors, in
addition to the ones that have been pointed out earlier [1,2], $assuming$ these
materials are superconductors. Alternatively and more likely, whether or not
the drops in resistance signal a thermodynamic phase transition, our analysis
indicates that superhydrides are not superconductors.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:14:27 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 15:52:42 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jan 2021 22:23:44 GMT""},{""version"":""v4"",""created"":""Tue, 26 Jan 2021 03:30:04 GMT""}]","2021-01-27"
"2101.07209","Luis Souza Jr.","Luis A. de Souza Jr., Luis C. S. Afonso, Alanna Ebigbo, Andreas
  Probst, Helmut Messmann, Robert Mendel, Christoph Palm and Jo\~ao P. Papa","Learning Visual Representations with Optimum-Path Forest and its
  Applications to Barrett's Esophagus and Adenocarcinoma Diagnosis",,,"10.1007/s00521-018-03982-0",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we introduce the unsupervised Optimum-Path Forest (OPF)
classifier for learning visual dictionaries in the context of Barrett's
esophagus (BE) and automatic adenocarcinoma diagnosis. The proposed approach
was validated in two datasets (MICCAI 2015 and Augsburg) using three different
feature extractors (SIFT, SURF, and the not yet applied to the BE context
A-KAZE), as well as five supervised classifiers, including two variants of the
OPF, Support Vector Machines with Radial Basis Function and Linear kernels, and
a Bayesian classifier. Concerning MICCAI 2015 dataset, the best results were
obtained using unsupervised OPF for dictionary generation using supervised OPF
for classification purposes and using SURF feature extractor with accuracy
nearly to 78% for distinguishing BE patients from adenocarcinoma ones.
Regarding the Augsburg dataset, the most accurate results were also obtained
using both OPF classifiers but with A-KAZE as the feature extractor with
accuracy close to 73%. The combination of feature extraction and
bag-of-visual-words techniques showed results that outperformed others obtained
recently in the literature, as well as we highlight new advances in the related
research area. Reinforcing the significance of this work, to the best of our
knowledge, this is the first one that aimed at addressing computer-aided BE
identification using bag-of-visual-words and OPF classifiers, being this
application of unsupervised technique in the BE feature calculation the major
contribution of this work. It is also proposed a new BE and adenocarcinoma
description using the A-KAZE features, not yet applied in the literature.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:15:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 20:41:20 GMT""}]","2021-01-21"
"2101.07211","Amina Hussein","A.E. Hussein, A.V. Arefiev, T. Batson, H. Chen, R.S. Craxton, A.S.
  Davies, D.H. Froula, Z.Gong, D. Haberberger, Y. Ma, P.M. Nilson, W. Theobald,
  T. Wang, K. Weichman, G.J. Williams, L.Willingale","Towards the Optimisation of Direct Laser Acceleration","21 pages, 7 figures",,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experimental measurements using the OMEGA EP laser facility demonstrated
direct laser acceleration (DLA) of electron beams to (505 $\pm$ 75) MeV with
(140 $\pm$ 30)~nC of charge from a low-density plasma target using a 400 J,
picosecond duration pulse. Similar trends of electron energy with target
density are also observed in self-consistent two-dimensional particle-in-cell
simulations. The intensity of the laser pulse is sufficiently large that the
electrons are rapidly expelled from along the laser pulse propagation axis to
form a channel. The dominant acceleration mechanism is confirmed to be DLA and
the effect of quasi-static channel fields on energetic electron dynamics is
examined. A strong channel magnetic field, self-generated by the accelerated
electrons, is found to play a comparable role to the transverse electric
channel field in defining the boundary of electron motion.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:16:53 GMT""}]","2021-01-19"
"2101.07212","Xin Wang","Xin Wang and Juan Liu and Feng Gao and Zhizhen Zhang","The dynamic energy balance in earthquakes expressed by fault surface
  morphology",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  The dynamic energy balance is essential for earthquake studies. The energy
balance approach is one of the most famous developments in fracture mechanics.
To interpret seismological data, crack models and sliding on a frictional
surface (fault) models are widely used. The macroscopically observable energy
budget and the microscopic processes can be related through the fracture energy
$G_c$. The fault surface morphology is the direct result of the microscopic
processes near the crack tip or on the frictional interface. Here we show that
the dynamic energy balance in earthquakes can be expressed by fault surface
morphology, and that they are quantitatively linked. The direct shear
experiments proves the predictions of the theoretical discussions, and show
that the strain rate has crucial influence on the dynamic energy balance.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:17:42 GMT""}]","2021-01-19"
"2101.07213","Manuel Pavon Valderrama","Fang-Zheng Peng, Mario S\'anchez S\'anchez, Mao-Jun Yan, Manuel Pavon
  Valderrama","Heavy-hadron molecular spectrum from light-meson exchange saturation","13 pages, 1 table; corresponds to the published version","Phys. Rev. D 105, 034028 (2022)","10.1103/PhysRevD.105.034028",,"hep-ph hep-ex hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If known, the spectrum of heavy-hadron molecules will be a key tool to
disentangle the nature of the exotic states that are being discovered in
experiments. Here we argue that the general features of the molecular spectrum
can be deduced from the idea that the short-range interaction between the heavy
hadrons is effectively described by scalar and vector meson exchange, i.e. the
$\sigma$, $\omega$ and $\rho$ mesons. By means of a contact-range theory where
the couplings are saturated by the aforementioned light mesons we are indeed
able to postdict the $X(3872)$ (as a $D^* \bar{D}$ molecule) from the three
$P_c(4312)$, $P_c(4440)$ and $P_c(4457)$ pentaquarks (as $\bar{D}\Sigma_c$ and
$\bar{D}^* \Sigma_c$ molecules). We predict a $J^{PC} = 1^{--}$ $D \bar{D}_1$
molecule at $4240-4260\,{\rm MeV}$ which might support the hypothesis that the
$Y(4260)$ is at least partly molecular. The extension of these ideas to the
light baryons requires minor modifications, after which we recover approximate
SU(4)-Wigner symmetry in the two-nucleon system and approximately reproduce the
masses of the deuteron and the virtual state.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:17:43 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 18:46:19 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 13:12:52 GMT""}]","2022-03-01"
"2101.07221","Jyotishman Bhowmick","Jyotishman Bhowmick, Debashish Goswami and Soumalya Joardar","Levi-Civita connections for conformally deformed metrics on tame
  differential calculi","Most of the results were included in arxiv 1606.08142 which has now
  been split into two parts. New results include a short proof for existence of
  Levi-Civita connections on conformally deformed metrics and an equivalent
  criterion of metric-compatibility of a connection on tame differential
  calculi",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a tame differential calculus over a noncommutative algebra
$\mathcal{A}$ and an $\mathcal{A}$-bilinear pseudo-Riemannian metric $g_0,$
consider the conformal deformation $ g = k. g_0, $ $k$ being an invertible
element of $\mathcal{A}.$We prove that there exists a unique connection
$\nabla$ on the bimodule of one-forms of the differential calculus which is
torsionless and compatible with $g.$ We derive a concrete formula connecting
$\nabla$ and the Levi-Civita connection for the pseudo-Riemannian metric $g_0.$
As an application, we compute the Ricci and scalar curvature for a general
conformal perturbation of the canonical metric on the noncommutative $2$-torus
as well as for a natural metric on the quantum Heisenberg manifold. For the
latter, the scalar curvature turns out to be a negative constant.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:21:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 05:47:49 GMT""}]","2021-01-20"
"2101.07222","Brendon Lutnick","Brendon Lutnick, David Manthey, and Pinaki Sarder","A tool for user friendly, cloud based, whole slide image segmentation","7 pages, 4 figures, and 26 references. We are currently preparing it
  for submission in a peer reviewed journal",,,,"eess.IV q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Convolutional neural networks, the state of the art for image segmentation,
have been successfully applied to histology images by many computational
researchers. However, the translatability of this technology to clinicians and
biological researchers is limited due to the complex and undeveloped user
interface of the code, as well as the extensive computer setup required. As an
extension of our previous work (arXiv:1812.07509), we have developed a tool for
segmentation of whole slide images (WSIs) with an easy to use graphical user
interface. Our tool runs a state-of-the-art convolutional neural network for
segmentation of WSIs in the cloud. Our plugin is built on the open source tool
HistomicsTK by Kitware Inc. (Clifton Park, NY), which provides remote data
management and viewing abilities for WSI datasets. The ability to access this
tool over the internet will facilitate widespread use by computational
non-experts. Users can easily upload slides to a server where our plugin is
installed and perform human in the loop segmentation analysis remotely. This
tool is open source, and has the ability to be adapted to segment of any
pathological structure. For a proof of concept, we have trained it to segment
glomeruli from renal tissue images, achieving an F-score > 0.97 on holdout
tissue slides.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:21:31 GMT""}]","2021-01-19"
"2101.07223","Simon Pietro Romano","Diego Antonelli, Roberta Cascella, Gaetano Perrone, Simon Pietro
  Romano, Antonio Schiano","Leveraging AI to optimize website structure discovery during Penetration
  Testing",,,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dirbusting is a technique used to brute force directories and file names on
web servers while monitoring HTTP responses, in order to enumerate server
contents. Such a technique uses lists of common words to discover the hidden
structure of the target website. Dirbusting typically relies on response codes
as discovery conditions to find new pages. It is widely used in web application
penetration testing, an activity that allows companies to detect websites
vulnerabilities. Dirbusting techniques are both time and resource consuming and
innovative approaches have never been explored in this field. We hence propose
an advanced technique to optimize the dirbusting process by leveraging
Artificial Intelligence. More specifically, we use semantic clustering
techniques in order to organize wordlist items in different groups according to
their semantic meaning. The created clusters are used in an ad-hoc implemented
next-word intelligent strategy. This paper demonstrates that the usage of
clustering techniques outperforms the commonly used brute force methods.
Performance is evaluated by testing eight different web applications. Results
show a performance increase that is up to 50% for each of the conducted
experiments.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:21:42 GMT""}]","2021-01-19"
"2101.07224","Tim Davidge","T. J. Davidge","The Lop-sided Spiral Galaxy NGC 247: Clues to a Possible Interaction
  with NGC 253","To appear in the Astronomical Journal",,"10.3847/1538-3881/abd40b",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations that span a broad range of wavelengths are used to examine
asymmetries in the disk of the nearby late-type spiral galaxy NGC 247. The
northern spiral arm is over-luminous at all wavelengths when compared with
other parts of the galaxy at similar galactocentric radii, while the density of
very luminous red stars in the void that is immediately south of this arm
matches that in other parts of the disk at the same galactocentric radius. Two
bubbles with spatial extents of many kpc are identified in the disk, and many
of the young stars in the southern disk of NGC 247 are located in the walls of
one of these structures. Dynamical age estimates of these bubbles coincide with
the last large-scale star formation event in the nucleus, suggesting that there
was large-scale star formation throughout the disk of NGC 247 a few hundred Myr
in the past. Morphological similarities are seen with the classical lop-sided
galaxy NGC 4027, and it is concluded that NGC 247 is a significantly lop-sided
spiral galaxy. The void in the northern disk is then the area between the main
body of the disk and the northern arm viewed in projection. The implications of
a lop-sided morphology for NGC 247 in the context of interactions with its
nearby starburst galaxy companion NGC 253 are discussed.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:22:49 GMT""}]","2021-02-10"
"2101.07225","Andre Vieira","Andre P. Vieira, Eric Goles, Hans J. Herrmann","Phase transitions in a conservative Game of Life","To appear in Physical Review E","Phys. Rev. E 103, 012132 (2021)","10.1103/PhysRevE.103.012132",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the dynamics of a conservative version of Conway's Game of
Life, in which a pair consisting of a dead and a living cell can switch their
states following Conway's rules but only by swapping their positions,
irrespective of their mutual distance. Our study is based on square-lattice
simulations as well as a mean-field calculation. As the density of dead cells
is increased, we identify a discontinuous phase transition between an inactive
phase, in which the dynamics freezes after a finite time, and an active phase,
in which the dynamics persists indefinitely in the thermodynamic limit. Further
increasing the density of dead cells leads the system back to an inactive phase
via a second transition, which is continuous on the square lattice but
discontinuous in the mean-field limit.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:23:53 GMT""}]","2021-02-03"
"2101.07226","Zeliang Liu","Zeliang Liu","Cell division in deep material networks applied to multiscale strain
  localization modeling","38 pages, 21 figures",,"10.1016/j.cma.2021.113914",,"cs.CE cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the increasing importance of strain localization modeling (e.g.,
failure analysis) in computer-aided engineering, there is a lack of effective
approaches to capturing relevant material behaviors consistently across
multiple length scales. We aim to address this gap within the framework of deep
material networks (DMN) -- a machine learning model with embedded mechanics in
the building blocks. A new cell-division scheme is proposed to track the scale
transition through the network, and its consistency is ensured by the physics
of fitting parameters. Essentially, each microscale node in the bottom layer is
described by an ellipsoidal cell with its dimensions back-propagated from the
macroscale material point. New crack surfaces in the cell are modeled by
enriching cohesive layers, and failure algorithms are developed for crack
initiation and evolution in the implicit DMN analysis. Besides studies on a
single material point, we apply the multiscale model to concurrent multiscale
simulations for the dynamic crush of a particle-reinforced composite tube and
various tests on carbon fiber reinforced polymer composites. For the latter,
experimental validations on an off-axis tensile test specimen are also
provided.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:24:51 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 18:29:11 GMT""}]","2021-06-16"
"2101.07227","Raz Slutsky","Alexander Lubotzky, Raz Slutsky","On the Asymptotic Number of Generators of High Rank Arithmetic Lattices",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  $ $Abert, Gelander and Nikolov [AGN17] conjectured that the number of
generators $d(\Gamma)$ of a lattice $\Gamma$ in a high rank simple Lie group
$H$ grows sub-linearly with $v = \mu(H / \Gamma)$, the co-volume of $\Gamma$ in
$H$. We prove this for non-uniform lattices in a very strong form, showing that
for $2-$generic such $H$'s, $d(\Gamma) = O_H(\log v / \log \log v)$, which is
essentially optimal. While we can not prove a new upper bound for uniform
lattices, we will show that for such lattices one can not expect to achieve a
better bound than $d(\Gamma) = O(\log v)$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:25:25 GMT""}]","2021-01-19"
"2101.07228","Anuj Kumar","Michael S. Jolly, Anuj Kumar, Vincent R. Martinez","On the existence, uniqueness, and smoothing of solutions to the
  generalized SQG equations in critical Sobolev spaces","34 pages and 1 figure",,"10.1007/s00220-021-04124-9",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the dissipative generalized surface quasi-geostrophic
equations in a supercritical regime where the order of the dissipation is small
relative to order of the velocity, and the velocities are less regular than the
advected scalar by up to one order of derivative. We also consider a
non-degenerate modification of the endpoint case in which the velocity is less
smooth than the advected scalar by slightly more than one order. The existence
and uniqueness theory of these equations in the borderline Sobolev spaces is
addressed, as well as the instantaneous smoothing effect of their corresponding
solutions. In particular, it is shown that solutions emanating from initial
data belonging to these Sobolev classes immediately enter a Gevrey class. Such
results appear to be the first of its kind for a quasilinear parabolic equation
whose coefficients are of higher order than its linear term; they rely on an
approximation scheme which modifies the flux in such a way that preserves the
underlying commutator structure lost by having to work in the critical space
setting, as well as delicate adaptations of well-known commutator estimates to
Gevrey classes.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:25:31 GMT""}]","2021-07-21"
"2101.07229","Guillaume St-Onge","Guillaume St-Onge, Hanlin Sun, Antoine Allard, Laurent
  H\'ebert-Dufresne, Ginestra Bianconi","Universal nonlinear infection kernel from heterogeneous exposure on
  higher-order networks","21 pages, 9 figures","Phys. Rev. Lett. 127, 158301 (2021)","10.1103/PhysRevLett.127.158301",,"physics.soc-ph nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The colocation of individuals in different environments is an important
prerequisite for exposure to infectious diseases on a social network. Standard
epidemic models fail to capture the potential complexity of this scenario by
(1) neglecting the higher-order structure of contacts which typically occur
through environments like workplaces, restaurants, and households; and by (2)
assuming a linear relationship between the exposure to infected contacts and
the risk of infection. Here, we leverage a hypergraph model to embrace the
heterogeneity of environments and the heterogeneity of individual participation
in these environments. We find that combining heterogeneous exposure with the
concept of minimal infective dose induces a universal nonlinear relationship
between infected contacts and infection risk. Under nonlinear infection
kernels, conventional epidemic wisdom breaks down with the emergence of
discontinuous transitions, super-exponential spread, and hysteresis.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:29:28 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 12:53:13 GMT""},{""version"":""v3"",""created"":""Tue, 27 Jul 2021 17:07:09 GMT""}]","2021-10-13"
"2101.07230","Tanmoy Bhattacharya","Tanmoy Bhattacharya, Vincenzo Cirigliano, Rajan Gupta, Emanuele
  Mereghetti and Boram Yoon (Los Alamos National Laboratory)","Contribution of the QCD $\Theta$-term to nucleon electric dipole moment","27 pages, 21 figures","Phys. Rev. D 103, 114507 (2021)","10.1103/PhysRevD.103.114507","LA-UR-20-30515","hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a calculation of the contribution of the $\Theta$-term to the
neutron and proton electric dipole moments using seven 2+1+1-flavor HISQ
ensembles. We also estimate the topological susceptibility for the 2+1+1 theory
to be $\chi_Q = (66(9)(4) \rm MeV)^4$ in the continuum limit at $M_\pi = 135$
MeV. The calculation of the nucleon three-point function is done using
Wilson-clover valence quarks. The CP-violating form factor $F_3$ is calculated
by expanding in small $\Theta$. We show that lattice artifacts introduce a term
proportional to $a$ that does not vanish in the chiral limit, and we include
this in our chiral-continuum fits. A chiral perturbation theory analysis shows
that the $N(0) \pi(0)$ state should provide the leading excited state
contribution, and we study the effect of such a state. Detailed analysis of the
contributions to the neutron and proton electric dipole moment using two
strategies for removing excited state contamination are presented. Using the
excited state spectrum from fits to the two-point function, we find
$d_n^\Theta$ is small, $|d_n^\Theta| \lesssim 0.01 \overline \Theta e$ fm,
whereas for the proton we get $|d_p^\Theta| \sim 0.02 \overline \Theta e$ fm.
On the other hand, if the dominant excited-state contribution is from the $N
\pi$ state, then $|d_n^\Theta|$ could be as large as $0.05 \overline \Theta e$
fm and $|d_p^\Theta| \sim 0.07 \overline \Theta e$ fm. Our overall conclusion
is that present lattice QCD calculations do not provide a reliable estimate of
the contribution of the $\Theta$-term to the nucleon electric dipole moments,
and a factor of ten higher statistics data are needed to get better control
over the systematics and possibly a $3\sigma$ result.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:30:01 GMT""}]","2021-06-16"
"2101.07231","Nima TaheriNejad","Simon Michael Laube and Nima TaheriNejad","Device Variability Analysis for Memristive Material Implication",,,,,"cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Currently, memristor devices suffer from variability between devices and from
cycle to cycle. In this work, we study the impact of device variations on
memristive Material Implication (IMPLY). New constraints for different
parameters and variables are analytically derived and compared to extensive
simulation results, covering single gate and 1T1R crossbar structures. We show
that a static analysis based on switching conditions is not sufficient for an
overall assessment of robustness against device variability. Furthermore, we
outline parameter ranges within which the IMPLY gate is predicted to produce
correct output values. Our study shows that threshold voltage is the most
critical parameter. This work helps scientists and engineers to understand the
pitfalls of designing reliable IMPLY-based calculation units better and design
them with more ease. Moreover, these analyses can be used to determine whether
a certain memristor technology is suitable for implementation of IMPLY-based
circuits and systems.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:31:43 GMT""}]","2021-01-19"
"2101.07232","Felix Klein","Gideon Geier, Philippe Heim, Felix Klein, Bernd Finkbeiner","Syntroids: Synthesizing a Game for FPGAs using Temporal Logic
  Specifications",,,,,"cs.LO cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Syntroids, a case study for the automatic synthesis of hardware
from a temporal logic specification. Syntroids is a space shooter arcade game
realized on an FPGA, where the control flow architecture has been completely
specified in Temporal Stream Logic (TSL) and implemented using reactive
synthesis. TSL is a recently introduced temporal logic that separates control
and data. This leads to scalable synthesis, because the cost of the synthesis
process is independent of the complexity of the handled data.
  In this case study, we report on our experience with the TSL-based
development of the Syntroids game and on the implementation quality obtained
with synthesis in comparison to manual programming. We also discuss solved and
open challenges with respect to currently available synthesis tools.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:35:25 GMT""}]","2021-01-19"
"2101.07233","Yang P. Liu","Yu Gao, Yang P. Liu, Richard Peng","Fully Dynamic Electrical Flows: Sparse Maxflow Faster Than Goldberg-Rao","78 pages, v2. Fixes an issue relating to handling of adaptivity and
  randomness -- we thank Aaron Sidford for discussions during which this error
  was pointed out",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an algorithm for computing exact maximum flows on graphs with $m$
edges and integer capacities in the range $[1, U]$ in
$\widetilde{O}(m^{\frac{3}{2} - \frac{1}{328}} \log U)$ time. For sparse graphs
with polynomially bounded integer capacities, this is the first improvement
over the $\widetilde{O}(m^{1.5} \log U)$ time bound from [Goldberg-Rao JACM
`98].
  Our algorithm revolves around dynamically maintaining the augmenting
electrical flows at the core of the interior point method based algorithm from
[M\k{a}dry JACM `16]. This entails designing data structures that, in limited
settings, return edges with large electric energy in a graph undergoing
resistance updates.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:38:34 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 03:19:18 GMT""}]","2021-06-11"
"2101.07234","Roberto Tanzi","Roberto Tanzi and Domenico Giulini","Asymptotic symmetries of scalar electrodynamics and of the abelian Higgs
  model in Hamiltonian formulation","We have modified the first part of section 2 and expanded sections
  4.4 and 4.5. In addition, we have corrected a few typos, including a wrong
  index in equation (2.7). The results and the conclusions are unchanged.
  Accepted on JHEP",,"10.1007/JHEP08(2021)117",,"hep-th gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the asymptotic symmetry group of a scalar field
minimally-coupled to an abelian gauge field using the Hamiltonian formulation.
This extends previous work by Henneaux and Troessaert on the pure
electromagnetic case. We deal with minimally coupled massive and massless
scalar fields and find that they behave differently insofar as the latter do
not allow for canonically implemented asymptotic boost symmetries. We also
consider the abelian Higgs model and show that its asymptotic canonical
symmetries reduce to the Poincar\'e group in an unproblematic fashion.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:38:41 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 14:42:20 GMT""}]","2021-09-15"
"2101.07235","Jean-Francois Rajotte","Jean-Francois Rajotte, Sumit Mukherjee, Caleb Robinson, Anthony Ortiz,
  Christopher West, Juan Lavista Ferres, Raymond T Ng","Reducing bias and increasing utility by federated generative modeling of
  medical images using a centralized adversary","10 pages, 10 figures",,,,"stat.ML cs.AI cs.CV cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a
generative mechanism enabling collaborative learning. In particular, we show
how a data owner with limited and biased data could benefit from other data
owners while keeping data from all the sources private. This is a common
scenario in medical image analysis where privacy legislation prevents data from
being shared outside local premises. FELICIA works for a large family of
Generative Adversarial Networks (GAN) architectures including vanilla and
conditional GANs as demonstrated in this work. We show that by using the
FELICIA mechanism, a data owner with limited image samples can generate
high-quality synthetic images with high utility while neither data owners has
to provide access to its data. The sharing happens solely through a central
discriminator that has access limited to synthetic data. Here, utility is
defined as classification performance on a real test set. We demonstrate these
benefits on several realistic healthcare scenarions using benchmark image
datasets (MNIST, CIFAR-10) as well as on medical images for the task of skin
lesion classification. With multiple experiments, we show that even in the
worst cases, combining FELICIA with real data gracefully achieves performance
on par with real data while most results significantly improves the utility.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:40:46 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 01:20:38 GMT""}]","2021-08-31"
"2101.07236","C. S. Shahbazi","C. Lazaroiu and C. S. Shahbazi","The duality covariant geometry and DSZ quantization of abelian gauge
  theory","51 pages",,,,"math.DG hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We develop the Dirac-Schwinger-Zwanziger (DSZ) quantization of classical
abelian gauge theories with general duality structure on oriented Lorentzian
four-manifolds $(M,g)$ of arbitrary topology, obtaining, as a result, the
duality-covariant geometric formulation of such theories through connections on
principal bundles. We implement the DSZ condition by restricting the field
strengths of the theory to those which define classes originating in the
degree-two cohomology of a local system valued in the groupoid of integral
symplectic spaces. We prove that such field strengths are curvatures of
connections $\mathcal{A}$ defined on principal bundles $P$ whose structure
group $G$ is the disconnected group of automorphisms of an integral affine
symplectic torus. The connected component of the identity of $G$ is a torus
group, while its group of connected components is a modified Siegel modular
group. This formulation includes electromagnetic and magnetoelectric gauge
potentials on an equal footing and describes the equations of motion through a
first-order polarized self-duality condition for the curvature of
$\mathcal{A}$. The condition involves a combination of the Hodge operator of
$(M,g)$ with a taming of the duality structure determined by $P$, whose choice
encodes the self-couplings of the theory. This description is reminiscent of
the theory of four-dimensional euclidean instantons, even though we consider a
two-derivative theory in Lorentzian signature. We use this formulation to
characterize the hierarchy of duality groups of abelian gauge theory, providing
a gauge-theoretic description of the electromagnetic duality group as the
discrete remnant of the gauge group of $P$. We also perform the time-like
reduction of the polarized self-duality condition to a Riemannian
three-manifold, obtaining a new type of Bogomolny equation which we solve
explicitly in a particular case.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:44:52 GMT""}]","2021-01-19"
"2101.07237","Matthew Ferland","Kyle Burke, Matthew Ferland, and Shanghua Teng","Transverse Wave: an impartial color-propagation game inspired by Social
  Influence and Quantum Nim","29 Pages",,,,"cs.CC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study a colorful, impartial combinatorial game played on a
two-dimensional grid, Transverse Wave. We are drawn to this game because of its
apparent simplicity, contrasting intractability, and intrinsic connection to
two other combinatorial games, one inspired by social influence and another
inspired by quantum superpositions.
  More precisely, we show that Transverse Wave is at the intersection of
social-influence-inspired Friend Circle and superposition-based Demi-Quantum
Nim. Transverse Wave is also connected with Schaefer's logic game Avoid True.
In addition to analyzing the mathematical structures and computational
complexity of Transverse Wave, we provide a web-based version of the game,
playable at
https://turing.plymouth.edu/~kgb1013/DB/combGames/transverseWave.html.
Furthermore, we formulate a basic network-influence inspired game, called
Demographic Influence, which simultaneously generalizes Node-Kyles and
Demi-Quantum Nim (which in turn contains as special cases Nim, Avoid True, and
Transverse Wave). These connections illuminate the lattice order, induced by
special-case/generalization relationships over mathematical games, fundamental
to both the design and comparative analyses of combinatorial games.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:45:03 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 20:29:33 GMT""}]","2021-01-21"
"2101.07238","Sam Mellick","Sam Mellick","The Palm groupoid of a point process and factor graphs on amenable and
  Property (T) groups","37 pages, 3 figures",,,,"math.GR math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a probability measure preserving and r-discrete groupoid that is
associated to every invariant point process on a locally compact and second
countable group. This groupoid governs certain factor processes of the point
process, in particular the existence of Cayley factor graphs. With this method
we are able to show that point processes on amenable groups admit all (and only
admit) Cayley factor graphs of amenable groups, and that the Poisson point
process on groups with Kazhdan's Property (T) admits no Cayley factor graphs.
This gives examples of pmp countable Borel equivalence relations that cannot be
generated by any free action of a countable group.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:45:51 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 08:50:30 GMT""}]","2021-01-20"
"2101.07239","Kevin Zumbrun","Aric Wheeler and Kevin Zumbrun","Convective Turing Bifurcation",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the approach pioneered by Eckhaus, Mielke, Schneider, and others
for reaction diffusion systems [E, M1, M2, S1, S2, SZJV], we systematically
derive formally by multiscale expansion and justify rigorously by
Lyapunov-Schmidt reduction amplitude equations describing Turing-type
bifurcations of general reaction diffusion convection systems. Notably, our
analysis includes also higher-order, nonlocal, and even certain semilinear
hyperbolic systems.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:46:10 GMT""}]","2021-01-19"
"2101.07240","Svetlana Kutuzova","Svetlana Kutuzova, Oswin Krause, Douglas McCloskey, Mads Nielsen,
  Christian Igel","Multimodal Variational Autoencoders for Semi-Supervised Learning: In
  Defense of Product-of-Experts",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Multimodal generative models should be able to learn a meaningful latent
representation that enables a coherent joint generation of all modalities
(e.g., images and text). Many applications also require the ability to
accurately sample modalities conditioned on observations of a subset of the
modalities. Often not all modalities may be observed for all training data
points, so semi-supervised learning should be possible. In this study, we
propose a novel product-of-experts (PoE) based variational autoencoder that
have these desired properties. We benchmark it against a mixture-of-experts
(MoE) approach and an approach of combining the modalities with an additional
encoder network. An empirical evaluation shows that the PoE based models can
outperform the contrasted models. Our experiments support the intuition that
PoE models are more suited for a conjunctive combination of modalities.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:47:43 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 11:45:08 GMT""}]","2021-08-02"
"2101.07241","Haoyu Xiong","Haoyu Xiong, Quanzhou Li, Yun-Chun Chen, Homanga Bharadhwaj, Samarth
  Sinha, Animesh Garg","Learning by Watching: Physical Imitation of Manipulation Skills from
  Human Videos","Project Website: https://www.pair.toronto.edu/lbw-kp/","IROS 2021",,,"cs.RO cs.CV cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Learning from visual data opens the potential to accrue a large range of
manipulation behaviors by leveraging human demonstrations without specifying
each of them mathematically, but rather through natural task specification. In
this paper, we present Learning by Watching (LbW), an algorithmic framework for
policy learning through imitation from a single video specifying the task. The
key insights of our method are two-fold. First, since the human arms may not
have the same morphology as robot arms, our framework learns unsupervised human
to robot translation to overcome the morphology mismatch issue. Second, to
capture the details in salient regions that are crucial for learning state
representations, our model performs unsupervised keypoint detection on the
translated robot videos. The detected keypoints form a structured
representation that contains semantically meaningful information and can be
used directly for computing reward and policy learning. We evaluate the
effectiveness of our LbW framework on five robot manipulation tasks, including
reaching, pushing, sliding, coffee making, and drawer closing. Extensive
experimental evaluations demonstrate that our method performs favorably against
the state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:50:32 GMT""},{""version"":""v2"",""created"":""Sun, 14 Nov 2021 15:05:21 GMT""}]","2021-11-16"
"2101.07242","Reem Khojah","Reem Khojah, Darren Lo, Fiona Tang, and Dino Di Carlo","The Evolution of Flow and Mass Transport in 3D Confined Cavities","5 pages",,,,"physics.flu-dyn physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Flow in channels and ducts with adjoining cavities are common in natural and
engineered systems. Here we report numerical and experimental results of 3D
confined cavity flow, identifying critical conditions in the recirculating flow
formation and mass transport over a range of channel flow properties ($0.1\leq
Re \leq 300$) and cavity aspect ratio ($0.1 \leq H/X_{s} \leq1$). In contrast
to 2D systems, a mass flux boundary is not formed in 3D confined cavity-channel
flow. Streamlines directly enter a recirculating vortex in the cavity and exit
to the main channel leading to an exponential increase in the cavity mass flux
when the recirculating vortex fills the cavity volume. These findings extend
our understanding of flow entry and exit in cavities and suggest conditions
where convective mass transport into and out of cavities would be amplified and
vortex particle capture reduced.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:53:01 GMT""}]","2021-01-19"
"2101.07243","Zhuo Chen","Di Luo, Zhuo Chen, Kaiwen Hu, Zhizhen Zhao, Vera Mikyoung Hur, and
  Bryan K. Clark","Gauge Invariant and Anyonic Symmetric Autoregressive Neural Networks for
  Quantum Lattice Models",,"Physical Review Research 5 (1), 013216 (2023)",,,"cond-mat.str-el cond-mat.dis-nn cs.LG hep-lat quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetries such as gauge invariance and anyonic symmetry play a crucial role
in quantum many-body physics. We develop a general approach to constructing
gauge invariant or anyonic symmetric autoregressive neural networks, including
a wide range of architectures such as Transformer and recurrent neural network,
for quantum lattice models. These networks can be efficiently sampled and
explicitly obey gauge symmetries or anyonic constraint. We prove that our
methods can provide exact representation for the ground and excited states of
the 2D and 3D toric codes, and the X-cube fracton model. We variationally
optimize our symmetry incorporated autoregressive neural networks for ground
states as well as real-time dynamics for a variety of models. We simulate the
dynamics and the ground states of the quantum link model of $\text{U(1)}$
lattice gauge theory, obtain the phase diagram for the 2D $\mathbb{Z}_2$ gauge
theory, determine the phase transition and the central charge of the
$\text{SU(2)}_3$ anyonic chain, and also compute the ground state energy of the
$\text{SU(2)}$ invariant Heisenberg spin chain. Our approach provides powerful
tools for exploring condensed matter physics, high energy physics and quantum
information science.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:55:21 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 23:40:37 GMT""},{""version"":""v3"",""created"":""Fri, 7 Apr 2023 19:50:29 GMT""}]","2023-04-11"
"2101.07244","Ivan Panin","Ivan Panin","A short exact sequence","arXiv admin note: text overlap with arXiv:1707.01763, arXiv:1406.1129",,,,"math.AG math.KT","http://creativecommons.org/licenses/by/4.0/","  Let R be a regular semi-local integral domain containing a field and K be its
fraction field. Let mu: G --> T be an R-group schemes morphism between
reductive R-group schemes, which is smooth as a scheme morphism. Suppose that T
is an R-torus.Then the map T(R)/mu(G(R)) --> T(K)/mu(G(K)) is injective and
certain purity theorem is true.These and other results are derived from an
extended form of Grothendieck--Serre conjecture proven in the present paper for
rings R as above.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:55:32 GMT""}]","2021-01-19"
"2101.07245","Karim Alexander Adiprasito","Karim Adiprasito and Stavros Argyrios Papadakis and Vasiliki Petrotou","Anisotropy, biased pairings, and the Lefschetz property for
  pseudomanifolds and cycles","20 pages. Proof for cycles moved to the main part",,,,"math.CO math.AC math.AG math.AT","http://creativecommons.org/licenses/by/4.0/","  We prove the hard Lefschetz property for pseudomanifolds and cycles in any
characteristic with respect to an appropriate Artinian reduction. The proof is
a combination of Adiprasito's biased pairing theory and a generalization of a
formula of Papadakis-Petrotou to arbitrary characteristic. In particular, we
prove the Lefschetz theorem for doubly Cohen Macaulay complexes, solving a
generalization of the g-conjecture due to Stanley. We also provide a simplified
presentation of the characteristic 2 case, and generalize it to pseudomanifolds
and cycles.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:55:53 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 13:35:38 GMT""}]","2021-05-26"
"2101.07246","Caio Marcellos Mr.","Caio Felippe Curitiba Marcellos, Gerson Francisco da Silva Junior,
  Elvis do Amaral Soares, Fabio Ramos, Amaro G. Barreto Jr","PyEquIon: A Python Package For Automatic Speciation Calculations of
  Aqueous Electrolyte Solutions","27 total pages; 9 images",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In several industrial applications, such as crystallization, pollution
control, and flow assurance, an accurate understanding of the aqueous
electrolyte solutions is crucial. Electrolyte equilibrium calculation
contributes with the design and optimization of processes by providing
important information, such as species concentration, solution pH and potential
for solid formation. In this work, a pure Python library distributed under
BSD-3 license was developed for the calculation of aqueous electrolyte
equilibrium. The package takes as inputs the feed components of a given
solution, and it automatically identifies its composing ions and the chemical
reactions involved to calculate equilibrium conditions. Moreover, there is no
established electrolyte activity coefficient model for a broad range of
operational conditions. Hence, in this package, built-in activity coefficient
models are structured in a modular approach, so that the non-ideality
calculation can be performed by a user provided function, which allows further
research in the topic. The package can be used by researchers to readily
identify the equilibrium reactions and possible solid phases in a user friendly
language.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:55:55 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 18:00:09 GMT""}]","2021-05-12"
"2101.07247","Ruben Melcher","Jan Kurkofka and Ruben Melcher","Countably determined ends and graphs","17 pages, 2 figures",,,,"math.CO math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The directions of an infinite graph $G$ are a tangle-like description of its
ends: they are choice functions that choose compatibly for all finite vertex
sets $X\subseteq V(G)$ a component of $G-X$. Although every direction is
induced by a ray, there exist directions of graphs that are not uniquely
determined by any countable subset of their choices. We characterise these
directions and their countably determined counterparts in terms of star-like
substructures or rays of the graph. Curiously, there exist graphs whose
directions are all countably determined but which cannot be distinguished all
at once by countably many choices. We structurally characterise the graphs
whose directions can be distinguished all at once by countably many choices,
and we structurally characterise the graphs which admit no such countably many
choices. Our characterisations are phrased in terms of normal trees and
tree-decompositions. Our four (sub)structural characterisations imply
combinatorial characterisations of the four classes of infinite graphs that are
defined by the first and second axiom of countability applied to their end
spaces: the two classes of graphs whose end spaces are first countable or
second countable, respectively, and the complements of these two classes.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:56:03 GMT""}]","2021-01-19"
"2101.07248","Emre I\c{s}{\i}k","H.V. \c{S}enavc{\i}, T. K{\i}l{\i}\c{c}o\u{g}lu, E. I\c{s}{\i}k,
  G.A.J. Hussain, D. Montes, E. Bahar, S.K. Solanki","Observing and modelling the young solar analogue EK Draconis: starspot
  distribution, elemental abundances, and evolutionary status","15 pages, 16 figures, accepted for publication in MNRAS; corrections
  in Abstract and Introduction",,"10.1093/mnras/stab199",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations and modelling of stars with near-solar masses in their early
phases of evolution is critical for a better understanding of how dynamos of
solar-type stars evolve. We examine the chemical composition and the spot
distribution of the pre-main-sequence solar analogue EK Dra. Using spectra from
the HERMES Spectrograph (La Palma), we obtain the abundances of 23 elements
with respect to the solar ones, which lead to a $[{\rm Fe/H}]=0.03$, with
significant overabundance of Li and Ba. The s-process elements Sr, Y, and Ce
are marginally overabundant, while Co, Ni, Cu, Zn are marginally deficient
compared to solar abundances. The overabundance of Ba is most likely due to the
assumption of depth-independent microturbulent velocity. Li abundance is
consistent with the age and the other abundances may indicate distinct initial
conditions of the pre-stellar nebula. We estimate a mass of 1.04 $M_\odot$ and
an age of $27^{+11}_{-8}$\,Myr using various spectroscopic and photometric
indicators. We study the surface distribution of dark spots, using 17 spectra
collected during 15 nights using the CAFE Spectrograph (Calar Alto). We also
conduct flux emergence and transport (FEAT) simulations for EK Dra's parameters
and produce 15-day-averaged synoptic maps of the likely starspot distributions.
Using Doppler imaging, we reconstruct the surface brightness distributions for
the observed spectra and FEAT simulations, which show overall agreement for
polar and mid-latitude spots, while in the simulations there is a lack of
low-latitude spots compared to the observed image. We find indications that
cross-equatorial extensions of mid-latitude spots can be artefacts of the less
visible southern-hemisphere activity.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:56:59 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 12:10:42 GMT""}]","2021-02-03"
"2101.07249","Ieva Dau\v{z}ickait\.e","Ieva Dau\v{z}ickait\.e, Amos S. Lawless, Jennifer A. Scott, and Peter
  Jan van Leeuwen","Randomised preconditioning for the forcing formulation of weak
  constraint 4D-Var",,,"10.1002/qj.4151",,"math.NA cs.NA math.OC","http://creativecommons.org/licenses/by/4.0/","  There is growing awareness that errors in the model equations cannot be
ignored in data assimilation methods such as four-dimensional variational
assimilation (4D-Var). If allowed for, more information can be extracted from
observations, longer time windows are possible, and the minimisation process is
easier, at least in principle. Weak constraint 4D-Var estimates the model error
and minimises a series of linear least-squares cost functionsfunctions, which
can be achieved using the conjugate gradient (CG) method; minimising each cost
function is called an inner loop. CG needs preconditioning to improve its
performance. In previous work, limited memory preconditioners (LMPs) have been
constructed using approximations of the eigenvalues and eigenvectors of the
Hessian in the previous inner loop. If the Hessian changes significantly in
consecutive inner loops, the LMP may be of limited usefulness. To circumvent
this, we propose using randomised methods for low rank eigenvalue decomposition
and use these approximations to cheaply construct LMPs using information from
the current inner loop. Three randomised methods are compared. Numerical
experiments in idealized systems show that the resulting LMPs perform better
than the existing LMPs. Using these methods may allow more efficient and robust
implementations of incremental weak constraint 4D-Var.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:57:11 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 15:08:22 GMT""}]","2021-11-24"
"2101.07250","Xujun Liu","Xujun Liu, Olgica Milenkovic, George V. Moustakides","Query-Based Selection of Optimal Candidates under the Mallows Model","28 pages, 2 figures, 2 tables",,,,"stat.ME cs.DM cs.IT math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the secretary problem in which rank-ordered lists are generated by
the Mallows model and the goal is to identify the highest-ranked candidate
through a sequential interview process which does not allow rejected candidates
to be revisited. The main difference between our formulation and existing
models is that, during the selection process, we are given a fixed number of
opportunities to query an infallible expert whether the current candidate is
the highest-ranked or not. If the response is positive, the selection process
terminates, otherwise, the search continues until a new potentially optimal
candidate is identified. Our optimal interview strategy, as well as the
expected number of candidates interviewed and the expected number of queries
used, can be determined through the evaluation of well-defined recurrence
relations. Specifically, if we are allowed to query $s-1$ times and to make a
final selection without querying (thus, making $s$ selections in total) then
the optimum scheme is characterized by $s$ thresholds that depend on the
parameter $\theta$ of the Mallows distribution but are independent on the
maximum number of queries.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:58:10 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 17:34:09 GMT""},{""version"":""v3"",""created"":""Thu, 2 Mar 2023 12:46:39 GMT""}]","2023-03-03"
"2101.07251","Furkan Gursoy","Furkan G\""ursoy, Mounir Haddad, C\'ecile Bothorel","Alignment and stability of embeddings: measurement and inference
  improvement",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representation learning (RL) methods learn objects' latent embeddings where
information is preserved by distances. Since distances are invariant to certain
linear transformations, one may obtain different embeddings while preserving
the same information. In dynamic systems, a temporal difference in embeddings
may be explained by the stability of the system or by the misalignment of
embeddings due to arbitrary transformations. In the literature, embedding
alignment has not been defined formally, explored theoretically, or analyzed
empirically. Here, we explore the embedding alignment and its parts, provide
the first formal definitions, propose novel metrics to measure alignment and
stability, and show their suitability through synthetic experiments. Real-world
experiments show that both static and dynamic RL methods are prone to produce
misaligned embeddings and such misalignment worsens the performance of dynamic
network inference tasks. By ensuring alignment, the prediction accuracy raises
by up to 90% in static and by 40% in dynamic RL methods.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:58:59 GMT""}]","2021-01-19"
"2101.07252","Joel Zinn","Joel C. Zinn","Validation of the Gaia Early Data Release 3 parallax zero-point model
  with asteroseismology","Published in AJ","The Astronomical Journal, Volume 161, Issue 5 (2020)","10.3847/1538-3881/abe936",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Gaia Early Data Release 3 (EDR3) provides trigonometric parallaxes for
1.5 billion stars, with reduced systematics compared to Gaia Data Release 2 and
reported precisions better by up to a factor of two. New to EDR3 is a tentative
model for correcting the parallaxes of magnitude-, position-, and
color-dependent systematics for five- and six-parameter astrometric solutions,
$Z_5$ and $Z_6$. Using a sample of over 2,000 first-ascent red giant branch
stars with asteroseismic parallaxes, I perform an independent check of the
$Z_5$ model in a Gaia magnitude range of $9 \lesssim G \lesssim 13$ and color
range of $1.4\mu \mathrm{m} ^{-1} \lesssim \nu_{\mathrm{eff}} \lesssim 1.5 \mu
\mathrm{m} ^{-1}$. This analysis therefore bridges the Gaia team's consistency
check of $Z_5$ for $G > 13$, and indications from independent analysis using
Cepheids of a $\approx 15 \mu \mathrm{as}$ over-correction for $G < 11$. I find
an over-correction sets in at $G \lesssim 10.8$, such that $Z_5$-corrected EDR3
parallaxes are larger than asteroseismic parallaxes by $15 \pm 3 \mu
\mathrm{as}$. For $G \gtrsim 10.8$, EDR3 and asteroseismic parallaxes in the
Kepler field agree up to a constant consistent with expected spatial variations
in EDR3 parallaxes after a linear, color-dependent adjustment. I also infer an
average under-estimation of EDR3 parallax uncertainties in the sample of $22
\pm 6\%$, consistent with the Gaia team's estimates at similar magnitudes and
independent analysis using wide binaries. Finally, I extend the Gaia team's
parallax spatial covariance model to brighter magnitudes ($G < 13$) and smaller
scales (down to $\approx 0.1\deg$), where systematic EDR3 parallax
uncertainties are at least $\approx 3-4 \mu \mathrm{as}$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:59:01 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 17:39:20 GMT""},{""version"":""v3"",""created"":""Mon, 26 Apr 2021 20:14:35 GMT""}]","2021-04-28"
"2101.07253","Maximilian Jaritz","Maximilian Jaritz, Tuan-Hung Vu, Raoul de Charette, \'Emilie Wirbel,
  and Patrick P\'erez","Cross-modal Learning for Domain Adaptation in 3D Semantic Segmentation","TPAMI 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain adaptation is an important task to enable learning when labels are
scarce. While most works focus only on the image modality, there are many
important multi-modal datasets. In order to leverage multi-modality for domain
adaptation, we propose cross-modal learning, where we enforce consistency
between the predictions of two modalities via mutual mimicking. We constrain
our network to make correct predictions on labeled data and consistent
predictions across modalities on unlabeled target-domain data. Experiments in
unsupervised and semi-supervised domain adaptation settings prove the
effectiveness of this novel domain adaptation strategy. Specifically, we
evaluate on the task of 3D semantic segmentation from either the 2D image, the
3D point cloud or from both. We leverage recent driving datasets to produce a
wide variety of domain adaptation scenarios including changes in scene layout,
lighting, sensor setup and weather, as well as the synthetic-to-real setup. Our
method significantly improves over previous uni-modal adaptation baselines on
all adaption scenarios. Our code is publicly available at
https://github.com/valeoai/xmuda_journal
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:59:21 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 12:19:05 GMT""}]","2022-06-23"
"2101.07254","Julio Parra-Martinez","Zvi Bern, Julio Parra-Martinez, Radu Roiban, Michael S. Ruf,
  Chia-Hsien Shen, Mikhail P. Solon, Mao Zeng","Scattering Amplitudes and Conservative Binary Dynamics at ${\cal
  O}(G^4)$","5 pages + references, 2 figures, 1 table. Hamiltonian coefficients in
  Mathematica attachment. v2: published version","Phys. Rev. Lett. 126, 171601 (2021)","10.1103/PhysRevLett.126.171601","CALT-TH-2021-004, FR-PHENO-2021-03, OUTP-21-03P","hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using scattering amplitudes, we obtain the potential contributions to
conservative binary dynamics in general relativity at fourth post-Minkowskian
order, ${\cal O}(G^4)$. As in previous lower-order calculations, we harness
powerful tools from the modern scattering amplitudes program including
generalized unitarity, the double copy, and advanced multiloop integration
methods, in combination with effective field theory. The classical amplitude
involves polylogarithms with up to transcendental weight two and elliptic
integrals. We derive the radial action directly from the amplitude, and
determine the corresponding Hamiltonian in isotropic gauge. Our results are in
agreement with known overlapping terms up to sixth post-Newtonian order, and
with the probe limit. We also determine the post-Minkowskian energy loss from
radiation emission at ${\cal O}(G^3)$ via its relation to the tail effect.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:59:31 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 20:36:18 GMT""}]","2021-05-20"
"2101.07255","Julio Parra-Martinez","Enrico Herrmann, Julio Parra-Martinez, Michael S. Ruf, Mao Zeng","Gravitational Bremsstrahlung from Reverse Unitarity","5 pages + references, 3 figures. v2: published version","Phys. Rev. Lett. 126, 201602 (2021)","10.1103/PhysRevLett.126.201602","CALT-TH-2021-003, FR-PHENO-2021-02, OUTP-21-02P","hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the total radiated momentum carried by gravitational waves during
the scattering of two spinless black holes at the lowest order in Newton's
constant, $\mathcal O(G^3)$, and all orders in velocity. By analytic
continuation into the bound state regime, we obtain the ${\cal O}(G^3)$ energy
loss in elliptic orbits. This provides an essential step towards the complete
understanding of the third-post-Minkowskian binary dynamics. We employ the
formalism of Kosower, Maybee, and O'Connell (KMOC) which relates classical
observables to quantum scattering amplitudes and derive the relevant integrands
using generalized unitarity. The subsequent phase-space integrations are
performed via the reverse unitarity method familiar from collider physics,
using differential equations to obtain the exact velocity dependence from
near-static boundary conditions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:59:44 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 20:26:22 GMT""}]","2021-05-20"
"2101.07261","Hugo Daniel Macedo","John Fitzgerald, Tomohiro Oda, and Hugo Daniel Macedo","Proceedings of the 18th International Overture Workshop",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This volume contains the papers presented at the 18th International Overture
Workshop, held online on 7th December 2020. This event was the latest in a
series of workshops around the Vienna Development Method (VDM), the open-source
project Overture, and related tools and formalisms. VDM is one of the longest
established formal methods for systems development. A lively community of
researchers and practitioners has grown up in academia and industry has grown
around the modelling languages (VDM-SL, VDM++, VDM-RT, CML) and tools
(VDMTools, Overture, Crescendo, Symphony, the INTO-CPS chain, and ViennaTalk).
Together, these provide a platform for work on modelling and analysis
technology that includes static and dynamic analysis, test generation,
execution support, and model checking. This workshop provided updates on the
emerging technology of VDM/Overture, including collaboration infrastructure,
collaborative modelling and co-simulation for Cyber-Physical Systems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:35:46 GMT""}]","2021-01-20"
"2101.07262","Yin-Chen He","Yin-Chen He, Junchen Rong, and Ning Su","A roadmap for bootstrapping critical gauge theories: decoupling
  operators of conformal field theories in $d>2$ dimensions","V2 update: the bootstrap island of scalar QED in 3d has been produced
  in this version (see Fig. 3)!","SciPost Phys. 11, 111 (2021)","10.21468/SciPostPhys.11.6.111",,"hep-th cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We propose a roadmap for bootstrapping conformal field theories (CFTs)
described by gauge theories in dimensions $d>2$. In particular, we provide a
simple and workable answer to the question of how to detect the gauge group in
the bootstrap calculation. Our recipe is based on the notion of
\emph{decoupling operator}, which has a simple (gauge) group theoretical
origin, and is reminiscent of the null operator of $2d$ Wess-Zumino-Witten CFTs
in higher dimensions. Using the decoupling operator we can efficiently detect
the rank (i.e. color number) of gauge groups, e.g., by imposing gap conditions
in the CFT spectrum. We also discuss the physics of the equation of motion,
which has interesting consequences in the CFT spectrum as well. As an
application of our recipes, we study a prototypical critical gauge theory,
namely the scalar QED which has a $U(1)$ gauge field interacting with critical
bosons. We show that the scalar QED can be solved by conformal bootstrap,
namely we have obtained its kinks and islands in both $d=3$ and $d=2+\epsilon$
dimensions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 01:06:58 GMT""},{""version"":""v3"",""created"":""Wed, 4 Aug 2021 18:30:40 GMT""}]","2021-12-29"
"2101.07263","Benjamin Nachman","Benjamin Nachman and Jesse Thaler","E Pluribus Unum Ex Machina: Learning from Many Collider Events at Once","17 pages, 10 figures, 1 table; v2: added footnote about GAN training
  and added exponential example in appendix; v3: minor updates to match journal
  version","Phys. Rev. D 103, 116013 (2021)","10.1103/PhysRevD.103.116013","MIT-CTP 5271","physics.data-an hep-ex hep-ph stat.ML","http://creativecommons.org/licenses/by/4.0/","  There have been a number of recent proposals to enhance the performance of
machine learning strategies for collider physics by combining many distinct
events into a single ensemble feature. To evaluate the efficacy of these
proposals, we study the connection between single-event classifiers and
multi-event classifiers under the assumption that collider events are
independent and identically distributed (IID). We show how one can build
optimal multi-event classifiers from single-event classifiers, and we also show
how to construct multi-event classifiers such that they produce optimal
single-event classifiers. This is illustrated for a Gaussian example as well as
for classification tasks relevant for searches and measurements at the Large
Hadron Collider. We extend our discussion to regression tasks by showing how
they can be phrased in terms of parametrized classifiers. Empirically, we find
that training a single-event (per-instance) classifier is more effective than
training a multi-event (per-ensemble) classifier, as least for the cases we
studied, and we relate this fact to properties of the loss function gradient in
the two cases. While we did not identify a clear benefit from using multi-event
classifiers in the collider context, we speculate on the potential value of
these methods in cases involving only approximate independence, as relevant for
jet substructure studies.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 05:09:40 GMT""},{""version"":""v3"",""created"":""Sun, 20 Jun 2021 17:42:10 GMT""}]","2021-06-23"
"2101.07264","Jerome P. Gauntlett","Igal Arav, K. C. Matthew Cheung, Jerome P. Gauntlett, Matthew M.
  Roberts and Christopher Rosen","A new family of $AdS_4$ S-folds in type IIB string theory","56 pages, 13 figures; very minor changes, published version",,"10.1007/JHEP05(2021)222","Imperial/TP/2021/JG/01; ICCUB-20-XXX","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct infinite new classes of $AdS_4\times S^1\times S^5$ solutions of
type IIB string theory which have non-trivial $SL(2,\mathbb{Z})$ monodromy
along the $S^1$ direction. The solutions are supersymmetric and holographically
dual, generically, to $\mathcal{N}=1$ SCFTs in $d=3$. The solutions are first
constructed as $AdS_4\times \mathbb{R}$ solutions in $D=5$ $SO(6)$ gauged
supergravity and then uplifted to $D=10$. Unlike the known $AdS_4\times
\mathbb{R}$ S-fold solutions, there is no continuous symmetry associated with
the $\mathbb{R}$ direction. The solutions all arise as limiting cases of Janus
solutions of $d=4$, $\mathcal{N}=4$ SYM theory which are supported both by a
different value of the coupling constant on either side of the interface, as
well as by fermion and boson mass deformations. As special cases, the
construction recovers three known S-fold constructions, preserving
$\mathcal{N}=1,2$ and 4 supersymmetry, as well as a recently constructed
$\mathcal{N}=1$ $AdS_4\times S^1\times S^5$ solution (not S-folded). We also
present some novel ""one-sided Janus"" solutions that are non-singular.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 14:46:27 GMT""}]","2023-01-11"
"2101.07265","Kaloian Lozanov","Peter Adshead and Kaloian D. Lozanov","Self-gravitating Vector Dark Matter","15 pages (9+6), 5 figures; matches published version","Phys. Rev. D 103, 103501 (2021)","10.1103/PhysRevD.103.103501",,"gr-qc astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive the non-relativistic limit of a massive vector field. We show that
the Cartesian spatial components of the vector behave as three identical,
non-interacting scalar fields. We find classes of spherical, cylindrical, and
planar self-gravitating vector solitons in the Newtonian limit. The
gravitational properties of the lowest-energy vector solitons$\mathrm{-}$the
gravitational potential and density field$\mathrm{-}$depend only on the net
mass of the soliton and the vector particle mass. In particular, these
self-gravitating, ground-state vector solitons are independent of the
distribution of energy across the vector field components, and are
indistinguishable from their scalar-field counterparts. Fuzzy Vector Dark
Matter models can therefore give rise to halo cores with identical
observational properties to the ones in scalar Fuzzy Dark Matter models. We
also provide novel hedgehog vector soliton solutions, which cannot be observed
in scalar-field theories. The gravitational binding of the lowest-energy
hedgehog halo is about three times weaker than the ground-state vector soliton.
Finally, we show that no spherically symmetric solitons exist with a
divergence-free vector field.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 19:26:41 GMT""}]","2021-07-09"
"2101.07266","Imran Nasim","Imran Nasim, Cristobal Petrovich, Adam Nasim, Fani Dosopoulou, Fabio
  Antonini","Formation of counter-rotating and highly eccentric massive black hole
  binaries in galaxy mergers","Accepted in MNRAS",,"10.1093/mnras/stab351",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supermassive black hole (SMBH) binaries represent the main target for
missions such as the Laser Interferometer Space Antenna and Pulsar Timing
Arrays. The understanding of their dynamical evolution prior to coalescence is
therefore crucial to improving detection strategies and for the astrophysical
interpretation of the gravitational wave data. In this paper, we use
high-resolution $N$-body simulations to model the merger of two equal-mass
galaxies hosting a central SMBH. In our models, all binaries are initially
prograde with respect to the galaxy sense of rotation. But, binaries that form
with a high eccentricity, $e\gtrsim 0.7$, quickly reverse their sense of
rotation and become almost perfectly retrograde at the moment of binary
formation. The evolution of these binaries proceeds towards larger
eccentricities, as expected for a binary hardening in a counter-rotating
stellar distribution. Binaries that form with lower eccentricities remain
prograde and at comparatively low eccentricities. We study the origin of the
orbital flip by using an analytical model that describes the early stages of
binary evolution. This model indicates that the orbital plane flip is due to
the torque from the triaxial background mass distribution that naturally arises
from the galactic merger process. Our results imply the existence of a
population of SMBH binaries with a high eccentricity and could have significant
implications for the detection of the gravitational wave signal emitted by
these systems.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 20:55:28 GMT""}]","2021-02-17"
"2101.07267","Lennart Bittel","Lennart Bittel and Martin Kliesch","Training variational quantum algorithms is NP-hard","8+4 pages, 1 Figure","Phys. Rev. Lett. 127, 120502 (2021)","10.1103/PhysRevLett.127.120502",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational quantum algorithms are proposed to solve relevant computational
problems on near term quantum devices. Popular versions are variational quantum
eigensolvers and quantum ap- proximate optimization algorithms that solve
ground state problems from quantum chemistry and binary optimization problems,
respectively. They are based on the idea of using a classical computer to train
a parameterized quantum circuit. We show that the corresponding classical
optimization problems are NP-hard. Moreover, the hardness is robust in the
sense that, for every polynomial time algorithm, there are instances for which
the relative error resulting from the classical optimization problem can be
arbitrarily large assuming P $\neq$ NP. Even for classically tractable systems
composed of only logarithmically many qubits or free fermions, we show the
optimization to be NP-hard. This elucidates that the classical optimization is
intrinsically hard and does not merely inherit the hardness from the ground
state problem. Our analysis shows that the training landscape can have many far
from optimal persistent local minima. This means that gradient and higher order
descent algorithms will generally converge to far from optimal solutions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 09:16:58 GMT""}]","2022-04-15"
"2101.07268","William C. C. Lima","Jos Gibbons, Atsushi Higuchi and William C. C. Lima","Infrared problem in the Faddeev-Popov-ghost propagator in perturbative
  quantum gravity in de Sitter spacetime","21 pages. Discussion improved and references added; matches published
  version","Phys. Rev. D 103, 065016 (2021)","10.1103/PhysRevD.103.065016",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The propagators for the Faddeev-Popov (FP) ghosts in Yang-Mills theory and
perturbative gravity in the covariant gauge are infrared (IR) divergent in de
Sitter spacetime. An IR cutoff in the momentum space to regularize these
divergences breaks the de Sitter invariance. These IR divergences are due to
the spatially constant modes in the Yang-Mills case and the modes proportional
to the Killing vectors in the case of perturbative gravity. It has been
proposed that these IR divergences can be removed, with the de Sitter
invariance preserved, by first regularizing them with an additional mass term
for the FP ghosts and then taking the massless limit. In the Yang-Mills case,
this procedure has been shown to correspond to requiring that the physical
states, and the vacuum state in particular, be annihilated by some conserved
charges in the Landau gauge. In this paper we show that there are similar
conserved charges in perturbative gravity in the covariant Landau gauge in de
Sitter spacetime and that the IR-regularization procedure described above also
correspond to requiring that the vacuum state be annihilated by these charges
with a natural definition of the interacting vacuum state.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 16:04:39 GMT""}]","2021-03-30"
"2101.07269","James Jackman","James A. G. Jackman, Evgenya Shkolnik, R. O. Parke Loyd","Stellar flares from blended and neighbouring stars in Kepler short
  cadence observations","10 pages, 2 figures, 2 tables. Accepted for publication in the
  Monthly Notices of the Royal Astronomical Society",,"10.1093/mnras/stab166",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of a search for stellar flares from stars neighbouring
the target sources in the Kepler short cadence data. These flares have been
discarded as contaminants in previous surveys and therefore provide an
unexplored resource of flare events, in particular high energy events from
faint stars. We have measured M dwarf flare energies up to 1.5$\times$10^35
erg, pushing the limit for flare energies measured using Kepler data. We have
used our sample to study theflaring activity of wide binaries, finding that the
lower mass counterpart in a wide binary flares more often at a given energy. Of
the 4430 flares detected in our original search, 298 came from a neighbouring
star, a rate of 6.7$\pm$0.4 per cent for the Kepler short cadence lightcurves.
We have used our sample to estimate a 5.8$\pm$0.1 per cent rate of false
positive flare events in studies using TESS short cadence data.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""}]","2021-02-03"
"2101.07270","Melissa van Beekveld","Melissa van Beekveld, Eric Laenen, Jort Sinninghe Damst\'e, Leonardo
  Vernazza","Next-to-leading power threshold corrections for finite order and
  resummed colour-singlet cross sections","Code available at github.com/melli1992/resummation",,"10.1007/JHEP05(2021)114","Nikhef/2021-001","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study next-to-leading-power (NLP) threshold corrections in colour-singlet
production processes, with particular emphasis on Drell-Yan (DY) and
single-Higgs production. We assess the quality of the partonic and hadronic
threshold expansions for each process up to NNLO. We determine numerically the
NLP leading-logarithmic (LL) resummed contribution in addition to the
leading-power next-to-next-to-leading logarithmic (LP NNLL) resummed DY and
Higgs cross sections, matched to NNLO. We find that the inclusion of NLP
logarithms is numerically more relevant than increasing the precision to
N$^3$LL at LP for these processes. We also perform an analytical and numerical
comparison of LP NNLL + NLP LL resummation in soft-collinear effective theory
and direct QCD, where we achieve excellent analytical and numerical agreement
once the NLP LL terms are included in both formalisms. Our results underline
the phenomenological importance of understanding the NLP structure of QCD cross
sections.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""}]","2021-06-02"
"2101.07271","Christian Friedrich Steinwachs","Christian F. Steinwachs","Non-perturbative quantum Galileon in the exact renormalization group","20 pages, 3 figures",,"10.1088/1475-7516/2021/04/038","FR-PHENO-2021-04","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the non-perturbative renormalization group flow of the scalar
Galileon model in flat space. We discuss different expansion schemes of the
Galileon truncation, including a heat-kernel based derivative expansion, a
vertex expansion in momentum space and a curvature expansion in terms of a
covariant geometric formulation. We find that the Galileon symmetry prevents a
quantum induced renormalization group running of the Galileon couplings.
Consequently, the Galileon truncation only features a trivial Gaussian fixed
point.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""}]","2021-04-21"
"2101.07272","Alessandro Mininno","Federico Carta, Alessandro Mininno, Nicole Righi, Alexander Westphal","Gopakumar-Vafa Hierarchies in Winding Inflation and Uplifts","v2, JHEP accepted, added references, 1+44 pages, 5 figures, 3
  appendices",,"10.1007/JHEP05(2021)271","DESY-21-007, IFT-UAM/CSIC-21-3","hep-th astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a combined mechanism to realize both winding inflation and de
Sitter uplifts. We realize the necessary structure of competing terms in the
scalar potential not via tuning the vacuum expectation values of the complex
structure moduli, but by a hierarchy of the Gopakumar-Vafa invariants of the
underlying Calabi-Yau threefold. To show that Calabi-Yau threefolds with the
prescribed hierarchy actually exist, we explicitly create a database of all the
genus $0$ Gopakumar-Vafa invariants up to total degree $10$ for all the
complete intersection Calabi-Yau's up to Picard number $9$. As a side product,
we also identify all the redundancies present in the CICY list, up to Picard
number $13$. Both databases can be accessed at this link:
https://www.desy.de/~westphal/GV_CICY_webpage/GVInvariants.html .
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 08:46:10 GMT""}]","2021-06-16"
"2101.07273","Ruth Sch\""afer","Sebastian Bruggisser, Ruth Sch\""afer, Danny van Dyk, Susanne Westhoff","The Flavor of UV Physics","53 pages, 9 figures, 11 tables",,"10.1007/JHEP05(2021)257",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New physics not far above the TeV scale should leave a pattern of virtual
effects in observables at lower energies. What do these effects tell us about
the flavor structure of a UV theory? Within the framework of Standard Model
Effective Field Theory (SMEFT), we resolve the flavor structure of the Wilson
coefficients in a combined analysis of top-quark and $B$-physics observables.
Our fit to LHC and $b$-factory measurements shows that combining top and bottom
observables is crucial to pin down possible sources of flavor symmetry breaking
from UV physics. Our analysis includes the full analytic expansion of SMEFT
coefficients in Minimal Flavor Violation and a detailed study of SMEFT effects
in $b\to s$ flavor transitions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:01 GMT""}]","2021-06-16"
"2101.07274","Olaf Lechtenfeld","Francisca Carrillo-Morales, Francisco Correa, Olaf Lechtenfeld","Integrability, intertwiners and non-linear algebras in Calogero models","16 pages",,"10.1007/JHEP05(2021)163",,"hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  For the rational quantum Calogero systems of type $A_1{\oplus}A_2$, $AD_3$
and $BC_3$, we explicitly present complete sets of independent conserved
charges and their nonlinear algebras. Using intertwining (or shift) operators,
we include the extra `odd' charges appearing for integral couplings. Formulae
for the energy eigenstates are used to tabulate the low-level wave functions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:02 GMT""}]","2023-01-11"
"2101.07275","Alexander Tsirlin","S. Bachus, D. A. S. Kaib, A. Jesche, V. Tsurkan, A. Loidl, S. M.
  Winter, A. A. Tsirlin, R. Valent\'i, P. Gegenwart","Angle-dependent thermodynamics of $\alpha$-RuCl$_3$","4.5 pages + Supplemental Material","Phys. Rev. B 103, 054440 (2021)","10.1103/PhysRevB.103.054440",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermodynamics of the Kitaev honeycomb magnet $\alpha$-RuCl$_3$ is studied
for different directions of in-plane magnetic field using measurements of the
magnetic Gr\""uneisen parameter $\Gamma_B$ and specific heat $C$. We identify
two critical fields $B_c^{\rm AF1}$ and $B_c^{\rm AF2}$ corresponding,
respectively, to a transition between two magnetically ordered states and the
loss of magnetic order toward a quantum paramagnetic state. The $B_c^{AF2}$
phase boundary reveals a narrow region of magnetic fields where inverse melting
of the ordered phase may occur. No additional transitions are detected above
$B_c^{\rm AF2}$ for any direction of the in-plane field, although a shoulder
anomaly in $\Gamma_B$ is observed systematically at $8-10$ T. Large
field-induced entropy effects imply additional low-energy excitations at low
fields and/or strongly field-dependent phonon entropies. Our results establish
universal features of $\alpha$-RuCl$_3$ in high magnetic fields and challenge
the presence of a field-induced Kitaev spin liquid in this material.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:02 GMT""}]","2021-03-03"
"2101.07276","Fabio Franchini","Vanja Mari\'c, Salvatore Marco Giampaolo, and Fabio Franchini","The fate of local order in topologically frustrated spin chains","18 pages, 4 figures. Substantial expansion over the first version,
  which includes the generalization of the theorems to states with an arbitrary
  finite number of domain walls and numerical analysis in support of our
  results","Phys. Rev. B 105, 064408 (2022)","10.1103/PhysRevB.105.064408","RBI-ThPhys-2021-3","cond-mat.stat-mech cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been recently shown that the presence of topological frustration,
induced by periodic boundary conditions in an antiferromagnetic $XY$ chain made
of an odd number of spins, prevents the realization of a perfectly staggered
local order. Starting from this result and exploiting a recently introduced
approach which enables the direct calculation of the expectation value of any
operator with support over a finite range of lattice sites, in this work we
investigate the possible fates of local orders. We show that, regardless of the
variety of possible situations, they can be all arranged in two different
cases. A system admits a finite local order only if the ground state is
degenerate, with at least two elements whose momenta differ, in the
thermodynamic limit, by $\pi$, and this order breaks translational symmetry. In
all other cases, any local order decays to zero, algebraically (or faster) in
the chain length. Moreover, we show that, in some cases, which of the two
possibilities is realized, may depend on the sequence of chain lengths with
which the thermodynamic limit is reached. These results are established both
analytically and by exact diagonalization and illustrated through examples.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 17:33:13 GMT""}]","2022-05-04"
"2101.07277","Bruce T. Draine","B. T. Draine and Brandon S. Hensley","Using the Starlight Polarization Efficiency Integral to Constrain Shapes
  and Porosities of Interstellar Grains","submitted to ApJ",,"10.3847/1538-4357/ac0050",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new method for using the observed starlight polarization and
polarized submm emission to constrain the shapes and porosities of interstellar
grains. We present the modified picket fence approximation (MPFA), and verify
that it is sufficiently accurate for modeling starlight polarization. We
introduce the starlight polarization integral $\Pi_{\rm obs}$ as a measure of
overall strength of the observed polarization of starlight, and the starlight
polarization efficiency integral $\Phi$ to characterize the effectiveness of
different grain types for producing polarization of starlight. The starlight
polarization integral $\Pi_{\rm obs}$ determines the mass-weighted alignment
$\langle f_{\rm align}\rangle$ of the grains. Approximating the aligned grains
in the interstellar medium as spheroids, we use $\Pi_{\rm obs}/\Phi$ to show
that the observed starlight polarization constrains the grains to have a
minimum degree of asphericity. For porosity ${\cal P}=0$, the minimum axial
ratio is $\sim$1.4 for oblate spheroids, or $\sim$1.8 for prolate spheroids. If
the grains are porous, more extreme axial ratios are required. The same grains
that produce the starlight polarization are able to provide the observed
polarized emission at submm wavelengths, but with further limits on shape and
porosity. Porosities ${\cal P}>0.75$ are ruled out. If interstellar grains can
be approximated by astrodust spheroids, we predict the ratio of 10$\mu{\rm m}$
polarization to starlight polarization $p_V$: $p(10\mu{\rm
m})/p_V=0.222\pm0.026$. For Cyg OB2-12 we predict $p(10\mu{\rm
m})=(2.1\pm0.3)\%$, which should be observable.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:08 GMT""}]","2021-10-04"
"2101.07278","Banibrata Mukhopadhyay","Surajit Kalita and Banibrata Mukhopadhyay","Gravitational wave in f(R) gravity: possible signature of sub- and
  super-Chandrasekhar limiting mass white dwarfs","15 pages including 10 figures and 1 table; accepted for publication
  in ApJ","ApJ 909, 65 (2021)","10.3847/1538-4357/abddb8",,"astro-ph.HE astro-ph.SR gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After the prediction of many sub- and super-Chandrasekhar (at least a dozen
for the latter) limiting mass white dwarfs, hence apparently peculiar class of
white dwarfs, from the observations of luminosity of type Ia supernovae,
researchers have proposed various models to explain these two classes of white
dwarfs separately. We earlier showed that these two peculiar classes of white
dwarfs, along with the regular white dwarfs, can be explained by a single form
of the f(R) gravity, whose effect is significant only in the high-density
regime, and it almost vanishes in the low-density regime. However, since there
is no direct detection of such white dwarfs, it is difficult to single out one
specific theory from the zoo of modified theories of gravity. We discuss the
possibility of direct detection of such white dwarfs in gravitational wave
astronomy. It is well-known that in f(R) gravity, more than two polarization
modes are present. We estimate the amplitudes of all the relevant modes for the
peculiar as well as the regular white dwarfs. We further discuss the
possibility of their detections through future-based gravitational wave
detectors, such as LISA, ALIA, DECIGO, BBO, or Einstein Telescope, and thereby
put constraints or rule out various modified theories of gravity. This
exploration links the theory with possible observations through gravitational
wave in f(R) gravity.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:09 GMT""}]","2021-03-09"
"2101.07279","Keller VandeBogert","Ayah Almousa and Keller VandeBogert","Linear Strands of Initial Ideals of Determinantal Facet Ideals","16 pages; v2: added revisions in line with referee comments + DOI for
  published version. v1: significantly expanded version of contents originally
  appearing in 2006.14434. arXiv admin note: text overlap with arXiv:2006.14434",,"10.1080/00927872.2021.2002885",,"math.AC","http://creativecommons.org/licenses/by/4.0/","  A determinantal facet ideal (DFI) is an ideal $J_\Delta$ generated by maximal
minors of a generic matrix parametrized by an associated simplicial complex
$\Delta$. In this paper, we construct an explicit linear strand for the initial
ideal with respect to any diagonal term order $<$ of an arbitrary DFI. In
particular, we show that if $\Delta$ has no \emph{1-nonfaces}, then the Betti
numbers of the linear strand of $J_\Delta$ and its initial ideal coincide. We
apply this result to prove a conjecture of Ene, Herzog, and Hibi on Betti
numbers of closed binomial edge ideals in the case that the associated graph
has at most $2$ maximal cliques. More generally, we show that the linear strand
of the initial ideal (with respect to $<$) of \emph{any} DFI is supported on a
polyhedral cell complex obtained as an induced subcomplex of the \emph{complex
of boxes}, introduced by Nagel and Reiner.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:34 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 16:18:59 GMT""}]","2022-01-27"
"2101.07280","Saad Nadeem","Shawn Mathew, Saad Nadeem and Arie Kaufman","Visualizing Missing Surfaces In Colonoscopy Videos using Shared Latent
  Space Representations","IEEE International Symposium on Biomedical Imaging (ISBI) 2021,
  **Shawn Mathew and Saad Nadeem contributed equally",,"10.1109/ISBI48211.2021.9433982",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical colonoscopy (OC), the most prevalent colon cancer screening tool, has
a high miss rate due to a number of factors, including the geometry of the
colon (haustral fold and sharp bends occlusions), endoscopist inexperience or
fatigue, endoscope field of view, etc. We present a framework to visualize the
missed regions per-frame during the colonoscopy, and provides a workable
clinical solution. Specifically, we make use of 3D reconstructed virtual
colonoscopy (VC) data and the insight that VC and OC share the same underlying
geometry but differ in color, texture and specular reflections, embedded in the
OC domain. A lossy unpaired image-to-image translation model is introduced with
enforced shared latent space for OC and VC. This shared latent space captures
the geometric information while deferring the color, texture, and specular
information creation to additional Gaussian noise input. This additional noise
input can be utilized to generate one-to-many mappings from VC to OC and OC to
OC. The code, data and trained models will be released via our Computational
Endoscopy Platform at https://github.com/nadeemlab/CEP.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:51 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 14:38:09 GMT""}]","2021-06-24"
"2101.07281","Stephan Narison","R.M. Albuquerque (FAT-Univ. Rio de Janeiro, BR), S. Narison (LUPM-CNRS
  Montpellier, FR and iHEPMAD-Univ. Antananarivo, MG), D. Rabetiarivony
  (iHEPMAD-Univ. Antananarivo, MG)","Z_c -like spectra from QCD Laplace sum rules at NLO","22 pages in two-column format; 24 figures, 6 tables : Version
  published in PRD","Phys. Rev. D 103, 074015 (2021)","10.1103/PhysRevD.103.074015",,"hep-ph hep-ex hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a global analysis of the observed Z_c, Z_cs and future Z_css-like
spectra using the inverse Laplace transform (LSR) version of QCD spectral sum
rules (QSSR) within stability criteria. Integrated compact QCD expressions of
the LO spectral functions up to dimension-six condensates are given.
Next-to-Leading Order (NLO) factorized perturbative contributions are included.
We re-emphasize the importance to include PT radiative corrections (though
numerically small) for heavy quark sum rules in order to justify the (ad hoc)
definition and value of the heavy quark mass used frequently at LO in the
literature. We also demonstrate that, contrary to a na\""ive qualitative 1/N_c
counting, the two-meson scattering contributions to the four-quark spectral
functions are numerically negligible confirming the reliability of the LSR
predictions. Our results are summarized in Tables III to VI. The Z_c(3900) and
Z_cs(3983) spectra are well reproduced by the T_c(3900) and T_cs(3973)
tetramoles (superposition of quasi-degenerated molecules and tetraquark states
having the same quantum numbers and with almost equal couplings to the
currents). The Z_c(4025) or Z_c(4040) state can be fitted with the D*_0D_1
molecule having a mass 4023(130) MeV while the Z_cs bump around 4.1 GeV can be
likely due to the (D^*_s0D_1+ D^*_0D_s1) molecules. The Z_c(4430) can be a
radial excitation of the Z_c(3900) weakly coupled to the current, while all
strongly coupled ones are in the region (5634-6527) MeV. The double strange
tetramole state T_css which one may identify with the future Z_css is predicted
to be at 4064(46) MeV. It is remarkable to notice the regular mass-spliitings
of the tetramoles due to SU(3) breakings M_{T_cs}-M_{T_c}= M_{T_css}-M_{T_cs=
(73- 91) MeV.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:52 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 20:13:49 GMT""}]","2021-04-28"
"2101.07282","Andrea Smirne","Andrea Smirne, Nina Megier, Bassano Vacchini","On the connection between microscopic description and memory effects in
  open quantum system dynamics","12 pages, 6 figures; Accepted for publication in Quantum","Quantum 5, 439 (2021)","10.22331/q-2021-04-26-439",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The exchange of information between an open quantum system and its
environment allows us to discriminate among different kinds of dynamics, in
particular detecting memory effects to characterize non-Markovianity. Here, we
investigate the role played by the system-environment correlations and the
environmental evolution in the flow of information. First, we derive general
conditions ensuring that two generalized dephasing microscopic models of the
global system-environment evolution result exactly in the same open-system
dynamics, for any initial state of the system. Then, we use the trace distance
to quantify the distinct contributions to the information inside and outside
the open system in the two models. Our analysis clarifies how the interplay
between system-environment correlations and environmental-state
distinguishability can lead to the same information flow from and toward the
open system, despite significant qualitative and quantitative differences at
the level of the global evolution.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:01:19 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 14:29:41 GMT""}]","2021-04-28"
"2101.07283","Xiao Xiao","Xiao Xiao, J. K. Freericks and A. F. Kemper","Robust measurement of wave function topology on NISQ quantum computers","21 pages, 14 figures, 4 tables","Quantum 7, 987 (2023)","10.22331/q-2023-04-27-987",,"quant-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Topological quantum phases of quantum materials are defined through their
topological invariants. These topological invariants are quantities that
characterize the global geometrical properties of the quantum wave functions
and thus are immune to local noise. Here, we present a strategy to measure
topological invariants on quantum computers. We show that our strategy can be
easily integrated with the variational quantum eigensolver (VQE) so that the
topological properties of generic quantum many-body states can be characterized
on current quantum hardware. We demonstrate the robust nature of the method by
measuring topological invariants for both non-interacting and interacting
models, and map out interacting quantum phase diagrams on quantum simulators
and IBM quantum hardware.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:01:38 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 17:45:42 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 01:30:31 GMT""},{""version"":""v4"",""created"":""Mon, 3 Oct 2022 15:41:58 GMT""},{""version"":""v5"",""created"":""Thu, 13 Apr 2023 03:15:14 GMT""},{""version"":""v6"",""created"":""Mon, 24 Apr 2023 13:25:43 GMT""}]","2023-05-03"
"2101.07284","Parveen Kumar","Parveen Kumar, Kyrylo Snizhko, Yuval Gefen, and Bernd Rosenow","Optimized Steering: Quantum State Engineering and Exceptional Points","6 pages + 4 pages supplementary information, 2 figures","Phys. Rev. A 105, L010203 (2022)","10.1103/PhysRevA.105.L010203",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The state of a quantum system may be steered towards a predesignated target
state, employing a sequence of weak $\textit{blind}$ measurements (where the
detector's readouts are traced out). Here we analyze the steering of a
two-level system using the interplay of a system Hamiltonian and weak
measurements, and show that $\textit{any}$ pure or mixed state can be targeted.
We show that the optimization of such a steering protocol is underlain by the
presence of Liouvillian exceptional points. More specifically, for high purity
target states, optimal steering implies purely relaxational dynamics marked by
a second-order exceptional point, while for low purity target states, it
implies an oscillatory approach to the target state. The dynamical phase
transition between these two regimes is characterized by a third-order
exceptional point.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:02:05 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 15:39:32 GMT""},{""version"":""v3"",""created"":""Thu, 11 Feb 2021 11:58:07 GMT""},{""version"":""v4"",""created"":""Tue, 18 Jan 2022 17:32:56 GMT""}]","2022-01-19"
"2101.07285","Kai Meinerz","Kai Meinerz, Chae-Yeun Park, and Simon Trebst","Scalable Neural Decoder for Topological Surface Codes","10 pages, 10 figures, 5 tables","Phys. Rev. Lett. 128, 080505 (2022)","10.1103/PhysRevLett.128.080505",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With the advent of noisy intermediate-scale quantum (NISQ) devices, practical
quantum computing has seemingly come into reach. However, to go beyond
proof-of-principle calculations, the current processing architectures will need
to scale up to larger quantum circuits which in turn will require fast and
scalable algorithms for quantum error correction. Here we present a neural
network based decoder that, for a family of stabilizer codes subject to
depolarizing noise and syndrome measurement errors, is scalable to tens of
thousands of qubits (in contrast to other recent machine learning inspired
decoders) and exhibits faster decoding times than the state-of-the-art union
find decoder for a wide range of error rates (down to 1%). The key innovation
is to autodecode error syndromes on small scales by shifting a preprocessing
window over the underlying code, akin to a convolutional neural network in
pattern recognition approaches. We show that such a preprocessing step allows
to effectively reduce the error rate by up to two orders of magnitude in
practical applications and, by detecting correlation effects, shifts the actual
error threshold, up to fifteen percent higher than the threshold of
conventional error correction algorithms such as union find or minimum weight
perfect matching, even in the presence of measurement errors. An in-situ
implementation of such machine learning-assisted quantum error correction will
be a decisive step to push the entanglement frontier beyond the NISQ horizon.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:02:09 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 13:02:46 GMT""}]","2022-02-25"
"2101.07286","Pontus Giselsson","Mattias F\""alt, Pontus Giselsson","Generalized Alternating Projections on Manifolds and Convex Sets",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we extend the previous convergence results for the generalized
alternating projection method applied to subspaces in [arXiv:1703.10547] to
hold also for smooth manifolds. We show that the algorithm locally behaves
similarly in the subspace and manifold settings and that the same rates are
obtained. We also present convergence rate results for when the algorithm is
applied to non-empty, closed, and convex sets. The results are based on a
finite identification property that implies that the algorithm after an initial
identification phase solves a smooth manifold feasibility problem. Therefore,
the rates in this paper hold asymptotically for problems in which this
identification property is satisfied. We present a few examples where this is
the case and also a counter example for when this is not.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:04:04 GMT""},{""version"":""v2"",""created"":""Mon, 19 Dec 2022 17:12:49 GMT""},{""version"":""v3"",""created"":""Thu, 30 Mar 2023 10:13:03 GMT""}]","2023-03-31"
"2101.07287","Yahia Shabara","Yahia Shabara, C. Emre Koksal and Eylem Ekici","How Long to Estimate Sparse MIMO Channels",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Large MIMO transceivers are integral components of next-generation wireless
networks. However, for such systems to be practical, their channel estimation
process needs to be fast and reliable. Although several solutions for fast
estimation of sparse channels do exist, there is still a gap in understanding
the fundamental limits governing this problem. Specifically, we need to better
understand the lower bound on the number of measurements under which accurate
channel estimates can be obtained. This work bridges that knowledge gap by
deriving a tight asymptotic lower bound on the number of measurements. This not
only helps develop a better understanding for the sparse MIMO channel
estimation problem, but it also provides a benchmark for evaluating current and
future solutions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:04:30 GMT""}]","2021-01-20"
"2101.07288","Eduardo O. Schmidt","Eduardo O. Schmidt, Laura D. Baravalle and Adriana R.
  Rodr\'iguez-Kamenetzky","Spectroscopic study of the [OIII]$\lambda$5007 profile in Seyfert 1
  galaxies","18 pages, 10 figures, 2 tables. Accepted for publication in Monthly
  Notices of the Royal Astronomical Society (MNRAS)",,"10.1093/mnras/stab167",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spectra of active galactic nuclei usually exhibit wings in some emission
lines, such as [OIII]$\lambda\lambda$5007,4959, with these wings generally
being blueshifted and related to strong winds and outflows. The aim of this
work was to analyse the [OIII] emission lines in broad line Seyfert 1 (BLS1)
galaxies in order to detect the presence of wings, and to study the [OIII] line
properties and their possible connection with the central engine. In addition,
we attempted to compare the black hole mass distribution in both BLS1 galaxies
with symmetric and blue-asymmetric [OIII] profiles. For this purpose, we
carried out a spectroscopic study of a sample of 45 nearby southern BLS1
galaxies from the 6 Degree Field Galaxy survey. The [OIII] emission lines were
well fitted using a single Gaussian function in 23 galaxies, while 22 objects
presented a wing component and required a double-Gaussian decomposition. By
computing the radial velocity difference between the wing and core centroids
(i.e. $\Delta$v), we found 18 galaxies exhibiting blueshifted wings, 2 objects
presenting red wings and 2 galaxies showing symmetric wings ($\Delta$v$= 0$).
Moreover, $\Delta$v was slightly correlated with the black hole mass. In
addition, we computed the radial velocity difference of the blue-side full
extension of the wing relative to the centroid of the core component through
the \emph{blue emission} parameter, which revealed a correlation with black
hole mass, in agreement with previous results reported for narrow line
galaxies. Finally, in our sample, similar black hole mass distributions were
observed in both BLS1 galaxies with symmetric and blueshifted asymmetric [OIII]
profiles.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:06:26 GMT""}]","2021-02-03"
"2101.07289","Damianos Iosifidis","Damianos Iosifidis","The Perfect Hyperfluid of Metric-Affine Gravity: The Foundation","11 pages, no figures",,"10.1088/1475-7516/2021/04/072",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We set the foundation and formulate the Perfect (Ideal) Hyperfluid. The
latter represents the natural generalization of the usual perfect fluid
structure where now the microscopic characteristics of matter (spin, shear,
dilation) are also taken into account, sourcing a non-Riemannian arena (i.e
spacetime torsion and non-metricity) for Metric-Affine Gravity. We derive the
energy tensors of this Hyperfluid structure and subsequently present the
conservation laws obeyed by them. Finally, we consider a Cosmological
application of this Perfect Hyperfluid and classify some possible forms of this
fluid structure.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:09:26 GMT""}]","2021-05-05"
"2101.07290","Jason Swanson","Thomas G. Kurtz and Jason Swanson","Finite Markov chains coupled to general Markov processes and an
  application to metastability II","27 pages; to be published in ""Stochastic Analysis, Filtering, and
  Stochastic Optimization: A Commemorative Volume to Honor Mark H. A. Davis's
  Contributions""",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a diffusion given by a small noise perturbation of a dynamical
system driven by a potential function with a finite number of local minima. The
classical results of Freidlin and Wentzell show that the time this diffusion
spends in the domain of attraction of one of these local minima is
approximately exponentially distributed and hence the diffusion should behave
approximately like a Markov chain on the local minima. By the work of Bovier
and collaborators, the local minima can be associated with the small
eigenvalues of the diffusion generator. In Part I of this work, by applying a
Markov mapping theorem, we used the eigenfunctions of the generator to couple
this diffusion to a Markov chain whose generator has eigenvalues equal to the
eigenvalues of the diffusion generator that are associated with the local
minima and established explicit formulas for conditional probabilities
associated with this coupling. The fundamental question now becomes to relate
the coupled Markov chain to the approximate Markov chain suggested by the
results of Freidlin and Wentzel. In this paper, we take up this question and
provide a complete analysis of this relationship in the special case of a
double-well potential in one dimension.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:12:32 GMT""}]","2021-01-20"
"2101.07291","Mohammed S. Al-Abiad","Mohammed S. Al-Abiad, Md. Zoheb Hassan, and Md. Jahangir Hossain","Cross-Layer Network Codes for Content Delivery in Cache-Enabled D2D
  Networks","12 pages, 5 figures, paper",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the use of cross-layer network coding (CLNC),
caching, and device-to-device (D2D) communications to jointly optimize the
delivery of a set of popular contents to a set of user devices (UDs). In the
considered D2D network, a group of near-by UDs cooperate with each other and
use NC to combine their cached files, so as the completion time required for
delivering all requested contents to all UDs is minimized. Unlike the previous
work that considers only one transmitting UD at a time, our work allows
multiple UDs to transmit simultaneously given the interference among the active
links is small. Such configuration brings a new trade-off among scheduling UDs
to transmitting UDs, selecting the coding decisions and the transmission
rate/power. Therefore, we consider the completion time minimization problem
that involves scheduling multiple transmitting UDs, determining their
transmission rates/powers and file combinations. The problem is shown to be
intractable because it involves all future coding decisions. To tackle the
problem at each transmission slot, we first design a graph called herein the
D2D Rate-Aware IDNC graph where its vertices have weights that judiciously
balance between the rates/powers of the transmitting UDs and the number of
their scheduled UDs. Then, we propose an innovative and efficient CLNC solution
that iteratively selects a set of transmitting UDs only if the interference
caused by the transmissions of the newly selected UDs does not significantly
impact the overall completion time. Simulation results show that the proposed
solution offers significant completion time reduction compared with the
existing algorithms.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:18:15 GMT""}]","2021-01-20"
"2101.07292","Rainer Rehak","Kirsten Bock, Christian R. K\""uhne, Rainer M\""uhlhoff, M\v{e}to R.
  Ost, J\""org Pohle, Rainer Rehak","Data Protection Impact Assessment for the Corona App","97 pages, German version here: https://www.fiff.de/dsfa-corona",,,,"cs.CY cs.CR cs.SI","http://creativecommons.org/licenses/by/4.0/","  Since SARS-CoV-2 started spreading in Europe in early 2020, there has been a
strong call for technical solutions to combat or contain the pandemic, with
contact tracing apps at the heart of the debates. The EU's General Daten
Protection Regulation (GDPR) requires controllers to carry out a data
protection impact assessment (DPIA) where their data processing is likely to
result in a high risk to the rights and freedoms (Art. 35 GDPR). A DPIA is a
structured risk analysis that identifies and evaluates possible consequences of
data processing relevant to fundamental rights and describes the measures
envisaged to address these risks or expresses the inability to do so. Based on
the Standard Data Protection Model (SDM), we present a scientific DPIA which
thoroughly examines three published contact tracing app designs that are
considered to be the most ""privacy-friendly"": PEPP-PT, DP-3T and a concept
summarized by Chaos Computer Club member Linus Neumann, all of which process
personal health data. The DPIA starts with an analysis of the processing
context and some expected use cases. Then, the processing activities are
described by defining a realistic processing purpose. This is followed by the
legal assessment and threshold analysis. Finally, we analyse the weak points,
the risks and determine appropriate protective measures. We show that even
decentralized implementations involve numerous serious weaknesses and risks.
Legally, consent is unfit as legal ground hence data must be processed based on
a law. We also found that measures to realize the rights of data subjects and
affected people are not sufficient. Last but not least, we show that
anonymization must be understood as a continuous process, which aims at
separating the personal reference and is based on a mix of legal,
organizational and technical measures. All currently available proposals lack
such an explicit separation process.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:23:30 GMT""}]","2021-01-20"
"2101.07293","Xihan Ji","Xihan Ji, Cheng Li, Renbin Yan, Houjun Mo, Lihwai Lin, Hu Zou, Jianhui
  Lian, David V. Stark, Rogemar A. Riffel, Hsi-An Pan, Dmitry Bizyaev, Kevin
  Bundy","SDSS-IV MaNGA: the physical origin of off-galaxy H$\alpha$ blobs in the
  local Universe","26 pages, 18 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab2789",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  H$\alpha$ blobs are off-galaxy emission-line regions with weak or no optical
counterparts. They are mostly visible in H$\alpha$ line, appearing as
concentrated blobs. Such unusual objects have been rarely observed and studied,
and their physical origin is still unclear. We have identified 13 H$\alpha$
blobs in the public data of MaNGA survey, by visually inspecting both the
optical images and the spatially resolved maps of H$\alpha$ line for $\sim
4600$ galaxy systems. Among the 13 H$\alpha$ blobs, 2 were reported in
previously MaNGA-based studies and 11 are newly discovered. This sample, though
still small in size, is by far the largest sample with both deep imaging and
integral field spectroscopy. Therefore, for the first time we are able to
perform statistical studies to investigate the physical origin of H$\alpha$
blobs. We examine the physical properties of these H$\alpha$ blobs and their
associated galaxies, including their morphology, environments, gas-phase
metallicity, kinematics of ionized gas, and ionizing sources. We find that the
H$\alpha$ blobs in our sample can be broadly divided into two groups. One is
associated with interacting/merging galaxy systems, of which the ionization is
dominated by shocks or diffuse ionized gas. It is likely that these H$\alpha$
blobs used to be part of their nearby galaxies, but were stripped away at some
point due to tidal interactions. The other group is found in gas-rich systems,
appearing as low-metallicity star-forming regions that are visually detached
from the main galaxy. These H$\alpha$ blobs could be associated with faint
disks, spiral arms, or dwarf galaxies.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:24:55 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 15:48:46 GMT""}]","2021-10-13"
"2101.07294","Smail Bougouffa PhD","Smail Bougouffa","Quadrupole absorption rate for atoms in circularly-polarized optical
  vortices","13 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:2007.04021","Results in Physics 27 (2021) 104541","10.1016/j.rinp.2021.104541",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Twisted light beams, or optical vortices, have been used to drive the
circular motion of microscopic particles in optical tweezers and have been
shown to generate vortices in quantum gases. Recent studies have established
that electric quadrupole interactions can mediate an orbital angular momentum
exchange between twisted light and the electronic degrees of freedom of atoms.
Here we consider a quadrupole atomic transition mediated by a
circularly-polarized optical vortex. We evaluate the transfer rate of the
optical angular momentum to a $Ca^+$ ion involving the $4^2S_{1/2}\rightarrow
3^2D_{5/2}$ quadrupole transition and explain how the polarization state and
the topological charge of the vortex beam determine the selection rules.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:27:03 GMT""},{""version"":""v2"",""created"":""Sat, 17 Jul 2021 08:38:21 GMT""}]","2021-07-20"
"2101.07295","Anh Thai","Anh Thai, Stefan Stojanov, Zixuan Huang, Isaac Rehg, James M. Rehg","The Surprising Positive Knowledge Transfer in Continual 3D Object Shape
  Reconstruction","Accepted to 3DV 2022",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continual learning has been extensively studied for classification tasks with
methods developed to primarily avoid catastrophic forgetting, a phenomenon
where earlier learned concepts are forgotten at the expense of more recent
samples. In this work, we present a set of continual 3D object shape
reconstruction tasks, including complete 3D shape reconstruction from different
input modalities, as well as visible surface (2.5D) reconstruction which,
surprisingly demonstrate positive knowledge (backward and forward) transfer
when training with solely standard SGD and without additional heuristics. We
provide evidence that continuously updated representation learning of
single-view 3D shape reconstruction improves the performance on learned and
novel categories over time. We provide a novel analysis of knowledge transfer
ability by looking at the output distribution shift across sequential learning
tasks. Finally, we show that the robustness of these tasks leads to the
potential of having a proxy representation learning task for continual
classification. The codebase, dataset and pre-trained models released with this
article can be found at https://github.com/rehg-lab/CLRec
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:29:12 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 03:42:31 GMT""},{""version"":""v3"",""created"":""Wed, 8 Dec 2021 06:01:48 GMT""},{""version"":""v4"",""created"":""Wed, 16 Mar 2022 16:05:54 GMT""},{""version"":""v5"",""created"":""Fri, 9 Sep 2022 03:44:35 GMT""}]","2022-09-12"
"2101.07296","Stefan Stojanov","Stefan Stojanov, Anh Thai, James M. Rehg","Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias","Accepted at CVPR2021. Project page, code and data available at
  https://rehg-lab.github.io/publication-pages/lowshot-shapebias/",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is widely accepted that reasoning about object shape is important for
object recognition. However, the most powerful object recognition methods today
do not explicitly make use of object shape during learning. In this work,
motivated by recent developments in low-shot learning, findings in
developmental psychology, and the increased use of synthetic data in computer
vision research, we investigate how reasoning about 3D shape can be used to
improve low-shot learning methods' generalization performance. We propose a new
way to improve existing low-shot learning approaches by learning a
discriminative embedding space using 3D object shape, and using this embedding
by learning how to map images into it. Our new approach improves the
performance of image-only low-shot learning approaches on multiple datasets. We
also introduce Toys4K, a 3D object dataset with the largest number of object
categories currently available, which supports low-shot learning.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:29:41 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 23:13:19 GMT""}]","2021-06-22"
"2101.07297","Harold Steinacker","Stefan Fredenhagen and Harold C. Steinacker","Exploring the gravity sector of emergent higher-spin gravity: effective
  action and a solution","39 pages, v2: minor issues fixed, conclusion unchanged V3: Appendix
  E.1 corrected, no change of results or conclusions","JHEP 05 (2021) 183","10.1007/JHEP05(2021)183","UWThPh 2021-1","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We elaborate the description of the semi-classical gravity sector of
Yang-Mills matrix models on a covariant quantum FLRW background. The basic
geometric structure is a frame, which arises from the Poisson structure on an
underlying $S^2$ bundle over space-time. The equations of motion for the
associated Weitzenb\""ock torsion obtained in arXiv:2002.02742 are rewritten in
the form of Yang-Mills-type equations for the frame. An effective action is
found which reproduces these equations of motion, which contains an
Einstein-Hilbert term coupled to a dilaton, an axion and a Maxwell-type term
for the dynamical frame. An explicit rotationally invariant solution is found,
which describes a gravitational field coupled to the dilaton.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:32:39 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 10:20:18 GMT""},{""version"":""v3"",""created"":""Fri, 10 Mar 2023 20:39:12 GMT""}]","2023-03-14"
"2101.07298","Diego Alonso-Or\'an","Diego Alonso-Or\'an and Juan Juan J. L. Vel\'azquez","Boundary value problems for two dimensional steady incompressible fluids","27 pages, 2 figures",,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this paper we study the solvability of different boundary value problems
for the two dimensional steady incompressible Euler equation. Two main methods
are currently available to study those problems, namely the Grad-Shafranov
method and the vorticity transport method. We describe for which boundary value
problems these methods can be applied. The obtained solutions have
non-vanishing vorticity.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:35:04 GMT""}]","2021-01-20"
"2101.07299","Vasiliki Kougia Ms","John Pavlopoulos, Vasiliki Kougia, Ion Androutsopoulos, Dimitris
  Papamichail","Diagnostic Captioning: A Survey",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diagnostic Captioning (DC) concerns the automatic generation of a diagnostic
text from a set of medical images of a patient collected during an examination.
DC can assist inexperienced physicians, reducing clinical errors. It can also
help experienced physicians produce diagnostic reports faster. Following the
advances of deep learning, especially in generic image captioning, DC has
recently attracted more attention, leading to several systems and datasets.
This article is an extensive overview of DC. It presents relevant datasets,
evaluation measures, and up to date systems. It also highlights shortcomings
that hinder DC's progress and proposes future directions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:40:32 GMT""}]","2021-01-20"
"2101.07300","Kingshuk Majumdar","Kingshuk Majumdar and Subhendra D. Mahanti","Quantum fluctuation effects on the ordered Moments in a two dimensional
  frustrated ferrimagnet","9 pages, 6 figures","J. Phys. Condens. Matter 33, 125801 (2021)","10.1088/1361-648X/abd8b6",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel two-dimensional (2D)frustrated quantum spin-1/2
anisotropic Heisenberg model with alternating ferromagnetic and
antiferromagnetic magnetic chains along one direction and antiferromagnetic
interactions along the other. The (mean-field) ground state is ferrimagnetic in
certain range of the interaction space. Spin-wave theory analysis of the
reduction of ordered moments at inequivalent spin sites and the instability of
the spin waves suggest a quantum phase transition which has the characteristics
of both the frustrated two-dimensional antiferromagnetic S=1/2 ($J_1, J_2$)
model and 1D S$_1$=1, S$_2$=1/2 quantum ferrimagnetic model.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:41:10 GMT""}]","2021-01-20"
"2101.07301","Enrico Tapavicza","Enrico Tapavicza, Guido Falk von Rudorff, David O. De Haan, Mario
  Contin, Christian George, Matthieu Riva, O. Anatole von Lilienfeld","Elucidating atmospheric brown carbon -- Supplanting chemical intuition
  with exhaustive enumeration and machine learning",,,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To unravel the structures of C12H12O7 isomers, identified as light-absorbing
photooxidation products of syringol in atmospheric chamber experiments, we
apply a graph-based molecule generator and machine learning workflow. To
accomplish this in a bias-free manner, molecular graphs of the entire chemical
subspace of C12H12O7 were generated, assuming that the isomers contain two
C6-rings; this led to 260 million molecular graphs and 120 million stable
structures. Using quantum chemistry excitation energies and oscillator
strengths as training data, we predicted these quantities using kernel ridge
regression and simulated UV/Vis absorption spectra. Then we determined the
probability of the molecules to cause the experimental spectrum within the
errors of the different methods. Molecules whose spectra were likely to match
the experimental spectrum were clustered according to structural features,
resulting in clusters of > 500,000 molecules. While we identified several
features that correlate with a high probability to cause the experimental
spectrum, no clear composition of necessary features can be given. Thus, the
absorption spectrum is not sufficient to uniquely identify one specific isomer
structure. If more structural features were known from experimental data, the
number of structures could be reduced to a few tens of thousands candidates. We
offer a procedure to detect when sufficient fragmentation data has been
included to reduce the number of possible molecules. The most efficient
strategy to obtain valid candidates is obtained if structural data is applied
already at the bias-free molecule generation stage. The systematic enumeration,
however, is necessary to avoid mis-identification of molecules, while it
guarantees that there are no other molecules that would also fit the spectrum
in question.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:43:41 GMT""}]","2021-01-20"
"2101.07302","Fernando Navarra","C. Le Roux, F. S. Navarra and L. M. Abreu","Understanding the $K^*/K$ ratio in heavy ion collisions","9 pages, 5 figures",,"10.1016/j.physletb.2021.136284",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the $K^*$ meson dissociation in heavy ion collisions during the
hadron gas phase. We use the production and absorption cross sections of the
$K^*$ and $K$ mesons in a hadron gas, which were calculated in a previous work.
We compute the time evolution of the $K^*$ abundance and the $K^* /K$ ratio
during the hadron gas phase. Assuming a Bjorken type cooling and using an
empirical relation between the freeze-out temperature and the central
multiplicity density, we are able to write $K^* /K$ as a function of ($ dN /d
\eta (\eta =0)$). The obtained function is in very good agreement with recent
experimental data.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:45:34 GMT""}]","2021-04-28"
"2101.07303","Andrea Droghetti","Andrea Droghetti","Oxygen doping and polaron magnetic coupling in Alq$_3$ films","6 pages, 2 figures","Journal of Magnetism and Magnetic Materials 502, 166578 (2020)","10.1016/j.jmmm.2020.166578",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The understanding of the Physics underlying the performances of organic
spin-valve devices is still incomplete. According to some recent models, spin
transport takes place in an impurity band inside the fundamental gap of organic
semiconductors. This seems to be confirmed by recent experiments performed with
La$_{0.7}$Sr$_{0.3}$MnO$_3$/Alq$_3$/AlO$_x$/Co devices. The reported results
suggest a possible correlation between the magnetoresistance and the variable
oxygen doping in the Alq$_3$ spacer. In this paper we investigate by means of
first-principles calculations the electronic and magnetic properties of O$_2$
molecules and ions in Alq$_3$ films to establish whether oxygen plays any
important role for spin transport in
La$_{0.7}$Sr$_{0.3}$MnO$_3$/Alq$_3$/AlO$_x$/Co devices. The conclusion is that
it does not. In fact, we show that O$_2$ molecules do not form an impurity band
and there is no magnetic interaction between them. In contrast, we suggest that
spin-transport may be enabled by the direct exchange coupling between Alq$_3^-$
ions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:45:37 GMT""}]","2021-01-20"
"2101.07304","Brendan Lucier","Nicole Immorlica, Ian Kash, Brendan Lucier","Buying Data Over Time: Approximately Optimal Strategies for Dynamic
  Data-Driven Decisions",,,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  We consider a model where an agent has a repeated decision to make and wishes
to maximize their total payoff. Payoffs are influenced by an action taken by
the agent, but also an unknown state of the world that evolves over time.
Before choosing an action each round, the agent can purchase noisy samples
about the state of the world. The agent has a budget to spend on these samples,
and has flexibility in deciding how to spread that budget across rounds. We
investigate the problem of choosing a sampling algorithm that optimizes total
expected payoff. For example: is it better to buy samples steadily over time,
or to buy samples in batches? We solve for the optimal policy, and show that it
is a natural instantiation of the latter. Under a more general model that
includes per-round fixed costs, we prove that a variation on this batching
policy is a 2-approximation.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:50:20 GMT""}]","2021-01-20"
"2101.07305","Adetayo Victor Eyelade","Adetayo V. Eyelade, Marina Stepanova, Cristobal M. Espinoza, Pablo S.
  Moya","On the Relation between Kappa Distribution Functions and the Plasma Beta
  Parameter in the Earth Magnetosphere: THEMIS observations","20 pages, 13 figures, to be published in Astrophysical Journal
  Supplement Series",,"10.3847/1538-4365/abdec9",,"physics.space-ph astro-ph.EP physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The Earth's magnetosphere represents a natural plasma laboratory that allows
us to study the behavior of particle distribution functions in the absence of
Coulomb collisions, typically described by the Kappa distributions. We have
investigated the properties of these functions for ions and electrons in
different magnetospheric regions, thereby making it possible to reveal the
$\kappa$-parameters for a wide range of plasma beta ($\beta$) values (from
$10^{-3}$ to $10^{2}$). This was done using simultaneous ion and electron
measurements from the five Time History of Events and Macroscale Interactions
during Substorms (THEMIS) spacecraft spanning the years 2008 to 2018. It was
found that for a fixed plasma $\beta$, the $\kappa$-index and core energy
($E_c$) of the distribution can be modeled by the power-law
$\kappa=AE_c^\gamma$ for both species, and the relation between $\beta$,
$\kappa$, and $E_c$ is much more complex than earlier reported: both $A$ and
$\gamma$ exhibit systematic dependencies with $\beta$. Our results indicate
that $\beta \sim 0.1-0.3$ is a range where the plasma is more dynamic since it
is influenced by both the magnetic field and temperature fluctuations, which
suggests that the transition between magnetically dominated plasmas to
kinetically dominated plasmas occurs at these values of $\beta$. For $\beta > 1
$, both $A$ and $\gamma$ take nearly constant values, a feature that is
especially notable for the electrons and might be related to their
demagnetization. The relation between $\beta$, $\kappa$, and $E_c$ that we
present is an important result that can be used by theoretical models in the
future.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:51:09 GMT""}]","2021-03-24"
"2101.07306","Qiuhua Huang","Tao Fu, Dexin Wang, Xiaoyuan Fan, Qiuhua Huang","Component Importance and Interdependence Analysis for Transmission,
  Distribution and Communication Systems","11 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  For critical infrastructure restoration planning, the real-time scheduling
and coordination of system restoration efforts, the key in decision-making is
to prioritize those critical components that are out of service during the
restoration. For this purpose, there is a need for component importance
analysis. While it has been investigated extensively for individual systems,
component importance considering interdependence among transmission,
distribution and communication (T&D&C) systems has not been systematically
analyzed and widely adopted. In this study, we propose a component importance
assessment method in the context of interdependence between T&D&C networks.
Analytic methods for multilayer networks and a set of metrics have been applied
for assessing the component importance and interdependence between T&D&C
networks based on their physical characteristics. The proposed methodology is
further validated with integrated synthetic Illinois regional transmission,
distribution, and communication (T&D&C) systems, the results reveal the unique
characteristics of component/node importance, which may be strongly affected by
the network topology and cross-domain node mapping.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:51:47 GMT""}]","2021-01-20"
"2101.07307","Tobias Schmid","Tobias Schmid, Stefanie Schraufstetter, Jonas Fritzsch, Dominik
  Hellhake, Greta Koelln and Stefan Wagner","Formal Verification of a Fail-Operational Automotive Driving System",,,,,"cs.SE cs.SY eess.SY","http://creativecommons.org/licenses/by-sa/4.0/","  A fail-operational system for highly automated driving must complete the
driving task even in the presence of a failure. This requires redundant
architectures and a mechanism to reconfigure the system in case of a failure.
Therefore, an arbitration logic is used. For functional safety, the switch-over
to a fall-back level must be conducted in the presence of any electric and
electronic failure. To provide evidence for a safety argumentation in
compliance with ISO 26262, verification of the arbitration logic is necessary.
The verification process provides confirmation of the correct failure reactions
and that no unintended system states are attainable. Conventional safety
analyses, such as the failure mode and effect analysis, have its limits in this
regard. We present an analytical approach based on formal verification, in
particular model checking, to verify the fail-operational behaviour of a
driving system. For that reason, we model the system behaviour and the relevant
architecture and formally specify the safety requirements. The scope of the
analysis is defined according to the requirements of ISO 26262. We verify a
fail-operational arbitration logic for highly automated driving in compliance
with the industry standard. Our results show that formal methods for safety
evaluation in automotive fail-operational driving systems can be successfully
applied. We were able to detect failures, which would have been overlooked by
other analyses and thus contribute to the development of safety critical
functions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:52:29 GMT""}]","2021-02-10"
"2101.07308","Le Thanh Nguyen-Meidine","Le Thanh Nguyen-Meidine, Atif Belal, Madhu Kiran, Jose Dolz,
  Louis-Antoine Blais-Morin, Eric Granger","Knowledge Distillation Methods for Efficient Unsupervised Adaptation
  Across Multiple Domains","This is the extended journal version of arXiv:2005.07839",,"10.1016/j.imavis.2021.104096",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Beyond the complexity of CNNs that require training on large annotated
datasets, the domain shift between design and operational data has limited the
adoption of CNNs in many real-world applications. For instance, in person
re-identification, videos are captured over a distributed set of cameras with
non-overlapping viewpoints. The shift between the source (e.g. lab setting) and
target (e.g. cameras) domains may lead to a significant decline in recognition
accuracy. Additionally, state-of-the-art CNNs may not be suitable for such
real-time applications given their computational requirements. Although several
techniques have recently been proposed to address domain shift problems through
unsupervised domain adaptation (UDA), or to accelerate/compress CNNs through
knowledge distillation (KD), we seek to simultaneously adapt and compress CNNs
to generalize well across multiple target domains. In this paper, we propose a
progressive KD approach for unsupervised single-target DA (STDA) and
multi-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single
target domain by distilling from a larger teacher CNN, trained on both target
and source domain data in order to maintain its consistency with a common
representation. Our proposed approach is compared against state-of-the-art
methods for compression and STDA of CNNs on the Office31 and ImageClef-DA image
classification datasets. It is also compared against state-of-the-art methods
for MTDA on Digits, Office31, and OfficeHome. In both settings -- KD-STDA and
KD-MTDA -- results indicate that our approach can achieve the highest level of
accuracy across target domains, while requiring a comparable or lower CNN
complexity.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:53:16 GMT""}]","2021-01-20"
"2101.07309","Bernhard Heim","Bernhard Heim and Markus Neuhauser","Asymptotic expansion of Fourier coefficients of reciprocals of
  Eisenstein series",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In this paper we give a classification of the asymptotic expansion of the
$q$-expansion of reciprocals of Eisenstein series $E_k$ of weight $k$ for the
modular group $\func{SL}_2(\mathbb{Z})$. For $k \geq 12$ even, this extends
results of Hardy and Ramanujan, and Berndt, Bialek and Yee, utilizing the
Circle Method on the one hand, and results of Petersson, and Bringmann and
Kane, developing a theory of meromorphic Poincar{\'e} series on the other. We
follow a uniform approach, based on the zeros of the Eisenstein series with the
largest imaginary part. These special zeros provide information on the
singularities of the Fourier expansion of $1/E_k(z)$ with respect to $q = e^{2
\pi i z}$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:55:37 GMT""}]","2021-01-20"
"2101.07310","Mohammad Mozaffari","Saeedeh Moloudi, Mohammad Mozaffari, Sandeep Narayanan Kadan Veedu,
  Kittipong Kittichokechai, Y.-P. Eric Wang, Johan Bergman, and Andreas
  H\""oglund","Coverage Evaluation for 5G Reduced Capability New Radio (NR-RedCap)",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fifth generation (5G) wireless technology is primarily designed to
address a wide range of use cases categorized into the enhanced mobile
broadband (eMBB), ultra-reliable and low latency communication (URLLC), and
massive machine-type communication (mMTC). Nevertheless, there are a few other
use cases which are in-between these main use cases such as industrial wireless
sensor networks, video surveillance, or wearables. In order to efficiently
serve such use cases, in Release 17, the 3rd generation partnership project
(3GPP) introduced the reduced capability NR devices (NR-RedCap) with lower cost
and complexity, smaller form factor and longer battery life compared to regular
NR devices. However, one key potential consequence of device cost and
complexity reduction is the coverage loss. In this paper, we provide a
comprehensive evaluation of NR RedCap coverage for different physical channels
and initial access messages to identify the channels/messages that are
potentially coverage limiting for RedCap UEs. We perform the coverage
evaluations for RedCap UEs operating in three different scenarios, namely
Rural, Urban and Indoor with carrier frequencies 700 MHz, 2.6 GHz and 28 GHz,
respectively. Our results confirm that for all the considered scenarios, the
amounts of required coverage recovery for RedCap channels are either less than
1 dB or can be compensated by considering smaller data rate targets for RedCap
use cases.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:56:42 GMT""}]","2021-01-20"
"2101.07311","Elina Palmgren","Ismo T. Koponen, Elina Palmgren and Esko Keski-Vakkuri","Characterising heavy-tailed networks using q-generalised entropy and
  q-adjacency kernels",,,"10.1016/j.physa.2020.125666",,"physics.soc-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Heavy-tailed networks, which have degree distributions characterised by
slower than exponentially bounded tails, are common in many different
situations. Some interesting cases, where heavy tails are characterised by
inverse powers $\lambda$ in the range $1<\lambda<2,$ arise for associative
knowledge networks, and semantic and linguistic networks. In these cases, the
differences between the networks are often delicate, calling for robust methods
to characterise the differences. Here, we introduce a method for comparing
networks using a density matrix based on q-generalised adjacency matrix
kernels. It is shown that comparison of networks can then be performed using
the q-generalised Kullback-Leibler divergence. In addition, the q-generalised
divergence can be interpreted as a q-generalised free energy, which enables the
thermodynamic-like macroscopic description of the heavy-tailed networks. The
viability of the q-generalised adjacency kernels and the thermodynamic-like
description in characterisation of complex networks is demonstrated using a
simulated set of networks, which are modular and heavy-tailed with a degree
distribution of inverse power law in the range $1<\lambda<2$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:57:25 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 08:26:55 GMT""}]","2021-01-21"
"2101.07312","Tobias Huber","Tobias Huber, Benedikt Limmer, Elisabeth Andr\'e","Benchmarking Perturbation-based Saliency Maps for Explaining Atari
  Agents",,,,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most prominent methods for explaining the behavior of Deep
Reinforcement Learning (DRL) agents is the generation of saliency maps that
show how much each pixel attributed to the agents' decision. However, there is
no work that computationally evaluates and compares the fidelity of different
saliency map approaches specifically for DRL agents. It is particularly
challenging to computationally evaluate saliency maps for DRL agents since
their decisions are part of an overarching policy. For instance, the output
neurons of value-based DRL algorithms encode both the value of the current
state as well as the value of doing each action in this state. This ambiguity
should be considered when evaluating saliency maps for such agents. In this
paper, we compare five popular perturbation-based approaches to create saliency
maps for DRL agents trained on four different Atari 2600 games. The approaches
are compared using two computational metrics: dependence on the learned
parameters of the agent (sanity checks) and fidelity to the agent's reasoning
(input degradation). During the sanity checks, we encounter issues with one
approach and propose a solution to fix these issues. For fidelity, we identify
two main factors that influence which saliency approach should be chosen in
which situation.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:57:52 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 09:02:25 GMT""},{""version"":""v3"",""created"":""Wed, 2 Feb 2022 16:46:07 GMT""}]","2022-02-03"
"2101.07313","Giacomo Fragione","Giacomo Fragione, Abraham Loeb","Constraining neutron star radii in black hole-neutron star mergers from
  their electromagnetic counterparts","6 pages, 3 figures, accepted by MNRAS",,"10.1093/mnras/stab666",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mergers of black hole (BH) and neutron star (NS) binaries are of interest
since the emission of gravitational waves (GWs) can be followed by an
electromagnetic (EM) counterpart, which could power short gamma-ray bursts.
Until now, LIGO/Virgo has only observed a candidate BH-NS event,
GW190426\_152155, which was not followed by any EM counterpart. We discuss how
the presence (absence) of a remnant disk, which powers the EM counterpart, can
be used along with spin measurements by LIGO/Virgo to derive a lower (upper)
limit on the radius of the NS. For the case of GW190426\_152155, large
measurement errors on the spin and mass ratio prevent from placing an upper
limit on the NS radius. Our proposed method works best when the aligned
component of the BH spin (with respect to the orbital angular momentum) is the
largest, and can be used to complement the information that can be extracted
from the GW signal to derive valuable information on the NS equation of state.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:58:01 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 20:23:36 GMT""}]","2021-03-17"
"2101.07314","Takuma Yagi","Takuma Yagi, Takumi Nishiyasu, Kunimasa Kawasaki, Moe Matsuki, Yoichi
  Sato","GO-Finder: A Registration-Free Wearable System for Assisting Users in
  Finding Lost Objects via Hand-Held Object Discovery","13 pages, 13 figures, ACM IUI 2021",,"10.1145/3397481.3450664",,"cs.HC cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People spend an enormous amount of time and effort looking for lost objects.
To help remind people of the location of lost objects, various computational
systems that provide information on their locations have been developed.
However, prior systems for assisting people in finding objects require users to
register the target objects in advance. This requirement imposes a cumbersome
burden on the users, and the system cannot help remind them of unexpectedly
lost objects. We propose GO-Finder (""Generic Object Finder""), a
registration-free wearable camera based system for assisting people in finding
an arbitrary number of objects based on two key features: automatic discovery
of hand-held objects and image-based candidate selection. Given a video taken
from a wearable camera, Go-Finder automatically detects and groups hand-held
objects to form a visual timeline of the objects. Users can retrieve the last
appearance of the object by browsing the timeline through a smartphone app. We
conducted a user study to investigate how users benefit from using GO-Finder
and confirmed improved accuracy and reduced mental load regarding the object
search task by providing clear visual cues on object locations.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:04:56 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 11:16:44 GMT""}]","2021-02-15"
"2101.07315","Xiaojun Yuan","Zhen-Qing He, Hang Liu, Xiaojun Yuan, Ying-Jun Angela Zhang, and
  Ying-Chang Liang","Semi-Blind Cascaded Channel Estimation for Reconfigurable Intelligent
  Surface Aided Massive MIMO",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Reconfigurable intelligent surface (RIS) is envisioned to be a promising
green technology to reduce the energy consumption and improve the coverage and
spectral efficiency of massive multiple-input multiple-output (MIMO) wireless
networks. In a RIS-aided MIMO system, the acquisition of channel state
information (CSI) is important for achieving passive beamforming gains of the
RIS, but is also challenging due to the cascaded property of the
transmitter-RIS-receiver channel and the lack of signal processing capability
of the passive RIS elements. The state-of-the-art approach for CSI acquisition
in such a system is a pure training-based strategy that depends on a long
sequence of pilot symbols. In this paper, we investigate semi-blind cascaded
channel estimation for RIS-aided massive MIMO systems, in which the receiver
simultaneously estimates the channel coefficients and the partially unknown
transmit signal with a small number of pilot sequences. Specifically, we
formulate the semi-blind cascaded channel estimation as a trilinear matrix
factorization task. Under the Bayesian inference framework, we develop a
computationally efficient iterative algorithm using the approximate message
passing principle to resolve the trilinear inference problem. Meanwhile, we
present an analytical framework to characterize the theoretical performance
bound of the proposed approach in the large-system limit via the replica method
developed in statistical physics. Extensive simulation results demonstrate the
effectiveness of the proposed semi-blind cascaded channel estimation algorithm.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:12:59 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 17:57:42 GMT""},{""version"":""v3"",""created"":""Thu, 11 Feb 2021 01:39:57 GMT""}]","2021-02-12"
"2101.07316","Dominic Bunnett","Dominic Bunnett, Michael Joswig and Julian Pfeifle","Stacky fans and tropical moduli in polymake","8 pages, v2. New title and complete restructuring with new author.
  Main result strengthened to contractibility of moduli space rather than
  trivial homology",,,,"math.CO math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate geometric embeddings among several classes of stacky fans and
algorithms, e.g., to compute their homology. Interesting cases arise from
moduli spaces of tropical curves. Specifically, we show that the tropical
honeycomb curves form a contractible sub-locus in the moduli of all tropical
$K_4$-curves.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:15:23 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 16:13:20 GMT""}]","2021-09-21"
"2101.07317","Layton Hall","Layton A. Hall, Murat Yessenov, Ayman F. Abouraddy","Space-time wave packets violate the universal relationship between
  angular dispersion and pulse-front tilt",,,"10.1364/OL.420135",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Introducing angular dispersion into a pulsed field tilts the pulse front with
respect to the phase front. There exists between the angular dispersion and the
pulse-front tilt a universal relationship that is device-independent, and also
independent of the pulse shape and bandwidth. We show here that this
relationship is violated by propagation-invariant space-time (ST) wave packets,
which are pulsed beams endowed with precise spatio-temporal structure
corresponding to a particular form of angular dispersion. We demonstrate
theoretically and experimentally that underlying ST wave packets is -- to the
best of our knowledge -- the first example in optics of non-differentiable
angular dispersion, resulting in pulse-front tilt that depends on the pulse
bandwidth even at fixed angular dispersion.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:17:39 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 14:55:29 GMT""}]","2021-09-30"
"2101.07318","Andrea Manenti","Andrea Manenti, Alessandro Vichi","Exploring $SU(N)$ adjoint correlators in $3d$","41 pages, 10 figures",,,"UUITP-04/21","hep-th cond-mat.stat-mech cond-mat.str-el hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use numerical bootstrap techniques to study correlation functions of
scalars transforming in the adjoint representation of $SU(N)$ in three
dimensions. We obtain upper bounds on operator dimensions for various
representations and study their dependence on $N$. We discover new families of
kinks, one of which could be related to bosonic QED${}_3$. We then specialize
to the cases $N=3,4$, which have been conjectured to describe a phase
transition respectively in the ferromagnetic complex projective model $CP^2$
and the antiferromagnetic complex projective model $ACP^{3}$. Lattice
simulations provide strong evidence for the existence of a second order phase
transition, while an effective field theory approach does not predict any fixed
point. We identify a set of assumptions that constrain operator dimensions to
small regions overlapping with the lattice predictions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:21:22 GMT""}]","2021-01-20"
"2101.07319","Jacek Bojarski Mr","Jacek Bojarski, Janusz Matkowski","Means in money exchange operations",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is observed that in some money exchange operations, the applied $n$
-variable mean $M$ should be self reciprocally-conjugate, i.e. it should
satisfy the equality \[ M\left( x_{1},\ldots,x_{n}\right) M\left(
\frac{1}{x_{1}},\ldots,\frac{1}{x_{n}} \right) =1,\quad x_{1},\ldots,x_{n}>0.
\] The main result says that the only weighted quasiarithmetic mean satisfying
this condition is the weighet geometric mean.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:21:57 GMT""}]","2021-01-20"
"2101.07320","Eric Nussbaum","Eric Nussbaum, Erik Sauer and Stephen Hughes","Inverse design of broadband and lossless topological photonic crystal
  waveguide modes",,"Opt. Lett. 46, 1732-1735 (2021)","10.1364/OL.420080",,"physics.optics","http://creativecommons.org/licenses/by-sa/4.0/","  Topological photonic crystal waveguides can create edge states that may be
more robust against fabrication disorder, and can yield propagation modes below
the light line. We present a fully three-dimensional method to modify
state-of-the-art designs to achieve a significant bandwidth improvement for
lossless propagation. Starting from an initial design with a normalized
bandwidth of 7.5% (13.4 THz), the modification gives more than 100% bandwidth
improvement to 16.2% (28.0 THz). This new design is obtained using automatic
differentiation enabled inverse design and a guided mode expansion technique to
efficiently calculate the band structure and edge state modes.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:26:45 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 18:12:47 GMT""}]","2021-04-19"
"2101.07321","Krenare Pireva Nuci","Vedat Apuk, Krenare Pireva Nu\c{c}i","Classification of Pedagogical content using conventional machine
  learning and deep learning model","11 pages",,,,"cs.AI cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  The advent of the Internet and a large number of digital technologies has
brought with it many different challenges. A large amount of data is found on
the web, which in most cases is unstructured and unorganized, and this
contributes to the fact that the use and manipulation of this data is quite a
difficult process. Due to this fact, the usage of different machine and deep
learning techniques for Text Classification has gained its importance, which
improved this discipline and made it more interesting for scientists and
researchers for further study. This paper aims to classify the pedagogical
content using two different models, the K-Nearest Neighbor (KNN) from the
conventional models and the Long short-term memory (LSTM) recurrent neural
network from the deep learning models. The result indicates that the accuracy
of classifying the pedagogical content reaches 92.52 % using KNN model and
87.71 % using LSTM model.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:29:34 GMT""}]","2021-01-20"
"2101.07322","Laurence Ramos","Laurence Ramos, Am\'elie Banc, Ameur Louhichi, Justine Pincemaille,
  Jacques Jestin, Zhendong Fu, Marie-Sousai Appavou, Paul Menut,
  Marie-H\'el\`ene Morel","Impact of the protein composition on the structure and viscoelasticity
  of polymer-like gluten gels","accepted for publication in Journal of Physics: Condensed Matter,
  Special issue on ""Glasses and gels: a crossroad of molecular liquids,
  polymers and colloids""","J. Phys.: Condens. Matter 33 (2021) 144001","10.1088/1361-648X/abdf91",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We investigate the structure of gluten polymer-like gels in a binary mixture
of water/ethanol, $50/50$ v/v, a good solvent for gluten proteins. Gluten
comprises two main families of proteins, monomeric gliadins and polymer
glutenins. In the semi-dilute regime, scattering experiments highlight two
classes of behavior, akin to standard polymer solution and polymer gel,
depending on the protein composition. We demonstrate that these two classes are
encoded in the structural features of the proteins in very dilute solution, and
are correlated with the presence of proteins assemblies of typical size tens of
nanometers. The assemblies only exist when the protein mixture is sufficiently
enriched in glutenins. They are found directly associated to the presence in
the gel of domains enriched in non-exchangeable H-bonds and of size comparable
to that of the protein assemblies. The domains are probed in neutron scattering
experiments thanks to their unique contrast. We show that the sample
visco-elasticity is also directly correlated to the quantity of domains
enriched in H-bonds, showing the key role of H-bonds in ruling the
visco-elasticity of polymer gluten gels.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:29:52 GMT""}]","2021-02-11"
"2101.07323","Juan Carlos Pozo","Francisco Alegr\'ia and Juan C. Pozo","Non-local in time telegraph equations and very slowly growing variances",,,,,"math.AP math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider a class of non-local in time telegraph equations.
Recently, it has been proved that the fundamental solutions of such equations
can be interpreted as the probability density function of a stochastic process.
We study the asymptotic behavior of the variance of this process at large and
short times. In this context, we develop a method to construct new examples
such the variance has a slowly growth behavior, extending the earlier results.
Finally, we show that our approach can be adapted to define new
integro-differential operators which are interesting in sub-diffusion
processes.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:40:35 GMT""}]","2021-01-20"
"2101.07324","Gabriele Bruni","G. Bruni, J. L. G\'omez, L. Vega-Garc\'ia, A. P. Lobanov, A. Fuentes,
  T. Savolainen, Y. Y. Kovalev, M. Perucho, J.-M. Mart\'i, J. M. Anderson, P.
  G. Edwards, L. I. Gurvits, M. M. Lisakov, A. B. Pushkarev, K. V. Sokolovsky,
  and J. A. Zensus","RadioAstron reveals a spine-sheath jet structure in 3C 273","Accepted by A&A","A&A 654, A27 (2021)","10.1051/0004-6361/202039423",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present Space-VLBI RadioAstron observations at 1.6 GHz and 4.8 GHz of the
flat spectrum radio quasar 3C 273, with detections on baselines up to 4.5 and
3.3 Earth Diameters, respectively. Achieving the best angular resolution at 1.6
GHz to date, we have imaged limb-brightening in the jet, not previously
detected in this source. In contrast, at 4.8 GHz, we detected emission from a
central stream of plasma, with a spatial distribution complementary to the
limb-brightened emission, indicating an origin in the spine of the jet. While a
stratification across the jet width in the flow density, internal energy,
magnetic field, or bulk flow velocity are usually invoked to explain the
limb-brightening, the different jet structure detected at the two frequencies
probably requires a stratification in the emitting electron energy
distribution. Future dedicated numerical simulations will allow the
determination of which combination of physical parameters are needed to
reproduce the spine/sheath structure observed by Space-VLBI with RadioAstron in
3C 273
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:42:04 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 09:08:49 GMT""}]","2021-10-06"
"2101.07325","Roberto Niardi","Roberto Niardi","Gauge Field Theories and Propagators in Curved Space-Time","97 pages, 2 figures. To be published in Int. J. Geom. Methods Mod.
  Phys",,"10.1142/S0219887821300014",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper DeWitt's formalism for field theories is presented; it provides
a framework in which the quantization of fields possessing infinite dimensional
invariance groups may be carried out in a manifestly covariant
(non-Hamiltonian) fashion, even in curved space-time. Another important virtue
of DeWitt's approach is that it emphasizes the common features of apparently
very different theories such as Yang-Mills theories and General Relativity;
moreover, it makes it possible to classify all gauge theories in three
categories characterized in a purely geometrical way, i.e., by the algebra
which the generators of the gauge group obey; the geometry of such theories is
the fundamental reason underlying the emergence of ghost fields in the
corresponding quantum theories, too. These ""tricky extra particles"", as Feynman
called them in 1964, contribute to a physical observable such as the
stress-energy tensor, which can be expressed in terms of Feynman's Green
function itself. Therefore, an entire section is devoted to the study of the
Green functions of the neutron scalar meson: in flat space-time, the choice of
a particular Green's function is the choice of an integration contour in the
""momentum"" space; in curved space-time the momentum space is no longer
available, and the definition of the different Green functions requires a
careful discussion itself. After the necessary introduction of bitensors, world
function and parallel displacement tensor, an expansion for the Feynman
propagator in curved space-time is obtained. Most calculations are explicitly
shown.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 20:44:13 GMT""}]","2021-01-20"
"2101.07326","Jean-Francois Berret","Evdokia K. Oikonomou, Camille Grandisson, Konstantin Golemanov, Ritu
  Ahuja and Jean-Franccois Berret","Silicone incorporation into an esterquat based fabric softener in
  presence of guar polymers","19 pages, 7 figures, 55 references","Colloids and Surfaces A: Physicochemical and Engineering Aspects
  615, 126175 (2021)","10.1016/j.colsurfa.2021.126175",,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fabric softeners are widely used to make clothes soft and impart nice smell.
Household conditioners are water-based formulations consisting of quaternary
ammonium surfactants assembled in vesicles. On the other hand, formulations
used for textiles finishing are typically silicone oil emulsions. Here, these
technologies are combined in a novel industrial formulation which contains both
surfactant vesicles and silicone oil. In particular, we insert an
amino-modified silicone oil into a recently developed softener comprising
vesicles of an esterquat and guar polymers. Two strategies based on the use of
esterquat or guar gum as stabilizers for the silicone incorporation in the
fabric softener are proposed. Dynamic light scattering (DLS), cryogenic
transmission electron microscopy (cryoTEM), optical and fluorescent microscopy
are applied to study the stability and the insertion of the silicone oil into
the softener. It is shown that silicone oil is stabilized by the surfactant and
the guar gum in nano- or micro-metric droplets. The vesicles structure and
properties are not affected by the silicone oil while the formulation stability
is preserved. These findings suggest that the proposed route for adding
silicone oil into a topical conditioner is a promising route for multipurpose
fabric softener development.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:01:43 GMT""}]","2021-09-21"
"2101.07327","Hung-Wei Tseng","Alec Rohloff and Zackary Allen and Kung-Min Lin and Joshua Okrend and
  Chengyi Nie and Yu-Chia Liu and Hung-Wei Tseng","OpenUVR: an Open-Source System Framework for Untethered Virtual Reality
  Applications",,,,,"cs.NI cs.HC cs.OS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advancements in heterogeneous computing technologies enable the significant
potential of virtual reality (VR) applications. To offer the best user
experience (UX), a system should adopt an untethered, wireless-network-based
architecture to transfer VR content between the user and the content generator.
However, modern wireless network technologies make implementing such an
architecture challenging, as VR applications require superior video quality --
with high resolution, high frame rates, and very low latency.
  This paper presents OpenUVR, an open-source framework that uses commodity
hardware components to satisfy the demands of interactive, real-time VR
applications. OpenUVR significantly improves UX through a redesign of the
system stack and addresses the most time-sensitive issues associated with
redundant memory copying in modern computing systems. OpenUVR presents a
cross-layered VR datapath to avoid redundant data operations and computation
among system components, OpenUVR customizes the network stack to eliminate
unnecessary memory operations incurred by mismatching data formats in each
layer, and OpenUVR uses feedback from mobile devices to remove memory buffers.
  Together, these modifications allow OpenUVR to reduce VR application delays
to 14.32 ms, meeting the 20 ms minimum latency in avoiding motion sickness. As
an open-source system that is fully compatible with commodity hardware, OpenUVR
offers the research community an opportunity to develop, investigate, and
optimize applications for untethered, high-performance VR architectures.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:02:16 GMT""}]","2021-01-20"
"2101.07328","Mohsen Ahmadi","Mohsen Ahmadi, Kevin Leach, Ryan Dougherty, Stephanie Forrest, and
  Westley Weimer","MIMOSA: Reducing Malware Analysis Overhead with Coverings",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  There is a growing body of malware samples that evade automated analysis and
detection tools. Malware may measure fingerprints (""artifacts"") of the
underlying analysis tool or environment and change their behavior when
artifacts are detected. While analysis tools can mitigate artifacts to reduce
exposure, such concealment is expensive. However, not every sample checks for
every type of artifact-analysis efficiency can be improved by mitigating only
those artifacts most likely to be used by a sample. Using that insight, we
propose MIMOSA, a system that identifies a small set of ""covering"" tool
configurations that collectively defeat most malware samples with increased
efficiency. MIMOSA identifies a set of tool configurations that maximize
analysis throughput and detection accuracy while minimizing manual effort,
enabling scalable automation to analyze stealthy malware. We evaluate our
approach against a benchmark of 1535 labeled stealthy malware samples. Our
approach increases analysis throughput over state of the art on over 95% of
these samples. We also investigate cost-benefit tradeoffs between the fraction
of successfully-analyzed samples and computing resources required. MIMOSA
provides a practical, tunable method for efficiently deploying analysis
resources.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:06:52 GMT""}]","2021-01-20"
"2101.07329","Lucy D'Agostino McGowan","Lucy D'Agostino McGowan, Kyra H. Grantz, and Eleanor Murray","Quantifying Uncertainty in Infectious Disease Mechanistic Models","American Journal of Epidemiology, 2021",,"10.1093/aje/kwab013",,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This primer describes the statistical uncertainty in mechanistic models and
provides R code to quantify it. We begin with an overview of mechanistic models
for infectious disease, and then describe the sources of statistical
uncertainty in the context of a case study on SARS-CoV-2. We describe the
statistical uncertainty as belonging to three categories: data uncertainty,
stochastic uncertainty, and structural uncertainty. We demonstrate how to
account for each of these via statistical uncertainty measures and sensitivity
analyses broadly, as well as in a specific case study on estimating the basic
reproductive number, $R_0$, for SARS-CoV-2.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:12:33 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 20:02:59 GMT""}]","2021-01-25"
"2101.07330","Benjamin Zhang","Benjamin Zhang, Tuhin Sahai, and Youssef Marzouk","A Koopman framework for rare event simulation in stochastic differential
  equations","Added minor revisions to the description of the methodology in
  Section 2, explanation of numerical examples in Section 3, and additional
  discussion in Section 6. One additional numerical example is provided in
  Section 3. Results are unchanged. Journal of Computational Physics, 2022",,"10.1016/j.jcp.2022.111025",,"stat.CO math.DS math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We exploit the relationship between the stochastic Koopman operator and the
Kolmogorov backward equation to construct importance sampling schemes for
stochastic differential equations. Specifically, we propose using
eigenfunctions of the stochastic Koopman operator to approximate the Doob
transform for an observable of interest (e.g., associated with a rare event)
which in turn yields an approximation of the corresponding zero-variance
importance sampling estimator. Our approach is broadly applicable and
systematic, treating non-normal systems, non-gradient systems, and systems with
oscillatory dynamics or rank-deficient noise in a common framework. In
nonlinear settings where the stochastic Koopman eigenfunctions cannot be
derived analytically, we use dynamic mode decomposition (DMD) methods to
compute them numerically, but the framework is agnostic to the particular
numerical method employed. Numerical experiments demonstrate that even coarse
approximations of a few eigenfunctions, where the latter are built from
non-rare trajectories, can produce effective importance sampling schemes for
rare events.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:23:11 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 22:22:09 GMT""}]","2022-02-09"
"2101.07331","Houssam Yassin","Houssam Yassin","Normal modes with boundary dynamics in geophysical fluids","28 pages, 5 figures","J. Math. Phys. 62, 093102 (2021)","10.1063/5.0048273",,"physics.flu-dyn math.AP physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three-dimensional geophysical fluids support both internal and
boundary-trapped waves. To obtain the normal modes in such fluids we must solve
a differential eigenvalue problem for the vertical structure (for simplicity,
we only consider horizontally periodic domains). If the boundaries are
dynamically inert (e.g., rigid boundaries in the Boussinesq internal wave
problem, flat boundaries in the quasigeostrophic Rossby wave problem) the
resulting eigenvalue problem typically has a Sturm-Liouville form and the
properties of such problems are well-known. However, when restoring forces are
also present at the boundaries, then the equations of motion contain a
time-derivative in the boundary conditions and this leads to an eigenvalue
problem where the eigenvalue correspondingly appears in the boundary
conditions. In certain cases, the eigenvalue problem can be formulated as an
eigenvalue problem in the Hilbert space $L^2\oplus \mathbb{C}$ and this theory
is well-developed. Less explored is the case when the eigenvalue problem takes
place in a Pontryagin space, as in the Rossby wave problem over sloping
topography. This article develops the theory of such problems and explores the
properties of wave problems with dynamically-active boundaries. The theory
allows us to solve the initial value problem for quasigeostrophic Rossby waves
in a region with sloping bottom (we also apply the theory to two Boussinesq
problems with a free-surface). For a step-function perturbation at a
dynamically-active boundary, we find that the resulting time-evolution consists
of waves present in proportion to their projection onto the dynamically-active
boundary.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:25:41 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 18:55:27 GMT""},{""version"":""v3"",""created"":""Sun, 21 Feb 2021 19:16:40 GMT""},{""version"":""v4"",""created"":""Mon, 6 Sep 2021 20:15:40 GMT""},{""version"":""v5"",""created"":""Tue, 14 Sep 2021 14:51:08 GMT""}]","2021-09-15"
"2101.07332","Julien Tranchida","Svetoslav Nikolov, Mitchell A. Wood, Attila Cangi, Jean-Bernard
  Maillet, Mihai-Cosmin Marinica, Aidan P. Thompson, Michael P. Desjarlais,
  Julien Tranchida","Quantum-accurate magneto-elastic predictions with classical spin-lattice
  dynamics","15 pages, 6 figures, 2 tables","npj Computational Materials 7, 153 (2021)","10.1038/s41524-021-00617-2",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  A data-driven framework is presented for building magneto-elastic
machine-learning interatomic potentials (ML-IAPs) for large-scale spin-lattice
dynamics simulations. The magneto-elastic ML-IAPs are constructed by coupling a
collective atomic spin model with an ML-IAP. Together they represent a
potential energy surface from which the mechanical forces on the atoms and the
precession dynamics of the atomic spins are computed. Both the atomic spin
model and the ML-IAP are parametrized on data from first-principles
calculations. We demonstrate the efficacy of our data-driven framework across
magneto-structural phase transitions by generating a magneto-elastic ML-IAP for
{\alpha}-iron. The combined potential energy surface yields excellent agreement
with first-principles magneto-elastic calculations and quantitative predictions
of diverse materials properties including bulk modulus, magnetization, and
specific heat across the ferromagnetic-paramagnetic phase transition.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:27:59 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 03:28:59 GMT""},{""version"":""v3"",""created"":""Tue, 2 Feb 2021 15:44:15 GMT""}]","2022-12-07"
"2101.07333","Jean-Michel Roquejoffre","Jean-Michel Roquejoffre, Violaine Roussier-Michom","Sharp large time behaviour in $N$-dimensional reaction-diffusion
  equations of bistable type",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We study the large time behaviour of the reaction-diffsuion equation
$\partial_t u=\Delta u +f(u)$ in spatial dimension $N$, when the nonlinear term
is bistable and the initial datum is compactly supported. We prove the
existence of a Lipschitz function $s^\infty$ of the unit sphere, such that
$u(t,x)$ converges uniformly in $\mathbb{R}^N$, as $t$ goes to infinity, to
  $U_{c_*}\bigg(|x|-c_*t + \frac{N-1}{c_*} \mathrm{ln}t +
s^\infty\Big(\frac{x}{|x|}\Big)\bigg)$, where $U_{c*}$ is the unique 1D
travelling profile. This extends earlier results that identified the locations
of the level sets of the solutions with $o_{t\to+\infty}(t)$ precision, or
identified precisely the level sets locations for almost radial initial data.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:28:50 GMT""}]","2021-01-20"
"2101.07334","Sishu Shankar Muni","Igor A. Shepelev, Sishu Shankar Muni, Tatyana E. Vadivasova","Synchronization of wave structures in a heterogeneous multiplex network
  of 2D vdP lattices with attractive and repulsive intra-layer coupling","20 pages, 7 figures",,"10.1063/5.0044327",,"nlin.PS nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore numerically the synchronization effects in a heterogeneous
two-layer network of two-dimensional (2D) lattices of van der Pol
oscillators.The inter-layer coupling of the multiplex network has an attractive
character. One layer of 2D lattices is characterized by attractive coupling of
oscillators and demonstrates a spiral wave regime for both the local and
nonlocal interaction. The oscillators in the second layer are coupled through
active elements and the interaction between them has the repulsive character.
We show that the lattice with the repulsive type of coupling demonstrates
complex spatiotemporal cluster structures, which can be called as
labyrinth-like structures. We show for the first time that this multiplex
network with fundamentally different types of intra-layer coupling demonstrates
the mutual synchronization and a competition between two types of structures.
Our numerical study indicates that the synchronization threshold and the type
of spatiotemporal patterns in both the layers strongly depend on the ratio of
the intra-layer coupling strength of the two lattices. We also analyze the
impact of intra-layer coupling ranges on the synchronization effects.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:36:17 GMT""}]","2021-03-17"
"2101.07335","Hongyan Guo","Hongyan Guo","Algebra of q-difference operators, affine vertex algebras, and their
  modules",,,,,"math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explore a canonical connection between the algebra of
$q$-difference operators $\widetilde{V}_{q}$, affine Lie algebra and affine
vertex algebras associated to certain subalgebra $\mathcal{A}$ of the Lie
algebra $\mathfrak{gl}_{\infty}$. We also introduce and study a category
$\mathcal{O}$ of $\widetilde{V}_{q}$-modules. More precisely, we obtain a
realization of $\widetilde{V}_{q}$ as a covariant algebra of the affine Lie
algebra $\widehat{\mathcal{A}^{*}}$, where $\mathcal{A}^{*}$ is a 1-dimensional
central extension of $\mathcal{A}$. We prove that restricted
$\widetilde{V_{q}}$-modules of level $\ell_{12}$ correspond to
$\mathbb{Z}$-equivariant $\phi$-coordinated quasi-modules for the vertex
algebra $V_{\widetilde{\mathcal{A}}}(\ell_{12},0)$, where
$\widetilde{\mathcal{A}}$ is a generalized affine Lie algebra of $\mathcal{A}$.
In the end, we show that objects in the category $\mathcal{O}$ are restricted
$\widetilde{V_{q}}$-modules, and we classify simple modules in the category
$\mathcal{O}$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:40:00 GMT""}]","2021-01-20"
"2101.07336","Christopher Mayero","Christopher Mayero and Joseph Akeyo Omolo and Onyango Stephen Okeyo","Rabi oscillations, entanglement and teleportation in the
  anti-Jaynes-Cummings model","11 pages and 6 figures",,"10.4236/jmp.2021.124029",,"quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  This paper provides a scheme for generating maximally entangled qubit states
in the anti-Jaynes-Cummings interaction mechanism, so called entangled
anti-polariton qubit states. We demonstrate that in an initial vacuum-field,
Rabi oscillations in a cavity mode in the anti-Jaynes-Cummings interaction
process, occur in the reverse sense relative to the Jaynes-Cummings interaction
process and that time evolution of entanglement in the anti-Jaynes-Cummings
interaction process takes the same form as in the Jaynes-Cummings interaction
process. With the generated anti-polariton qubit state as one of the initial
qubits, we present quantum teleportation of an atomic quantum state by applying
entanglement swapping protocol achieving an impressive maximal teleportation
fidelity~$F_\rho=1$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:41:52 GMT""},{""version"":""v2"",""created"":""Sat, 17 Jul 2021 05:06:31 GMT""}]","2021-07-20"
"2101.07337","Zijian Zhang","Zijian Zhang, Jaspreet Singh, Ujwal Gadiraju, Avishek Anand","Dissonance Between Human and Machine Understanding","23 pages, 5 figures","[J]. Proceedings of the ACM on Human-Computer Interaction, 2019,
  3(CSCW): 1-23","10.1145/3359158",,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Complex machine learning models are deployed in several critical domains
including healthcare and autonomous vehicles nowadays, albeit as functional
black boxes. Consequently, there has been a recent surge in interpreting
decisions of such complex models in order to explain their actions to humans.
Models that correspond to human interpretation of a task are more desirable in
certain contexts and can help attribute liability, build trust, expose biases
and in turn build better models. It is, therefore, crucial to understand how
and which models conform to human understanding of tasks. In this paper, we
present a large-scale crowdsourcing study that reveals and quantifies the
dissonance between human and machine understanding, through the lens of an
image classification task. In particular, we seek to answer the following
questions: Which (well-performing) complex ML models are closer to humans in
their use of features to make accurate predictions? How does task difficulty
affect the feature selection capability of machines in comparison to humans?
Are humans consistently better at selecting features that make image
recognition more accurate? Our findings have important implications on
human-machine collaboration, considering that a long term goal in the field of
artificial intelligence is to make machines capable of learning and reasoning
like humans.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:45:35 GMT""}]","2021-01-20"
"2101.07338","Marcus Angeloni","Marcus de Assis Angeloni and Helio Pedrini","Improving Makeup Face Verification by Exploring Part-Based
  Representations",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, we have seen an increase in the global facial recognition market
size. Despite significant advances in face recognition technology with the
adoption of convolutional neural networks, there are still open challenges,
such as when there is makeup in the face. To address this challenge, we propose
and evaluate the adoption of facial parts to fuse with current holistic
representations. We propose two strategies of facial parts: one with four
regions (left periocular, right periocular, nose and mouth) and another with
three facial thirds (upper, middle and lower). Experimental results obtained in
four public makeup face datasets and in a challenging cross-dataset protocol
show that the fusion of deep features extracted of facial parts with holistic
representation increases the accuracy of face verification systems and
decreases the error rates, even without any retraining of the CNN models. Our
proposed pipeline achieved competitive results for the four datasets (EMFD,
FAM, M501 and YMU).
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:51:38 GMT""},{""version"":""v2"",""created"":""Sat, 16 Oct 2021 14:59:14 GMT""}]","2021-10-19"
"2101.07339","Joshua Kim","Joshua Y. Kim, Greyson Y. Kim, Chunfeng Liu, Rafael A. Calvo, Silas
  C.R. Taylor, Kalina Yacef","MONAH: Multi-Modal Narratives for Humans to analyze conversations","14 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In conversational analyses, humans manually weave multimodal information into
the transcripts, which is significantly time-consuming. We introduce a system
that automatically expands the verbatim transcripts of video-recorded
conversations using multimodal data streams. This system uses a set of
preprocessing rules to weave multimodal annotations into the verbatim
transcripts and promote interpretability. Our feature engineering contributions
are two-fold: firstly, we identify the range of multimodal features relevant to
detect rapport-building; secondly, we expand the range of multimodal
annotations and show that the expansion leads to statistically significant
improvements in detecting rapport-building.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:55:58 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 02:25:23 GMT""}]","2021-01-21"
"2101.07340","Odilon Ardizzon Mattos","Odilon A. Mattos, Tobias Frederico, Odilon Louren\c{c}o","Thermodynamical phases in a PNJL model at zero temperature","10 pages, 11 figures","Eur. Phys. J. C 81, 24 (2021)","10.1140/epjc/s10052-021-08827-0",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The confinement/deconfinement transition described the
Polyakov-Nambu-Jona-Lasinio (PNJL) model is extended to be operative at zero
temperature regime. In this study, the scalar and vector channel interaction
strengths of the original PNJL model are modified by introducing a dependence
on the traced Polyakov loop. In such a way the effective interactions depend on
the quark phase and in turn provides a backreaction of the quarks to the
gluonic sector, also at zero temperature. On general grounds from quantum
chromodynamics this is an expected feature. The thermodynamics of the extended
model (PNJL0) is studied in detail. It presents along with a suitable choice of
the Polyakov potential, a first order confined/deconfined quark phase
transition even at $T=0$. We also show that the vector channel plays an
important role in order to allow $\Phi\ne0$ solutions for the PNJL0 model.
Furthermore, the sensitivity of the combined quarkyonic and deconfinement
phases to the vector interaction strength and the proposed parametrization of
the Polyakov-loop potential at $T=0$ allowed to set a window for the bulk
values of the relevant parameters.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:00:40 GMT""}]","2021-01-20"
"2101.07341","Leonard Hardiman","Leonard Hardiman","Graphical characterization of modular invariance","8 pages, many figures",,,,"math.QA","http://creativecommons.org/licenses/by/4.0/","  For a given modular tensor category we study representations of the
corresponding tube category whose isomorphism classes are modular invariant
matrices. In particular, we provide a characterization of these representations
in terms of the annular graphical calculus of the tube category.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:09:54 GMT""}]","2021-01-20"
"2101.07342","Trevor Doherty Mr.","Trevor Doherty, Susan McKeever, Nebras Al-Attar, Tiarnan Murphy,
  Claudia Aura, Arman Rahman, Amanda O'Neill, Stephen P Finn, Elaine Kay,
  William M. Gallagher, R. William G. Watson, Aoife Gowen and Patrick Jackman","Feature Fusion of Raman Chemical Imaging and Digital Histopathology
  using Machine Learning for Prostate Cancer Detection","19 pages, 8 tables, 18 figures",,"10.1039/D1AN00075F",,"eess.IV cs.LG q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The diagnosis of prostate cancer is challenging due to the heterogeneity of
its presentations, leading to the over diagnosis and treatment of
non-clinically important disease. Accurate diagnosis can directly benefit a
patient's quality of life and prognosis. Towards addressing this issue, we
present a learning model for the automatic identification of prostate cancer.
While many prostate cancer studies have adopted Raman spectroscopy approaches,
none have utilised the combination of Raman Chemical Imaging (RCI) and other
imaging modalities. This study uses multimodal images formed from stained
Digital Histopathology (DP) and unstained RCI. The approach was developed and
tested on a set of 178 clinical samples from 32 patients, containing a range of
non-cancerous, Gleason grade 3 (G3) and grade 4 (G4) tissue microarray samples.
For each histological sample, there is a pathologist labelled DP - RCI image
pair. The hypothesis tested was whether multimodal image models can outperform
single modality baseline models in terms of diagnostic accuracy. Binary
non-cancer/cancer models and the more challenging G3/G4 differentiation were
investigated. Regarding G3/G4 classification, the multimodal approach achieved
a sensitivity of 73.8% and specificity of 88.1% while the baseline DP model
showed a sensitivity and specificity of 54.1% and 84.7% respectively. The
multimodal approach demonstrated a statistically significant 12.7% AUC
advantage over the baseline with a value of 85.8% compared to 73.1%, also
outperforming models based solely on RCI and median Raman spectra. Feature
fusion of DP and RCI does not improve the more trivial task of tumour
identification but does deliver an observed advantage in G3/G4 discrimination.
Building on these promising findings, future work could include the acquisition
of larger datasets for enhanced model generalization.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:11:42 GMT""}]","2021-09-15"
"2101.07343","Bence Bial","Attila Nagy, Bence Bial, Judit \'Acs","Automatic punctuation restoration with BERT models","11 pages, 6 figures, source code at
  https://github.com/attilanagy234/neural-punctuator",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present an approach for automatic punctuation restoration with BERT models
for English and Hungarian. For English, we conduct our experiments on Ted
Talks, a commonly used benchmark for punctuation restoration, while for
Hungarian we evaluate our models on the Szeged Treebank dataset. Our best
models achieve a macro-averaged $F_1$-score of 79.8 in English and 82.2 in
Hungarian. Our code is publicly available.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:13:01 GMT""}]","2021-01-20"
"2101.07344","Arjun Balasubramanian","Arjun Balasubramanian, Adarsh Kumar, Yuhan Liu, Han Cao, Shivaram
  Venkataraman, Aditya Akella","Accelerating Deep Learning Inference via Learned Caches",,,,,"cs.LG cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Neural Networks (DNNs) are witnessing increased adoption in multiple
domains owing to their high accuracy in solving real-world problems. However,
this high accuracy has been achieved by building deeper networks, posing a
fundamental challenge to the low latency inference desired by user-facing
applications. Current low latency solutions trade-off on accuracy or fail to
exploit the inherent temporal locality in prediction serving workloads.
  We observe that caching hidden layer outputs of the DNN can introduce a form
of late-binding where inference requests only consume the amount of computation
needed. This enables a mechanism for achieving low latencies, coupled with an
ability to exploit temporal locality. However, traditional caching approaches
incur high memory overheads and lookup latencies, leading us to design learned
caches - caches that consist of simple ML models that are continuously updated.
We present the design of GATI, an end-to-end prediction serving system that
incorporates learned caches for low-latency DNN inference. Results show that
GATI can reduce inference latency by up to 7.69X on realistic workloads.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:13:08 GMT""}]","2021-01-20"
"2101.07345","Husileng Xiao","Husileng Xiao","On finite dimensional representations of finite W-superalgebras","V2, typos corrected,16 pages, a part overlap with arxiv:2002.10604.
  V3 a bad but not serious error is corrected( see Proposition 4.1) V4 accepted
  version","Science China Mathematics 2022","10.1007/s11425-021-2048-x",,"math.RT","http://creativecommons.org/publicdomain/zero/1.0/","  Let $\mathfrak{g}=\mathfrak{g}_{\bar{0}}+\mathfrak{g}_{\bar{1}}$ be a basic
Lie superalgebra, $\mathcal{W}_0$ (resp.$\mathcal{W}$) be the finite
W-(resp.super-) algebras constructed from a fixed nilpotent element in
$\mathfrak{g}_{\bar{0}}$. Based on a relation between finite W-algebra
$\mathcal{W}_0$ and W-superalgebra $\mathcal{W}$ found recently by the author
and Shu, we study the finite dimensional representations of finite
W-superalgebras in this paper. We first formulate and prove a version of
Premet's conjecture for the finite W-superalgebras from basic simple Lie
superalgebras. As in the W-algebra case, the Premet's conjecture is very close
to give a classification to the finite dimensional simple
$\mathcal{W}$-modules. In the case of $\ggg$ is Lie superalgebras of basic type
\Rmnum{1}, we prove the set of simple $\mathcal{W}$-supermodules is bijective
with that of simple $\mathcal{W}_0$-modules; presenting a triangular
decomposition to the tensor product of $\mathcal{W}$ with a Clifford algebra,
we also give an algorithm to compute the character of the finite dimensional
simple $\mathcal{W}$-supermodules with integral central character.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:16:12 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jan 2021 03:55:35 GMT""},{""version"":""v3"",""created"":""Mon, 19 Apr 2021 14:20:06 GMT""},{""version"":""v4"",""created"":""Sun, 12 Sep 2021 01:50:43 GMT""},{""version"":""v5"",""created"":""Mon, 17 Oct 2022 06:00:44 GMT""}]","2022-10-18"
"2101.07346","Tomasz Szemberg","Roberta Di Gennaro, Giovanna Ilardi, Rosa Maria Mir\'o-Roig, Tomasz
  Szemberg, Justyna Szpond","Companion varieties for root systems and Fermat arrangements","Revised version following advices by the referees. Accepted for
  publication in JPAA",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unexpected hypersurfaces are a brand name for some special linear systems.
They were introduced around 2017 and are a field of intensive study since then.
They attracted a lot of attention because of their close tights to various
other areas of mathematics including vector bundles, arrangements of
hyperplanes, geometry of projective varieties. Our research is motivated by the
what is now known as the BMSS duality, which is a new way of deriving
projective varieties out of already constructed. The last author coined the
concept of companion surfaces in the setting of unexpected curves admitted by
the $B_3$ root system. Here we extend this construction in various directions.
We revisit the configurations of points associated to either root systems or to
Fermat arrangements and we study the geometry of the associated varieties and
their companions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:19:24 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 16:03:33 GMT""}]","2022-02-09"
"2101.07347","Shuvo Kumar Paul","S. K. Paul, M. T. Chowdhury, M. Nicolescu, M. Nicolescu","Object Detection and Pose Estimation from RGB and Depth Data for
  Real-time, Adaptive Robotic Grasping",,,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  In recent times, object detection and pose estimation have gained significant
attention in the context of robotic vision applications. Both the
identification of objects of interest as well as the estimation of their pose
remain important capabilities in order for robots to provide effective
assistance for numerous robotic applications ranging from household tasks to
industrial manipulation. This problem is particularly challenging because of
the heterogeneity of objects having different and potentially complex shapes,
and the difficulties arising due to background clutter and partial occlusions
between objects. As the main contribution of this work, we propose a system
that performs real-time object detection and pose estimation, for the purpose
of dynamic robot grasping. The robot has been pre-trained to perform a small
set of canonical grasps from a few fixed poses for each object. When presented
with an unknown object in an arbitrary pose, the proposed approach allows the
robot to detect the object identity and its actual pose, and then adapt a
canonical grasp in order to be used with the new pose. For training, the system
defines a canonical grasp by capturing the relative pose of an object with
respect to the gripper attached to the robot's wrist. During testing, once a
new pose is detected, a canonical grasp for the object is identified and then
dynamically adapted by adjusting the robot arm's joint angles, so that the
gripper can grasp the object in its new pose. We conducted experiments using a
humanoid PR2 robot and showed that the proposed framework can detect
well-textured objects, and provide accurate pose estimation in the presence of
tolerable amounts of out-of-plane rotation. The performance is also illustrated
by the robot successfully grasping objects from a wide range of arbitrary
poses.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:22:47 GMT""}]","2021-01-20"
"2101.07348","Arvind Balasubramanian","Arvind Balasubramanian, Alessandra Corsi, Emil Polisensky, Tracy E.
  Clarke, Namir E. Kassim","Radio observations of SN2004dk with VLITE confirm late-time
  re-brightening","10 pages, 4 figures. Published in ApJ","ApJ 923 (2021) 32","10.3847/1538-4357/ac2154",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of stripped-envelope core-collapse supernovae (SNe), with evidence
for strong interaction of SN ejecta with the circumstellar medium (CSM),
provides insights into the pre-supernova progenitor, and a fast-forwarded view
of the progenitor mass-loss history. In this context, we present late-time
radio observations of SN2004dk, a type Ibc supernova located in the galaxy, NGC
6118, at a distance of $d_L \approx 23$ Mpc. About 15 years after explosion,
SN2004dk has shown evidence for H$\alpha$ emission, possibly linked to the SN
ejecta interacting with an H-rich CSM. Using data from the VLA Low Band
Ionosphere and Transient Experiment (VLITE), we confirm the presence of a
late-time radio re-brightening accompanying the observed H$\alpha$ emission. We
model the SN2004dk radio light curves within the (spherically symmetric)
synchrotron-self-absorption (SSA) model. Within this model, our VLITE
observations combined with previously collected VLA data favor an
interpretation of SN2004dk as a strongly CSM-interacting radio SN going through
a complex environment shaped by a non-steady mass-loss from the SN progenitor.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:27:37 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 16:23:44 GMT""}]","2021-12-15"
"2101.07349","Rui Ni","Ashik Ullah Mohammad Masuk, Ashwanth K. R. Salibindla, and Rui Ni","Simultaneous measurements of deforming Hinze-scale bubbles with
  surrounding turbulence",,,"10.1017/jfm.2020.933",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally investigate the breakup mechanisms and probability of
Hinze-scale bubbles in turbulence. The Hinze scale is defined as the critical
bubble size based on the critical mean Weber number, across which the bubble
breakup probability was believed to have an abrupt transition from being
dominated by turbulence stresses to being suppressed completely by the surface
tension. In this work, to quantify the breakup probability of bubbles with
sizes close to the Hinze scale and to examine different breakup mechanisms,
both bubbles and their surrounding tracer particles were simultaneously
tracked. From the experimental results, two Weber numbers, one calculated from
the slip velocity between the two phases and the other one acquired from local
velocity gradients, are separated and fitted with models that can be linked
back to turbulence characteristics. Moreover, we also provide an empirical
model to link bubble deformation to the two Weber numbers by extending the
relationship obtained from potential flow theory. The proposed relationship
between bubble aspect ratio and the Weber numbers seems to work consistently
well for a range of bubble sizes. Furthermore, the time traces of the bubble
aspect ratio and the two Weber numbers are connected using the linear forced
oscillator model. Finally, having access to the distributions of these two
Weber numbers provides a unique way to extract the breakup probability of
bubbles with sizes close to the Hinze scale.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:27:58 GMT""}]","2021-02-03"
"2101.07350","Tajudeen Yahaya Dr.","Tajudeen Yahaya, Titilola Salisu, Yusuf Abdulrahman, Abdulrazak Umar","Update on the genetic and epigenetic etiology of gestational diabetes
  mellitus: a review","14 pages",,,,"q-bio.GN","http://creativecommons.org/licenses/by/4.0/","  Background: Many studies have been conducted on the genetic and epigenetic
etiology of gestational diabetes mellitus (GDM) in the last two decades because
of the diseases increasing prevalence and role in the global diabetes mellitus
(DM) explosion. An update on the genetic and epigenetic etiology of GDM then
becomes imperative to better understand and stem the rising incidence of the
disease. This review, therefore, articulated GDM candidate genes and their
pathophysiology for the awareness of stakeholders. Main body (genetic and
epigenetic etiology, GDM): The search discovered 83 GDM candidate genes, of
which TCF7L2, MTNR1B, CDKAL1, IRS1, and KCNQ1 are the most prevalent. Certain
polymorphisms of these genes can modulate beta-cell dysfunction, adiposity,
obesity, and insulin resistance through several mechanisms. Environmental
triggers such as diets, pollutants, and microbes may also cause epigenetic
changes in these genes, resulting in a loss of insulin-boosting and glucose
metabolism functions. Early detection and adequate management may resolve the
condition after delivery; otherwise, it will progress to maternal type 2
diabetes mellitus (T2DM) and fetal configuration to future obesity and DM. This
shows that GDM is a strong risk factor for T2DM and, in rare cases, type 1
diabetes mellitus (T1DM) and maturity-onset diabetes of the young (MODY). This
further shows that GDM significantly contributes to the rising incidence and
burden of DM worldwide and its prevention may reverse the trend. Conclusion:
Mutations and epigenetic changes in certain genes are strong risk factors for
GDM. For affected individuals with such etiologies, medical practitioners
should formulate drugs and treatment procedures that target these genes and
their pathophysiology.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:33:47 GMT""}]","2021-01-20"
"2101.07351","Pablo Calder\'on","Pablo Calder\'on, Mariano Ruiz","On perturbations of woven pairs of frames",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we prove some results related to small perturbations of a frame
for a Hilbert space $\mathcal{H}$ in order to have a woven pair for
$\mathcal{H}$. Our results complete those known in the literature. In addition
we study a necessary condition for a woven pair, that resembles a
characterization for Riesz frames.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:39:20 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 11:30:34 GMT""},{""version"":""v3"",""created"":""Fri, 4 Mar 2022 20:59:16 GMT""}]","2022-03-08"
"2101.07353","Yan Peng","Yan Peng","A unified hoop conjecture for black holes and horizonless compact stars","5 pages",,,,"gr-qc hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We propose a unified version of hoop conjecture valid for various black holes
and horizonless compact stars. This conjecture is expressed by the mass to
circumference ratio $4\pi M_{in}/C\leqslant 1$, where C is the circumference of
the smallest ring that can engulf the object in all azimuthal directions and
$M_{in}$ is the mass within the engulfing sphere.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:46:47 GMT""}]","2021-01-20"
"2101.07354","Yichi Zhang","Yichi Zhang, Minh Tang","Exact Recovery of Community Structures Using DeepWalk and Node2vec",,,,,"stat.ML cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random-walk based network embedding algorithms like DeepWalk and node2vec are
widely used to obtain Euclidean representation of the nodes in a network prior
to performing downstream inference tasks. However, despite their impressive
empirical performance, there is a lack of theoretical results explaining their
large-sample behavior. In this paper, we study node2vec and DeepWalk through
the perspective of matrix factorization. In particular, we analyze these
algorithms in the setting of community detection for stochastic blockmodel
graphs (and their degree-corrected variants). By exploiting the row-wise
uniform perturbation bound for leading singular vectors, we derive
high-probability error bounds between the matrix factorization-based
node2vec/DeepWalk embeddings and their true counterparts, uniformly over all
node embeddings. Based on strong concentration results, we further show the
perfect membership recovery by node2vec/DeepWalk, followed by $K$-means/medians
algorithms. Specifically, as the network becomes sparser, our results guarantee
that with large enough window size and vertices number, applying
$K$-means/medians on the matrix factorization-based node2vec embeddings can,
with high probability, correctly recover the memberships of all vertices in a
network generated from the stochastic blockmodel (or its degree-corrected
variants). The theoretical justifications are mirrored in the numerical
experiments and real data applications, for both the original node2vec and its
matrix factorization variant.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:49:22 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 03:00:47 GMT""}]","2022-10-25"
"2101.07355","Celine Merlet","El Hassane Lahrar and Irena Deroche and Cam\'elia Matei Ghimbeu and
  Patrice Simon and C\'eline Merlet","On the effect of surface functional groups on the structural and
  dynamical properties of an ionic liquid confined in zeolite templated carbons
  studied through molecular simulations",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Porous carbons are used in a wide range of applications, including
electrochemical double layer capacitors for energy storage, in which
electrolyte ion properties under confinement are crucial for the performance of
the systems. While many synthesis techniques lead to the presence of surface
functional groups, their effect on the adsorption and diffusion of electrolyte
ions is still poorly understood. In this study we investigate the effect of
surface chemistry on dynamical and structural properties of adsorbed ions
through molecular dynamics simulations of a neat ionic liquid in contact with
several zeolite templated carbons. The steric and specific influence of
functional groups is explored using three structures: a structure without any
functional groups; a structure with ester, hydroxyl, anhydride acid and
carboxyl functional groups; and a structure where the oxygen and hydrogen atoms
are replaced by carbon atoms. We show that the functionalization has a limited
impact on the structure of the confined electrolyte but affects the diffusion
coefficients, and that the relative importance of the structure and chemical
nature of the functional groups is not the same depending on the ion type and
property considered.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:49:28 GMT""}]","2021-01-20"
"2101.07356","Yekbun Adiguzel","Yekbun Adiguzel","Peptides of H. sapiens and P. falciparum that are predicted to bind
  strongly to HLA-A*24:02 and homologous to a SARS-CoV-2 peptide","37 pages, 4 figures",,"10.1016/j.actatropica.2021.106013",,"q-bio.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aim: This study is looking for a common pathogenicity between SARS-CoV-2 and
plasmodium species, in individuals with certain HLA serotypes. Methods: 1-)
Tblastx searches of SARS-CoV-2 are performed by limiting searches to plasmodium
species that infect human. 2-) Aligned sequences in the respective organisms'
proteomes are searched with blastp. 3-) Binding predictions of the identified
SARS-CoV-2 peptide to MHC class I supertype representatives are performed. 4-)
Blastp searches of predicted-epitopes that bind strongly to the identified HLA
allele are performed by limiting searches to human and to the plasmodium
species. 5-) Peptides with minimum 60 % identity to the predicted-epitopes are
found in results. 6-) Peptides among those, which bind strongly to the same HLA
allele, are predicted. 7-) Step-4 is repeated by limiting searches to human,
for peptides sourced by limiting searches to plasmodium species at step-4. 8-)
Step-5 and 6 are performed with results of 7. Results: CFLGYFCTCYFGLFC peptide
of SARS-CoV-2 has the highest identity to P. vivax. Its GYFCTCYFGLF and
YFCTCYFGLF parts are predicted to bind strongly to HLA-A*24:02. Results
obtained only for peptides homologous to YFCTCYFGLF, as follows: YYCARRFGLF,
YYCHCPFGVF, and YYCQQYFFLF are potential HLA-A*24:02 epitopes in the human
proteome. Among FFYTFYFELF, YFVACLFILF, and YFPTITFHLF peptides in the
plasmodium species' proteomes with strong binding affinity to HLA-A*24:02, only
FFYTFYFELF of P. falciparum is homologous to the potential HLA-A*24:02 epitope
YFYLFSLELF in the human proteome. Conclusion: Immune responses to the
identified-peptides with similar sequences and strong binding affinities to
HLA-A*24:02 may lead to autoimmune response risk in individuals with
HLA-A*24:02 serotypes, upon getting infected with SARS-CoV-2 or P. falciparum.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:52:07 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 00:19:52 GMT""},{""version"":""v3"",""created"":""Thu, 11 Feb 2021 00:11:28 GMT""},{""version"":""v4"",""created"":""Tue, 23 Feb 2021 06:19:14 GMT""},{""version"":""v5"",""created"":""Thu, 27 May 2021 04:21:09 GMT""}]","2021-06-22"
"2101.07357","David Lim","David K. Lim, Naim U. Rashid, Junier B. Oliva, Joseph G. Ibrahim","Unsupervised Imputation of Non-ignorably Missing Data Using
  Importance-Weighted Autoencoders","31 pages, 4 figures, 2 tables, under review (Biometrics Methodology)",,,,"cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  Deep Learning (DL) methods have dramatically increased in popularity in
recent years. While its initial success was demonstrated in the classification
and manipulation of image data, there has been significant growth in the
application of DL methods to problems in the biomedical sciences. However, the
greater prevalence and complexity of missing data in biomedical datasets
present significant challenges for DL methods. Here, we provide a formal
treatment of missing data in the context of Variational Autoencoders (VAEs), a
popular unsupervised DL architecture commonly utilized for dimension reduction,
imputation, and learning latent representations of complex data. We propose a
new VAE architecture, NIMIWAE, that is one of the first to flexibly account for
both ignorable and non-ignorable patterns of missingness in input features at
training time. Following training, samples can be drawn from the approximate
posterior distribution of the missing data can be used for multiple imputation,
facilitating downstream analyses on high dimensional incomplete datasets. We
demonstrate through statistical simulation that our method outperforms existing
approaches for unsupervised learning tasks and imputation accuracy. We conclude
with a case study of an EHR dataset pertaining to 12,000 ICU patients
containing a large number of diagnostic measurements and clinical outcomes,
where many features are only partially observed.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:53:29 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 20:05:41 GMT""},{""version"":""v3"",""created"":""Fri, 17 Jun 2022 21:59:17 GMT""}]","2022-06-22"
"2101.07358","Bhavini Singh","Bhavini Singh, Lalit K. Rajendran, Pavlos P. Vlachos and Sally P. M.
  Bane","Shock generated vorticity in spark discharges","Submitted to the Journal of Physics D",,"10.1088/1361-6463/abfe7f",,"physics.flu-dyn physics.app-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spark discharges induce a complex flow field consisting of a shock wave at
early times (~ 1 $\mu$ s), a pair of vortex rings, and a hot gas kernel. The
vortex rings entrain ambient gas into the hot gas kernel and control its
cooling and expansion. In this work, we investigate the shock wave's
contribution in producing the vortex ring vorticity. We analyze high-speed (700
kHz) schlieren images of the shock wave for a range of electrical energies to
measure the shock properties and estimate shock velocity and curvature. These
measurements are combined with a model to calculate the vorticity generated.
The measurements show that the highest vorticity is generated near the peak
shock curvature location, and the shock curvature and strength increase with
electrical energy deposited. A comparison of the vorticity estimated from the
model to vorticity measurements from stereoscopic particle image velocimetry
shows the results to be statistically equivalent. This suggests that the shock
curvature and velocity contribute to the vortex rings induced by spark
discharges.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:53:40 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 20:59:30 GMT""}]","2021-07-07"
"2101.07359","Zeyu Bian","Zeyu Bian, Erica EM Moodie, Susan M Shortreed and Sahir Bhatnagar","Variable Selection in Regression-based Estimation of Dynamic Treatment
  Regimes",,,,,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  Dynamic treatment regimes (DTRs) consist of a sequence of decision rules, one
per stage of intervention, that finds effective treatments for individual
patients according to patient information history. DTRs can be estimated from
models which include the interaction between treatment and a small number of
covariates which are often chosen a priori. However, with increasingly large
and complex data being collected, it is difficult to know which prognostic
factors might be relevant in the treatment rule. Therefore, a more data-driven
approach of selecting these covariates might improve the estimated decision
rules and simplify models to make them easier to interpret. We propose a
variable selection method for DTR estimation using penalized dynamic weighted
least squares. Our method has the strong heredity property, that is, an
interaction term can be included in the model only if the corresponding main
terms have also been selected. Through simulations, we show our method has both
the double robustness property and the oracle property, and the newly proposed
methods compare favorably with other variable selection approaches.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:53:55 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 03:58:18 GMT""},{""version"":""v3"",""created"":""Fri, 3 Dec 2021 19:30:40 GMT""}]","2021-12-07"
"2101.07360","Saeed Seddighin","Michael Mitzenmacher and Saeed Seddighin","Dynamic Longest Increasing Subsequence and the Erd\""{o}s-Szekeres
  Partitioning Problem",,,,,"cs.DS","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we provide new approximation algorithms for dynamic variations
of the longest increasing subsequence (\textsf{LIS}) problem, and the
complementary distance to monotonicity (\textsf{DTM}) problem. In this setting,
operations of the following form arrive sequentially: (i) add an element, (ii)
remove an element, or (iii) substitute an element for another. At every point
in time, the algorithm has an approximation to the longest increasing
subsequence (or distance to monotonicity). We present a
$(1+\epsilon)$-approximation algorithm for \textsf{DTM} with polylogarithmic
worst-case update time and a constant factor approximation algorithm for
\textsf{LIS} with worst-case update time $\tilde O(n^\epsilon)$ for any
constant $\epsilon > 0$.% $n$ in the runtime denotes the size of the array at
the time the operation arrives.
  Our dynamic algorithm for \textsf{LIS} leads to an almost optimal algorithm
for the Erd\""{o}s-Szekeres partitioning problem. Erd\""{o}s-Szekeres
partitioning problem was introduced by Erd\""{o}s and Szekeres in 1935 and was
known to be solvable in time $O(n^{1.5}\log n)$. Subsequent work improve the
runtime to $O(n^{1.5})$ only in 1998. Our dynamic \textsf{LIS} algorithm leads
to a solution for Erd\""{o}s-Szekeres partitioning problem with runtime $\tilde
O_{\epsilon}(n^{1+\epsilon})$ for any constant $\epsilon > 0$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:55:32 GMT""}]","2021-01-20"
"2101.07361","Maliha Islam","Maliha Tashfia Islam, Anna Fariha, Alexandra Meliou, Babak Salimi","Through the Data Management Lens: Experimental Analysis and Evaluation
  of Fair Classification","Technical report of SIGMOD 2022 paper",,,,"cs.LG cs.CY cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classification, a heavily-studied data-driven machine learning task, drives
an increasing number of prediction systems involving critical human decisions
such as loan approval and criminal risk assessment. However, classifiers often
demonstrate discriminatory behavior, especially when presented with biased
data. Consequently, fairness in classification has emerged as a high-priority
research area. Data management research is showing an increasing presence and
interest in topics related to data and algorithmic fairness, including the
topic of fair classification. The interdisciplinary efforts in fair
classification, with machine learning research having the largest presence,
have resulted in a large number of fairness notions and a wide range of
approaches that have not been systematically evaluated and compared. In this
paper, we contribute a broad analysis of 13 fair classification approaches and
additional variants, over their correctness, fairness, efficiency, scalability,
robustness to data errors, sensitivity to underlying ML model, data efficiency,
and stability using a variety of metrics and real-world datasets. Our analysis
highlights novel insights on the impact of different metrics and high-level
approach characteristics on different aspects of performance. We also discuss
general principles for choosing approaches suitable for different practical
settings, and identify areas where data-management-centric solutions are likely
to have the most impact.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:55:40 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 06:52:56 GMT""},{""version"":""v3"",""created"":""Fri, 24 Dec 2021 23:05:12 GMT""},{""version"":""v4"",""created"":""Sun, 10 Apr 2022 02:13:04 GMT""}]","2022-04-12"
"2101.07362","Lucy Auton DPhil","Lucy C. Auton, Satyajit Pramanik, Mohit P. Dalwadi, Christopher W.
  MacMinn, and Ian M. Griffiths","A homogenised model for flow, transport and sorption in a heterogeneous
  porous medium",,,"10.1017/jfm.2021.938",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major challenge in flow through porous media is to better understand the
link between microstructure and macroscale flow and transport. For idealised
microstructures, the mathematical framework of homogenisation theory can be
used for this purpose. Here, we consider a two-dimensional microstructure
comprising an array of obstacles of smooth but arbitrary shape, the size and
spacing of which can vary along the length of the porous medium. We use
homogenisation via the method of multiple scales to systematically upscale a
novel problem involving cells of varying area to obtain effective continuum
equations for macroscale flow and transport. The equations are characterised by
the local porosity, a local anisotropic flow permeability, an effective local
anisotropic solute diffusivity, and an effective local adsorption rate. These
macroscale properties depend nontrivially on the two degrees of microstructural
geometric freedom in our problem: obstacle size, and obstacle spacing. We
exploit this dependence to construct and compare scenarios where the same
porosity profile results from different combinations of obstacle size and
spacing. We focus on a simple example geometry comprising circular obstacles on
a rectangular lattice, for which we numerically determine the macroscale
permeability and effective diffusivity. We investigate scenarios where the
porosity is spatially uniform but the permeability and diffusivity are not. Our
results may be useful in the design of filters, or for studying the impact of
deformation on transport in soft porous media.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:56:47 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 20:47:17 GMT""}]","2021-12-22"
"2101.07363","Rchid Rabaoui","Rchid Rabaoui","Some results on higher order isosymmetries in Semi-Hilbertian Spaces",,,,,"math.FA","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we introduce the class of $(A,(m,n))$-isosymmetric operators
and we study some of their properties, for a positive semi-definite operator
$A$ and $ m,n\in\mathbb{ N}$, which extend, by changing the initial inner
product with the semi-inner product induced by $A$, the well-known class of
$(m,n)$-isosymmetric operators introduced by Mark Stankus (\cite{mark1},
\cite{mark}). In particular, we characterize a family of $A$-isosymmetric
$(2\times2)$ upper triangular operator matrices. Moreover, we show that that if
$T$ is $(A,(m,n))$-isosymmetric and if $Q$ is a nilpotent operator of order $r$
doubly commuting with $T$, then $T^p$ is $(A,(m,n))$-isosymmetric symmetric for
any $p\in \mathbb{N}$ and $(T +Q)$ is $\big(A,(m+2r -2, n+2r
-1)\big)$-isosymmetric. Some properties of the spectrum are also investigated.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:58:31 GMT""}]","2021-01-20"
"2101.07364","Domingo  Garc\'ia-Senz","Domingo Garc\'ia-Senz, Rub\'en M. Cabez\'on and Jos\'e A. Escart\'in","Conservative, density-based smoothed particle hydrodynamics with
  improved partition of the unity and better estimation of gradients","20 pages, 20 figures, published in Astronomy and Astrophysics","A&A 659, A175 (2022)","10.1051/0004-6361/202141877",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The correct evaluation of gradients is at the cornerstone of the smoothed
particle hydrodynamics (SPH) technique. Using an integral approach to estimate
gradients has proven to enhance accuracy substantially. Such approach retains
the Lagrangian structure of SPH equations and is fully conservative. But, in
practice, it is difficult to make the Lagrangian formulation totally consistent
to an exact partition of the unity.
  In this paper we study, among other things, the connection between the choice
of the volume elements (VEs), which enters in the SPH summations, and the
accuracy in the gradient estimation within the integral approach scheme (ISPH).
A new variant of VEs are proposed which improve the partition of the unity and
is fully compatible with the Lagrangian formulation of SPH, including the
grad-h corrections. Using analytic considerations, simple static toy models in
1D, and a few full 3D test cases, we show that any improvement in the partition
of the unity also leads to a better calculation of gradients when the integral
approach is used jointly. Additionally, we propose an easy-to-implement
modification of the ISPH scheme, which makes it more flexible and better suited
to handle sharp density contrasts.
  The ISPH code built with the proposed scheme has been validated with a good
number of standard tests, some of them involving contact discontinuities. The
performance of the code was excellent in all of them, showing that an
improvement in the partition of the unity is not detrimental of the good
conservation of energy, momentum, and entropy typical of Lagrangian schemes.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:04:01 GMT""},{""version"":""v2"",""created"":""Thu, 30 Dec 2021 13:05:55 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 19:12:09 GMT""},{""version"":""v4"",""created"":""Wed, 30 Mar 2022 09:01:34 GMT""}]","2022-03-31"
"2101.07365","Rafael Dowsley","Amanda Resende, Davis Railsback, Rafael Dowsley, Anderson C. A.
  Nascimento, Diego F. Aranha","Fast Privacy-Preserving Text Classification based on Secure Multiparty
  Computation",,,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a privacy-preserving Naive Bayes classifier and apply it to the
problem of private text classification. In this setting, a party (Alice) holds
a text message, while another party (Bob) holds a classifier. At the end of the
protocol, Alice will only learn the result of the classifier applied to her
text input and Bob learns nothing. Our solution is based on Secure Multiparty
Computation (SMC). Our Rust implementation provides a fast and secure solution
for the classification of unstructured text. Applying our solution to the case
of spam detection (the solution is generic, and can be used in any other
scenario in which the Naive Bayes classifier can be employed), we can classify
an SMS as spam or ham in less than 340ms in the case where the dictionary size
of Bob's model includes all words (n = 5200) and Alice's SMS has at most m =
160 unigrams. In the case with n = 369 and m = 8 (the average of a spam SMS in
the database), our solution takes only 21ms.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:08:12 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 06:26:21 GMT""}]","2021-06-09"
"2101.07366","Vishvesh Kumar","A.R. Bagheri Salec, Vishvesh Kumar and S.M. Tabatabaie","Convolution Properties of Orlicz Spaces on hypergroups","13 pages. To appear in Proc. Amer. Math. Soc",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, for a locally compact commutative hypergroup $K$ and for a
pair $(\Phi_1, \Phi_2)$ of Young functions satisfying sequence condition, we
give a necessary condition in terms of aperiodic elements of the center of $K,$
for the convolution $f\ast g$ to exist a.e., where $f$ and $g$ are arbitrary
elements of Orlicz spaces $L^{\Phi_1}(K)$ and $L^{\Phi_2}(K)$, respectively. As
an application, we present some equivalent conditions for compactness of a
compactly generated locally compact abelian group. Moreover, we also
characterize compact convolution operators from $L^1_w(K)$ into $L^\Phi_w(K)$
for a weight $w$ on a locally compact hypergroup $K$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:09:05 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 20:24:37 GMT""}]","2021-07-29"
"2101.07370","Berat Kurar Barakat","Berat Kurar Barakat, Ahmad Droby, Reem Alaasam, Boraq Madi, Irina
  Rabaev, Jihad El-Sana","Text line extraction using fully convolutional network and energy
  minimization",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Text lines are important parts of handwritten document images and easier to
analyze by further applications. Despite recent progress in text line
detection, text line extraction from a handwritten document remains an unsolved
task. This paper proposes to use a fully convolutional network for text line
detection and energy minimization for text line extraction. Detected text lines
are represented by blob lines that strike through the text lines. These blob
lines assist an energy function for text line extraction. The detection stage
can locate arbitrarily oriented text lines. Furthermore, the extraction stage
is capable of finding out the pixels of text lines with various heights and
interline proximity independent of their orientations. Besides, it can finely
split the touching and overlapping text lines without an orientation
assumption. We evaluate the proposed method on VML-AHTE, VML-MOC, and
Diva-HisDB datasets. The VML-AHTE dataset contains overlapping, touching and
close text lines with rich diacritics. The VML-MOC dataset is very challenging
by its multiply oriented and skewed text lines. The Diva-HisDB dataset exhibits
distinct text line heights and touching text lines. The results demonstrate the
effectiveness of the method despite various types of challenges, yet using the
same parameters in all the experiments.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:23:03 GMT""}]","2021-01-20"
"2101.07371","Kangning Wang","Liang Lyu, Brandon Fain, Kamesh Munagala and Kangning Wang","Centrality with Diversity","Accepted by the 14th ACM International Conference on Web Search and
  Data Mining (WSDM 2021)",,"10.1145/3437963.3441789",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph centrality measures use the structure of a network to quantify central
or ""important"" nodes, with applications in web search, social media analysis,
and graphical data mining generally. Traditional centrality measures such as
the well known PageRank interpret a directed edge as a vote in favor of the
importance of the linked node. We study the case where nodes may belong to
diverse communities or interests and investigate centrality measures that can
identify nodes that are simultaneously important to many such diverse
communities. We propose a family of diverse centrality measures formed as fixed
point solutions to a generalized nonlinear eigenvalue problem. Our measure can
be efficiently computed on large graphs by iterated best response and we study
its normative properties on both random graph models and real-world data. We
find that we are consistently and efficiently able to identify the most
important diverse nodes of a graph, that is, those that are simultaneously
central to multiple communities.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:26:30 GMT""}]","2021-01-20"
"2101.07372","Jose Munoz","Malik A Dawi and Jose J Munoz","Stability bounds of a delay visco-elastic rheological model with
  substrate friction",,,,,"q-bio.TO math.DS","http://creativecommons.org/licenses/by/4.0/","  Cells and tissues exhibit oscillatory deformations during remodelling,
migration or embryogenesis. Although it has been shown that these oscillations
correlate with cell biochemical signalling, it is yet unclear the role of these
oscillations in triggering drastic cell reorganisation events or instabilities,
and the coupling of this oscillatory response with tested visco-elastic
properties.
  We here present a rheological model that incorporates elastic, viscous and
frictional components, and that is able to generate oscillatory response
through a delay adaptive process of the rest-length. We analyse its stability
properties as a function of the model parameters and deduce analytical bounds
of the stable domain. While increasing values of the delay and remodelling rate
render the model unstable, we also show that increasing friction with the
substrate destabilise the oscillatory response. Furthermore, we numerically
verify that the extension of the model to non-linear strain measures is able to
generate sustained oscillations that alternate between stable and unstable
regions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:26:45 GMT""}]","2021-01-20"
"2101.07373","Simon Johnston","Simon Johnston, C. Sobey, S. Dai, M. Keith, M. Kerr, R. N. Manchester,
  L. S. Oswald, A. Parthasarathy, R. M. Shannon, P. Weltevrede","Two years of pulsar observations with the Ultra-Wideband Receiver on the
  Parkes radio telescope","Accepted for publication in MNRAS. This version fixes transcription
  errors in Table 4",,"10.1093/mnras/stab095",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/publicdomain/zero/1.0/","  The major programme for observing young, non-recycled pulsars with the Parkes
telescope has transitioned from a narrow-band system to an ultra-wideband
system capable of observing between 704 and 4032 MHz. We report here on the
initial two years of observations with this receiver. Results include
dispersion measure (DM) and Faraday rotation measure (RM) variability with
time, determined with higher precision than hitherto, flux density measurements
and the discovery of several nulling and mode changing pulsars. PSR J1703-4851
is shown to be one of a small subclass of pulsars that has a weak and a strong
mode which alternate rapidly in time. PSR J1114-6100 has the fourth highest
|RM| of any known pulsar despite its location far from the Galactic Centre. PSR
J1825-1446 shows variations in both DM and RM likely due to its motion behind a
foreground supernova remnant.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:27:45 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 21:54:04 GMT""}]","2021-02-10"
"2101.07374","Kaiqiong Zhao","Kaiqiong Zhao, Karim Oualkacha, Lajmi Lakhal-Chaieb, Aur\'elie Labbe,
  Kathleen Klein, Sasha Bernatsky, Marie Hudson, In\'es Colmegna, Celia M.T.
  Greenwood","Detecting differentially methylated regions in bisulfite sequencing data
  using quasi-binomial mixed models with smooth covariate effect estimates",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying disease-associated changes in DNA methylation can help to gain a
better understanding of disease etiology. Bisulfite sequencing technology
allows the generation of methylation profiles at single base of DNA. We
previously developed a method for estimating smooth covariate effects and
identifying differentially methylated regions (DMRs) from bisulfite sequencing
data, which copes with experimental errors and variable read depths; this
method utilizes the binomial distribution to characterize the variability in
the methylated counts. However, bisulfite sequencing data frequently include
low-count integers and can exhibit over or under dispersion relative to the
binomial distribution. We present a substantial improvement to our previous
work by proposing a quasi-likelihood-based regional testing approach which
accounts for multiplicative and additive sources of dispersion. We demonstrate
the theoretical properties of the resulting tests, as well as their marginal
and conditional interpretations. Simulations show that the proposed method
provides correct inference for smooth covariate effects and captures the major
methylation patterns with excellent power.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:29:27 GMT""}]","2021-01-20"
"2101.07375","Ivan Kaygorodov","Ivan Kaygorodov and Farukh Mashurov","One-generated nilpotent assosymmetric algebras","arXiv admin note: substantial text overlap with arXiv:1903.08997,
  arXiv:2004.03598",,"10.1142/S0219498822500311",,"math.RA","http://creativecommons.org/publicdomain/zero/1.0/","  We give the classification of $5$- and $6$-dimensional complex one-generated
nilpotent assosymmetric algebras.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:30:53 GMT""}]","2021-01-20"
"2101.07376","Khalid Alsamadony","Khalid L. Alsamadony, Ertugrul U. Yildirim, Guenther Glatz, Umair bin
  Waheed, Sherif M. Hanafy","Deep-Learning Driven Noise Reduction for Reduced Flux Computed
  Tomography",,"Sensors 21, no. 5: 1921 (2021)","10.3390/s21051921",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have received considerable attention in clinical
imaging, particularly with respect to the reduction of radiation risk. Lowering
the radiation dose by reducing the photon flux inevitably results in the
degradation of the scanned image quality. Thus, researchers have sought to
exploit deep convolutional neural networks (DCNNs) to map low-quality, low-dose
images to higher-dose, higher-quality images thereby minimizing the associated
radiation hazard. Conversely, computed tomography (CT) measurements of
geomaterials are not limited by the radiation dose. In contrast to the human
body, however, geomaterials may be comprised of high-density constituents
causing increased attenuation of the X-Rays. Consequently, higher dosage images
are required to obtain an acceptable scan quality. The problem of prolonged
acquisition times is particularly severe for micro-CT based scanning
technologies. Depending on the sample size and exposure time settings, a single
scan may require several hours to complete. This is of particular concern if
phenomena with an exponential temperature dependency are to be elucidated. A
process may happen too fast to be adequately captured by CT scanning. To
address the aforementioned issues, we apply DCNNs to improve the quality of
rock CT images and reduce exposure times by more than 60\%, simultaneously. We
highlight current results based on micro-CT derived datasets and apply transfer
learning to improve DCNN results without increasing training time. The approach
is applicable to any computed tomography technology. Furthermore, we contrast
the performance of the DCNN trained by minimizing different loss functions such
as mean squared error and structural similarity index.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:31:37 GMT""}]","2021-09-14"
"2101.07377","Sanchari Das","Sanchari Das and Robert S. Gutzwiller and Rod D. Roscoe and Prashanth
  Rajivan and Yang Wang and L. Jean Camp and Roberto Hoyle","Panel: Humans and Technology for Inclusive Privacy and Security",,,,,"cs.CR cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  Computer security and user privacy are critical issues and concerns in the
digital era due to both increasing users and threats to their data. Separate
issues arise between generic cybersecurity guidance (i.e., protect all user
data from malicious threats) and the individualistic approach of privacy (i.e.,
specific to users and dependent on user needs and risk perceptions). Research
has shown that several security- and privacy-focused vulnerabilities are
technological (e.g., software bugs (Streiff, Kenny, Das, Leeth, & Camp, 2018),
insecure authentication (Das, Wang, Tingle, & Camp, 2019)), or behavioral
(e.g., sharing passwords (Das, Dingman, & Camp, 2018); and compliance (Das,
Dev, & Srinivasan, 2018) (Dev, Das, Rashidi, & Camp, 2019)). This panel
proposal addresses a third category of sociotechnical vulnerabilities that can
and sometimes do arise from non-inclusive design of security and privacy. In
this panel, we will address users' needs and desires for privacy. The panel
will engage in in-depth discussions about value-sensitive design while focusing
on potentially vulnerable populations, such as older adults, teens, persons
with disabilities, and others who are not typically emphasized in general
security and privacy concerns. Human factors have a stake in and ability to
facilitate improvements in these areas.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:35:42 GMT""}]","2021-01-20"
"2101.07378","Jade Checlair","Jade H. Checlair, Geronimo L. Villanueva, Benjamin P.C. Hayworth,
  Stephanie L. Olson, Thaddeus D. Komacek, Tyler D. Robinson, Predrag Popovic,
  Huanzhou Yang, Dorian S. Abbot","Probing the capability of future direct imaging missions to spectrally
  constrain the frequency of Earth-like planets","Accepted at The Astronomical Journal, January 7 2021. arXiv admin
  note: substantial text overlap with arXiv:2008.03952",,"10.3847/1538-3881/abdb36",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A critical question in astrobiology is whether exoEarth candidates (EECs) are
Earth-like, in that they originate life that progressively oxygenates their
atmospheres similarly to Earth. We propose answering this question
statistically by searching for O2 and O3 on EECs with missions such as HabEx or
LUVOIR. We explore the ability of these missions to constrain the fraction, fE,
of EECs that are Earth-like in the event of a null detection of O2 or O3 on all
observed EECs. We use the Planetary Spectrum Generator to simulate observations
of EECs with O2 and O3 levels based on Earth's history. We consider four
instrument designs: LUVOIR-A (15m), LUVOIR-B (8m), HabEx with a starshade (4m,
""HabEx/SS""), HabEx without a starshade (4m, ""HabEx/no-SS""); as well as three
estimates of the occurrence rate of EECs (eta_earth): 24%, 5%, and 0.5%. In the
case of a null-detection, we find that for eta_earth = 24%, LUVOIR-A, LUVOIR-B,
and HabEx/SS would constrain fE to <= 0.094, <= 0.18, and <= 0.56,
respectively. This also indicates that if fE is greater than these upper
limits, we are likely to detect O3 on at least 1 EEC. Conversely, we find that
HabEx/no-SS cannot constrain fE, due to the lack of an coronagraph ultraviolet
channel. For eta_earth = 5%, only LUVOIR-A and LUVOIR-B would be able to
constrain fE, to <= 0.45 and <= 0.85, respectively. For eta_earth = 0.5%, none
of the missions would allow us to constrain fE, due to the low number of
detectable EECs. We conclude that the ability to constrain fE is more robust to
uncertainties in eta_earth for missions with larger aperture mirrors. However
all missions are susceptible to an inconclusive null detection if eta_earth is
sufficiently low.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:37:09 GMT""}]","2021-03-03"
"2101.07379","Xia Hong","Dawei Li, Shuo Sun, Zhiyong Xiao, Jingfeng Song, Ding-Fu Shao, Evgeny
  Y. Tsymbal, Stephen Ducharme, and Xia Hong","Giant Transport Anisotropy in ReS$_2$ Revealed via Nanoscale Conducting
  Path Control","13 pages, 4 figures, w. Supplemental Material","Phys. Rev. Lett. 127, 136803 (2021)","10.1103/PhysRevLett.127.136803",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low in-plane symmetry in layered 1T'-ReS$_2$ results in strong band
anisotropy, while its manifestation in the electronic properties is challenging
to resolve due to the lack of effective approaches for controlling the local
current path. In this work, we reveal the giant transport anisotropy in
monolayer to four-layer ReS$_2$ by creating directional conducting paths via
nanoscale ferroelectric control. By reversing the polarization of a
ferroelectric polymer top layer, we induce conductivity switching ratio of
>1.5x10$^8$ in the ReS$_2$ channel at 300 K. Characterizing the domain-defined
conducting nanowires in an insulating background shows that the conductivity
ratio between the directions along and perpendicular to the Re-chain can exceed
5.5x10$^4$. Theoretical modeling points to the band origin of the transport
anomaly, and further reveals the emergence of a flat band in few-layer ReS$_2$.
Our work paves the path for implementing the highly anisotropic 2D materials
for designing novel collective phenomena and electron lensing applications.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:46:08 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 01:00:27 GMT""}]","2021-09-29"
"2101.07380","Aur\'elien Bibaut","Aurelien Bibaut, Maya Petersen, Nikos Vlassis, Maria Dimakopoulou,
  Mark van der Laan","Sequential causal inference in a single world of connected units",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider adaptive designs for a trial involving N individuals that we
follow along T time steps. We allow for the variables of one individual to
depend on its past and on the past of other individuals. Our goal is to learn a
mean outcome, averaged across the N individuals, that we would observe, if we
started from some given initial state, and we carried out a given sequence of
counterfactual interventions for $\tau$ time steps.
  We show how to identify a statistical parameter that equals this mean
counterfactual outcome, and how to perform inference for this parameter, while
adaptively learning an oracle design defined as a parameter of the true data
generating distribution. Oracle designs of interest include the design that
maximizes the efficiency for a statistical parameter of interest, or designs
that mix the optimal treatment rule with a certain exploration distribution. We
also show how to design adaptive stopping rules for sequential hypothesis
testing.
  This setting presents unique technical challenges. Unlike in usual
statistical settings where the data consists of several independent
observations, here, due to network and temporal dependence, the data reduces to
one single observation with dependent components. In particular, this precludes
the use of sample splitting techniques. We therefore had to develop a new
equicontinuity result and guarantees for estimators fitted on dependent data.
  We were motivated to work on this problem by the following two questions. (1)
In the context of a sequential adaptive trial with K treatment arms, how to
design a procedure to identify in as few rounds as possible the treatment arm
with best final outcome? (2) In the context of sequential randomized disease
testing at the scale of a city, how to estimate and infer the value of an
optimal testing and isolation strategy?
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:56:57 GMT""}]","2021-01-20"
"2101.07381","Shintaro Ito","A. Aguilar-Arevalo, M. Aoki, M. Blecher, D.I. Britton, D. vom Bruch,
  D.A. Bryman, S. Chen, J. Comfort, S. Cuen-Rochin, L. Doria, P. Gumplinger, A.
  Hussein, Y. Igarashi, S. Ito, S. Kettell, L. Kurchaninov, L.S. Littenberg, C.
  Malbrunot, R.E. Mischke, T. Numao, D. Protopopescu, A. Sher, T. Sullivan, D.
  Vavilov","Search for three body pion decays ${\pi}^+{\to}l^+{\nu}X$","8 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2006.00389","Phys. Rev. D 103, 052006 (2021)","10.1103/PhysRevD.103.052006",,"hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  The three body pion decays ${\pi}^+{\rightarrow}l^+{\nu}X~(l=e,{\mu})$, where
$X$ is a weakly interacting neutral boson, were searched for using the full
data set from the PIENU experiment. An improved limit on
${\Gamma}({\pi}^+{\to}e^+{\nu}X)/{\Gamma}({\pi}^+{\to}{\mu}^+{\nu}_{\mu})$ in
the mass range $0<m_X<120$ MeV/$c^2$ and a first result for
${\Gamma}({\pi}^+{\to}{\mu}^+{\nu}X)/{\Gamma}({\pi}^+{\to}{\mu}^+{\nu}_{\mu})$
in the region $0<m_X<33.9$ MeV/$c^2$ were obtained. The Majoron-neutrino
coupling model was also constrained using the current experimental result of
the ${\pi}^+{\to}e^+{\nu}_e({\gamma})$ branching ratio.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:59:13 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 07:06:10 GMT""}]","2021-03-24"
"2101.07382","Nikos Voskarides","Svitlana Vakulenko, Nikos Voskarides, Zhucheng Tu, Shayne Longpre","A Comparison of Question Rewriting Methods for Conversational Passage
  Retrieval","ECIR 2021 short paper",,,,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversational passage retrieval relies on question rewriting to modify the
original question so that it no longer depends on the conversation history.
Several methods for question rewriting have recently been proposed, but they
were compared under different retrieval pipelines. We bridge this gap by
thoroughly evaluating those question rewriting methods on the TREC CAsT 2019
and 2020 datasets under the same retrieval pipeline. We analyze the effect of
different types of question rewriting methods on retrieval performance and show
that by combining question rewriting methods of different types we can achieve
state-of-the-art performance on both datasets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:17:52 GMT""}]","2021-01-20"
"2101.07383","Kai Yao","Kai Yao, Alberto Ortiz, Francisco Bonnin-Pascual","A DCNN-based Arbitrarily-Oriented Object Detector for Quality Control
  and Inspection Application",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the success of machine vision systems for on-line automated quality
control and inspection processes, an object recognition solution is presented
in this work for two different specific applications, i.e., the detection of
quality control items in surgery toolboxes prepared for sterilizing in a
hospital, as well as the detection of defects in vessel hulls to prevent
potential structural failures. The solution has two stages. First, a feature
pyramid architecture based on Single Shot MultiBox Detector (SSD) is used to
improve the detection performance, and a statistical analysis based on ground
truth is employed to select parameters of a range of default boxes. Second, a
lightweight neural network is exploited to achieve oriented detection results
using a regression method. The first stage of the proposed method is capable of
detecting the small targets considered in the two scenarios. In the second
stage, despite the simplicity, it is efficient to detect elongated targets
while maintaining high running efficiency.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:23:27 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 12:12:54 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jun 2022 05:41:36 GMT""}]","2022-07-01"
"2101.07384","Ira M. Gessel","Ira M. Gessel","On a polynomial congruence for Eulerian polynomials",,,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  We give a short proof, using generating functions, for a polynomial
congruence for Eulerian polynomials first proved, using arrangements of
hyperplanes, by Yoshinaga and later proved, using roots of unity, by Iijima,
Sasaki, Takahashi, and Yoshinaga.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:28:11 GMT""}]","2021-01-20"
"2101.07385","Maximilian Amsler","Sebastian Ament, Maximilian Amsler, Duncan R. Sutherland, Ming-Chiang
  Chang, Dan Guevarra, Aine B. Connolly, John M. Gregoire, Michael O. Thompson,
  Carla P. Gomes, R. Bruce van Dover","Autonomous synthesis of metastable materials",,"Autonomous materials synthesis via hierarchical active learning of
  nonequilibrium phase diagrams, Science Advances, Vol 7, Issue 5, 2021","10.1126/sciadv.abg4930",,"cond-mat.mtrl-sci cs.AI cs.LG cs.MA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous experimentation enabled by artificial intelligence (AI) offers a
new paradigm for accelerating scientific discovery. Non-equilibrium materials
synthesis is emblematic of complex, resource-intensive experimentation whose
acceleration would be a watershed for materials discovery and development. The
mapping of non-equilibrium synthesis phase diagrams has recently been
accelerated via high throughput experimentation but still limits materials
research because the parameter space is too vast to be exhaustively explored.
We demonstrate accelerated synthesis and exploration of metastable materials
through hierarchical autonomous experimentation governed by the Scientific
Autonomous Reasoning Agent (SARA). SARA integrates robotic materials synthesis
and characterization along with a hierarchy of AI methods that efficiently
reveal the structure of processing phase diagrams. SARA designs lateral
gradient laser spike annealing (lg-LSA) experiments for parallel materials
synthesis and employs optical spectroscopy to rapidly identify phase
transitions. Efficient exploration of the multi-dimensional parameter space is
achieved with nested active learning (AL) cycles built upon advanced machine
learning models that incorporate the underlying physics of the experiments as
well as end-to-end uncertainty quantification. With this, and the coordination
of AL at multiple scales, SARA embodies AI harnessing of complex scientific
tasks. We demonstrate its performance by autonomously mapping synthesis phase
boundaries for the Bi$_2$O$_3$ system, leading to orders-of-magnitude
acceleration in establishment of a synthesis phase diagram that includes
conditions for kinetically stabilizing $\delta$-Bi$_2$O$_3$ at room
temperature, a critical development for electrochemical technologies such as
solid oxide fuel cells.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:29:26 GMT""},{""version"":""v2"",""created"":""Sun, 19 Dec 2021 15:16:08 GMT""}]","2021-12-21"
"2101.07386","Christopher Caruvana","Christopher Caruvana and Robert R. Kallman","Applications of Descriptive Set Theory to Complex Analysis",,,,,"math.CV math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Descriptive set theory can be used to prove new results in classical complex
analysis. Let $\mathcal{A}(\Omega)$ be the set of complex analytic functions on
an open subset $\Omega \subseteq \mathbb{C}$ endowed with the usual topology of
uniform convergence on compact subsets. $\mathcal{A}(\Omega)$ is a Polish ring
with the operations of point-wise addition and point-wise multiplication.
Inspired by Bers' algebraic characterization of the relation of conformality,
we show that the topology on $\mathcal{A}(\Omega)$ is the only Polish topology
for which $\mathcal{A}(\Omega)$ is a Polish ring for arbitrary open $\Omega$.
In a different direction, we show that the bounded complex-analytic functions
on the unit disk admits no Polish topology for which it is a Polish ring. Along
these lines, a corollary of our general result is that the abstract field of
meromorphic functions on an open $\Omega$ cannot be made into a Polish field.
We also study the Lie ring structure on $\mathcal{A}(\Omega)$ which turns out
to be a Polish Lie ring with the usual topology. In this case, we restrict our
attention to those domains $\Omega$ that are connected. We extend a result of
Amemiya to see that the Lie ring structure is determined by the conformal
structure of $\Omega$. In a similar vein to our ring considerations, we see
that, for certain domains $\Omega$ of usual interest, the Lie ring
$\mathcal{A}(\Omega)$ has a unique Polish topology for which it is a Polish Lie
ring.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:36:47 GMT""}]","2021-01-20"
"2101.07387","Yefan Tian","Yefan Tian, Nader Ghassemi, Joseph H. Ross Jr","Gap-opening transition in Dirac semimetal ZrTe$_5$","5 pages, 4 figures","Phys. Rev. Lett. 126, 236401 (2021)","10.1103/PhysRevLett.126.236401",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply $^{125}$Te nuclear magnetic resonance (NMR) spectroscopy to
investigate the Dirac semimetal ZrTe$_5$. With the NMR magnetic field parallel
to the $b$-axis, we observe significant quantum magnetic effects. These include
an abrupt drop at 150 K in spin-lattice relaxation rate. This corresponds to a
gap-opening transition in the Dirac carriers, likely indicating the onset of
excitonic pairing. Below 50 K, we see a more negative shift for the Te$_z$
bridging site indicating the repopulation of Dirac levels with spin polarized
carriers at these temperatures. This is the previously reported 3D quantum Hall
regime; however, we see no sign of a charge density wave as has been proposed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:40:42 GMT""}]","2021-06-14"
"2101.07388","Bill Tomlinson","Bill Tomlinson, Rebecca W. Black","Work Online, Welfare Calls, and Wine Night: Effects of the COVID-19
  Pandemic on Individuals' Technology Use","20 pages, 1 figure",,,,"cs.HC cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The COVID-19 pandemic has changed the ways many people use computational
systems. We conducted an empirical study, using qualitative and quantitative
analyses of free-response surveys completed by 62 US residents, to explore how
COVID-19 affected their computer use across work, education, home life, and
social life. Nearly all participants experienced an increase in computer usage
for themselves or a family member in one or more of the four domains. The
increases involved both increasing frequency of existing uses as well as the
adoption of new types of use. Changes in usage impacted many aspects of
people's lives, including relationships, affective experiences, and life
trajectories. Understanding these changes is important to the future of HCI, as
the field adapts to COVID-19 and potential future pandemics.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:43:00 GMT""}]","2021-01-20"
"2101.07389","Qiufan Lin","Qiufan Lin and Dominique Fouchez and J\'er\^ome Pasquet","Galaxy Image Translation with Semi-supervised Noise-reconstructed
  Generative Adversarial Networks","Accepted at ICPR 2020",,"10.1109/ICPR48806.2021.9412143",,"cs.CV astro-ph.IM eess.IV","http://creativecommons.org/licenses/by/4.0/","  Image-to-image translation with Deep Learning neural networks, particularly
with Generative Adversarial Networks (GANs), is one of the most powerful
methods for simulating astronomical images. However, current work is limited to
utilizing paired images with supervised translation, and there has been rare
discussion on reconstructing noise background that encodes instrumental and
observational effects. These limitations might be harmful for subsequent
scientific applications in astrophysics. Therefore, we aim to develop methods
for using unpaired images and preserving noise characteristics in image
translation. In this work, we propose a two-way image translation model using
GANs that exploits both paired and unpaired images in a semi-supervised manner,
and introduce a noise emulating module that is able to learn and reconstruct
noise characterized by high-frequency features. By experimenting on multi-band
galaxy images from the Sloan Digital Sky Survey (SDSS) and the Canada France
Hawaii Telescope Legacy Survey (CFHT), we show that our method recovers global
and local properties effectively and outperforms benchmark image translation
models. To our best knowledge, this work is the first attempt to apply
semi-supervised methods and noise reconstruction techniques in astrophysical
studies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:43:14 GMT""}]","2022-02-16"
"2101.07390","Vijay Vazirani","Vijay V. Vazirani","The General Graph Matching Game: Approximate Core","10 pages",,,,"cs.GT econ.TH math.CO","http://creativecommons.org/licenses/by/4.0/","  The classic paper of Shapley and Shubik \cite{Shapley1971assignment}
characterized the core of the assignment game using ideas from matching theory
and LP-duality theory and their highly non-trivial interplay. Whereas the core
of this game is always non-empty, that of the general graph matching game can
be empty.
  This paper salvages the situation by giving an imputation in the
$2/3$-approximate core for the latter. This bound is best possible, since it is
the integrality gap of the natural underlying LP. Our profit allocation method
goes further: the multiplier on the profit of an agent is often better than ${2
\over 3}$ and lies in the interval $[{2 \over 3}, 1]$, depending on how
severely constrained the agent is.
  Next, we provide new insights showing how discerning core imputations of an
assignment games are by studying them via the lens of complementary slackness.
We present a relationship between the competitiveness of individuals and teams
of agents and the amount of profit they accrue in imputations that lie in the
core, where by {\em competitiveness} we mean whether an individual or a team is
matched in every/some/no maximum matching. This also sheds light on the
phenomenon of degeneracy in assignment games, i.e., when the maximum weight
matching is not unique.
  The core is a quintessential solution concept in cooperative game theory. It
contains all ways of distributing the total worth of a game among agents in
such a way that no sub-coalition has incentive to secede from the grand
coalition. Our imputation, in the $2/3$-approximate core, implies that a
sub-coalition will gain at most a $3/2$ factor by seceding, and less in typical
cases.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:53:22 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 05:10:16 GMT""},{""version"":""v3"",""created"":""Mon, 26 Apr 2021 12:08:16 GMT""},{""version"":""v4"",""created"":""Fri, 16 Jul 2021 17:55:03 GMT""}]","2021-07-19"
"2101.07391","Maria Jose Pacifico","Diego Barros, Christian Bonatti and Maria Jose Pacifico","Up, down, two-sided Lorenz attractor, collisions, merging and switching","64 pages and 21 figures",,,,"math.DS","http://creativecommons.org/publicdomain/zero/1.0/","  We present a slightly modified version of the well known ""geometric Lorenz
attractor"". It consists in a C1 open set O of vector fields in R3 having an
attracting region U containing: (1) a unique singular saddle point sigma; (2) a
unique attractor Lambda containing the singular point; (3) the maximal
invariant in U contains at most 2 chain recurrence classes, which are Lambda
and (at most) one hyperbolic horseshoe. The horseshoe and the singular
attractor have a collision along the union of 2 co-dimension 1 sub-manifolds
which divide O in 3 regions. By crossing this collision locus, the attractor
and the horseshoe may merge in a two-sided Lorenz attractor, or they may
exchange their nature: the Lorenz attractor expel the singular point sigma and
becomes a horseshoe and the horseshoe absorbs sigma becoming a Lorenz
attractor.
  By crossing this collision locus, the attractor and the horseshoe may merge
in a two-sided Lorenz attractor, or they may exchange their nature: the Lorenz
attractor expel the singular point sigma and becomes a horseshoe and the
horseshoe absorbs sigma becoming a Lorenz attractor.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:56:10 GMT""}]","2021-01-20"
"2101.07392","Ellicott Matthay","Ellicott C. Matthay, Erin Hagan, Laura M. Gottlieb, May Lynn Tan,
  David Vlahov, Nancy Adler, M. Maria Glymour","Powering population health research: Considerations for plausible and
  actionable effect sizes","24 pages, 1 figure",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Evidence for Action (E4A), a signature program of the Robert Wood Johnson
Foundation, funds investigator-initiated research on the impacts of social
programs and policies on population health and health inequities. Across
thousands of letters of intent and full proposals E4A has received since 2015,
one of the most common methodological challenges faced by applicants is
selecting realistic effect sizes to inform power and sample size calculations.
E4A prioritizes health studies that are both (1) adequately powered to detect
effect sizes that may reasonably be expected for the given intervention and (2)
likely to achieve intervention effects sizes that, if demonstrated, correspond
to actionable evidence for population health stakeholders. However, little
guidance exists to inform the selection of effect sizes for population health
research proposals. We draw on examples of five rigorously evaluated population
health interventions. These examples illustrate considerations for selecting
realistic and actionable effect sizes as inputs to power and sample size
calculations for research proposals to study population health interventions.
We show that plausible effects sizes for population health inteventions may be
smaller than commonly cited guidelines suggest. Effect sizes achieved with
population health interventions depend on the characteristics of the
intervention, the target population, and the outcomes studied. Population
health impact depends on the proportion of the population receiving the
intervention. When adequately powered, even studies of interventions with small
effect sizes can offer valuable evidence to inform population health if such
interventions can be implemented broadly. Demonstrating the effectiveness of
such interventions, however, requires large sample sizes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:56:30 GMT""}]","2021-01-20"
"2101.07393","Austin W. Hanjie","Austin W. Hanjie, Victor Zhong, Karthik Narasimhan","Grounding Language to Entities and Dynamics for Generalization in
  Reinforcement Learning","Accepted to ICML 2021. Note author list and name changes from
  previous version",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the use of natural language to drive the generalization of
control policies and introduce the new multi-task environment Messenger with
free-form text manuals describing the environment dynamics. Unlike previous
work, Messenger does not assume prior knowledge connecting text and state
observations $-$ the control policy must simultaneously ground the game manual
to entity symbols and dynamics in the environment. We develop a new model, EMMA
(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned
attention module that allows for selective focus over relevant descriptions in
the manual for each entity in the environment. EMMA is end-to-end
differentiable and learns a latent grounding of entities and dynamics from text
to observations using only environment rewards. EMMA achieves successful
zero-shot generalization to unseen games with new dynamics, obtaining a 40%
higher win rate compared to multiple baselines. However, win rate on the
hardest stage of Messenger remains low (10%), demonstrating the need for
additional work in this direction.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:59:16 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 23:34:49 GMT""}]","2021-06-15"
"2101.07394","Ming Zeng","Ming Zeng, Ebrahim Bedeer, Xingwang Li, Quoc-Viet Pham, Octavia A.
  Dobre, Paul Fortier, Leslie A. Rusch","IRS-Empowered Wireless Communications: State-of-the-Art, Key Techniques,
  and Open Issues","submitted to IEEE Magazines, Intelligent reflecting surface (IRS),
  millimeter wave, non-orthogonal multiple access, physical layer security,
  hardware impairments",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we overview intelligent reflecting surface (IRS)-empowered
wireless communication systems. We first present the fundamentals of
IRS-assisted wireless transmission. On this basis, we explore the integration
of IRS with various advanced transmission technologies, such as millimeter
wave, non-orthogonal multiple access, and physical layer security. Following
this, we discuss the effects of hardware impairments and imperfect
channel-state-information on the IRS system performance. Finally, we highlight
several open issues to be addressed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:00:37 GMT""}]","2021-01-20"
"2101.07395","Amir Sagiv","Amir Sagiv","Spectral convergence of probability densities for forward problems in
  uncertainty quantification",,,,,"math.NA cs.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The estimation of probability density functions (PDF) using approximate maps
is a fundamental building block in computational probability. We consider
forward problems in uncertainty quantification: the inputs or the parameters of
a deterministic model are random with a known distribution. The scalar quantity
of interest is a fixed measurable function of the parameters, and is therefore
a random variable as a well. Often, the quantity of interest map is not
explicitly known and difficult to compute, and so the computational problem is
to design a good approximation (surrogate model) of the quantity of interest.
For the goal of approximating the {\em moments} of the quantity of interest,
there is a well developed body of research. One widely popular approach is
generalized Polynomial Chaos (gPC) and its many variants, which approximate
moments with spectral accuracy. However, it is not clear whether the quantity
of interest can be approximated with spectral accuracy as well. This result
does not follow directly from spectrally accurate moment estimation. In this
paper, we prove convergence rates for PDFs using collocation and Galerkin gPC
methods with Legendre polynomials in all dimensions. In particular, exponential
convergence of the densities is guaranteed for analytic quantities of interest.
In one dimension, we provide more refined results with stronger convergence
rates, as well as an alternative proof strategy based on optimal-transport
techniques.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:00:50 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 23:24:19 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 01:44:46 GMT""}]","2022-03-28"
"2101.07396","Panos Achlioptas","Panos Achlioptas, Maks Ovsjanikov, Kilichbek Haydarov, Mohamed
  Elhoseiny, Leonidas Guibas","ArtEmis: Affective Language for Visual Art","https://artemisdataset.org",,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a novel large-scale dataset and accompanying machine learning
models aimed at providing a detailed understanding of the interplay between
visual content, its emotional effect, and explanations for the latter in
language. In contrast to most existing annotation datasets in computer vision,
we focus on the affective experience triggered by visual artworks and ask the
annotators to indicate the dominant emotion they feel for a given image and,
crucially, to also provide a grounded verbal explanation for their emotion
choice. As we demonstrate below, this leads to a rich set of signals for both
the objective content and the affective impact of an image, creating
associations with abstract concepts (e.g., ""freedom"" or ""love""), or references
that go beyond what is directly visible, including visual similes and
metaphors, or subjective references to personal experiences. We focus on visual
art (e.g., paintings, artistic photographs) as it is a prime example of imagery
created to elicit emotional responses from its viewers. Our dataset, termed
ArtEmis, contains 439K emotion attributions and explanations from humans, on
81K artworks from WikiArt. Building on this data, we train and demonstrate a
series of captioning systems capable of expressing and explaining emotions from
visual stimuli. Remarkably, the captions produced by these systems often
succeed in reflecting the semantic and abstract content of the image, going
well beyond systems trained on existing datasets. The collected dataset and
developed methods are available at https://artemisdataset.org.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:03:40 GMT""}]","2021-01-20"
"2101.07397","Yi Zhang","Qingyuan Hu, Yi Zhang, Kanishka Misra, Julia Rayz","Exploring Lexical Irregularities in Hypothesis-Only Models of Natural
  Language Inference","Accepted by 2020 IEEE 19th International Conference on Cognitive
  Informatics & Cognitive Computing (ICCI* CC). IEEE",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) is
the task of predicting the entailment relation between a pair of sentences
(premise and hypothesis). This task has been described as a valuable testing
ground for the development of semantic representations, and is a key component
in natural language understanding evaluation benchmarks. Models that understand
entailment should encode both, the premise and the hypothesis. However,
experiments by Poliak et al. revealed a strong preference of these models
towards patterns observed only in the hypothesis, based on a 10 dataset
comparison. Their results indicated the existence of statistical irregularities
present in the hypothesis that bias the model into performing competitively
with the state of the art. While recast datasets provide large scale generation
of NLI instances due to minimal human intervention, the papers that generate
them do not provide fine-grained analysis of the potential statistical patterns
that can bias NLI models. In this work, we analyze hypothesis-only models
trained on one of the recast datasets provided in Poliak et al. for word-level
patterns. Our results indicate the existence of potential lexical biases that
could contribute to inflating the model performance.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:08:06 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 22:52:27 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jan 2021 01:37:22 GMT""}]","2021-01-25"
"2101.07398","Jacob Spertus","Jacob V Spertus","Optimal sampling and assay for soil organic carbon estimation","30 pages, 3 figures",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The world needs around 150 Pg of negative carbon emissions to mitigate
climate change. Global soils may provide a stable, sizeable reservoir to help
achieve this goal by sequestering atmospheric carbon dioxide as soil organic
carbon (SOC). In turn, SOC can support healthy soils and provide a multitude of
ecosystem benefits. To support SOC sequestration, researchers and policy makers
must be able to precisely measure the amount of SOC in a given plot of land.
SOC measurement is typically accomplished by taking soil cores selected at
random from the plot under study, mixing (compositing) some of them together,
and analyzing (assaying) the composited samples in a laboratory. Compositing
reduces assay costs, which can be substantial. Taking samples is also costly.
Given uncertainties and costs in both sampling and assay along with a desired
estimation precision, there is an optimal composite size that will minimize the
budget required to achieve that precision. Conversely, given a fixed budget,
there is a composite size that minimizes uncertainty. In this paper, we
describe and formalize sampling and assay for SOC and derive the optima for
three commonly used assay methods: dry combustion in an elemental analyzer,
loss-on-ignition, and mid-infrared spectroscopy. We demonstrate the utility of
this approach using data from a soil survey conducted in California. We give
recommendations for practice and provide software to implement our framework.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:23:37 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 20:12:30 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 03:20:02 GMT""},{""version"":""v4"",""created"":""Mon, 30 Aug 2021 19:09:19 GMT""}]","2021-09-01"
"2101.07399","Yuyang Wang","Yuyang Wang, Zhonglin Cao, Amir Barati Farimani","Deep Reinforcement Learning Optimizes Graphene Nanopores for Efficient
  Desalination","Yuyang Wang and Zhonglin Cao contributed equally to this work","npj 2D Mater Appl 5, 66 (2021)","10.1038/s41699-021-00246-9",,"cs.LG physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional nanomaterials, such as graphene, have been extensively
studied because of their outstanding physical properties. Structure and
geometry optimization of nanopores on such materials is beneficial for their
performances in real-world engineering applications, like water desalination.
However, the optimization process often involves very large number of
experiments or simulations which are expensive and time-consuming. In this
work, we propose a graphene nanopore optimization framework via the combination
of deep reinforcement learning (DRL) and convolutional neural network (CNN) for
efficient water desalination. The DRL agent controls the growth of nanopore by
determining the atom to be removed at each timestep, while the CNN predicts the
performance of nanoporus graphene for water desalination: the water flux and
ion rejection at a certain external pressure. With the synchronous feedback
from CNN-accelerated desalination performance prediction, our DRL agent can
optimize the nanoporous graphene efficiently in an online manner. Molecular
dynamics (MD) simulations on promising DRL-designed graphene nanopores show
that they have higher water flux while maintaining rival ion rejection rate
compared to the normal circular nanopores. Semi-oval shape with rough edges
geometry of DRL-designed pores is found to be the key factor for their high
water desalination performance. Ultimately, this study shows that DRL can be a
powerful tool for material design.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:24:18 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 05:03:18 GMT""}]","2022-01-19"
"2101.07400","Alex Rutar","Kathryn E. Hare and Alex Rutar","Local Dimensions of Self-similar Measures Satisfying the Finite
  Neighbour Condition","32 pages, 4 figures. Published version with various minor fixes","Nonlinearity 35 (2022), 4876-4904","10.1088/1361-6544/ac8040",,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We study sets of local dimensions for self-similar measures in $\mathbb{R}$
satisfying the finite neighbour condition, which is formally stronger than the
weak separation condition but satisfied in all known examples. Under a mild
technical assumption, we establish that the set of attainable local dimensions
is a finite union of (possibly singleton) compact intervals. The number of
intervals is bounded above by the number of non-trivial maximal strongly
connected components of a finite directed graph construction depending only on
the governing iterated function system. We also explain how our results allow
computations of the sets of local dimensions in many explicit cases. This
contextualizes and generalizes a vast amount of prior work on sets of local
dimensions for self-similar measures satisfying the weak separation condition.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:25:09 GMT""},{""version"":""v2"",""created"":""Sun, 4 Sep 2022 21:49:36 GMT""}]","2022-09-07"
"2101.07401","Yuki Sato","Jan Ambjorn, Yuki Hiraga, Yoshiyasu Ito and Yuki Sato","Wormholes in 2d Horava-Lifshitz quantum gravity","10 pages",,"10.1016/j.physletb.2021.136205",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We quantize the two-dimensional projectable Horava-Lifshitz gravity with a
bi-local as well as space-like wormhole interaction. The resulting quantum
Hamiltonian coincides with the one obtained through summing over all genus in
the string field theory for two-dimensional causal dynamical triangulations.
This implies that our wormhole interaction can be interpreted as a splitting or
joining interaction of one-dimensional strings.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:39:43 GMT""}]","2021-03-17"
"2101.07402","Winston Alarcon-Athens","Winston Alarc\'on Athens","Dirichlet series for complex powers of the Riemann zeta function",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To obtain the Dirichlet series for complex powers of the Riemann zeta
function, we define and study the basic properties of a sequence of polynomials
that, used as coefficients of the respective terms of the Dirichlet series of
the Riemann zeta function in the half plane $x > 1$, produces the required
exponential function. Unlike the method described in ([4], p.~278), which
requires more advanced knowledge of the relationships between Dirichlet series
and multiplicative arithmetic functions, our approach only needs mathematical
induction on the total number of prime divisors of $n$, the Dirichlet product
and the use of an analytic property characteristic of the exponential function
in the complex plane.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:40:51 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 05:44:26 GMT""},{""version"":""v3"",""created"":""Tue, 9 Feb 2021 23:41:57 GMT""},{""version"":""v4"",""created"":""Thu, 11 Feb 2021 19:29:25 GMT""},{""version"":""v5"",""created"":""Mon, 12 Apr 2021 18:40:52 GMT""}]","2021-04-14"
"2101.07403","Roberto Armellin","Roberto Armellin","Collision Avoidance Maneuver Optimization with a Multiple-Impulse Convex
  Formulation",,,"10.1016/j.actaastro.2021.05.046",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method to compute optimal collision avoidance maneuvers for short-term
encounters is presented. The maneuvers are modeled as multiple-impulses to
handle impulsive cases and to approximate finite burn arcs associated either
with short alert times or the use of low-thrust propulsion. The maneuver design
is formulated as a sequence of convex optimization problems solved in
polynomial time by state-of-the-art primal-dual interior-point algorithms. The
proposed approach calculates optimal solutions without assumptions about the
thrust arc structure and thrust direction. The execution time is fraction of a
second for an optimization problem with hundreds of variables and constraints,
making it suitable for autonomous calculations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:41:43 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 02:59:14 GMT""},{""version"":""v3"",""created"":""Fri, 26 Feb 2021 00:41:44 GMT""},{""version"":""v4"",""created"":""Thu, 3 Jun 2021 23:36:54 GMT""},{""version"":""v5"",""created"":""Wed, 9 Jun 2021 04:04:19 GMT""}]","2021-06-10"
"2101.07404","Yuki Okoda","Yuki Okoda, Yoko Oya, Logan Francis, Doug Johnstone, Shu-ichiro
  Inutsuka, Cecilia Ceccarelli, Claudio Codella, Claire Chandler, Nami Sakai,
  Yuri Aikawa, Felipe Alves, Nadia Balucani, Eleonora Bianchi, Mathilde
  Bouvier, Paola Caselli, Emmanuel Caux, Steven Charnley, Spandan Choudhury,
  Marta De Simone, Francois Dulieu, Aurora Dur\'an, Lucy Evans, C\'ecile Favre,
  Davide Fedele, Siyi Feng, Francesco Fontani, Tetsuya Hama, Tomoyuki Hanawa,
  Eric Herbst, Tomoya Hirota, Muneaki Imai, Andrea Isella, Izaskun
  J\'imenez-Serra, Claudine Kahane, Bertrand Lefloch, Laurent Loinard, Ana
  L\'opez-Sepulcre, Luke T. Maud, Maria Jose Maureira, Francois Menard, Seyma
  Mercimek, Anna Miotello, George Moellenbrock, Shoji Mori, Nadia M. Murillo,
  Riouhei Nakatani, Hideko Nomura, Yasuhiro Oba, Ross O'Donoghue, Satoshi
  Ohashi, Juan Ospina-Zamudio, Jaime Pineda, Linda Podio, Albert Rimola,
  Takeshi Sakai, Dominique Segura Cox, Yancy Shirley, Brian Svoboda, Vianney
  Taquet, Leonardo Testi, Charlotte Vastel, Serena Viti, Naoki Watanabe,
  Yoshimasa Watanabe, Arezu Witzel, Ci Xue, Yichen Zhang, Bo Zhao, and Satoshi
  Yamamoto","FAUST II. Discovery of a Secondary Outflow in IRAS 15398-3359:
  Variability in Outflow Direction during the Earliest Stage of Star Formation?",,,"10.3847/1538-4357/abddb1",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have observed the very low-mass Class 0 protostar IRAS 15398-3359 at
scales ranging from 50 au to 1800 au, as part of the ALMA Large Program FAUST.
We uncover a linear feature, visible in H2CO, SO, and C18O line emission, which
extends from the source along a direction almost perpendicular to the known
active outflow. Molecular line emission from H2CO, SO, SiO, and CH3OH further
reveals an arc-like structure connected to the outer end of the linear feature
and separated from the protostar, IRAS 15398-3359, by 1200 au. The arc-like
structure is blue-shifted with respect to the systemic velocity. A velocity
gradient of 1.2 km/s over 1200 au along the linear feature seen in the H2CO
emission connects the protostar and the arc-like structure kinematically. SO,
SiO, and CH3OH are known to trace shocks, and we interpret the arc-like
structure as a relic shock region produced by an outflow previously launched by
IRAS 15398-3359. The velocity gradient along the linear structure can be
explained as relic outflow motion. The origins of the newly observed arc-like
structure and extended linear feature are discussed in relation to turbulent
motions within the protostellar core and episodic accretion events during the
earliest stage of protostellar evolution.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:41:51 GMT""}]","2021-03-31"
"2101.07405","Guangyi Hong","Guangyi Hong and Zhian Wang","Asymptotic stability of exogenous chemotaxis systems with physical
  boundary conditions","23 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the exogenous chemotaxis system with physical
mixed zero-flux and Dirichlet boundary conditions in one dimension. Since the
Dirichlet boundary condition can not contribute necessary estimates for the
cross-diffusion structure in the system, the global-in-time existence and
asymptotic behavior of solutions remain open up to date. In this paper, we
overcome this difficulty by employing the technique of taking anti-derivative
so that the Dirichlet boundary condition can be fully used, and show that the
system admits global strong solutions which exponentially stabilize to the
unique stationary solution as time tends to infinity against some suitable
small perturbations. To the best of our knowledge, this is the first result
obtained on the global well-posedness and asymptotic behavior of solutions to
the exogenous chemotaxis system with physical boundary conditions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:42:37 GMT""}]","2021-01-20"
"2101.07406","Nakamasa Inoue","Nakamasa Inoue, Eisuke Yamagata, Hirokatsu Kataoka","Initialization Using Perlin Noise for Training Networks with a Limited
  Amount of Data","Accepted to ICPR2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel network initialization method using Perlin noise for
training image classification networks with a limited amount of data. Our main
idea is to initialize the network parameters by solving an artificial noise
classification problem, where the aim is to classify Perlin noise samples into
their noise categories. Specifically, the proposed method consists of two
steps. First, it generates Perlin noise samples with category labels defined
based on noise complexity. Second, it solves a classification problem, in which
network parameters are optimized to classify the generated noise samples. This
method produces a reasonable set of initial weights (filters) for image
classification. To the best of our knowledge, this is the first work to
initialize networks by solving an artificial optimization problem without using
any real-world images. Our experiments show that the proposed method
outperforms conventional initialization methods on four image classification
datasets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:43:10 GMT""}]","2021-01-20"
"2101.07407","Dachun Yang","Jin Tao, Dachun Yang, Wen Yuan and Yangyang Zhang","Compactness Characterizations of Commutators on Ball Banach Function
  Spaces","36 pages, Submitted. arXiv admin note: text overlap with
  arXiv:1911.04953, arXiv:1906.03653",,,,"math.FA math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a ball Banach function space on ${\mathbb R}^n$. Let $\Omega$ be a
Lipschitz function on the unit sphere of ${\mathbb R}^n$,which is homogeneous
of degree zero and has mean value zero, and let $T_\Omega$ be the convolutional
singular integral operator with kernel $\Omega(\cdot)/|\cdot|^n$. In this
article, under the assumption that the Hardy--Littlewood maximal operator
$\mathcal{M}$ is bounded on both $X$ and its associated space, the authors
prove that the commutator $[b,T_\Omega]$ is compact on $X$ if and only if
$b\in{\rm CMO}({\mathbb R}^n)$. To achieve this, the authors mainly employ
three key tools: some elaborate estimates, given in this article, on the norm
in $X$ of the commutators and the characteristic functions of some measurable
subset,which are implied by the assumed boundedness of ${\mathcal M}$ on $X$
and its associated space as well as the geometry of $\mathbb R^n$; the complete
John--Nirenberg inequality in $X$ obtained by Y. Sawano et al.; the generalized
Fr\'{e}chet--Kolmogorov theorem on $X$ also established in this article. All
these results have a wide range of applications. Particularly, even when
$X:=L^{p(\cdot)}({\mathbb R}^n)$ (the variable Lebesgue space),
$X:=L^{\vec{p}}({\mathbb R}^n)$ (the mixed-norm Lebesgue space),
$X:=L^\Phi({\mathbb R}^n)$ (the Orlicz space), and $X:=(E_\Phi^q)_t({\mathbb
R}^n)$ (the Orlicz-slice space or the generalized amalgam space), all these
results are new.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:44:03 GMT""}]","2021-01-20"
"2101.07408","Matthew Davidow","Matthew Davidow, Cory Merow, Judy Che-Castaldo, Toryn Schafer,
  Marie-Christine Duker, Derek Corcoran, David Matteson","Clustering Future Scenarios Based on Predicted Range Maps","26 pages, 10 figures",,,,"q-bio.QM stat.AP","http://creativecommons.org/licenses/by/4.0/","  Predictions of biodiversity trajectories under climate change are crucial in
order to act effectively in maintaining the diversity of species. In many
ecological applications, future predictions are made under various global
warming scenarios as described by a range of different climate models. The
outputs of these various predictions call for a reliable interpretation. We
propose a interpretable and flexible two step methodology to measure the
similarity between predicted species range maps and cluster the future scenario
predictions utilizing a spectral clustering technique. We find that clustering
based on ecological impact (predicted species range maps) is mainly driven by
the amount of warming. We contrast this with clustering based only on predicted
climate features, which is driven mainly by climate models. The differences
between these clusterings illustrate that it is crucial to incorporate
ecological information to understand the relevant differences between climate
models. The findings of this work can be used to better synthesize forecasts of
biodiversity loss under the wide spectrum of results that emerge when
considering potential future biodiversity loss.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:48:08 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jul 2022 19:23:27 GMT""}]","2022-07-19"
"2101.07409","Zexi Niu","Zexi Niu, Haibo Yuan, Jifeng Liu","Correction to the photometric colors of Gaia Early Data Release 3","ApJL accepted. 9 pages, 5 figures, 1 table",,"10.3847/2041-8213/abe1c2",,"astro-ph.SR astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  In this work, we use the spectroscopy-based stellar color regression (SCR)
method with ~ 0.7 million common stars between LAMOST DR7 and Gaia EDR3 to
acquire color corrections in G - GRP and GBP - GRP. A sub-mmag precision is
achieved. Our results demonstrate that improvements in the calibration process
of the EDR3 have removed the color term in GBP - GRP and eliminated the
discontinuity caused by the changes of instrument configurations to a great
extent. However, modest systematic trends with G magnitude are still detected.
The corresponding color correction terms as a function of G are provided for
9.5 < G < 17.5 mag and compared with other determinations. We conclude that the
corrections given in this work are particularly suited for cases where the
color-color investigations are required while for color-magnitude
investigations other corrections may be better due to systematic with
reddening. Possible applications of our results are discussed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:51:49 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jan 2021 03:10:35 GMT""}]","2021-02-24"
"2101.07410","Anthony Bellotti","Ken Chung and Anthony Bellotti","Evidence and Behaviour of Support and Resistance Levels in Financial
  Time Series",,,,,"q-fin.ST","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper investigates the phenomenon of support and resistance levels (SR
levels) in financial time series, which act as temporary price barriers that
reverses price trends. We develop a heuristic discovery algorithm for this
purpose, to discover and evaluate SR levels for intraday price series. Our
simple approach discovers SR levels which are able to reverse price trends
statistically significantly. Asset price entering SR levels with higher number
of price bounces before are more likely to bounce on such SR levels again. We
also show that the decay aspect of the discovered SR levels as decreasing
probability of price bounce over time. We conclude SR levels are features in
financial time series are not explained simply by AR(1) processes, stationary
or otherwise; and that they contribute to the temporary predictability and
stationarity of the investigated price series.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:54:19 GMT""}]","2021-01-20"
"2101.07411","Jeremy Bailey","Jeremy Bailey, Kimberly Bott, Daniel V. Cotton, Lucyna
  Kedziora-Chudczer, Jinglin Zhao, Dag Evensberget, Jonathan P. Marshall,
  Duncan Wright, P.W.Lucas","Polarization of hot Jupiter systems: a likely detection of stellar
  activity and a possible detection of planetary polarization","16 pages, 8 figures, accepted by MNRAS",,"10.1093/mnras/stab172",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present high-precision linear polarization observations of four bright hot
Jupiter systems ($\tau$ Boo, HD 179949, HD 189733 and 51 Peg) and use the data
to search for polarized reflected light from the planets. The data for 51 Peg
are consistent with a reflected light polarization signal at about the level
expected with 2.8$\sigma$ significance and a false alarm probability of 1.9 per
cent. More data will be needed to confirm a detection of reflected light in
this system. HD 189733 shows highly variable polarization that appears to be
most likely the result of magnetic activity of the host star. This masks any
polarization due to reflected light, but a polarization signal at the expected
level of $\sim$20 ppm cannot be ruled out. $\tau$ Boo and HD 179949 show no
evidence for polarization due to reflected light. The results are consistent
with the idea that many hot Jupiters have low geometric albedos. Conclusive
detection of polarized reflected light from hot Jupiters is likely to require
further improvements in instrument sensitivity.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:57:31 GMT""}]","2021-02-03"
"2101.07412","Eunwoo Song","Eunwoo Song, Ryuichi Yamamoto, Min-Jae Hwang, Jin-Seob Kim, Ohsung
  Kwon, Jae-Min Kim","Improved parallel WaveGAN vocoder with perceptually weighted spectrogram
  loss","To appear in SLT 2021",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a spectral-domain perceptual weighting technique for
Parallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed
Parallel WaveGAN vocoder successfully generates waveform sequences using a fast
non-autoregressive WaveNet model. By employing multi-resolution short-time
Fourier transform (MR-STFT) criteria with a generative adversarial network, the
light-weight convolutional networks can be effectively trained without any
distillation process. To further improve the vocoding performance, we propose
the application of frequency-dependent weighting to the MR-STFT loss function.
The proposed method penalizes perceptually-sensitive errors in the frequency
domain; thus, the model is optimized toward reducing auditory noise in the
synthesized speech. Subjective listening test results demonstrate that our
proposed method achieves 4.21 and 4.26 TTS mean opinion scores for female and
male Korean speakers, respectively.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 01:59:52 GMT""}]","2021-01-20"
"2101.07413","Junyuan Hong","Junyuan Hong and Zhangyang Wang and Jiayu Zhou","Dynamic Privacy Budget Allocation Improves Data Efficiency of
  Differentially Private Gradient Descent","Accepted to FAccT'22; Updated abstract",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Protecting privacy in learning while maintaining the model performance has
become increasingly critical in many applications that involve sensitive data.
Private Gradient Descent (PGD) is a commonly used private learning framework,
which noises gradients based on the Differential Privacy protocol. Recent
studies show that \emph{dynamic privacy schedules} of decreasing noise
magnitudes can improve loss at the final iteration, and yet theoretical
understandings of the effectiveness of such schedules and their connections to
optimization algorithms remain limited. In this paper, we provide comprehensive
analysis of noise influence in dynamic privacy schedules to answer these
critical questions. We first present a dynamic noise schedule minimizing the
utility upper bound of PGD, and show how the noise influence from each
optimization step collectively impacts utility of the final model. Our study
also reveals how impacts from dynamic noise influence change when momentum is
used. We empirically show the connection exists for general non-convex losses,
and the influence is greatly impacted by the loss curvature.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:04:00 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 14:08:48 GMT""},{""version"":""v3"",""created"":""Wed, 19 Oct 2022 00:35:08 GMT""}]","2022-10-20"
"2101.07414","Wei Hou  Tan","Wei-Hou Tan, Philippe Piot, Alexander Zholents","Formation of Temporally Shaped Electron Bunches for Beam-Driven
  Collinear Wakefield Accelerators","15 pages, 20 figures","Phys. Rev. Accel. Beams 24, 051303 (2021)","10.1103/PhysRevAccelBeams.24.051303",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Beam-driven collinear wakefield accelerators (CWAs) that operate by using
slow-wave structures or plasmas hold great promise toward reducing the size of
contemporary accelerators. Sustainable acceleration of charged particles to
high energies in the CWA relies on using field-generating relativistic electron
bunches with a highly asymmetric peak current profile and a large energy chirp.
A new approach to obtaining such bunches has been proposed and illustrated with
the accelerator design supported by particle tracking simulations. It has been
shown that the required particle distribution in the longitudinal phase space
can be obtained without collimators, giving CWAs an opportunity for employment
in applications requiring a high repetition rate of operation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:10:15 GMT""}]","2021-05-26"
"2101.07415","Xingyou Song","Xingyou Song, Krzysztof Choromanski, Jack Parker-Holder, Yunhao Tang,
  Qiuyi Zhang, Daiyi Peng, Deepali Jain, Wenbo Gao, Aldo Pacchiano, Tamas
  Sarlos, Yuxiang Yang","ES-ENAS: Efficient Evolutionary Optimization for Large Hybrid Search
  Spaces","Previously published at ICLR 2020 NAS Workshop. See
  https://github.com/google-research/google-research/tree/master/es_enas for
  associated code",,,,"cs.LG cs.NE cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we approach the problem of optimizing blackbox functions over
large hybrid search spaces consisting of both combinatorial and continuous
parameters. We demonstrate that previous evolutionary algorithms which rely on
mutation-based approaches, while flexible over combinatorial spaces, suffer
from a curse of dimensionality in high dimensional continuous spaces both
theoretically and empirically, which thus limits their scope over hybrid search
spaces as well. In order to combat this curse, we propose ES-ENAS, a simple and
modular joint optimization procedure combining the class of sample-efficient
smoothed gradient techniques, commonly known as Evolutionary Strategies (ES),
with combinatorial optimizers in a highly scalable and intuitive way, inspired
by the one-shot or supernet paradigm introduced in Efficient Neural
Architecture Search (ENAS). By doing so, we achieve significantly more sample
efficiency, which we empirically demonstrate over synthetic benchmarks, and are
further able to apply ES-ENAS for architecture search over popular RL
benchmarks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:19:05 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 23:48:45 GMT""},{""version"":""v3"",""created"":""Tue, 21 Sep 2021 23:50:08 GMT""},{""version"":""v4"",""created"":""Mon, 6 Dec 2021 21:45:20 GMT""},{""version"":""v5"",""created"":""Thu, 28 Apr 2022 01:41:21 GMT""},{""version"":""v6"",""created"":""Wed, 15 Mar 2023 15:05:53 GMT""}]","2023-03-16"
"2101.07416","Xiaotian Xu","Xiaotian Xu and Yancy Diaz-Mercado","Swarm Herding: A Leader-Follower Framework For Multi-Robot Navigation",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A leader-follower framework is proposed for multi-robot navigation of large
scale teams where the leader agents corral the follower agents. A group of
leaders is modeled as a 2D deformable object where discrete masses (i.e.,
leader robots) are interconnected by springs and dampers. A time-varying domain
is defined by the positions of leaders while the external forces induce
deformations of the domain from its nominal configuration. The team of
followers is performing coverage over the time-varying domain by employing a
perspective transformation that maps between the nominal and deformed
configurations. A decentralized control strategy is proposed where a leader
only takes local sensing information and information about its neighbors
(connected by virtual springs and dampers), and a follower only needs partial
information about leaders and information about its Delaunay neighbors.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:26:43 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 23:30:02 GMT""}]","2021-03-11"
"2101.07417","Negin Karisani","Negin Karisani, Daniel E. Platt, Saugata Basu and Laxmi Parida","Inferring COVID-19 Biological Pathways from Clinical Phenotypes via
  Topological Analysis","Proceedings of the AAAI Workshop on Health Intelligence 2021",,,,"cs.CL math.AT","http://creativecommons.org/licenses/by/4.0/","  COVID-19 has caused thousands of deaths around the world and also resulted in
a large international economic disruption. Identifying the pathways associated
with this illness can help medical researchers to better understand the
properties of the condition. This process can be carried out by analyzing the
medical records. It is crucial to develop tools and models that can aid
researchers with this process in a timely manner. However, medical records are
often unstructured clinical notes, and this poses significant challenges to
developing the automated systems. In this article, we propose a pipeline to aid
practitioners in analyzing clinical notes and revealing the pathways associated
with this disease. Our pipeline relies on topological properties and consists
of three steps: 1) pre-processing the clinical notes to extract the salient
concepts, 2) constructing a feature space of the patients to characterize the
extracted concepts, and finally, 3) leveraging the topological properties to
distill the available knowledge and visualize the result. Our experiments on a
publicly available dataset of COVID-19 clinical notes testify that our pipeline
can indeed extract meaningful pathways.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:27:03 GMT""},{""version"":""v2"",""created"":""Sun, 13 Mar 2022 03:45:05 GMT""},{""version"":""v3"",""created"":""Sun, 1 May 2022 23:59:10 GMT""}]","2022-05-03"
"2101.07418","Yongmin Kim","Halim Choi, Yong Ho Shin, Chang Soo Park, Yongmin Kim, Daeyoung Park,
  Moon Seok Jeong, Hiroyuki Nojiri, Zhuo Yang, and Yoshimitsu Kohama","Combination of Optical Transitions of Polarons with Rashba Effect in
  Methylammonium Lead Tri-halide Perovskites under High Magnetic Fields","31 pages, 12 figures","Phys. Rev. B 104, 035205 (2021)","10.1103/PhysRevB.104.035205",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate photoluminescence (PL) transitions of MAPbX$_{3}$ (X = I, Br
and Cl) organic-inorganic hybrid perovskite single crystals under magnetic
fields of up to 60 T. In these materials, sharp free-exciton transition peaks
emerge at a low temperature (4.2 K). Under strong magnetic fields, the
free-exciton PL transitions of three different halogens show dramatic
differences. The free-exciton transitions of the MAPbCl$_{3}$ crystal undergo
negative energy shifts, while those of the MAPbBr$_{3}$ crystal show normal
diamagnetic shifts. To obtain the variation from Cl to Br, we attempt to
measure PL transitions of MAPbCl$_{x}$Br$_{3-x}$. For MAPbI$_{3}$, the
transition-energy shifts for both $\sigma^{+}$ and $\sigma^{-}$ transitions at
4.2 K exhibit a power-law dependence on the magnetic field. Such inconsistent
magnetic-field effects on different halogens make it difficult to understand
the transition-energy behavior through a unified model. We propose a possible
mechanism for the field effects that is based on a combination of the Rashba
effect induced by strong spin-orbit coupling and the polaron effect caused by
the polar nature of the inorganic elements.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:28:40 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 01:07:20 GMT""}]","2021-07-28"
"2101.07419","Haiwei Wu","Haiwei Wu and Jiantao Zhou","GIID-Net: Generalizable Image Inpainting Detection via Neural
  Architecture Search and Attention","Some errors are found in the Section V of Experimental Results, and
  more experiments are needed to be added. Besides, there are some
  modifications we want to present in the Section III of the Methods, e.g.,
  updating the figures for better describe the proposed methods. Thanks!",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning (DL) has demonstrated its powerful capabilities in the field of
image inpainting, which could produce visually plausible results. Meanwhile,
the malicious use of advanced image inpainting tools (e.g. removing key objects
to report fake news) has led to increasing threats to the reliability of image
data. To fight against the inpainting forgeries, in this work, we propose a
novel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),
to detect the inpainted regions at pixel accuracy. The proposed GIID-Net
consists of three sub-blocks: the enhancement block, the extraction block and
the decision block. Specifically, the enhancement block aims to enhance the
inpainting traces by using hierarchically combined special layers. The
extraction block, automatically designed by Neural Architecture Search (NAS)
algorithm, is targeted to extract features for the actual inpainting detection
tasks. In order to further optimize the extracted latent features, we integrate
global and local attention modules in the decision block, where the global
attention reduces the intra-class differences by measuring the similarity of
global features, while the local attention strengthens the consistency of local
features. Furthermore, we thoroughly study the generalizability of our
GIID-Net, and find that different training data could result in vastly
different generalization capability. Extensive experimental results are
presented to validate the superiority of the proposed GIID-Net, compared with
the state-of-the-art competitors. Our results would suggest that common
artifacts are shared across diverse image inpainting methods. Finally, we build
a public inpainting dataset of 10K image pairs for the future research in this
area.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:29:40 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jan 2021 05:44:31 GMT""}]","2021-02-01"
"2101.07420","Thaisa Tamusiunas","Gustav Beier, Christian Garcia, Wesley G. Lautenschlaeger, Juliana
  Pedrotti and Tha\'isa Tamusiunas","Generalizations of Lagrange and Sylow Theorems for Groupoids",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show a classification method for finite groupoids and discuss the
cardinality of cosets and its relation with the index. We prove a
generalization of the Lagrange's Theorem and establish a Sylow theory for
groupoids.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:29:50 GMT""}]","2021-01-20"
"2101.07421","Alexander Ritter","Alexander C. Ritter and Raymond R. Volkas","Implementing Asymmetric Dark Matter and Dark Electroweak Baryogenesis in
  a Mirror Two-Higgs-Doublet Model","58 pages, 6 figures. Matches published version. New content added,
  primarily in Sec.IV.A","Phys. Rev. D 104, 035032 (2021)","10.1103/PhysRevD.104.035032",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Models of asymmetric dark matter (ADM) seek to explain the apparent
coincidence between the present-day mass densities of visible and dark matter,
$\Omega_{\mathrm{DM}} \simeq 5\Omega_{\mathrm{VM}}$. However, most ADM models
only relate the number densities of visible and dark matter without motivating
the similar particle masses. We expand upon a recent work that obtained a
natural mass relationship in a mirror matter ADM model with two Higgs doublets
in each sector, by looking to implement dark electroweak baryogenesis as the
means of asymmetry generation. We explore two aspects of the mechanism: the
nature of the dark electroweak phase transition, and the transfer of particle
asymmetries between the sectors by the use of portal interactions. We find that
both aspects can be implemented successfully for various regions of the
parameter space. We also analyse one portal interaction -- the neutron portal
-- in greater detail, in order to satisfy the observational constraints on dark
radiation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:31:37 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 03:33:35 GMT""}]","2021-09-02"
"2101.07422","Lei He","Lei He, Jiwen Lu, Guanghui Wang, Shiyu Song, Jie Zhou","SOSD-Net: Joint Semantic Object Segmentation and Depth Estimation from
  Monocular images",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Depth estimation and semantic segmentation play essential roles in scene
understanding. The state-of-the-art methods employ multi-task learning to
simultaneously learn models for these two tasks at the pixel-wise level. They
usually focus on sharing the common features or stitching feature maps from the
corresponding branches. However, these methods lack in-depth consideration on
the correlation of the geometric cues and the scene parsing. In this paper, we
first introduce the concept of semantic objectness to exploit the geometric
relationship of these two tasks through an analysis of the imaging process,
then propose a Semantic Object Segmentation and Depth Estimation Network
(SOSD-Net) based on the objectness assumption. To the best of our knowledge,
SOSD-Net is the first network that exploits the geometry constraint for
simultaneous monocular depth estimation and semantic segmentation. In addition,
considering the mutual implicit relationship between these two tasks, we
exploit the iterative idea from the expectation-maximization algorithm to train
the proposed network more effectively. Extensive experimental results on the
Cityscapes and NYU v2 dataset are presented to demonstrate the superior
performance of the proposed approach.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:41:03 GMT""}]","2021-01-20"
"2101.07423","G\""ozde \""Ozcan","G\""ozde \""Ozcan, Armin Moharrer, Stratis Ioannidis","Submodular Maximization via Taylor Series Approximation","15 pages, 2 figures, to be published in the SIAM International
  Conference on Data Mining proceedings (SDM 2021)",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We study submodular maximization problems with matroid constraints, in
particular, problems where the objective can be expressed via compositions of
analytic and multilinear functions. We show that for functions of this form,
the so-called continuous greedy algorithm attains a ratio arbitrarily close to
$(1-1/e) \approx 0.63$ using a deterministic estimation via Taylor series
approximation. This drastically reduces execution time over prior art that uses
sampling.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:41:45 GMT""}]","2021-01-20"
"2101.07424","Jorge Bacca","Jorge Bacca, Yesid Fonseca and Henry Arguello","Compressive Spectral Image Reconstruction using Deep Prior and Low-Rank
  Tensor Representation",,,"10.1364/AO.420305",,"eess.IV math.OC","http://creativecommons.org/licenses/by/4.0/","  Compressive spectral imaging (CSI) has emerged as an alternative spectral
image acquisition technology, which reduces the number of measurements at the
cost of requiring a recovery process. In general, the reconstruction methods
are based on hand-crafted priors used as regularizers in optimization
algorithms or recent deep neural networks employed as an image generator to
learn a non-linear mapping from the low-dimensional compressed measurements to
the image space. However, these data-driven methods need many spectral images
to obtain good performance. In this work, a deep recovery framework for CSI
without training data is presented. The proposed method is based on the fact
that the structure of some deep neural networks and an appropriated
low-dimensional structure are sufficient to impose a structure of the
underlying spectral image from CSI. We analyzed the low-dimension structure via
the Tucker representation, modeled in the first net layer. The proposed scheme
is obtained by minimizing the $\ell_2$-norm distance between the compressive
measurements and the predicted measurements, and the desired recovered spectral
image is formed just before the forward operator. Simulated and experimental
results verify the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:42:17 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 01:12:36 GMT""}]","2021-05-19"
"2101.07425","Jianguo Chen","Jianguo Chen and Kenli Li and Keqin Li and Philip S. Yu and Zeng Zeng","Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing
  System Using Gated Graph Neural Network",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benefiting from convenient cycling and flexible parking locations, the
Dockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular
in many countries. However, redundant and low-utility stations waste public
urban space and maintenance costs of DL-PBS vendors. In this paper, we propose
a Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the
optimal bicycle station layout for the DL-PBS network. The BSDP system contains
four modules: bicycle drop-off location clustering, bicycle-station graph
modeling, bicycle-station location prediction, and bicycle-station layout
recommendation. In the bicycle drop-off location clustering module, candidate
bicycle stations are clustered from each spatio-temporal subset of the
large-scale cycling trajectory records. In the bicycle-station graph modeling
module, a weighted digraph model is built based on the clustering results and
inferior stations with low station revenue and utility are filtered. Then,
graph models across time periods are combined to create a graph sequence model.
In the bicycle-station location prediction module, the GGNN model is used to
train the graph sequence data and dynamically predict bicycle stations in the
next period. In the bicycle-station layout recommendation module, the predicted
bicycle stations are fine-tuned according to the government urban management
plan, which ensures that the recommended station layout is conducive to city
management, vendor revenue, and user convenience. Experiments on actual DL-PBS
networks verify the effectiveness, accuracy and feasibility of the proposed
BSDP system.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:51:12 GMT""}]","2021-01-20"
"2101.07426","Vincent Tan","Eugene T. Y. Ang, Milashini Nambiar, Yong Sheng Soh, Vincent Y. F. Tan","An Interpretable Intensive Care Unit Mortality Risk Calculator","7 pages, 5 figures",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mortality risk is a major concern to patients have just been discharged from
the intensive care unit (ICU). Many studies have been directed to construct
machine learning models to predict such risk. Although these models are highly
accurate, they are less amenable to interpretation and clinicians are typically
unable to gain further insights into the patients' health conditions and the
underlying factors that influence their mortality risk. In this paper, we use
patients' profiles extracted from the MIMIC-III clinical database to construct
risk calculators based on different machine learning techniques such as
logistic regression, decision trees, random forests and multilayer perceptrons.
We perform an extensive benchmarking study that compares the most salient
features as predicted by various methods. We observe a high degree of agreement
across the considered machine learning methods; in particular, the cardiac
surgery recovery unit, age, and blood urea nitrogen levels are commonly
predicted to be the most salient features for determining patients' mortality
risks. Our work has the potential for clinicians to interpret risk predictions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:51:44 GMT""}]","2021-01-20"
"2101.07427","Zhaoqi Wu","Zhaoqi Wu, Lin Zhang, Shao-Ming Fei, Xianqing Li-Jost","Average skew information-based coherence and its typicality for random
  quantum states","24pages","2021 J. Phys. A: Math. Theor. 54 015302","10.1088/1751-8121/abcab7",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the average skew information-based coherence for both random pure
and mixed states. The explicit formulae of the average skew information-based
coherence are derived and shown to be the functions of the dimension N of the
state space. We demonstrate that as N approaches to infinity, the average
coherence is 1 for random pure states, and a positive constant less than 1/2
for random mixed states. We also explore the typicality of average skew
information-based coherence of random quantum states. Furthermore, we identify
a coherent subspace such that the amount of the skew information-based
coherence for each pure state in this subspace can be bounded from below almost
always by a fixed number that is arbitrarily close to the typical value of
coherence.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:51:48 GMT""}]","2021-01-20"
"2101.07428","Arnold Filtser","Arnold Filtser, Hung Le","Locality-Sensitive Orderings and Applications to Reliable Spanners","To appear in STOC 22",,,,"cs.DS cs.CG","http://creativecommons.org/licenses/by/4.0/","  Chan, Har-Peled, and Jones [2020] recently developed locality-sensitive
ordering (LSO), a new tool that allows one to reduce problems in the Euclidean
space $\mathbb{R}^d$ to the $1$-dimensional line. They used LSO's to solve a
host of problems. Later, Buchin, Har-Peled, and Ol{\'{a}}h [2019,2020] used the
LSO of Chan {\em et al. } to construct very sparse \emph{reliable spanners} for
the Euclidean space. A highly desirable feature of a reliable spanner is its
ability to withstand a massive failure: the network remains functioning even if
90\% of the nodes fail. In a follow-up work, Har-Peled, Mendel, and Ol{\'{a}}h
[2021] constructed reliable spanners for general and topologically structured
metrics. Their construction used a different approach, and is based on sparse
covers.
  In this paper, we develop the theory of LSO's in non-Euclidean metrics by
introducing new types of LSO's suitable for general and topologically
structured metrics. We then construct such LSO's, as well as constructing
considerably improved LSO's for doubling metrics. Afterwards, we use our new
LSO's to construct reliable spanners with improved stretch and sparsity
parameters. Most prominently, we construct $\tilde{O}(n)$-size reliable
spanners for trees and planar graphs with the optimal stretch of $2$. Along the
way to the construction of LSO's and reliable spanners, we introduce and
construct ultrametric covers, and construct $2$-hop reliable spanners for the
line.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:52:36 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 20:44:48 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 15:54:24 GMT""}]","2022-03-01"
"2101.07429","Fei Gao","Hanliang Jiang, Fuhao Shen, Fei Gao, Weidong Han","Learning Efficient, Explainable and Discriminative Representations for
  Pulmonary Nodules Classification",,"Pattern Recognition, 2021",,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic pulmonary nodules classification is significant for early diagnosis
of lung cancers. Recently, deep learning techniques have enabled remarkable
progress in this field. However, these deep models are typically of high
computational complexity and work in a black-box manner. To combat these
challenges, in this work, we aim to build an efficient and (partially)
explainable classification model. Specially, we use \emph{neural architecture
search} (NAS) to automatically search 3D network architectures with excellent
accuracy/speed trade-off. Besides, we use the convolutional block attention
module (CBAM) in the networks, which helps us understand the reasoning process.
During training, we use A-Softmax loss to learn angularly discriminative
representations. In the inference stage, we employ an ensemble of diverse
neural networks to improve the prediction accuracy and robustness. We conduct
extensive experiments on the LIDC-IDRI database. Compared with previous
state-of-the-art, our model shows highly comparable performance by using less
than 1/40 parameters. Besides, empirical study shows that the reasoning process
of learned networks is in conformity with physicians' diagnosis. Related code
and results have been released at: https://github.com/fei-hdu/NAS-Lung.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:53:44 GMT""}]","2021-01-20"
"2101.07430","An Chen","An Chen, Zhigang Ren, Muyi Wang, Yongsheng Liang, Hanqing Liu, Wenhao
  Du","A Surrogate-Assisted Variable Grouping Algorithm for General Large Scale
  Global Optimization Problems",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Problem decomposition plays a vital role when applying cooperative
coevolution (CC) to large scale global optimization problems. However, most
learning-based decomposition algorithms either only apply to additively
separable problems or face the issue of false separability detections.
Directing against these limitations, this study proposes a novel decomposition
algorithm called surrogate-assisted variable grouping (SVG). SVG first designs
a general-separability-oriented detection criterion according to whether the
optimum of a variable changes with other variables. This criterion is
consistent with the separability definition and thus endows SVG with broad
applicability and high accuracy. To reduce the fitness evaluation requirement,
SVG seeks the optimum of a variable with the help of a surrogate model rather
than the original expensive high-dimensional model. Moreover, it converts the
variable grouping process into a dynamic-binary-tree search one, which
facilitates reutilizing historical separability detection information and thus
reducing detection times. To evaluate the performance of SVG, a suite of
benchmark functions with up to 2000 dimensions, including additively and
non-additively separable ones, were designed. Experimental results on these
functions indicate that, compared with six state-of-the-art decomposition
algorithms, SVG possesses broader applicability and competitive efficiency.
Furthermore, it can significantly enhance the optimization performance of CC.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:57:44 GMT""}]","2021-01-20"
"2101.07431","Yingshuang Fu","Le Qin, Zhi-Hao Zhang, Zeyu Jiang, Kai Fan, Wen-Hao Zhang, Qiao-Yin
  Tang, Hui-Nan Xia, Fanqi Meng, Qinghua Zhang, Lin Gu, Damien West, Shengbai
  Zhang, Ying-Shuang Fu","Realization of AlSb in the double layer honeycomb structure: a robust
  new class of two-dimensional material","21 pages, 6 figures","ACS Nano 15, 8184 (2021)","10.1021/acsnano.1c00470",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exploring new two-dimensional (2D) van der Waals (vdW) systems is at the
forefront of materials physics. Here, through molecular beam epitaxy on
graphene-covered SiC(0001), we report successful growth of AlSb in the
double-layer honeycomb (DLHC) structure, a 2D vdW material which has no direct
analogue to its 3D bulk and is predicted kinetically stable when freestanding.
The structural morphology and electronic structure of the experimental 2D AlSb
are characterized with spectroscopic imaging scanning tunneling microscopy and
cross-sectional imaging scanning transmission electron microscopy, which
compare well to the proposed DLHC structure. The 2D AlSb exhibits a bandgap of
0.93 eV versus the predicted 1.06 eV, which is substantially smaller than the
1.6 eV of bulk. We also attempt the less-stable InSb DLHC structure; however,
it grows into bulk islands instead. The successful growth of a DLHC material
here opens the door for the realization of a large family of novel 2D DLHC
traditional semiconductors with unique excitonic, topological, and electronic
properties.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:58:57 GMT""}]","2021-08-09"
"2101.07432","Houssam Yassin","Houssam Yassin and Stephen M. Griffies","On the Discrete Normal Modes of Quasigeostrophic Theory","19 pages, 9 figures",,"10.1175/JPO-D-21-0199.1",,"physics.ao-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discrete baroclinic modes of quasigeostrophic theory are incomplete and
the incompleteness manifests as a loss of information in the projection
process. The incompleteness of the baroclinic modes is related to the presence
of two previously unnoticed stationary step-wave solutions of the Rossby wave
problem with flat boundaries. These step-waves are the limit of surface
quasigeostrophic waves as boundary buoyancy gradients vanish. A complete normal
mode basis for quasigeostrophic theory is obtained by considering the
traditional Rossby wave problem with prescribed buoyancy gradients at the lower
and upper boundaries. The presence of these boundary buoyancy gradients
activates the previously inert boundary degrees of freedom. These Rossby waves
have several novel properties such as the presence of multiple modes with no
internal zeros, a finite number of modes with negative norms, and their
vertical structures form a basis capable of representing any quasigeostrophic
state with a differentiable series expansion. Using this complete basis, we are
able to obtain a differentiable series expansion to the potential vorticity of
Bretherton (with Dirac delta contributions). We also examine the
quasigeostrophic vertical velocity modes and derive a complete basis for such
modes as well. A natural application of these modes is the development of a
weakly non-linear wave-interaction theory of geostrophic turbulence that takes
topography into account.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:00:43 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 20:24:39 GMT""}]","2022-03-14"
"2101.07433","Alexander Wong","Hayden Gunraj, Ali Sabri, David Koff, and Alexander Wong","COVID-Net CT-2: Enhanced Deep Neural Networks for Detection of COVID-19
  from Chest CT Images Through Bigger, More Diverse Learning","15 pages",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 pandemic continues to rage on, with multiple waves causing
substantial harm to health and economies around the world. Motivated by the use
of CT imaging at clinical institutes around the world as an effective
complementary screening method to RT-PCR testing, we introduced COVID-Net CT, a
neural network tailored for detection of COVID-19 cases from chest CT images as
part of the open source COVID-Net initiative. However, one potential limiting
factor is restricted quantity and diversity given the single nation patient
cohort used. In this study, we introduce COVID-Net CT-2, enhanced deep neural
networks for COVID-19 detection from chest CT images trained on the largest
quantity and diversity of multinational patient cases in research literature.
We introduce two new CT benchmark datasets, the largest comprising a
multinational cohort of 4,501 patients from at least 15 countries. We leverage
explainability to investigate the decision-making behaviour of COVID-Net CT-2,
with the results for select cases reviewed and reported on by two
board-certified radiologists with over 10 and 30 years of experience,
respectively. The COVID-Net CT-2 neural networks achieved accuracy, COVID-19
sensitivity, PPV, specificity, and NPV of 98.1%/96.2%/96.7%/99%/98.8% and
97.9%/95.7%/96.4%/98.9%/98.7%, respectively. Explainability-driven performance
validation shows that COVID-Net CT-2's decision-making behaviour is consistent
with radiologist interpretation by leveraging correct, clinically relevant
critical factors. The results are promising and suggest the strong potential of
deep neural networks as an effective tool for computer-aided COVID-19
assessment. While not a production-ready solution, we hope the open-source,
open-access release of COVID-Net CT-2 and benchmark datasets will continue to
enable researchers, clinicians, and citizen data scientists alike to build upon
them.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:04:09 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 13:51:26 GMT""}]","2021-01-27"
"2101.07434","Ye Huang","Ye Huang, Di Kang, Wenjing Jia, Xiangjian He, Liu Liu","Channelized Axial Attention for Semantic Segmentation -- Considering
  Channel Relation within Spatial Attention for Semantic Segmentation","Paper presentation revised. Add more experiments",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Spatial and channel attentions, modelling the semantic interdependencies in
spatial and channel dimensions respectively, have recently been widely used for
semantic segmentation. However, computing spatial and channel attentions
separately sometimes causes errors, especially for those difficult cases. In
this paper, we propose Channelized Axial Attention (CAA) to seamlessly
integrate channel attention and spatial attention into a single operation with
negligible computation overhead. Specifically, we break down the dot-product
operation of the spatial attention into two parts and insert channel relation
in between, allowing for independently optimized channel attention on each
spatial location. We further develop grouped vectorization, which allows our
model to run with very little memory consumption without slowing down the
running speed. Comparative experiments conducted on multiple benchmark
datasets, including Cityscapes, PASCAL Context, and COCO-Stuff, demonstrate
that our CAA outperforms many state-of-the-art segmentation models (including
dual attention) on all tested datasets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:08:03 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 16:24:11 GMT""},{""version"":""v3"",""created"":""Mon, 19 Apr 2021 16:07:07 GMT""},{""version"":""v4"",""created"":""Tue, 20 Apr 2021 00:59:58 GMT""},{""version"":""v5"",""created"":""Sun, 12 Sep 2021 09:31:12 GMT""}]","2021-09-14"
"2101.07435","Ankang Sun","Ankang Sun, Bo Chen, Xuan Vinh Doan","Fairness Criteria for Allocating Indivisible Chores: Connections and
  Efficiencies",,,,,"cs.GT cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study several fairness notions in allocating indivisible chores (i.e.,
items with non-positive values) to agents who have additive and submodular cost
functions. The fairness criteria we are concern with are envy-free up to any
item (EFX), envy-free up to one item (EF1), maximin share (MMS), and pairwise
maximin share (PMMS), which are proposed as relaxations of envy-freeness in the
setting of additive cost functions. For allocations under each fairness
criterion, we establish their approximation guarantee for other fairness
criteria. Under the additive setting, our results show strong connections
between these fairness criteria and, at the same time, reveal intrinsic
differences between goods allocation and chores allocation. However, such
strong relationships cannot be inherited by the submodular setting, under which
PMMS and MMS are no longer relaxations of envy-freeness and, even worse, few
non-trivial guarantees exist. We also investigate efficiency loss under these
fairness constraints and establish their prices of fairness.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:08:43 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 02:18:59 GMT""},{""version"":""v3"",""created"":""Tue, 28 Sep 2021 11:05:02 GMT""}]","2021-09-29"
"2101.07436","Mingkang Wang","Mingkang Wang, Diego J. Perez-Morelo, Vladimir Aksyuk","Overcoming Thermo-Optical Dynamics in Broadband Nanophotonic Sensing",,"Microsyst Nanoeng 7, 52 (2021)","10.1038/s41378-021-00281-y",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advances in integrated photonics open exciting opportunities for
batch-fabricated optical sensors using high quality factor nanophotonic
cavities to achieve ultra-high sensitivities and bandwidths. The sensitivity
improves with higher optical power, however, localized absorption and heating
within a micrometer-scale mode volume prominently distorts the cavity
resonances and strongly couples the sensor response to thermal dynamics,
limiting the sensitivity and hindering the measurement of broadband
time-dependent signals. Here, we derive a frequency-dependent photonic sensor
transfer function that accounts for thermo-optical dynamics and quantitatively
describes the measured broadband optomechanical signal from an integrated
photonic atomic-force-microscopy nanomechanical probe. Using this transfer
function, the probe can be operated in the high optical power, strongly
thermo-optically nonlinear regime, reaching a sensitivity of $\approx$ 0.4
fm/Hz$^{1/2}$, an improvement of $\approx 10\times$ relative to the best
performance in the linear regime. Counterintuitively, we discover that higher
transduction gain and sensitivity are obtained with lower quality factor
optical modes for low signal frequencies. Not limited to optomechanical
transducers, the derived transfer function is generally valid for describing
small-signal dynamic response of a broad range of technologically important
photonic sensors subject to the thermo-optical effect.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:09:17 GMT""}]","2021-07-09"
"2101.07437","Jianguo Chen","Jianguo Chen and Kenli Li and Keqin Li and Philip S. Yu and Zeng Zeng","Dynamic Bicycle Dispatching of Dockless Public Bicycle-sharing Systems
  using Multi-objective Reinforcement Learning",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a new generation of Public Bicycle-sharing Systems (PBS), the dockless PBS
(DL-PBS) is an important application of cyber-physical systems and intelligent
transportation. How to use AI to provide efficient bicycle dispatching
solutions based on dynamic bicycle rental demand is an essential issue for
DL-PBS. In this paper, we propose a dynamic bicycle dispatching algorithm based
on multi-objective reinforcement learning (MORL-BD) to provide the optimal
bicycle dispatching solution for DL-PBS. We model the DL-PBS system from the
perspective of CPS and use deep learning to predict the layout of bicycle
parking spots and the dynamic demand of bicycle dispatching. We define the
multi-route bicycle dispatching problem as a multi-objective optimization
problem by considering the optimization objectives of dispatching costs,
dispatch truck's initial load, workload balance among the trucks, and the
dynamic balance of bicycle supply and demand. On this basis, the collaborative
multi-route bicycle dispatching problem among multiple dispatch trucks is
modeled as a multi-agent MORL model. All dispatch paths between parking spots
are defined as state spaces, and the reciprocal of dispatching costs is defined
as a reward. Each dispatch truck is equipped with an agent to learn the optimal
dispatch path in the dynamic DL-PBS network. We create an elite list to store
the Pareto optimal solutions of bicycle dispatch paths found in each action,
and finally, get the Pareto frontier. Experimental results on the actual DL-PBS
systems show that compared with existing methods, MORL-BD can find a higher
quality Pareto frontier with less execution time.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:09:51 GMT""}]","2021-01-20"
"2101.07438","Rodney Polkinghorne","Rodney E. S. Polkinghorne, Andrew J. Groszek, Tapio P. Simula","Geometric phases of a vortex in a superfluid","8 pages, 7 figures, 5 videos. Submitted to Physical Review Letters",,"10.1103/PhysRevA.104.L041305",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider geometric phases of mobile quantum vortices in superfluid
Bose-Einstein condensates. Haldane and Wu [Phys. Rev. Lett. 55, 2887 (1985)]
showed that the geometric phase, $\gamma_{\mathcal C}=2\pi N_{\mathcal C}$, of
such a vortex is determined by the number of condensate atoms $N_{\mathcal C}$
enclosed by the vortex trajectory. Considering an experimentally realistic
freely orbiting vortex leads to an apparent disagreement with this prediction.
We resolve it using the superfluid electrodynamics picture, which allows us to
identify two additional contributions to the measured geometric phase; (i) a
topologically protected edge current of vortices at the condensate boundary,
and (ii) a superfluid displacement current. Our results generalise to, and pave
the way for experimental measurements of vortex geometric phases using scalar
and spinor Bose--Einstein condensates, and superfluid Fermi gases.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:13:08 GMT""}]","2021-11-10"
"2101.07439","Junghyuk Lee","Manri Cheon, Toinon Vigier, Luk\'a\v{s} Krasula, Junghyuk Lee, Patrick
  Le Callet, Jong-Seok Lee","Ambiguity of Objective Image Quality Metrics: A New Methodology for
  Performance Evaluation",,"Signal Processing: Image Communication (2021)","10.1016/j.image.2021.116150",,"cs.MM eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective image quality metrics try to estimate the perceptual quality of the
given image by considering the characteristics of the human visual system.
However, it is possible that the metrics produce different quality scores even
for two images that are perceptually indistinguishable by human viewers, which
have not been considered in the existing studies related to objective quality
assessment. In this paper, we address the issue of ambiguity of objective image
quality assessment. We propose an approach to obtain an ambiguity interval of
an objective metric, within which the quality score difference is not
perceptually significant. In particular, we use the visual difference
predictor, which can consider viewing conditions that are important for visual
quality perception. In order to demonstrate the usefulness of the proposed
approach, we conduct experiments with 33 state-of-the-art image quality metrics
in the viewpoint of their accuracy and ambiguity for three image quality
databases. The results show that the ambiguity intervals can be applied as an
additional figure of merit when conventional performance measurement does not
determine superiority between the metrics. The effect of the viewing distance
on the ambiguity interval is also shown.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:13:25 GMT""}]","2021-01-22"
"2101.07440","Kanupriya Sinha","Kanupriya Sinha, Adri\'an Ezequiel Rubio L\'opez, Yi\u{g}it
  Suba\c{s}{\i}","Dissipative dynamics of a particle coupled to field via internal degrees
  of freedom","LA-UR-21-20103","Phys. Rev. D 103, 056023 (2021)","10.1103/PhysRevD.103.056023",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the non-equilibrium dissipative dynamics of the center of mass of a
particle coupled to a field via its internal degrees of freedom. We model the
internal and external degrees of freedom of the particle as quantum harmonic
oscillators in 1+1 D, with the internal oscillator coupled to a scalar quantum
field at the center of mass position. Such a coupling results in a nonlinear
interaction between the three pertinent degrees of freedom -- the center of
mass, internal degree of freedom, and the field. It is typically assumed that
the internal dynamics is decoupled from that of the center of mass owing to
their disparate characteristic time scales. Here we use an influence functional
approach that allows one to account for the self-consistent backaction of the
different degrees of freedom on each other, including the coupled
non-equilibrium dynamics of the internal degree of freedom and the field, and
their influence on the dissipation and noise of the center of mass. Considering
a weak nonlinear interaction term, we employ a perturbative generating
functional approach to derive a second order effective action and a
corresponding quantum Langevin equation describing the non-equilibrium dynamics
of the center of mass. We analyze the resulting dissipation and noise arising
from the field and the internal degree of freedom as a composite environment.
Furthermore, we establish a generalized fluctuation-dissipation relation for
the late-time dissipation and noise kernels. Our results are pertinent to open
quantum systems that possess intermediary degrees of freedom between system and
environment, such as in the case of optomechanical interactions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:21:20 GMT""}]","2021-03-25"
"2101.07441","Bi-Heng Liu","Xiao-Min Hu, Cen-Xiao Huang, Yu-Bo Sheng, Lan Zhou, Bi-Heng Liu, Yu
  Guo, Chao Zhang, Wen-Bo Xing, Yun-Feng Huang, Chuan-Feng Li, Guang-Can Guo","Long-distance entanglement purification for quantum communication","The typos in the title and abstract are modified","Phys. Rev. Lett. 126, 010503 (2021)","10.1103/PhysRevLett.126.010503",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-quality long-distance entanglement is essential for both quantum
communication and scalable quantum networks. Entanglement purification is to
distill high-quality entanglement from low-quality entanglement in a noisy
environment and it plays a key role in quantum repeaters. The previous
significant entanglement purification experiments require two pairs of
low-quality entangled states and were demonstrated in table-top. Here we
propose and report a high-efficiency and long-distance entanglement
purification using only one pair of hyperentangled states. We also demonstrate
its practical application in entanglement-based quantum key distribution (QKD).
One pair of polarization spatial-mode hyperentanglement was distributed over 11
km multicore fiber (noisy channel). After purification, the fidelity of
polarization entanglement arises from 0.771 to 0.887 and the effective key rate
in entanglement-based QKD increases from 0 to 0.332. The values of
Clauser-Horne-Shimony-Holt (CHSH) inequality of polarization entanglement
arises from 1.829 to 2.128. Moreover, by using one pair of hyperentanglement
and deterministic controlled-NOT gate, the total purification efficiency can be
estimated as 6.6x10^3 times than the experiment using two pairs of entangled
states with spontaneous parametric down-conversion (SPDC) sources. Our results
offer the potential to be implemented as part of a full quantum repeater and
large scale quantum network.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:25:01 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 08:02:35 GMT""}]","2021-01-21"
"2101.07442","Lei Wang","Ting Zhang, Lei Wang, Jing Ning, Wei Lu, Xiaofei Wang, Hai-wei Zhang,
  Xian-guo Tuo","Simulation of an imaging system for internal contamination of lungs
  using MPA-MURA coded aperture collimator",,,,,"physics.med-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nuclides inhaled during nuclear accidents usually cause internal
contamination of the lungs with low activity. Although a parallel-hole imaging
system, which is widely used in medical gamma cameras, has a high resolution
and good image quality, owing to its extremely low detection efficiency, it
remains difficult to obtain images of inhaled lung contamination. In this
study, the Monte Carlo method was used to study the internal lung contamination
imaging using the MPA-MURA coded-aperture collimator. The imaging system
consisted of an adult male lung model, with a mosaicked, pattern-centered, and
anti-symmetric MURA coded-aperture collimator model and a CsI(Tl) detector
model. The MLEM decoding algorithm was used to reconstruct the internal
contamination image, and the complementary imaging method was used to reduce
the number of artifacts. The full width at half maximum of the I-131 point
source image reconstructed by the mosaicked, pattern-centered, and
anti-symmetric Modified uniformly redundant array (MPA-MURA) coded-aperture
imaging reached 2.51 mm, and the signal-to-noise ratio of the simplified
respiratory tract source (I-131) image reconstructed through MPA-MURA
coded-aperture imaging was 3.98 dB. Although the spatial resolution of MPA-MURA
coded aperture imaging is not as good as that of parallel-hole imaging, the
detection efficiency of PMA-MURA coded-aperture imaging is two orders of
magnitude higher than that of parallel hole collimator imaging. Considering the
low activity level of internal lung contamination caused by nuclear accidents,
PMA-MURA coded-aperture imaging has significant potential for the development
of lung contamination imaging.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:35:11 GMT""}]","2021-01-20"
"2101.07443","Xi Zhang","Xi Zhang","The limit of the harmonic flow on flat complex vector bundle",,,,,"math.DG","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper we study the limiting behaviour of the harmonic flow on flat
complex vector bundle, and prove the limit must be isomorphic to the graded
flat complex vector bundle associated to the Jordan-H\""older filtration.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:35:28 GMT""}]","2021-01-20"
"2101.07444","Jordan Hall","Jordan R. Hall and Varis Carey","Accelerating Derivative-Free Optimization with Dimension Reduction and
  Hyperparameter Learning","50 pages (26 pages of which are the technical report), 5 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider convex, black-box objective functions with additive or
multiplicative noise with a high-dimensional parameter space and a data space
of lower dimension, where gradients of the map exist, but may be inaccessible.
We investigate Derivative-Free Optimization (DFO) in this setting and propose a
novel method, Active STARS (ASTARS), based on STARS (Chen and Wild, 2015) and
dimension reduction in parameter space via Active Subspace (AS) methods
(Constantine, 2015). STARS hyperparmeters are inversely proportional to the
known dimension of parameter space, resulting in heavy smoothing and small step
sizes for large dimensions. When possible, ASTARS leverages a lower-dimensional
AS, defining a set of directions in parameter space causing the majority of the
variance in function values. ASTARS iterates are updated with steps only taken
in the AS, reducing the value of the objective function more efficiently than
STARS, which updates iterates in the full parameter space. Computational costs
may be reduced further by learning ASTARS hyperparameters and the AS, reducing
the total evaluations of the objective function and eliminating the requirement
that the user specify hyperparameters, which may be unknown in our setting. We
call this method Fully Automated ASTARS (FAASTARS). We show that STARS and
ASTARS will both converge -- with a certain complexity -- even with inexact,
estimated hyperparemters. We also find that FAASTARS converges with the use of
estimated AS's and hyperparameters. We explore the effectiveness of ASTARS and
FAASTARS in numerical examples which compare ASTARS and FAASTARS to STARS.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:38:56 GMT""}]","2021-01-20"
"2101.07445","Yuan Gao","Yuan Gao, Jian-Guo Liu","Surfactant-dependent contact line dynamics and droplet spreading on
  textured substrates: derivations and computations","35 pages, 6 figures","Physica D, 428 (2021) 133067","10.1016/j.physd.2021.133067",,"physics.flu-dyn cs.NA math.AP math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study spreading of a droplet, with insoluble surfactant covering its
capillary surface, on a textured substrate. In this process, the
surfactant-dependent surface tension dominates the behaviors of the whole
dynamics, particularly the moving contact lines. This allows us to derive the
full dynamics of the droplets laid by the insoluble surfactant: (i) the moving
contact lines, (ii) the evolution of the capillary surface, (iii) the
surfactant dynamics on this moving surface with a boundary condition at the
contact lines and (iv) the incompressible viscous fluids inside the droplet.
Our derivations base on Onsager's principle with Rayleigh dissipation
functionals for either the viscous flow inside droplets or the motion by mean
curvature of the capillary surface. We also prove the Rayleigh dissipation
functional for viscous flow case is stronger than the one for the motion by
mean curvature. After incorporating the textured substrate profile, we design a
numerical scheme based on unconditionally stable explicit boundary updates and
moving grids, which enable efficient computations for many challenging examples
showing significant impacts of the surfactant to the deformation of droplets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:46:38 GMT""},{""version"":""v2"",""created"":""Sat, 2 Oct 2021 16:53:47 GMT""}]","2022-11-08"
"2101.07446","Kohji Matsumoto","Kohji Matsumoto","An M-function associated with Goldbach's problem","16pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the existence of the M-function, by which we can state the limit
theorem for the value-distribution of the main term in the asymptotic formula
for the summatory function of the Goldbach generating function.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:48:19 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 05:22:44 GMT""}]","2021-03-19"
"2101.07447","Liam Morrow","Liam C. Morrow and Timothy J. Moroney and Michael C. Dallaston and
  Scott W. McCue","A review of one-phase Hele-Shaw flows and a level-set method for
  non-standard configurations",,,"10.1017/S144618112100033X",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The classical model for studying one-phase Hele-Shaw flows is based on a
highly nonlinear moving boundary problem with the fluid velocity related to
pressure gradients via a Darcy-type law. In a standard configuration with the
Hele-Shaw cell made up of two flat stationary plates, the pressure is harmonic.
Therefore, conformal mapping techniques and boundary integral methods can be
readily applied to study the key interfacial dynamics, including the
Saffman-Taylor instability and viscous fingering patterns. As well as providing
a brief review of these key issues, we present a flexible numerical scheme for
studying both standard and non-standard Hele-Shaw flows. Our method consists of
using a modified finite difference stencil in conjunction with the level set
method to solve the governing equation for pressure on complicated domains and
track the location of the moving boundary. Simulations show that our method is
capable of reproducing the distinctive morphological features of the
Saffman-Taylor instability on a uniform computational grid. By making
straightforward adjustments, we show how our scheme can easily be adapted to
solve for a wide variety of non-standard configurations, including cases where
the gap between the plates is linearly tapered, the plates are separated in
time, and the entire Hele-Shaw cell is rotated at a given angular velocity.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:49:35 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 10:36:15 GMT""}]","2021-09-27"
"2101.07448","Peng Gao","Peng Gao, Minghang Zheng, Xiaogang Wang, Jifeng Dai, Hongsheng Li","Fast Convergence of DETR with Spatially Modulated Co-Attention",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The recently proposed Detection Transformer (DETR) model successfully applies
Transformer to objects detection and achieves comparable performance with
two-stage object detection frameworks, such as Faster-RCNN. However, DETR
suffers from its slow convergence. Training DETR \cite{carion2020end} from
scratch needs 500 epochs to achieve a high accuracy. To accelerate its
convergence, we propose a simple yet effective scheme for improving the DETR
framework, namely Spatially Modulated Co-Attention (SMCA) mechanism. The core
idea of SMCA is to conduct regression-aware co-attention in DETR by
constraining co-attention responses to be high near initially estimated
bounding box locations. Our proposed SMCA increases DETR's convergence speed by
replacing the original co-attention mechanism in the decoder while keeping
other operations in DETR unchanged. Furthermore, by integrating multi-head and
scale-selection attention designs into SMCA, our fully-fledged SMCA can achieve
better performance compared to DETR with a dilated convolution-based backbone
(45.6 mAP at 108 epochs vs. 43.3 mAP at 500 epochs). We perform extensive
ablation studies on COCO dataset to validate the effectiveness of the proposed
SMCA.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:52:44 GMT""}]","2021-01-20"
"2101.07449","Kohji Matsumoto","Kohji Matsumoto","A survey on the theory of multiple Dirichlet series with arithmetical
  coefficients on the numerators","13pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We survey some recent developments in the analytic theory of multiple
Dirichlet series with arithmetical coefficients on the numerators.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:54:12 GMT""}]","2021-01-20"
"2101.07450","David Martinez","David Martinez Iraola and Antonio Jimeno Yepes","Single versus Multiple Annotation for Named Entity Recognition of
  Mutations",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The focus of this paper is to address the knowledge acquisition bottleneck
for Named Entity Recognition (NER) of mutations, by analysing different
approaches to build manually-annotated data. We address first the impact of
using a single annotator vs two annotators, in order to measure whether
multiple annotators are required. Once we evaluate the performance loss when
using a single annotator, we apply different methods to sample the training
data for second annotation, aiming at improving the quality of the dataset
without requiring a full pass. We use held-out double-annotated data to build
two scenarios with different types of rankings: similarity-based and confidence
based. We evaluate both approaches on: (i) their ability to identify training
instances that are erroneous (cases where single-annotator labels differ from
double-annotation after discussion), and (ii) on Mutation NER performance for
state-of-the-art classifiers after integrating the fixes at different
thresholds.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:54:17 GMT""}]","2021-01-20"
"2101.07451","Junghyuk Lee","Junghyuk Lee, Toinon Vigier, Patrick Le Callet, Jong-Seok Lee","Wide Color Gamut Image Content Characterization: Method, Evaluation, and
  Applications",,"IEEE Transactions on Multimedia (2020)","10.1109/TMM.2020.3032026",,"cs.MM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel framework to characterize a wide color
gamut image content based on perceived quality due to the processes that change
color gamut, and demonstrate two practical use cases where the framework can be
applied. We first introduce the main framework and implementation details.
Then, we provide analysis for understanding of existing wide color gamut
datasets with quantitative characterization criteria on their characteristics,
where four criteria, i.e., coverage, total coverage, uniformity, and total
uniformity, are proposed. Finally, the framework is applied to content
selection in a gamut mapping evaluation scenario in order to enhance
reliability and robustness of the evaluation results. As a result, the
framework fulfils content characterization for studies where quality of
experience of wide color gamut stimuli is involved.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:55:26 GMT""}]","2021-01-21"
"2101.07452","Liu Lijuan","Lijuan Liu, Yuming Wang, Zhenjun Zhou, Jun Cui","The Source Locations of Major Flares and CMEs in the Emerging Active
  Regions","33 pages, 19 figurs, accepted for publication in ApJ",,"10.3847/1538-4357/abde37",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Major flares and coronal mass ejections (CMEs) tend to originate from the
compact polarity inversion lines (PILs) in the solar active regions (ARs).
Recently, a scenario named as ""collisional shearing"" is proposed by
\citet{Chintzoglou_2019} to explain the phenomenon, which suggests that the
collision between different emerging bipoles is able to form the compact PIL,
driving the shearing and flux cancellation that are responsible to the
subsequent large activities. In this work, through tracking the evolution of 19
emerging ARs from their birth until they produce the first major flares or
CMEs, we investigated the source PILs of the activities, i.e., the active PILs,
to explore the generality of ""collisional shearing"". We find that none of the
active PILs is the self PIL (sPIL) of a single bipole. We further find that 11
eruptions originate from the collisional PILs (cPILs) formed due to the
collision between different bipoles, 6 from the conjoined systems of sPIL and
cPIL, and 2 from the conjoined systems of sPIL and ePIL (external PIL between
the AR and the nearby preexisting polarities). Collision accompanied by
shearing and flux cancellation is found developing at all PILs prior to the
eruptions, with $84\%$ (16/19) cases having collisional length longer than
18~Mm. Moreover, we find that the magnitude of the flares is positively
correlated with the collisional length of the active PILs, indicating that the
intenser activities tend to originate from the PILs with severer collision. The
results suggest that the ""collisional shearing"", i.e., bipole-bipole
interaction during the flux emergence is a common process in driving the major
activities in emerging ARs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 03:55:35 GMT""}]","2021-03-16"
"2101.07453","Chunhui Liu","Chunhui Liu","On the global determinant method","39 pages. arXiv admin note: text overlap with arXiv:1910.00306",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we build the global determinant method of Salberger by
Arakelov geometry explicitly. As an application, we study the dependence on the
degree of the number of rational points of bounded height in plane curves. We
will also explain why some constants will be more explicit if we admit the
Generalized Riemann Hypothesis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:05:16 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 14:49:37 GMT""}]","2022-05-24"
"2101.07454","Aaron Szasz","Aaron Szasz and Johannes Motruk","Phase diagram of the anisotropic triangular lattice Hubbard model","v3: Added data regarding incommensurate spiral order using flux
  insertion, 20 pages, 6 figures, plus 23 pages (35 figures) Supplemental
  Material; v2: Slightly increased parameter space resolution for largest
  cylinder; v1: 19 pages, 6 figures, plus 22 pages (34 figures) Supplemental
  Material","Phys. Rev. B 103, 235132 (2021)","10.1103/PhysRevB.103.235132",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent study [Phys. Rev. X 10, 021042 (2020)], we showed using
large-scale density matrix renormalization group (DMRG) simulations on infinite
cylinders that the triangular lattice Hubbard model has a chiral spin liquid
phase. In this work, we introduce hopping anisotropy in the model, making one
of the three distinct bonds on the lattice stronger or weaker compared with the
other two. We implement the anisotropy in two inequivalent ways, one which
respects the mirror symmetry of the cylinder and one which breaks this
symmetry. In the full range of anisotropy, from the square lattice to weakly
coupled one-dimensional chains, we find a variety of phases. Near the isotropic
limit we find the three phases identified in our previous work: metal, chiral
spin liquid, and 120$^\circ$ spiral order; we note that a recent paper suggests
the apparently metallic phase may actually be a Luther-Emery liquid, which
would also be in agreement with our results. When one bond is weakened by a
relatively small amount, the ground state quickly becomes the square lattice
N\'{e}el order. When one bond is strengthened, the story is much less clear,
with the phases that we find depending on the orientation of the anisotropy and
on the cylinder circumference. While our work is to our knowledge the first
DMRG study of the anisotropic triangular lattice Hubbard model, the overall
phase diagram we find is broadly consistent with that found previously using
other methods, such as variational Monte Carlo and dynamical mean field theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:08:22 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 16:00:43 GMT""},{""version"":""v3"",""created"":""Thu, 17 Jun 2021 18:09:26 GMT""}]","2021-06-23"
"2101.07455","Hanul Jeon","Hanul Jeon","How strong is a Reinhardt set over extensions of CZF?","16 pages. Merged into arXiv:2204.05831",,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the lower bound of the consistency strength of $\mathsf{CZF}$
with Full Separation $\mathsf{Sep}$ and a Reinhardt set, a constructive
analogue of Reinhardt cardinals. We show that $\mathsf{CZF+Sep}$ with a
Reinhardt set interprets $\mathsf{ZF^-}$ with a cofinal elementary embedding
$j\colon V\prec V$. We also see that $\mathsf{CZF+Sep}$ with a Reinhardt set
interprets $\mathsf{ZF^-}$ with a model of $\mathsf{ZF+WA_0}$, the Wholeness
axiom for bounded formulas.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:17:38 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 19:35:25 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 00:52:40 GMT""}]","2022-04-14"
"2101.07456","Ali Rafei","Ali Rafei, Carol A. C. Flannagan, Brady T. West and Michael R. Elliott","Robust Bayesian Inference for Big Data: Combining Sensor-based Records
  with Traditional Survey Data",,,"10.48550/arXiv.2101.0745",,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Big Data often presents as massive non-probability samples. Not only is the
selection mechanism often unknown, but larger data volume amplifies the
relative contribution of selection bias to total error. Existing bias
adjustment approaches assume that the conditional mean structures have been
correctly specified for the selection indicator or key substantive measures. In
the presence of a reference probability sample, these methods rely on a
pseudo-likelihood method to account for the sampling weights of the reference
sample, which is parametric in nature. Under a Bayesian framework, handling the
sampling weights is an even bigger hurdle. To further protect against model
misspecification, we expand the idea of double robustness such that more
flexible non-parametric methods, as well as Bayesian models, can be used for
prediction. In particular, we employ Bayesian additive regression trees, which
not only capture non-linear associations automatically but permit direct
quantification of the uncertainty of point estimates through its posterior
predictive draws. We apply our method to sensor-based naturalistic driving data
from the second Strategic Highway Research Program using the 2017 National
Household Travel Survey as a benchmark.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:20:15 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 21:39:08 GMT""}]","2022-03-29"
"2101.07457","Sergey Tolpygo","Sergey. K. Tolpygo, Evan B. Golden, Terence J. Weir, and Vladimir
  Bolkhovsky (Lincoln Laboratory, Massachusetts Institute of Technology,
  Lexington, MA, USA)","Inductance and mutual inductance of superconductor integrated circuit
  features with sizes down to 120 nm. Part I","21 pagers, 21 figures, 4 tables, 61 references. This work was
  presented at Applied Superconductivity Conference, ASC 2020 Virtual
  Conference, Oct. 24 - Nov. 7, 2020",,"10.1088/1361-6668/ac04b9",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data are presented on inductance of various features used in superconductor
digital integrated circuits such as microstrip and stripline inductors with
linewidths down to 120 nm and different combinations of ground plane layers,
effect of perforations of various sizes in the ground planes and their distance
to the inductors on inductance, inductance of vias of various sizes between
adjacent layers and composite vias between distant superconducting layers.
Effects of magnetic flux trapping in ground plane moats on coupling to nearby
inductors are discussed for circuit cooling in a residual field of several
configurations. Test circuits used for the measurements were fabricated in a
new 150-nm node of a fully planarized process with eight niobium layers, SC2
process, developed at MIT Lincoln Laboratory for superconductor electronics and
in its 250-nm node SC1, as well as in the standard fabrication process SFQ5ee.
The SC2 process utilizes 193-nm photolithography in combination with plasma
etching and chemical mechanical planarization of interlayer dielectrics to
define inductors with linewidth down to about 100 nm on critical layers. All
other processes use 248 nm photolithography. Effects of variation of process
parameters on circuit inductors are discussed. The measured data are compared
with the results of inductance extraction using software packages InductEx and
wxLC. Part II is devoted to mutual inductance of various closely spaced
features in integrated circuits, meanders, and transformers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:22:49 GMT""}]","2021-08-11"
"2101.07458","Wei Lian","Wei Lian and Wangmeng Zuo and Lei Zhang","Hybrid Trilinear and Bilinear Programming for Aligning Partially
  Overlapping Point Sets",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Alignment methods which can handle partially overlapping point sets and are
invariant to the corresponding transformations are desirable in computer
vision, with applications such as providing initial transformation
configuration for local search based methods like ICP. To this end, we first
show that the objective of the robust point matching (RPM) algorithm is a cubic
polynomial. We then utilize the convex envelopes of trilinear and bilinear
monomials to develop its lower bounding function. The resulting lower bounding
problem can be efficiently solved via linear assignment and low dimensional
convex quadratic programming. We next develop a branch-and-bound (BnB)
algorithm which only branches over the transformation parameters and converges
quickly. Experimental results demonstrated favorable performance of the
proposed method over the state-of-the-art methods in terms of robustness and
speed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:24:23 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 07:24:46 GMT""}]","2021-01-26"
"2101.07459","Sergei Zharikov","S. Zharikov, D. Zyuzin, Yu. Shibanov, A. Kirichenko, R. E. Mennickent,
  S. Geier, A. Cabrera-Lavers","PSR B0656+14: the unified outlook from the infrared to X-rays","18 pages, 9 figures, Accepted for publication in MNRAS",,"10.1093/mnras/stab157",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report detection of PSR B0656$+$14 with the Gran Telescopio Canarias in
narrow optical $F657$, $F754$, $F802$, and $F902$ and near-infrared $JHK_s$
bands. The pulsar detection in the $K_s$ band extends its spectrum to 2.2
$\mu$m and confirms its flux increase towards the infrared. We also present a
thorough analysis of the optical spectrum obtained by us with the VLT. For a
consistency check, we revised the pulsar near-infrared and narrow-band
photometry obtained with the \textit{HST}. We find no narrow spectral lines in
the optical spectrum. We compile available near-infrared-optical-UV and
archival 0.3-20keV X-ray data and perform a self-consistent analysis of the
rotation phase-integrated spectrum of the pulsar using unified spectral models.
The spectrum is best fitted by the four-component model including two
blackbodies, describing the thermal emission from the neutron star surface and
its hot polar cap, the broken power-law, originating from the pulsar
magnetosphere, and an absorption line near $\sim$0.5 keV detected previously.
The fit provides better constraints on the model parameters than using only a
single spectral domain. The derived surface temperature is
$T_{NS}^{\infty}=7.9(3)\times10^5$K. The intrinsic radius (7.8-9.9 km) of the
emitting region is smaller than a typical neutron star radius (13km) and
suggests a nonuniform temperature distribution over the star surface. In
contrast, the derived radius of the hot polar cap is about twice as large as
the `canonical' one. The spectrum of the nonthermal emission steepens from the
optical to X-rays and has a break near 0.1 keV. The X-ray data suggest the
presence of another absorption line near 0.3keV.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:26:35 GMT""}]","2021-01-27"
"2101.07460","Prashant Singh Dr","P. Singh, D. Sauceda, R. Arroyavea","High temperature oxidation behavior of disordered (Ti0.5Zr0.5)2AlC MAX
  phase via a Machine Learning-Augmented DFT Approach","8 pages; 2 Figures; 1 Table",,"10.1016/j.mlblux.2021.100062",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Zr-based MAX phases have attracted considerable attention for their
outstanding irradiation behavior and high neutron transparency relevant to
nuclear power generation technologies. In spite of increased understanding of
physical behavior crystalline MAX phases, the high-temperature oxidation
behavior and reaction mechanism of disordered MAX phases both from theory and
experiments are not well understood due to increased system complexity. Here,
we present a detailed comparative assessment of high-temperature
thermodynamic-stability and oxidation behavior (reaction-products and chemical
activity) of ordered Ti2AlC and disordered (Ti0.5Zr0.5)2AlC. We believe that
the new insights will enhance our understanding of oxidation process in
disordered MAX phases.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:29:23 GMT""}]","2021-05-11"
"2101.07461","Daoyi Dong","Daoyi Dong","Learning Control of Quantum Systems","9 pages","In: Baillieul J., Samad T. (eds) Encyclopedia of Systems and
  Control. Springer, London (2020)","10.1007/978-1-4471-5102-9_100161-1",,"quant-ph cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper provides a brief introduction to learning control of quantum
systems. In particular, the following aspects are outlined, including
gradient-based learning for optimal control of quantum systems, evolutionary
computation for learning control of quantum systems, learning-based quantum
robust control, and reinforcement learning for quantum control.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:35:36 GMT""}]","2021-01-20"
"2101.07462","Xinhan Di","Xinhan Di, Pengqian Yu","Deep Reinforcement Learning for Producing Furniture Layout in Indoor
  Scenes","computer vision reinforcement learning. arXiv admin note: text
  overlap with arXiv:2012.08514, arXiv:2012.08131",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the industrial interior design process, professional designers plan the
size and position of furniture in a room to achieve a satisfactory design for
selling. In this paper, we explore the interior scene design task as a Markov
decision process (MDP), which is solved by deep reinforcement learning. The
goal is to produce an accurate position and size of the furniture
simultaneously for the indoor layout task. In particular, we first formulate
the furniture layout task as a MDP problem by defining the state, action, and
reward function. We then design the simulated environment and train
reinforcement learning agents to produce the optimal layout for the MDP
formulation. We conduct our experiments on a large-scale real-world interior
layout dataset that contains industrial designs from professional designers.
Our numerical results demonstrate that the proposed model yields higher-quality
layouts as compared with the state-of-art model. The developed simulator and
codes are available at \url{https://github.com/CODE-SUBMIT/simulator1}.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:38:58 GMT""}]","2021-01-20"
"2101.07463","Marc Cheong","Marc Cheong and Kobi Leins and Simon Coghlan","Computer Science Communities: Who is Speaking, and Who is Listening to
  the Women? Using an Ethics of Care to Promote Diverse Voices","Accepted to ACM FAccT 2021. 10 pages, 1 figure. This arXiv copy is a
  working draft only and not the final version",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Those working on policy, digital ethics and governance often refer to issues
in `computer science', that includes, but is not limited to, common subfields
of Artificial Intelligence (AI), Computer Science (CS) Computer Security
(InfoSec), Computer Vision (CV), Human Computer Interaction (HCI), Information
Systems, (IS), Machine Learning (ML), Natural Language Processing (NLP) and
Systems Architecture. Within this framework, this paper is a preliminary
exploration of two hypotheses, namely 1) Each community has differing inclusion
of minoritised groups (using women as our test case); and 2) Even where women
exist in a community, they are not published representatively. Using data from
20,000 research records, totalling 503,318 names, preliminary data supported
our hypothesis. We argue that ACM has an ethical duty of care to its community
to increase these ratios, and to hold individual computing communities to
account in order to do so, by providing incentives and a regular reporting
system, in order to uphold its own Code.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:44:28 GMT""}]","2021-01-20"
"2101.07464","Yue Lu","Yue M. Lu","Householder Dice: A Matrix-Free Algorithm for Simulating Dynamics on
  Gaussian and Random Orthogonal Ensembles",,,,,"cs.IT math.IT physics.data-an stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a new algorithm, named Householder Dice (HD), for
simulating dynamics on dense random matrix ensembles with translation-invariant
properties. Examples include the Gaussian ensemble, the Haar-distributed random
orthogonal ensemble, and their complex-valued counterparts. A ""direct"" approach
to the simulation, where one first generates a dense $n \times n$ matrix from
the ensemble, requires at least $\mathcal{O}(n^2)$ resource in space and time.
The HD algorithm overcomes this $\mathcal{O}(n^2)$ bottleneck by using the
principle of deferred decisions: rather than fixing the entire random matrix in
advance, it lets the randomness unfold with the dynamics. At the heart of this
matrix-free algorithm is an adaptive and recursive construction of (random)
Householder reflectors. These orthogonal transformations exploit the group
symmetry of the matrix ensembles, while simultaneously maintaining the
statistical correlations induced by the dynamics. The memory and computation
costs of the HD algorithm are $\mathcal{O}(nT)$ and $\mathcal{O}(nT^2)$,
respectively, with $T$ being the number of iterations. When $T \ll n$, which is
nearly always the case in practice, the new algorithm leads to significant
reductions in runtime and memory footprint. Numerical results demonstrate the
promise of the HD algorithm as a new computational tool in the study of
high-dimensional random systems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 04:50:53 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 00:15:14 GMT""}]","2021-01-25"
"2101.07465","Kavirajan Rajendran","K Rajendran (1 and 2), Sajani Surendran (1 and 2), Stella Jes Varghese
  (2) and Arindam Chakraborty (3) ((1) Multi-Scale Modelling Programme (MSMP),
  CSIR Fourth Paradigm Institute (CSIR-4PI), Bangalore, India, (2) Academy of
  Scientific and Innovative Research (AcSIR), Ghaziabad, India, (3) Indian
  Institute of Science (IISc), Bangalore, India)","Sensitivity of Indian summer monsoon rainfall forecast skill of CFSv2
  model to initial conditions and the role of model biases","33 pages, 4 tables, 9 figures and 1 appendix",,,,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse Indian summer monsoon (ISM) seasonal reforecasts by CFSv2 model,
initiated from January (4-month lead time, L4) through May (0-month lead time,
L0) initial conditions (ICs), to examine the cause for highest all-India ISM
rainfall (ISMR) forecast skill with February (L3) ICs. The reported highest L3
skill is based on correlation between observed and predicted interannual
variation (IAV) of ISMR. Other scores such as mean error, bias, RMSE, mean,
standard deviation and coefficient of variation, indicate higher or comparable
skill for April(L1)/May(L0) ICs. Though theory suggests that forecast skill
degrades with increase in lead-time, CFSv2 shows highest skill with L3 ICs, due
to predicting 1983 ISMR excess for which other ICs fail. But this correct
prediction is caused by wrong forecast of La Nina or cooling of equatorial
central Pacific (NINO3.4) during ISM season. In observation, normal sea surface
temperatures (SSTs) prevailed over NINO3.4 and ISMR excess was due to variation
of convection over equatorial Indian Ocean or EQUINOO, which CFSv2 failed to
capture with all ICs. Major results are reaffirmed by analysing an optimum
number of 5 experimental reforecasts by current version of CFSv2 with
late-April/early-May ICs having short yet useful lead-time. These reforecasts
showed least seasonal biases and highest ISMR correlation skill if 1983 is
excluded. Model deficiencies such as over-sensitivity of ISMR to SST variation
over NINO3.4 (ENSO) and unrealistic influence of ENSO on EQUINOO, contribute to
errors in ISMR forecasting. Whereas, in observation, ISMR is influenced by both
ENSO and EQUINOO. Forecast skill for Boreal summer ENSO is found to be
deficient with lowest skill for L3/L4 ICs, hinting the possible influence of
long lead-time induced dynamical drift. The results warrant the need for
minimisation of bias in SST boundary forcing to achieve improved ISMR
forecasts.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:10:44 GMT""}]","2021-01-20"
"2101.07466","Eunhye Song","Eunhye Song","Sequential Bayesian Risk Set Inference for Robust Discrete Optimization
  via Simulation","Under review since September 2019",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimization via simulation (OvS) procedures that assume the simulation
inputs are generated from the real-world distributions are subject to the risk
of selecting a suboptimal solution when the distributions are substituted with
input models estimated from finite real-world data -- known as input model
risk. Focusing on discrete OvS, this paper proposes a new Bayesian framework
for analyzing input model risk of implementing an arbitrary solution, $x$,
where uncertainty about the input models is captured by a posterior
distribution. We define the $\alpha$-level risk set of solution $x$ as the set
of solutions whose expected performance is better than $x$ by a practically
meaningful margin $(>\delta)$ given common input models with significant
probability ($>\alpha$) under the posterior distribution. The user-specified
parameters, $\delta$ and $\alpha$, control robustness of the procedure to the
desired level as well as guards against unnecessary conservatism. An empty risk
set implies that there is no practically better solution than $x$ with
significant probability even though the real-world input distributions are
unknown. For efficient estimation of the risk set, the conditional mean
performance of a solution given a set of input distributions is modeled as a
Gaussian process (GP) that takes the solution-distributions pair as an input.
In particular, our GP model allows both parametric and nonparametric input
models. We propose the sequential risk set inference procedure that estimates
the risk set and selects the next solution-distributions pair to simulate using
the posterior GP at each iteration. We show that simulating the pair expected
to change the risk set estimate the most in the next iteration is the
asymptotic one-step optimal sampling rule that minimizes the number of
incorrectly classified solutions, if the procedure runs without stopping.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:11:15 GMT""}]","2021-01-20"
"2101.07467","Chirag Dhara","Chirag Dhara and Vandana Singh","The Elephant in the Room: Why Transformative Education Must Address the
  Problem of Endless Exponential Economic Growth","To be published in: Iyengar, R. and Kwauk, C. (Eds.), ""Charting an
  SDG 4.7 roadmap for radical, transformative change in the midst of climate
  breakdown"". Brill Publishers",,,,"econ.GN physics.ed-ph q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  A transformative approach to addressing complex social-environmental problems
warrants reexamining our most fundamental assumptions about sustainability and
progress, including the entrenched imperative for limitless economic growth.
Our global resource footprint has grown in lock-step with GDP since the
industrial revolution, spawning the climate and ecological crises. Faith that
technology will eventually decouple resource use from GDP growth is pervasive,
despite there being practically no empirical evidence of decoupling in any
country. We argue that complete long-term decoupling is, in fact, well-nigh
impossible for fundamental physical, mathematical, logical, pragmatic and
behavioural reasons. We suggest that a crucial first step toward a
transformative education is to acknowledge this incompatibility, and provide
examples of where and how our arguments may be incorporated in education. More
broadly, we propose that foregrounding SDG 12 with a functional definition of
sustainability, and educating and upskilling students to this end, must be a
necessary minimum goal of any transformative approach to sustainability
education. Our aim is to provide a conceptual scaffolding around which learning
frameworks may be developed to make room for diverse alternative paths to truly
sustainable social-ecological cultures.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:23:19 GMT""}]","2021-01-20"
"2101.07468","Somnath Bhowmick","Pawan Kumar Tripathi, Shivraj Karewar, Yu-Chieh Lo, Somnath Bhowmick","Role of interface morphology on the martensitic transformation in pure
  Fe","10 pages, 9 figures","Materialia (2021)","10.1016/j.mtla.2021.101085",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Using classical molecular dynamics simulations, we study austenite to ferrite
phase transformation in iron, focusing on the role of interface morphology. We
compare two different morphologies; a \textit{flat} interface in which the two
phases are joined according to Nishiyama-Wasserman orientation relationship vs.
a \textit{ledged} one, having steps similar to the vicinal surface. We identify
the atomic displacements along a misfit dislocation network at the interface
leading to the phase transformation. In case of \textit{ledged} interface,
stacking faults are nucleated at the steps, which hinder the interface motion,
leading to a lower mobility of the inter-phase boundary, than that of flat
interface. Interestingly, we also find the temperature dependence of the
interface mobility to show opposite trends in case of \textit{flat} vs.
\textit{ledged} boundary. We believe that our study is going to present a
unified and comprehensive view of martensitic transformation in iron with
different interface morphology, which is lacking at present, as \textit{flat}
and \textit{ledged} interfaces are treated separately in the existing
literature.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:24:34 GMT""}]","2022-09-07"
"2101.07469","Eric Woolgar","Eric Woolgar and Ran Xie","Self-similar curve shortening flow in hyperbolic 2-space",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We find and classify self-similar solutions of the curve shortening flow in
standard hyperbolic 2-space. Together with earlier work of Halld\'orsson on
curve shortening flow in the plane and Santos dos Reis and Tenenblat in the
2-sphere, this completes the classification of self-similar curve shortening
flows in the constant curvature model spaces in 2-dimensions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:30:29 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 06:52:01 GMT""}]","2021-02-23"
"2101.07470","Primitivo Acosta-Hum\'anez","Primitivo Acosta-Hum\'anez, Moulay Barkatou, Raquel S\'anchez-Cauce
  and Jacques-Arthur Weil","Darboux Transformations for Orthogonal Differential Systems and
  Differential Galois Theory",,"SIGMA 19 (2023), 016, 29 pages","10.3842/SIGMA.2023.016",,"math.CA","http://creativecommons.org/licenses/by-sa/4.0/","  Darboux developed an ingenious algebraic mechanism to construct infinite
chains of ''integrable'' second-order differential equations as well as their
solutions. After a surprisingly long time, Darboux's results were rediscovered
and applied in many frameworks, for instance in quantum mechanics (where they
provide useful tools for supersymmetric quantum mechanics), in soliton theory,
Lax pairs and many other fields involving hierarchies of equations. In this
paper, we propose a method which allows us to generalize the Darboux
transformations algorithmically for tensor product constructions on linear
differential equations or systems. We obtain explicit Darboux transformations
for third-order orthogonal systems ($\mathfrak{so}(3, C_K)$ systems) as well as
a framework to extend Darboux transformations to any symmetric power of
$\mathrm{SL}(2,\mathbb{C})$-systems. We introduce SUSY toy models for these
tensor products, giving as an illustration the analysis of some shape invariant
potentials. All results in this paper have been implemented and tested in the
computer algebra system Maple.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:30:37 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 02:12:02 GMT""},{""version"":""v3"",""created"":""Fri, 31 Mar 2023 11:04:56 GMT""}]","2023-04-03"
"2101.07471","Weihua Xu","Weihua Xu, Feifei Gao, Jianhua Zhang, Xiaoming Tao and Ahmed Alkhateeb","Deep Learning Based Channel Covariance Matrix Estimation with User
  Location and Scene Images","31 pages, 20 figures",,"10.1109/TCOMM.2021.3107947",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Channel covariance matrix (CCM) is one critical parameter for designing the
communications systems. In this paper, a novel framework of the deep learning
(DL) based CCM estimation is proposed that exploits the perception of the
transmission environment without any channel sample or the pilot signals.
Specifically, as CCM is affected by the user's movement, we design a deep
neural network (DNN) to predict CCM from user location and user speed, and the
corresponding estimation method is named as ULCCME. A location denoising method
is further developed to reduce the positioning error and improve the robustness
of ULCCME. For cases when user location information is not available, we
propose an interesting way that uses the environmental 3D images to predict the
CCM, and the corresponding estimation method is named as SICCME. Simulation
results show that both the proposed methods are effective and will benefit the
subsequent channel estimation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:32:19 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 06:05:53 GMT""},{""version"":""v3"",""created"":""Tue, 18 Apr 2023 16:34:11 GMT""}]","2023-04-19"
"2101.07472","Jae Yeon Mun","Jae Yeon Mun, Ho Seong Hwang, Myung Gyoon Lee, Aeree Chung, Hyein
  Yoon, Jong Chul Lee","Star Formation Activity of Galaxies Undergoing Ram Pressure Stripping in
  the Virgo Cluster","20 pages, 9 figures. To appear in JKAS",,,,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study galaxies undergoing ram pressure stripping in the Virgo cluster to
examine whether we can identify any discernible trend in their star formation
activity. We first use 48 galaxies undergoing different stages of stripping
based on HI morphology, HI deficiency, and relative extent to the stellar disk,
from the VIVA survey. We then employ a new scheme for galaxy classification
which combines HI mass fractions and locations in projected phase space,
resulting in a new sample of 365 galaxies. We utilize a variety of star
formation tracers, which include g - r, WISE [3.4] - [12] colors, and
starburstiness that are defined by stellar mass and star formation rates to
compare the star formation activity of galaxies at different stripping stages.
We find no clear evidence for enhancement in the integrated star formation
activity of galaxies undergoing early to active stripping. We are instead able
to capture the overall quenching of star formation activity with increasing
degree of ram pressure stripping, in agreement with previous studies. Our
results suggest that if there is any ram pressure stripping induced
enhancement, it is at best locally modest, and galaxies undergoing enhancement
make up a small fraction of the total sample. Our results also indicate that it
is possible to trace galaxies at different stages of stripping with the
combination of HI gas content and location in projected phase space, which can
be extended to other galaxy clusters that lack high-resolution HI imaging.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:44:13 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 07:48:06 GMT""}]","2021-03-25"
"2101.07473","Michio Otsuki","Michio Otsuki and Hisao Hayakawa","Softening and residual loss modulus of jammed grains under oscillatory
  shear in an absorbing state",,"Phys. Rev. Lett. 128, 208002 (2022)","10.1103/PhysRevLett.128.208002",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  From a theoretical study of the mechanical response of jammed materials
comprising frictionless and overdamped particles under oscillatory shear, we
find that the material becomes soft, and the loss modulus remains finite even
in an absorbing state where any irreversible plastic deformation does not
exist. The trajectories of the particles in this region exhibit hysteresis
loops. We succeed in clarifying the origin of the softening of the material and
the residual loss modulus with the aid of Fourier analysis. We also clarify the
roles of the yielding point in the softening to distinguish the plastic
deformation from reversible deformation in the absorbing state.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 05:58:06 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 08:39:59 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 04:59:07 GMT""},{""version"":""v4"",""created"":""Tue, 28 Dec 2021 07:28:57 GMT""},{""version"":""v5"",""created"":""Wed, 18 May 2022 01:18:21 GMT""}]","2022-05-19"
"2101.07474","Weisheng Huang","Xiao-Song Yang, Weisheng Huang","Indices of equilibrium points of linear control systems with saturated
  state feedback",,,,,"math.OC math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper we investigate some properties of equilibrium points in
n-dimensional linear control systems with saturated state feedback. We provide
an index formula for equilibrium points and discuss its relation to boundaries
of attraction basins in feedback systems with single input. In addition, we
also touch upon convexity of attraction basin.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:05:41 GMT""}]","2021-01-20"
"2101.07475","Akashdeep Dey","Akashdeep Dey","The Allen-Cahn equation on the complete Riemannian manifolds of finite
  volume",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The semi-linear, elliptic PDE $AC_{\varepsilon}(u):=-\varepsilon^2\Delta
u+W'(u)=0$ is called the Allen-Cahn equation. In this article we will prove the
existence of finite energy solution to the Allen-Cahn equation on certain
complete, non-compact manifolds. More precisely, suppose $M^{n+1}$ (with
$n+1\geq 3$) is a complete Riemannian manifold of finite volume. Then there
exists $\varepsilon_0>0$, depending on the ambient Riemannian metric, such that
for all $0<\varepsilon\leq\varepsilon_0$, there exists
$\mathfrak{u}_{\varepsilon}:M\rightarrow (-1,1)$ satisfying
$AC_{\varepsilon}(\mathfrak{u}_{\varepsilon})=0$ with the energy
$E_{\varepsilon}(\mathfrak{u}_{\varepsilon})<\infty$ and the Morse index
$\text{Ind}(\mathfrak{u}_{\varepsilon})\leq 1$. Moreover,
$0<\liminf_{\varepsilon\rightarrow
0}E_{\varepsilon}(\mathfrak{u}_{\varepsilon})\leq\limsup_{\varepsilon\rightarrow
0}E_{\varepsilon}(\mathfrak{u}_{\varepsilon})<\infty.$ Our result is motivated
by the theorem of Chambers-Liokumovich and Song, which says that $M$ contains a
complete minimal hypersurface $\Sigma$ with $0<\mathcal{H}^n(\Sigma)<\infty.$
This theorem can be recovered from our result.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:11:49 GMT""}]","2021-01-20"
"2101.07476","Kazuharu Bamba","Riasat Ali, Kazuharu Bamba, Muhammad Asgher, and Syed Asif Ali Shah","Tunneling Under the Influence of Quantum Gravity in Black Rings","8 pages, 2 figures, version accepted for publication in International
  Journal of Modern Physics D",,"10.1142/S0218271821500024","FU-PCG-70","gr-qc","http://creativecommons.org/licenses/by/4.0/","  We explore the Lagrangian equation in the background of generalized
uncertainty principle. The tunneling radiation through the black ring horizon
is observed. We investigated the tunneling radiation through the
Hamilton-Jacobi method for solutions of Einstein-Maxwell-dilation gravity
theory. The radiation of black ring without back reaction and self interaction
of particles are studied. Furthermore, we consider the quantum gravity effect
on the stability of black ring.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:17:59 GMT""}]","2021-01-20"
"2101.07477","Carlos Augusto Mera Acosta","Carlos Mera Acosta, Linding Yuan, Gustavo M. Dalpian, Alex Zunger","The different shapes of spin textures as a journey through Brillouin
  zone chiral and polar symmetries","28 pages and 9 figures","Phys. Rev. B 104, 104408 (2021)","10.1103/PhysRevB.104.104408",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Crystallographic space group symmetry (CPGS) such as polar and nonpolar
crystal classes have long been known to classify compounds that have
spin-orbit-induced spin splitting. While taking a journey through the Brillouin
Zone (BZ) from one k-point to another for a fixed CPGS, it is expected that the
wavevector point group symmetry (WPGS) can change, and consequently a
qualitative change in the texture of the spin polarization (the expectation
value of spin operator $\vec{S}^{nk_{0}}$ in Bloch state $u(n,k)$ and the
wavevector $k_0$). However, the nature of the spin texture (ST) change is
generally unsuspected. In this work, we determine a full classification of the
linear-in-$k$ spin texture patterns based on the polarity and chirality
reflected in the WPGS at $k_0$. The spin-polarization vector $\vec{S}^{nk_{0}}$
controlling the ST is bound to be parallel to the rotation axis and
perpendicular to the mirror planes and hence, symmetry operation types in WPGSs
impose symmetry restriction to the ST. For instance, the ST is always parallel
to the wavevector $k$ in non-polar chiral WPGSs since they contain only
rotational symmetries. Some consequences of the ST classification based on the
symmetry operations in the WPGS include the observation of ST patterns that are
unexpected according to the symmetry of the crystal. For example, it is usually
established that spin-momentum locking effect requires the crystal inversion
symmetry breaking by an asymmetric electric potential. However, we find that
polar WPGS can have this effect even in compounds without electric dipoles or
external electric fields. We use the determined relation between WPGS and ST as
a design principle to select compounds with multiple ST near band edges at
different $k$-valleys. Based on high-throughput calculations for 1481
compounds, we find 37 previously fabricated materials with different ST near
band edges.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:26:22 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 19:36:48 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 03:10:29 GMT""}]","2021-09-15"
"2101.07478","Dakyeong Kim","Dakyeong Kim, Shingo Kobayashi and Yasuhiro Asano","Josephson effect of superconductors with $J=3/2$ electrons","10 pages, 2 figures","Phys. Rev. B 103, 184516 (2021)","10.1103/PhysRevB.103.184516",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The angular momentum of an electron is characterized well by pseudospin with
$J=3/2$ in the presence of strong spin-orbit interactions. We study
theoretically the Josephson effect of superconductors in which such two $J=3/2$
electrons form a Cooper pair. Within even-parity symmetry class,
pseudospin-quintet pairing states with $J=2$ can exist as well as
pseudospin-singlet state with $J=0$. We focus especially on the Josephson
selection rule among these even-parity superconductors. We find that the
selection rule between quintet states is severer than that between spin-triplet
states formed by two $S=1/2$ electrons. The effects of a pseudospin-active
interface on the selection rule are discussed as well as those of odd-frequency
Cooper pairs generated by pseudospin dependent band structures.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:26:37 GMT""}]","2021-05-31"
"2101.07479","Yue Meng","Chen Cheng, Pengwei Xie, Abdusalam Abdukerim, Wei Chen, Xun Chen,
  Yunhua Chen, Xiangyi Cui, Yingjie Fan, Deqing Fang, Changbo Fu, Mengting Fu,
  Lisheng Geng, Karl Giboni, Linhui Gu, Xuyuan Guo, Ke Han, Changda He, Di
  Huang, Yan Huang, Yanlin Huang, Zhou Huang, Xiangdong Ji, Yonglin Ju,
  Shuaijie Li, Qing Lin, Huaxuan Liu, Jianglai Liu, Liqiang Liu, Xiaoying Lu,
  Wenbo Ma, Yugang Ma, Yajun Mao, Yue Meng, Nasir Shaheed, Kaixiang Ni, Jinhua
  Ning, Xuyang Ning, Xiangxiang Ren, Changsong Shang, Guofang Shen, Lin Si,
  Andi Tan, Anqing Wang, Hongwei Wang, Meng Wang, Qiuhong Wang, Siguang Wang,
  Wei Wang, Xiuli Wang, Zhou Wang, Mengmeng Wu, Shiyong Wu, Weihao Wu, Jingkai
  Xia, Mengjiao Xiao, Xiang Xiao, Binbin Yan, Jijun Yang, Yong Yang, Chunxu Yu,
  Jumin Yuan, Ying Yuan, Xinning Zeng, Dan Zhang, Tao Zhang, Li Zhao, Qibin
  Zheng, Jifang Zhou, Ning Zhou, Xiaopeng Zhou","Search for Light Dark Matter-Electron Scatterings in the PandaX-II
  Experiment","6 pages, 5 figures, 2 tables","Phys. Rev. Lett. 126, 211803 (2021)","10.1103/PhysRevLett.126.211803",,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  We report constraints on light dark matter through its interactions with
shell electrons in the PandaX-II liquid xenon detector with a total 46.9
tonne$\cdot$day exposure. To effectively search for these very low energy
electron recoils, ionization-only signals are selected from the data. 1821
candidates are identified within ionization signal range between 50 to 75
photoelectrons, corresponding to a mean electronic recoil energy from 0.08 to
0.15 keV. The 90% C.L. exclusion limit on the scattering cross section between
the dark matter and electron is calculated based on Poisson statistics. Under
the assumption of point interaction, we provide the world's most stringent
limit within the dark matter mass range from 15 to 30 $\rm MeV/c^2$, with the
corresponding cross section from $2.5\times10^{-37}$ to $3.1\times10^{-38}$
cm$^2$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:31:13 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 06:25:03 GMT""}]","2021-05-31"
"2101.07480","Geon Lee","Geon Lee, Minyoung Choe, Kijung Shin","How Do Hyperedges Overlap in Real-World Hypergraphs? -- Patterns,
  Measures, and Generators","Accepted to WWW 2021 - The Web Conference 2021",,,,"cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Hypergraphs, a generalization of graphs, naturally represent groupwise
relationships among multiple individuals or objects, which are common in many
application areas, including web, bioinformatics, and social networks. The
flexibility in the number of nodes in each hyperedge, which provides the
expressiveness of hypergraphs, brings about structural differences between
graphs and hypergraphs. Especially, the overlaps of hyperedges lead to complex
high-order relations beyond pairwise relations, raising new questions that have
not been considered in graphs: How do hyperedges overlap in real-world
hypergraphs? Are there any pervasive characteristics? What underlying process
can cause such patterns? In this work, we closely investigate thirteen
real-world hypergraphs from various domains and share interesting observations
of overlaps of hyperedges. To this end, we define principled measures and
statistically compare the overlaps of hyperedges in real-world hypergraphs and
those in null models. Additionally, based on the observations, we propose
HyperLap, a realistic hypergraph generative model. HyperLap is (a) Realistic:
it accurately reproduces overlapping patterns of real-world hypergraphs, (b)
Automatically Fittable: its parameters can be tuned automatically using
HyperLap+ to generate hypergraphs particularly similar to a given target
hypergraph, (c) Scalable: it generates and fits a hypergraph with 0.7 billion
hyperedges within a few hours.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:33:08 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 05:04:32 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 09:39:10 GMT""},{""version"":""v4"",""created"":""Tue, 20 Apr 2021 02:27:43 GMT""}]","2021-04-21"
"2101.07481","Riku Togashi","Riku Togashi, Masahiro Kato, Mayu Otani, Shin'ichi Satoh","Density-Ratio Based Personalised Ranking from Implicit Feedback","Accepted by WWW 2021",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning from implicit user feedback is challenging as we can only observe
positive samples but never access negative ones. Most conventional methods cope
with this issue by adopting a pairwise ranking approach with negative sampling.
However, the pairwise ranking approach has a severe disadvantage in the
convergence time owing to the quadratically increasing computational cost with
respect to the sample size; it is problematic, particularly for large-scale
datasets and complex models such as neural networks. By contrast, a pointwise
approach does not directly solve a ranking problem, and is therefore inferior
to a pairwise counterpart in top-K ranking tasks; however, it is generally
advantageous in regards to the convergence time. This study aims to establish
an approach to learn personalised ranking from implicit feedback, which
reconciles the training efficiency of the pointwise approach and ranking
effectiveness of the pairwise counterpart. The key idea is to estimate the
ranking of items in a pointwise manner; we first reformulate the conventional
pointwise approach based on density ratio estimation and then incorporate the
essence of ranking-oriented approaches (e.g. the pairwise approach) into our
formulation. Through experiments on three real-world datasets, we demonstrate
that our approach not only dramatically reduces the convergence time (one to
two orders of magnitude faster) but also significantly improving the ranking
performance.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:38:57 GMT""}]","2021-01-20"
"2101.07482","Zheshen Zhang","Shuhong Hao, Haowei Shi, Wei Li, Quntao Zhuang, Zheshen Zhang","Entanglement-Assisted Communication Surpassing the Ultimate Classical
  Capacity","12 pages, 5 figures. Comments are welcome","Phys. Rev. Lett. 126, 250501 (2021)","10.1103/PhysRevLett.126.250501",,"quant-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Entanglement underpins a variety of quantum-enhanced communication, sensing,
and computing capabilities. Entanglement-assisted communication (EACOMM)
leverages entanglement pre-shared by communication parties to boost the rate of
classical information transmission. Pioneering theory works showed that EACOMM
can enable a communication rate well beyond the ultimate classical capacity of
optical communications, but an experimental demonstration of any EACOMM
advantage remains elusive. Here, we report the implementation of EACOMM
surpassing the classical capacity over lossy and noisy bosonic channels. We
construct a high-efficiency entanglement source and a phase-conjugate quantum
receiver to reap the benefit of pre-shared entanglement, despite entanglement
being broken by channel loss and noise. We show that EACOMM beats the
Holevo-Schumacher-Westmoreland capacity of classical communication by up to
14.6%, when both protocols are subject to the same power constraint at the
transmitter. As a practical performance benchmark, a classical communication
protocol without entanglement assistance is implemented, showing that EACOMM
can reduce the bit-error rate by up to 69% over the same bosonic channel. Our
work opens a route to provable quantum advantages in a wide range of quantum
information processing tasks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:41:09 GMT""}]","2021-06-30"
"2101.07483","Ran He","Ming-Zhong Ai, Sai Li, Ran He, Zheng-Yuan Xue, Jin-Ming Cui, Yun-Feng
  Huang, Chuan-Feng Li, Guang-Can Guo","Experimental Realization of Nonadiabatic Holonomic Single-Qubit Quantum
  Gates with Two Dark Paths in a Trapped Ion","13 pages, 5 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For circuit-based quantum computation, experimental implementation of
universal set of quantum logic gates with high-fidelity and strong robustness
is essential and central. Quantum gates induced by geometric phases, which
depend only on global properties of the evolution paths, have built-in
noise-resilience features. Here, we propose and experimentally demonstrate
nonadiabatic holonomic single-qubit quantum gates on two dark paths in a
trapped $^{171}\mathrm{Yb}^{+}$ ion based on four-level systems with resonant
drives. We confirm the implementation with measured gate fidelity through both
quantum process tomography and randomized benchmarking methods. Meanwhile, we
find that nontrivial holonomic two-qubit quantum gates can also be realized
within current experimental technologies. Compared with previous
implementations on three-level systems, our experiment share both the advantage
of fast nonadiabatic evolution and the merit of robustness against systematic
errors, and thus retains the main advantage of geometric phases. Therefore, our
experiment confirms a promising method for fast and robust holonomic quantum
computation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:57:50 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 01:48:18 GMT""}]","2021-01-21"
"2101.07484","Minxin Huang","Bao-ning Du, Min-xin Huang","Free BMN Correlators With More Stringy Modes","39 pages, 3 figures. v2: journal version, references added",,"10.1007/JHEP03(2021)246","USTC-ICTS/PCFT-21-04","hep-th","http://creativecommons.org/licenses/by/4.0/","  In the type IIB maximally supersymmetric pp-wave background, stringy excited
modes are described by BMN (Berenstein-Madalcena-Nastase) operators in the dual
$\mathcal{N}=4$ super-Yang-Mills theory. In this paper, we continue the studies
of higher genus free BMN correlators with more stringy modes, mostly focusing
on the case of genus one and four stringy modes in different transverse
directions. Surprisingly, we find that the non negativity of torus two-point
functions, which is a consequence of a previously proposed probability
interpretation and has been verified in the cases with two and three stringy
modes, is no longer true for the case of four or more stringy modes.
Nevertheless, the factorization formula, which is also a proposed holographic
dictionary relating the torus two-point function to a string diagram
calculation, is still valid. We also check the correspondence of planar
three-point functions with Green-Schwarz string vertex with many string modes.
We discuss some issues in the case of multiple stringy modes in the same
transverse direction. Our calculations provide some new perspectives on pp-wave
holography.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:06:31 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 13:34:33 GMT""}]","2021-04-14"
"2101.07485","Qianwei Qu","Qianwei Qu, Bridgette Cooper, Sergei N. Yurchenko and Jonathan
  Tennyson","A spectroscopic model for the low-lying electronic states of NO","14 pages","J. Chem. Phys. 154, 074112 (2021)","10.1063/5.0038527",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rovibronic structure of A$^2\Sigma^+$, B$^2\Pi$ and C$^2\Pi$ states of
nitric oxide (NO)is studied with the aim of producing comprehensive line lists
for its near ultraviolet spectrum. Empirical energy levels for the three
electronic states are determined using the a combination of the empirical
MARVEL procedure and ab initio calculations, and the available experimental
data are critically evaluated. Abinito methods which deal simultaneously with
the Rydberg-like A$^2\Sigma^+$ and C$^2\Pi$, and the valence B$^2\Pi$ state are
tested. Methods of modeling the sharp avoided crossing between the B$^2\Pi$ and
C$^2\Pi$ states are tested. A rovibronic Hamiltonian matrix is constructed
using variational nuclear motion program DUO whose eigenvalues are fitted to
the MARVEL energy levels. The matrix also includes coupling terms obtained from
the refinement of the ab initio potential energy and spin-orbit coupling
curves. Calculated and observed energy levels agree well with each other,
validating the applicability of our method and providing a useful model for
this open shell system.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:10:50 GMT""},{""version"":""v2"",""created"":""Sun, 22 Aug 2021 03:09:47 GMT""}]","2021-08-24"
"2101.07486","Tianyi Liu","Tianyi Liu, Daniel Jost, Brian Moritz, Edwin W. Huang, Rudi Hackl,
  Thomas P. Devereaux","Tendencies of enhanced electronic nematicity in the Hubbard model and a
  comparison with Raman scattering on high-temperature superconductors","8 pages, 7 figures","Phys. Rev. B 103, 134502 (2021)","10.1103/PhysRevB.103.134502",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pseudogap regime of the cuprate high-temperature superconductors is
characterized by a variety of competing orders, the nature of which are still
widely debated. Recent experiments have provided evidence for electron nematic
order, in which the electron fluid breaks rotational symmetry while preserving
translational invariance. Raman spectroscopy, with its ability to symmetry
resolve low energy excitations, is a unique tool that can be used to assess
nematic fluctuations and nematic ordering tendencies. Here, we compare results
from determinant quantum Monte Carlo simulations of the Hubbard model to
experimental results from Raman spectroscopy in
$\text{La}_{2-x}\text{Sr}_{x}\text{CuO}_{4}$, which show a prominent increase
in the $B_{1g}$ response around 10% hole doping as the temperature decreases,
indicative of a rise in nematic fluctuations at low energy. Our results support
a picture of nematic fluctuations with $B_{1g}$ symmetry occurring in
underdoped cuprates, which may arise from melted stripes at elevated
temperatures.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:12:32 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 04:38:40 GMT""}]","2021-04-14"
"2101.07487","Berat Kurar Barakat","Ahmad Droby, Berat Kurar Barakat, Borak Madi, Reem Alaasam and Jihad
  El-Sana","Unsupervised Deep Learning for Handwritten Page Segmentation",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Segmenting handwritten document images into regions with homogeneous patterns
is an important pre-processing step for many document images analysis tasks.
Hand-labeling data to train a deep learning model for layout analysis requires
significant human effort. In this paper, we present an unsupervised deep
learning method for page segmentation, which revokes the need for annotated
images. A siamese neural network is trained to differentiate between patches
using their measurable properties such as number of foreground pixels, and
average component height and width. The network is trained that spatially
nearby patches are similar. The network's learned features are used for page
segmentation, where patches are classified as main and side text based on the
extracted features. We tested the method on a dataset of handwritten document
images with quite complex layouts. Our experiments show that the proposed
unsupervised method is as effective as typical supervised methods.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:13:38 GMT""}]","2021-01-20"
"2101.07488","Gursharn Kaur","Kwok Pui Choi, Gursharn Kaur and Taoyang Wu","On asymptotic joint distributions of cherries and pitchforks for random
  phylogenetic trees",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tree shape statistics provide valuable quantitative insights into
evolutionary mechanisms underpinning phylogenetic trees, a commonly used graph
representation of evolution systems ranging from viruses to species. By
developing limit theorems for a version of extended P\'olya urn models in which
negative entries are permitted for their replacement matrices, we present
strong laws of large numbers and central limit theorems for asymptotic joint
distributions of two subtree counting statistics, the number of cherries and
that of pitchforks, for random phylogenetic trees generated by two widely used
null tree models: the proportional to distinguishable arrangements (PDA) and
the Yule-Harding-Kingman (YHK) models. Our results indicate that the limiting
behaviour of these two statistics, when appropriately scaled, are independent
of the initial trees used in the tree generating process.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:18:05 GMT""}]","2021-01-20"
"2101.07489","Ryo Fujita","Ryo Fujita, David Hernandez, Se-jin Oh, Hironori Oya","Isomorphisms among quantum Grothendieck rings and propagation of
  positivity","v3: minor revision, 68 pages, Lemma 3.12 and Lemma 8.3 corrected, to
  appear in Crelle's journal","Journal f\""ur die reine und angewandte Mathematik (Crelle's
  Journal) 2022 (785) 117--185","10.1515/crelle-2021-0088",,"math.RT math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let ($\mathfrak{g},\mathsf{g})$ be a pair of complex finite-dimensional
simple Lie algebras whose Dynkin diagrams are related by (un)folding, with
$\mathsf{g}$ being of simply-laced type. We construct a collection of ring
isomorphisms between the quantum Grothendieck rings of monoidal categories
$\mathscr{C}_{\mathfrak{g}}$ and $\mathscr{C}_{\mathsf{g}}$ of
finite-dimensional representations over the quantum loop algebras of
$\mathfrak{g}$ and $\mathsf{g}$ respectively. As a consequence, we solve
long-standing problems : the positivity of the analogs of Kazhdan-Lusztig
polynomials and the positivity of the structure constants of the quantum
Grothendieck rings for any non-simply-laced $\mathfrak{g}$. In addition,
comparing our isomorphisms with the categorical relations arising from the
generalized quantum affine Schur-Weyl dualities, we prove the analog of
Kazhdan-Lusztig conjecture (formulated in [H., Adv. Math., 2004]) for simple
modules in remarkable monoidal subcategories of $\mathscr{C}_{\mathfrak{g}}$
for any non-simply-laced $\mathfrak{g}$, and for any simple finite-dimensional
modules in $\mathscr{C}_{\mathfrak{g}}$ for $\mathfrak{g}$ of type
$\mathrm{B}_n$. In the course of the proof we obtain and combine several new
ingredients. In particular we establish a quantum analog of $T$-systems, and
also we generalize the isomorphisms of [H.-Leclerc, J. Reine Angew. Math.,
2015] and [H.-O., Adv. Math., 2019] to all $\mathfrak{g}$ in a unified way,
that is isomorphisms between subalgebras of the quantum group of $\mathsf{g}$
and subalgebras of the quantum Grothendieck ring of $\mathscr{C}_\mathfrak{g}$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:24:15 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 09:07:29 GMT""},{""version"":""v3"",""created"":""Wed, 15 Dec 2021 07:32:06 GMT""}]","2022-04-05"
"2101.07490","Stavros Garoufalidis","Stavros Garoufalidis and Emanuel Scheidegger","On the Quantum K-Theory of the Quintic",,"SIGMA 18 (2022), 021, 20 pages","10.3842/SIGMA.2022.021",,"math.AG hep-th math.GT","http://creativecommons.org/licenses/by-sa/4.0/","  Quantum K-theory of a smooth projective variety at genus zero is a collection
of integers that can be assembled into a generating series $J(Q,q,t)$ that
satisfies a system of linear differential equations with respect to $t$ and
$q$-difference equations with respect to $Q$. With some mild assumptions on the
variety, it is known that the full theory can be reconstructed from its small
$J$-function $J(Q,q,0)$ which, in the case of Fano manifolds, is a
vector-valued $q$-hypergeometric function. On the other hand, for the quintic
3-fold we formulate an explicit conjecture for the small $J$-function and its
small linear $q$-difference equation expressed linearly in terms of the
Gopakumar-Vafa invariants. Unlike the case of quantum knot invariants, and the
case of Fano manifolds, the coefficients of the small linear $q$-difference
equations are not Laurent polynomials, but rather analytic functions in two
variables determined linearly by the Gopakumar-Vafa invariants of the quintic.
Our conjecture for the small $J$-function agrees with a proposal of
Jockers-Mayr.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:24:31 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 07:25:19 GMT""}]","2022-03-22"
"2101.07491","Abolfazl Lavaei","Abolfazl Lavaei, Sadegh Soudjani, Alessandro Abate, Majid Zamani","Automated Verification and Synthesis of Stochastic Hybrid Systems: A
  Survey",,,,,"cs.LO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic hybrid systems have received significant attentions as a relevant
modelling framework describing many systems, from engineering to the life
sciences: they enable the study of numerous applications, including
transportation networks, biological systems and chemical reaction networks,
smart energy and power grids, and beyond. Automated verification and policy
synthesis for stochastic hybrid systems can be inherently challenging: this is
due to the heterogeneity of their dynamics (presence of continuous and discrete
components), the presence of uncertainty, and in some applications the large
dimension of state and input sets. Over the past few years, a few hundred
articles have investigated these models, and developed diverse and powerful
approaches to mitigate difficulties encountered in the analysis and synthesis
of such complex stochastic systems. In this survey, we overview the most recent
results in the literature and discuss different approaches, including
(in)finite abstractions, verification and synthesis for temporal logic
specifications, stochastic similarity relations, (control) barrier
certificates, compositional techniques, and a selection of results on
continuous-time stochastic systems; we finally survey recently developed
software tools that implement the discussed approaches. Throughout the
manuscript we discuss a few open topics to be considered as potential future
research directions: we hope that this survey will guide younger researchers
through a comprehensive understanding of the various challenges, tools, and
solutions in this enticing and rich scientific area.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:24:47 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 05:48:03 GMT""}]","2022-03-11"
"2101.07492","Taniya Seth","Taniya Seth and Pranab K. Muhuri","Optimizing Hyperparameters in CNNs using Bilevel Programming in Time
  Series Data",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Hyperparameter optimization has remained a central topic within the machine
learning community due to its ability to produce state-of-the-art results. With
the recent interest growing in the usage of CNNs for time series prediction, we
propose the notion of optimizing Hyperparameters in CNNs for the purpose of
time series prediction. In this position paper, we give away the idea of
modeling the concerned hyperparameter optimization problem using bilevel
programming.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:24:54 GMT""}]","2021-01-20"
"2101.07493","Chaoyu Song","Chaoyu Song, Xiang Yuan, Ce Huang, Shenyang Huang, Qiaoxia Xing, Chong
  Wang, Cheng Zhang, Yuangang Xie, Yuchen Lei, Fanjie Wang, Lei Mu, Jiasheng
  Zhang, Faxian Xiu, Hugen Yan","Plasmons in the van der Waals charge-density-wave material 2H-TaSe2","30 pages, 5 figures","Nature Communications 12,386(2021)","10.1038/s41467-020-20720-0",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Plasmons in two-dimensional (2D) materials beyond graphene have recently
gained much attention. However, the experimental investigation is limited due
to the lack of suitable materials. Here, we experimentally demonstrate
localized plasmons in a correlated 2D charge-density-wave (CDW) material:
2H-TaSe2. The plasmon resonance can cover a broad spectral range from the
terahertz (40 {\mu}m) to the telecom (1.55 {\mu}m) region, which is further
tunable by changing thickness and dielectric environments. The plasmon
dispersion flattens at large wave vectors, resulted from the universal
screening effect of interband transitions. More interestingly, anomalous
temperature dependence of plasmon resonances associated with CDW excitations is
observed. In the CDW phase, the plasmon peak close to the CDW excitation
frequency becomes wider and asymmetric, mimicking two coupled oscillators. Our
study not only reveals the universal role of the intrinsic screening on 2D
plasmons, but also opens an avenue for tunable plasmons in 2D correlated
materials.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:34:01 GMT""}]","2021-01-20"
"2101.07494","Filbert Juwono","W. K. Wong, Filbert H. Juwono, and Tock H. Chua","SIR Simulation of COVID-19 Pandemic in Malaysia: Will the Vaccination
  Program be Effective?",,,,,"physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Since the end of 2019, COVID-19 has significantly affected the lives of
people around the world. Towards the end of 2020, several COVID-19 vaccine
candidates with relatively high efficacy have been reported in the final phase
of clinical trials. Vaccines have been considered as critical tools for opening
up social and economic activities, thereby lessening the impact of this disease
on the society. This paper presents a simulation of COVID-19 spread using
modified Susceptible-Infected-Removed (SIR) model under vaccine intervention in
several localities of Malaysia, i.e. those cities or states with high
relatively COVID-19 cases such as Kuala Lumpur, Penang, Sabah, and Sarawak. The
results show that at different vaccine efficacy levels (0.75, 0.85, and 0.95),
the curves of active infection vary slightly, indicating that vaccines with
efficacy above 0.75 would produce the herd immunity required to level the
curves. In addition, disparity is significant between implementing or not
implementing a vaccination program. Simulation results also show that lowering
the reproduction number, R0 is necessary to keep the infection curve flat
despite vaccination. This is due to the assumption that vaccination is mostly
carried out gradually at the assumed fixed rate. The statement is based on our
simulation results with two values of R0: 1.1 and 1.2, indicative of reduction
of R0 by social distancing. The lower R0 shows a smaller peak amplitude about
half the value simulated with R0=1.2. In conclusion, the simulation model
suggests a two-pronged strategy to combat the COVID-19 pandemic in Malaysia:
vaccination and compliance with standard operating procedure issued by the
World Health Organization (e.g. social distancing).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:39:42 GMT""}]","2021-01-20"
"2101.07495","Nathan Grosshans","Nathan Grosshans, Pierre Mckenzie (DIRO), Luc Segoufin (VALDA)","Tameness and the power of programs over monoids in DA",,,,,"cs.CC cs.DM cs.FL cs.LO","http://creativecommons.org/licenses/by/4.0/","  The program-over-monoid model of computation originates with Barrington's
proof that the model captures the complexity class $\mathsf{NC^1}$. Here we
make progress in understanding the subtleties of the model. First, we identify
a new tameness condition on a class of monoids that entails a natural
characterization of the regular languages recognizable by programs over monoids
from the class. Second, we prove that the class known as $\mathbf{DA}$
satisfies tameness and hence that the regular languages recognized by programs
over monoids in $\mathbf{DA}$ are precisely those recognizable in the classical
sense by morphisms from $\mathbf{QDA}$. Third, we show by contrast that the
well studied class of monoids called $\mathbf{J}$ is not tame. Finally, we
exhibit a program-length-based hierarchy within the class of languages
recognized by programs over monoids from $\mathbf{DA}$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:41:31 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 09:00:01 GMT""},{""version"":""v3"",""created"":""Fri, 6 May 2022 09:50:26 GMT""},{""version"":""v4"",""created"":""Thu, 12 May 2022 09:42:11 GMT""},{""version"":""v5"",""created"":""Fri, 29 Jul 2022 20:36:54 GMT""}]","2022-08-02"
"2101.07496","Jun Han Mr","Jun Han, Martin Renqiang Min, Ligong Han, Li Erran Li, Xuan Zhang","Disentangled Recurrent Wasserstein Autoencoder","ICLR 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning disentangled representations leads to interpretable models and
facilitates data generation with style transfer, which has been extensively
studied on static data such as images in an unsupervised learning framework.
However, only a few works have explored unsupervised disentangled sequential
representation learning due to challenges of generating sequential data. In
this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new
framework for generative modeling of sequential data. R-WAE disentangles the
representation of an input sequence into static and dynamic factors (i.e.,
time-invariant and time-varying parts). Our theoretical analysis shows that,
R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance
between model distribution and sequential data distribution, and simultaneously
maximizes the mutual information between input data and different disentangled
latent factors, respectively. This is superior to (recurrent) VAE which does
not explicitly enforce mutual information maximization between input data and
disentangled latent representations. When the number of actions in sequential
data is available as weak supervision information, R-WAE is extended to learn a
categorical latent representation of actions to improve its disentanglement.
Experiments on a variety of datasets show that our models outperform other
baselines with the same settings in terms of disentanglement and unconditional
video generation both quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:43:25 GMT""}]","2021-01-20"
"2101.07497","Jing Wang","Jing Wang, Robbe Van Pottelberge, Amber Jacobs, Ben Van Duppen and
  Francois M. Peeters","Confinement and edge effects on atomic collapse in graphene nanoribbons",,,"10.1103/PhysRevB.103.035426",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Atomic collapse in graphene nanoribbons behaves in a fundamentally different
way as compared to monolayer graphene, due to the presence of multiple energy
bands and the effect of edges. For armchair nanoribbons we find that bound
states gradually transform into atomic collapse states with increasing impurity
charge. This is very different in zig-zag nanoribbons where multiple
quasi-one-dimensional \emph{bound states} are found that originates from the
zero energy zig-zag edge states. They are a consequence of the flat band and
the electron distribution of these bound states exhibits two peaks. The lowest
energy edge state transforms from a bound state into an atomic collapse
resonance and shows a distinct relocalization from the edge to the impurity
position with increasing impurity charge.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:45:01 GMT""}]","2021-02-24"
"2101.07498","Benjamin Goertzel","Ben Goertzel","Paraconsistent Foundations for Quantum Probability",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is argued that a fuzzy version of 4-truth-valued paraconsistent logic
(with truth values corresponding to True, False, Both and Neither) can be
approximately isomorphically mapped into the complex-number algebra of quantum
probabilities. I.e., p-bits (paraconsistent bits) can be transformed into close
approximations of qubits. The approximation error can be made arbitrarily
small, at least in a formal sense, and can be related to the degree of
irreducible ""evidential error"" assumed to plague an observer's observations.
This logical correspondence manifests itself in program space via an
approximate mapping between probabilistic and quantum types in programming
languages.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:48:41 GMT""}]","2021-01-20"
"2101.07499","Guorong Hu","Qing Hong, Guorong Hu, Michael Ruzhansky","Fourier multipliers for Hardy spaces on graded Lie groups","20 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the $H^p(G) \rightarrow L^p(G)$, $0< p \leq 1$,
boundedness of multiplier operators defined via group Fourier transform on a
graded Lie group $G$, where $H^p(G)$ is the Hardy space on $G$. Our main result
extends those obtained in [Colloq. Math. \textbf{165} (2021), 1--30], where the
$L^1(G)\rightarrow L^{1,\infty}(G)$ and $L^p(G) \rightarrow L^p(G)$, $1< p
<\infty$, boundedness of such Fourier multiplier operators were proved.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:56:12 GMT""},{""version"":""v2"",""created"":""Wed, 5 Oct 2022 22:42:43 GMT""}]","2022-10-07"
"2101.07500","Sascha P. Quanz","S.P. Quanz, M. Ottiger, E. Fontanet, J. Kammerer, F. Menti, F.
  Dannert, A. Gheorghe, O. Absil, V.S. Airapetian, E. Alei, R. Allart, D.
  Angerhausen, S. Blumenthal, L.A. Buchhave, J. Cabrera, \'O.
  Carri\'on-Gonz\'alez, G. Chauvin, W.C. Danchi, C. Dandumont, D. Defr\`ere, C.
  Dorn, D. Ehrenreich, S. Ertel, M. Fridlund, A. Garc\'ia Mu\~noz, C. Gasc\'on,
  J.H. Girard, A. Glauser, J.L. Grenfell, G. Guidi, J. Hagelberg, R. Helled,
  M.J. Ireland, M. Janson, R.K. Kopparapu, J. Korth, T. Kozakis, S. Kraus, A.
  L\'eger, L. Leedj\""arv, T. Lichtenberg, J. Lillo-Box, H. Linz, R. Liseau, J.
  Loicq, V. Mahendra, F. Malbet, J. Mathew, B. Mennesson, M.R. Meyer, L.
  Mishra, K. Molaverdikhani, L. Noack, A.V. Oza, E. Pall\'e, H. Parviainen, A.
  Quirrenbach, H. Rauer, I. Ribas, M. Rice, A. Romagnolo, S. Rugheimer, E.W.
  Schwieterman, E. Serabyn, S. Sharma, K.G. Stassun, J. Szul\'agyi, H.S. Wang,
  F. Wunderlich, M.C. Wyatt and the LIFE collaboration","Large Interferometer For Exoplanets (LIFE): I. Improved exoplanet
  detection yield estimates for a large mid-infrared space-interferometer
  mission","Accepted for publication by A&A - some typos corrected and
  affiliations updated; 14 pages main text (incl. 14 figures); first paper in
  the LIFE paper series; papers II (arXiv:2203.00471) and III
  (arXiv:2112.02054) are also available","A&A 664, A21 (2022)","10.1051/0004-6361/202140366",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  One of the long-term goals of exoplanet science is the atmospheric
characterization of dozens of small exoplanets in order to understand their
diversity and search for habitable worlds and potential biosignatures.
Achieving this goal requires a space mission of sufficient scale. We seek to
quantify the exoplanet detection performance of a space-based mid-infrared
nulling interferometer that measures the thermal emission of exoplanets. For
this, we have developed an instrument simulator that considers all major
astrophysical noise sources and coupled it with Monte Carlo simulations of a
synthetic exoplanet population around main-sequence stars within 20 pc. This
allows us to quantify the number (and types) of exoplanets that our mission
concept could detect over a certain time period. Two different scenarios to
distribute the observing time among the stellar targets are discussed and
different apertures sizes and wavelength ranges are considered. Within a
2.5-year initial search phase, an interferometer consisting of four 2 m
apertures with a total instrument throughput of 5% covering a wavelength range
between 4 and 18.5 $\mu$m could detect up to ~550 exoplanets with radii between
0.5 and 6 R$_\oplus$ with an integrated SNR$\ge$7. At least ~160 of the
detected exoplanets have radii $\le$1.5 R$_\oplus$. Depending on the observing
scenario, ~25-45 rocky exoplanets (objects with radii between 0.5 and 1.5
$_{\oplus}$) orbiting within the empirical habitable zone (eHZ) of their host
stars are among the detections. With an aperture size of 3.5 m, the total
number of detections can increase to up to ~770, including ~60-80 rocky, eHZ
planets. With 1 m aperture size, the maximum detection yield is ~315
exoplanets, including $\le$20 rocky, eHZ planets. In terms of predicted
detection yield, such a mission can compete with large single-aperture
reflected light missions. (abridged)
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:59:31 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 14:28:17 GMT""},{""version"":""v3"",""created"":""Fri, 8 Apr 2022 15:45:51 GMT""},{""version"":""v4"",""created"":""Wed, 20 Apr 2022 10:03:23 GMT""}]","2022-08-10"
"2101.07501","Mohamed Kamel Riahi Dr.","M. K. Riahi, M. Ali, Y. Addad and E. Abu-Nada","Combined Newton-Raphson and Streamlines-Upwind Petrov-Galerkin
  iterations for nano-particles transport in buoyancy driven flow","26 pages, 41 figures",,,,"physics.flu-dyn cs.CE cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The present study deals with the finite element discretization of nanofluid
convective transport in an enclosure with variable properties. We study the
Buongiorno model, which couples the Navier-Stokes equations for the base fluid,
an advective-diffusion equation for the heat transfer, and an advection
dominated nanoparticle fraction concentration subject to thermophoresis and
Brownian motion forces. We develop an iterative numerical scheme that combines
Newton's method (dedicated to the resolution of the momentum and energy
equations) with the transport equation that governs the nanoparticles
concentration in the enclosure. We show that Stream Upwind Petrov-Galerkin
regularization approach is required to solve properly the ill-posed Buongiorno
transport model being tackled as a variational problem under mean value
constraint. Non-trivial numerical computations are reported to show the
effectiveness of our proposed numerical approach in its ability to provide
reasonably good agreement with the experimental results available in the
literature. The numerical experiments demonstrate that by accounting for only
the thermophoresis and Brownian motion forces in the concentration transport
equation, the model is not able to reproduce the heat transfer impairment due
to the presence of suspended nanoparticles in the base fluid. It reveals,
however, the significant role that these two terms play in the vicinity of the
hot and cold walls.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:10:31 GMT""}]","2021-01-27"
"2101.07502","Hangmei Rao","Hangmei Rao, Sa Xiao, Shihao Yan, Jianquan Wang and Wanbin Tang","UAV-Enabled Cooperative Jamming for Covert Communications",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work employs an unmanned aerial vehicle (UAV) as a jammer to aid a
covert communication from a transmitter Alice to a receiver Bob, where the UAV
transmits artificial noise (AN) with random power to deliberately create
interference to a warden Willie. In the considered system, the UAV's trajectory
is critical to the covert communication performance, since the AN transmitted
by the UAV also generates interference to Bob. To maximize the system
performance, we formulate an optimization problem to jointly design the UAV's
trajectory and Alice's transmit power. The formulated optimization problem is
non-convex and is normally solved by a conventional iterative (CI) method,
which requires multiple approximations based on Taylor expansions and an
initialization on the UAV's trajectory. In order to eliminate these
requirements, this work, for the first time, develops a geometric (GM) method
to solve the optimization problem. By analyzing the covertness constraint, the
GM method decouples the joint optimization into optimizing the UAV's trajectory
and Alice's transmit power separately. Our examination shows that the GM method
can significantly outperform the CI method in terms of achieving a higher
average covert rate and the complexity of the GM method is lower than that of
the CI method.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:16:26 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 17:50:07 GMT""}]","2022-02-28"
"2101.07503","Weilu Gao","Weilu Gao, Davoud Adinehloo, Ali Mojibpour, Yohei Yomogida, Atsushi
  Hirano, Takeshi Tanaka, Hiromichi Kataura, Ming Zheng, Vasili Perebeinos,
  Junichiro Kono","Band Structure Dependent Electronic Localization in Macroscopic Films of
  Single-Chirality Single-Wall Carbon Nanotubes","4 figures, 1 table, 25 pages","Carbon 183, 774 (2021)","10.1016/j.carbon.2021.07.057",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Significant understanding has been achieved over the last few decades
regarding chirality-dependent properties of single-wall carbon nanotubes
(SWCNTs), primarily through single-tube studies. However, macroscopic
manifestations of chirality dependence have been limited, especially in
electronic transport, despite the fact that such distinct behaviors are needed
for many applications of SWCNT-based devices. In addition, developing reliable
transport theory is challenging since a description of localization phenomena
in an assembly of nanoobjects requires precise knowledge of disorder on
multiple spatial scales, particularly if the ensemble is heterogeneous. Here,
we report an observation of pronounced chirality-dependent electronic
localization in temperature and magnetic field dependent conductivity
measurements on macroscopic films of single-chirality SWCNTs. The samples
included large-gap semiconducting (6,5) and (10,3) films, narrow-gap
semiconducting (7,4) and (8,5) films, and armchair metallic (6,6) films.
Experimental data and theoretical calculations revealed Mott
variable-range-hopping dominated transport in all samples, while localization
lengths fall into three distinct categories depending on their band gaps.
Armchair films have the largest localization length. Our detailed analyses on
electronic transport properties of single-chirality SWCNT films provide
significant new insight into electronic transport in ensembles of nanoobjects,
offering foundations for designing and deploying macroscopic SWCNT solid-state
devices.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:26:15 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 17:31:41 GMT""},{""version"":""v3"",""created"":""Mon, 20 Sep 2021 22:21:44 GMT""}]","2021-09-22"
"2101.07504","Sergey Troshin","S.M. Troshin, N.E. Tyurin","Central elastic scattering","13 pages, 2 figures, revised version","Phys. Lett. B 816(2021)136186","10.1016/j.physletb.2021.136186",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We comment on phase selection of the scattering amplitude, emphasizing that
the elastic overlap function should have a central impact parameter profile at
high energies and highlighting the role of the reflective scattering mode at
the LHC energies.
  Emerging problems with the use of peripheral impact parameter dependence of
the elastic overlap function are explicitly indicated. Their solution is an
elimination of the phases connected to peripheral form of the elastic overlap
function. Contrary, we adhere to a relative peripheral form of the {\it
inelastic} overlap function with an additional new feature of a maximum at
nonzero value of the impact parameter at the highest energies.
Phenomenologically, the dynamics of hadron scattering is motivated by a hadron
structure with a hard central core presence.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:27:48 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 07:40:32 GMT""},{""version"":""v3"",""created"":""Thu, 4 Mar 2021 12:18:57 GMT""}]","2021-03-10"
"2101.07505","Kurando Baba","Kurando Baba and Kenro Furutani","Calabi-Yau structure and Bargmann type transformation on the Cayley
  projective plane","47 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our purpose is to show the existence of a Calabi-Yau structure on the
punctured cotangent bundle $T^{*}_{0}(P^2\mathbb{O})$ of the Cayley projective
plane $P^{2}\mathbb{O}$ and to construct a Bargmann type transformation from a
space of holomorphic functions on $T^{*}_{0}(P^2\mathbb{O})$ to $L_{2}$-space
on $P^{2}\mathbb{O}$. The space of holomorphic functions corresponds to the
Fock space in the case of the original Bargmann transformation. A K\""ahler
structure on $T^{*}_{0}(P^{2}\mathbb{O})$ was shown by identifying it with a
quadrics in the complex space $\mathbb{C}^{27}\backslash\{0\}$ and the natural
symplectic form of the cotangent bundle $T^{*}_{0}(P^2\mathbb{O})$ is expressed
as a K\""ahler form. Our method to construct the transformation is the pairing
of polarizations, one is the natural Lagrangian foliation given by the
projection map ${\bf q}:T^{*}_{0}(P^2\mathbb{O})\longrightarrow
P^{2}\mathbb{O}$ and the polarization given by the K\""ahler structure.
  The transformation gives a quantization of the geodesic flow in terms of one
parameter group of elliptic Fourier integral operators whose canonical
relations are defined by the graph of the geodesic flow action at each time. It
turn out that for the Cayley projective plane the results are not same with
other cases of the original Bargmann transformation for Euclidean space,
spheres and other projective spaces.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:32:31 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 06:16:15 GMT""}]","2021-03-11"
"2101.07506","Charles Vial","Jeff Achter and Sebastian Casalaina-Martin and Charles Vial","The Walker Abel-Jacobi map descends","17 pages","Mathematische Zeitschrift (2021)","10.1007/s00209-021-02833-4",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a complex projective manifold, Walker has defined a regular homomorphism
lifting Griffiths' Abel-Jacobi map on algebraically trivial cycle classes to a
complex abelian variety, which admits a finite homomorphism to the Griffiths
intermediate Jacobian. Recently Suzuki gave an alternate, Hodge-theoretic,
construction of this Walker Abel-Jacobi map. We provide a third construction
based on a general lifting property for surjective regular homomorphisms, and
prove that the Walker Abel-Jacobi map descends canonically to any field of
definition of the complex projective manifold. In addition, we determine the
image of the l-adic Bloch map restricted to algebraically trivial cycle classes
in terms of the coniveau filtration.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:32:38 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 11:17:12 GMT""}]","2021-09-06"
"2101.07507","Shih-Yu Chen","Shih-Yu Chen","On Deligne's conjecture for symmetric fourth $L$-functions of Hilbert
  modular forms","to be published in Advances in Mathematics. arXiv admin note: text
  overlap with arXiv:2012.00625",,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We prove an automorphic analogue of Deligne's conjecture for symmetric fourth
$L$-functions of Hilbert modular forms. We extend the result of Morimoto based
on generalization and refinement of the results of Grobner and Lin to
cohomological irreducible essentially conjugate self-dual cuspidal automorphic
representations of ${\rm GL}_2$ and ${\rm GL}_3$ over CM-fields.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:36:14 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jan 2023 03:36:11 GMT""}]","2023-01-04"
"2101.07508","Francesco Marino","Marzena Ciszak and Francesco Marino","Acoustic black-hole bombs and scalar clouds in a photon-fluid model","11 pages, 5 figures","Phys. Rev. D 103, 045004 (2021)","10.1103/PhysRevD.103.045004",,"gr-qc cond-mat.quant-gas physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive bosonic fields in the background of a Kerr black hole can either
trigger superradiant instabilities (black-hole bombs) or form equilibrium
configurations corresponding to pure bound states, known as stationary scalar
clouds. Here, similar phenomena are shown to emerge in the fluctuation dynamics
of a rotating photon-fluid model. In the presence of suitable vortex flows, the
density fluctuations are governed by the massive Klein-Gordon equation on a
(2+1) curved spacetime, possessing an ergoregion and an event horizon. We
report on superradiant instabilities originating from quasi-bound phonon states
trapped by the vortex background and, remarkably, on the existence of
stationary modes in synchronous rotation with the horizon. These represent the
acoustic counterpart of astrophysical scalar clouds. Our system offers a
promising platform for analogue gravity experiments on superradiant
instabilities of massive bosons and black-hole-field equilibrium
configurations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:36:59 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 12:33:14 GMT""}]","2021-02-10"
"2101.07509","Wolfgang H\""ohl","Wolfgang H\""ohl","COVID-19 and Digital Transformation -- Developing an Open Experimental
  Testbed for Sustainable and Innovative Environments (ETSIE) using Fuzzy
  Cognitive Maps","21 pages, 11 figures and 17 tables; keywords: soft computing; fuzzy
  cognitive maps; digital transformation; COVID-19; decision making;
  sustainability; integrated world system modeling",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper sketches a new approach using Fuzzy Cognitive Maps (FCMs) to
operably map and simulate digital transformation in architecture and urban
planning. Today these processes are poorly understood. Many current studies on
digital transformation are only treating questions of economic efficiency.
Sustainability and social impact only play a minor role. Decisive definitions,
concepts and terms stay unclear. Therefore this paper develops an open
experimental testbed for sustainable and innovative environments (ETSIE) for
three different digital transformation scenarios using FCMs. A traditional
growth-oriented scenario, a COVID-19 scenario and an innovative and sustainable
COVID-19 scenario are modeled and tested. All three scenarios have the same
number of components, connections and the same driver components. Only the
initial state vectors are different and the internal correlations are weighted
differently. This allows for comparing all three scenarios on an equal basis.
The mental modeler software is used (Gray et al. 2013). This paper presents one
of the first applications of FCMs in the context of digital transformation. It
is shown, that the traditional growth-oriented scenario is structurally very
similar to the current COVID-19 scenario. The current pandemic is able to
accelerate digital transformation to a certain extent. But the pandemic does
not guarantee for a distinct sustainable and innovative future development.
Only by changing the initial state vectors and the weights of the connections
an innovative and sustainable turnaround in a third scenario becomes possible.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:37:54 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 11:28:55 GMT""}]","2021-01-21"
"2101.07510","Eva Viehmann","Eva Viehmann","On Newton strata in the $B_{dR}^+$-Grassmannian","33 pages, final version, to appear in Duke Math. J",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study parabolic reductions and Newton points of G-bundles on the
Fargues-Fontaine curve and the Newton stratification on the
$B_{dR}^+$-Grassmannian for any reductive group G. Let $Bun_G$ be the stack of
G-bundles on the Fargues-Fontaine curve. Our first main result is to show that
under the identification of the points of $Bun_G$ with Kottwitz's set B(G), the
closure relations on the topological space $|Bun_G|$ coincide with the opposite
of the usual partial order on B(G). Furthermore, we prove that every
non-Hodge-Newton decomposable Newton stratum in a minuscule affine Schubert
cell in the $B_{dR}^+$-Grassmannian intersects the weakly admissible locus,
proving a conjecture of Chen. On the way, we study several interesting
properties of parabolic reductions of $G$-bundles, and determine which Newton
strata have classical points.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:39:22 GMT""},{""version"":""v2"",""created"":""Sat, 4 Mar 2023 19:36:42 GMT""}]","2023-03-07"
"2101.07511","Adnan Qayyum","Adnan Qayyum, Kashif Ahmad, Muhammad Ahtazaz Ahsan, Ala Al-Fuqaha, and
  Junaid Qadir","Collaborative Federated Learning For Healthcare: Multi-Modal COVID-19
  Diagnosis at the Edge","preprint version",,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  Despite significant improvements over the last few years, cloud-based
healthcare applications continue to suffer from poor adoption due to their
limitations in meeting stringent security, privacy, and quality of service
requirements (such as low latency). The edge computing trend, along with
techniques for distributed machine learning such as federated learning, have
gained popularity as a viable solution in such settings. In this paper, we
leverage the capabilities of edge computing in medicine by analyzing and
evaluating the potential of intelligent processing of clinical visual data at
the edge allowing the remote healthcare centers, lacking advanced diagnostic
facilities, to benefit from the multi-modal data securely. To this aim, we
utilize the emerging concept of clustered federated learning (CFL) for an
automatic diagnosis of COVID-19. Such an automated system can help reduce the
burden on healthcare systems across the world that has been under a lot of
stress since the COVID-19 pandemic emerged in late 2019. We evaluate the
performance of the proposed framework under different experimental setups on
two benchmark datasets. Promising results are obtained on both datasets
resulting in comparable results against the central baseline where the
specialized models (i.e., each on a specific type of COVID-19 imagery) are
trained with central data, and improvements of 16\% and 11\% in overall
F1-Scores have been achieved over the multi-modal model trained in the
conventional Federated Learning setup on X-ray and Ultrasound datasets,
respectively. We also discuss in detail the associated challenges,
technologies, tools, and techniques available for deploying ML at the edge in
such privacy and delay-sensitive applications.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:40:59 GMT""}]","2021-01-20"
"2101.07512","Zhaoxia Yin","Jie Wang, Zhaoxia Yin, Jing Jiang, and Yang Du","Attention-Guided Black-box Adversarial Attacks with Large-Scale
  Multiobjective Evolutionary Optimization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fooling deep neural networks (DNNs) with the black-box optimization has
become a popular adversarial attack fashion, as the structural prior knowledge
of DNNs is always unknown. Nevertheless, recent black-box adversarial attacks
may struggle to balance their attack ability and visual quality of the
generated adversarial examples (AEs) in tackling high-resolution images. In
this paper, we propose an attention-guided black-box adversarial attack based
on the large-scale multiobjective evolutionary optimization, termed as LMOA. By
considering the spatial semantic information of images, we firstly take
advantage of the attention map to determine the perturbed pixels. Instead of
attacking the entire image, reducing the perturbed pixels with the attention
mechanism can help to avoid the notorious curse of dimensionality and thereby
improves the performance of attacking. Secondly, a large-scale multiobjective
evolutionary algorithm is employed to traverse the reduced pixels in the
salient region. Benefiting from its characteristics, the generated AEs have the
potential to fool target DNNs while being imperceptible by the human vision.
Extensive experimental results have verified the effectiveness of the proposed
LMOA on the ImageNet dataset. More importantly, it is more competitive to
generate high-resolution AEs with better visual quality compared with the
existing black-box adversarial attacks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:48:44 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 01:53:58 GMT""},{""version"":""v3"",""created"":""Thu, 13 Jan 2022 16:58:56 GMT""}]","2022-01-14"
"2101.07513","Jiaming Qi","Jiaming Qi, Guangfu Ma, Peng Zhou, Haibo Zhang, Yueyong Lyu, David
  Navarro-Alarcon","Towards Latent Space Based Manipulation of Elastic Rods using
  Autoencoder Models and Robust Centerline Extractions",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The automatic shape control of deformable objects is a challenging (and
currently hot) manipulation problem due to their high-dimensional geometric
features and complex physical properties. In this study, a new methodology to
manipulate elastic rods automatically into 2D desired shapes is presented. An
efficient vision-based controller that uses a deep autoencoder network is
designed to compute a compact representation of the object's
infinite-dimensional shape. An online algorithm that approximates the
sensorimotor mapping between the robot's configuration and the object's shape
features is used to deal with the latter's (typically unknown) mechanical
properties. The proposed approach computes the rod's centerline from raw visual
data in real-time by introducing an adaptive algorithm on the basis of a
self-organizing network. Its effectiveness is thoroughly validated with
simulations and experiments.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:49:07 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 06:24:38 GMT""},{""version"":""v3"",""created"":""Fri, 9 Apr 2021 11:14:13 GMT""}]","2021-04-12"
"2101.07514","H. Antia","H. M. Antia, P. C. Agrawal, Dhiraj Dedhia, Tilak Katoch, R. K.
  Manchanda, Ranjeev Misra, Kallol Mukerjee, Mayukh Pahari, Jayashree Roy, P.
  Shah, J. S. Yadav","Large Area X-ray Proportional Counter (LAXPC) in Orbit Performance :
  Calibration, background, analysis software","Accepted for publication in JAA",,"10.1007/s12036-021-09712-8",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Large Area X-ray Proportional Counter (LAXPC) instrument on-board
AstroSat has three nominally identical detectors for timing and spectral
studies in the energy range of 3--80 keV. The performance of these detectors
during the five years after the launch of AstroSat is described. Currently,
only one of the detector is working nominally. The variation in pressure,
energy resolution, gain and background with time are discussed. The
capabilities and limitations of the instrument are described. A brief account
of available analysis software is also provided.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:57:34 GMT""}]","2021-06-23"
"2101.07515","Huan Chen Dr","Ting-Ting Sun, Zi-Yue Zheng, Huan Chen, G. Fiorella Burgio, and
  Hans-Josef Schulze","The equation of state and radial oscillations of neutron stars","9 pages, 7 figures","Phys. Rev. D 103, 103003 (2021)","10.1103/PhysRevD.103.103003",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  We investigate radial oscillations of pure neutron stars and hybrid stars,
employing equations of state of nuclear matter from Brueckner-Hartree-Fock
theory, and of quark matter from the Dyson-Schwinger quark model, performing a
Gibbs construction for the mixed phase in hybrid stars. We calculate the
eigenfrequencies and corresponding oscillation functions. Our results for the
zero points of the first-order radial oscillation frequencies give the maximum
mass of stable neutron stars, consistent with the common criterion
$dM/d\rho_c=0$. Possible observations of the radial oscillation frequencies
could help to learn more about the equation of state, predict the maximum mass
of neutron stars more precisely, and indicate the presence of quark matter.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:59:58 GMT""}]","2021-05-12"
"2101.07516","Nazmi Burak Budanur","Elena Marensi, G\""okhan Yaln{\i}z, Bj\""orn Hof and Nazmi Burak Budanur","Symmetry-reduced Dynamic Mode Decomposition of Near-wall Turbulence","22 pages, 10 figures",,"10.1017/jfm.2022.1001",,"physics.flu-dyn nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven dimensionality reduction methods such as proper orthogonal
decomposition (POD) and dynamic mode decomposition (DMD) have proven to be
useful for exploring complex phenomena within fluid dynamics and beyond. A
well-known challenge for these techniques is posed by the continuous
symmetries, e.g. translations and rotations, of the system under consideration
as drifts in the data dominate the modal expansions without providing an
insight into the dynamics of the problem. In the present study, we address this
issue for fluid flows in rectangular channels by formulating a continuous
symmetry reduction method that eliminates the translations in the streamwise
and spanwise directions simultaneously. We demonstrate our method by computing
the symmetry-reduced dynamic mode decomposition (SRDMD) of sliding windows of
data obtained from the transitional plane-Couette and turbulent
plane-Poiseuille flow simulations. In the former setting, SRDMD captures the
dynamics in the vicinity of the invariant solutions with translation
symmetries, i.e. travelling waves and relative periodic orbits, whereas in the
latter, our calculations reveal episodes of turbulent time evolution that can
be approximated by a low-dimensional linear expansion.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:01:08 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 18:46:51 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 13:28:01 GMT""},{""version"":""v4"",""created"":""Mon, 28 Nov 2022 16:23:43 GMT""}]","2022-12-27"
"2101.07517","Inga Abel","Inga Abel, Helmut Graeb","FUBOCO: Structure Synthesis of Basic Op-Amps by FUnctional BlOck
  COmposition","This work has been submitted to ACM for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a method to automatically synthesize the structure of an
operational amplifier. It is positioned between approaches with fixed design
plans and a small search space of structures and approaches with generic
structural production rules and a large search space with technically
impractical structures. The presented approach develops a hierarchical
composition graph based on functional blocks that spans a search space of
thousands of technically meaningful structure variants for single-output,
fully-differential and complementary operational amplifiers. The search
algorithm is a combined heuristic and enumerative process. The evaluation is
based on circuit sizing with a library of behavioral equations of functional
blocks. Formalizing the knowledge of functional blocks in op-amps for
structural synthesis and sizing inherently reduces the search space and lessens
the number of created topologies not fulfilling the specifications.
Experimental results for the three op-amp classes are presented. An outlook how
this method can be extended to multi-stage op-amps is given.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:01:12 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 11:15:22 GMT""}]","2021-09-27"
"2101.07518","Fu-Jen Tsai","Fu-Jen Tsai, Yan-Tsung Peng, Yen-Yu Lin, Chung-Chi Tsai, and Chia-Wen
  Lin","BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring","TIP 2022, Code: https://github.com/pp00704831/BANet",,"10.1109/TIP.2022.3216216",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image motion blur results from a combination of object motions and camera
shakes, and such blurring effect is generally directional and non-uniform.
Previous research attempted to solve non-uniform blurs using self-recurrent
multiscale, multi-patch, or multi-temporal architectures with self-attention to
obtain decent results. However, using self-recurrent frameworks typically lead
to a longer inference time, while inter-pixel or inter-channel self-attention
may cause excessive memory usage. This paper proposes a Blur-aware Attention
Network (BANet), that accomplishes accurate and efficient deblurring via a
single forward pass. Our BANet utilizes region-based self-attention with
multi-kernel strip pooling to disentangle blur patterns of different magnitudes
and orientations and cascaded parallel dilated convolution to aggregate
multi-scale content features. Extensive experimental results on the GoPro and
RealBlur benchmarks demonstrate that the proposed BANet performs favorably
against the state-of-the-arts in blurred image restoration and can provide
deblurred results in real-time.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:03:40 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 03:40:12 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jul 2022 08:57:44 GMT""},{""version"":""v4"",""created"":""Tue, 25 Oct 2022 12:00:50 GMT""}]","2022-11-23"
"2101.07519","Joachim Arts","Willem van Jaarsveld, Joachim Arts","Projected Inventory Level Policies for Lost Sales Inventory Systems:
  Asymptotic Optimality in Two Regimes",,,,,"math.PR math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the canonical periodic review lost sales inventory system with
positive lead-times and stochastic i.i.d. demand under the average cost
criterion. We introduce a new policy that places orders such that the expected
inventory level at the time of arrival of an order is at a fixed level and call
it the Projected Inventory Level (PIL) policy. We prove that this policy has a
cost-rate superior to the equivalent system where excess demand is back-ordered
instead of lost and is therefore asymptotically optimal as the cost of losing a
sale approaches infinity under mild distributional assumptions. We further show
that this policy dominates the constant order policy for any finite lead-time
and is therefore asymptotically optimal as the lead-time approaches infinity
for the case of exponentially distributed demand per period. Numerical results
show this policy also performs superior relative to other policies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:07:07 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 10:57:49 GMT""},{""version"":""v3"",""created"":""Sun, 30 Oct 2022 20:20:25 GMT""}]","2022-11-01"
"2101.07520","Saurabh Verma","S. Verma","Hausdorff dimension and infinitesimal similitudes on complete metric
  spaces","20 pages",,,,"math.DS math.MG math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we answer a question of Nussbaum, Priyadarshi, and Lunel
[Positive operators and Hausdorff dimension of invariant sets, Trans. Amer.
Math. Soc. 364(2) (2012) 1029-1066.]. We also show that the Hausdorff dimension
and box dimension of the attractor generated by a finite set of contractive
infinitesimal similitudes are the same. Further, we extend many results of
dimension theory to complete metric spaces. In the last part, we fill the gaps
in the proofs of some articles, which are related to the dimension theory, and
hint at some possible improvements in the recent papers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:07:41 GMT""}]","2021-01-20"
"2101.07521","Lorenzo Brandolese","Lorenzo Brandolese (ICJ), Takahiro Okabe","Annihilation of slowly-decaying terms of Navier-Stokes flows by external
  forcing",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this paper is to provide an algorithm that, for any sufficiently
localised, divergence-free small initial data, explicitly constructs a
localised external force leading to a rapidly dissipative solutions of the
Navier-Stokes equations $\mathbb{R}^n$: namely, the energy decay rate of the
flow will be forced to satisfy $\|u(t)\|_2^2 = o(t^{-(n+2)/2})$ as $t \to
\infty$, which is beyond the usual optimal rate. An important feature of our
construction is that this force can always be taken compactly supported in
space-time, and its profile arbitrarily prescribed up to a spatial rescaling.
Since the forcing term vanishes after a finite time interval, our result
suggests that nontrivial interactions between the linear and nonlinear parts
occur, annihilating all the slowly decaying terms contained in Miyakawa and
Schonbek's asymptotic profiles.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:12:03 GMT""}]","2021-01-20"
"2101.07522","Sungkyun Choi","Sungkyun Choi, Heung-Sik Kim, Hun-Ho Kim, Aleksandra Krajewska, Gideok
  Kim, Matteo Minola, Tomohiro Takayama, Hidenori Takagi, Kristjan Haule, David
  Vanderbilt, and Bernhard Keimer","Lattice dynamics and structural transition of the hyperhoneycomb iridate
  $\beta$-Li$_2$IrO$_3$ investigated by high-pressure Raman scattering","16 pages, 7 figures, 5 tables, Supplemental Material included",,"10.1103/PhysRevB.101.054102",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a polarized Raman scattering study of the lattice dynamics of
$\beta$-Li$_2$IrO$_3$ under hydrostatic pressures up to 7.62 GPa. At ambient
pressure, $\beta$-Li$_2$IrO$_3$ exhibits the hyperhoneycomb crystal structure
and a magnetically ordered state of spin-orbit entangled Jeff = 1/2 moments
that is strongly influenced by bond-directional (Kitaev) exchange interactions.
At a critical pressure of ~ 4.1 GPa, the phonon spectrum changes abruptly
consistent with the reported structural transition into a monoclinic, dimerized
phase. A comparison to the phonon spectra obtained from density functional
calculations shows reasonable overall agreement. The calculations also indicate
that the high-pressure phase is a nonmagnetic insulator driven by the formation
of Ir-Ir dimer bonds. Our results thus indicate a strong sensitivity of the
electronic properties of $\beta$-Li$_2$IrO$_3$ to the pressure-induced
structural transition.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:12:40 GMT""}]","2021-01-20"
"2101.07523","Nicolas Becu","Ahmed Laatabi, Nicolas Becu (LIENSs), Nicolas Marilleau (UMMISCO),
  C\'ecilia Pignon-Mussaud (LIENSs), Marion Amalric (CITERES), X. Bertin
  (LIENSs), Brice Anselme (PRODIG), Elise Beck (PACTE)","Mapping and Describing Geospatial Data to Generalize Complex Mapping and
  Describing Geospatial Data to Generalize Complex Models: The Case of
  LittoSIM-GEN Models",,"International Journal of Geospatial and Environmental Research,
  KAGES, 2020",,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For some scientific questions, empirical data are essential to develop
reliable simulation models. These data usually come from different sources with
diverse and heterogeneous formats. The design of complex data-driven models is
often shaped by the structure of the data available in research projects.
Hence, applying such models to other case studies requires either to get
similar data or to transform new data to fit the model inputs. It is the case
of agent-based models (ABMs) that use advanced data structures such as
Geographic Information Systems data. We faced this problem in the LittoSIM-GEN
project when generalizing our participatory flooding model (LittoSIM) to new
territories. From this experience, we provide a mapping approach to structure,
describe, and automatize the integration of geospatial data into ABMs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:16:05 GMT""}]","2021-01-20"
"2101.07524","Jiaheng Wei","Jiaheng Wei, Minghao Liu, Jiahao Luo, Andrew Zhu, James Davis, and
  Yang Liu","DuelGAN: A Duel Between Two Discriminators Stabilizes the GAN Training","Under Review",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce DuelGAN, a generative adversarial network (GAN)
solution to improve the stability of the generated samples and to mitigate mode
collapse. Built upon the Vanilla GAN's two-player game between the
discriminator $D_1$ and the generator $G$, we introduce a peer discriminator
$D_2$ to the min-max game. Similar to previous work using two discriminators,
the first role of both $D_1$, $D_2$ is to distinguish between generated samples
and real ones, while the generator tries to generate high-quality samples which
are able to fool both discriminators. Different from existing methods, we
introduce another game between $D_1$ and $D_2$ to discourage their agreement
and therefore increase the level of diversity of the generated samples. This
property alleviates the issue of early mode collapse by preventing $D_1$ and
$D_2$ from converging too fast. We provide theoretical analysis for the
equilibrium of the min-max game formed among $G, D_1, D_2$. We offer
convergence behavior of DuelGAN as well as stability of the min-max game. It's
worth mentioning that DuelGAN operates in the unsupervised setting, and the
duel between $D_1$ and $D_2$ does not need any label supervision. Experiments
results on a synthetic dataset and on real-world image datasets (MNIST, Fashion
MNIST, CIFAR-10, STL-10, CelebA, VGG, and FFHQ) demonstrate that DuelGAN
outperforms competitive baseline work in generating diverse and high-quality
samples, while only introduces negligible computation cost.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:25:23 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 04:06:20 GMT""},{""version"":""v3"",""created"":""Sun, 20 Mar 2022 08:13:45 GMT""}]","2022-03-22"
"2101.07525","Zeming Li","Zeming Li, Songtao Liu, Jian Sun","Momentum^2 Teacher: Momentum Teacher with Momentum Statistics for
  Self-Supervised Learning","11 pages, Tech report",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a novel approach, Momentum$^2$ Teacher, for
student-teacher based self-supervised learning. The approach performs momentum
update on both network weights and batch normalization (BN) statistics. The
teacher's weight is a momentum update of the student, and the teacher's BN
statistics is a momentum update of those in history. The Momentum$^2$ Teacher
is simple and efficient. It can achieve the state of the art results (74.5\%)
under ImageNet linear evaluation protocol using small-batch size(\eg, 128),
without requiring large-batch training on special hardware like TPU or
inefficient across GPU operation (\eg, shuffling BN, synced BN). Our
implementation and pre-trained models will be given on
GitHub\footnote{https://github.com/zengarden/momentum2-teacher}.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:27:03 GMT""}]","2021-01-20"
"2101.07526","Ragnhild Laursen","Ragnhild Laursen and Asger Hobolth","A sampling algorithm to compute the set of feasible solutions for
  non-negative matrix factorization with an arbitrary rank","18 pages, 8 figures, 1 algorithm",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Non-negative Matrix Factorization (NMF) is a useful method to extract
features from multivariate data, but an important and sometimes neglected
concern is that NMF can result in non-unique solutions. Often, there exist a
Set of Feasible Solutions (SFS), which makes it more difficult to interpret the
factorization. This problem is especially ignored in cancer genomics, where NMF
is used to infer information about the mutational processes present in the
evolution of cancer. In this paper the extent of non-uniqueness is investigated
for two mutational counts data, and a new sampling algorithm, that can find the
SFS, is introduced. Our sampling algorithm is easy to implement and applies to
an arbitrary rank of NMF. This is in contrast to state of the art, where the
NMF rank must be smaller than or equal to four. For lower ranks we show that
our algorithm performs similarly to the polygon inflation algorithm that is
developed in relations to chemometrics. Furthermore, we show how the size of
the SFS can have a high influence on the appearing variability of a solution.
Our sampling algorithm is implemented in an R package \textbf{SFS}
(\url{https://github.com/ragnhildlaursen/SFS}).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:27:45 GMT""}]","2021-01-20"
"2101.07527","Xiangdong Zhang","Xiangdong Zhang, Gaoping Long and Yongge Ma","Loop quantum gravity and cosmological constant","6 pages, 1 figure; v2, accepted by PLB","Physics Letters B 823, (2021) 136770","10.1016/j.physletb.2021.136770",,"gr-qc astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  An one-parameter regularization freedom of the Hamiltonian constraint for
loop quantum gravity is analyzed. The corresponding spatially flat, homogenous
and isotropic model includes the two well-known models of loop quantum
cosmology as special cases. The quantum bounce nature is tenable in the
generalized cases. For positive value of the regularization parameter, the
effective Hamiltonian leads to an asymptotic de-Sitter branch of the Universe
connecting to the standard Friedmann branch by the quantum bounce. Remarkably,
by suitably choosing the value of the regularization parameter, the
observational cosmological constant can emerge at large volume limit from the
effect of quantum gravity, and the effective Newtonian constant satisfies the
experimental restrictions in the meantime.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:28:23 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 11:44:02 GMT""}]","2021-11-12"
"2101.07528","Edouard Oyallon","Louis Thiry (DI-ENS), Michael Arbel (UCL), Eugene Belilovsky (MILA),
  Edouard Oyallon (MLIA)","The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels
  Methods",,"International Conference on Learning Representation (ICLR 2021),
  2021, Vienna (online), Austria",,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent line of work showed that various forms of convolutional kernel
methods can be competitive with standard supervised deep convolutional networks
on datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while
being more amenable to theoretical analysis. In this work, we highlight the
importance of a data-dependent feature extraction step that is key to the
obtain good performance in convolutional kernel methods. This step typically
corresponds to a whitened dictionary of patches, and gives rise to a
data-driven convolutional kernel methods. We extensively study its effect,
demonstrating it is the key ingredient for high performance of these methods.
Specifically, we show that one of the simplest instances of such kernel
methods, based on a single layer of image patches followed by a linear
classifier is already obtaining classification accuracies on CIFAR-10 in the
same range as previous more sophisticated convolutional kernel methods. We
scale this method to the challenging ImageNet dataset, showing such a simple
approach can exceed all existing non-learned representation methods. This is a
new baseline for object recognition without representation learning methods,
that initiates the investigation of convolutional kernel models on ImageNet. We
conduct experiments to analyze the dictionary that we used, our ablations
showing they exhibit low-dimensional properties.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:30:58 GMT""}]","2021-01-20"
"2101.07529","Mattijs Baert","Mattijs Baert, Sam Leroux, Pieter Simoens","Intelligent Frame Selection as a Privacy-Friendlier Alternative to Face
  Recognition","accepted for AAAI 2021 Workshop on Privacy-Preserving Artificial
  Intelligence (PPAI-21)",,,,"cs.CV cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The widespread deployment of surveillance cameras for facial recognition
gives rise to many privacy concerns. This study proposes a privacy-friendly
alternative to large scale facial recognition. While there are multiple
techniques to preserve privacy, our work is based on the minimization principle
which implies minimizing the amount of collected personal data. Instead of
running facial recognition software on all video data, we propose to
automatically extract a high quality snapshot of each detected person without
revealing his or her identity. This snapshot is then encrypted and access is
only granted after legal authorization. We introduce a novel unsupervised face
image quality assessment method which is used to select the high quality
snapshots. For this, we train a variational autoencoder on high quality face
images from a publicly available dataset and use the reconstruction probability
as a metric to estimate the quality of each face crop. We experimentally
confirm that the reconstruction probability can be used as biometric quality
predictor. Unlike most previous studies, we do not rely on a manually defined
face quality metric as everything is learned from data. Our face quality
assessment method outperforms supervised, unsupervised and general image
quality assessment methods on the task of improving face verification
performance by rejecting low quality images. The effectiveness of the whole
system is validated qualitatively on still images and videos.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:31:42 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 13:29:00 GMT""}]","2021-01-28"
"2101.07530","Gabriele De Luca","G. De Luca, J. Spring, U. Bashir, M. Campanini, R. Totani, C.
  Dominguez, A. Zakharova, M. D\""obeli, T. Greber, M. D. Rossell, C.
  Piamonteze, M. Gibert","Robust ferromagnetism in insulating La$_2$NiMnO$_6$ thin films","15 pages, 4 figures","APL Materials 9, 081111 (2021)","10.1063/5.0055614",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The field of oxide spintronics can strongly benefit from the establishment of
robust ferromagnetic insulators with near room-temperature Curie temperature.
Here we investigate the structural, electronic, and magnetic properties of
atomically-precise epitaxially-strained thin films of the double perovskite
La$_2$NiMnO$_6$ (LNMO) grown by off-axis radio-frequency magnetron sputtering.
We find that the films retain both a strong insulating behavior and a bulk-like
Curie temperature in the order of 280 K, nearly independently from epitaxial
strain conditions. These results suggest a prospective implementation of LNMO
films in multi-layer device architectures where a high-temperature
ferromagnetic insulating state is a prerequisite.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:31:58 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 08:51:27 GMT""}]","2021-08-25"
"2101.07531","Prathmesh Vinze Mr.","Prathmesh M. Vinze, Akash Choudhary and S. Pushpavanam","Motion of an active particle in a linear concentration gradient",,,"10.1063/5.0043578",,"cond-mat.soft physics.app-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Janus particles self-propel by generating local tangential concentration
gradients along their surface. These gradients are present in a thin layer
whose thickness is small compared to the particle size. Chemical asymmetry
along the surface is a prerequisite to generate tangential chemical gradient,
which gives rise to diffusioosmotic flows in a thin region around the particle.
This results in an effective slip on the particle surface. This slip results in
the observed ""swimming"" motion of a freely suspended particle even in the
absence of externally imposed concentration gradients.Motivated by the
chemotactic behaviour of their biological counterparts(such as sperm cells,
neutrophils, macrophages, bacteria etc.), which sense and respond to external
chemical gradients, the current work aims at developing a theoretical framework
to study the motion of a Janus particle in an externally imposed linear
concentration gradient. The external gradient along with the self-generated
concentration gradient determines the swimming velocity and orientation of the
particle.The dominance of each of these effects is characterised by a
non-dimensional activity number A. The surface of Janus particle is modelled as
having a different activity and mobility coefficient on the two halves.Using
Lorentz Reciprocal theorem, an analytical expression for the rotational and
translational velocity is obtained. The analytical framework helps us divide
the parameter space of surface activity and mobility into four regions where
the particle exhibits different trajectories.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:35:03 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 13:05:05 GMT""}]","2021-03-31"
"2101.07532","Maria Thurow","Maria Thurow, Florian Dumpert, Burim Ramosaj, Markus Pauly","Goodness (of fit) of Imputation Accuracy: The GoodImpact Analysis",,,,,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In statistical survey analysis, (partial) non-responders are integral
elements during data acquisition. Treating missing values during data
preparation and data analysis is therefore a non-trivial underpinning. Focusing
on different data sets from the Federal Statistical Office of Germany
(DESTATIS), we investigate various imputation methods regarding their
imputation accuracy. Since the latter is not uniquely determined in theory and
practice, we study different measures for assessing imputation accuracy: Beyond
the most common measures, the normalized-root mean squared error (NRMSE) and
the proportion of false classification (PFC), we put a special focus on
(distribution) distance- and association measures for assessing imputation
accuracy. The aim is to deliver guidelines for correctly assessing
distributional accuracy after imputation. Our empirical findings indicate a
discrepancy between the NRMSE resp. PFC and distance measures. While the latter
measure distributional similarities, NRMSE and PFC focus on data
reproducibility. We realize that a low NRMSE or PFC seem not to imply lower
distributional discrepancies. Although several measures for assessing
distributional discrepancies exist, our results indicate that not all of them
are suitable for evaluating imputation-induced differences.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:35:15 GMT""}]","2021-01-20"
"2101.07533","Gilles Rosolen","Gilles Rosolen and Bjorn Maes","Strong multipolar transition enhancement with graphene nanoislands","21 pages and 8 pages supplementary information",,,,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the past half century, a major approximation was natural in the field
of light-matter interaction: the point-dipole model. It was assumed that the
wavelength is much larger than the size of the emitting atom or molecule, so
that the emitter can be described as a single or a collection of elementary
dipoles. As it is legitimate for visible light, the approximation does no
longer hold near plasmonic nanostructures, where the effective wavelength can
drop below 10 nm. In that case deviations arise from the approximate model.
First, the emitter spatial extent influences the far-field spectrum. Second,
high-order transitions beyond the dipolar ones are not forbidden anymore. Going
beyond the approximation requires intensive numerical efforts to compute the
photonic response over the spatial extent of the emitter, since the complete
Green's function is required. Here, we develop a general model that computes
the multipolar transition rates of a quantum emitter in a photonic environment,
by computing the Green's function through an eigenpermittivity modal expansion.
We apply the method on graphene nanoislands, and we demonstrate a local
breakdown of the selection rules, with quadrupolar transition rates becoming
100 times larger than dipolar ones.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:43:25 GMT""}]","2021-01-20"
"2101.07534","Federico Chiariotti","Siddharth Chandak, Federico Chiariotti, Petar Popovski","Hidden Markov Model-Based Encoding for Time-Correlated IoT Sources","Preprint version of the paper published in IEEE Communications
  Letters",,"10.1109/LCOMM.2020.3044210",,"cs.NI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As the use of Internet of Things (IoT) devices for monitoring purposes
becomes ubiquitous, the efficiency of sensor communication is a major issue for
the modern Internet. Channel coding is less efficient for extremely short
packets, and traditional techniques that rely on source compression require
extensive signaling or pre-existing knowledge of the source dynamics. In this
work, we propose an encoding and decoding scheme that learns source dynamics
online using a Hidden Markov Model (HMM), puncturing a short packet code to
outperform existing compression-based approaches. Our approach shows
significant performance improvements for sources that are highly correlated in
time, with no additional complexity on the sender side.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:45:27 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 11:45:48 GMT""}]","2021-01-21"
"2101.07535","Dan Li","Dacheng Chen, Dan Li, Xiuqin Xu, Ruizhi Yang, See-Kiong Ng","Electrocardiogram Classification and Visual Diagnosis of Atrial
  Fibrillation with DenseECG",,,,,"eess.SP cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Atrial Fibrillation (AF) is a common cardiac arrhythmia affecting a large
number of people around the world. If left undetected, it will develop into
chronic disability or even early mortality. However, patients who have this
problem can barely feel its presence, especially in its early stage. A
non-invasive, automatic, and effective detection method is therefore needed to
help early detection so that medical intervention can be implemented in time to
prevent its progression.
  Electrocardiogram (ECG), which records the electrical activities of the
heart, has been widely used for detecting the presence of AF. However, due to
the subtle patterns of AF, the performance of detection models have largely
depended on complicated data pre-processing and expertly engineered features.
In our work, we developed DenseECG, an end-to-end model based on 5 layers 1D
densely connected convolutional neural network. We trained our model using the
publicly available dataset from 2017 PhysioNet Computing in Cardiology(CinC)
Challenge containing 8528 single-lead ECG recordings of short-term heart
rhythms (9-61s). Our trained model was able to outperform the other
state-of-the-art AF detection models on this dataset without complicated data
pre-processing and expert-supervised feature engineering.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:45:46 GMT""}]","2021-01-20"
"2101.07536","Melvin Leok","Brian Tran and Melvin Leok","Multisymplectic Hamiltonian Variational Integrators","45 pages, 9 figures",,"10.1080/00207160.2021.1999427",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational integrators have traditionally been constructed from the
perspective of Lagrangian mechanics, but there have been recent efforts to
adopt discrete variational approaches to the symplectic discretization of
Hamiltonian mechanics using Hamiltonian variational integrators. In this paper,
we will extend these results to the setting of Hamiltonian multisymplectic
field theories. We demonstrate that one can use the notion of Type II
generating functionals for Hamiltonian partial differential equations as the
basis for systematically constructing Galerkin Hamiltonian variational
integrators that automatically satisfy a discrete multisymplectic conservation
law, and establish a discrete Noether's theorem for discretizations that are
invariant under a Lie group action on the discrete dual jet bundle. In
addition, we demonstrate that for spacetime tensor product discretizations, one
can recover the multisymplectic integrators of Bridges and Reich, and show that
a variational multisymplectic discretization of a Hamiltonian multisymplectic
field theory using spacetime tensor product Runge--Kutta discretizations is
well-defined if and only if the partitioned Runge--Kutta methods are symplectic
in space and time.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:47:48 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 04:13:36 GMT""}]","2022-02-10"
"2101.07537","Partha Pratim Deka","P. P. Deka, G. C. Dewangan, K. P. Singh and J. Postma","A pair of UV nuclei or a compact star forming region near the active
  nucleus in Mrk~766?",,,"10.1007/s12036-021-09695-6",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of a bright, compact ultraviolet source at a
projected separation of 1.1~kpc from the known active galactic nucleus (AGN) in
Mrk~766 based on Astrosat/UVIT observations. We perform radial profile analysis
and derive the UV flux almost free from the nearby contaminating sources. The
new source is about 2.5 and 5.6 times fainter than the AGN in the far and near
UV bands. The two sources appear as a pair of nuclei in Mrk~766. We investigate
the nature of the new source based on the UV flux ratio, X-ray and optical
emission. The new source is highly unlikely to be another accreting
supermassive black hole in Mrk~766 as it lacks X-ray emission. We find that the
UV/Optical flux of the new source measured at four different bands closely
follow the shape of the template spectrum of starburst galaxies. This strongly
suggests that the new source is a compact star-forming region.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:50:57 GMT""}]","2021-06-23"
"2101.07538","Zhaoxia Yin","Jie Wang, Zhaoxia Yin, Jin Tang, Jing Jiang, and Bin Luo","PICA: A Pixel Correlation-based Attentional Black-box Adversarial Attack",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The studies on black-box adversarial attacks have become increasingly
prevalent due to the intractable acquisition of the structural knowledge of
deep neural networks (DNNs). However, the performance of emerging attacks is
negatively impacted when fooling DNNs tailored for high-resolution images. One
of the explanations is that these methods usually focus on attacking the entire
image, regardless of its spatial semantic information, and thereby encounter
the notorious curse of dimensionality. To this end, we propose a pixel
correlation-based attentional black-box adversarial attack, termed as PICA.
Firstly, we take only one of every two neighboring pixels in the salient region
as the target by leveraging the attentional mechanism and pixel correlation of
images, such that the dimension of the black-box attack reduces. After that, a
general multiobjective evolutionary algorithm is employed to traverse the
reduced pixels and generate perturbations that are imperceptible by the human
vision. Extensive experimental results have verified the effectiveness of the
proposed PICA on the ImageNet dataset. More importantly, PICA is
computationally more efficient to generate high-resolution adversarial examples
compared with the existing black-box attacks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:53:52 GMT""}]","2021-01-20"
"2101.07539","Daniel Kaplan","Daniel Kaplan, Tobias Holder, Binghai Yan","Twisted photovoltaics at terahertz frequencies from momentum shift
  current","7 pages, with appendices. 4 figures. Close to published version","Phys. Rev. Research 4, 013209 (2022)","10.1103/PhysRevResearch.4.013209",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The bulk photovoltaic effect (BPVE) converts light into a coherent dc current
at zero bias, through what is commonly known as the shift current. This current
has previously been attributed to the displacement of the electronic wave
function center in real space, when the sample is excited by light. We reveal
that materials like twisted bilayer graphene (TBG) with a flatband dispersion
are uniquely suited to maximize the BPVE because they lead to an enhanced shift
in the momentum space, unlike any previously known shift current mechanism. We
identify properties of quantum geometry, which go beyond the quantum geometric
tensor, and are unrelated to Berry charges, as the physical origin of the large
BPVE we observe in TBG. Our calculations show that TBG with a band gap of
several meV exhibits a giant BPVE in a range of 0.2-1 THz, which represents the
strongest BPVE reported so far at this frequency in a two-dimensional material
and partially persists even a room temperature. Our paper provides a design
principle for shift current generation, which applies to a broad range of
twisted heterostructures with the potential to overcome the so-called
""terahertz gap"" in THz sensing.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:54:49 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 08:42:48 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 11:03:16 GMT""}]","2022-03-24"
"2101.07540","Rafael Lahoz-Beltra","A. Gargantilla Becerra, M. Guti\'errez, R. Lahoz-Beltra","A synthetic biology approach for the design of genetic algorithms with
  bacterial agents",,,,,"cs.NE cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bacteria have been a source of inspiration for the design of evolutionary
algorithms. At the beginning of the 20th century synthetic biology was born, a
discipline whose goal is the design of biological systems that do not exist in
nature, for example, programmable synthetic bacteria. In this paper, we
introduce as a novelty the designing of evolutionary algorithms where all the
steps are conducted by synthetic bacteria. To this end, we designed a genetic
algorithm, which we have named BAGA, illustrating its utility solving simple
instances of optimization problems such as function optimization, 0/1 knapsack
problem, Hamiltonian path problem. The results obtained open the possibility of
conceiving evolutionary algorithms inspired by principles, mechanisms and
genetic circuits from synthetic biology. In summary, we can conclude that
synthetic biology is a source of inspiration either for the design of
evolutionary algorithms or for some of their steps, as shown by the results
obtained in our simulation experiments.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:59:33 GMT""}]","2021-01-20"
"2101.07541","Malisa Vucinic","Jelena Kova\v{c} (UCG), Jovan Crnogorac (UCG), Enis Ko\v{c}an (UCG),
  Malisa Vucinic (EVA)","Sniffing Multi-hop Multi-channel Wireless Sensor Networks","2020 28th Telecommunications Forum (TELFOR), Nov 2020, Belgrade,
  Serbia",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As wireless sensor networks grow larger, more complex and their role more
significant, it becomes necessary to have an insight into the network traffic.
For this purpose, sniffers play an irreplaceable role. Since a sniffer is a
device of limited range, to cover a multi-hop network it is necessary to
consider the deployment of multiple sniffers. This motivates the research on
the optimal number and position of sniffers in the network. We present a
solution based on a minimal dominant set from graph theory. We evaluate the
proposed solution and implement it as an extension of the 6TiSCH simulator. Our
solution assumes a 50-nodes scenario, deployed in 2x2 km outdoor area, with 10%
of packet drops over all channels, when 10 sniffers are used.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:02:11 GMT""}]","2021-01-20"
"2101.07542","Berat Kurar Barakat","Berat Kurar Barakat, Rafi Cohen, Irina Rabaev, and Jihad El-Sana","VML-MOC: Segmenting a multiply oriented and curved handwritten text
  lines dataset",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper publishes a natural and very complicated dataset of handwritten
documents with multiply oriented and curved text lines, namely VML-MOC dataset.
These text lines were written as remarks on the page margins by different
writers over the years. They appear at different locations within the
orientations that range between 0 and 180 or as curvilinear forms. We evaluate
a multi-oriented Gaussian based method to segment these handwritten text lines
that are skewed or curved in any orientation. It achieves a mean pixel
Intersection over Union score of 80.96% on the test documents. The results are
compared with the results of a single-oriented Gaussian based text line
segmentation method.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:10:45 GMT""}]","2021-01-20"
"2101.07543","Sophie Musset","Sophie Musset, Eduard Kontar, Lindsay Glesener, Nicole Vilmer,
  Abdallah Hamini","Constraints on the acceleration region of type III radio bursts from
  decimetric radio spikes and faint X-ray bursts",,,,,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the release of energy during the gradual phase of a flare,
characterized by faint bursts of non-thermal hard X-ray (HXR) emission
associated with decimetric radio spikes and type III radio bursts starting at
high frequencies and extending to the heliosphere. We characterize the site of
electron acceleration in the corona and study the radial evolution of radio
source sizes in the high corona. Imaging and spectroscopy of the HXR emission
with Fermi and RHESSI provide a diagnostic of the accelerated electrons in the
corona as well as a lower limit on the height of the acceleration region. Radio
observations in the decimetric range with the ORFEES spectrograph provide radio
diagnostics close to the acceleration region. Radio spectro-imaging with LOFAR
in the meter range provide the evolution of the radio source sizes with their
distance from the Sun, in the high corona. Non-thermal HXR bursts and radio
spikes are well correlated on short timescales. The spectral index of
non-thermal HXR emitting electrons is -4 and their number is about $2\times
10^{33}$ electrons/s. The density of the acceleration region is constrained
between $1-5 \times 10^9$ cm$^{-3}$. Electrons accelerated upward rapidly
become unstable to Langmuir wave production, leading to high starting
frequencies of the type III radio bursts, and the elongation of the radio beam
at its source is between 0.5 and 11.4 Mm. The radio source sizes and their
gradient observed with LOFAR are larger than the expected size and gradient of
the size of the electron beam, assuming it follows the expansion of the
magnetic flux tubes. These observations support the idea that the fragmentation
of the radio emission into spikes is linked to the fragmentation of the
acceleration process itself. The combination of HXR and radio diagnostics in
the corona provides strong constrains on the site of electron acceleration.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:12:49 GMT""}]","2021-01-20"
"2101.07544","Antoine Glicenstein","Antoine Glicenstein, Giovanni Ferioli, Ludovic Brossard, Yvan R. P.
  Sortais, Daniel Barredo, Florence Nogrette, Igor Ferrier-Barbut, Antoine
  Browaeys","Fast and efficient preparation of 1D chains and dense cold atomic clouds",,"Phys. Rev. A 103, 043301 (2021)","10.1103/PhysRevA.103.043301",,"physics.atom-ph cond-mat.quant-gas physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the efficient and fast ($\sim 2\mathrm{Hz}$) preparation of
randomly loaded 1D chains of individual $^{87}$Rb atoms and of dense atomic
clouds trapped in optical tweezers using a new experimental platform. This
platform is designed for the study of both structured and disordered atomic
systems in free space. It is composed of two high-resolution optical systems
perpendicular to each other, enhancing observation and manipulation
capabilities. The setup includes a dynamically controllable telescope, which we
use to vary the tweezer beam waist. A D1 $\Lambda$-enhanced gray molasses
enhances the loading of the traps from a magneto-optical trap. Using these
tools, we prepare chains of up to $\sim 100$ atoms separated by $\sim 1
\mathrm{\mu m}$ by retro-reflecting the tweezer light, hence producing a 1D
optical lattice with strong transverse confinement. Dense atomic clouds with
peak densities up to $n_0 = 10^{15}\:\mathrm{at}/\mathrm{cm}^3$ are obtained by
compression of an initial cloud. This high density results into interatomic
distances smaller than $\lambda/(2\pi)$ for the D2 optical transitions, making
it ideal to study light-induced interactions in dense samples.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:16:18 GMT""}]","2021-04-07"
"2101.07545","Aymeric Baradat","Luigi Ambrosio and Aymeric Baradat and Yann Brenier","$\Gamma$-convergence for a class of action functionals induced by
  gradients of convex functions",,,,,"math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  Given a real function $f$, the rate function for the large deviations of the
diffusion process of drift $\nabla f$ given by the Freidlin-Wentzell theorem
coincides with the time integral of the energy dissipation for the gradient
flow associated with $f$. This paper is concerned with the stability in the
hilbertian framework of this common action functional when $f$ varies. More
precisely, we show that if $(f_h)_h$ is uniformly $\lambda$-convex for some
$\lambda \in \mathbb{R}$ and converges towards $f$ in the sense of Mosco
convergence, then the related functionals $\Gamma$-converge in the strong
topology of curves.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:16:47 GMT""}]","2021-01-20"
"2101.07546","Charlie Dickens","Graham Cormode, Charlie Dickens, David P. Woodruff","Subspace exploration: Bounds on Projected Frequency Estimation",,,,,"cs.DS cs.CC","http://creativecommons.org/licenses/by/4.0/","  Given an $n \times d$ dimensional dataset $A$, a projection query specifies a
subset $C \subseteq [d]$ of columns which yields a new $n \times |C|$ array. We
study the space complexity of computing data analysis functions over such
subspaces, including heavy hitters and norms, when the subspaces are revealed
only after observing the data. We show that this important class of problems is
typically hard: for many problems, we show $2^{\Omega(d)}$ lower bounds.
However, we present upper bounds which demonstrate space dependency better than
$2^d$. That is, for $c,c' \in (0,1)$ and a parameter $N=2^d$ an
$N^c$-approximation can be obtained in space $\min(N^{c'},n)$, showing that it
is possible to improve on the na\""{i}ve approach of keeping information for all
$2^d$ subsets of $d$ columns. Our results are based on careful constructions of
instances using coding theory and novel combinatorial reductions that exhibit
such space-approximation tradeoffs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:18:22 GMT""}]","2021-01-20"
"2101.07547","Alfredo Donno","Matteo Cavaleri, Daniele D'Angeli, Alfredo Donno, Emanuele Rodaro","On an uncountable family of graphs whose spectrum is a Cantor set","33 pages, 10 figures",,,,"math.GR math.CO math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For each $p\geq 1$, the star automaton group $\mathcal{G}_{S_p}$ is an
automaton group which can be defined starting from a star graph on $p+1$
vertices. We study Schreier graphs associated with the action of the group
$\mathcal{G}_{S_p}$ on the regular rooted tree $T_{p+1}$ of degree $p+1$ and on
its boundary $\partial T_{p+1}$. With the transitive action on the $n$-th level
of $T_{p+1}$ is associated a finite Schreier graph $\Gamma^p_n$, whereas there
exist uncountably many orbits of the action on the boundary, represented by
infinite Schreier graphs which are obtained as limits of the sequence
$\{\Gamma_n^p\}_{n\geq 1}$ in the Gromov-Hausdorff topology. We obtain an
explicit description of the spectrum of the graphs $\{\Gamma_n^p\}_{n\geq 1}$.
Then, by using amenability of $\mathcal{G}_{S_p}$, we prove that the spectrum
of each infinite Schreier graph is the union of a Cantor set of zero Lebesgue
measure, which is the Julia set of the quadratic map $f_p(z) = z^2-2(p-1)z
-2p$, and a countable collection of isolated points supporting the KNS spectral
measure. We also give a complete classification of the infinite Schreier graphs
up to isomorphism of unrooted graphs, showing that they may have $1$, $2$ or
$2p$ ends, and that the case of $1$ end is generic with respect to the uniform
measure on $\partial T_{p+1}$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:18:45 GMT""}]","2021-01-20"
"2101.07548","Zhiming Dong","Xianpeng Wang, Zhiming Dong, Lixin Tang and Qingfu Zhang","Multiobjective Multitasking Optimization Based on Decomposition with
  Dual Neighborhoods",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a multiobjective multitasking optimization evolutionary
algorithm based on decomposition with dual neighborhood. In our proposed
algorithm, each subproblem not only maintains a neighborhood based on the
Euclidean distance among weight vectors within its own task, but also keeps a
neighborhood with subproblems of other tasks. Gray relation analysis is used to
define neighborhood among subproblems of different tasks. In such a way,
relationship among different subproblems can be effectively exploited to guide
the search. Experimental results show that our proposed algorithm outperforms
four state-of-the-art multiobjective multitasking evolutionary algorithms and a
traditional decomposition-based multiobjective evolutionary algorithm on a set
of test problems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:18:47 GMT""}]","2021-01-20"
"2101.07549","Niels Ole Salscheider","Niels Ole Salscheider","Object Tracking by Detection with Visual and Motion Cues",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-driving cars and other autonomous vehicles need to detect and track
objects in camera images. We present a simple online tracking algorithm that is
based on a constant velocity motion model with a Kalman filter, and an
assignment heuristic. The assignment heuristic relies on four metrics: An
embedding vector that describes the appearance of objects and can be used to
re-identify them, a displacement vector that describes the object movement
between two consecutive video frames, the Mahalanobis distance between the
Kalman filter states and the new detections, and a class distance. These
metrics are combined with a linear SVM, and then the assignment problem is
solved by the Hungarian algorithm. We also propose an efficient CNN
architecture that estimates these metrics. Our multi-frame model accepts two
consecutive video frames which are processed individually in the backbone, and
then optical flow is estimated on the resulting feature maps. This allows the
network heads to estimate the displacement vectors. We evaluate our approach on
the challenging BDD100K tracking dataset. Our multi-frame model achieves a good
MOTA value of 39.1% with low localization error of 0.206 in MOTP. Our fast
single-frame model achieves an even lower localization error of 0.202 in MOTP,
and a MOTA value of 36.8%.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:29:16 GMT""}]","2021-01-20"
"2101.07550","Louis Dublois","Louis Dublois, Michael Lampis, Vangelis Th. Paschos","Upper Dominating Set: Tight Algorithms for Pathwidth and Sub-Exponential
  Approximation","This paper has been accepted to CIAC 2021",,,,"cs.DS cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An upper dominating set is a minimal dominating set in a graph. In the
\textsc{Upper Dominating Set} problem, the goal is to find an upper dominating
set of maximum size. We study the complexity of parameterized algorithms for
\textsc{Upper Dominating Set}, as well as its sub-exponential approximation.
First, we prove that, under ETH, \textsc{$k$-Upper Dominating Set} cannot be
solved in time $O(n^{o(k)})$ (improving on $O(n^{o(\sqrt{k})})$), and in the
same time we show under the same complexity assumption that for any constant
ratio $r$ and any $\varepsilon > 0$, there is no $r$-approximation algorithm
running in time $O(n^{k^{1-\varepsilon}})$. Then, we settle the problem's
complexity parameterized by pathwidth by giving an algorithm running in time
$O^*(6^{pw})$ (improving the current best $O^*(7^{pw})$), and a lower bound
showing that our algorithm is the best we can get under the SETH. Furthermore,
we obtain a simple sub-exponential approximation algorithm for this problem: an
algorithm that produces an $r$-approximation in time $n^{O(n/r)}$, for any
desired approximation ratio $r < n$. We finally show that this
time-approximation trade-off is tight, up to an arbitrarily small constant in
the second exponent: under the randomized ETH, and for any ratio $r > 1$ and
$\varepsilon > 0$, no algorithm can output an $r$-approximation in time
$n^{(n/r)^{1-\varepsilon}}$. Hence, we completely characterize the
approximability of the problem in sub-exponential time.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:31:08 GMT""}]","2021-01-20"
"2101.07551","Jianmin Dong","X. L. Shang, P. Wang, W. Zuo, and J. M. Dong","Role of nucleon-nucleon correlation in transport coefficients and
  gravitational-wave-driven $r$-mode instability of neutron stars","11 pages, 6 figures","Phys. Lett. B, 811, 135963 (2020)","10.1016/j.physletb.2020.135963",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  The thermal conductivity and shear viscosity of dense nuclear matter, along
with the corresponding shear viscosity timescale of canonical neutron stars
(NSs), are investigated, where the effect of Fermi surface depletion (i.e., the
$Z$-factor effect) induced by the nucleon-nucleon correlation are taken into
account. The factors which are responsible for the transport coefficients,
including the equation of state for building the stellar structure, nucleon
effective masses, in-medium cross sections, and the $Z$-factor at Fermi
surfaces, are all calculated in the framework of the Brueckner theory. The
Fermi surface depletion is found to enhance the transport coefficients by
several times at high densities, which is more favorable to damping the
gravitational-wave-driven $r$-mode instability of NSs. Yet, the onset of the
$Z$-factor-quenched neutron triplet superfluidity provides the opposite
effects, which can be much more significant than the above mentioned $Z$-factor
effect itself. Therefore, different from the previous understanding, the
nucleon shear viscosity is still smaller than the lepton one in the superfluid
NS matter at low temperatures. Accordingly, the shear viscosity cannot stablize
canonical NSs against $r$-mode oscillations even at quite low core temperatures
$10^6$ K.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:31:47 GMT""}]","2021-01-20"
"2101.07552","Yakov Shnir","Yakov Shnir","Chains of interacting solitons","18 pages, 9 figures; invited contribution to the Special Issue
  ""Symmetry in Particle Physics II"" in Symmetry",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an overview of multisoliton chains arising in various
non-integrable field theories, and discuss different mechanisms, which may lead
to the occurrence of such axially-symmetric classical solutions. We explain the
pattern of interactions between different solitons, in particular Q-balls,
Skyrmions and monopoles and show how chains of interacting non-BPS solitons may
form in a dynamic equilibrium between repulsive and attractive forces.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:34:02 GMT""}]","2021-01-20"
"2101.07553","Anna Abbatiello","Anna Abbatiello, Eduard Feireisl","On the motion of a compressible viscous fluid driven by time periodic
  inflow/outflow boundary conditions",,,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the barotropic Navier-Stokes system describing the motion of a
compressible viscous fluid confined to a bounded domain driven by time periodic
inflow/outflow boundary conditions. We show that the problem admits a time
periodic solution in the class of weak solutions satisfying the energy
inequality.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:35:05 GMT""}]","2021-01-20"
"2101.07554","Tillmann Miltzow","Fabian Klute, Meghana M. Reddy, Tillmann Miltzow","Local Complexity of Polygons","7 pages, 5 figures",,,,"cs.CG cs.DM cs.DS","http://creativecommons.org/licenses/by/4.0/","  Many problems in Discrete and Computational Geometry deal with simple
polygons or polygonal regions. Many algorithms and data-structures perform
considerably faster, if the underlying polygonal region has low local
complexity. One obstacle to make this intuition rigorous, is the lack of a
formal definition of local complexity. Here, we give two possible definitions
and show how they are related in a combinatorial sense. We say that a polygon
$P$ has point visibility width $w=pvw$, if there is no point $q\in P$ that sees
more than $w$ reflex vertices. We say that a polygon $P$ has chord visibility
width $w=cvw $, if there is no chord $c=\textrm{seg}(a,b)\subset P$ that sees
more than w reflex vertices. We show that \[ cvw \leq pvw ^{O( pvw )},\] for
any simple polygon. Furthermore, we show that there exists a simple polygon
with \[ cvw \geq 2^{\Omega( pvw )}.\]
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:38:00 GMT""}]","2021-01-20"
"2101.07555","Ru Li","Ru Li, Shuaicheng Liu, Guangfu Wang, Guanghui Liu and Bing Zeng","JigsawGAN: Auxiliary Learning for Solving Jigsaw Puzzles with Generative
  Adversarial Networks","Accepted by IEEE Transactions on Image Processing (TIP)","IEEE Transactions on Image Processing, 2021","10.1109/TIP.2021.3120052",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper proposes a solution based on Generative Adversarial Network (GAN)
for solving jigsaw puzzles. The problem assumes that an image is divided into
equal square pieces, and asks to recover the image according to information
provided by the pieces. Conventional jigsaw puzzle solvers often determine the
relationships based on the boundaries of pieces, which ignore the important
semantic information. In this paper, we propose JigsawGAN, a GAN-based
auxiliary learning method for solving jigsaw puzzles with unpaired images (with
no prior knowledge of the initial images). We design a multi-task pipeline that
includes, (1) a classification branch to classify jigsaw permutations, and (2)
a GAN branch to recover features to images in correct orders. The
classification branch is constrained by the pseudo-labels generated according
to the shuffled pieces. The GAN branch concentrates on the image semantic
information, where the generator produces the natural images to fool the
discriminator, while the discriminator distinguishes whether a given image
belongs to the synthesized or the real target domain. These two branches are
connected by a flow-based warp module that is applied to warp features to
correct the order according to the classification results. The proposed method
can solve jigsaw puzzles more efficiently by utilizing both semantic
information and boundary information simultaneously. Qualitative and
quantitative comparisons against several representative jigsaw puzzle solvers
demonstrate the superiority of our method.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:40:38 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 08:21:12 GMT""},{""version"":""v3"",""created"":""Fri, 15 Jul 2022 08:10:38 GMT""}]","2022-07-18"
"2101.07556","Roy Karasik","Roy Karasik, Osvaldo Simeone, Marco Di Renzo, Shlomo Shamai (Shitz)","Single-RF Multi-User Communication Through Reconfigurable Intelligent
  Surfaces: An Information-Theoretic Analysis","Submitted for possible conference publication. arXiv admin note: text
  overlap with arXiv:2012.00407",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Reconfigurable intelligent surfaces (RISs) are typically used in multi-user
systems to mitigate interference among active transmitters. In contrast, this
paper studies a setting with a conventional active encoder as well as a passive
encoder that modulates the reflection pattern of the RIS. The RIS hence serves
the dual purpose of improving the rate of the active encoder and of enabling
communication from the second encoder. The capacity region is characterized,
and information-theoretic insights regarding the trade-offs between the rates
of the two encoders are derived by focusing on the high- and low-power regimes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:41:16 GMT""}]","2021-01-20"
"2101.07557","Christina Giannoula","Christina Giannoula, Nandita Vijaykumar, Nikela Papadopoulou,
  Vasileios Karakostas, Ivan Fernandez, Juan G\'omez-Luna, Lois Orosa,
  Nectarios Koziris, Georgios Goumas, Onur Mutlu","SynCron: Efficient Synchronization Support for Near-Data-Processing
  Architectures","To appear in the 27th IEEE International Symposium on
  High-Performance Computer Architecture (HPCA-27)",,,,"cs.AR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Near-Data-Processing (NDP) architectures present a promising way to alleviate
data movement costs and can provide significant performance and energy benefits
to parallel applications. Typically, NDP architectures support several NDP
units, each including multiple simple cores placed close to memory. To fully
leverage the benefits of NDP and achieve high performance for parallel
workloads, efficient synchronization among the NDP cores of a system is
necessary. However, supporting synchronization in many NDP systems is
challenging because they lack shared caches and hardware cache coherence
support, which are commonly used for synchronization in multicore systems, and
communication across different NDP units can be expensive.
  This paper comprehensively examines the synchronization problem in NDP
systems, and proposes SynCron, an end-to-end synchronization solution for NDP
systems. SynCron adds low-cost hardware support near memory for synchronization
acceleration, and avoids the need for hardware cache coherence support. SynCron
has three components: 1) a specialized cache memory structure to avoid memory
accesses for synchronization and minimize latency overheads, 2) a hierarchical
message-passing communication protocol to minimize expensive communication
across NDP units of the system, and 3) a hardware-only overflow management
scheme to avoid performance degradation when hardware resources for
synchronization tracking are exceeded.
  We evaluate SynCron using a variety of parallel workloads, covering various
contention scenarios. SynCron improves performance by 1.27$\times$ on average
(up to 1.78$\times$) under high-contention scenarios, and by 1.35$\times$ on
average (up to 2.29$\times$) under low-contention real applications, compared
to state-of-the-art approaches. SynCron reduces system energy consumption by
2.08$\times$ on average (up to 4.25$\times$).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:48:58 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 00:09:20 GMT""},{""version"":""v3"",""created"":""Sat, 13 Feb 2021 11:47:24 GMT""}]","2021-02-16"
"2101.07558","Joern Steuding","Janyarak Tongsomporn, Saeree Wananiyakul, J\""orn Steuding","Sums of Consecutive Prime Squares",,,,,"math.NT","http://creativecommons.org/publicdomain/zero/1.0/","  We prove explicit bounds for the number of sums of consecutive prime squares
below a given magnitude.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:56:57 GMT""}]","2021-01-20"
"2101.07559","Juan Elias","J. Elias, M. E. Rossi","A constructive approach to one-dimensional Gorenstein $k$-algebras","To appear in Trans. Am. Math. Soc",,,,"math.AC math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $R$ be the power series ring or the polynomial ring over a field $k$ and
let $I $ be an ideal of $R.$ Macaulay proved that the Artinian Gorenstein
$k$-algebras $R/I$ are in one-to-one correspondence with the cyclic
$R$-submodules of the divided power series ring $\Gamma. $ The result is
effective in the sense that any polynomial of degree $s$ produces an Artinian
Gorenstein $k$-algebra of socle degree $s.$ In a recent paper, the authors
extended Macaulay's correspondence characterizing the $R$-submodules of $\Gamma
$ in one-to-one correspondence with Gorenstein d-dimensional $k$-algebras.
However, these submodules in positive dimension are not finitely generated. Our
goal is to give constructive and finite procedures for the construction of
Gorenstein $k$-algebras of dimension one and any codimension. This has been
achieved through a deep analysis of the $G$-admissible submodules of $\Gamma. $
Applications to the Gorenstein linkage of zero-dimensional schemes and to
Gorenstein affine semigroup rings are discussed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:01:42 GMT""}]","2021-01-20"
"2101.07560","Federica Pes","Federica Pes, Giuseppe Rodriguez","A doubly relaxed minimal-norm Gauss-Newton method for underdetermined
  nonlinear least-squares problems",,"Appl.Numer.Math. 171 (2022) 233-248","10.1016/j.apnum.2021.09.002",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  When a physical system is modeled by a nonlinear function, the unknown
parameters can be estimated by fitting experimental observations by a
least-squares approach. Newton's method and its variants are often used to
solve problems of this type. In this paper, we are concerned with the
computation of the minimal-norm solution of an underdetermined nonlinear
least-squares problem. We present a Gauss-Newton type method, which relies on
two relaxation parameters to ensure convergence, and which incorporates a
procedure to dynamically estimate the two parameters, as well as the rank of
the Jacobian matrix, along the iterations. Numerical results are presented.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:07:24 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 10:25:45 GMT""},{""version"":""v3"",""created"":""Mon, 9 Aug 2021 10:21:24 GMT""},{""version"":""v4"",""created"":""Sun, 29 Aug 2021 13:59:13 GMT""},{""version"":""v5"",""created"":""Fri, 17 Sep 2021 12:59:23 GMT""}]","2021-09-20"
"2101.07561","Paul Novello","Paul Novello, Ga\""el Po\""ette, David Lugato, Pietro Congedo","Leveraging Local Variation in Data: Sampling and Weighting Schemes for
  Supervised Deep Learning",,,"10.1615/JMachLearnModelComput.2022041819",,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In the context of supervised learning of a function by a neural network, we
claim and empirically verify that the neural network yields better results when
the distribution of the data set focuses on regions where the function to learn
is steep. We first traduce this assumption in a mathematically workable way
using Taylor expansion and emphasize a new training distribution based on the
derivatives of the function to learn. Then, theoretical derivations allow
constructing a methodology that we call Variance Based Samples Weighting
(VBSW). VBSW uses labels local variance to weight the training points. This
methodology is general, scalable, cost-effective, and significantly increases
the performances of a large class of neural networks for various classification
and regression tasks on image, text, and multivariate data. We highlight its
benefits with experiments involving neural networks from linear models to
ResNet and Bert.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:08:40 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 12:50:28 GMT""},{""version"":""v3"",""created"":""Tue, 27 Sep 2022 15:37:42 GMT""}]","2022-09-28"
"2101.07562","Douglas Leith","Francesco Gringoli, Douglas J. Leith","Modelling Downlink Packet Aggregation in Paced 802.11ac WLANs","arXiv admin note: substantial text overlap with arXiv:1910.09651",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive an analytic model of packet aggregation on the the downlink of an
802.11ac WLAN when packet arrivals are paced. The model is closed-form and so
suitable for both analysis and design of next generation edge architectures
that aim to achieve high rate and low delay. The model is validated against
both simulations and experimental measurements and found to be remarkably
accurate despite its simplicity.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:10:20 GMT""}]","2021-01-20"
"2101.07563","Kathryn Schutte","Kathryn Schutte, Olivier Moindrot, Paul H\'erent, Jean-Baptiste
  Schiratti, Simon J\'egou","Using StyleGAN for Visual Interpretability of Deep Learning Models on
  Medical Images","Accepted for oral session of Medical Imaging meets NeurIPS 2020
  workshop:
  http://www.cse.cuhk.edu.hk/~qdou/public/medneurips2020/70_neurips2020_cameraready_opt.pdf",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  As AI-based medical devices are becoming more common in imaging fields like
radiology and histology, interpretability of the underlying predictive models
is crucial to expand their use in clinical practice. Existing heatmap-based
interpretability methods such as GradCAM only highlight the location of
predictive features but do not explain how they contribute to the prediction.
In this paper, we propose a new interpretability method that can be used to
understand the predictions of any black-box model on images, by showing how the
input image would be modified in order to produce different predictions. A
StyleGAN is trained on medical images to provide a mapping between latent
vectors and images. Our method identifies the optimal direction in the latent
space to create a change in the model prediction. By shifting the latent
representation of an input image along this direction, we can produce a series
of new synthetic images with changed predictions. We validate our approach on
histology and radiology images, and demonstrate its ability to provide
meaningful explanations that are more informative than GradCAM heatmaps. Our
method reveals the patterns learned by the model, which allows clinicians to
build trust in the model's predictions, discover new biomarkers and eventually
reveal potential biases.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:13:20 GMT""}]","2021-01-20"
"2101.07564","Luc Pronzato","Luc Pronzato","Performance analysis of greedy algorithms for minimising a Maximum Mean
  Discrepancy","36 pages, 7 figures, preprint submitted to a journal",,,,"stat.ML cs.LG stat.CO","http://creativecommons.org/licenses/by/4.0/","  We analyse the performance of several iterative algorithms for the
quantisation of a probability measure $\mu$, based on the minimisation of a
Maximum Mean Discrepancy (MMD). Our analysis includes kernel herding, greedy
MMD minimisation and Sequential Bayesian Quadrature (SBQ). We show that the
finite-sample-size approximation error, measured by the MMD, decreases as $1/n$
for SBQ and also for kernel herding and greedy MMD minimisation when using a
suitable step-size sequence. The upper bound on the approximation error is
slightly better for SBQ, but the other methods are significantly faster, with a
computational cost that increases only linearly with the number of points
selected. This is illustrated by two numerical examples, with the target
measure $\mu$ being uniform (a space-filling design application) and with $\mu$
a Gaussian mixture. They suggest that the bounds derived in the paper are
overly pessimistic, in particular for SBQ. The sources of this pessimism are
identified but seem difficult to counter.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:18:51 GMT""},{""version"":""v2"",""created"":""Thu, 28 Apr 2022 07:54:23 GMT""}]","2022-04-29"
"2101.07565","Etera R. Livine","Etera R. Livine","Loop Quantum Gravity Boundary Dynamics and SL(2,C) Gauge Theory","24 pages",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of the quest for a holographic formulation of quantum gravity,
we investigate the basic boundary theory structure for loop quantum gravity. In
3+1 space-time dimensions, the boundary theory lives on the 2+1-dimensional
time-like boundary and is supposed to describe the time evolution of the edge
modes living on the 2-dimensional boundary of space, i.e. the space-time
corner. Focusing on ""electric"" excitations -- quanta of area -- living on the
corner, we formulate their dynamics in terms of classical spinor variables and
we show that the coupling constants of a polynomial Hamiltonian can be
understood as the components of a background boundary 2+1-metric. This leads to
a deeper conjecture of a correspondence between boundary Hamiltonian and
boundary metric states. We further show that one can reformulate the quanta of
area data in terms of a SL(2,C) connection, transporting the spinors on the
boundary surface and whose SU(2) component would define ""magnetic"" excitations
(tangential Ashtekar-Barbero connection), thereby opening the door to writing
the loop quantum gravity boundary dynamics as a 2+1-dimensional SL(2,C) gauge
theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:20:06 GMT""}]","2021-01-20"
"2101.07566","David Benisty","David Benisty, David Vasak, Johannes Kirsch, Jurgen Struckmeier","Low-Redshift Constraints on Covariant Canonical Gauge Theory of Gravity","9 pages; 5 figures","Eur. Phys. J. C81 (2021) 125","10.1140/epjc/s10052-021-08924-0",,"gr-qc astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Constraints on the Covariant Canonical Gauge Gravity (CCGG) theory from
low-redshift cosmology are studied. The formulation extends Einstein's theory
of General Relativity (GR) by a quadratic Riemann-Cartan term in the
Lagrangian, controlled by a ""deformation"" parameter. In the Friedman universe
this leads to an additional geometrical stress energy and promotes, due to the
necessary presence of torsion, the cosmological constant to a time-dependent
function. The MCMC analysis of the combined data sets of Type Ia Supernovae,
Cosmic Chronometers and Baryon Acoustic Oscillations yields a fit that is well
comparable with the $\Lambda$CDM results. The modifications implied in the CCGG
approach turn out to be subdominant in the low-redshift cosmology. However, a
non-zero spatial curvature and deformation parameter are shown to be consistent
with observations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:21:14 GMT""}]","2021-02-09"
"2101.07567","Jianmin Dong","J. M. Dong, Q. Zhao, L. J. Wang, W. Zuo, J. Z. Gu","Alpha-Cluster formation in heavy alpha-emitters within a multistep model","7 pages, 4 figures","Physics Letters B, 813, 136063 (2021)","10.1016/j.physletb.2021.136063",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  $\alpha$-decay always has enormous impetuses to the development of physics
and chemistry, in particular due to its indispensable role in the research of
new elements. Although it has been observed in laboratories for more than a
century, it remains a difficult problem to calculate accurately the formation
probability $S_\alpha$ microscopically. To this end, we establish a new model,
i.e., multistep model, and the corresponding formation probability $S_\alpha$
values of some typical $\alpha$-emitters are calculated without adjustable
parameters. The experimental half-lives, in particular their irregular behavior
around a shell closure, are remarkably well reproduced by half-life laws
combined with these $S_\alpha$. In our strategy, the cluster formation is a
gradual process in heavy nuclei, different from the situation that cluster
pre-exists in light nuclei. The present study may pave the way to a fully
understanding of $\alpha$-decay from the perspective of nuclear structure.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:23:41 GMT""}]","2021-01-20"
"2101.07568","Yan Przhiyalkovskiy V.","Yan Przhiyalkovskiy","Continuous measurements in probability representation of quantum
  mechanics",,"Proc. Steklov Inst. Math., 313 (2021), 193-202","10.1134/S0081543821020188",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The continuous quantum measurement within the probability representation of
quantum mechanics is discussed. The partial classical propagator of the
symplectic tomogram associated to a particular measurement outcome is
introduced, for which the representation of a continuous measurement through
the restricted path integral is applied. The classical propagator for the
system undergoing a non-selective measurement is derived by summing these
partial propagators over the entire outcome set. The elaborated approach is
illustrated by considering non-selective position measurement of a quantum
oscillator and a particle.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:25:17 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 09:44:59 GMT""}]","2021-08-03"
"2101.07569","Benedykt R. Jany B.R. Jany","Arkadiusz Janas, Witold Piskorz, Aleksandr Kryshtal, Grzegorz Cempura,
  Wojciech Belza, Adam Kruk, Benedykt R. Jany, Franciszek Krok","Into the Origin of Electrical Conductivity for the Metal-Semiconductor
  Junction at the Atomic Level",,"Applied Surface Science 570 (2021) 150958","10.1016/j.apsusc.2021.150958",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The metal-semiconductor (M-S) junction based devices are commonly used in all
sorts of electronic devices. Their electrical properties are defined by the
metallic phase properties with a respect to the semiconductor used. Here we
make an in-depth survey on the origin of the M-S junction at the atomic scale
by studying the properties of the AuIn2 nanoelectrodes formed on the InP(001)
surface by the in situ electrical measurements in combination with a detailed
investigation of atomically resolved structure supported by the first-principle
calculations of its local electrical properties. We have found that a different
crystallographic orientation of the same metallic phase with a respect to the
semiconductor structure influences strongly the M-S junction rectifying
properties by subtle change of the metal Fermi level and influencing the band
edge moving at the interface. This ultimately changes conductivity regime
between Ohmic and Schottky type. The effect of crystallographic orientation has
to be taken into account in the engineering of the M-S junction-based
electronic devices.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:25:32 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 16:01:37 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 15:43:02 GMT""},{""version"":""v4"",""created"":""Mon, 13 Sep 2021 09:27:22 GMT""}]","2021-09-14"
"2101.07570","Thomas K.F. Chiu","Thomas K.F. Chiu, Helen Meng, Ching-Sing Chai, Irwin King, Savio Wong
  and Yeung Yam","Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI)
  Curriculum","8 pages 5 figures",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for
the Future Project (AI4Future) co-created an AI curriculum for pre-tertiary
education and evaluated its efficacy. While AI is conventionally taught in
tertiary level education, our co-creation process successfully developed the
curriculum that has been used in secondary school teaching in Hong Kong and
received positive feedback. Background: AI4Future is a cross-sector project
that engages five major partners - CUHK Faculty of Engineering and Faculty of
Education, Hong Kong secondary schools, the government and the AI industry. A
team of 14 professors with expertise in engineering and education collaborated
with 17 principals and teachers from 6 secondary schools to co-create the
curriculum. This team formation bridges the gap between researchers in
engineering and education, together with practitioners in education context.
Research Questions: What are the main features of the curriculum content
developed through the co-creation process? Would the curriculum significantly
improve the students perceived competence in, as well as attitude and
motivation towards AI? What are the teachers perceptions of the co-creation
process that aims to accommodate and foster teacher autonomy? Methodology: This
study adopted a mix of quantitative and qualitative methods and involved 335
student participants. Findings: 1) two main features of learning resources, 2)
the students perceived greater competence, and developed more positive attitude
to learn AI, and 3) the co-creation process generated a variety of resources
which enhanced the teachers knowledge in AI, as well as fostered teachers
autonomy in bringing the subject matter into their classrooms.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:26:19 GMT""}]","2021-01-20"
"2101.07571","Tomoe Kishimoto","Tomoe Kishimoto, Masahiko Saito, Junichi Tanaka, Yutaro Iiyama, Ryu
  Sawada and Koji Terashi","An Improvement of Object Detection Performance using Multi-step Machine
  Learnings","Submitted to ICIP 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Connecting multiple machine learning models into a pipeline is effective for
handling complex problems. By breaking down the problem into steps, each
tackled by a specific component model of the pipeline, the overall solution can
be made accurate and explainable. This paper describes an enhancement of object
detection based on this multi-step concept, where a post-processing step called
the calibration model is introduced. The calibration model consists of a
convolutional neural network, and utilizes rich contextual information based on
the domain knowledge of the input. Improvements of object detection performance
by 0.8-1.9 in average precision metric over existing object detectors have been
observed using the new model.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:32:27 GMT""}]","2021-01-20"
"2101.07572","Giovanni Catino","Giovanni Catino","Metrics of constant negative scalar-Weyl curvature",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extending Aubin's construction of metrics with constant negative scalar
curvature, we prove that every $n$-dimensional closed manifold admits a
Riemannian metric with constant negative scalar-Weyl curvature, that is
$R+t|W|, t\in\mathbb{R}$. In particular, there are no topological obstructions
for metrics with $\varepsilon$-pinched Weyl curvature and negative scalar
curvature.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:32:57 GMT""}]","2021-01-20"
"2101.07573","Matteo Viale","Matteo Viale","The model-companionship spectrum of set theory, generic absoluteness,
  and the Continuum problem","expands and systematizes arXiv:2003.07114 and arXiv:2003.07120",,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We show that for $\Pi_2$-properties of second or third order arithmetic as
formalized in appropriate natural signatures the apparently weaker notion of
forcibility overlaps with the standard notion of consistency (assuming large
cardinal axioms).
  Among such $\Pi_2$-properties we mention: the negation of the Continuum
hypothesis, Souslin Hypothesis, the negation of Whitehead's conjecture on free
groups, the non-existence of outer automorphisms for the Calkin algebra, etc...
In particular this gives an a posteriori explanation of the success forcing
(and forcing axioms) met in producing models of such properties.
  Our main results relate generic absoluteness theorems for second order
arithmetic, Woodin's axiom $(*)$ and forcing axioms to Robinson's notion of
model companionship (as applied to set theory). We also briefly outline in
which ways these results provide an argument to refute the Continuum
hypothesis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:33:34 GMT""}]","2021-01-20"
"2101.07574","Houwang Li","Houwang Li and Wenming Zou","Quasilinear Schr\""odinger equations: ground state and infinitely many
  normalized solutions",,"Pacific J. Math. 322 (2023) 99-138","10.2140/pjm.2023.322.99",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In the present paper, we study the normalized solutions for the following
quasilinear Schr\""odinger equations:
  $$-\Delta u-u\Delta u^2+\lambda u=|u|^{p-2}u \quad \text{in}~\mathbb R^N,$$
with prescribed mass
  $$\int_{\mathbb R^N} u^2=a^2.$$ We first consider the mass-supercritical case
$p>4+\frac{4}{N}$, which has not been studied before. By using a perturbation
method, we succeed to prove the existence of ground state normalized solutions,
and by applying the index theory, we obtain the existence of infinitely many
normalized solutions. Then we turn to study the mass-critical case, i.e.,
$p=4+\frac{4}{N}$, and obtain some new existence results. Moreover, we also
observe a concentration behavior of the ground state solutions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:35:39 GMT""}]","2023-05-03"
"2101.07575","Chanseok Park","Chanseok Park and Min Wang","A note on the g and h control charts","17 pages, 1 figure, 2 tables",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  In this note, we revisit the $g$ and $h$ control charts that are commonly
used for monitoring the number of conforming cases between the two consecutive
appearances of nonconformities. It is known that the process parameter of these
charts is usually unknown and estimated by using the maximum likelihood
estimator and the minimum variance unbiased estimator. However, the minimum
variance unbiased estimator in the control charts has been inappropriately used
in the quality engineering literature. This observation motivates us to provide
the correct minimum variance unbiased estimator and investigate theoretical and
empirical biases of these estimators under consideration. Given that these
charts are developed based on the underlying assumption that samples from the
process should be balanced, which is often not satisfied in many practical
applications, we propose a method for constructing these charts with unbalanced
samples.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:47:51 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 04:41:52 GMT""}]","2021-01-25"
"2101.07576","Rita Pucci","Rita Pucci, Christian Micheloni, Niki Martinel","Collaboration among Image and Object Level Features for Image
  Colourisation",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image colourisation is an ill-posed problem, with multiple correct solutions
which depend on the context and object instances present in the input datum.
Previous approaches attacked the problem either by requiring intense user
interactions or by exploiting the ability of convolutional neural networks
(CNNs) in learning image level (context) features. However, obtaining human
hints is not always feasible and CNNs alone are not able to learn object-level
semantics unless multiple models pretrained with supervision are considered. In
this work, we propose a single network, named UCapsNet, that separate
image-level features obtained through convolutions and object-level features
captured by means of capsules. Then, by skip connections over different layers,
we enforce collaboration between such disentangling factors to produce high
quality and plausible image colourisation. We pose the problem as a
classification task that can be addressed by a fully self-supervised approach,
thus requires no human effort. Experimental results on three benchmark datasets
show that our approach outperforms existing methods on standard quality metrics
and achieves a state of the art performances on image colourisation. A large
scale user study shows that our method is preferred over existing solutions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:48:12 GMT""}]","2021-01-20"
"2101.07577","Chen Gao","Siyi Liu, Chen Gao, Yihong Chen, Depeng Jin, Yong Li","Learnable Embedding Sizes for Recommender Systems","International Conference on Learning Representations (ICLR), 2021",,,,"cs.LG cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The embedding-based representation learning is commonly used in deep learning
recommendation models to map the raw sparse features to dense vectors. The
traditional embedding manner that assigns a uniform size to all features has
two issues. First, the numerous features inevitably lead to a gigantic
embedding table that causes a high memory usage cost. Second, it is likely to
cause the over-fitting problem for those features that do not require too large
representation capacity. Existing works that try to address the problem always
cause a significant drop in recommendation performance or suffers from the
limitation of unaffordable training time cost. In this paper, we proposed a
novel approach, named PEP (short for Plug-in Embedding Pruning), to reduce the
size of the embedding table while avoiding the drop of recommendation accuracy.
PEP prunes embedding parameter where the pruning threshold(s) can be adaptively
learned from data. Therefore we can automatically obtain a mixed-dimension
embedding-scheme by pruning redundant parameters for each feature. PEP is a
general framework that can plug in various base recommendation models.
Extensive experiments demonstrate it can efficiently cut down embedding
parameters and boost the base model's performance. Specifically, it achieves
strong recommendation performance while reducing 97-99% parameters. As for the
computation cost, PEP only brings an additional 20-30% time cost compared with
base models. Codes are available at
https://github.com/ssui-liu/learnable-embed-sizes-for-RecSys.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:50:33 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 10:38:59 GMT""}]","2021-03-12"
"2101.07578","Quan Quan","Quan Quan, Rao Fu, Mengxin Li, Donghui Wei, Yan Gao and Kai-Yuan Cai","Practical Distributed Control for VTOL UAVs to Pass a Virtual Tube",,,"10.1109/TIV.2021.3123110",,"cs.RO cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to
amateur and commercial users alike. An air traffic management (ATM) system is
needed to help ensure that this newest entrant into the skies does not collide
with others. In an ATM, airspace can be composed of airways, intersections and
nodes. In this paper, for simplicity, distributed coordinating the motions of
Vertical TakeOff and Landing (VTOL) UAVs to pass an airway is focused. This is
formulated as a virtual tube passing problem, which includes passing a virtual
tube, inter-agent collision avoidance and keeping within the virtual tube.
Lyapunov-like functions are designed elaborately, and formal analysis based on
invariant set theorem is made to show that all UAVs can pass the virtual tube
without getting trapped, avoid collision and keep within the virtual tube. What
is more, by the proposed distributed control, a VTOL UAV can keep away from
another VTOL UAV or return back to the virtual tube as soon as possible, once
it enters into the safety area of another or has a collision with the virtual
tube during it is passing the virtual tube. Simulations and experiments are
carried out to show the effectiveness of the proposed method and the comparison
with other methods.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:52:30 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 18:37:56 GMT""}]","2023-01-25"
"2101.07579","Panagiotis Tigas","Panagiotis Tigas and Tyson Hosmer","Spatial Assembly: Generative Architecture With Reinforcement Learning,
  Self Play and Tree Search","Workshop on Machine Learning for Creativity and Design at the 34rd
  Conference on Neural Information Processing Systems (NeurIPS 2020)",,,,"cs.AI cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  With this work, we investigate the use of Reinforcement Learning (RL) for the
generation of spatial assemblies, by combining ideas from Procedural Generation
algorithms (Wave Function Collapse algorithm (WFC)) and RL for Game Solving.
WFC is a Generative Design algorithm, inspired by Constraint Solving. In WFC,
one defines a set of tiles/blocks and constraints and the algorithm generates
an assembly that satisfies these constraints. Casting the problem of generation
of spatial assemblies as a Markov Decision Process whose states transitions are
defined by WFC, we propose an algorithm that uses Reinforcement Learning and
Self-Play to learn a policy that generates assemblies that maximize objectives
set by the designer. Finally, we demonstrate the use of our Spatial Assembly
algorithm in Architecture Design.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:57:10 GMT""}]","2021-01-20"
"2101.07580","Moritz Brehm","Moritz Brehm","Light-emission from ion-implanted group-IV nanostructures","Silicon Photonics IV: Innovative Frontiers, edited by David J.
  Lockwood and Lorenzo Pavesi, Springer series Topics in Applied Physics (2021)",,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Silicon photonics is destined to revolutionize technological areas, such as
short-distance data transfer and sensing applications by combining the benefits
of integrated optics with the assertiveness of silicon-based microelectronics.
However, the lack of practical and low-cost silicon-based monolithic light
sources such as light-emitting diodes and, in particular, lasers is the main
bottleneck for silicon photonics to become the key technology of the 21st
century. After briefly reviewing the state of the art regarding silicon-based
light-emitters, we discuss the challenges and benefits of a highly flexible
approach: The epitaxial incorporation of group-IV nanostructures into
crystalline silicon. We argue that a paradigm change for group-IV quantum dots
(QDs) can be achieved by the intentional incorporation of extended point
defects inside the QDs upon low energy ion implantation. The superior
light-emission properties from such defect-enhanced quantum dots (DEQDs), our
present understanding of their structural formation and light-emission
mechanisms will be discussed. We will show that useful electrically-driven
devices, such as light-emitting diodes (LEDs) can be fabricated employing
optically active DEQD-material. These LEDs exhibit exceptional
temperature-stability of their light emission properties even up to 100{\deg}C,
unprecedented for purely group-IV-based optoelectronic devices. Thereafter, we
will assess the superior temperature stability of the structural properties of
DEQDs upon thermal annealing, the scalability of the light-emission with the
DEQD density and passivation schemes to further improve the optical properties.
The chapter ends with a discussion of future research directions that will
spark the development of this exciting field even further.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:03:19 GMT""}]","2021-01-20"
"2101.07581","Jiacheng Liu","Jiacheng Liu, Meghna Singh, Catherine ST.Hill, Vino Raj, Lisa
  Kirkland, Jaideep Srivastava","Continual Deterioration Prediction for Hospitalized COVID-19 Patients","8 pages, 11 figures. Submitted to JAMIA in OCT, 2020",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Leading up to August 2020, COVID-19 has spread to almost every country in the
world, causing millions of infected and hundreds of thousands of deaths. In
this paper, we first verify the assumption that clinical variables could have
time-varying effects on COVID-19 outcomes. Then, we develop a temporal
stratification approach to make daily predictions on patients' outcome at the
end of hospital stay. Training data is segmented by the remaining length of
stay, which is a proxy for the patient's overall condition. Based on this, a
sequence of predictive models are built, one for each time segment. Thanks to
the publicly shared data, we were able to build and evaluate prototype models.
Preliminary experiments show 0.98 AUROC, 0.91 F1 score and 0.97 AUPR on
continuous deterioration prediction, encouraging further development of the
model as well as validations on different datasets. We also verify the key
assumption which motivates our method. Clinical variables could have
time-varying effects on COVID-19 outcomes. That is to say, the feature
importance of a variable in the predictive model varies at different disease
stages.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:03:56 GMT""}]","2021-01-20"
"2101.07582","Frank Rathmann","J. Slim, N.N. Nikolaev, F. Rathmann, A. Wirzba, A. Nass, V. Hejny, J.
  Pretz, H. Soltner, F. Abusaif, A. Aggarwal, A. Aksentev, A. Andres, L.
  Barion, G. Ciullo, S. Dymov, R. Gebel, M. Gaisser, K. Grigoryev, D. Grzonka,
  O. Javakhishvili, A. Kacharava, V. Kamerdzhiev, S. Karanth, I. Keshelashvili,
  A. Lehrach, P. Lenisa, N. Lomidze, B. Lorentz, A. Magiera, D. Mchedlishvili,
  F. M\""uller, A. Pesce, V. Poncza, D. Prasuhn, A. Saleev, V. Shmakova,
  H.Str\""oher, M. Tabidze, G. Tagliente, Y. Valdau, T. Wagner, C. Weidemann, A.
  Wro\'nska, M. \.Zurek","First detection of collective oscillations of a stored deuteron beam
  with an amplitude close to the quantum limit","20 pages, 16 figures",,"10.1103/PhysRevAccelBeams.24.124601",,"nucl-ex quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigated coherent betatron oscillations of a deuteron beam in the
storage ring COSY, excited by a detuned radio-frequency Wien filter. The beam
oscillations were detected by conventional beam position monitors. With the
currently available apparatus, we show that oscillation amplitudes down to
\SI{1}{\micro \meter} can be detected. The interpretation of the response of
the stored beam to the detuned radio-frequency Wien filter is based on
simulations of the beam evolution in the lattice of the ring and realistic
time-dependent 3D field maps of the Wien filter. Future measurements of the
electric dipole moment of protons will, however, require control of the
relative position of counter-propagating beams in the sub-picometer range.
Since here the stored beam can be considered as a rarefied gas of uncorrelated
particles, we moreover demonstrate that the amplitudes of the zero-point
(ground state) betatron oscillations of individual particles are only a factor
of about 10 larger than the Heisenberg uncertainty limit. As a consequence of
this, we conclude that quantum mechanics does not preclude the control of the
beam centroids to sub-picometer accuracy. The smallest Lorentz force exerted on
a single particle that we have been able to determine is \SI{10}{aN}.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:07:33 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 11:24:35 GMT""}]","2022-01-05"
"2101.07583","John Wallace","John Wallace and Asaf Pe'er","An Observational Signature of Sub-Equipartition Magnetic Fields in the
  Spectra of Black Hole Binaries","11 pages, 6 figures. Refereed version, accepted for publication in
  ApJ. Corrections to parameters of V404 Cyg and other minor changes","2021 ApJ 916 63","10.3847/1538-4357/ac0721",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A common assumption used in the study of accretion disks is that the magnetic
energy density and the kinetic energy density should be in equipartition. This
assumption relies on the faster growth rate of the magnetic field strength
against the kinetic energy of the particles in the flow, for decreasing radius,
combined with a dissipation mechanism that tends towards equipartition. In this
paper, we examine this assumption by modeling the radio, mm and optical spectra
of several black hole binaries in their quiescent state. We use a standard
two-component disk model, consisting of an inner geometrically thick and
optically thin disk, emitting thermal synchrotron radiation, along with an
outer, thin disk, which radiates as a multicolor blackbody. We find that at the
low accretion rates typical of the quiescent state, the spectral shape is
qualitatively reproduced using magnetic fields that are between 0.1% and 1% of
the equipartition value, considerably smaller than previously thought. We
discuss our findings in view of (1) the launching of jets in these objects,
which is commonly believed to rely on the presence of a strong magnetic field
in the central region of the disk; and (2) the role of magnetic dissipation in
the structure of the inflow.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:09:06 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 10:42:20 GMT""}]","2021-07-30"
"2101.07584","Matthew Barton","M. C. Barton, P. D. Stevenson, A. Rios","Nuclear ground states in a consistent implementation of the
  time-dependent density matrix approach","14 pages, 7 figures, 8 tables","Phys. Rev. C 103, 064304 (2021)","10.1103/PhysRevC.103.064304",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: Time-dependent techniques in nuclear theory often rely on
mean-field or Hartree-Fock descriptions. Beyond mean-field dynamical
calculations within the time-dependent density matrix (TDDM) theory have often
invoked symmetry restrictions and ignored the connection between the mean-field
and the induced interaction. Purpose: We study the ground states obtained in a
TDDM approach for nuclei from $A=12$ to $A=24$, including examples of even and
odd-even nuclei with and without intrinsic deformation. We overcome previous
limitations using three-dimensional simulations and employ density-independent
Skyrme interactions self-consistently. Methods: The correlated ground states
are found starting from the Hartree-Fock solution, by adiabatically including
the beyond-mean-field terms in real time. Results: We find that, within this
approach, correlations are responsible for $\approx 4-5 \%$ of the total
energy. Radii are generally unaffected by the introduction of beyond mean-field
correlations. Large nuclear correlation entropies are associated to large
correlation energies. By all measures, $^{12}$C is the most correlated isotope
in the mass region considered. Conclusions: Our work is the starting point of a
consistent implementation of the TDDM technique for applications into nuclear
reactions. Our results indicate that correlation effects in structure are
small, but beyond-mean-field dynamical simulations could provide new insight
into several issues of interest.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:09:25 GMT""}]","2021-06-09"
"2101.07585","Matteo Baggioli","Matteo Baggioli, Alessio Zaccone","Explaining the specific heat of liquids based on instantaneous normal
  modes","v2: fitting analysis extended and improved","Phys. Rev. E 104, 014103 (2021)","10.1103/PhysRevE.104.014103",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The successful prediction of the specific heat of solids is a milestone in
the kinetic theory of matter, due to Debye (1912). No such success, however,
has ever been obtained for the specific heat of liquids, which has remained a
mystery for over a century. A theory of specific heat of liquids is derived
here using a recently proposed analytical form of the vibrational density of
states (DOS) of liquids, which takes into account saddle points in the liquid
energy landscape via the so-called instantaneous normal modes (INMs),
corresponding to negative eigenvalues (imaginary frequencies) of the Hessian
matrix. The theory is able to explain the typical monotonic decrease of
specific heat with temperature observed in liquids, in terms of the average INM
excitation lifetime decreasing with T (in accordance with Arrehnius law), and
provides an excellent single-parameter fitting to several sets of experimental
data for atomic and molecular liquids. It also correlates the height of the
liquid energy barrier with the slope of the specific heat in function of
temperature in accordance with the available data. These findings demonstrate
that the specific heat of liquids is controlled by the instantaneous normal
modes, i.e. by localized, unstable (exponentially decaying) vibrational
excitations, and provide the missing connection between anharmonicity, saddle
points in the energy landscape, and the thermodynamics of liquids.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:11:41 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 13:09:29 GMT""}]","2021-07-14"
"2101.07586","Weilong Kong","Weilong Kong, Tong Yang, Jun Zhou, Yong Zheng Luo, Jingsheng Chen, Lei
  Shen, Yong Jiang, Yuan Ping Feng, and Ming Yang","Tunable Rashba spin-orbit coupling and its interplay with multiorbital
  effect and magnetic ordering at oxide interfaces","24 pages, 4 figures",,"10.1103/PhysRevB.104.155152",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The complex oxide heterostructures such as LaAlO3/SrTiO3 (LAO/STO) interface
are paradigmatic platforms to explore emerging multi-degrees of freedom
coupling and the associated exotic phenomena. In this study, we reveal the
effects of multiorbital and magnetic ordering on Rashba spin-orbit coupling
(SOC) at the LAO/STO (001) interface. Based on first-principles calculations,
we show that the Rashba spin splitting near the conduction band edge can be
tuned substantially by the interfacial insulator-metal transition due to the
multiorbital effect of the lowest t_2g bands. We further unravel a competition
between Rashba SOC and intrinsic magnetism, in which the Rashba SOC induced
spin polarization is suppressed by the interfacial magnetic ordering. These
results deepen our understanding of intricate electronic and magnetic
reconstruction at the perovskite oxide interfaces and shed light on the
engineering of oxide heterostructures for all-oxides-based spintronic devices.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:16:56 GMT""}]","2021-11-10"
"2101.07587","Svante Janson","Svante Janson and Sofia Olhede","Can smooth graphons in several dimensions be represented by smooth
  graphons on $[0,1]$?","6 pages",,,,"math.CO math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A graphon that is defined on $[0,1]^d$ and is H\""older$(\alpha)$ continuous
for some $d\ge2$ and $\alpha\in(0,1]$ can be represented by a graphon on
$[0,1]$ that is H\""older$(\alpha/d)$ continuous. We give examples that show
that this reduction in smoothness to $\alpha/d$ is the best possible, for any
$d$ and $\alpha$; for $\alpha=1$, the example is a dot product graphon and
shows that the reduction is the best possible even for graphons that are
polynomials.
  A motivation for studying the smoothness of graphon functions is that this
represents a key assumption in non-parametric statistical network analysis. Our
examples show that making a smoothness assumption in a particular dimension is
not equivalent to making it in any other latent dimension.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:17:01 GMT""}]","2021-01-20"
"2101.07588","Boning Di","Boning Di, Qianjun He, Dunyan Yan","Two-weight Norm Inequalities for Local Fractional Integrals on Gaussian
  Measure Spaces","25 pages, 2 figures",,"10.1007/s10114-022-1114-6",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the authors establish the two-weight boundedness of the local
fractional maximal operators and local fractional integrals on Gaussian measure
spaces associated with the local weights. More precisely, the authors first
obtain the two-weight weak-type estimate for the local-$a$ fractional maximal
operators of order $\alpha$ from $L^{p}(v)$ to $L^{q,\infty}(u)$ with $1\leq
p\leq q<\infty$ under a condition of $(u,v)\in \bigcup_{b'>a}
A_{p,q,\alpha}^{b'}$, and then obtain the two-weight weak-type estimate for the
local fractional integrals. In addition, the authors obtain the two-weight
strong-type boundedness of the local fractional maximal operators under a
condition of $(u,v)\in\mathscr{M}_{p,q,\alpha}^{6a+9\sqrt{d}a^2}$ and the
two-weight strong-type boundedness of the local fractional integrals. These
estimates are established by the radialization method and dyadic approach.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:19:46 GMT""}]","2022-08-31"
"2101.07589","Dengxin Dai","Ke Li, Dengxin Dai, Ender Konukoglu, Luc Van Gool","Hyperspectral Image Super-Resolution with Spectral Mixup and
  Heterogeneous Datasets","16 pages, 14 tables, 5 figures; Code available at
  https://github.com/kli8996/HSISR",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies Hyperspectral image (HSI) super-resolution (SR). HSI SR is
characterized by high-dimensional data and a limited amount of training
examples. This exacerbates the undesirable behaviors of neural networks such as
memorization and sensitivity to out-of-distribution samples. This work
addresses these issues with three contributions. First, we observe that HSI SR
and RGB image SR are correlated and develop a novel multi-tasking network to
train them jointly so that the auxiliary task RGB image SR can provide
additional supervision. Second, we propose a simple, yet effective data
augmentation routine, termed Spectral Mixup, to construct effective virtual
training samples to enlarge the training set. Finally, we extend the network to
a semi-supervised setting so that it can learn from datasets containing only
low-resolution HSIs. With these contributions, our method is able to learn from
heterogeneous datasets and lift the requirement for having a large amount of HD
HSI training samples. Extensive experiments on four standard datasets show that
our method outperforms existing methods significantly and underpin the
relevance of our contributions. Code has been made available at
https://github.com/kli8996/HSISR.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:19:53 GMT""},{""version"":""v2"",""created"":""Sat, 3 Apr 2021 11:00:44 GMT""}]","2021-04-06"
"2101.07590","Orr Fischer","Keren Censor-Hillel, Orr Fischer, Tzlil Gonen, Fran\c{c}ois Le Gall,
  Dean Leitersdorf, Rotem Oshman","Fast Distributed Algorithms for Girth, Cycles and Small Subgraphs",,,,,"cs.DS cs.DC","http://creativecommons.org/licenses/by/4.0/","  In this paper we give fast distributed graph algorithms for detecting and
listing small subgraphs, and for computing or approximating the girth. Our
algorithms improve upon the state of the art by polynomial factors, and for
girth, we obtain an constant-time algorithm for additive +1 approximation in
the Congested Clique, and the first parametrized algorithm for exact
computation in CONGEST.
  In the Congested Clique, we develop a technique for learning small
neighborhoods, and apply it to obtain an $O(1)$-round algorithm that computes
the girth with only an additive +1 error. Next, we introduce a new technique
(the partition tree technique) allowing for efficiently and deterministically
listing all copies of any subgraph, improving upon the state-of the-art for
non-dense graphs. We give two applications of this technique: First we show
that for constant $k$, $C_{2k}$-detection can be solved in $O(1)$ rounds in the
Congested Clique, improving on prior work which used matrix multiplication and
had polynomial round complexity. Second, we show that in triangle-free graphs,
the girth can be exactly computed in time polynomially faster than the best
known bounds for general graphs.
  In CONGEST, we describe a new approach for finding cycles, and apply it in
two ways: first we show a fast parametrized algorithm for girth with round
complexity $\tilde{O}(\min(g\cdot n^{1-1/\Theta(g)},n))$ for any girth $g$; and
second, we show how to find small even-length cycles $C_{2k}$ for $k = 3,4,5$
in $O(n^{1-1/k})$ rounds, which is a polynomial improvement upon the previous
running times.
  Finally, using our improved $C_6$-freeness algorithm and the barrier on
proving lower bounds on triangle-freeness of Eden et al., we show that
improving the current $\tilde\Omega(\sqrt{n})$ lower bound for $C_6$-freeness
of Korhonen et al. by any polynomial factor would imply strong circuit
complexity lower bounds.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:29:24 GMT""}]","2021-01-20"
"2101.07591","Setianto Setianto","Setianto Setianto, Liu Kin Men, Camellia Panatarani, and I Made Joni","Visualization the electrostatic potential energy map of graphene quantum
  dots","2nd International Conference and Exhibition on Powder Technology
  (ICePTi) 2019",,"10.1063/5.0003019",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphene quantum dots (GQDs) represent single layers up to dozens of graphene
layers smaller than 30 nm. GQDs are newish molecules that have aroused great
interest in research because of their exceptional and manageable optical,
electrical, chemical, and structural properties. In this work, we report
electrostatic potential energy maps, or molecular electrostatic potential
surfaces, illustrate the charge distributions of GQDs three-dimensionally.
Knowledge of the charge distributions can be used to determine how GQDs
interact with one another. To analyze the distribution of molecular charges
accurately, a large number of electrostatic potential energy values must be
calculated. The best way to transmit these data is to visualize them as in the
electrostatic potential map. A ZINDO semi-empirical quantum chemistry method
then imposes the calculated data onto an electron density model of the GQDs
derived from the Schr\""odinger equation. To make the electrostatic potential
energy data of GQDs easy to interpret, a color spectrum, with red as the lowest
electrostatic potential energy value and blue as the highest, is employed to
convey the varying intensities of the electrostatic potential energy values.
The results of the four GQD models suggest that the energy of the ionization
potential lies in a range of -7.20 eV to -5.31 eV and the electron affinity is
-2.65 to -0.24 eV.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:31:27 GMT""}]","2021-01-20"
"2101.07592","Axel Laborieux","Axel Laborieux, Maxence Ernoult, Tifenn Hirtzlin and Damien Querlioz","Synaptic metaplasticity in binarized neural networks","3 pages, 1 figure","Computational and Systems Neuroscience (Cosyne) 2021","10.1038/s41467-021-22768-y",,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  Unlike the brain, artificial neural networks, including state-of-the-art deep
neural networks for computer vision, are subject to ""catastrophic forgetting"":
they rapidly forget the previous task when trained on a new one. Neuroscience
suggests that biological synapses avoid this issue through the process of
synaptic consolidation and metaplasticity: the plasticity itself changes upon
repeated synaptic events. In this work, we show that this concept of
metaplasticity can be transferred to a particular type of deep neural networks,
binarized neural networks, to reduce catastrophic forgetting.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:32:07 GMT""}]","2021-06-09"
"2101.07593","Carlo Sanna","Carlo Sanna","Additive bases and Niven numbers",,,"10.1017/S0004972721000186",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $g \geq 2$ be an integer. A natural number is said to be a base-$g$ Niven
number if it is divisible by the sum of its base-$g$ digits. Assuming Hooley's
Riemann Hypothesis, we prove that the set of base-$g$ Niven numbers is an
additive basis, that is, there exists a positive integer $C_g$ such that every
natural number is the sum of at most $C_g$ base-$g$ Niven numbers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:34:57 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 12:44:26 GMT""}]","2021-07-01"
"2101.07594","Ken Deng","Ken Deng, Chang Sun, Yitong Liu, Hongwen Yang","Real-Time Limited-View CT Inpainting and Reconstruction with Dual Domain
  Based on Spatial Information",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Low-dose Computed Tomography is a common issue in reality. Current reduction,
sparse sampling and limited-view scanning can all cause it. Between them,
limited-view CT is general in the industry due to inevitable mechanical and
physical limitation. However, limited-view CT can cause serious imaging problem
on account of its massive information loss. Thus, we should effectively utilize
the scant prior information to perform completion. It is an undeniable fact
that CT imaging slices are extremely dense, which leads to high continuity
between successive images. We realized that fully exploit the spatial
correlation between consecutive frames can significantly improve restoration
results in video inpainting. Inspired by this, we propose a deep learning-based
three-stage algorithm that hoist limited-view CT imaging quality based on
spatial information. In stage one, to better utilize prior information in the
Radon domain, we design an adversarial autoencoder to complement the Radon
data. In the second stage, a model is built to perform inpainting based on
spatial continuity in the image domain. At this point, we have roughly restored
the imaging, while its texture still needs to be finely repaired. Hence, we
propose a model to accurately restore the image in stage three, and finally
achieve an ideal inpainting result. In addition, we adopt FBP instead of
SART-TV to make our algorithm more suitable for real-time use. In the
experiment, we restore and reconstruct the Radon data that has been cut the
rear one-third part, they achieve PSNR of 40.209, SSIM of 0.943, while
precisely present the texture.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:42:58 GMT""}]","2021-01-20"
"2101.07595","Ariando","J.X. Hu, J. Gou, M. Yang, G. J. Omar, J. Y. Tan, S. W. Zeng, Y. P.
  Liu, K. Han, Z. S. Lim, Z. Huang, A. T. S. Wee, A. Ariando","Room-temperature colossal magnetoresistance in terraced single-layer
  graphene","64 pages; Main 31 pages, 4 figures; Supplementary 33 pages, 18
  figures","Advanced Materials 32, 2002201 (2020)","10.1002/adma.202002201",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Disorder-induced magnetoresistance (MR) effect is quadratic at low
perpendicular magnetic fields and linear at high fields. This effect is
technologically appealing, especially in the two-dimensional (2D) materials
such as graphene, since it offers potential applications in magnetic sensors
with nanoscale spatial resolution. However, it is a great challenge to realize
a graphene magnetic sensor based on this effect because of the difficulty in
controlling the spatial distribution of disorder and enhancing the MR
sensitivity in the single-layer regime. Here, we report a room-temperature
colossal MR of up to 5,000% at 9 T in terraced single-layer graphene. By
laminating single-layer graphene on a terraced substrate, such as TiO2
terminated SrTiO3, we demonstrate a universal one order of magnitude
enhancement in the MR compared to conventional single-layer graphene devices.
Strikingly, a colossal MR of >1,000% was also achieved in the terraced graphene
even at a high carrier density of ~1012 cm-2. Systematic studies of the MR of
single-layer graphene on various oxide- and non-oxide-based terraced surfaces
demonstrate that the terraced structure is the dominant factor driving the MR
enhancement. Our results open a new route for tailoring the physical property
of 2D materials by engineering the strain through a terraced substrate.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:51:01 GMT""}]","2021-01-20"
"2101.07596","Ziyue Wang","Shile Chen, Ziyue Wang, and Pengfei Zhuang","Equal-time kinetic equations in a rotational field","12 pages",,"10.1088/1674-1137/ac39fd",,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We investigate quantum kinetic theory for a massive fermion system under a
rotational field. From the Dirac equation in curved space we derive the
complete set of kinetic equations for the spin components of the covariant and
equal-time Wigner functions. While the particles are no longer on a mass shell
in general case due to the rotation-spin coupling, there are always only two
independent components, which can be taken as the number and spin densities.
With the help from the off-shell constraint we obtain the closed transport
equations for the two independent components in classical limit and at quantum
level. The classical rotation-orbital coupling controls the dynamical evolution
of the number density, but the quantum rotation-spin coupling explicitly
changes the spin density.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:52:14 GMT""}]","2022-11-09"
"2101.07597","Chengyi Wang","Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei,
  Michael Zeng and Xuedong Huang","UniSpeech: Unified Speech Representation Learning with Labeled and
  Unlabeled Data","accepted by ICML2021",,,,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a unified pre-training approach called UniSpeech to
learn speech representations with both unlabeled and labeled data, in which
supervised phonetic CTC learning and phonetically-aware contrastive
self-supervised learning are conducted in a multi-task learning manner. The
resultant representations can capture information more correlated with phonetic
structures and improve the generalization across languages and domains. We
evaluate the effectiveness of UniSpeech for cross-lingual representation
learning on public CommonVoice corpus. The results show that UniSpeech
outperforms self-supervised pretraining and supervised transfer learning for
speech recognition by a maximum of 13.4% and 17.8% relative phone error rate
reductions respectively (averaged over all testing languages). The
transferability of UniSpeech is also demonstrated on a domain-shift speech
recognition task, i.e., a relative word error rate reduction of 6% against the
previous approach.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:53:43 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 09:17:28 GMT""}]","2021-06-11"
"2101.07598","Sergei Koltcov","Sergei Koltcov, Vera Ignatenko, Maxim Terpilovskii, Paolo Rosso","Analysis and tuning of hierarchical topic models based on Renyi entropy
  approach",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hierarchical topic modeling is a potentially powerful instrument for
determining the topical structure of text collections that allows constructing
a topical hierarchy representing levels of topical abstraction. However, tuning
of parameters of hierarchical models, including the number of topics on each
hierarchical level, remains a challenging task and an open issue. In this
paper, we propose a Renyi entropy-based approach for a partial solution to the
above problem. First, we propose a Renyi entropy-based metric of quality for
hierarchical models. Second, we propose a practical concept of hierarchical
topic model tuning tested on datasets with human mark-up. In the numerical
experiments, we consider three different hierarchical models, namely,
hierarchical latent Dirichlet allocation (hLDA) model, hierarchical Pachinko
allocation model (hPAM), and hierarchical additive regularization of topic
models (hARTM). We demonstrate that hLDA model possesses a significant level of
instability and, moreover, the derived numbers of topics are far away from the
true numbers for labeled datasets. For hPAM model, the Renyi entropy approach
allows us to determine only one level of the data structure. For hARTM model,
the proposed approach allows us to estimate the number of topics for two
hierarchical levels.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:54:47 GMT""}]","2021-01-20"
"2101.07599","Timoth\'ee Anne","Timoth\'ee Anne, Jack Wilkinson, Zhibin Li","Meta-Reinforcement Learning for Adaptive Motor Control in Changing Robot
  Dynamics and Environments",,,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work developed a meta-learning approach that adapts the control policy
on the fly to different changing conditions for robust locomotion. The proposed
method constantly updates the interaction model, samples feasible sequences of
actions of estimated the state-action trajectories, and then applies the
optimal actions to maximize the reward. To achieve online model adaptation, our
proposed method learns different latent vectors of each training condition,
which are selected online given the newly collected data. Our work designs
appropriate state space and reward functions, and optimizes feasible actions in
an MPC fashion which are then sampled directly in the joint space considering
constraints, hence requiring no prior design of specific walking gaits. We
further demonstrate the robot's capability of detecting unexpected changes
during interaction and adapting control policies quickly. The extensive
validation on the SpotMicro robot in a physics simulation shows adaptive and
robust locomotion skills under varying ground friction, external pushes, and
different robot models including hardware faults and changes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:57:12 GMT""}]","2021-01-20"
"2101.07600","Ricards Marcinkevics","Ri\v{c}ards Marcinkevi\v{c}s, Julia E. Vogt","Interpretable Models for Granger Causality Using Self-explaining Neural
  Networks","ICLR 2021",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Exploratory analysis of time series data can yield a better understanding of
complex dynamical systems. Granger causality is a practical framework for
analysing interactions in sequential data, applied in a wide range of domains.
In this paper, we propose a novel framework for inferring multivariate Granger
causality under nonlinear dynamics based on an extension of self-explaining
neural networks. This framework is more interpretable than other
neural-network-based techniques for inferring Granger causality, since in
addition to relational inference, it also allows detecting signs of
Granger-causal effects and inspecting their variability over time. In
comprehensive experiments on simulated data, we show that our framework
performs on par with several powerful baseline methods at inferring Granger
causality and that it achieves better performance at inferring interaction
signs. The results suggest that our framework is a viable and more
interpretable alternative to sparse-input neural networks for inferring Granger
causality.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:59:00 GMT""}]","2021-01-20"
"2101.07601","Laura Dreissen","L.S. Dreissen, C. Roth, E.L. Gr\""undeman, J.J. Krauth, M.G.J. Favier,
  and K.S.E. Eikema","Demonstration of Ramsey-Comb Precision Spectroscopy in Xenon at Vacuum
  Ultraviolet Wavelengths Produced with High-Harmonic Generation",,"Phys. Rev. A 101, 052509 (2020)","10.1103/PhysRevA.101.052509",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The remarkable progress in the field of laser spectroscopy induced by the
invention of the frequency-comb laser has enabled many new high-precision tests
of fundamental theory and searches for new physics. Extending frequency-comb
based spectroscopy techniques to the vacuum (VUV) and extreme ultraviolet (XUV)
spectral range would enable measurements in e.g. heavier hydrogen-like systems
and open up new possibilities for tests of quantum electrodynamics and
measurements of fundamental constants. The main approaches rely on
high-harmonic generation (HHG), which is known to induce spurious phase shifts
from plasma formation. After our initial report (Physical Review Letters 123,
143001 (2019)), we give a detailed account of how the Ramsey-comb technique is
used to probe the plasma dynamics with high precision, and enables accurate
spectroscopy in the VUV. A series of Ramsey fringes is recorded to track the
phase evolution of a superposition state in xenon atoms, excited by two
up-converted frequency-comb pulses. Phase shifts of up to 1 rad induced by HHG
were observed at ns timescales and with mrad-level accuracy at $110$ nm. Such
phase shifts could be reduced to a negligible level, enabling us to measure the
$5p^6 \rightarrow 5p^5 8s~^2[3/2]_1$ transition frequency in $^{132}Xe$ at 110
nm (seventh harmonic) with sub-MHz accuracy. The obtained value is $10^4$ times
more precise than the previous determination and the fractional accuracy of
$2.3 \times 10^{-10}$ is $3.6$ times better than the previous best
spectroscopic measurement using HHG. The isotope shifts between $^{132}Xe$ and
two other isotopes were determined with an accuracy of $420$ kHz. The method
can be readily extended to achieve kHz-level accuracy, e.g. to measure the
$1S-2S$ transition in $He^+$. Therefore, the Ramsey-comb method shows great
promise for high-precision spectroscopy of targets requiring VUV and XUV
wavelengths.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:59:04 GMT""}]","2021-01-20"
"2101.07602","Pavlos Lagoudakis Prof","I. Gnusov, H. Sigurdsson, J. Toepfer, S. Baryshev, S. Alyatkin and P.
  Lagoudakis","All-optical linear polarization engineering in single and coupled
  exciton-polariton condensates",,"Phys. Rev. Applied 16, 034014 (2021)","10.1103/PhysRevApplied.16.034014",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We demonstrate all-optical linear polarization control of exciton-polariton
condensates in anisotropic elliptical optical traps. The cavity inherent TE-TM
splitting lifts the ground state spin degeneracy with emerging fine structure
modes polarized linear parallel and perpendicular to the trap major axis with
the condensate populating the latter. Our findings show a new type of
polarization control with exciting perspectives in both spinoptronics and
studies on extended systems of interacting nonlinear optical elements with
anisotropic coupling strength and adjustable fine structure.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:59:08 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 10:38:00 GMT""}]","2021-09-15"
"2101.07603","Kiryl Piasotski","Kiryl Piasotski and Mikhail Pletyukhov","Diagrammatic Approach to Scattering of Multi-Photon States in Waveguide
  QED",,"Phys. Rev. A 104, 023709 (2021)","10.1103/PhysRevA.104.023709",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We give an exposure to diagrammatic techniques in waveguide QED systems. A
particular emphasis is placed on the systems with delayed coherent quantum
feedback. Specifically, we show that the $N$-photon scattering matrices in
single-qubit waveguide QED systems, within the rotating wave approximation,
admit for a parametrization in terms of $N-1$-photon effective vertex functions
and provide a detailed derivation of a closed hierarchy of generalized
Bethe-Salpeter equations satisfied by these vertex functions. The advantage of
this method is that the above mentioned integral equations hold independently
of the number of radiation channels, their bandwidth, the dispersion of the
modes they are supporting, and the structure of the radiation-qubit coupling
interaction, thus enabling one to study multi-photon scattering problems beyond
the Born-Markov approximation. Further, we generalize the diagrammatic
techniques to the systems containing more than a single emitter by presenting
an exact set of equations governing the generic two and three-photon scattering
operators. The above described theoretical machinery is then showcased on the
example of a three-photon scattering on a giant acoustic atom, recently studied
experimentally [Nat. Phys. 15, 1123 (2019)].
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:00:35 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 14:12:56 GMT""}]","2021-09-01"
"2101.07604","Nhu Nguyen","Nhu N. Nguyen","Exponential tightness of a family of Skorohod integrals",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exponential tightness of a family of Skorohod integrals is studied in this
paper. We first provide a counterexample to illustrate that in general the
exponential tightness with speed $\epsilon$ similar to It\^o integral does not
hold, even for any speed $\epsilon^\alpha$ with $\alpha > 0$. Then, some
characterizations of this subject are given. Application is also provided to
illustrate the proposed results.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:01:28 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 15:47:49 GMT""}]","2021-07-13"
"2101.07605","Alexandre Jeanneau","Alexandre Jeanneau, Johan Kosmalski, Eduard Muslimov, Emmanuel Hugot,
  Roland Bacon, Johan Richard","Curved detector-based optical design for the VLT/BlueMUSE instrument",,"Proc. SPIE 11447, Ground-based and Airborne Instrumentation for
  Astronomy VIII, 114475M (13 December 2020)","10.1117/12.2561684",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  BlueMUSE (Blue Multi Unit Spectroscopic Explorer) is a blue-optimised, medium
spectral resolution, panoramic integral field spectrograph proposed for the
Very Large Telescope (VLT) and based on the MUSE concept. BlueMUSE will open up
a new range of galactic and extragalactic science cases allowed by its specific
capabilities in the 350 - 580 nm range: an optimised end-to-end transmission
down to 350 nm, a larger FoV (up to $1.4 \times 1.4$ arcmin$^2$) sampled at 0.3
arcsec, and a higher spectral resolution ($\lambda/\Delta \lambda \sim 3500$)
compared to MUSE. To our knowledge, achieving such capabilities with a
comparable mechanical footprint and an identical detector format ($4\text{k}
\times 4\text{k}$, 15 $\mathrm{\mu m}$ CCD) would not be possible with a
conventional spectrograph design. In this paper, we present the optomechanical
architecture and design of BlueMUSE at pre-phase A level, with a particular
attention to some original aspects such as the use of curved detectors.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:07:31 GMT""}]","2021-01-20"
"2101.07606","Viraj Kulkarni","Tanveer Gupte, Mrunmai Niljikar, Manish Gawali, Viraj Kulkarni, Amit
  Kharat, Aniruddha Pant","Deep Learning Models for Calculation of Cardiothoracic Ratio from Chest
  Radiographs for Assisted Diagnosis of Cardiomegaly","6 pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose an automated method based on deep learning to compute the
cardiothoracic ratio and detect the presence of cardiomegaly from chest
radiographs. We develop two separate models to demarcate the heart and chest
regions in an X-ray image using bounding boxes and use their outputs to
calculate the cardiothoracic ratio. We obtain a sensitivity of 0.96 at a
specificity of 0.81 with a mean absolute error of 0.0209 on a held-out test
dataset and a sensitivity of 0.84 at a specificity of 0.97 with a mean absolute
error of 0.018 on an independent dataset from a different hospital. We also
compare three different segmentation model architectures for the proposed
method and observe that Attention U-Net yields better results than SE-Resnext
U-Net and EfficientNet U-Net. By providing a numeric measurement of the
cardiothoracic ratio, we hope to mitigate human subjectivity arising out of
visual assessment in the detection of cardiomegaly.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:09:29 GMT""}]","2021-01-20"
"2101.07607","Pierpaolo De Blasi","Pierpaolo De Blasi, Rams\'es H. Mena, Igor Pr\""unster","Asymptotic behavior of the number of distinct values in a sample from
  the geometric stick-breaking process","20 pages",,,,"math.ST math.PR stat.TH","http://creativecommons.org/licenses/by/4.0/","  Discrete random probability measures are a key ingredient of Bayesian
nonparametric inferential procedures. A sample generates ties with positive
probability and a fundamental object of both theoretical and applied interest
is the corresponding random number of distinct values. The growth rate can be
determined from the rate of decay of the small frequencies implying that, when
the decreasingly ordered frequencies admit a tractable form, the asymptotics of
the number of distinct values can be conveniently assessed. We focus on the
geometric stick-breaking process and we investigate the effect of the choice of
the distribution for the success probability on the asymptotic behavior of the
number of distinct values. We show that a whole range of logarithmic behaviors
are obtained by appropriately tuning the prior. We also derive a two-term
expansion and illustrate its use in a comparison with a larger family of
discrete random probability measures having an additional parameter given by
the scale of the negative binomial distribution.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:09:36 GMT""}]","2021-01-20"
"2101.07608","Urban Larsson Dr","Douglas E. Iannucci and Urban Larsson","Game values of arithmetic functions","20 pages, 4 figures",,,,"math.NT cs.DM math.CO","http://creativecommons.org/licenses/by/4.0/","  Arithmetic functions in Number Theory meet the Sprague-Grundy function from
Combinatorial Game Theory. We study a variety of 2-player games induced by
standard arithmetic functions, such as Euclidian division, divisors, remainders
and relatively prime numbers, and their negations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:17:59 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 05:54:05 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jul 2021 12:20:20 GMT""}]","2021-07-06"
"2101.07609","Chengzhi Zhang","Shutian Ma, Heng Zhang, Chengzhi Zhang, Xiaozhong Liu","Chronological Citation Recommendation with Time Preference",,,,,"cs.IR cs.CL","http://creativecommons.org/licenses/by/4.0/","  Citation recommendation is an important task to assist scholars in finding
candidate literature to cite. Traditional studies focus on static models of
recommending citations, which do not explicitly distinguish differences between
papers that are caused by temporal variations. Although, some researchers have
investigated chronological citation recommendation by adding time related
function or modeling textual topics dynamically. These solutions can hardly
cope with function generalization or cold-start problems when there is no
information for user profiling or there are isolated papers never being cited.
With the rise and fall of science paradigms, scientific topics tend to change
and evolve over time. People would have the time preference when citing papers,
since most of the theoretical basis exist in classical readings that published
in old time, while new techniques are proposed in more recent papers. To
explore chronological citation recommendation, this paper wants to predict the
time preference based on user queries, which is a probability distribution of
citing papers published in different time slices. Then, we use this time
preference to re-rank the initial citation list obtained by content-based
filtering. Experimental results demonstrate that task performance can be
further enhanced by time preference and it's flexible to be added in other
citation recommendation frameworks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:18:05 GMT""}]","2021-01-20"
"2101.07610","Jack Tyler","Jack Tyler and Alexander Wittig","On Asteroid Retrieval Missions Enabled by Invariant Manifold Dynamics","Updated to the accepted manuscript; to be published in Acta
  Astronautica (2021)",,"10.1016/j.actaastro.2021.03.002",,"astro-ph.EP astro-ph.IM math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, the retrieval of entire asteroids has received significant
attention, with many approaches leveraging the invariant manifolds of the
Circular-Restricted Three-body Problem to capture an asteroid into a periodic
orbit about the $L_1$ or $L_2$ points of the Sun-Earth system. Previous works
defined an `Easily Retrievable Object' (ERO) as any Near-Earth Object (NEO)
which is retrievable using these invariant manifolds with an impulsive $\Delta
v$ of less than $500$ m/s. We extend the previous literature by analysing the
Pareto fronts for the EROs discovered for the first time, using
high-performance computing to lift optimisation constraints used in previous
literature, and modifying the method used to filter unsuitable NEOs from the
NEO catalogue. In doing so, we can demonstrate that EROs have approximately the
same transfer cost for almost any possible transfer time, including
single-impulse transfers, which could offer significant flexibility to mission
designers. We also identify $44$ EROs, of which $27$ are new, and improve on
previously-known transfer solutions by up to $443$ m/s, including $17$ new
capture trajectories with $\Delta v$ costs of less than $100$ m/s.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:19:53 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 15:00:35 GMT""}]","2021-03-24"
"2101.07611","Jan Naudts","Jan Naudts","Exponential arcs in the manifold of vector states on a sigma-finite von
  Neumann algebra","31 pages A4, extends and replaces arXiv:1901.06267","Inf0. Geo. (2022)","10.1007/s41884-021-00064-4",,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the notion of exponential arcs in Hilbert space and of
exponential arcs connecting vector states on a sigma-finite von Neumann algebra
in its standard representation. Results from Tomita-Takesaki theory form an
essential ingredient. Starting point is a non-commutative Radon-Nikodym theorem
that involves positive operators affiliated with the commutant algebra. It is
shown that exponential arcs are differentiable and that parts of an exponential
arc are again exponential arcs. Special cases of probability theory and of
quantum probability are used to illustrate the approach.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:20:46 GMT""}]","2022-01-06"
"2101.07612","Viraj Kulkarni","Abhishek Shivdeo, Rohit Lokwani, Viraj Kulkarni, Amit Kharat,
  Aniruddha Pant","Comparative Evaluation of 3D and 2D Deep Learning Techniques for
  Semantic Segmentation in CT Scans","9 pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Image segmentation plays a pivotal role in several medical-imaging
applications by assisting the segmentation of the regions of interest. Deep
learning-based approaches have been widely adopted for semantic segmentation of
medical data. In recent years, in addition to 2D deep learning architectures,
3D architectures have been employed as the predictive algorithms for 3D medical
image data. In this paper, we propose a 3D stack-based deep learning technique
for segmenting manifestations of consolidation and ground-glass opacities in 3D
Computed Tomography (CT) scans. We also present a comparison based on the
segmentation results, the contextual information retained, and the inference
time between this 3D technique and a traditional 2D deep learning technique. We
also define the area-plot, which represents the peculiar pattern observed in
the slice-wise areas of the pathology regions predicted by these deep learning
models. In our exhaustive evaluation, 3D technique performs better than the 2D
technique for the segmentation of CT scans. We get dice scores of 79% and 73%
for the 3D and the 2D techniques respectively. The 3D technique results in a 5X
reduction in the inference time compared to the 2D technique. Results also show
that the area-plots predicted by the 3D model are more similar to the ground
truth than those predicted by the 2D model. We also show how increasing the
amount of contextual information retained during the training can improve the
3D model's performance.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:23:43 GMT""}]","2021-01-20"
"2101.07613","Ken Deng","Yitong Liu, Ken Deng, Chang Sun, Hongwen Yang","A Lightweight Structure Aimed to Utilize Spatial Correlation for
  Sparse-View CT Reconstruction",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Sparse-view computed tomography (CT) is known as a widely used approach to
reduce radiation dose while accelerating imaging through lowered projection
views and correlated calculations. However, its severe imaging noise and
streaking artifacts turn out to be a major issue in the low dose protocol. In
this paper, we propose a dual-domain deep learning-based method that breaks
through the limitations of currently prevailing algorithms that merely process
single image slices. Since the scanned object usually contains a high degree of
spatial continuity, the obtained consecutive imaging slices embody rich
information that is largely unexplored. Therefore, we establish a cascade model
named LS-AAE which aims to tackle the above problem. In addition, in order to
adapt to the social trend of lightweight medical care, our model adopts the
inverted residual with linear bottleneck in the module design to make it mobile
and lightweight (reduce model parameters to one-eighth of its original) without
sacrificing its performance. In our experiments, sparse sampling is conducted
at intervals of 4{\deg}, 8{\deg} and 16{\deg}, which appears to be a
challenging sparsity that few scholars have attempted before. Nevertheless, our
method still exhibits its robustness and achieves the state-of-the-art
performance by reaching the PSNR of 40.305 and the SSIM of 0.948, while
ensuring high model mobility. Particularly, it still exceeds other current
methods when the sampling rate is one-fourth of them, thereby demonstrating its
remarkable superiority.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:26:17 GMT""}]","2021-01-20"
"2101.07614","Chengzhi Zhang","Chengzhi Zhang, Lifan Liu, Yuzhuo Wang","Characterizing References from Different Disciplines: A Perspective of
  Citation Content Analysis",,,,,"cs.DL cs.CL","http://creativecommons.org/licenses/by/4.0/","  Multidisciplinary cooperation is now common in research since social issues
inevitably involve multiple disciplines. In research articles, reference
information, especially citation content, is an important representation of
communication among different disciplines. Analyzing the distribution
characteristics of references from different disciplines in research articles
is basic to detecting the sources of referred information and identifying
contributions of different disciplines. This work takes articles in PLoS as the
data and characterizes the references from different disciplines based on
Citation Content Analysis (CCA). First, we download 210,334 full-text articles
from PLoS and collect the information of the in-text citations. Then, we
identify the discipline of each reference in these academic articles. To
characterize the distribution of these references, we analyze three
characteristics, namely, the number of citations, the average cited intensity
and the average citation length. Finally, we conclude that the distributions of
references from different disciplines are significantly different. Although
most references come from Natural Science, Humanities and Social Sciences play
important roles in the Introduction and Background sections of the articles.
Basic disciplines, such as Mathematics, mainly provide research methods in the
articles in PLoS. Citations mentioned in the Results and Discussion sections of
articles are mainly in-discipline citations, such as citations from Nursing and
Medicine in PLoS.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:30:00 GMT""}]","2021-01-20"
"2101.07615","Ulrich Ellwanger","Ulrich Ellwanger","Weyl Consistency Conditions from a local Wilsonian Cutoff","22 pages, Sections 3 and 4 re-written",,"10.1140/epjc/s10052-021-09215-4",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  A local UV cutoff $\Lambda(x)$ transforming under Weyl rescalings allows to
construct Weyl invariant kinetic terms for scalar fields including Wilsonian
cutoff functions. First we consider scalar fields in curved space-time with
local bare couplings of any canonical dimension, and anomalous dimensions which
describe their dependence on the UV cutoff. The local component of the UV
cutoff plays the role of an additional coupling, albeit with a trivial constant
$\beta$ function. This approach allows to derive Weyl consistency conditions
for the corresponding anomalous dimensions which assume the form of an exact
gradient flow. For renormalizable theories the Weyl consistency conditions are
initially of the form of an approximate gradient flow for the $\beta$
functions, and we derive conditions under which it becomes the form of an exact
gradient flow.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:30:50 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 14:53:45 GMT""},{""version"":""v3"",""created"":""Tue, 9 Mar 2021 10:51:58 GMT""},{""version"":""v4"",""created"":""Wed, 7 Apr 2021 10:35:05 GMT""}]","2021-06-02"
"2101.07616","Tie-Jun Gao","Tie-Jun Gao, Xiu-Yi Yang","Double peaks of gravitational wave spectrum induced from inflection
  point inflation",,,"10.1140/epjc/s10052-021-09269-4",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the possibility to induce double peaks of gravitational
wave(GW) spectrum from primordial scalar perturbations in inflationary models
with three inflection points.Where the inflection points can be generated from
a polynomial potential or generated from Higgs like $\phi^4$ potential with the
running of quartic coupling.In such models, the inflection point at large
scales predicts the scalar spectral index and tensor-to-scalar ratio consistent
with current CMB constraints, and the other two inflection points generate two
large peaks in the scalar power spectrum at small scales, which can induce GWs
with double peaks energy spectrum. We find that for some choices parameters the
double peaks spectrum can be detected by future GW detectors, and one of the
peaks around $f\simeq10^{-9}\sim10^{-8}$Hz can also explain the recent NANOGrav
signal. Moreover, the peaks of power spectrum allow for the generation of
primordial black holes, which account for a significant fraction of dark
matter.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:35:39 GMT""},{""version"":""v2"",""created"":""Sat, 1 May 2021 15:11:14 GMT""}]","2021-06-30"
"2101.07617","Kenta Higuchi","Kenta Higuchi","Feynman Integral in Quantum Walk, Barrier-top Scattering and Hadamard
  Walk",,,,,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this article is to relate the discrete quantum walk on
$\mathbb{Z}$ with the continuous Schr\""odinger operator on $\mathbb{R}$ in the
scattering problem. Each point of $\mathbb{Z}$ is associated with a barrier of
the potential, and the coin operator of the quantum walk is determined by the
transfer matrix between bases of WKB solutions on the classically allowed
regions of both sides of the barrier. This correspondence enables us to
represent each entry of the scattering matrix of the Schr\""odinger operator as
a countable sum of probability amplitudes associated with the paths of the
quantum walker. In particular, the barrier-top scattering corresponds to the
Hadamard walk in the semiclassical limit.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:44:28 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 04:15:11 GMT""}]","2021-02-08"
"2101.07618","Qian Huang","Chang Li and Qian Huang and Xing Li and Qianhan Wu","Human Action Recognition Based on Multi-scale Feature Maps from Depth
  Video Sequences","20 pages, 7 figures",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human action recognition is an active research area in computer vision.
Although great process has been made, previous methods mostly recognize actions
based on depth data at only one scale, and thus they often neglect multi-scale
features that provide additional information action recognition in practical
application scenarios. In this paper, we present a novel framework focusing on
multi-scale motion information to recognize human actions from depth video
sequences. We propose a multi-scale feature map called Laplacian pyramid depth
motion images(LP-DMI). We employ depth motion images (DMI) as the templates to
generate the multi-scale static representation of actions. Then, we caculate
LP-DMI to enhance multi-scale dynamic information of motions and reduces
redundant static information in human bodies. We further extract the
multi-granularity descriptor called LP-DMI-HOG to provide more discriminative
features. Finally, we utilize extreme learning machine (ELM) for action
classification. The proposed method yeilds the recognition accuracy of 93.41%,
85.12%, 91.94% on public MSRAction3D dataset, UTD-MHAD and DHA dataset. Through
extensive experiments, we prove that our method outperforms state-of-the-art
benchmarks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:46:42 GMT""}]","2021-01-20"
"2101.07619","Mostafa Akhavan Safar","Mostafa Akhavan Safar, Babak Teimourpour, Abbas Nozari-Dalini","Cancer driver gene detection in transcriptional regulatory networks
  using the structure analysis of weighted regulatory interactions",,"2022.Current Bioinformatics, 17(4), 327-343","10.2174/1574893617666220127094224",,"q-bio.MN q-bio.BM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Identification of genes that initiate cell anomalies and cause cancer in
humans is among the important fields in the oncology researches. The mutation
and development of anomalies in these genes are then transferred to other genes
in the cell and therefore disrupt the normal functionality of the cell. These
genes are known as cancer driver genes (CDGs). Various methods have been
proposed for predicting CDGs, most of which based on genomic data and based on
computational methods. Therefore, some researchers have developed novel
bioinformatics approaches. In this study, we propose an algorithm, which is
able to calculate the effectiveness and strength of each gene and rank them by
using the gene regulatory networks and the stochastic analysis of regulatory
linking structures between genes. To do so, firstly we constructed the
regulatory network using gene expression data and the list of regulatory
interactions. Then, using biological and topological features of the network,
we weighted the regulatory interactions. After that, the obtained regulatory
interactions weight was used in interaction structure analysis process.
Interaction analysis was achieved using two separate Markov chains on the
bipartite graph obtained from the main graph of the gene network. To do so, the
stochastic approach for link-structure analysis has been implemented. The
proposed algorithm categorizes higher-ranked genes as driver genes. The
efficiency of the proposed algorithm, regarding the F-measure value and number
of identified driver genes, was compared with 23 other computational and
network-based methods.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:50:54 GMT""}]","2023-03-03"
"2101.07620","Angelika Geroldinger","Rainer Puhr, Georg Heinze, Mariana Nold, Lara Lusa and Angelika
  Geroldinger","Firth's logistic regression with rare events: accurate effect estimates
  AND predictions?",,,"10.1002/sim.7273",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Firth-type logistic regression has become a standard approach for the
analysis of binary outcomes with small samples. Whereas it reduces the bias in
maximum likelihood estimates of coefficients, bias towards 1/2 is introduced in
the predicted probabilities. The stronger the imbalance of the outcome, the
more severe is the bias in the predicted probabilities. We propose two simple
modifications of Firth-type logistic regression resulting in unbiased predicted
probabilities. The first corrects the predicted probabilities by a post-hoc
adjustment of the intercept. The other is based on an alternative formulation
of Firth-types estimation as an iterative data augmentation procedure. Our
suggested modification consists in introducing an indicator variable which
distinguishes between original and pseudo observations in the augmented data.
In a comprehensive simulation study these approaches are compared to other
attempts to improve predictions based on Firth-type penalization and to other
published penalization strategies intended for routine use. For instance, we
consider a recently suggested compromise between maximum likelihood and
Firth-type logistic regression. Simulation results are scrutinized both with
regard to prediction and regression coefficients. Finally, the methods
considered are illustrated and compared for a study on arterial closure devices
in minimally invasive cardiac surgery.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:54:28 GMT""}]","2021-01-20"
"2101.07621","Tomomi Matsui","Akihiro Kawana and Tomomi Matsui","Trading Transforms of Non-weighted Simple Games and Integer Weights of
  Weighted Simple Games","23 pages","Theory and Decision (2021)","10.1007/s11238-021-09831-2",,"cs.GT cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates simple games. A fundamental research question in this
field is to determine necessary and sufficient conditions for a simple game to
be a weighted majority game. Taylor and Zwicker (1992) showed that a simple
game is non-weighted if and only if there exists a trading transform of finite
size. They also provided an upper bound on the size of such a trading
transform, if it exists. Gvozdeva and Slinko (2011) improved that upper bound;
their proof employed a property of linear inequalities demonstrated by Muroga
(1971).In this study, we provide a new proof of the existence of a trading
transform when a given simple game is non-weighted. Our proof employs Farkas'
lemma (1894), and yields an improved upper bound on the size of a trading
transform.
  We also discuss an integer-weight representation of a weighted simple game,
improving the bounds obtained by Muroga (1971). We show that our bound on the
quota is tight when the number of players is less than or equal to five, based
on the computational results obtained by Kurz (2012).
  Furthermore, we discuss the problem of finding an integer-weight
representation under the assumption that we have minimal winning coalitions and
maximal losing coalitions.In particular, we show a performance of a rounding
method.
  Lastly, we address roughly weighted simple games. Gvozdeva and Slinko (2011)
showed that a given simple game is not roughly weighted if and only if there
exists a potent certificate of non-weightedness. We give an upper bound on the
length of a potent certificate of non-weightedness. We also discuss an
integer-weight representation of a roughly weighted simple game.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:54:41 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 10:21:53 GMT""}]","2022-01-13"
"2101.07622","Chang Sun","Chang Sun","Knowledge Graph for Microdata of Statistics Netherlands",,,,,"cs.DL cs.DB","http://creativecommons.org/licenses/by/4.0/","  Statistics Netherlands (CBS) hosted a huge amount of data not only on the
statistical level but also on the individual level. With the development of
data science technologies, more and more researchers request to conduct their
research by using high-quality individual data from CBS (called CBS Microdata)
or combining them with other data sources. Making great use of these data for
research and scientific purposes can tremendously benefit the whole society.
However, CBS Microdata has been collected and maintained in different ways by
different departments in and out of CBS. The representation, quality, metadata
of datasets are not sufficiently harmonized. The project converts the
descriptions of all CBS microdata sets into one knowledge graph with
comprehensive metadata in Dutch and English using text mining and semantic web
technologies. Researchers can easily query the metadata, explore the relations
among multiple datasets, and find the needed variables. For example, if a
researcher searches a dataset about ""Age at Death"" in the Health and Well-being
category, all information related to this dataset will appear including
keywords and variable names. ""Age at Death"" dataset has a keyword - ""Death"".
This keyword will lead to other datasets such as ""Date of Death"". ""Cause of
Death"", ""Production statistics Health and welfare"" from Population, Business
categories, and Health and well-being categories. This will tremendously save
time and costs for the data requester but also data maintainers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:54:57 GMT""}]","2021-01-20"
"2101.07623","Olivier Thom","Olivier Thom","Dualit\'e complexe entre sous-vari\'et\'es r\'eelles dans
  $\mathbb{P}^2(\mathbb{C})$","In french",,,,"math.GT math.CV math.DG","http://creativecommons.org/licenses/by/4.0/","  We introduce a notion of semi-legendrian real submanifold in a complex
manifold of dimension 3 and prove that real submanifolds of $\mathbb{C}^2$ can
be uniquely lifted to $\mathbb{C}^3$. Then we deduce a complex duality between
real submanifolds of $\mathbb{P}^2(\mathbb{C})$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:56:17 GMT""}]","2021-01-20"
"2101.07624","Binjie Li","Binjie Li, Qin Zhou and Xiaoping Xie","Analysis of a discretization of a distributed control problem with a
  stochastic evolution equation","The theoretical result of this work is improved in our another work:
  arXiv:2106.13428",,,,"math.NA cs.NA math.OC","http://creativecommons.org/licenses/by/4.0/","  This paper analyzes a discretization of a stochastic parabolic optimal
control problem, where the diffusion term contains the control variable. With
rough data, the convergence of the discretization is derived. In addition, a
Monte-Carlo method is presented.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:56:45 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 16:57:20 GMT""},{""version"":""v3"",""created"":""Tue, 30 Aug 2022 09:35:34 GMT""}]","2022-08-31"
"2101.07625","Taisuke Kobayashi","Taisuke Kobayashi, Takanori Jin","Mirror-Descent Inverse Kinematics for Box-constrained Joint Space","6 pages, 4 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To control humanoid robots, the reference pose of end effector(s) is planned
in task space, then mapped into the reference joints by IK. By viewing that
problem as approximate quadratic programming (QP), recent QP solvers can be
applied to solve it precisely, but iterative numerical IK solvers based on
Jacobian are still in high demand due to their low computational cost. However,
the conventional Jacobian-based IK usually clamps the obtained joints during
iteration according to the constraints in practice, causing numerical
instability due to non-smoothed objective function. To alleviate the clamping
problem, this study explicitly considers the joint constraints, especially the
box constraints in this paper, inside the new IK solver. Specifically, instead
of clamping, a mirror descent (MD) method with box-constrained real joint space
and no-constrained mirror space is integrated with the Jacobian-based IK,
so-called MD-IK. In addition, to escape local optima nearly on the boundaries
of constraints, a heuristic technique, called $\epsilon$-clamping, is
implemented as margin in software level. Finally, to increase convergence
speed, the acceleration method for MD is integrated assuming continuity of
solutions at each time. As a result, the accelerated MD-IK achieved more stable
and enough fast tracking performance compared to the conventional IK solvers.
The low computational cost of the proposed method mitigated the time delay
until the solution is obtained in real-time humanoid gait control, achieving a
more stable gait.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:58:40 GMT""},{""version"":""v2"",""created"":""Thu, 8 Dec 2022 04:36:02 GMT""}]","2022-12-09"
"2101.07626","Daniel Nieto","D. Nieto, T. Miener, A. Brill, J. L. Contreras, T. B. Humensky, R.
  Mukherjee (for the CTA Consortium)","Reconstruction of IACT events using deep learning techniques with
  CTLearn","4 pages, 3 figures, to appear in the proceedings of the XXX
  Astronomical Data Analysis Software and Systems (ADASS) conference (published
  by ASP)",,,,"astro-ph.IM","http://creativecommons.org/licenses/by-sa/4.0/","  Arrays of imaging atmospheric Cherenkov telescopes (IACT) are superb
instruments to probe the very-high-energy gamma-ray sky. This type of telescope
focuses the Cherenkov light emitted from air showers, initiated by
very-high-energy gamma rays and cosmic rays, onto the camera plane. Then, a
fast camera digitizes the longitudinal development of the air shower, recording
its spatial, temporal, and calorimetric information. The properties of the
primary very-high-energy particle initiating the air shower can then be
inferred from those images: the primary particle can be classified as a gamma
ray or a cosmic ray and its energy and incoming direction can be estimated.
This so-called full-event reconstruction, crucial to the sensitivity of the
array to gamma rays, can be assisted by machine learning techniques. We present
a deep-learning driven, full-event reconstruction applied to simulated IACT
events using CTLearn. CTLearn is a Python package that includes modules for
loading and manipulating IACT data and for running deep learning models with
TensorFlow, using pixel-wise camera data as input.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:02:31 GMT""}]","2021-01-20"
"2101.07627","Karol Gregor","Karol Gregor, Frederic Besse","Self-Organizing Intelligent Matter: A blueprint for an AI generating
  algorithm","13 pages, 2 figures",,,,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  We propose an artificial life framework aimed at facilitating the emergence
of intelligent organisms. In this framework there is no explicit notion of an
agent: instead there is an environment made of atomic elements. These elements
contain neural operations and interact through exchanges of information and
through physics-like rules contained in the environment. We discuss how an
evolutionary process can lead to the emergence of different organisms made of
many such atomic elements which can coexist and thrive in the environment. We
discuss how this forms the basis of a general AI generating algorithm. We
provide a simplified implementation of such system and discuss what advances
need to be made to scale it up further.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:02:54 GMT""}]","2021-01-20"
"2101.07628","Ebrahim Soori","Bijan Orouji, Ebrahim Soori","The split common null point problem for generalized resolvents and
  nonexpansive mappings in Banach spaces","21",,,,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, the split common null point problem in two Banach spaces is
considered. Then, using the generalized resolvents of maximal monotone
operators and the generalized projections and an infinite family of
nonexpansive mappings, a strong convergence theorem for finding a solution of
the split common null point problem in two Banach spaces in the presence of a
sequence of errors will be proved.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:05:25 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 09:46:45 GMT""},{""version"":""v3"",""created"":""Fri, 26 Mar 2021 17:55:09 GMT""}]","2021-03-29"
"2101.07629","Cicero Carvalho","Bruno Andrade, C\'icero Carvalho, Victor G.L. Neumann and Ant\^onio
  C.P. Veiga","A family of codes with locality containing optimal codes",,,,,"cs.IT math.AG math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Locally recoverable codes were introduced by Gopalan et al. in 2012, and in
the same year Prakash et al. introduced the concept of codes with locality,
which are a type of locally recoverable codes. In this work we introduce a new
family of codes with locality, which are subcodes of a certain family of
evaluation codes. We determine the dimension of these codes, and also bounds
for the minimum distance. We present the true values of the minimum distance in
special cases, and also show that elements of this family are ""optimal codes"",
as defined by Prakash et al.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:07:24 GMT""}]","2021-01-20"
"2101.07630","Andre Rodrigues","Andr\'e Rodrigues, Andr\'e Santos, Kyle Montague, Tiago Guerreiro","Promoting Self-Efficacy Through an Effective Human-Powered Nonvisual
  Smartphone Task Assistant",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accessibility assessments typically focus on determining a binary measurement
of task performance success/failure; and often neglect to acknowledge the
nuances of those interactions. Although a large population of blind people find
smartphone interactions possible, many experiences take a significant toll and
can have a lasting negative impact on the individual and their willingness to
step out of technological comfort zones. There is a need to assist and support
individuals with the adoption and learning process of new tasks to mitigate
these negative experiences. We contribute with a human-powered nonvisual task
assistant for smartphones to provide pervasive assistance. We argue, in
addition to success, one must carefully consider promoting and evaluating
factors such as self-efficacy and the belief in one's own abilities to control
and learn to use technology. In this paper, we show effective assistant
positively affects self-efficacy when performing new tasks with smartphones,
affects perceptions of accessibility and enables systemic task-based learning.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:07:33 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 15:11:42 GMT""}]","2021-04-14"
"2101.07631","Islam Tanash","Islam M. Tanash and Taneli Riihonen","Improved Coefficients for the Karagiannidis-Lioumpas Approximations and
  Bounds to the Gaussian Q-Function","IEEE Communications Letters",,"10.1109/LCOMM.2021.3052257",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  We revisit the Karagiannidis-Lioumpas (KL) approximation of the Q-function by
optimizing its coefficients in terms of absolute error, relative error and
total error. For minimizing the maximum absolute/relative error, we describe
the targeted uniform error functions by sets of nonlinear equations so that the
optimized coefficients are the solutions thereof. The total error is minimized
with numerical search. We also introduce an extra coefficient in the KL
approximation to achieve significantly tighter absolute and total error at the
expense of unbounded relative error. Furthermore, we extend the KL expression
to lower and upper bounds with optimized coefficients that minimize the error
measures in the same way as for the approximations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:08:45 GMT""}]","2021-01-20"
"2101.07632","Hung-Ting Su","Chen-Hsi Chang, Hung-Ting Su, Jui-heng Hsu, Yu-Siang Wang, Yu-Cheng
  Chang, Zhe Yu Liu, Ya-Liang Chang, Wen-Feng Cheng, Ke-Jyun Wang and Winston
  H. Hsu","Situation and Behavior Understanding by Trope Detection on Films","WWW 2021. The first two authors contributed equally to this work",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The human ability of deep cognitive skills are crucial for the development of
various real-world applications that process diverse and abundant user
generated input. While recent progress of deep learning and natural language
processing have enabled learning system to reach human performance on some
benchmarks requiring shallow semantics, such human ability still remains
challenging for even modern contextual embedding models, as pointed out by many
recent studies. Existing machine comprehension datasets assume sentence-level
input, lack of casual or motivational inferences, or could be answered with
question-answer bias. Here, we present a challenging novel task, trope
detection on films, in an effort to create a situation and behavior
understanding for machines. Tropes are storytelling devices that are frequently
used as ingredients in recipes for creative works. Comparing to existing movie
tag prediction tasks, tropes are more sophisticated as they can vary widely,
from a moral concept to a series of circumstances, and embedded with
motivations and cause-and-effects. We introduce a new dataset, Tropes in Movie
Synopses (TiMoS), with 5623 movie synopses and 95 different tropes collecting
from a Wikipedia-style database, TVTropes. We present a multi-stream
comprehension network (MulCom) leveraging multi-level attention of words,
sentences, and role relations. Experimental result demonstrates that modern
models including BERT contextual embedding, movie tag prediction systems, and
relational networks, perform at most 37% of human performance (23.97/64.87) in
terms of F1 score. Our MulCom outperforms all modern baselines, by 1.5 to 5.0
F1 score and 1.5 to 3.0 mean of average precision (mAP) score. We also provide
a detailed analysis and human evaluation to pave ways for future research.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:09:54 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 03:51:10 GMT""}]","2021-04-01"
"2101.07633","Juanjuan Ren","Juanjuan Ren, Sebastian Franke, and Stephen Hughes","Quasinormal modes and Purcell factors of coupled loss-gain resonators
  and index-modulated ring resonators near exceptional points","27 pages, 13 figures","Physical Review X 11, 041020 (2021)","10.1103/PhysRevX.11.041020",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We first present a quasinormal mode (QNM) theory for coupled loss-gain
resonators working near an exceptional point. Assuming linear media, which can
be fully quantified using the complex pole properties of the QNMs, we show how
the QNMs yield a quantitatively good model to a full dipole spontaneous
emission response in Maxwell's equations at various spatial positions and
frequencies (linear response). We also develop a highly accurate and intuitive
QNM coupled-mode theory, which can be used to rigorously model such systems
using only the QNMs of the bare resonators, where the hybrid QNMs of the
complete system are automatically obtained. Near a lossy exceptional point, we
analytically show how the QNMs yield a Lorentzian-like and a
Lorentzian-squared-like response for the spontaneous emission lineshape,
consistent with other works. However, using rigorous analytical and numerical
solutions for microdisk resonators, we demonstrate that the general lineshapes
are far richer than what has been previously predicted. Indeed, the classical
picture of spontaneous emission can take on a wide range of positive and
negative Purcell factors from the hybrid modes of the coupled loss-gain system.
These negative Purcell factors are unphysical and signal a clear breakdown of
the classical dipole picture of spontaneous emission in such media, though the
negative local density of states is correct. We also show the rich spectral
features of the Green function propagators, which can be used to model various
physical observables. Second, we present a QNM approach to model index
modulated ring resonators working near an exceptional point and show unusual
chiral power flow from linearly polarized emitters, in agreement with recent
experiments, which is quantitatively explained without invoking the
interpretation of a missing dimension (the Jordan vector) and a decoupling from
the cavity eigenmodes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:11:07 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 02:34:04 GMT""}]","2021-11-04"
"2101.07634","Soichiro Hashiba","Soichiro Hashiba, Yusuke Yamada","Stokes phenomenon and gravitational particle production -- How to
  evaluate it in practice","23 + 18 pages, 13 + 7 figures, [v2] Minor revision","JCAP 05 (2021) 022","10.1088/1475-7516/2021/05/022","RESCEU-1/21","hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit gravitational particle production from the Stokes phenomenon
viewpoint, which helps us make a systematic way to understand asymptotic
behavior of mode functions in time-dependent background. One of our purposes of
this work is to make the method more practical for evaluation of
non-perturbative particle production rate. In particular, with several examples
of time-dependent backgrounds, we introduce some approximation methods that
make the analysis more practical. Specifically, we consider particle production
in simple expanding backgrounds, preheating after $R^2$ inflation, and a
transition model with smoothly changing mass. As we find several technical
issues in analyzing the Stokes phenomenon of each example, we discuss how to
simplify the problems while showing the accuracy of analytic estimation under
the approximations we make.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:18:45 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 08:23:39 GMT""}]","2021-05-13"
"2101.07635","Ryo Tazaki","Ryo Tazaki, Koji Murakawa, Takayuki Muto, Mitsuhiko Honda, Akio K.
  Inoue","Scattering polarization of 3-$\mu$m water-ice feature by large icy
  grains","19 pages, 17 figures, 1 table; Accepted for publication in ApJ",,"10.3847/1538-4357/abdd3d",,"astro-ph.GA astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Water ice has a strong spectral feature at a wavelength of approximately
$3~\mu$m, which plays a vital role in our understanding of the icy universe. In
this study, we investigate the scattering polarization of this water-ice
feature. The linear polarization degree of light scattered by $\mu$m-sized icy
grains is known to be enhanced at the ice band; however, the dependence of this
polarization enhancement on various grain properties is unclear. We find that
the enhanced polarization at the ice band is sensitive to the presence of
$\mu$m-sized grains as well as their ice abundance. We demonstrate that this
enhancement is caused by the high absorbency of the water-ice feature, which
attenuates internal scattering and renders the surface reflection dominant over
internal scattering. Additionally, we compare our models with polarimetric
observations of the low-mass protostar L1551 IRS 5. Our results show that
scattering by a maximum grain radius of a few microns with a low water-ice
abundance is consistent with observations. Thus, scattering polarization of the
water-ice feature is a useful tool for characterizing ice properties in various
astronomical environments.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:22:43 GMT""}]","2021-03-31"
"2101.07636","Sergey Mozgovoy","Sergey Mozgovoy","Operadic approach to wall-crossing","28 pages",,,,"math.AG hep-th math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wall-crossing phenomena are ubiquitous in many problems of algebraic geometry
and theoretical physics. Various ways to encode the relevant information and
the need to track the changes under the variation of parameters lead to rather
complicated transformation rules and non-trivial combinatorial problems. In
this paper we propose a framework, reminiscent of collections and plethysms in
the theory of operads, that conceptualizes those transformation rules. As an
application we obtain new streamlined proofs of some existing wall-crossing
formulas as well as some new formulas related to attractor invariants.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:22:54 GMT""}]","2021-01-20"
"2101.07637","Clare Dobbs","C. L. Dobbs, J. Wurster","The properties of clusters, and the orientation of magnetic fields
  relative to filaments, in magnetohydrodynamic simulations of colliding clouds","13 pages, 9 figures",,"10.1093/mnras/stab150",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We have performed Smoothed Particle Magneto-Hydrodynamics (SPMHD)
calculations of colliding clouds to investigate the formation of massive
stellar clusters, adopting a timestep criterion to prevent large divergence
errors. We find that magnetic fields do not impede the formation of young
massive clusters (YMCs), and the development of high star formation rates,
although we do see a strong dependence of our results on the direction of the
magnetic field. If the field is initially perpendicular to the collision, and
sufficiently strong, we find that star formation is delayed, and the morphology
of the resulting clusters is significantly altered. We relate this to the large
amplification of the field with this initial orientation. We also see that
filaments formed with this configuration are less dense. When the field is
parallel to the collision, there is much less amplification of the field, dense
filaments form, and the formation of clusters is similar to the purely
hydrodynamical case. Our simulations reproduce the observed tendency for
magnetic fields to be aligned perpendicularly to dense filaments, and parallel
to low density filaments. Overall our results are in broad agreement with past
work in this area using grid codes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:27:53 GMT""}]","2021-02-03"
"2101.07638","Tomi Koivisto","Tomi Koivisto, Luxi Zheng","Scale-invariant cosmology in de Sitter gauge theory","9 pages, 0 figures","Phys. Rev. D 103, 124063 (2021)","10.1103/PhysRevD.103.124063",,"gr-qc astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  The Planck mass and the cosmological constant determine the minimum and the
maximum distances in the physical universe. A relativistic theory that takes
into account a fundamental distance limit $\ell$ on par with the fundamental
speed limit $c$, is based on the de Sitter extension of the Lorentz symmetry.
This article proposes a new de Sitter gauge theory of gravity which allows the
consistent cosmological evolution of the $\ell$. The theory is locally
equivalent to Dirac's scale-invariant version of general relativity, and
suggests a novel non-singular extension of cosmology.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:28:21 GMT""}]","2021-07-07"
"2101.07639","Eva Sciacca","Eva Sciacca, Mel Krokos, Ugo Becciani, Cristobal Bordiu, Filomena
  Bufano, Alessandro Costa, Carmelo Pino, Simone Riggi, Fabio Vitello, Carlos
  Brandt, Angelo Rossi, Eugenio Topa, Simone Mantovani, Laura Vettorello,
  Thomas Cecconello, Giuseppe Vizzari","Novel EOSC Services for Space Challenges: The NEANIAS First Outcomes",,,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The European Open Science Cloud (EOSC) initiative faces the challenge of
developing an agile, fit-for-purpose, and sustainable service-oriented platform
that can address the evolving needs of scientific communities. The NEANIAS
project plays an active role in the materialization of the EOSC ecosystem by
actively contributing to the technological, procedural, strategic and business
development of EOSC. We present the first outcomes of the NEANIAS activities
relating to co-design and delivery of new innovative services for space
research for data management and visualization (SPACE-VIS), map making and
mosaicing (SPACE-MOS) and pattern and structure detection (SPACE-ML). We
include a summary of collected user requirements driving our services and
methodology for their delivery, together with service access details and
pointers to future works.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:29:26 GMT""}]","2021-01-20"
"2101.07640","Angelika Geroldinger","Angelika Geroldinger, Lara Lusa, Mariana Nold, and Georg Heinze","On resampling methods for model assessment in penalized and unpenalized
  logistic regression",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Penalized logistic regression methods are frequently used to investigate the
relationship between a binary outcome and a set of explanatory variables. The
model performance can be assessed by measures such as the concordance statistic
(c-statistic), the discrimination slope and the Brier score. Often, data
resampling techniques, e.g. crossvalidation, are employed to correct for
optimism in these model performance criteria. Especially with small samples or
a rare binary outcome variable, leave-one-out crossvalidation is a popular
choice. Using simulations and a real data example, we compared the effect of
different resampling techniques on the estimation of c-statistics,
discrimination slopes and Brier scores for three estimators of logistic
regression models, including the maximum likelihood and two maximum
penalized-likelihood estimators. Our simulation study confirms earlier studies
reporting that leave-one-out crossvalidated c-statistics can be strongly biased
towards zero. In addition, our study reveals that this bias is more pronounced
for estimators shrinking predicted probabilities towards the observed event
rate, such as ridge regression. Leave-one-out crossvalidation also provided
pessimistic estimates of the discrimination slope but nearly unbiased estimates
of the Brier score. We recommend to use leave-pair-out crossvalidation,
five-fold crossvalidation with repetition, the enhanced or the .632+ bootstrap
to estimate c-statistics and leave-pair-out or five-fold crossvalidation to
estimate discrimination slopes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:30:24 GMT""}]","2021-01-20"
"2101.07641","Fateme Salehi","Fateme Salehi, Naaser Neda, Mohammad-Hassan Majidi, Hamed Ahmadi","Cooperative NOMA-Based User Pairing for URLLC: A Max-Min Fairness
  Approach","11 pages, 6 figures, This paper has been accepted to publish for IEEE
  systems journal",,"10.1109/JSYST.2021.3116112",,"cs.IT cs.SY eess.SY math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, cooperative non-orthogonal multiple access (C-NOMA) is
considered in short packet communications with finite blocklength (FBL) codes.
The performance of a decode-and-forward (DF) relaying along with selection
combining (SC) and maximum ratio combining (MRC) strategies at the receiver
side is examined. We explore joint user pairing and resource allocation to
maximize fair throughput in a downlink (DL) scenario. In each pair, the user
with a stronger channel (strong user) acts as a relay for the other one (weak
user), and optimal power and blocklength are allocated to achieve max-min
throughput. To this end, first, only one pair is considered, and optimal
resource allocation is explored. Also, a suboptimal algorithm is suggested,
which converges to a near-optimal solution. Finally, the problem is extended to
a general scenario, and a suboptimal C-NOMA-based user pairing is proposed.
Numerical results show that the proposed C-NOMA scheme in both SC and MRC
strategies significantly improves the users' fair throughput compared to the
NOMA and OMA. It is also investigated that the proposed pairing scheme based on
C-NOMA outperforms the Hybrid NOMA/OMA scheme from the average throughput
perspective, while the fairness index degrades slightly.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:30:33 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 05:05:43 GMT""}]","2022-09-07"
"2101.07642","Mariano Cadoni","Mariano Cadoni, Andrea P. Sanna","Unified description of galactic dynamics and the cosmological constant","4 pages, no figures. Version 2: Typos corrected, small text changes",,"10.1088/1361-6382/abfd92",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We explore the phenomenology of a two-fluid cosmological model, where the
field equations of general relativity (GR) are sourced by baryonic and cold
dark matter. We find that the model allows for a unified description of small
and large scale, late-time cosmological dynamics. Specifically, in the static
regime we recover the flattening of galactic rotation curves by requiring the
matter density profile to scale as $1/r^2$. The same behavior describes matter
inhomogeneities distribution at small cosmological scales. This traces galactic
dynamics back to structure formation. At large cosmological scales, we focus on
back reaction effects of the spacetime geometry to the presence of matter
inhomogeneities. We find that a cosmological constant with the observed order
of magnitude, emerges by averaging the back reaction term on spatial scales of
order 100 Mpc and it is related in a natural way to matter distribution. This
provides a resolution to both the cosmological constant and the coincidence
problems and shows the existence of an intriguing link between the small and
large scale behavior in cosmology.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:30:55 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 09:06:18 GMT""}]","2021-07-07"
"2101.07643","Hiroyuki Tajima","Hiroyuki Tajima, Junichi Takahashi, Simeon I. Mistakidis, Eiji Nakano,
  and Kei Iida","Polaron Problems in Ultracold Atoms: Role of a Fermi Sea across
  Different Spatial Dimensions and Quantum Fluctuations of a Bose Medium","39 pages, 9 figures","Atoms 9, 18 (2021)","10.3390/atoms9010018",,"cond-mat.quant-gas cond-mat.str-el nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The notion of a polaron, originally introduced in the context of electrons in
ionic lattices, helps us to understand how a quantum impurity behaves when
being immersed in and interacting with a many-body background. We discuss the
impact of the impurities on the medium particles by considering feedback
effects from polarons that can be realized in ultracold quantum gas
experiments. In particular, we exemplify the modifications of the medium in the
presence of either Fermi or Bose polarons. Regarding Fermi polarons we present
a corresponding many-body diagrammatic approach operating at finite
temperatures and discuss how mediated two- and three-body interactions are
implemented within this framework. Utilizing this approach, we analyze the
behavior of the spectral function of Fermi polarons at finite temperature by
varying impurity-medium interactions as well as spatial dimensions from three
to one. Interestingly, we reveal that the spectral function of the medium atoms
could be a useful quantity for analyzing the transition/crossover from
attractive polarons to molecules in three-dimensions. As for the Bose polaron,
we showcase the depletion of the background Bose-Einstein condensate in the
vicinity of the impurity atom. Such spatial modulations would be important for
future investigations regarding the quantification of interpolaron correlations
in Bose polaron problems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:31:08 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 07:02:28 GMT""}]","2021-04-16"
"2101.07645","Bianca Garilli","B. Garilli, R. McLure, L. Pentericci, P. Franzetti, A. Gargiulo, A.
  Carnall, O. Cucciati, A. Iovino, R. Amorin, M. Bolzonella, A. Bongiorno, M.
  Castellano, A. Cimatti, M. Cirasuolo, F. Cullen, J. Dunlop, D. Elbaz, S.
  Finkelstein, A. Fontana, F. Fontanot, M. Fumana, L. Guaita, W. Hartley, M.
  Jarvis, S. Juneau, D. Maccagni, D. McLeod, K. Nandra, E. Pompei, L. Pozzetti,
  M. Scodeggio, M. Talia, A. Calabro', G. Cresci, J. P.U. Fynbo, N. P. Hathi,
  P. Hibon, A. M. Koekemoer, M. Magliocchetti, M. Salvato, G. Vietri, G.
  Zamorani, O. Almaini, I. Balestra, S. Bardelli, R.Begley, G. Brammer, E. F.
  Bell, R.A.A. Bowler, M. Brusa, F. Buitrago, C. Caputi, P. Cassata, S.
  Charlot, A. Citro, S. Cristiani, E. Curtis-Lake, M. Dickinson, G. Fazio, H.C.
  Ferguson, F. Fiore, M. Franco, A. Georgakakis, M. Giavalisco, A. Grazian, M.
  Hamadouche, I. Jung, S. Kim, Y. Khusanova, O. Le Fevre, M. Longhetti, J.
  Lotz, F. Mannucci, D. Maltby, K. Matsuoka, H. Mendez-Hernandez, J.
  Mendez-Abreu, M. Mignoli, M. Moresco, M. Nonino, M. Pannella, C. Papovich, P.
  Popesso, G. Roberts-Borsani, D.J. Rosario, A. Saldana-Lopez, P. Santini, A.
  Saxena, D. Schaerer, C. Schreiber, D. Stark, L.A.M. Tasca, R. Thomas, E.
  Vanzella, V. Wild, C. Williams, E. Zucca","The VANDELS ESO public spectroscopic survey: final Data Release of 2087
  spectra and spectroscopic measurements","16 pages, 13 figures, accepted for publication in Astronomy &
  Astrophysics","A&A 647, A150 (2021)","10.1051/0004-6361/202040059",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  VANDELS is an ESO Public Spectroscopic Survey designed to build a sample of
high signal to noise, medium resolution spectra of galaxies at redshift between
1 and 6.5. Here we present the final Public Data Release of the VANDELS Survey,
comprising 2087 redshift measurements. We give a detailed description of sample
selection, observations and data reduction procedures. The final catalogue
reaches a target selection completeness of 40% at iAB = 25. The high Signal to
Noise ratio of the spectra (above 7 in 80% of the spectra) and the dispersion
of 2.5{\AA} allowed us to measure redshifts with high precision, the redshift
measurement success rate reaching almost 100%. Together with the redshift
catalogue and the reduced spectra, we also provide optical mid-IR photometry
and physical parameters derived through SED fitting. The observed galaxy sample
comprises both passive and star forming galaxies covering a stellar mass range
8.3< Log(M*/Msolar)<11.7. All catalogues and spectra are accessible through the
survey database (http://vandels.inaf.it) where all information can be queried
interactively, and via the ESO Archive (https://www.eso.org/qi/).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:32:43 GMT""}]","2021-03-31"
"2101.07648","Elio Joseph","Elio Joseph","Approximation rationnelle de sous-espaces vectoriels","PhD thesis, in French",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  The goal of this PhD thesis is to study a diophantine approximation problem
stated by Schmidt in 1967. The problem aim to study the approximation of a
subspace of $\mathbb{R}^n$ by rational subspaces, not necessarily of the same
dimension, by determining the exponents of approximation associated to the
various angles between the subspaces.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:36:38 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 09:06:54 GMT""}]","2021-06-07"
"2101.07653","Sven Koehler","Sven Koehler, Tarique Hussain, Zach Blair, Tyler Huffaker, Florian
  Ritzmann, Animesh Tandon, Thomas Pickardt, Samir Sarikouch, Heiner Latus,
  Gerald Greil, Ivo Wolf, Sandy Engelhardt","Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice
  Cardiac MR Images by Incorporating Pretrained Task Networks","Accepted for IEEE Transaction on Medical Imaging (TMI) 2021 on
  13.01.2021",,"10.1109/TMI.2021.3052972",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Anisotropic multi-slice Cardiac Magnetic Resonance (CMR) Images are
conventionally acquired in patient-specific short-axis (SAX) orientation. In
specific cardiovascular diseases that affect right ventricular (RV) morphology,
acquisitions in standard axial (AX) orientation are preferred by some
investigators, due to potential superiority in RV volume measurement for
treatment planning. Unfortunately, due to the rare occurrence of these
diseases, data in this domain is scarce. Recent research in deep learning-based
methods mainly focused on SAX CMR images and they had proven to be very
successful. In this work, we show that there is a considerable domain shift
between AX and SAX images, and therefore, direct application of existing models
yield sub-optimal results on AX samples. We propose a novel unsupervised domain
adaptation approach, which uses task-related probabilities in an attention
mechanism. Beyond that, cycle consistency is imposed on the learned
patient-individual 3D rigid transformation to improve stability when
automatically re-sampling the AX images to SAX orientations. The network was
trained on 122 registered 3D AX-SAX CMR volume pairs from a multi-centric
patient cohort. A mean 3D Dice of $0.86\pm{0.06}$ for the left ventricle,
$0.65\pm{0.08}$ for the myocardium, and $0.77\pm{0.10}$ for the right ventricle
could be achieved. This is an improvement of $25\%$ in Dice for RV in
comparison to direct application on axial slices. To conclude, our pre-trained
task module has neither seen CMR images nor labels from the target domain, but
is able to segment them after the domain gap is reduced. Code:
https://github.com/Cardio-AI/3d-mri-domain-adaptation
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:39:30 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 08:25:53 GMT""}]","2022-01-21"
"2101.07658","Jef Laga","Jef Laga","Arithmetic statistics of Prym surfaces","Accepted version",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a family of abelian surfaces over $\mathbb{Q}$ arising as Prym
varieties of double covers of genus-$1$ curves by genus-$3$ curves. These
abelian surfaces carry a polarization of type $(1,2)$ and we show that the
average size of the Selmer group of this polarization equals $3$. Moreover we
show that the average size of the $2$-Selmer group of the abelian surfaces in
the same family is bounded above by $5$. This implies an upper bound on the
average rank of these Prym varieties, and gives evidence for the heuristics of
Poonen and Rains for a family of abelian varieties which are not principally
polarized. The proof is a combination of an analysis of the Lie algebra
embedding $F_4\subset E_6$, invariant theory, a classical geometric
construction due to Pantazis, a study of N\'eron component groups of Prym
surfaces and Bhargava's orbit-counting techniques.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:44:20 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 18:17:22 GMT""},{""version"":""v3"",""created"":""Fri, 1 Apr 2022 13:35:28 GMT""}]","2022-04-04"
"2101.07659","Hongguang Liu","Muxin Han and Hongguang Liu","Loop Quantum Gravity on Dynamical Lattice and Improved Cosmological
  Effective Dynamics with Inflaton","44 pages, 17 figures","Phys. Rev. D 104, 024011 (2021)","10.1103/PhysRevD.104.024011",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the path integral formulation of the reduced phase space Loop Quantum
Gravity (LQG), we propose a new approach to allow the spatial cubic lattice
(graph) to change dynamically in the physical time evolution. The equations of
motion of the path integral derive the effective dynamics of cosmology from the
full LQG, when we focus on solutions with homogeneous and isotropic symmetry.
The resulting cosmological effective dynamics with the dynamical lattice
improves the effective dynamics obtained earlier from the path integral with
fixed spatial lattice: The improved effective dynamics recovers the FLRW
cosmology at low energy density and resolves the big-bang singularity with a
bounce. The critical density $\rho_c$ at the bounce is Planckian $\rho_c\sim
\Delta^{-1}$ where $\Delta$ is a Planckian area serving as certain UV cut-off
of the effective theory. The effective dynamics gives the unsymmetric bounce
and has the de-Sitter (dS) spacetime in the past of the bounce. The
cosmological constant $\Lambda_{eff}$ of the dS spacetime is emergent from the
quantum effect $\Lambda_{eff}\sim\Delta^{-1}$. These results are qualitatively
similar to the properties of $\bar{\mu}$-scheme Loop Quantum Cosmology (LQC).
Moreover, we generalize the earlier path integral formulation of the full LQG
by taking into account the coupling with an additional real scalar field, which
drives the slow-roll inflation of the effective cosmological dynamics. In
addition, we discuss the cosmological perturbation theory on the dynamical
lattice, and the relation to the Mukhanov-Sasaki equation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:49:55 GMT""}]","2021-07-14"
"2101.07660","Xiaodong Wang","Xiaodong Wang","Remark on an inequality for closed hypersurfaces in complete manifolds
  with nonnegative Ricci curvature","Typos corrected",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We give a simple proof of a recent result due to Agostiniani, Fogagnolo and
Mazzieri.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:49:58 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 19:13:49 GMT""}]","2021-01-22"
"2101.07661","Martin Huber","Simon Berset, Martin Huber, Mark Schelker","The fiscal response to revenue shocks",,,,,"econ.GN q-fin.EC stat.AP stat.ML","http://creativecommons.org/licenses/by/4.0/","  We study the impact of fiscal revenue shocks on local fiscal policy. We focus
on the very volatile revenues from the immovable property gains tax in the
canton of Zurich, Switzerland, and analyze fiscal behavior following large and
rare positive and negative revenue shocks. We apply causal machine learning
strategies and implement the post-double-selection LASSO estimator to identify
the causal effect of revenue shocks on public finances. We show that local
policymakers overall predominantly smooth fiscal shocks. However, we also find
some patterns consistent with fiscal conservatism, where positive shocks are
smoothed, while negative ones are mitigated by spending cuts.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:51:28 GMT""}]","2021-01-20"
"2101.07662","Hui Chen","Yuchen He, Yuan Yuan, Hui Chen, Huaibin Zheng, Jianbin Liu, and Zhuo
  Xu","Ptychography Intensity Interferometry Imaging for Dynamic Distant Object",,,,,"physics.optics eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a promising lensless imaging method for distance objects, intensity
interferometry imaging (III) had been suffering from the unreliable phase
retrieval process, hindering the development of III for decades. Recently, the
introduction of the ptychographic detection in III overcame this challenge, and
a method called ptychographic III (PIII) was proposed. We here experimentally
demonstrate that PIII can image a dynamic distance object. A reasonable image
for the moving object can be retrieved with only two speckle patterns for each
probe, and only 10 to 20 iterations are needed. Meanwhile, PIII exhibits robust
to the inaccurate information of the probe. Furthermore, PIII successfully
recovers the image through a fog obfuscating the imaging light path, under
which a conventional camera relying on lenses fails to provide a recognizable
image.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:52:19 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 10:51:56 GMT""}]","2021-02-11"
"2101.07663","Dingwen Zhang","Mingchen Zhuge, Deng-Ping Fan, Nian Liu, Dingwen Zhang, Dong Xu, and
  Ling Shao","Salient Object Detection via Integrity Learning","TPAMI accepted",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although current salient object detection (SOD) works have achieved
significant progress, they are limited when it comes to the integrity of the
predicted salient regions. We define the concept of integrity at both a micro
and macro level. Specifically, at the micro level, the model should highlight
all parts that belong to a certain salient object. Meanwhile, at the macro
level, the model needs to discover all salient objects in a given image. To
facilitate integrity learning for SOD, we design a novel Integrity Cognition
Network (ICON), which explores three important components for learning strong
integrity features. 1) Unlike existing models, which focus more on feature
discriminability, we introduce a diverse feature aggregation (DFA) component to
aggregate features with various receptive fields (i.e., kernel shape and
context) and increase feature diversity. Such diversity is the foundation for
mining the integral salient objects. 2) Based on the DFA features, we introduce
an integrity channel enhancement (ICE) component with the goal of enhancing
feature channels that highlight the integral salient objects, while suppressing
the other distracting ones. 3) After extracting the enhanced features, the
part-whole verification (PWV) method is employed to determine whether the part
and whole object features have strong agreement. Such part-whole agreements can
further improve the micro-level integrity for each salient object. To
demonstrate the effectiveness of our ICON, comprehensive experiments are
conducted on seven challenging benchmarks. Our ICON outperforms the baseline
methods in terms of a wide range of metrics. Notably, our ICON achieves about
10% relative improvement over the previous best model in terms of average false
negative ratio (FNR), on six datasets. Codes and results are available at:
https://github.com/mczhuge/ICON.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:53:12 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 03:55:27 GMT""},{""version"":""v3"",""created"":""Sun, 21 Feb 2021 07:01:56 GMT""},{""version"":""v4"",""created"":""Wed, 8 Sep 2021 05:18:21 GMT""},{""version"":""v5"",""created"":""Wed, 15 Sep 2021 04:16:42 GMT""},{""version"":""v6"",""created"":""Wed, 13 Apr 2022 08:07:07 GMT""},{""version"":""v7"",""created"":""Mon, 13 Jun 2022 08:14:47 GMT""}]","2022-06-14"
"2101.07664","Nicholas Botzer","Nicholas Botzer, Shawn Gu, and Tim Weninger","Analysis of Moral Judgement on Reddit","Submitted to ICWSM 2021, 9 pages and 6 figures",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  Moral outrage has become synonymous with social media in recent years.
However, the preponderance of academic analysis on social media websites has
focused on hate speech and misinformation. This paper focuses on analyzing
moral judgements rendered on social media by capturing the moral judgements
that are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels
associated with each judgement we train a classifier that can take a comment
and determine whether it judges the user who made the original post to have
positive or negative moral valence. Then, we use this classifier to investigate
an assortment of website traits surrounding moral judgements in ten other
subreddits, including where negative moral users like to post and their posting
patterns. Our findings also indicate that posts that are judged in a positive
manner will score higher.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:57:04 GMT""}]","2021-01-20"
"2101.07665","Josep-Maria Mondelo","Alex Haro and Josep-Maria Mondelo","Flow map parameterization methods for invariant tori in Hamiltonian
  systems",,,"10.1016/j.cnsns.2021.105859",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this paper is to present a methodology for the computation of
invariant tori in Hamiltonian systems combining flow map methods,
parameterization methods, and symplectic geometry. While flow map methods
reduce the dimension of the tori to be computed by one (avoiding Poincare
maps), parameterization methods reduce the cost of a single step of the derived
Newton-like method to be proportional to the cost of a FFT. Symplectic
properties lead to some magic cancellations that make the methods work. The
multiple shooting version of the methods are applied to the computation of
invariant tori and their invariant bundles around librational equilibrium
points of the Restricted Three Body Problem. The invariant bundles are the
first order approximations of the corresponding invariant manifolds, commonly
known as the whiskers, which are very important in the dynamical organization
and have important applications in space mission design.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:57:32 GMT""}]","2021-06-30"
"2101.07666","Mikael de la Salle","Mikael de la Salle","A duality operators/Banach spaces","34 pages. Old project, already announced at several occasions in
  2016, and that took a long time to be completed. Comments welcome v2: 37
  pages. Section 5 added on the duality between Banach spaces and operators on
  full Lp spaces. A few references added",,,,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  Given a set $B$ of operators between subspaces of $L_p$ spaces, we
characterize the operators between subspaces of $L_p$ spaces that remain
bounded on the $X$-valued $L_p$ space for every Banach space on which elements
of the original class $B$ are bounded.
  This is a form of the bipolar theorem for a duality between the class of
Banach spaces and the class of operators between subspaces of $L_p$ spaces,
essentially introduced by Pisier. The methods we introduce allow us to recover
also the other direction --characterizing the bipolar of a set of Banach
spaces--, which had been obtained by Hernandez in 1983.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:58:03 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 16:24:41 GMT""}]","2021-03-10"
"2101.07667","Martin Wistuba","Martin Wistuba and Josif Grabocka","Few-Shot Bayesian Optimization with Deep Kernel Surrogates","Published as a conference paper at ICLR 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperparameter optimization (HPO) is a central pillar in the automation of
machine learning solutions and is mainly performed via Bayesian optimization,
where a parametric surrogate is learned to approximate the black box response
function (e.g. validation error). Unfortunately, evaluating the response
function is computationally intensive. As a remedy, earlier work emphasizes the
need for transfer learning surrogates which learn to optimize hyperparameters
for an algorithm from other tasks. In contrast to previous work, we propose to
rethink HPO as a few-shot learning problem in which we train a shared deep
surrogate model to quickly adapt (with few response evaluations) to the
response function of a new task. We propose the use of a deep kernel network
for a Gaussian process surrogate that is meta-learned in an end-to-end fashion
in order to jointly approximate the response functions of a collection of
training data sets. As a result, the novel few-shot optimization of our deep
kernel surrogate leads to new state-of-the-art results at HPO compared to
several recent methods on diverse metadata sets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:00:39 GMT""}]","2021-01-20"
"2101.07668","Simon Hengchen","Simon Hengchen and Nina Tahmasebi and Dominik Schlechtweg and Haim
  Dubossarsky","Challenges for Computational Lexical Semantic Change","To appear in: Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon
  Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language
  Science Press. [preliminary page numbering]",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The computational study of lexical semantic change (LSC) has taken off in the
past few years and we are seeing increasing interest in the field, from both
computational sciences and linguistics. Most of the research so far has focused
on methods for modelling and detecting semantic change using large diachronic
textual data, with the majority of the approaches employing neural embeddings.
While methods that offer easy modelling of diachronic text are one of the main
reasons for the spiking interest in LSC, neural models leave many aspects of
the problem unsolved. The field has several open and complex challenges. In
this chapter, we aim to describe the most important of these challenges and
outline future directions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:01:30 GMT""}]","2021-01-20"
"2101.07669","Sebastian Garcia-Valencia","Sebastian Garcia-Valencia, Alejandro Betancourt, Juan G.
  Lalinde-Pulido","A framework to compare music generative models using automatic
  evaluation metrics extended to rhythm","arXiv admin note: substantial text overlap with arXiv:2012.01231",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  To train a machine learning model is necessary to take numerous decisions
about many options for each process involved, in the field of sequence
generation and more specifically of music composition, the nature of the
problem helps to narrow the options but at the same time, some other options
appear for specific challenges. This paper takes the framework proposed in a
previous research that did not consider rhythm to make a series of design
decisions, then, rhythm support is added to evaluate the performance of two RNN
memory cells in the creation of monophonic music. The model considers the
handling of music transposition and the framework evaluates the quality of the
generated pieces using automatic quantitative metrics based on geometry which
have rhythm support added as well.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:04:46 GMT""}]","2021-01-20"
"2101.07670","Abhiram Soori","Dhavala Suri and Abhiram Soori","Finite transverse conductance in topological insulators under an applied
  in-plane magnetic field","8 pages, 8 captioned figures","J. Phys.: Condens. Matter 33, 335301 (2021)","10.1088/1361-648X/ac06ea",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Recently, in topological insulators (TIs) the phenomenon of planar Hall
effect (PHE) wherein a current driven in presence an in-plane magnetic field
generates a transverse voltage has been experimentally witnessed. There have
been a couple of theoretical explanations of this phenomenon. We investigate
this phenomenon based on scattering theory on a normal metal-TI-normal metal
hybrid structure and calculate the conductances in longitudinal and transverse
directions to the applied bias. The transverse conductance depends on the
spatial location between the two NM-TI junctions where it is calculated. It is
zero in the drain electrode when the chemical potentials of the top and the
bottom TI surfaces ($\mu_t$ and $\mu_b$ respectively) are equal. The
longitudinal conductance is $\pi$-periodic in $\phi$-the angle between the bias
direction and the direction of the in-plane magnetic field. The transverse
conductance is $\pi$-periodic in $\phi$ when $\mu_t=\mu_b$ whereas it is
$2\pi$-periodic in $\phi$ when $\mu_t\neq\mu_b$. As a function of the magnetic
field, the magnitude of transverse conductance increases initially and peaks.
At higher magnetic fields, it decays for angles $\phi$ closer to $0,\pi$
whereas oscillates for angles $\phi$ close to $\pi/2$. The conductances
oscillate with the length of the TI region. A finite width of the system makes
the transport separate into finitely many channels. The features of the
conductances are similar to those in the limit of infinitely wide system except
when the width is so small that only one channel participates in the transport.
When only one channel participates in transport, the transverse conductance in
the region $0<x<L$ is zero for $\mu_t=\mu_b$ and the transverse conductance in
the region $x>L$ is zero even for the case $\mu_t\neq\mu_b$. We understand the
features in the obtained results.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:06:37 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 15:57:59 GMT""}]","2021-06-30"
"2101.07671","Jun Chen","Jun Chen, Haopeng Chen","Edge-Featured Graph Attention Network",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Lots of neural network architectures have been proposed to deal with learning
tasks on graph-structured data. However, most of these models concentrate on
only node features during the learning process. The edge features, which
usually play a similarly important role as the nodes, are often ignored or
simplified by these models. In this paper, we present edge-featured graph
attention networks, namely EGATs, to extend the use of graph neural networks to
those tasks learning on graphs with both node and edge features. These models
can be regarded as extensions of graph attention networks (GATs). By reforming
the model structure and the learning process, the new models can accept node
and edge features as inputs, incorporate the edge information into feature
representations, and iterate both node and edge features in a parallel but
mutual way. The results demonstrate that our work is highly competitive against
other node classification approaches, and can be well applied in edge-featured
graph learning tasks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:08:12 GMT""}]","2021-01-20"
"2101.07672","Jennifer Duncan","Jennifer Duncan","A Nonlinear Variant of Ball's Inequality",,,,,"math.CA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We adapt an induction-on-scales argument of Bennett, Bez, Buschenhenke,
Cowling, and Flock to establish a global near-monotonicity statement for the
nonlinear Brascamp-Lieb functional under a certain heat-flow, from which
follows a stability result for the finiteness of global nonlinear Brascamp-Lieb
inequalities.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:10:07 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 17:04:03 GMT""},{""version"":""v3"",""created"":""Wed, 20 Oct 2021 11:50:02 GMT""},{""version"":""v4"",""created"":""Mon, 16 May 2022 16:23:20 GMT""}]","2022-05-17"
"2101.07673","Saeed Ullah Khan","Muhammad Zahid, Saeed Ullah Khan, Jingli Ren","Shadow cast and center of mass energy in a charged Gauss-Bonnet-AdS
  black hole","13 Pages, 9 Figures",,"10.1016/j.cjph.2021.05.003",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is devoted to the exploration of shadow cast and center of mass
energy in the background of a 4-dimensional charged Gauss-Bonnet AdS black
hole. On investigating particle dynamics, we have examined BH's metric
function. Whereas, with the help of null geodesics, we pursue to calculate the
celestial coordinates and the shadow radius of the black hole. We have made use
of the hawking temperature to study the energy emission rate. Moreover, we have
explored the center of mass energy and discussed its characteristics under the
influence of spacetime parameters. For a better understanding, we graphically
represent all of our main findings. The acquired result shows that both charge
and AdS radius ($l$) decrease the shadow radius, while the Gauss-Bonnet
coupling parameter $\alpha$ increases the shadow radius in AdS spacetime. On
the other hand, both $Q$ and $\alpha$ result in diminishing the shadow radius
in asymptotically flat spacetime. Finally, we investigate the energy emission
rate and center of mass energy under the influence of $Q$ and $\alpha$.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:17:56 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 16:48:57 GMT""}]","2021-07-07"
"2101.07674","Ernest Appau Kofi Mensah","Appau Ernest","An Artificial Intelligence based approach to estimating time of arrival
  and bus occupancy for public transport systems in Africa","Needs to be updated",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  This document entails a progressive report on the design and implementation
of a bus tracking and monitoring system . This report has its contents within
the limits of five chapters with each concisely exploring their various
objectives. Chapter one is the introductory chapter. It entails a brief
description of a bus tracking and monitoring system ,the need and the aims and
objectives of this project. Chapter two consists the literature review of this
project. This entails the critical analysis of previous related research and
projects undertaken by other people. The merits and demerits of the various
implementations.Chapter three consists of theory and design considerations of
the proposed system for Kwame Nkrumah University campus. Chapter four talks
about the methods used to collect data and the approach and technology stack
adopted to build the proposed system.Chapter five concludes the thesis and
discusses the results of test and deployment of the proposed system on Kwame
Nkrumah University of Science and Technology campus
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:10:16 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 23:24:51 GMT""}]","2021-05-25"
"2101.07676","Milan Groshev","Milan Groshev, Jorge Mart\'in-P\'erez, Kiril Antevski, Antonio de la
  Oliva, Carlos J. Bernardos","COTORRA: COntext-aware Testbed fOR Robotic Applications","4 pages, 4 figures, submitted to IEEE Communications Letters",,,,"cs.RO cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge & Fog computing have received considerable attention as promising
candidates for the evolution of robotic systems. In this letter, we propose
COTORRA, an Edge & Fog driven robotic testbed that combines context information
with robot sensor data to validate innovative concepts for robotic systems
prior to being applied in a production environment. In lab/university, we
established COTORRA as an easy applicable and modular testbed on top of
heterogeneous network infrastructure. COTORRA is open for pluggable robotic
applications. To verify its feasibility and assess its performance, we ran set
of experiments that show how autonomous navigation applications can achieve
target latencies bellow 15ms or perform an inter-domain (DLT) federation within
19 seconds.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:15:21 GMT""}]","2021-01-20"
"2101.07677","Jonathan Wei Zhong Lau","Jonathan Wei Zhong Lau, Kishor Bharti, Tobias Haug, Leong Chuan Kwek","Noisy intermediate scale quantum simulation of time dependent
  Hamiltonians","15 pages, 14 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computers are expected to help us to achieve accurate simulation of
the dynamics of many-body quantum systems. However, the limitations of current
NISQ devices prevents us from realising this goal today. Recently an algorithm
for performing quantum simulations called quantum assisted simulator has been
proposed that promises realization on current experimental devices. In this
work, we extend the quantum assisted simulator to simulate the dynamics of a
class of time-dependent Hamiltonians. We show that the quantum assisted
simulator is easier to implement as well as can realize multi-qubit
interactions and challenging driving protocols that are difficult with other
existing methods. We demonstrate this for a time-dependent Hamiltonian on the
IBM Quantum Experience cloud quantum computer by showing superior performance
of the quantum assisted simulator compared to Trotterization and variational
quantum simulation. Further, we demonstrate the capability to simulate the
dynamics of Hamiltonians consisting of 10000 qubits. Our results indicate that
quantum assisted simulator is a promising algorithm for current term quantum
hardware.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:20:03 GMT""},{""version"":""v2"",""created"":""Sun, 15 Aug 2021 01:16:43 GMT""}]","2021-08-17"
"2101.07678","Matej Kudrna","Mat\v{e}j Kudrna","Level Truncation Approach to Open String Field Theory","272 pages, 61 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a D-brane background in string theory (or equivalently boundary
conditions in a two-dimensional conformal field theory), classical solutions of
open string field theory equations of motion are conjectured to describe new
D-brane backgrounds (boundary conditions). In this thesis, we study these
solutions in bosonic open string field theory using the level truncation
approach, which is a numerical approach where the string field is truncated to
a finite number of degrees of freedom.
  We start with a review of the theoretical background and numerical methods
which are needed in the level truncation approach and then we discuss solutions
on several different backgrounds. First, we discuss universal solutions, which
do not depend on the open string background, then we analyze solutions of the
free boson theory compactified on a circle or on a torus, then marginal
solutions in three different approaches and finally solutions in theories which
include the A-series of Virasoro minimal models. In addition to known D-branes,
we find so-called exotic solutions which potentially describe yet unknown
boundary states.
  This paper is based on my doctoral thesis submitted to the Faculty of
Mathematics and Physics at Charles University in Prague.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:20:07 GMT""}]","2021-01-20"
"2101.07679","Alexis E. Block","Alexis E. Block, Sammy Christen, Roger Gassert, Otmar Hilliges, and
  Katherine J. Kuchenbecker","The Six Hug Commandments: Design and Evaluation of a Human-Sized Hugging
  Robot with Visual and Haptic Perception","9 pages, 6 Figures, 2 Tables, ACM/IEEE Human-Robot Interaction (HRI)
  Conference 2021",,"10.1145/3434073.3444656",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Receiving a hug is one of the best ways to feel socially supported, and the
lack of social touch can have severe negative effects on an individual's
well-being. Based on previous research both within and outside of HRI, we
propose six tenets (""commandments"") of natural and enjoyable robotic hugging: a
hugging robot should be soft, be warm, be human sized, visually perceive its
user, adjust its embrace to the user's size and position, and reliably release
when the user wants to end the hug. Prior work validated the first two tenets,
and the final four are new. We followed all six tenets to create a new robotic
platform, HuggieBot 2.0, that has a soft, warm, inflated body (HuggieChest) and
uses visual and haptic sensing to deliver closed-loop hugging. We first
verified the outward appeal of this platform in comparison to the previous
PR2-based HuggieBot 1.0 via an online video-watching study involving 117 users.
We then conducted an in-person experiment in which 32 users each exchanged
eight hugs with HuggieBot 2.0, experiencing all combinations of visual hug
initiation, haptic sizing, and haptic releasing. The results show that adding
haptic reactivity definitively improves user perception a hugging robot,
largely verifying our four new tenets and illuminating several interesting
opportunities for further improvement.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:20:19 GMT""}]","2021-01-20"
"2101.07680","Tomoya Naito","Tomoya Naito, Gianluca Col\`o, Haozhao Liang, and Xavier Roca-Maza","Second and fourth moments of the charge density and neutron-skin
  thickness of atomic nuclei","19 pages, 3 figures, 3 tables","Phys. Rev. C 104, 024316 (2021)","10.1103/PhysRevC.104.024316","RIKEN-QHP-481, RIKEN-iTHEMS-Report-21","nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method is presented to extract the neutron-skin thickness of atomic nuclei
from the second and fourth moments of the electric charge distribution. We show
that the value of the proton fourth moment must be independently known in order
to estimate the neutron skin thickness experimentally. To overcome this
problem, we propose the use of a strong linear correlation among the second and
fourth moments of the proton distribution as calculated with several energy
density functionals of common use. We take special care in estimating the
errors associated with the different contributions to the neutron radius and
show, for the first time, the analytic expressions for the spin-orbit
contribution to the charge fourth moments of neutrons and protons. To reduce
the uncertainty on the extraction of the neutron radius, two neighboring
even-even isotopes are used. Nevertheless, the error on the fourth moment of
the proton distribution, even if determined or assumed with large accuracy,
dominates and prevents the present method from being applied for a sound
determination of the neutron skin thickness.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:20:19 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 15:42:50 GMT""}]","2021-08-11"
"2101.07681","Sheng Liu","Sheng Liu, Xiaozhen Xie and Wenfeng Kong","Hyperspectral Image Denoising via Multi-modal and Double-weighted Tensor
  Nuclear Norm","arXiv admin note: text overlap with arXiv:2106.12489",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Hyperspectral images (HSIs) usually suffer from different types of pollution.
This severely reduces the quality of HSIs and limits the accuracy of subsequent
processing tasks. HSI denoising can be modeled as a low-rank tensor denoising
problem. Tensor nuclear norm (TNN) induced by tensor singular value
decomposition plays an important role in this problem. In this letter, we first
reconsider three inconspicuous but crucial phenomenons in TNN. In the Fourier
transform domain of HSIs, different frequency slices (FS) contain different
information; different singular values (SVs) of each FS also represent
different information. The two physical phenomenons lie not only in the
spectral mode but also in the spatial modes. Then based on them, we propose a
multi-modal and double-weighted TNN. It can adaptively shrink the FS and SVs
according to their physical meanings in all modes of HSIs. In the framework of
the alternating direction method of multipliers, we design an effective
alternating iterative strategy to optimize our proposed model. Denoised
experiments on both synthetic and real HSI datasets demonstrate their
superiority against related methods.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:20:38 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 04:31:17 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 07:31:17 GMT""}]","2022-06-22"
"2101.07682","Pooja Devi","Pooja Devi, Pascal D\'emoulin, Ramesh Chandra, Reetika Joshi, Brigitte
  Schmieder, and Bhuwan Joshi","Observations of a prominence eruption and loop contraction","16 pages, 9 figures, 1 table, and appendix",,"10.1051/0004-6361/202040042",,"astro-ph.SR","http://creativecommons.org/publicdomain/zero/1.0/","  Context. Prominence eruptions provide key observations to understand the
launch of coronal mass ejections as their cold plasma traces a part of the
unstable magnetic configuration.
  Aims. We select a well observed case to derive observational constraints for
eruption models.
  Methods. We analyze the prominence eruption and loop expansion and
contraction observed on 02 March 2015 associated with a GOES M3.7 class flare
(SOL2015-03-02T15:27) using the data from Atmospheric Imaging Assembly (AIA)
and the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI). We study
the prominence eruption and the evolution of loops using the time-distance
techniques.
  Results. The source region is a decaying bipolar active region where magnetic
flux cancellation is present for several days before the eruption. AIA
observations locate the erupting prominence within a flux rope viewed along its
local axis direction. We identify and quantify the motion of loops in
contraction and expansion located on the side of the erupting flux rope.
Finally, RHESSI hard X-ray observations identify the loop top and two
foot-point sources.
  Conclusions. Both AIA and RHESSI observations support the standard model of
eruptive flares. The contraction occurs 19 minutes after the start of the
prominence eruption indicating that this contraction is not associated with the
eruption driver. Rather, this prominence eruption is compatible with an
unstable flux rope where the contraction and expansion of the lateral loop is
the consequence of a side vortex developing after the flux rope is launched.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:21:34 GMT""}]","2021-03-24"
"2101.07683","Kui Yang","Kui Yang, Wenjing Zhao, Constantinos Antoniou","Utilizing Import Vector Machines to Identify Dangerous Pro-active
  Traffic Conditions","6 pages, 3 figures, 2020 IEEE 23rd International Conference on
  Intelligent Transportation Systems (ITSC)","In 2020 IEEE 23rd International Conference on Intelligent
  Transportation Systems (ITSC) (pp. 1-6). IEEE","10.1109/ITSC45102.2020.9294284",,"stat.ML cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic accidents have been a severe issue in metropolises with the
development of traffic flow. This paper explores the theory and application of
a recently developed machine learning technique, namely Import Vector Machines
(IVMs), in real-time crash risk analysis, which is a hot topic to reduce
traffic accidents. Historical crash data and corresponding traffic data from
Shanghai Urban Expressway System were employed and matched. Traffic conditions
are labelled as dangerous (i.e. probably leading to a crash) and safe (i.e. a
normal traffic condition) based on 5-minute measurements of average speed,
volume and occupancy. The IVM algorithm is trained to build the classifier and
its performance is compared to the popular and successfully applied technique
of Support Vector Machines (SVMs). The main findings indicate that IVMs could
successfully be employed in real-time identification of dangerous pro-active
traffic conditions. Furthermore, similar to the ""support points"" of the SVM,
the IVM model uses only a fraction of the training data to index kernel basis
functions, typically a much smaller fraction than the SVM, and its
classification rates are similar to those of SVMs. This gives the IVM a
computational advantage over the SVM, especially when the size of the training
data set is large.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:22:23 GMT""}]","2021-01-20"
"2101.07684","Zhenhua Qiao","Yulei Han, Shiyang Sun, Shifei Qi, Xiaohong Xu, and Zhenhua Qiao","Interlayer Ferromagnetism and High-Temperature Quantum Anomalous Hall
  Effect in \textit{p}-Doped MnBi$_2$Te$_4$ Multilayers",,"Phys. Rev. B 103, 245403 (2021)","10.1103/PhysRevB.103.245403",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interlayer antiferromagnetic coupling hinders the observation of quantum
anomalous Hall effect in magnetic topological insulator MnBi$_2$Te$_4$. We
demonstrate that interlayer \textit{ferromagnetism} can be established by
utilizing the \textit{p}-doping method in MnBi$_2$Te$_4$ multilayers. In two
septuple-layers system, the interlayer ferromagnetic coupling appears by doping
nonmagnetic elements (e.g., N, P, As, Na, Mg, K, and Ca), due to the
redistribution of orbital occupations of Mn. We further find that Mg and Ca
elements are the most suitable candidates because of their low formation
energy. Although, the \textit{p}-doped two septuple layers exhibit
topologically trivial band structure, the increase of layer thickness to three
(four) septuple layers with Ca (Mg) dopants leads to the formation of the
quantum anomalous Hall effect. Our proposed \textit{p}-doping strategy not only
makes MnBi$_2$Te$_4$ become an ideal platform to realize the high-temperature
quantum anomalous Hall effect without external magnetic field, but also can
compensate the electrons from the intrinsic \textit{n}-type defects in
MnBi$_2$Te$_4$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:22:30 GMT""}]","2021-06-09"
"2101.07685","Mattia Setzu","Mattia Setzu, Riccardo Guidotti, Anna Monreale, Franco Turini, Dino
  Pedreschi, Fosca Giannotti","GLocalX -- From Local to Global Explanations of Black Box AI Models","27 pages, 2 figures, submitted to ""Special Issue on: Explainable AI
  (XAI) for Web-based Information Processing""","Journal of Artificial Intelligence, Volume 294, May 2021, 103457","10.1016/j.artint.2021.103457",,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Artificial Intelligence (AI) has come to prominence as one of the major
components of our society, with applications in most aspects of our lives. In
this field, complex and highly nonlinear machine learning models such as
ensemble models, deep neural networks, and Support Vector Machines have
consistently shown remarkable accuracy in solving complex tasks. Although
accurate, AI models often are ""black boxes"" which we are not able to
understand. Relying on these models has a multifaceted impact and raises
significant concerns about their transparency. Applications in sensitive and
critical domains are a strong motivational factor in trying to understand the
behavior of black boxes. We propose to address this issue by providing an
interpretable layer on top of black box models by aggregating ""local""
explanations. We present GLocalX, a ""local-first"" model agnostic explanation
method. Starting from local explanations expressed in form of local decision
rules, GLocalX iteratively generalizes them into global explanations by
hierarchically aggregating them. Our goal is to learn accurate yet simple
interpretable models to emulate the given black box, and, if possible, replace
it entirely. We validate GLocalX in a set of experiments in standard and
constrained settings with limited or no access to either data or local
explanations. Experiments show that GLocalX is able to accurately emulate
several models with simple and small models, reaching state-of-the-art
performance against natively global solutions. Our findings show how it is
often possible to achieve a high level of both accuracy and comprehensibility
of classification models, even in complex domains with high-dimensional data,
without necessarily trading one property for the other. This is a key
requirement for a trustworthy AI, necessary for adoption in high-stakes
decision making applications.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:26:09 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 11:26:16 GMT""}]","2021-01-29"
"2101.07686","Giorgio Carelli","Andrea Basti, Nicol\`o Beverini, Filippo Bosi, Giorgio Carelli,
  Donatella Ciampini, Angela D.V. Di Virgilio, Francesco Fuso, Umberto
  Giacomelli, Enrico Maccioni, Paolo Marsili, Giuseppe Passeggio, Alberto
  Porzio, Andreino Simonelli and Giuseppe Terreni","Effects of temperature variations in high sensitivity Sagnac gyroscope","11 pages, 7 figures",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  GINGERINO is one of the most sensitive Sagnac laser-gyroscope based on an
heterolithic mechanical structure. It is a prototype for GINGER, the laser
gyroscopes array proposed to reconstruct the Earth rotation vector and in this
way to measure General Relativity effects. Many factors affect the final
sensitivity of laser gyroscopes, in particular, when they are used in long term
measurements, slow varying environmental parameters come into play. To
understand the role of different terms allows to design more effective
mechanical as well as optical layouts, while a proper model of the dynamics
affecting long term (low frequency) signals would increase the effectiveness of
the data analysis for improving the overall sensitivity. In this contribution
we focus our concerns on the effects of room temperature and pressure aiming at
further improving mechanical design and long term stability of the apparatus.
Our data are compatible with a local orientation changes of the Gran Sasso site
below $\mu$rad as predicted by geodetic models. This value is, consistent with
the requirements for GINGER and the installation of an high sensitivity Sagnac
gyroscope oriented at the maximum signal, \textit{i.e.} along the Earth
rotation axes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:26:27 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 09:28:57 GMT""},{""version"":""v3"",""created"":""Fri, 19 Mar 2021 11:30:58 GMT""}]","2021-03-22"
"2101.07687","Heinrich Dinkel","Heinrich Dinkel, Mengyue Wu, Kai Yu","Towards duration robust weakly supervised sound event detection",,,"10.1109/TASLP.2021.3054313",,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sound event detection (SED) is the task of tagging the absence or presence of
audio events and their corresponding interval within a given audio clip. While
SED can be done using supervised machine learning, where training data is fully
labeled with access to per event timestamps and duration, our work focuses on
weakly-supervised sound event detection (WSSED), where prior knowledge about an
event's duration is unavailable. Recent research within the field focuses on
improving segment- and event-level localization performance for specific
datasets regarding specific evaluation metrics. Specifically, well-performing
event-level localization requires fully labeled development subsets to obtain
event duration estimates, which significantly benefits localization
performance. Moreover, well-performing segment-level localization models output
predictions at a coarse-scale (e.g., 1 second), hindering their deployment on
datasets containing very short events (< 1 second). This work proposes a
duration robust CRNN (CDur) framework, which aims to achieve competitive
performance in terms of segment- and event-level localization. This paper
proposes a new post-processing strategy named ""Triple Threshold"" and
investigates two data augmentation methods along with a label smoothing method
within the scope of WSSED. Evaluation of our model is done on the DCASE2017 and
2018 Task 4 datasets, and URBAN-SED. Our model outperforms other approaches on
the DCASE2018 and URBAN-SED datasets without requiring prior duration
knowledge. In particular, our model is capable of similar performance to
strongly-labeled supervised models on the URBAN-SED dataset. Lastly, ablation
experiments to reveal that without post-processing, our model's localization
performance drop is significantly lower compared with other approaches.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:28:54 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 02:16:04 GMT""}]","2021-02-08"
"2101.07688","Shay Heizler","Shay I. Heizler and Tomer Shussman and Moshe Fraenkel","Radiation drive temperature measurements in aluminium via
  radiation-driven shock waves: Modeling using self-similar solutions","28 pages, 12 figures","Physics of Plasmas 28, 032105 (2021)","10.1063/5.0044783",,"physics.plasm-ph physics.comp-ph physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the phenomena of radiative-driven shock waves using a semi-analytic
model based on self similar solutions of the radiative hydrodynamic problem.
The relation between the hohlraum drive temperature $T_{\mathrm{Rad}}$ and the
resulting ablative shock $D_S$ is a well-known method for the estimation of the
drive temperature. However, the various studies yield different scaling
relations between $T_{\mathrm{Rad}}$ and $D_S$, based on different simulations.
In [T. Shussman and S.I. Heizler, Phys. Plas., 22, 082109 (2015)] we have
derived full analytic solutions for the subsonic heat wave, that include both
the ablation and the shock wave regions. Using this self-similar approach we
derive here the $T_{\mathrm{Rad}}(D_S)$ relation for aluminium, using the
detailed Hugoniot relations and including transport effects. By our
semi-analytic model, we find a spread of $\approx 40$eV in the
$T_{\mathrm{Rad}}(D_S)$ curve, as a function of the temperature profile's
duration and its temporal profile. Our model agrees with the various
experiments and the simulations data, explaining the difference between the
various scaling relations that appear in the literature.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:28:57 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 15:59:45 GMT""}]","2021-03-31"
"2101.07690","Peng Jiang","Peng Jiang, Rujia Wang, Bo Wu","Efficient Mining of Frequent Subgraphs with Two-Vertex Exploration",,,,,"cs.DB cs.PF","http://creativecommons.org/licenses/by/4.0/","  Frequent Subgraph Mining (FSM) is the key task in many graph mining and
machine learning applications. Numerous systems have been proposed for FSM in
the past decade. Although these systems show good performance for small
patterns (with no more than four vertices), we found that they have difficulty
in mining larger patterns. In this work, we propose a novel two-vertex
exploration strategy to accelerate the mining process. Compared with the
single-vertex exploration adopted by previous systems, our two-vertex
exploration avoids the large memory consumption issue and significantly reduces
the memory access overhead. We further enhance the performance through an
index-based quick pattern technique that reduces the overhead of isomorphism
checks, and a subgraph sampling technique that mitigates the issue of subgraph
explosion. The experimental results show that our system achieves significant
speedups against the state-of-the-art graph pattern mining systems and supports
larger pattern mining tasks that none of the existing systems can handle.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:35:24 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 21:08:42 GMT""}]","2021-02-09"
"2101.07691","Rachel Freedman","Rachel Freedman, Rohin Shah and Anca Dragan","Choice Set Misspecification in Reward Inference","Presented at the IJCAI-PRICAI 2020 Workshop on Artificial
  Intelligence Safety",,,,"cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Specifying reward functions for robots that operate in environments without a
natural reward signal can be challenging, and incorrectly specified rewards can
incentivise degenerate or dangerous behavior. A promising alternative to
manually specifying reward functions is to enable robots to infer them from
human feedback, like demonstrations or corrections. To interpret this feedback,
robots treat as approximately optimal a choice the person makes from a choice
set, like the set of possible trajectories they could have demonstrated or
possible corrections they could have made. In this work, we introduce the idea
that the choice set itself might be difficult to specify, and analyze choice
set misspecification: what happens as the robot makes incorrect assumptions
about the set of choices from which the human selects their feedback. We
propose a classification of different kinds of choice set misspecification, and
show that these different classes lead to meaningful differences in the
inferred reward and resulting performance. While we would normally expect
misspecification to hurt, we find that certain kinds of misspecification are
neither helpful nor harmful (in expectation). However, in other situations,
misspecification can be extremely harmful, leading the robot to believe the
opposite of what it should believe. We hope our results will allow for better
prediction and response to the effects of misspecification in real-world reward
inference.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:35:30 GMT""}]","2021-01-20"
"2101.07692","Alexandre Ara\'ujo","Alexandre Ara\'ujo and Adriana Valio","Kepler-411 Differential Rotation from Three Transiting Planets","9 pages",,"10.3847/2041-8213/abd3a7",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The differential rotation of the Sun is a crucial ingredient of the dynamo
theory responsible for the generation of its magnetic field. Currently, the
rotation profile of a star that hosts one or more transiting planets can be
estimated. By detecting the same spot in a later transit, it is possible to
infer the stellar rotation period at that latitude. In this work, we apply for
the first time transit spot mapping to determine the differential rotation of
Kepler-411, a K2V-type star with an average rotation period of 10.52 days,
radius of 0.79 R$_\odot$ and mass of 0.83 M$_\odot$. Kepler-411 hosts at least
four planets, the inner planet is a super-Earth with a radius of 1.88
R$_\oplus$ and an orbital period of 3.0051 days, whereas the two larger
transiting planets are mini Neptunes with radii of 3.27 and 3.31 R$_\oplus$,
and periods of 7.834435 and 58.0204 days, respectively. Their orbits are such
that they transit the star at latitudes of -11$^{\circ}$, -21$^{\circ}$, and
-49$^{\circ}$. Analysis of the transit light curves of the three planets
resulted in the detection of a total of 198 spots. For each transit latitude,
the rotation period of the star was estimated and the differential rotation
pattern estimated independently. Then a solar like differential rotation
profile was fit to the three rotation periods at the distinct latitudes, the
result agreed extremely well with the previous ones, resulting in a
differential shear of $0.0500\pm0.0006$ rd/d or a relative differential
rotation of $8.4\pm0.1$\%.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:40:02 GMT""}]","2021-01-20"
"2101.07693","Patrizia Semeraro","Roberto Fontana and Patrizia Semeraro","Exchangeable Bernoulli distributions: high dimensional simulation,
  estimate and testing",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the class of exchangeable Bernoulli distributions building on
their geometrical structure. Exchangeable Bernoulli probability mass functions
are points in a convex polytope and we have found analytical expressions for
their extremal generators. The geometrical structure turns out to be crucial to
simulate high dimensional and negatively correlated binary data. Furthermore,
for a wide class of statistical indices and measures of a probability mass
function we are able to find not only their sharp bounds in the class, but also
their distribution across the class. Estimate and testing are also addressed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:41:00 GMT""}]","2021-01-20"
"2101.07694","Matthew R. DeVerna","Matthew R. DeVerna, Francesco Pierri, Bao Tran Truong, John
  Bollenbacher, David Axelrod, Niklas Loynes, Christopher Torres-Lugo,
  Kai-Cheng Yang, Filippo Menczer, and John Bryden","CoVaxxy: A Collection of English-language Twitter Posts About COVID-19
  Vaccines","8 pages, 10 figures",,,,"cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With a substantial proportion of the population currently hesitant to take
the COVID-19 vaccine, it is important that people have access to accurate
information. However, there is a large amount of low-credibility information
about vaccines spreading on social media. In this paper, we present the CoVaxxy
dataset, a growing collection of English-language Twitter posts about COVID-19
vaccines. Using one week of data, we provide statistics regarding the numbers
of tweets over time, the hashtags used, and the websites shared. We also
illustrate how these data might be utilized by performing an analysis of the
prevalence over time of high- and low-credibility sources, topic groups of
hashtags, and geographical distributions. Additionally, we develop and present
the CoVaxxy dashboard, allowing people to visualize the relationship between
COVID-19 vaccine adoption and U.S. geo-located posts in our dataset. This
dataset can be used to study the impact of online information on COVID-19
health outcomes (e.g., vaccine uptake) and our dashboard can help with
exploration of the data.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:49:21 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 23:20:59 GMT""},{""version"":""v3"",""created"":""Tue, 20 Apr 2021 19:57:50 GMT""}]","2021-04-22"
"2101.07695","Stefano M. Iacus","Tiziana Carpi, Airo Hino, Stefano Maria Iacus, Giuseppe Porro","Twitter Subjective Well-Being Indicator During COVID-19 Pandemic: A
  Cross-Country Comparative Study",,,,,"econ.GN cs.CL q-fin.EC stat.AP","http://creativecommons.org/licenses/by/4.0/","  This study analyzes the impact of the COVID-19 pandemic on the subjective
well-being as measured through Twitter data indicators for Japan and Italy. It
turns out that, overall, the subjective well-being dropped by 11.7% for Italy
and 8.3% for Japan in the first nine months of 2020 compared to the last two
months of 2019 and even more compared to the historical mean of the indexes.
Through a data science approach we try to identify the possible causes of this
drop down by considering several explanatory variables including, climate and
air quality data, number of COVID-19 cases and deaths, Facebook Covid and flu
symptoms global survey, Google Trends data and coronavirus-related searches,
Google mobility data, policy intervention measures, economic variables and
their Google Trends proxies, as well as health and stress proxy variables based
on big data. We show that a simple static regression model is not able to
capture the complexity of well-being and therefore we propose a dynamic elastic
net approach to show how different group of factors may impact the well-being
in different periods, even over a short time length, and showing further
country-specific aspects. Finally, a structural equation modeling analysis
tries to address the causal relationships among the COVID-19 factors and
subjective well-being showing that, overall, prolonged mobility
restrictions,flu and Covid-like symptoms, economic uncertainty, social
distancing and news about the pandemic have negative effects on the subjective
well-being.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:51:53 GMT""}]","2021-01-20"
"2101.07696","Andr\'e Nusser","Karl Bringmann and Andr\'e Nusser","Translating Hausdorff is Hard: Fine-Grained Lower Bounds for Hausdorff
  Distance Under Translation","to be published at JoCG",,,,"cs.CG cs.CC","http://creativecommons.org/licenses/by/4.0/","  Computing the similarity of two point sets is a ubiquitous task in medical
imaging, geometric shape comparison, trajectory analysis, and many more
settings. Arguably the most basic distance measure for this task is the
Hausdorff distance, which assigns to each point from one set the closest point
in the other set and then evaluates the maximum distance of any assigned pair.
A drawback is that this distance measure is not translational invariant, that
is, comparing two objects just according to their shape while disregarding
their position in space is impossible.
  Fortunately, there is a canonical translational invariant version, the
Hausdorff distance under translation, which minimizes the Hausdorff distance
over all translations of one of the point sets. For point sets of size $n$ and
$m$, the Hausdorff distance under translation can be computed in time $\tilde
O(nm)$ for the $L_1$ and $L_\infty$ norm [Chew, Kedem SWAT'92] and $\tilde O(nm
(n+m))$ for the $L_2$ norm [Huttenlocher, Kedem, Sharir DCG'93].
  As these bounds have not been improved for over 25 years, in this paper we
approach the Hausdorff distance under translation from the perspective of
fine-grained complexity theory. We show (i) a matching lower bound of
$(nm)^{1-o(1)}$ for $L_1$ and $L_\infty$ (and all other $L_p$ norms) assuming
the Orthogonal Vectors Hypothesis and (ii) a matching lower bound of
$n^{2-o(1)}$ for $L_2$ in the imbalanced case of $m = O(1)$ assuming the 3SUM
Hypothesis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:52:55 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 16:48:14 GMT""},{""version"":""v3"",""created"":""Wed, 10 Mar 2021 13:43:02 GMT""},{""version"":""v4"",""created"":""Mon, 19 Jul 2021 13:15:29 GMT""},{""version"":""v5"",""created"":""Mon, 13 Jun 2022 15:30:38 GMT""}]","2022-06-14"
"2101.07697","Aurelian Isar","Roberto Grimaudo, Tatiana Mihaescu, Aurelian Isar, Iulia Ghiu,
  Antonino Messina","Dynamics of quantum discord of two coupled spin-1/2 subjected to
  time-dependent magnetic fields","15 pages, 7 figures","Results in Physics 13, 102147 (2019)",,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the dynamics of quantum discord of two interacting spin-1/2
subjected to controllable time-dependent magnetic fields. The exact time
evolution of discord is given for various input mixed states consisting of
classical mixtures of two Bell states. The quantum discord manifests a complex
oscillatory behaviour in time and is compared with that of quantum
entanglement, measured by concurrence. The interplay of the action of the
time-dependent magnetic fields and the spin-coupling mechanism in the
occurrence and evolution of quantum correlations is examined in detail.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:53:13 GMT""}]","2021-01-20"
"2101.07698","Erdal Yi\u{g}it","Erdal Yi\u{g}it and Alexander S. Medvedev and Mehdi Benna and Bruce
  Jakosky","Dust storm-enhanced gravity wave activity in the Martian thermosphere
  observed by MAVEN and implication for atmospheric escape","Accepted for publication in Geophysical Research Letters, 13 pages, 4
  figures",,"10.1029/2020GL092095",,"physics.space-ph astro-ph.EP physics.ao-ph physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Lower atmospheric global dust storms affect the small- and large-scale
weather and variability of the whole Martian atmosphere. Analysis of the CO$_2$
density data from the Neutral Gas and Ion Mass Spectrometer instrument (NGIMS)
on board NASA's Mars Atmosphere Volatile EvolutioN (MAVEN) spacecraft show a
remarkable increase of GW-induced density fluctuations in the thermosphere
during the 2018 major dust storm with distinct latitude and local time
variability. The mean thermospheric GW activity increases by a factor of two
during the storm event. The magnitude of relative density perturbations is
around 20% on average and 40% locally. One and a half months later, the GW
activity gradually decreases. Enhanced temperature disturbances in the Martian
thermosphere can facilitate atmospheric escape. For the first time, we estimate
that, for a 20% and 40% GW-induced disturbances, the net increase of Jeans
escape flux of hydrogen is a factor of 1.3 and 2, respectively.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:56:38 GMT""}]","2021-04-07"
"2101.07738","Oleksandra Ivanova","A.V. Ivanovaa","Small Bodies of the Solar System Active at Large Heliocentric Distances:
  Studies with the 6-Meter Telescope of Sao Ras","19 pages, 17 figures",,"10.1134/S1990341320010034",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A detailed study of comets active at large heliocentric distances (greater
than 4 au) which enter the Solar System for the first time and are composed of
matter in its elementary, unprocessed state, would help in our understanding of
the history and evolution of the Solar System. In particular, contemporary
giant planet formation models require the presence of accretion of volatile
elements such as neon, argon, krypton, xenon and others, which initially could
not survive at the distances where giant planets were formed. Nevertheless, the
volatile components could be effectively delivered by the Kuiper-belt and
Oort-cloud bodies, which were formed at temperatures below 30 K. This review is
dedicated to the results of a multi-year comprehensive study of small bodies of
the Solar System showing a comet-like activity at large heliocentric distances.
The data were obtained from observations with the 6-meter telescope of SAO RAS
equipped with multi-mode focal reducers SCORPIO and SCORPIO-2.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 18:12:02 GMT""}]","2021-01-20"
"2101.07790","Koray D\""uzta\c{s}","Koray D\""uzta\c{s}","The variational method, backreactions, and the absorption probability in
  Wald type problems","Accepted to appear in European Physical Journal C",,"10.1140/epjc/s10052-021-08879-2",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We argue that the variational method in Wald type thought experiments,
involves order of magnitude problems when one imposes the fact that $\delta M$
is inherently a first order quantity itself. One observes that the contribution
of the second order perturbations is actually of the fourth order. Therefore
backreactions have to be explicitly calculated. Here, we re-consider the
overspinning problem for Kerr-Newman black holes interacting with test fields.
We calculate the backreaction effects due to the induced increase in the
angular velocity of the event horizon, which brings a partial solution to the
overspinning problem. To bring an ultimate solution, we argue that the
absorption probability should be taken into account in Wald type problems where
black holes interact with test fields. This fundamentally alters the course of
the analysis of the thought experiments. Due to the fact that a small fraction
of the challenging modes is absorbed by the black holes, overspinning is
prevented for both nearly extremal and extremal cases. Some extreme cases are
easily fixed by backreaction effects. The arguments do not apply to the generic
overspinning by fermionic fields for which the absorption probability is
positive definite.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 22:06:02 GMT""}]","2021-01-21"
"2101.07791","Tadafumi Matsuno","Tadafumi Matsuno, Yutaka Hirai, Yuta Tarumi, Kenta Hotokezaka, Masaomi
  Tanaka, Amina Helmi","$R$-process enhancements of Gaia-Enceladus in GALAH DR3","accepted to A\&A","A&A 650, A110 (2021)","10.1051/0004-6361/202040227",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The dominant site of production of $r$-process elements remains unclear
despite recent observations of a neutron star merger. Observational constraints
on the properties of the sites can be obtained by comparing $r$-process
abundances in different environments. The recent Gaia data releases and large
samples from high-resolution optical spectroscopic surveys are enabling us to
compare $r$-process element abundances between stars formed in an accreted
dwarf galaxy, Gaia-Enceladus, and those formed in the Milky Way. We aim to
understand the origin of $r$-process elements in Gaia-Enceladus. We first
construct a sample of stars to study Eu abundances without being affected by
the detection limit. We then kinematically select 71 Gaia-Enceladus stars and
93 in-situ stars from the Galactic Archaeology with HERMES (GALAH) DR3, of
which 50 and 75 stars can be used to study Eu reliably. Gaia-Enceladus stars
clearly show higher ratios of [{Eu}/{Mg}] than in-situ stars. High [{Eu}/{Mg}]
along with low [{Mg}/{Fe}] are also seen in relatively massive satellite
galaxies such as the LMC, Fornax, and Sagittarius dwarfs. On the other hand,
unlike these galaxies, Gaia-Enceladus does not show enhanced [{Ba}/{Eu}] or
[{La}/{Eu}] ratios suggesting a lack of significant $s$-process contribution.
From comparisons with simple chemical evolution models, we show that the high
[{Eu}/{Mg}] of Gaia-Enceladus can naturally be explained by considering
$r$-process enrichment by neutron-star mergers with delay time distribution
that follows a similar power-law as type~Ia supernovae but with a shorter
minimum delay time.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:25:51 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 12:17:41 GMT""}]","2021-06-16"
"2101.07792","Vladimir Hizhnyakov Dr","Vladimir Hizhnyakov, Vadim Boltrushko, Helle Kaasik, Yurii Orlovskii","Rare Earth Ions Doped Mixed Crystals for Fast Quantum Computers with
  Optical Frequency Qubits","15 pages, 3 tables, 2 figures","Optics Communications 485, 126693 (2021)","10.1016/j.optcom.2020.126693",,"quant-ph cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The possibility of using mixed crystals highly doped with rare earth ions
(REIs) as physical systems for creating fast quantum computers with a sampling
time of nanoseconds is discussed. The electronic 4f states of rare earth ions
with small values of the diagonal elements of the Judd-Ofelt matrix U(2) are
proposed as optical frequency qubit levels. CNOT and other conditional gate
operations are performed by exciting the rare earth ion into the 4f state with
a large diagonal element of U(2), causing a Stark blockade. It is found that
the main interaction responsible for this blockade is the quadrupole-quadrupole
interaction. The large inhomogeneous broadening of the frequencies of the
electronic transitions in mixed crystals and the weak interaction of 4f
electrons with phonons make it possible to achieve a high computation rate and
a long decoherence time of the qubits. An ensemble of closest REIs is described
that can act as an OQC instance; the frequencies of the corresponding qubits
can be found using the spectral hole burning method.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:27:58 GMT""}]","2021-01-21"
"2101.07794","Daniel Bartl","Daniel Bartl and Shahar Mendelson","On Monte-Carlo methods in convex stochastic optimization",,"Annals of Applied Probability, 2022+",,,"math.ST math.OC math.PR q-fin.MF stat.TH","http://creativecommons.org/licenses/by/4.0/","  We develop a novel procedure for estimating the optimizer of general convex
stochastic optimization problems of the form $\min_{x\in\mathcal{X}}
\mathbb{E}[F(x,\xi)]$, when the given data is a finite independent sample
selected according to $\xi$. The procedure is based on a median-of-means
tournament, and is the first procedure that exhibits the optimal statistical
performance in heavy tailed situations: we recover the asymptotic rates
dictated by the central limit theorem in a non-asymptotic manner once the
sample size exceeds some explicitly computable threshold. Additionally, our
results apply in the high-dimensional setup, as the threshold sample size
exhibits the optimal dependence on the dimension (up to a logarithmic factor).
The general setting allows us to recover recent results on multivariate mean
estimation and linear regression in heavy-tailed situations and to prove the
first sharp, non-asymptotic results for the portfolio optimization problem.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:53:30 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 15:07:56 GMT""}]","2022-01-26"
"2101.08116","Francisco Ortin","Javier Escalada (1), Ted Scully (2), Francisco Ortin (1 and 2) ((1)
  University of Oviedo, (2) Cork Institute of Technology)","Improving type information inferred by decompilers with supervised
  machine learning",,,,,"cs.SE cs.LG cs.PL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In software reverse engineering, decompilation is the process of recovering
source code from binary files. Decompilers are used when it is necessary to
understand or analyze software for which the source code is not available.
Although existing decompilers commonly obtain source code with the same
behavior as the binaries, that source code is usually hard to interpret and
certainly differs from the original code written by the programmer. Massive
codebases could be used to build supervised machine learning models aimed at
improving existing decompilers. In this article, we build different
classification models capable of inferring the high-level type returned by
functions, with significantly higher accuracy than existing decompilers. We
automatically instrument C source code to allow the association of binary
patterns with their corresponding high-level constructs. A dataset is created
with a collection of real open-source applications plus a huge number of
synthetic programs. Our system is able to predict function return types with a
79.1% F1-measure, whereas the best decompiler obtains a 30% F1-measure.
Moreover, we document the binary patterns used by our classifier to allow their
addition in the implementation of existing decompilers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 11:45:46 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 11:01:27 GMT""}]","2021-02-25"
"2101.08131","Sergey Tyul'bashev A.","E.A. Brylyakova and S.A. Tyul'bashev","Pulse energy distribution for RRAT J0139+33 according to observations at
  the frequency 111 MHz","6 pages, 5 figures; Astronomy and Astrophysics (accepted)","A&A 647, A191 (2021)","10.1051/0004-6361/202037702",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using five year monitoring observations, we did a blind search for pulses for
rotating radio transient (RRAT) J0139+33 and PSR B0320+39. At the interval \pm
1.5m of the time corresponding to the source passing through the meridian, we
detected 39377 individual pulses for the pulsar B0320+39 and 1013 pulses for
RRAT J0139+33. The share of registered pulses from the total number of observed
periods for the pulsar B0320+39 is 74%, and for the transient J0139+33 it is
0.42%. Signal-to-noise ratio (S/N) for the strongest registered pulses is
approximately equal to: S/N = 262 (for B0320+39) and S/N = 154 (for J0139+33).
  Distributions of the number of detected pulses in S/N units for the pulsar
and for the rotating transient are obtained. The distributions could be
approximated with a lognormal and power dependencies. For B0320+39 pulsar, the
dependence is lognormal, it turns into a power dependence at high values of
S/N, and for RRAT J0139+33, the distribution of pulses by energy is described
by a broken (bimodal) power dependence with an exponent of about 0.4 and 1.8
(S/N < 19 and S/N > 19).
  We have not detected regular (pulsar) emission of J0139+33. Analysis of the
obtained data suggests that RRAT J0139+33 is a pulsar with giant pulses.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:55:14 GMT""}]","2021-04-07"
"2101.08136","An Pan","Yuting Gao, Jiurun Chen, Aiye Wang, An Pan, Caiwen Ma, Baoli Yao","High-throughput fast full-color digital pathology based on Fourier
  ptychographic microscopy via color transfer","24 pages, 8 figures",,"10.1007/s11433-021-1730-x",,"eess.IV physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Full-color imaging is significant in digital pathology. Compared with a
grayscale image or a pseudo-color image that only contains the contrast
information, it can identify and detect the target object better with color
texture information. Fourier ptychographic microscopy (FPM) is a
high-throughput computational imaging technique that breaks the tradeoff
between high resolution (HR) and large field-of-view (FOV), which eliminates
the artifacts of scanning and stitching in digital pathology and improves its
imaging efficiency. However, the conventional full-color digital pathology
based on FPM is still time-consuming due to the repeated experiments with
tri-wavelengths. A color transfer FPM approach, termed CFPM was reported. The
color texture information of a low resolution (LR) full-color pathologic image
is directly transferred to the HR grayscale FPM image captured by only a single
wavelength. The color space of FPM based on the standard CIE-XYZ color model
and display based on the standard RGB (sRGB) color space were established.
Different FPM colorization schemes were analyzed and compared with thirty
different biological samples. The average root-mean-square error (RMSE) of the
conventional method and CFPM compared with the ground truth is 5.3% and 5.7%,
respectively. Therefore, the acquisition time is significantly reduced by 2/3
with the sacrifice of precision of only 0.4%. And CFPM method is also
compatible with advanced fast FPM approaches to reduce computation time
further.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:51:57 GMT""}]","2022-04-26"
"2101.08137","Edilson Arruda","Edilson F. Arruda and Dayse H. Pastore and Clauda M. Dias and Shyam S.
  Das","Modelling and Optimal Control of Multi Strain Epidemics, with
  Application to COVID-19",,,"10.1371/journal.pone.0257512",,"eess.SY cs.SY q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This work introduces a novel epidemiological model that simultaneously
considers multiple viral strains, reinfections due to waning immunity response
over time and an optimal control formulation. This enables us to derive optimal
mitigation strategies over a prescribed time horizon under a more realistic
framework that does not imply perennial immunity and a single strain, although
these can also be derived as particular cases of our formulation. The model
also allows estimation of the number of infections over time in the absence of
mitigation strategies under any number of viral strains. We validate our
approach in the light of the COVID-19 epidemic and present a number of
experiments to shed light on the overall behaviour under one or two strains in
the absence of sufficient mitigation measures. We also derive optimal control
strategies for distinct mitigation costs and evaluate the effect of these costs
on the optimal mitigation measures over a two-year horizon. The results show
that relaxations in the mitigation measures cause a rapid increase in the
number of cases, which then demand more restrictive measures in the future.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:17:41 GMT""}]","2021-09-10"
"2101.08138","P\'eter Salvi","Kenjiro T. Miura, P\'eter Salvi","On the curvature extrema of special cubic B\'ezier curves",,,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is proved that special cubic B\'ezier curves, generated from quadratic
curves by the use of a scalar parameter, have at most one local curvature
extremum in the $(0,1)$ parameter interval.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 08:44:38 GMT""}]","2021-01-21"
"2101.08139","Aizhan Myrzakul R","Aizhan Myrzakul, Chi Xiong, Michael R.R. Good","Relativistic quantum information as radiation reaction: entanglement
  entropy and self-force of a moving mirror analog to the CGHS black hole","13 pages, 5 figures, 1 table","Entropy 2021, 23(12), 1664","10.3390/e23121664",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  The CGHS black hole has a spectrum and temperature that corresponds to an
accelerated reflecting boundary condition in flat spacetime. The beta
coefficients are identical to a moving mirror model where the acceleration is
exponential in laboratory time. The center and the event horizon of the black
hole are at the same location modeled by the perfectly reflecting regularity
condition that red-shifts the field modes. In addition to computing the energy
flux, we find the corresponding parameter associated with the black hole mass
and the cosmological constant in the gravitational analog system. Generalized
to any mirror trajectory we derive the self-force (Lorentz-Abraham-Dirac) and
express it and the power (Larmor) in connection with entanglement entropy,
inviting an interpretation of acceleration radiation in terms of information
flow. The mirror self-force and radiative power are applied to the particular
CGHS black hole analog moving mirror which reveals the physics of information
at the horizon during asymptotic approach to thermal equilibrium.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 06:03:39 GMT""}]","2021-12-14"
"2101.08177","Ximing Qiao","Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li, Yiran Chen, Hai Li","On Provable Backdoor Defense in Collaborative Learning",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  As collaborative learning allows joint training of a model using multiple
sources of data, the security problem has been a central concern. Malicious
users can upload poisoned data to prevent the model's convergence or inject
hidden backdoors. The so-called backdoor attacks are especially difficult to
detect since the model behaves normally on standard test data but gives wrong
outputs when triggered by certain backdoor keys. Although Byzantine-tolerant
training algorithms provide convergence guarantee, provable defense against
backdoor attacks remains largely unsolved. Methods based on randomized
smoothing can only correct a small number of corrupted pixels or labels;
methods based on subset aggregation cause a severe drop in classification
accuracy due to low data utilization. We propose a novel framework that
generalizes existing subset aggregation methods. The framework shows that the
subset selection process, a deciding factor for subset aggregation methods, can
be viewed as a code design problem. We derive the theoretical bound of data
utilization ratio and provide optimal code construction. Experiments on non-IID
versions of MNIST and CIFAR-10 show that our method with optimal codes
significantly outperforms baselines using non-overlapping partition and random
selection. Additionally, integration with existing coding theory results shows
that special codes can track the location of the attackers. Such capability
provides new countermeasures to backdoor attacks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:39:32 GMT""}]","2021-01-21"
"2101.08237","Huixiang Luo","Huixiang Luo, Hao Cheng, Fanxu Meng, Yuting Gao, Ke Li, Mengdan Zhang,
  Xing Sun","An Empirical Study and Analysis on Open-Set Semi-Supervised Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pseudo-labeling (PL) and Data Augmentation-based Consistency Training (DACT)
are two approaches widely used in Semi-Supervised Learning (SSL) methods. These
methods exhibit great power in many machine learning tasks by utilizing
unlabeled data for efficient training. But in a more realistic setting (termed
as open-set SSL), where unlabeled dataset contains out-of-distribution (OOD)
samples, the traditional SSL methods suffer severe performance degradation.
Recent approaches mitigate the negative influence of OOD samples by filtering
them out from the unlabeled data. However, it is not clear whether directly
removing the OOD samples is the best choice. Furthermore, why PL and DACT could
perform differently in open-set SSL remains a mystery. In this paper, we
thoroughly analyze various SSL methods (PL and DACT) on open-set SSL and
discuss pros and cons of these two approaches separately. Based on our
analysis, we propose Style Disturbance to improve traditional SSL methods on
open-set SSL and experimentally show our approach can achieve state-of-the-art
results on various datasets by utilizing OOD samples properly. We believe our
study can bring new insights for SSL research.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:38:17 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 06:14:51 GMT""}]","2021-09-15"
"2101.08658","Ofer Mendelevitch","Ofer Mendelevitch, Michael D. Lesh","Fidelity and Privacy of Synthetic Medical Data",,,,,"cs.LG cs.AI cs.CR","http://creativecommons.org/licenses/by/4.0/","  The digitization of medical records ushered in a new era of big data to
clinical science, and with it the possibility that data could be shared, to
multiply insights beyond what investigators could abstract from paper records.
The need to share individual-level medical data to accelerate innovation in
precision medicine continues to grow, and has never been more urgent, as
scientists grapple with the COVID-19 pandemic. However, enthusiasm for the use
of big data has been tempered by a fully appropriate concern for patient
autonomy and privacy. That is, the ability to extract private or confidential
information about an individual, in practice, renders it difficult to share
data, since significant infrastructure and data governance must be established
before data can be shared. Although HIPAA provided de-identification as an
approved mechanism for data sharing, linkage attacks were identified as a major
vulnerability. A variety of mechanisms have been established to avoid leaking
private information, such as field suppression or abstraction, strictly
limiting the amount of information that can be shared, or employing
mathematical techniques such as differential privacy. Another approach, which
we focus on here, is creating synthetic data that mimics the underlying data.
For synthetic data to be a useful mechanism in support of medical innovation
and a proxy for real-world evidence, one must demonstrate two properties of the
synthetic dataset: (1) any analysis on the real data must be matched by
analysis of the synthetic data (statistical fidelity) and (2) the synthetic
data must preserve privacy, with minimal risk of re-identification (privacy
guarantee). In this paper we propose a framework for quantifying the
statistical fidelity and privacy preservation properties of synthetic datasets
and demonstrate these metrics for synthetic data generated by Syntegra
technology.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:01:27 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 04:41:17 GMT""}]","2021-06-03"
"2101.09147","Jesus Fuentes","Jes\'us Fuentes and Octavio Obreg\'on","A superstatistical formulation of complexity measures","17 pages, 1 figure",,,,"cs.CC math-ph math.MP stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is discussed how the superstatistical formulation of effective Boltzmann
factors can be related to the concept of Kolmogorov complexity, generating an
infinite set of complexity measures (CMs) for quantifying information. At this
level, the information is treated according to its background, which means that
the CM depends on the inherent attributes of the information scenario. While
the basic Boltzmann factor directly produces the standard complexity measure
(SCM), it succeeds in the description of large-scale scenarios where the data
components are not interrelated with themselves, thus adopting the behaviour of
a gas. What happens in scenarios in which the presence of sources and sinks of
information cannot be neglected, needs of a CM other than the one produced by
the ordinary Boltzmann factor. We introduce a set of flexible CMs, without free
parameters, that converge asymptotically to the Kolmogorov complexity, but also
quantify the information in scenarios with a reasonable small density of
states. We prove that these CMs are obtained from a generalised relative
entropy and we suggest why such measures are the only compatible
generalisations of the SCM.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:19:14 GMT""}]","2021-01-25"
"2101.09163","Aidong Yang","Ye Ouyang (1), Lilei Wang (1), Aidong Yang (1), Maulik Shah (2), David
  Belanger (3 and 4), Tongqing Gao (5), Leping Wei (6), Yaqin Zhang (7) ((1)
  AsiaInfo Technologies, (2) Verizon, (3) AT&T, (4) Stevens Institute of
  Technology, (5) China Mobile, (6) China Telecom, (7) Tsinghua University)","The Next Decade of Telecommunications Artificial Intelligence","50 pages in English 24 figures. (Note version 5 is 19 pages, in
  Chinese, with 24 figures)","CAAI Artificial Intelligence Research, 2022, 1 (1): 28-53","10.26599/AIR.2022.9150003",,"cs.NI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been an exciting journey since the mobile communications and
artificial intelligence were conceived 37 years and 64 years ago. While both
fields evolved independently and profoundly changed communications and
computing industries, the rapid convergence of 5G and deep learning is
beginning to significantly transform the core communication infrastructure,
network management and vertical applications. The paper first outlines the
individual roadmaps of mobile communications and artificial intelligence in the
early stage, with a concentration to review the era from 3G to 5G when AI and
mobile communications started to converge. With regard to telecommunications
artificial intelligence, the paper further introduces in detail the progress of
artificial intelligence in the ecosystem of mobile communications. The paper
then summarizes the classifications of AI in telecom ecosystems along with its
evolution paths specified by various international telecommunications
standardization bodies. Towards the next decade, the paper forecasts the
prospective roadmap of telecommunications artificial intelligence. In line with
3GPP and ITU-R timeline of 5G & 6G, the paper further explores the network
intelligence following 3GPP and ORAN routes respectively, experience and
intention driven network management and operation, network AI signalling
system, intelligent middle-office based BSS, intelligent customer experience
management and policy control driven by BSS and OSS convergence, evolution from
SLA to ELA, and intelligent private network for verticals. The paper is
concluded with the vision that AI will reshape the future B5G or 6G landscape
and we need pivot our R&D, standardizations, and ecosystem to fully take the
unprecedented opportunities.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 07:33:44 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 02:25:23 GMT""},{""version"":""v3"",""created"":""Mon, 22 Feb 2021 10:19:47 GMT""},{""version"":""v4"",""created"":""Mon, 1 Mar 2021 14:41:49 GMT""},{""version"":""v5"",""created"":""Thu, 2 Dec 2021 02:25:55 GMT""},{""version"":""v6"",""created"":""Fri, 3 Dec 2021 02:18:41 GMT""}]","2022-10-11"
"2101.09164","Christoph Reinhardt","Christoph Reinhardt (1), Alexander Franke (2), J\""orn Schaffran (1),
  Roman Schnabel (2), Axel Lindner (1) ((1) Deutsches Elektronen Synchrotron
  (DESY), Hamburg, Germany, (2) Institut f\""ur Laserphysik und Zentrum f\""ur
  Optische Quantentechnologien der Universit\""at Hamburg, Hamburg, Germany)","Gas cooling of test masses for future gravitational-wave observatories",,,"10.1088/1361-6382/ac18bc",,"physics.ins-det astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations made with Advanced LIGO and Advanced Virgo have initiated
the era of gravitational-wave astronomy. The number of events detected by these
""2nd Generation"" (2G) ground-based observatories is partially limited by noise
arising from temperature-induced position fluctuations of the test mass mirror
surfaces used for probing spacetime dynamics. The design of next-generation
gravitational-wave observatories addresses this limitation by using
cryogenically cooled test masses; current approaches for continuously removing
heat (resulting from absorbed laser light) rely on heat extraction via
black-body radiation or conduction through suspension fibres. As a
complementing approach for extracting heat during observational runs, we
investigate cooling via helium gas impinging on the test mass in free molecular
flow. We establish a relation between cooling power and corresponding
displacement noise, based on analytical models, which we compare to numerical
simulations. Applying this theoretical framework with regard to the conceptual
design of the Einstein Telescope (ET), we find a cooling power of 10 mW at 18 K
for a gas pressure that exceeds the ET design strain noise goal by at most a
factor of $\sim 3$ in the signal frequency band from 3 to 11 Hz. A cooling
power of 100 mW at 18 K corresponds to a gas pressure that exceeds the ET
design strain noise goal by at most a factor of $\sim 11$ in the band from 1 to
28 Hz.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:35:09 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 19:24:59 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 20:35:11 GMT""}]","2021-09-01"
"2101.09165","Bangti Jin","Bangti Jin and Yavar Kian","Recovery of the Order of Derivation for Fractional Diffusion Equations
  in an Unknown Medium","22 pages, 3 figures, to appear at SIAM Journal on Applied Mathematics",,,,"math.AP cs.NA math.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we investigate the recovery of a parameter in a diffusion
process given by the order of derivation in time for a class of diffusion type
equations, including both classical and time-fractional diffusion equations,
from the flux measurement observed at one point on the boundary. The
mathematical model for time-fractional diffusion equations involves a
Djrbashian-Caputo fractional derivative in time. We prove a uniqueness result
in an unknown medium (e.g., diffusion coefficients, obstacle, initial condition
and source), i.e., the recovery of the order of derivation in a diffusion
process having several pieces of unknown information. The proof relies on the
analyticity of the solution at large time, asymptotic decay behavior, strong
maximum principle of the elliptic problem and suitable application of the Hopf
lemma. Further we provide an easy-to-implement reconstruction algorithm based
on a nonlinear least-squares formulation, and several numerical experiments are
presented to complement the theoretical analysis.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 23:18:54 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 13:34:51 GMT""}]","2021-11-04"
"2101.10074","Setareh Maghsudi","Setareh Maghsudi, Andrew Lan, Jie Xu, and Mihaela van der Schaar","Personalized Education in the AI Era: What to Expect Next?",,,"10.1109/MSP.2021.3055032",,"cs.CY cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of personalized learning is to design an effective knowledge
acquisition track that matches the learner's strengths and bypasses her
weaknesses to ultimately meet her desired goal. This concept emerged several
years ago and is being adopted by a rapidly-growing number of educational
institutions around the globe. In recent years, the boost of artificial
intelligence (AI) and machine learning (ML), together with the advances in big
data analysis, has unfolded novel perspectives to enhance personalized
education in numerous dimensions. By taking advantage of AI/ML methods, the
educational platform precisely acquires the student's characteristics. This is
done, in part, by observing the past experiences as well as analyzing the
available big data through exploring the learners' features and similarities.
It can, for example, recommend the most appropriate content among numerous
accessible ones, advise a well-designed long-term curriculum, connect
appropriate learners by suggestion, accurate performance evaluation, and the
like. Still, several aspects of AI-based personalized education remain
unexplored. These include, among others, compensating for the adverse effects
of the absence of peers, creating and maintaining motivations for learning,
increasing diversity, removing the biases induced by the data and algorithms,
and the like. In this paper, while providing a brief review of state-of-the-art
research, we investigate the challenges of AI/ML-based personalized education
and discuss potential solutions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 12:23:32 GMT""}]","2021-02-16"
"2101.10076","Song-Jin Im","Kil-Song Song, Song-Jin Im, Ji-Song Pae, Chol-Song Ri, Kum-Song Ho,
  Chol-Sun Kim, Yong-Ha Han","Optically induced nonreciprocity by a plasmonic pump in semiconductor
  wires",,"Phys. Rev. B 102, 115435 (2020)","10.1103/PhysRevB.102.115435",,"cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In most studies on all-optical diodes spatial asymmetry has been by necessity
applied to break Lorentz reciprocity. Here we suggest a paradigm for optically
induced nonreciprocity in semiconductor wires which are spatially
asymmetry-free and provide a very simple and efficient platform for plasmonic
devices. An azimuthal magnetic field induced by a plasmonic pump in the
semiconductor wire alters the material parameters and thus results in a
cross-nonlinear modulation of the plasmonic signal. Peculiarly the nonlinear
wavenumber shift has opposite signs for forward and backward signals whereas
Kerr or Kerr-like nonlinearity does not break Lorentz reciprocity in spatially
symmetric structures. This principle may open an avenue towards highly
integrated all-optical nonreciprocal devices.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:18:22 GMT""}]","2021-01-26"
"2101.10077","Hamid Chorsi","Xuejun Xie, Hamid T. Chorsi, Kunjesh Agashiwala, Hsun-Ming Chang,
  Jiahao Kang, Jae Hwan Chu, Ibrahim Sarpkaya, Han Htoon, Jon A. Schuller,
  Kaustav Banerjee","The scaling of the microLED and the advantage of 2D materials",,,,,"physics.app-ph physics.comp-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  The demand for higher resolution displays drives the demand for smaller
pixels. Displays show a trend of doubling the pixel number every 4 years and
doubling the pixel per inch (PPI) every 6 years. As the prospective candidate
for next-generation display technology, microLED (micro Light Emitting Diode)
will suffer from sidewall current leakage and poor extraction efficiency as its
lateral size reduces. Using Finite Element Analysis (FEA) method and
Finite-Difference Time-Domain (FDTD) method, we find that reducing the
thickness of the LED can reduce the current leaking to the sidewalls and reduce
the total internal reflection simultaneously. A promising solution to this
problem is by using atomically thin 2D materials to make LEDs. However,
monolayer inorganic 2D materials that can provide red, green and blue emission
are still lacking. Based on the blue light-emitting material fluorographene
(CF), partially fluorinated graphene (CFx) is synthesized in this work to emit
red and green colors from 683 nm to 555 nm (limited by the instrument). This
work also demonstrates lithographically defined regions with different colors,
paving the way for the scaling of microLED.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 21:12:20 GMT""}]","2021-01-26"
"2101.10078","Hedayat Zarkoob","Hedayat Zarkoob, Farzad Abdolhosseini, and Kevin Leyton-Brown","Mechanical TA 2: A System for Peer Grading with TA Support",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mechanical TA 2 (MTA2) is an open source web-based peer grading application
that leverages trusted TA graders to incentivize high-quality peer review. A
previous, prototype implementation of MTA proved the value of the concept, but
was neither suitable for use at scale nor easily extensible; MTA2 is a complete
reimplementation of the system that overcomes these hurdles. MTA2 serves two,
interconnected purposes: facilitating practical peer grading and serving as a
testbed for experimentation with different peer grading mechanisms. The system
is characterized by a modular design that makes customization easy; support for
dividing students into different pools based on their peer-grading prowess;
mechanisms for automated calibration and spot checking; and the ability for
students to appeal grades and to give feedback about individual reviews.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:41:15 GMT""}]","2021-01-26"
"2101.10079","Debra Laefer","Debra F. Laefer, Thomas Kirchner, Haoran (Frank) Jiang, Darlene
  Cheong, Yunqi (Veronica) Jiang, Aseah Khan, Weiyi Qiu, Nikki Tai, Tiffany
  Truong, Maimunah Virk","Data Resource Profile: Egress Behavior from Select NYC COVID-19 Exposed
  Health Facilities March-May 2020","14 Pages, 4 figures",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Vector control strategies are central to the mitigation and containment of
COVID-19 and have come in the form of municipal ordinances that restrict the
operational status of public and private spaces and associated services. Yet,
little is known about specific population responses in terms of risk behaviors.
To help understand the impact of those vector control variable strategies, a
multi-week, multi-site observational study was undertaken outside of 19 New
York City medical facilities during the peak of the city's initial COVID-19
wave (03/22/20-05/19/20). The aim was to capture perishable data of the touch,
destination choice, and PPE usage behavior of individuals egressing hospitals
and urgent care centers. A major goal was to establish an empirical basis for
future research on the way people interact with three-dimensional vector
environments. Anonymized data were collected via smart phones. Each data record
includes the time, data, and location of an individual leaving a healthcare
facility, their routing, interactions with the build environment, other
individuals, and themselves. Most records also note their PPE usage,
destination, intermediary stops, and transportation choices. The records were
linked with 61 socio-economic factors by the facility zip code and 7
contemporaneous weather factors and the merged in a unified shapefile in an
ARCGIS system. This paper describes the project team and protocols used to
produce over 5,100 publicly accessible observational records and an affiliated
codebook that can be used to study linkages between individual behaviors and
on-the-ground conditions.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:21:16 GMT""}]","2021-01-26"
"2101.10091","Mehran Sahandi Far","Mehran Sahandi Far, Michael Stolz, Jona M. Fischer, Simon B. Eickhoff,
  Juergen Dukart","JTrack: A Digital Biomarker Platform for Remote Monitoring in
  Neurological and Psychiatric Diseases","package Name for application is changed",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective: Health-related data being collected by smartphones offer a
promising complementary approach to in-clinic assessments. Here we introduce
the JTrack platform as a secure, reliable and extendable open-source solution
for remote monitoring in daily-life and digital phenotyping. Method: JTrack
consists of an Android-based smartphone application and a web-based project
management dashboard. A wide range of anonymized measurements from
motion-sensors, social and physical activities and geolocation information can
be collected in either active or passive modes. The dashboard also provides
management tools to monitor and manage data collection across studies. To
facilitate scaling, reproducibility, data management and sharing we integrated
DataLad as a data management infrastructure. JTrack was developed to comply
with security, privacy and the General Data Protection Regulation (GDPR)
requirements. Results: JTrack is an open-source (released under open-source
Apache 2.0 licenses) platform for remote assessment of digital biomarkers (DB)
in neurological, psychiatric and other indications. The main components of the
JTrack platform and examples of data being collected using JTrack are presented
here. Conclusion: Smartphone-based Digital Biomarker data may provide valuable
insight into daily life behaviour in health and disease. JTrack provides an
easy and reliable open-source solution for collection of such data.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:51:47 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 16:16:07 GMT""},{""version"":""v3"",""created"":""Tue, 2 Feb 2021 17:48:45 GMT""}]","2021-02-03"
"2101.10442","Setianto Setianto","Novianty Rizky Ardiani, Setianto Setianto, Budy Santosa, Bambang Mukti
  Wibawa, Camellia Panatarani, and I Made Joni","Quantitative analysis of iron sand mineral content from the south coast
  of Cidaun, West Java using rietveld refinement method",,,"10.1063/5.0003018",,"physics.geo-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Iron sand is one of the abundant natural resources in Indonesia, especially
on the south coast of Cidaun; West Java which is the basic material for
building and metal industry. Iron mineral content is generally metal oxide such
as magnetite, hematite and silica/quartz. Sand with iron content used in this
study is derived from beach sand Desa Kertajadi, Kecamatan Cidaun, Kabupaten
Cianjur, Jawa Barat. Then mass of 2 kg sand was separated using a magnetic
separator in order to obtain magnetic and nonmagnetic mineral content. After
nine rounds of separation takes two different types of samples that are no
separation sand (TS) sample and concentrate in the third separation (S3)
sample. The sample is then examined by X-Ray Diffraction (XRD) measurement and
analyzed quantitatively using MAUD software to determine the content of Fe3O4
(magnetite) by using the Rietveld refinement method from XRD data. As the
analysis result, the magnetite content contained in iron sand is counted
quantitatively for each different sample. For iron sand samples (TS) yielding a
24.27 percent of magnetite and a third concentrate separation sample (S3)
yields 61.98 percent.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 13:07:07 GMT""}]","2021-01-27"
"2101.10842","Masato Ishii","Masato Ishii and Masashi Sugiyama","Source-free Domain Adaptation via Distributional Alignment by Matching
  Batch Normalization Statistics",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel domain adaptation method for the
source-free setting. In this setting, we cannot access source data during
adaptation, while unlabeled target data and a model pretrained with source data
are given. Due to lack of source data, we cannot directly match the data
distributions between domains unlike typical domain adaptation algorithms. To
cope with this problem, we propose utilizing batch normalization statistics
stored in the pretrained model to approximate the distribution of unobserved
source data. Specifically, we fix the classifier part of the model during
adaptation and only fine-tune the remaining feature encoder part so that batch
normalization statistics of the features extracted by the encoder match those
stored in the fixed classifier. Additionally, we also maximize the mutual
information between the features and the classifier's outputs to further boost
the classification performance. Experimental results with several benchmark
datasets show that our method achieves competitive performance with
state-of-the-art domain adaptation methods even though it does not require
access to source data.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:22:33 GMT""}]","2021-01-27"
"2101.10844","Mingkui Tan","Zhuoman Liu, Wei Jia, Ming Yang, Peiyao Luo, Yong Guo, and Mingkui Tan","Deep View Synthesis via Self-Consistent Generative Network",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  View synthesis aims to produce unseen views from a set of views captured by
two or more cameras at different positions. This task is non-trivial since it
is hard to conduct pixel-level matching among different views. To address this
issue, most existing methods seek to exploit the geometric information to match
pixels. However, when the distinct cameras have a large baseline (i.e., far
away from each other), severe geometry distortion issues would occur and the
geometric information may fail to provide useful guidance, resulting in very
blurry synthesized images. To address the above issues, in this paper, we
propose a novel deep generative model, called Self-Consistent Generative
Network (SCGN), which synthesizes novel views from the given input views
without explicitly exploiting the geometric information. The proposed SCGN
model consists of two main components, i.e., a View Synthesis Network (VSN) and
a View Decomposition Network (VDN), both employing an Encoder-Decoder
structure. Here, the VDN seeks to reconstruct input views from the synthesized
novel view to preserve the consistency of view synthesis. Thanks to VDN, SCGN
is able to synthesize novel views without using any geometric rectification
before encoding, making it easier for both training and applications. Finally,
adversarial loss is introduced to improve the photo-realism of novel views.
Both qualitative and quantitative comparisons against several state-of-the-art
methods on two benchmark tasks demonstrated the superiority of our approach.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 10:56:00 GMT""}]","2021-01-27"
"2101.10845","Angelo Menezes","Angelo G. Menezes","Analysis and evaluation of Deep Learning based Super-Resolution
  algorithms to improve performance in Low-Resolution Face Recognition","MSc Thesis under supervision of Carlos A. E. Montesco presented at
  the Federal University of Sergipe, Brazil (2019)",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Surveillance scenarios are prone to several problems since they usually
involve low-resolution footage, and there is no control of how far the subjects
may be from the camera in the first place. This situation is suitable for the
application of upsampling (super-resolution) algorithms since they may be able
to recover the discriminant properties of the subjects involved. While general
super-resolution approaches were proposed to enhance image quality for
human-level perception, biometrics super-resolution methods seek the best
""computer perception"" version of the image since their focus is on improving
automatic recognition performance. Convolutional neural networks and deep
learning algorithms, in general, have been applied to computer vision tasks and
are now state-of-the-art for several sub-domains, including image
classification, restoration, and super-resolution. However, no work has
evaluated the effects that the latest proposed super-resolution methods may
have upon the accuracy and face verification performance in low-resolution
""in-the-wild"" data. This project aimed at evaluating and adapting different
deep neural network architectures for the task of face super-resolution driven
by face recognition performance in real-world low-resolution images. The
experimental results in a real-world surveillance and attendance datasets
showed that general super-resolution architectures might enhance face
verification performance of deep neural networks trained on high-resolution
faces. Also, since neural networks are function approximators and can be
trained based on specific objective functions, the use of a customized loss
function optimized for feature extraction showed promising results for
recovering discriminant features in low-resolution face images.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 02:41:57 GMT""}]","2021-01-27"
"2101.10846","Alessandro Bria","Alessandro Bria, Claudio Marrocco, Francesco Tortorella","Sinc-based convolutional neural networks for EEG-BCI-based motor imagery
  classification",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Brain-Computer Interfaces (BCI) based on motor imagery translate mental motor
images recognized from the electroencephalogram (EEG) to control commands. EEG
patterns of different imagination tasks, e.g. hand and foot movements, are
effectively classified with machine learning techniques using band power
features. Recently, also Convolutional Neural Networks (CNNs) that learn both
effective features and classifiers simultaneously from raw EEG data have been
applied. However, CNNs have two major drawbacks: (i) they have a very large
number of parameters, which thus requires a very large number of training
examples; and (ii) they are not designed to explicitly learn features in the
frequency domain. To overcome these limitations, in this work we introduce
Sinc-EEGNet, a lightweight CNN architecture that combines learnable band-pass
and depthwise convolutional filters. Experimental results obtained on the
publicly available BCI Competition IV Dataset 2a show that our approach
outperforms reference methods in terms of classification accuracy.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 15:55:29 GMT""}]","2021-01-27"
"2101.11461","Fupin Yao","Fupin Yao","Machine learning with limited data",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Thanks to the availability of powerful computing resources, big data and deep
learning algorithms, we have made great progress on computer vision in the last
few years. Computer vision systems begin to surpass humans in some tasks, such
as object recognition, object detection, face recognition and pose estimation.
Lots of computer vision algorithms have been deployed to real world
applications and started to improve our life quality. However, big data and
labels are not always available. Sometimes we only have very limited labeled
data, such as medical images which requires experts to label them. In this
paper, we study few shot image classification, in which we only have very few
labeled data. Machine learning with little data is a big challenge. To tackle
this challenge, we propose two methods and test their effectiveness thoroughly.
One method is to augment image features by mixing the style of these images.
The second method is applying spatial attention to explore the relations
between patches of images. We also find that domain shift is a critical issue
in few shot learning when the training domain and testing domain are different.
So we propose a more realistic cross-domain few-shot learning with unlabeled
data setting, in which some unlabeled data is available in the target domain.
We propose two methods in this setting. Our first method transfers the style
information of the unlabeled target dataset to the samples in the source
dataset and trains a model with stylized images and original images. Our second
method proposes a unified framework to fully utilize all the data. Both of our
methods surpass the baseline method by a large margin.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 17:10:39 GMT""}]","2021-01-28"
"2101.12009","Kazuoki Munakata","W. Kihara, K. Munakata, C. Kato, R. Kataoka, A. Kadokura, S. Miyake,
  M. Kozai, T. Kuwabara, M. Tokumaru, R. R. S. Mendon\c{c}a, E. Echer, A. Dal
  Lago, M. Rockenbach, N. J. Schuch, J. V. Bageston, C. R. Braga, H. K. Al
  Jassar, M. M. Sharma, M. L. Duldig, J. E. Humble, P. Evenson, I. Sabbah, and
  J. K\'ota","A Peculiar ICME Event in August 2018 Observed with the Global Muon
  Detector Network","19 pages, 3 figures, accepted for publication in the Space Weather",,"10.1029/2020SW002531",,"physics.space-ph astro-ph.EP astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that global observations of high-energy cosmic rays contribute
to understanding unique characteristics of a large-scale magnetic flux rope
causing a magnetic storm in August 2018. Following a weak interplanetary shock
on 25 August 2018, a magnetic flux rope caused an unexpectedly large
geomagnetic storm. It is likely that this event became geoeffective because the
flux rope was accompanied by a corotating interaction region and compressed by
high-speed solar wind following the flux rope. In fact, a Forbush decrease was
observed in cosmic-ray data inside the flux rope as expected, and a significant
cosmic-ray density increase exceeding the unmodulated level before the shock
was also observed near the trailing edge of the flux rope. The cosmic-ray
density increase can be interpreted in terms of the adiabatic heating of cosmic
rays near the trailing edge of the flux rope, as the corotating interaction
region prevents free expansion of the flux rope and results in the compression
near the trailing edge. A northeast-directed spatial gradient in the cosmic-ray
density was also derived during the cosmic-ray density increase, suggesting
that the center of the heating near the trailing edge is located northeast of
Earth. This is one of the best examples demonstrating that the observation of
high-energy cosmic rays provides us with information that can only be derived
from the cosmic ray measurements to observationally constrain the
three-dimensional macroscopic picture of the interaction between coronal mass
ejections and the ambient solar wind, which is essential for prediction of
large magnetic storms.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 09:17:50 GMT""}]","2021-04-07"
"2102.00824","Nikunj Gupta","Nikunj Gupta, G Srinivasaraghavan, Swarup Kumar Mohalik, Nishant
  Kumar, Matthew E. Taylor","HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via
  Learned Messaging",,,,,"cs.MA cs.AI cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Cooperative multi-agent reinforcement learning (MARL) has achieved
significant results, most notably by leveraging the representation-learning
abilities of deep neural networks. However, large centralized approaches
quickly become infeasible as the number of agents scale, and fully
decentralized approaches can miss important opportunities for information
sharing and coordination. Furthermore, not all agents are equal -- in some
cases, individual agents may not even have the ability to send communication to
other agents or explicitly model other agents. This paper considers the case
where there is a single, powerful, \emph{central agent} that can observe the
entire observation space, and there are multiple, low-powered \emph{local
agents} that can only receive local observations and are not able to
communicate with each other. The central agent's job is to learn what message
needs to be sent to different local agents based on the global observations,
not by centrally solving the entire problem and sending action commands, but by
determining what additional information an individual agent should receive so
that it can make a better decision. In this work we present our MARL algorithm
\algo, describe where it would be most applicable, and implement it in the
cooperative navigation and multi-agent walker domains. Empirical results show
that 1) learned communication does indeed improve system performance, 2)
results generalize to heterogeneous local agents, and 3) results generalize to
different reward structures.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:00:12 GMT""},{""version"":""v2"",""created"":""Fri, 2 Dec 2022 08:40:42 GMT""}]","2022-12-05"
"2102.01201","Tarik A. Rashid","Shahla U. Umar, Tarik A. Rashid","Critical Analysis: Bat Algorithm based Investigation and Application on
  Several Domains","25 pages, Review paper","World Journal of Engineering, 2021","10.1108/WJE-10-2020-0495",,"cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years several swarm optimization algorithms, such as Bat Algorithm
(BA) have emerged, which was proposed by Xin-She Yang in 2010. The idea of the
algorithm was taken from the echolocation ability of bats.
  Purpose: The purpose of this study is to provide the reader with a full study
of the Bat Algorithm, including its limitations, the fields that the algorithm
has been applied, versatile optimization problems in different domains, and all
the studies that assess its performance against other meta-heuristic
algorithms.
  Approach: Bat Algorithm is given in-depth in terms of backgrounds,
characteristics, limitations, it has also displayed the algorithms that
hybridized with BA (K-Medoids, Back-propagation neural network, Harmony Search
Algorithm, Differential Evaluation Strategies, Enhanced Particle Swarm
Optimization, and Cuckoo Search Algorithm) and their theoretical results, as
well as to the modifications that have been performed of the algorithm
(Modified Bat Algorithm (MBA), Enhanced Bat Algorithm (EBA), Bat Algorithm with
Mutation (BAM), Uninhabited Combat Aerial Vehicle-Bat algorithm with Mutation
(UCAV-BAM), Nonlinear Optimization)...
  Findings: Shed light on the advantages and disadvantages of this algorithm
through all the researches that dealt with the algorithm in addition to the
fields and applications it has addressed in the hope that it will help
scientists understand and develop it.
  Originality/value: As far as the research community knowledge, there is no
comprehensive survey study conducted on this algorithm cover{\i}ng all its
aspects.
  Keywords: Swarm Intelligence; Nature-Inspired Algorithms; Metaheuristic
Algorithms; Optimization Algorithms; Bat Algorithm.
","[{""version"":""v1"",""created"":""Mon, 18 Jan 2021 19:25:12 GMT""}]","2021-02-03"
"2103.11759","Jesus Fuentes","Jes\'us Fuentes and Octavio Obreg\'on","On how generalised entropies without parameters impact information
  optimisation processes","8 pages, 5 figures",,,,"cs.IT cond-mat.stat-mech math.IT","http://creativecommons.org/licenses/by/4.0/","  As an application of generalised statistical mechanics, it is studied a
possible route toward a consistent generalised information theory in terms of a
family of non-extensive, non-parametric entropies $H^\pm_D(P)$. Unlike other
proposals based on non-extensive entropies with a parameter dependence, our
scheme is asymptotically equivalent to the one formulated by Shannon, while it
differs in regions where the density of states is reasonably small, which leads
to information distributions constrained to their background. Two basic
concepts are discussed to this aim. First, we prove two effective coding
theorems for the entropies $H^\pm_D(P)$. Then we calculate the channel capacity
of a binary symmetric channel (BSC) and a binary erasure channel (BEC) in terms
of these entropies. We found that processes such as data compression and
channel capacity maximisation can be improved in regions where there is a low
density of states, whereas for high densities our results coincide with
Shannon's formulation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 00:23:12 GMT""}]","2021-03-23"
"2103.11900","Qiuping A. Wang","A. El Kaabouchi, F.X. Machu, J. Cocks, R. Wang, Y.Y. Zhu and Q.A. Wang","Study of a measure of efficiency as a tool for applying the principle of
  least effort to the derivation of the Zipf and the Pareto laws","25 pages, 5 figures","Advances in Complex Systems (May 17th, 2022)",,,"math.PR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The principle of least effort is believed to be a universal rule for living
systems. Its application to the derivation of the power law probability
distributions of living systems has long been challenging. Recently, a measure
of efficiency was proposed as a tool of deriving Zipf s and Pareto s laws
directly from the principle of least effort. The present work is a further
investigation of this efficiency measure from a mathematical point of view. The
aim is to get further insight into its properties and usefulness as a metric of
performance. We address some key mathematical properties of this efficiency
such as its sign, uniqueness and robustness. We also look at the relationship
between this measure and other properties of the system of interest such as
inequality and uncertainty, by introducing a new method for calculating
non-negative continuous entropy.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:31:40 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 13:14:10 GMT""},{""version"":""v3"",""created"":""Wed, 18 May 2022 23:05:26 GMT""}]","2022-05-20"
"2104.14345","Zdzislaw Musielak","Z.E. Musielak","New Equation of Nonrelativistic Physics and Theory of Dark Matter","12 pages","International Journal of Modern Physics A, 36, 2150042 (12 pages),
  2021","10.1142/S0217751X21500421",,"physics.gen-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Two infinite sets of Galilean invariant equations are derived using the
irreducible representations of the orthochrous extended Galilean group. It is
shown that one set contains the Schr\""odinger equation, which is the
fundamental equation for ordinary matter, and the other set has a new
asymmetric equation, which is proposed to be the fundamental equation for dark
matter. Using this new equation, a theory of dark matter is developed and its
profound physical implications are discussed. This theory explains the
currently known properties of dark matter and also predicts a detectable
gravitational radiation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 14:34:57 GMT""}]","2021-04-30"

"2101.07699","Maya Fishbach","Maya Fishbach, Zoheyr Doctor, Thomas Callister, Bruce Edelman, Jiani
  Ye, Reed Essick, Will M. Farr, Ben Farr, Daniel E. Holz","When are LIGO/Virgo's Big Black-Hole Mergers?","16 pages, 11 figures. Minor updates to match published version","The Astrophysical Journal, Volume 912, Number 2, 2021","10.3847/1538-4357/abee11","LIGO-P2100007","astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolution of the binary black hole (BBH) mass distribution
across cosmic time. The second gravitational-wave transient catalog (GWTC-2)
from LIGO/Virgo contains BBH events out to redshifts $z \sim 1$, with component
masses in the range $\sim5$--$80\,M_\odot$. In this catalog, the biggest black
holes, with $m_1 \gtrsim 45\,M_\odot$, are only found at the highest redshifts,
$z \gtrsim 0.4$. We ask whether the absence of high-mass BBH observations at
low redshift indicates that the astrophysical BBH mass distribution evolves:
the biggest BBHs only merge at high redshift, and cease merging at low
redshift. Alternatively, this feature might be explained by gravitational-wave
selection effects. Modeling the BBH primary mass spectrum as a power law with a
sharp maximum mass cutoff (Truncated model), we find that the cutoff increases
with redshift ($> 99.9\%$ credibility). An abrupt cutoff in the mass spectrum
is expected from (pulsational) pair instability supernova simulations; however,
GWTC-2 is only consistent with a Truncated mass model if the location of the
cutoff increases from $45^{+13}_{-5}\,M_\odot$ at $z < 0.4$ to
$80^{+16}_{-13}\,M_\odot$ at $z > 0.4$. Alternatively, if the primary mass
spectrum has a break in the power law (Broken power law) at
${38^{+15}_{-8}\,M_\odot}$, rather than a sharp cutoff, the data are consistent
with a non-evolving mass distribution. In this case, the overall rate of
mergers, at all masses, increases with increasing redshift. Future observations
will confidently distinguish between a sharp maximum mass cutoff that evolves
with redshift and a non-evolving mass distribution with a gradual taper, such
as a Broken power law. After $\sim 100$ BBH merger observations, a continued
absence of high-mass, low-redshift events would provide a clear signature that
the mass distribution evolves with redshift.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:05:04 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 17:45:24 GMT""}]","2021-05-12"
"2101.07700","Maximiliano Cristia","Maximiliano Cristi\'a and Ricardo D. Katz and Gianfranco Rossi","Proof Automation in the Theory of Finite Sets and Finite Set Relation
  Algebra",,,,,"cs.LO","http://creativecommons.org/publicdomain/zero/1.0/","  {log} ('setlog') is a satisfiability solver for formulas of the theory of
finite sets and finite set relation algebra (FSTRA). As such, it can be used as
an automated theorem prover (ATP) for this theory. {log} is able to
automatically prove a number of FSTRA theorems, but not all of them.
Nevertheless, we have observed that many theorems that {log} cannot
automatically prove can be divided into a few subgoals automatically
dischargeable by {log}. The purpose of this work is to present a prototype
interactive theorem prover (ITP), called {log}-ITP, providing evidence that a
proper integration of {log} into world-class ITP's can deliver a great deal of
proof automation concerning FSTRA. An empirical evaluation based on 210
theorems from the TPTP and Coq's SSReflect libraries shows a noticeable
reduction in the size and complexity of the proofs with respect to Coq.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:05:40 GMT""}]","2021-01-20"
"2101.07701","Daniel Gra\c{c}a","Daniel S. Gra\c{c}a and Ning Zhong","Computing the exact number of periodic orbits for planar flows",,,"10.1090/tran/8644",,"math.DS cs.LO math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we consider the problem of determining the \emph{exact} number
of periodic orbits for polynomial planar flows. This problem is a variant of
Hilbert's 16th problem. Using a natural definition of computability, we show
that the problem is noncomputable on the one hand and, on the other hand,
computable uniformly on the set of all structurally stable systems defined on
the unit disk. We also prove that there is a family of polynomial planar
systems which does not have a computable sharp upper bound on the number of its
periodic orbits.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:06:46 GMT""},{""version"":""v2"",""created"":""Fri, 28 Oct 2022 22:16:12 GMT""}]","2022-11-01"
"2101.07702","Saqib Hussain","Saqib Hussain, Rafael Alves Batista, Elisabete M. de Gouveia Dal Pino
  and Klaus Dolag","High-Energy Neutrino Production in Clusters of Galaxies","14 pages, 31 figures, journal paper",,"10.1093/mnras/stab1804",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Clusters of galaxies can potentially produce cosmic rays (CRs) up to
very-high energies via large-scale shocks and turbulent acceleration. Due to
their unique magnetic-field configuration, CRs with energy $\leq 10^{17}$ eV
can be trapped within these structures over cosmological time scales, and
generate secondary particles, including neutrinos and gamma rays, through
interactions with the background gas and photons. In this work, we compute the
contribution from clusters of galaxies to the diffuse neutrino background. We
employ three-dimensional cosmological magnetohydrodynamical simulations of
structure formation to model the turbulent intergalactic medium. We use the
distribution of clusters within this cosmological volume to extract the
properties of this population, including mass, magnetic field, temperature, and
density. We propagate CRs in this environment using multi-dimensional Monte
Carlo simulations across different redshifts (from $z \sim 5$ to $z =0$),
considering all relevant photohadronic, photonuclear, and hadronuclear
interaction processes. We find that, for CRs injected with a spectral index
$\alpha = 1.5 - 2.7$ and cutoff energy $E_\text{max} = 10^{16} - 5\times10^{17}
\; \text{eV}$, clusters contribute to a sizeable fraction to the diffuse flux
observed by the IceCube Neutrino Observatory, but most of the contribution
comes from clusters with $M \gtrsim 10^{14} \; M_{\odot}$ and redshift $ z
\lesssim 0.3$. If we include the cosmological evolution of the CR sources, this
flux can be even higher.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:06:57 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 13:57:52 GMT""}]","2021-07-07"
"2101.07703","Thomas Gilton","Omer Ben-Neria, Thomas Gilton","Club Stationary Reflection and the Special Aronszajn Tree Property",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We prove that it is consistent that Club Stationary Reflection and the
Special Aronszajn Tree Property simultaneously hold on $\omega_2$, thereby
contributing to the study of the tension between compactness and incompactness
in set theory. The poset which produces the final model follows the collapse of
an ineffable cardinal first with an iteration of club adding (with
anticipation) and second with an iteration specializing Aronszajn trees. In the
first part of the paper, we prove a general theorem about specializing
Aronszajn trees on $\omega_2$ after forcing with what we call
$\mathcal{F}$-Strongly Proper posets, where $\mathcal{F}$ is either the weakly
compact filter or the filter dual to the ineffability ideal. This type of
poset, of which the Levy collapse is a degenerate example, uses systems of
exact residue functions to create many strongly generic conditions. We prove a
new result about stationary set preservation by quotients of this kind of
poset; as a corollary, we show that the original Laver-Shelah model, which
starts from a weakly compact cardinal, satisfies a strong stationary reflection
principle, though it fails to satisfy the full Club Stationary Reflection. In
the second part, we show that the composition of collapsing and club adding
(with anticipation) is an $\mathcal{F}$-Strongly Proper poset. After proving a
new result about Aronszajn tree preservation, we show how to obtain the final
model.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:09:17 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 17:25:24 GMT""},{""version"":""v3"",""created"":""Mon, 16 May 2022 13:53:22 GMT""}]","2022-05-17"
"2101.07704","Elizabeth Collins-Woodfin","Elizabeth Collins-Woodfin","Overlap of a spherical spin glass model with microscopic external field","21 pages","Electron. J. Probab. 26: 1-22 (2021)","10.1214/21-EJP722",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the behavior of the 2-spin spherical Sherrington-Kirkpatrick model
with an external field by analyzing the overlap of a spin with the external
field. Previous research has noted that, at low temperature, this overlap
exhibits dramatically different behavior in the presence of an external field
as compared to the model with no external field. The transition between those
two settings was examined in a recent physics paper by Baik, Collins-Woodfin,
Le Doussal, and Wu as well as a recent math paper by Landon and Sosoe. Both
papers focus on the setting in which the external field strength, $h$,
approaches zero as the dimension, $N$, approaches infinity. In particular, the
paper of Baik et al studies the overlap with a microscopic external field
($h\sim N^{-1/2}$) but without a rigorous proof. This paper aims to give a
proof of that result. The proof involves representing the generating function
of the overlap as a ratio of contour integrals and then analyzing the
asymptotics of those contour integrals using results from random matrix theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:11:05 GMT""}]","2022-11-21"
"2101.07705","Xianlin Song","Xianlin Song, Ao Teng, Jianshuang Wei, Hao Chen, Yang Zhao, Jianheng
  Chen, Fangwei Liu, Qianxiang Wan, Guoning Huang, Lingfang Song, Aojie Zhao,
  Bo Li, Zihao Li, Qiming He, Jinhong Zhang","Interaction between optical pulse and tumor using finite element
  analysis",,,,,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Photoacoustic imaging is an emerging technology based on the photoacoustic
effect that has developed rapidly in recent years. It combines the high
contrast of optical imaging and the high penetration and high resolution of
acoustic imaging. As a non-destructive biological tissue imaging technology,
photoacoustic imaging has important application value in the field of
biomedicine. With its high efficiency bi-oimaging capabilities and excellent
biosafety performance, it has been favored by researchers. The visualization of
photoacoustic imaging has great research signifi-cance in the early diagnosis
of some diseases, especially tumors. In photoacoustic imaging, light
transmission and thermal effects are important processes. This article is based
on COMSOL software and uses finite element analysis to construct a physi-cal
model for simulation. Through laser pulses into the stomach tissue containing
tumor, the physical process of light transmission and biological heat transfer
was studied, and a photothermal model composed of two physical fields was
built, and finally a series of visualization graphics were obtained. This work
has certain theo-retical guiding significance for further promoting the
application of photoacoustic imaging in the field of biomedicine.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:11:12 GMT""}]","2021-01-20"
"2101.07706","Peng Jiang","Peng Jiang, Masuma Akter Rumi","Communication-Efficient Sampling for Distributed Training of Graph
  Convolutional Networks",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Training Graph Convolutional Networks (GCNs) is expensive as it needs to
aggregate data recursively from neighboring nodes. To reduce the computation
overhead, previous works have proposed various neighbor sampling methods that
estimate the aggregation result based on a small number of sampled neighbors.
Although these methods have successfully accelerated the training, they mainly
focus on the single-machine setting. As real-world graphs are large, training
GCNs in distributed systems is desirable. However, we found that the existing
neighbor sampling methods do not work well in a distributed setting.
Specifically, a naive implementation may incur a huge amount of communication
of feature vectors among different machines. To address this problem, we
propose a communication-efficient neighbor sampling method in this work. Our
main idea is to assign higher sampling probabilities to the local nodes so that
remote nodes are accessed less frequently. We present an algorithm that
determines the local sampling probabilities and makes sure our skewed neighbor
sampling does not affect much the convergence of the training. Our experiments
with node classification benchmarks show that our method significantly reduces
the communication overhead for distributed GCN training with little accuracy
loss.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:12:44 GMT""}]","2021-01-20"
"2101.07707","Hugo Tavares","Alberto Salda\~na and Hugo Tavares","On the least-energy solutions of the pure Neumann Lane-Emden equation","27 pages, 1 figure",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the pure Neumann Lane-Emden problem in a bounded domain \[
  -\Delta u = |u|^{p-1} u \text{ in }\Omega, \qquad \partial_\nu u=0 \text{ on
}\partial \Omega, \] in the subcritical, critical, and supercritical regimes.
We show existence and convergence of least-energy (nodal) solutions (l.e.n.s.).
In particular, we prove that l.e.n.s. converge to a l.e.n.s. of a problem with
sign nonlinearity as $p\searrow 0$; to a l.e.n.s. of the critical problem as
$p\nearrow 2^*$ (in particular, pure Neumann problems exhibit no blowup
phenomena at the critical Sobolev exponent $2^*$); and we show that the limit
as $p\to 1$ depends on the domain. Our proofs rely on different variational
characterizations of solutions including a dual approach and a nonlinear
eigenvalue problem. Finally, we also provide a qualitative analysis of
l.e.n.s., including symmetry, symmetry-breaking, and monotonicity results for
radial solutions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:18:04 GMT""}]","2021-01-20"
"2101.07708","Paul Rosen","Alon Friedman and Paul Rosen","Leveraging Peer Review in Visualization Education: A Proposal for a New
  Model",,"Pedagogy Data Visualization Workshop @ IEEE VIS, 2017",,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In visualization education, both science and humanities, the literature is
often divided into two parts: the design aspect and the analysis of the
visualization. However, we find limited discussion on how to motivate and
engage visualization students in the classroom. In the field of Writing
Studies, researchers develop tools and frameworks for student peer review of
writing. Based on the literature review from the field of Writing Studies, this
paper proposes a new framework to implement visualization peer review in the
classroom to engage today's students. This framework can be customized for
incremental and double-blind review to inspire students and reinforce critical
thinking about visualization.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:18:48 GMT""}]","2021-01-20"
"2101.07709","Nicholas Marshall","Tamir Bendory, Ti-Yen Lan, Nicholas F. Marshall, Iris Rukshin, Amit
  Singer","Multi-target detection with rotations","20 pages, 5 figures",,,,"eess.IV cs.CV stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the multi-target detection problem of estimating a
two-dimensional target image from a large noisy measurement image that contains
many randomly rotated and translated copies of the target image. Motivated by
single-particle cryo-electron microscopy, we focus on the low signal-to-noise
regime, where it is difficult to estimate the locations and orientations of the
target images in the measurement. Our approach uses autocorrelation analysis to
estimate rotationally and translationally invariant features of the target
image. We demonstrate that, regardless of the level of noise, our technique can
be used to recover the target image when the measurement is sufficiently large.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:20:01 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 17:16:13 GMT""}]","2022-09-05"
"2101.07710","Mohammad Fayaz","Mohammad Fayaz, Alireza Abadi, Soheila Khodakarim","The effect of Hybrid Principal Components Analysis on the Signal
  Compression Functional Regression: With EEG-fMRI Application","It has 11 pages with 3 tables and 3 figures. It presented at ""The
  13th International Conference of the ERCIM WG on Computational and
  Methodological Statistics (CMStatistics 2020) (Virtual), 19-21 December 2020""
  (http://www.cmstatistics.org/CMStatistics2020/index.php). We plan to publish
  it in statistical journals, especially in the conference's recommended
  journals",,,,"stat.ME stat.AP stat.CO stat.OT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective: In some situations that exist both scalar and functional data,
called mixed and hybrid data, the hybrid PCA (HPCA) was introduced. Among the
regression models for the hybrid data, we can count covariate-adjusted HPCA,
the Semi-functional partial linear regression, function-on-function (FOF)
regression with signal compression, and functional additive regression, models.
In this article, we study the effects of HPCA decomposition of hybrid data on
the prediction accuracy of the FOF regression with signal compressions. Method:
We stated a two-step procedure for incorporating the HPCA in the functional
regressions. The first step is reconstructing the data based on the HPCAs and
the second step is merging data on the other dimensions and calculate the
point-wise average of the desired functional dimension. We also choose the
number of HPCA based on Mean Squared Perdition Error (MSPE). Result: In the two
simulations, we show that the regression models with the first HPCA have the
best accuracy prediction and model fit summaries among no HPCA and all HPCAs
with a training/testing approach. Finally, we applied our methodology to the
EEG-fMRI dataset. Conclusions: We conclude that our methodology improves the
prediction of the experiments with the EEG datasets. And we recommend that
instead of using the functional PCA on the desired dimension, reconstruct the
data with HPCA and average it on the other two dimensions for functional
regression models.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:26:47 GMT""}]","2021-01-20"
"2101.07711","Irina Lomazova","Irina Lomazova, Vladimir Bashkin and Petr Jan\v{c}ar (Dept of Computer
  Science, Faculty of Science, Palack\'y University in Olomouc, Czech Republic)","Resource Bisimilarity in Petri Nets is Decidable",,"Fundamenta Informaticae, vol. 186, no. 1-4, pp. 175-194, 2022","10.3233/FI-222125",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Petri nets are a popular formalism for modeling and analyzing distributed
systems. Tokens in Petri net models can represent the control flow state or
resources produced/consumed by transition firings. We define a resource as a
part (a submultiset) of Petri net markings and call two resources equivalent
when replacing one of them with another in any marking does not change the
observable Petri net behavior. We consider resource similarity and resource
bisimilarity, two congruent restrictions of bisimulation equivalence on Petri
net markings. Previously it was proved that resource similarity (the largest
congruence included in bisimulation equivalence) is undecidable. Here we
present an algorithm for checking resource bisimilarity, thereby proving that
this relation (the largest congruence included in bisimulation equivalence that
is a bisimulation) is decidable. We also give an example of two resources in a
Petri net that are similar but not bisimilar.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:27:40 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 09:49:45 GMT""},{""version"":""v3"",""created"":""Mon, 14 Mar 2022 07:39:53 GMT""},{""version"":""v4"",""created"":""Thu, 5 May 2022 09:20:58 GMT""},{""version"":""v5"",""created"":""Tue, 28 Jun 2022 19:13:15 GMT""},{""version"":""v6"",""created"":""Thu, 4 Aug 2022 15:33:22 GMT""},{""version"":""v7"",""created"":""Mon, 22 Aug 2022 10:13:38 GMT""},{""version"":""v8"",""created"":""Mon, 3 Oct 2022 07:04:45 GMT""}]","2022-10-04"
"2101.07712","Malgorzata Worek","Malgorzata Worek","Modelling of top quark decays in $t\bar{t}\gamma$ production at the LHC","5 pages, 2 figures, 1 table. Presented at the 13th International
  Workshop on Top Quark Physics Durham, UK (videoconference), 14-18 September,
  2020",,,"TTK-21-01, P3H-21-001","hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this proceedings we briefly report on the state-of-the-art NLO QCD
computation for the $pp\to t\bar{t}\gamma$ process in the di-lepton channel. We
describe higher-order corrections to the $e^+\nu_e \, \mu^- \bar{\nu}_\mu \,
b\bar{b}\gamma$ final state at the LHC with $\sqrt{s}=13$ TeV. Off-shell top
quarks, double-, single- as well as non-resonant top-quark contributions along
with all interference effects are consistently incorporated at the matrix
element level. Results are presented in the form of fiducial integrated and
differential cross sections. The impact of top quark modelling is scrutinised
by an explicit comparison with the results in the narrow-width approximation.
Both types of predictions are now available in the HELAC-NLO framework.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:29:22 GMT""}]","2021-01-20"
"2101.07713","Rafael Pires","Rafael G. Pires, Daniel F. S. Santos, Marcos C.S. Santana, Claudio
  F.G. Santos, Joao P. Papa","Image Denoising using Attention-Residual Convolutional Neural Networks","Published in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and
  Images (SIBGRAPI)",,"10.1109/SIBGRAPI51738.2020.00022",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the image acquisition process, noise is usually added to the data
mainly due to physical limitations of the acquisition sensor, and also
regarding imprecisions during the data transmission and manipulation. In that
sense, the resultant image needs to be processed to attenuate its noise without
losing details. Non-learning-based strategies such as filter-based and noise
prior modeling have been adopted to solve the image denoising problem.
Nowadays, learning-based denoising techniques showed to be much more effective
and flexible approaches, such as Residual Convolutional Neural Networks. Here,
we propose a new learning-based non-blind denoising technique named Attention
Residual Convolutional Neural Network (ARCNN), and its extension to blind
denoising named Flexible Attention Residual Convolutional Neural Network
(FARCNN). The proposed methods try to learn the underlying noise expectation
using an Attention-Residual mechanism. Experiments on public datasets corrupted
by different levels of Gaussian and Poisson noise support the effectiveness of
the proposed approaches against some state-of-the-art image denoising methods.
ARCNN achieved an overall average PSNR results of around 0.44dB and 0.96dB for
Gaussian and Poisson denoising, respectively FARCNN presented very consistent
results, even with slightly worsen performance compared to ARCNN.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:37:57 GMT""}]","2021-01-20"
"2101.07714","Ashish Sharma","Ashish Sharma, Inna W. Lin, Adam S. Miner, David C. Atkins, Tim
  Althoff","Towards Facilitating Empathic Conversations in Online Mental Health
  Support: A Reinforcement Learning Approach","Published at WWW 2021",,,,"cs.CL cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online peer-to-peer support platforms enable conversations between millions
of people who seek and provide mental health support. If successful, web-based
mental health conversations could improve access to treatment and reduce the
global disease burden. Psychologists have repeatedly demonstrated that empathy,
the ability to understand and feel the emotions and experiences of others, is a
key component leading to positive outcomes in supportive conversations.
However, recent studies have shown that highly empathic conversations are rare
in online mental health platforms.
  In this paper, we work towards improving empathy in online mental health
support conversations. We introduce a new task of empathic rewriting which aims
to transform low-empathy conversational posts to higher empathy. Learning such
transformations is challenging and requires a deep understanding of empathy
while maintaining conversation quality through text fluency and specificity to
the conversational context. Here we propose PARTNER, a deep reinforcement
learning agent that learns to make sentence-level edits to posts in order to
increase the expressed level of empathy while maintaining conversation quality.
Our RL agent leverages a policy network, based on a transformer language model
adapted from GPT-2, which performs the dual task of generating candidate
empathic sentences and adding those sentences at appropriate positions. During
training, we reward transformations that increase empathy in posts while
maintaining text fluency, context specificity and diversity. Through a
combination of automatic and human evaluation, we demonstrate that PARTNER
successfully generates more empathic, specific, and diverse responses and
outperforms NLP methods from related tasks like style transfer and empathic
dialogue generation. Our work has direct implications for facilitating empathic
conversations on web-based platforms.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:37:58 GMT""},{""version"":""v2"",""created"":""Sat, 24 Apr 2021 21:30:22 GMT""},{""version"":""v3"",""created"":""Sun, 16 May 2021 17:58:38 GMT""}]","2021-05-18"
"2101.07715","David Bouget","David Bouget, Andr\'e Pedersen, Sayied Abdol Mohieb Hosainey, Ole
  Solheim, Ingerid Reinertsen","Meningioma segmentation in T1-weighted MRI leveraging global context and
  attention mechanisms","16 pages, 5 figures, 3 tables. Submitted to Artificial Intelligence
  in Medicine",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Meningiomas are the most common type of primary brain tumor, accounting for
approximately 30% of all brain tumors. A substantial number of these tumors are
never surgically removed but rather monitored over time. Automatic and precise
meningioma segmentation is therefore beneficial to enable reliable growth
estimation and patient-specific treatment planning. In this study, we propose
the inclusion of attention mechanisms over a U-Net architecture: (i)
Attention-gated U-Net (AGUNet) and (ii) Dual Attention U-Net (DAUNet), using a
3D MRI volume as input. Attention has the potential to leverage the global
context and identify features' relationships across the entire volume. To limit
spatial resolution degradation and loss of detail inherent to encoder-decoder
architectures, we studied the impact of multi-scale input and deep supervision
components. The proposed architectures are trainable end-to-end and each
concept can be seamlessly disabled for ablation studies. The validation studies
were performed using a 5-fold cross validation over 600 T1-weighted MRI volumes
from St. Olavs University Hospital, Trondheim, Norway. For the best performing
architecture, an average Dice score of 81.6% was reached for an F1-score of
95.6%. With an almost perfect precision of 98%, meningiomas smaller than 3ml
were occasionally missed hence reaching an overall recall of 93%. Leveraging
global context from a 3D MRI volume provided the best performances, even if the
native volume resolution could not be processed directly. Overall, near-perfect
detection was achieved for meningiomas larger than 3ml which is relevant for
clinical use. In the future, the use of multi-scale designs and refinement
networks should be further investigated to improve the performance. A larger
number of cases with meningiomas below 3ml might also be needed to improve the
performance for the smallest tumors.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:40:53 GMT""}]","2021-01-20"
"2101.07716","Paul Slater","Paul B. Slater","Hilbert-Schmidt Separability Probabilities from Bures Ensembles and vice
  versa: Applications to Quantum Steering Ellipsoids and Monotone Metrics","7 pages, 2 figures",,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reexamine a recent analysis in which, using the volume of the associated
quantum steering ellipsoid (QES) as a measure, we sought to estimate the
probability that a two-qubit state is separable. In the estimation process, we,
in effect, sought to attach to states random with respect to Hilbert-Schmidt
(HS) measure, the corresponding QES volumes. However, a study of the relations
between HS and Bures ensembles and their well-supported separability
probabilities of $\frac{8}{33}$ and $\frac{25}{341}$, respectively, now lead us
to explore as a possible alternative measure, the QES volume divided by the
$\Pi_{j<k}^{1...4} (\lambda_j-\lambda_k)^2 $ term of the HS volume element (the
$\lambda$'s being the four eigenvalues of the associated $4 \times 4$ density
matrix $\rho$). This measure is applied to the members of a HS ensemble of
random two-qubit states, yielding a QES separability probability estimate of
0.105458. Alternatively, weighting members of a Bures ensemble by the QES
volume divided by the eigenvalue part $\frac{1}{\sqrt{\mbox{det} \rho}}
\Pi_{j<k}^{1...4} \frac{(\lambda_j-\lambda_k)^2}{\lambda_j+\lambda_k}$ of the
Bures volume element, gives a close estimate of 0.100223. We also weight
members of a HS ensemble by the QES volume divided not only by the indicated HS
eigenvalue term, but also by the unitary component $|\Pi_{j<k}^{1...4}
\mbox{Re} (U^{-1}) \mbox{Im} (U^{-1})|$ of the volume element. For one hundred
thirty (rather variable) independent separability probability estimates, we,
then, obtain median and mean estimates of 0.0447729 and 0.117485 with variance
0.0381468.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:42:53 GMT""}]","2021-01-20"
"2101.07717","S M Raju","Sheikh Md Hanif Hossain, S M Raju and Amelia Ritahani Ismail","Predicting Pneumonia and Region Detection from X-Ray Images using Deep
  Neural Network","5 figures, 4 pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Biomedical images are increasing drastically. Along the way, many machine
learning algorithms have been proposed to predict and identify various kinds of
diseases. One such disease is Pneumonia which is an infection caused by both
bacteria and viruses through the inflammation of a person's lung air sacs. In
this paper, an algorithm was proposed that receives x-ray images as input and
verifies whether this patient is infected by Pneumonia as well as specific
region of the lungs that the inflammation has occurred at. The algorithm is
based on the transfer learning mechanism where pre-trained ResNet-50
(Convolutional Neural Network) was used followed by some custom layer for
making the prediction. The model has achieved an accuracy of 90.6 percent which
confirms that the model is effective and can be implemented for the detection
of Pneumonia in patients. Furthermore, a class activation map is used for the
detection of the infected region in the lungs. Also, PneuNet was developed so
that users can access more easily and use the services.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:43:05 GMT""}]","2021-01-20"
"2101.07718","Zhu Wang","Zhu Wang","Unified Robust Boosting",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boosting is a popular algorithm in supervised machine learning with wide
applications in regression and classification problems. Boosting can combine a
sequence of regression trees to obtain accurate prediction. In the presence of
outliers, traditional boosting may show inferior results since the algorithm
optimizes a convex loss function. Recent literature has proposed boosting
algorithms to optimizing robust nonconvex loss functions. However, there is a
lack of weighted estimation to indicate the outlier status of the observations.
This article proposes an iteratively reweighted boosting algorithm combining
robust loss optimization and weighted estimation, which is conveniently
constructed with existing software. The output includes the weights as a
valuable diagnostic to the outlier status of the observations. For
practitioners interested in the boosting algorithm, the new algorithm can be
interpreted as a method to tuning in observation weights, which can lead to a
more accurate model. The R package irboost is demonstrated with publicly
available data in various robust boosting approaches to generalized linear
models, classification and survival data analysis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:48:32 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 00:54:16 GMT""}]","2022-03-03"
"2101.07719","Wei-Chiu Ma","Wei-Chiu Ma, Shenlong Wang, Jiayuan Gu, Sivabalan Manivasagam, Antonio
  Torralba, Raquel Urtasun","Deep Feedback Inverse Problem Solver","ECCV 2020 Spotlight",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an efficient, effective, and generic approach towards solving
inverse problems. The key idea is to leverage the feedback signal provided by
the forward process and learn an iterative update model. Specifically, at each
iteration, the neural network takes the feedback as input and outputs an update
on the current estimation. Our approach does not have any restrictions on the
forward process; it does not require any prior knowledge either. Through the
feedback information, our model not only can produce accurate estimations that
are coherent to the input observation but also is capable of recovering from
early incorrect predictions. We verify the performance of our approach over a
wide range of inverse problems, including 6-DOF pose estimation, illumination
estimation, as well as inverse kinematics. Comparing to traditional
optimization-based methods, we can achieve comparable or better performance
while being two to three orders of magnitude faster. Compared to deep
learning-based approaches, our model consistently improves the performance on
all metrics. Please refer to the project page for videos, animations,
supplementary materials, etc.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:49:06 GMT""}]","2021-01-20"
"2101.07720","Peer Neubert","Peer Neubert and Stefan Schubert","Hyperdimensional computing as a framework for systematic aggregation of
  image descriptors",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image and video descriptors are an omnipresent tool in computer vision and
its application fields like mobile robotics. Many hand-crafted and in
particular learned image descriptors are numerical vectors with a potentially
(very) large number of dimensions. Practical considerations like memory
consumption or time for comparisons call for the creation of compact
representations. In this paper, we use hyperdimensional computing (HDC) as an
approach to systematically combine information from a set of vectors in a
single vector of the same dimensionality. HDC is a known technique to perform
symbolic processing with distributed representation in numerical vectors with
thousands of dimensions. We present a HDC implementation that is suitable for
processing the output of existing and future (deep-learning based) image
descriptors. We discuss how this can be used as a framework to process
descriptors together with additional knowledge by simple and fast vector
operations. A concrete outcome is a novel HDC-based approach to aggregate a set
of local image descriptors together with their image positions in a single
holistic descriptor. The comparison to available holistic descriptors and
aggregation methods on a series of standard mobile robotics place recognition
experiments shows a 20% improvement in average performance compared to
runner-up and 3.6x better worst-case performance.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:49:58 GMT""}]","2021-01-20"
"2101.07721","Simon Bohlender","Simon Bohlender, Ilkay Oksuz, Anirban Mukhopadhyay","A survey on shape-constraint deep learning for medical image
  segmentation",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Since the advent of U-Net, fully convolutional deep neural networks and its
many variants have completely changed the modern landscape of deep learning
based medical image segmentation. However, the over dependence of these methods
on pixel level classification and regression has been identified early on as a
problem. Especially when trained on medical databases with sparse available
annotation, these methods are prone to generate segmentation artifacts such as
fragmented structures, topological inconsistencies and islands of pixel. These
artefacts are especially problematic in medical imaging since segmentation is
almost always a pre-processing step for some downstream evaluation. The range
of possible downstream evaluations is rather big, for example surgical
planning, visualization, shape analysis, prognosis, treatment planning etc.
However, one common thread across all these downstream tasks is the demand of
anatomical consistency. To ensure the segmentation result is anatomically
consistent, approaches based on Markov/ Conditional Random Fields, Statistical
Shape Models are becoming increasingly popular over the past 5 years. In this
review paper, a broad overview of recent literature on bringing anatomical
constraints for medical image segmentation is given, the shortcomings and
opportunities of the proposed methods are thoroughly discussed and potential
future work is elaborated. We review the most relevant papers published until
the submission date. For quick access, important details such as the underlying
method, datasets and performance are tabulated.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:52:10 GMT""}]","2021-01-20"
"2101.07722","Philipp Oleynik","M.R. Mughal, J. Praks, R. Vainio, P. Janhunen, J. Envall, A.
  N\""asil\""a, P.Oleynik, P. Niemel\""a, A. Slavinskis, J. Gieseler, N.
  Jovanovic, B. Riwanto, P. Toivanen, H. Leppinen, T. Tikka, A. Punkkinen, R.
  Punkkinen, H.-P. Hedman, J.-O. Lill, J.M.K. Slotte","Aalto-1, multi-payload CubeSat: In-orbit results and lessons learned","35 pages",,"10.1016/j.actaastro.2020.11.044",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The in-orbit results and lessons learned of the first Finnish satellite
Aalto-1 are briefly presented in this paper. Aalto-1, a three-unit CubeSat
which was launched in June 2017, performed AaSI (Aalto Spectral Imager),
Radiation Monitor (RADMON), and Electrostatic Plasma Brake (EPB) missions. The
satellite partly fulfilled its mission objectives and allowed to either perform
or attempt the experiments. Although attitude control was partially functional,
AaSI and RADMON were able to acquire valuable measurements. EPB was
successfully commissioned but the tether deployment was not successful.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:52:50 GMT""}]","2021-01-20"
"2101.07723","Xu Zheng","Xu Zheng and Baowen Li","Fr\""{o}hlich Condensate of Phonons in Optomechanical Systems","13 pages, 9 figures",,"10.1103/PhysRevA.104.043512",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose that the optomechanical systems can be potential platforms to
implement the Fr\""{o}hlich condensate of phonons. We consider a one-dimensional
array of membranes coupled to the cavity field via a quadratic interaction, and
the cavity is pumped by an external laser. Analytical and numerical results
predict that the high phonon occupancy of the lowest or highest mechanical mode
is achievable depending on the detuning of the driving laser, the optomechnical
strength, and the temperature. The decoherence of the Fr\""{o}hlich condensate
can be largely suppressed by the large number of membranes. Our results shed
light on narrow-linewidth phonon laser, energy conversion/transfer, and
efficient multimode cooling.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:54:02 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 17:11:45 GMT""},{""version"":""v3"",""created"":""Tue, 23 Feb 2021 16:32:31 GMT""},{""version"":""v4"",""created"":""Fri, 1 Oct 2021 23:19:33 GMT""}]","2021-10-27"
"2101.07724","Mahmoud Hamed","M. Hamed, L. Ciesla, M. B\'ethermin, K. Ma{\l}ek, E. Daddi, M. T.
  Sargent, R. Gobat","Multiwavelength dissection of a massive heavily dust-obscured galaxy and
  its blue companion at z $\sim $2","10 pages, 7 figures, accepted for publication in A&A. Abstract
  abridged for arXiv submission","A&A 646, A127 (2021)","10.1051/0004-6361/202039577",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study a system of two galaxies, Astarte and Adonis, at z
$\sim $2 when the Universe was undergoing its peak of star formation activity.
Astarte is a dusty star-forming galaxy at the massive-end of the main sequence
(MS) and Adonis is a less-massive, bright in ultraviolet (UV), companion galaxy
with an optical spectroscopic redshift. We analyse the physical properties of
this system, and probe the gas mass of Astarte with its ALMA CO emission, to
investigate whether this ultra-massive galaxy is quenching or not. We use
CIGALE - a spectral energy distribution modeling code - to derive the key
physical properties of Astarte and Adonis, mainly their star formation rates
(SFRs), stellar masses, and dust luminosities. We inspect the variation of the
physical parameters depending on the assumed dust attenuation law. We also
estimate the molecular gas mass of Astarte from its CO emission, using
different $\alpha_{CO}$ and transition ratios ($r_{31}$) and discuss the
implication of the various assumptions on the gas mass derivation. We find that
Astarte exhibits a MS-like star formation activity, while Adonis is undergoing
a strong starburst (SB) phase. The molecular gas mass of Astarte is far below
the gas fraction of typical star-forming galaxies at z=2. This low gas content
and high SFR, result in a depletion time of $0.22\pm0.07$ Gyrs, slightly
shorter than what is expected for a MS galaxy at this redshift. The CO
luminosity versus the total IR luminosity suggests a MS-like activity assuming
a galactic conversion factor and a low transition ratio. The SFR of Astarte is
of the same order using different attenuation laws, unlike its stellar mass
that increases using shallow attenuation laws. We discuss these properties and
suggest that Astarte might be experiencing a recent decrease of star formation
activity and is quenching through the MS following a SB epoch.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:55:24 GMT""}]","2021-06-25"
"2101.07725","Muhammad AL-Qurishi Dr","Majed Alrubaian, Muhammad Al-Qurishi, Sherif Omar and Mohamed A.
  Mostafa","DeepTrust: A Deep Learning Approach for Measuring Social Media Users
  Trustworthiness","18 pages,6 figures",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Veracity of data posted on the microblog platforms has in recent years been a
subject of intensive study by professionals specializing in various fields of
informatics as well as sociology, particularly in the light of increasing
importance of online tools for news spreading. On Twitter and similar sites, it
is possible to report on ongoing situations globally with minimal delay, while
the cost of such reporting remains negligible. One of the most important
features of this social network is that content delivery can be customized to
allow users to focus only on news items covering subject matters they find
interesting. With this in mind, it becomes necessary to create verification
mechanisms that can ascertain whether the claims made on Twitter can be taken
seriously and prevent false content from spreading too far. This study
demonstrates an innovative System for verification of information that can
fulfill the role described above. The System is comprised of four mutually
connected modules: a legacy module, a trustworthiness classifier; a module
managing user authority, and a ranking procedure. All of the modules function
within an integrated framework and jointly contribute to an accurate
classification of messages and authors. Effectiveness of the solution was
evaluated empirically on a sample of Twitter users, with a strict 10-fold
evaluation procedure applied for each module. The findings indicate that the
solution successfully meets the primary objectives of the study and performs
its function as expected.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:55:32 GMT""}]","2021-01-20"
"2101.07726","Vishesh Jain","Vishesh Jain, Ashwin Sah, Mehtaab Sawhney","Anticoncentration versus the number of subset sums","10 pages; revised version",,,,"math.CO cs.DS math.PR","http://creativecommons.org/licenses/by/4.0/","  Let $\vec{w} = (w_1,\dots, w_n) \in \mathbb{R}^{n}$. We show that for any
$n^{-2}\le\epsilon\le 1$, if \[\#\{\vec{\xi} \in \{0,1\}^{n}: \langle
\vec{\xi}, \vec{w} \rangle = \tau\} \ge 2^{-\epsilon n}\cdot 2^{n}\] for some
$\tau \in \mathbb{R}$, then \[\#\{\langle \vec{\xi}, \vec{w} \rangle :
\vec{\xi} \in \{0,1\}^{n}\} \le 2^{O(\sqrt{\epsilon}n)}.\] This exponentially
improves the $\epsilon$ dependence in a recent result of Nederlof, Pawlewicz,
Swennenhuis, and W\k{e}grzycki and leads to a similar improvement in the
parameterized (by the number of bins) runtime of bin packing.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:59:03 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 21:48:47 GMT""}]","2021-06-16"
"2101.07727","Bob Briscoe","Bob Briscoe","Removing the Clock Machinery Lag from DCTCP/Prague","14pp, 4 figs, 17 refs. For changes between versions, see last page",,,"TR-BB-2020-002","cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This report explains how DCTCP takes 2--3 rounds before it even starts to
respond to congestion. This is due to the clocking machinery in its moving
average of congestion feedback. Instead, per-ACK mechanisms are proposed, which
cut out all the extra lag, leaving just the inherent single round of feedback
delay. Even though clocking per ACK updates the average much more frequently,
it is arranged to inherently smooth out variations over the same number of
round trips, independent of the number of ACKs per round.
  Evaluation of the v02 algorithm found design errors. This version (v04) is
published prior to evaluation, in order to elicit early feedback on the design.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:59:52 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 16:18:55 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 14:57:37 GMT""}]","2022-09-08"
"2101.07728","Bogdan Matioc","Jonas Bierler and Bogdan-Vasile Matioc","The multiphase Muskat problem with equal viscosities in two dimensions","29 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the two-dimensional multiphase Muskat problem describing the motion
of three immiscible fluids with equal viscosities in a vertical homogeneous
porous medium identified with $\mathbb{R}^2$ under the effect of gravity. We
first formulate the governing equations as a strongly coupled evolution problem
for the functions that parameterize the sharp interfaces between the fluids.
Afterwards we prove that the problem is of parabolic type and establish its
well-posedness together with two parabolic smoothing properties. For solutions
that are not global we exclude, in a certain regime, that the interfaces come
into contact along a curve segment.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:04:25 GMT""}]","2021-01-20"
"2101.07729","Noureddine Mohammedi","Noureddine Mohammedi","On a classical solution to the Abelian Higgs model","14 pages, 2 figures. Discussion extended and references added",,,,"hep-th hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  A particular solution to the equations of motion of the Abelian Higgs model
is given. The solution involves the Jacobi elliptic functions as well as the
Heun functions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:04:53 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 15:20:58 GMT""}]","2022-02-22"
"2101.07730","Junteng Jia","Junteng Jia and Austin R. Benson","A Unifying Generative Model for Graph Learning Algorithms: Label
  Propagation, Graph Convolutions, and Combinations",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semi-supervised learning on graphs is a widely applicable problem in network
science and machine learning. Two standard algorithms -- label propagation and
graph neural networks -- both operate by repeatedly passing information along
edges, the former by passing labels and the latter by passing node features,
modulated by neural networks. These two types of algorithms have largely
developed separately, and there is little understanding about the structure of
network data that would make one of these approaches work particularly well
compared to the other or when the approaches can be meaningfully combined.
Here, we develop a Markov random field model for the data generation process of
node attributes, based on correlations of attributes on and between vertices,
that motivates and unifies these algorithmic approaches. We show that label
propagation, a linearized graph convolutional network, and their combination
can all be derived as conditional expectations under our model, when
conditioning on different attributes. In addition, the data model highlights
deficiencies in existing graph neural networks (while producing new algorithmic
solutions), serves as a rigorous statistical framework for understanding graph
learning issues such as over-smoothing, creates a testbed for evaluating
inductive learning performance, and provides a way to sample graphs attributes
that resemble empirical data. We also find that a new algorithm derived from
our data generation model, which we call a Linear Graph Convolution, performs
extremely well in practice on empirical data, and provide theoretical
justification for why this is the case.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:07:08 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jan 2021 00:57:35 GMT""}]","2021-02-02"
"2101.07733","Jos\'e Luis Ram\'irez","Jazm\'in Mantilla, Wilson Olaya-Le\'on, Jos\'e L. Ram\'irez","Palindromic and Colored Superdiagonal Compositions","2 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A superdiagonal composition is one in which the $i$-th part or summand is of
size greater than or equal to $i$. In this paper, we study the number of
palindromic superdiagonal compositions and colored superdiagonal compositions.
In particular, we give generating functions and explicit combinatorial formulas
involving binomial coefficients and Stirling numbers of the first kind.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:12:12 GMT""}]","2021-01-20"
"2101.07735","Mohammadreza Tavakoli","Mohammadreza Tavakoli, Mirette Elias, G\'abor Kismih\'ok, S\""oren Auer","Metadata Analysis of Open Educational Resources","This paper has been accepted to be published in the 11th
  International Learning Analytics and Knowledge (LAK'2021), April 12--16,
  2021. ACM. arXiv admin note: text overlap with arXiv:2005.10542",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Open Educational Resources (OERs) are openly licensed educational materials
that are widely used for learning. Nowadays, many online learning repositories
provide millions of OERs. Therefore, it is exceedingly difficult for learners
to find the most appropriate OER among these resources. Subsequently, the
precise OER metadata is critical for providing high-quality services such as
search and recommendation. Moreover, metadata facilitates the process of
automatic OER quality control as the continuously increasing number of OERs
makes manual quality control extremely difficult. This work uses the metadata
of 8,887 OERs to perform an exploratory data analysis on OER metadata.
Accordingly, this work proposes metadata-based scoring and prediction models to
anticipate the quality of OERs. Based on the results, our analysis demonstrated
that OER metadata and OER content qualities are closely related, as we could
detect high-quality OERs with an accuracy of 94.6%. Our model was also
evaluated on 884 educational videos from Youtube to show its applicability on
other educational repositories.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:16:44 GMT""}]","2021-01-20"
"2101.07736","Mario Gliozzi","Mario Gliozzi, James K. Williams, Dina A. Michel (George Mason
  University)","Estimating black hole masses in obscured AGN using X-rays","15 pages, 6 figures, 5 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab181",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Determining the black hole masses in active galactic nuclei (AGN) is of
crucial importance to constrain the basic characteristics of their central
engines and shed light on their growth and co-evolution with their host
galaxies. While the black hole mass (MBH) can be robustly measured with
dynamical methods in bright type 1 AGN, where the variable primary emission and
the broad line region (BLR) are directly observed, a direct measurement is
considerably more challenging if not impossible for the vast majority of
heavily obscured type 2 AGN. In this work, we tested the validity of an
X-ray-based scaling method to constrain the MBH in heavily absorbed AGN. To
this end, we utilized a sample of type 2 AGN with good-quality hard X-ray data
obtained by the nuSTAR satellite and with MBH dynamically constrained from
megamaser measurements. Our results indicate that, when the X-ray broadband
spectra are fitted with physically motivated self-consistent models that
properly account for absorption, scattering, and emission line contributions
from the putative torus and constrain the primary X-ray emission, then the
X-ray scaling method yields MBH values that are consistent with those
determined from megamaser measurements within their respective uncertainties.
With this method we can therefore systematically determine the MBH in any type
2 AGN, provided that they possess good-quality X-ray data and accrete at a
moderate to high rate.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:18:07 GMT""}]","2021-02-03"
"2101.07737","Shashank Shekhar","Shashank Shekhar, Muralikrishnan Srinivasan, Sheetal Kalyani, and
  Mohamed-Slim Alouini","Outage Probability Analysis of Uplink Cell-Free Massive MIMO Network
  with and without Pilot Contamination","In this version, we have extended our analysis to multiple antenna AP
  and the scenario with and without pilot contamination",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper derives approximate outage probability (OP) expressions for uplink
cell-free massive multiple-input-multiple-output (CF-mMIMO) systems with and
without pilot contamination. The system's access points (APs) are considered to
have imperfect channel state information (CSI). The
signal-to-interference-plus-noise ratio (SINR) of the CF-mMIMO system is
approximated via a Log-normal distribution using a two-step moment matching
method. OP and ergodic rate expressions are derived with the help of the
approximated Log-normal distribution. For the no-pilot contamination scenario,
an exact expression is first derived using conditional expectations in terms of
a multi-fold integral. Then, a novel dimension reduction method is used to
approximate it by the sum of single-variable integrations. Both the
approximations derived for the CF-mMIMO systems are also useful for single-cell
collocated massive MIMO (mMIMO) systems and lead to closed-form expression. The
derived expressions closely match the simulated numerical values for OP and
ergodic rate.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:20:31 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 04:46:33 GMT""},{""version"":""v3"",""created"":""Thu, 8 Dec 2022 09:05:52 GMT""}]","2022-12-09"
"2101.07739","Federico Pianoforte","Federico Pianoforte, Matthias Schulte","Criteria for Poisson process convergence with applications to
  inhomogeneous Poisson-Voronoi tessellations","30 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article employs the relation between probabilities of two consecutive
values of a Poisson random variable to derive conditions for the weak
convergence of point processes to a Poisson process. As applications, we
consider the starting points of k-runs in a sequence of Bernoulli random
variables and point processes constructed using inradii and circumscribed radii
of inhomogeneous Poisson-Voronoi tessellations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:24:38 GMT""}]","2021-01-20"
"2101.07740","Jacques Tilouine","J. Tilouine, E. Urban","On the cohomology of GL(N) and adjoint Selmer groups",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We prove -under certain conditions (local-global compatibility and vanishing
of integral cohomology), a generalization of a theorem of Galatius and
Venkatesh. We consider the case of GL(N) over a CM field and we relate the
localization of penultimate non vanishing cuspidal cohomology group for a
locally symmetric space to the Selmer group of the Tate dual of the adjoint
representation. More precisely we construct a Hecke-equivariant injection from
the divisible group associated to the first fundamental group of a derived
deformation ring to the Selmer group of the twisted dual adjoint motive with
divisible coefficients and we identify its cokernel as its first
Tate-Shafarevich group. Actually, we also construct similar maps for higher
homotopy groups with values in exterior powers of Selmer groups, although with
less precise control on their kernel and cokernel. We generalize this to Hida
families as well.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:25:11 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 08:43:02 GMT""},{""version"":""v3"",""created"":""Thu, 13 Apr 2023 05:00:09 GMT""}]","2023-04-14"
"2101.07741","Julia Langer","J. Langer, V. Cimalla, M. Prescher, J. Ligl, B. Tegetmeyer, C.
  Schreyvogel and O. Ambacher","Quality assessment of in situ plasma etched diamond surfaces for CVD
  overgrowth","10 pages, 7 figures",,"10.1002/pssa.202100035",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In situ plasma etching is a common method to prepare diamond substrates for
epitaxial overgrowth to effectuate higher quality. However, there is no
practical, direct, qualitative method established so far to assess the
performance of the etching pretreatment. We propose an optimization of the
pretreatment process on grounds of high-resolution X-ray diffraction
measurements to judge the structural quality gain of the diamond substrates and
the effectiveness of the polishing-induced subsurface damage removal. The
obtained data shows, that parameters like thickness nor misorientation angle of
the diamond substrates seem to influence the gain of the structural quality.
The process duration, however, is an important key factor, when the amount of
material removal and the arising roughness are discussed. Furthermore, the
impact of the oxygen-to-hydrogen ratio is examined. And with rising oxygen
percentage, the structural quality gain remains similar, only the overall as
well as local mean roughness increases exponentially. Within the utilized
reactor setup, the best results are obtained after a 20-minute in situ hydrogen
plasma-etching step. The optimal pretreatment process, however, will always
embody a tradeoff and needs to be optimized for each reactor type. Due to the
introduced method a better evaluation and comparison of the achievements is
accomplishable.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:28:23 GMT""}]","2021-06-16"
"2101.07742","Simone Di Filippo","Simone Di Filippo, Davide Greggio, Maria Bergomi, Kalyan
  Radhakrishnan, Elisa Portaluri, Valentina Viotto, Carmelo Arcidiacono,
  Demetrio Magrin, Luca Marafatto, Marco Dima, Roberto Ragazzoni, Pierre
  Janin-Potiron, Lauren Schatz, Benoit Neichel, Olivier Fauvarque, Thierry
  Fusco","INGOT Wavefront Sensor: from the optical design to a preliminary
  laboratory test","6 pages, 8 figures, AO4ELT6 conference proceeding,
  http://ao4elt6.copl.ulaval.ca/proceedings.html",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ingot wavefront sensor is a novel pupil-plane wavefront sensor,
specifically designed to cope with the elongation typical of the extended
nature of the Laser Guide Star (LGS). In the framework of the ELT, we propose
an optical solution suitable for a Laser launch telescope, located outside the
telescope pupil. In this paper, we present the current optical design, based on
a reflective roof-shaped prism, which, at the level of the focal plane, splits
the light from an LGS producing three beams. The three images of the telescope
pupils can be then used for the retrieval of the first derivative of the
wavefront. The 3D nature of such a device requires new alignment techniques to
be determined theoretically and verified in the real world. A possible fully
automated procedure, relying solely on the illumination observed at the three
pupils, to align the prism to the image of the LGS is discussed. Careful
attention needs to be put both on the telecentricity of the system and on the
reference systems of the Ingot adjustments in the 3D space. This is crucial in
order to disentangle all the possible misalignment effects. In this context, we
devised a test-bench able to reproduce, in a scaled manner, the 3D illumination
that the Ingot will face at the ELT, in order to validate the design and to
perform preliminary tests of phase retrieval.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:29:26 GMT""}]","2021-01-20"
"2101.07743","Oliver Edy","O Edy, A. Lundgren, L. K. Nuttall","The Issues of Mismodelling Gravitational-Wave Data for Parameter
  Estimation","15 pages, 5 figures. Comments welcome","Phys. Rev. D 103, 124061 (2021)","10.1103/PhysRevD.103.124061","LIGO-P2100001","astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian inference is used to extract unknown parameters from gravitational
wave signals. Detector noise is typically modelled as stationary, although data
from the LIGO and Virgo detectors is not stationary. We demonstrate that the
posterior of estimated waveform parameters is no longer valid under the
assumption of stationarity. We show that while the posterior is unbiased, the
errors will be under- or overestimated compared to the true posterior. A
formalism was developed to measure the effect of the mismodelling, and found
the effect of any form of non-stationarity has an effect on the results, but
are not significant in certain circumstances. We demonstrate the effect of
short-duration Gaussian noise bursts and persistent oscillatory modulation of
the noise on binary-black-hole-like signals. In the case of short signals,
non-stationarity in the data does not have a large effect on the parameter
estimation, but the errors from non-stationary data containing signals lasting
tens of seconds or longer will be several times worse than if the noise was
stationary. Accounting for this limiting factor in parameter sensitivity could
be very important for achieving accurate astronomical results, including an
estimation of the Hubble parameter. This methodology for handling the
non-stationarity will also be invaluable for analysis of waveforms that last
minutes or longer, such as those we expect to see with the Einstein Telescope.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:33:45 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 11:59:46 GMT""}]","2021-07-13"
"2101.07744","Vatsal Sanjay","Vatsal Sanjay and Detlef Lohse and Maziyar Jalaal","Bursting Bubble in a Viscoplastic Medium","Please find the supplementary videos here:
  https://youtube.com/playlist?list=PLf5C5HCrvhLFETl6iaRr21pzr5Xab1OCM","Journal of Fluid Mechanics, 922, A2 (2021)","10.1017/jfm.2021.489",,"physics.flu-dyn cond-mat.soft","http://creativecommons.org/licenses/by-nc-nd/4.0/","  When a rising bubble in a Newtonian liquid reaches the liquid-air interface,
it can burst, leading to the formation of capillary waves and a jet on the
surface. Here, we numerically study this phenomenon in a yield stress fluid. We
show how viscoplasticity controls the fate of these capillary waves and their
interaction at the bottom of the cavity. Unlike Newtonian liquids, the free
surface converges to a non-flat final equilibrium shape once the driving
stresses inside the pool fall below the yield stress. Details of the dynamics,
including the flow's energy budgets, are discussed. The work culminates in a
regime map with four main regimes with different characteristic behaviours.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:35:44 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 11:34:25 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 11:14:01 GMT""},{""version"":""v4"",""created"":""Mon, 5 Jul 2021 14:00:06 GMT""}]","2021-07-06"
"2101.07745","Hiroyuki Fujioka","Hiroyuki Fujioka","Feasibility of an experimental search for a resonance of a pion and a
  light nucleus","7 pages, 2 figures; accepted for publication in PTEP","Prog. Theor. Exp. Phys. 2021 (2021) 051D01","10.1093/ptep/ptab041",,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hypothesis is proposed herein, suggesting that a pion-nuclear resonance may
be observed in the $\alpha+d\to{}^6\mathrm{Li}(3.563)+\pi^0$ reaction. The
resonance has a $\pi NN\alpha$ structure, containing $\alpha NN$ and $\pi NN$
subsystems. The former corresponds to the $A=6$ isotriplet
($^6\mathrm{He}_\text{g.s.}$, $^6\mathrm{Li}(3.563)$,
$^6\mathrm{Be}_\text{g.s.}$), whereas the latter is a hypothetical
$NN$-decoupled dibaryon. We propose an experiment to search for this resonance
using the $^7\mathrm{Li}(p,d)$ reaction.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:37:52 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 07:52:35 GMT""}]","2022-03-08"
"2101.07746","Jiri Stehlik","J. Stehlik, D. M. Zajac, D. L. Underwood, T. Phung, J. Blair, S.
  Carnevale, D. Klaus, G. A. Keefe, A. Carniol, M. Kumph, Matthias Steffen, O.
  E. Dial","Tunable Coupling Architecture for Fixed-frequency Transmons",,"Phys. Rev. Lett. 127, 080505 (2021)","10.1103/PhysRevLett.127.080505",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implementation of high-fidelity two-qubit operations is a key ingredient for
scalable quantum error correction. In superconducting qubit architectures
tunable buses have been explored as a means to higher fidelity gates. However,
these buses introduce new pathways for leakage. Here we present a modified
tunable bus architecture appropriate for fixed-frequency qubits in which the
adiabaticity restrictions on gate speed are reduced. We characterize this
coupler on a range of two-qubit devices achieving a maximum gate fidelity of
$99.85\%$. We further show the calibration is stable over one day.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:38:18 GMT""}]","2021-08-25"
"2101.07747","Mauro Brotons-Gisbert","Mauro Brotons-Gisbert, Hyeonjun Baek, Aidan Campbell, Kenji Watanabe,
  Takashi Taniguchi and Brian D. Gerardot","Moir\'e-trapped interlayer trions in a charge-tunable WSe$_2$/MoSe$_2$
  heterobilayer","12 pages, 4 figures","Phys. Rev. X 11, 031033 (2021)","10.1103/PhysRevX.11.031033",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Transition metal dichalcogenide heterobilayers offer attractive opportunities
to realize lattices of interacting bosons with several degrees of freedom. Such
heterobilayers can feature moir\'e patterns that modulate their electronic band
structure, leading to spatial confinement of single interlayer excitons (IXs)
that act as quantum emitters with $C_3$ symmetry. However, the narrow emission
linewidths of the quantum emitters contrast with a broad ensemble IX emission
observed in nominally identical heterobilayers, opening a debate regarding the
origin of IX emission. Here we report the continuous evolution from a few
trapped IXs to an ensemble of IXs with both triplet and singlet spin
configurations in a gate-tunable $2H$-MoSe$_2$/WSe$_2$ heterobilayer. We
observe signatures of dipolar interactions in the IX ensemble regime which,
when combined with magneto-optical spectroscopy, reveal that the narrow
quantum-dot-like and broad ensemble emission originate from IXs trapped in
moir\'e potentials with the same atomic registry. Finally, electron doping
leads to the formation of three different species of localised negative trions
with contrasting spin-valley configurations, among which we observe both
intervalley and intravalley IX trions with spin-triplet optical transitions.
Our results identify the origin of IX emission in MoSe$_2$/WSe$_2$
heterobilayers and highlight the important role of exciton-exciton interactions
and Fermi-level control in these highly tunable quantum materials.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:39:36 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 14:20:43 GMT""}]","2021-08-16"
"2101.07748","F. Javier Garc\'ia de Abajo","Valerio Di Giulio, Ofer Kfir, Claus Ropers, and F. Javier Garc\'ia de
  Abajo","Modulation of Cathodoluminescence Emission by Interference with External
  Light","26 pages, 7 figures, 87 references","ACS Nano 15, 7290-7304 (2021)","10.1021/acsnano.1c00549",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spontaneous processes triggered in a sample by free electrons are commonly
regarded as incoherent, and therefore unable to interfere with external light
sources. Here, we challenge this concept by showing through first-principles
theory that light and free-electron pulses can interfere when interacting with
a nanostructure, giving rise to a modulation in the spectral distribution of
the cathodoluminescence light emission that is strongly dependent on the
electron wave function. Specifically, for a temporally focused electron,
cathodoluminescence can be cancelled upon illumination with a spectrally
modulated dimmed laser that is phase-locked relative to the electron density
profile. We illustrate this idea with realistic simulations under attainable
conditions in currently available ultrafast electron microscopes. We further
argue that the interference between excitations produced by light and free
electrons opens a new window to manipulate the ultrafast materials response by
combining the spectral and temporal selectivity of the light with the atomic
resolution of electron beams.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:39:47 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 22:33:33 GMT""},{""version"":""v3"",""created"":""Tue, 30 Mar 2021 14:21:07 GMT""}]","2022-09-12"
"2101.07749","Claudio Marchi","Claudio Marchi","Picard groups for some blocks with TI defect groups","9 pages",,,,"math.RT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the Picard groups for principal blocks $B$ with TI defect groups
and cyclic inertial quotient. The methods used generalize results on self
stable equivalences and take advantage of the existence of equivalences given
by Green correspondence in this setting. In particular, we show that
$\text{Pic}(B)=\mathcal{E}(B)$, giving more evidence for a conjecture on basic
auto-Morita equivalences.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:41:02 GMT""}]","2021-01-20"
"2101.07750","Hua Sun","Yizhou Zhao, Hua Sun","Information Theoretic Secure Aggregation with User Dropouts",,,,,"cs.IT cs.CR cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the robust secure aggregation problem, a server wishes to learn and only
learn the sum of the inputs of a number of users while some users may drop out
(i.e., may not respond). The identity of the dropped users is not known a
priori and the server needs to securely recover the sum of the remaining
surviving users. We consider the following minimal two-round model of secure
aggregation. Over the first round, any set of no fewer than $U$ users out of
$K$ users respond to the server and the server wants to learn the sum of the
inputs of all responding users. The remaining users are viewed as dropped. Over
the second round, any set of no fewer than $U$ users of the surviving users
respond (i.e., dropouts are still possible over the second round) and from the
information obtained from the surviving users over the two rounds, the server
can decode the desired sum. The security constraint is that even if the server
colludes with any $T$ users and the messages from the dropped users are
received by the server (e.g., delayed packets), the server is not able to infer
any additional information beyond the sum in the information theoretic sense.
For this information theoretic secure aggregation problem, we characterize the
optimal communication cost. When $U \leq T$, secure aggregation is not
feasible, and when $U > T$, to securely compute one symbol of the sum, the
minimum number of symbols sent from each user to the server is $1$ over the
first round, and $1/(U-T)$ over the second round.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:43:48 GMT""}]","2021-01-20"
"2101.07751","Takuya Morozumi","Apriadi Salim Adam, Nicholas J. Benoit, Yuta Kawamura, Yamato Matsuo,
  Takuya Morozumi, Yusuke Shimizu, Yuya Tokunaga, and Naoya Toyota","Time Evolution of Lepton Number Carried by Majorana Neutrinos","20 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2004.07664. In v3,references are corrected. In v4, Fig.7 is added. In
  v6,the typos in Eq.(24),(29-33), and (90) are corrected. In v7,Eq.(20) and an
  author address are corrected","PTEP 2021(2021) 5,053B01","10.1093/ptep/ptab025","HUPD-2004","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the time evolution of the lepton family number for a SU(2) doublet
consisting of a neutrino and a charged lepton. The lepton family number is
defined through the weak basis of the SU(2) doublet, where the charged lepton
mass matrix is real and diagonal. The lepton family number carried by the
neutrino is defined by the left-handed current of the neutrino family. For this
work we assume the neutrinos have Majorana mass. This Majorana mass term is
switched on at time $t=0$ and the lepton family number is evolved. Since the
operator in the flavor eigenstate is continuously connected to that of the mass
eigenstate, the creation and annihilation operators for the two eigenstates are
related to each other. We compute the time evolution of all lepton family
numbers by choosing a specific initial flavor eigenstate for a neutrino. The
evolution is studied for relativistic and nonrelativistic neutrinos. The
nonrelativistic region is of particular interest for the Cosmic Neutrino
Background predicted from big bang models. In that region we find the lepton
family numbers are sensitive to Majorana and Dirac phases, the absolute mass,
and mass hierarchy of neutrinos.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:43:52 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 15:45:23 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 07:16:33 GMT""},{""version"":""v4"",""created"":""Wed, 17 Feb 2021 16:52:23 GMT""},{""version"":""v5"",""created"":""Thu, 18 Feb 2021 07:31:50 GMT""},{""version"":""v6"",""created"":""Tue, 30 Mar 2021 18:14:37 GMT""},{""version"":""v7"",""created"":""Sat, 29 May 2021 04:01:51 GMT""}]","2021-10-26"
"2101.07752","Asier Guti\'errez-Fandi\~no","David P\'erez-Fern\'andez and Asier Guti\'errez-Fandi\~no and Jordi
  Armengol-Estap\'e and Marta Villegas","Characterizing and Measuring the Similarity of Neural Networks with
  Persistent Homology",,,,,"cs.LG math.AT","http://creativecommons.org/licenses/by/4.0/","  Characterizing the structural properties of neural networks is crucial yet
poorly understood, and there are no well-established similarity measures
between networks. In this work, we observe that neural networks can be
represented as abstract simplicial complex and analyzed using their topological
'fingerprints' via Persistent Homology (PH). We then describe a PH-based
representation proposed for characterizing and measuring similarity of neural
networks. We empirically show the effectiveness of this representation as a
descriptor of different architectures in several datasets. This approach based
on Topological Data Analysis is a step towards better understanding neural
networks and serves as a useful similarity measure.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:44:50 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 13:17:49 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 09:43:19 GMT""}]","2021-06-01"
"2101.07753","Subhashree Mohanty","S. Mohanty, A. B. Kaliyar, V. Gaur, G. B. Mohanty, I. Adachi, K.
  Adamczyk, H. Aihara, S. Al Said, D. M. Asner, H. Atmacan, V. Aulchenko, T.
  Aushev, T. Aziz, V. Babu, S. Bahinipati, P. Behera, M. Bessner, V. Bhardwaj,
  T. Bilka, J. Biswal, A. Bobrov, A. Bozek, M. Bra\v{c}ko, T. E. Browder, M.
  Campajola, D. \v{C}ervenkov, V. Chekelian, A. Chen, B. G. Cheon, K. Chilikin,
  K. Cho, S.-J. Cho, S.-K. Choi, Y. Choi, S. Choudhury, D. Cinabro, S.
  Cunliffe, S. Das, N. Dash, G. De Nardo, R. Dhamija, F. Di Capua, Z.
  Dole\v{z}al, T. V. Dong, S. Eidelman, T. Ferber, B. G. Fulsom, N. Gabyshev,
  A. Garmash, A. Giri, P. Goldenzweig, B. Golob, O. Grzymkowska, Y. Guan, K.
  Gudkova, C. Hadjivasiliou, S. Halder, K. Hayasaka, H. Hayashii, W.-S. Hou,
  C.-L. Hsu, K. Inami, A. Ishikawa, R. Itoh, M. Iwasaki, W. W. Jacobs, H. B.
  Jeon, S. Jia, Y. Jin, K. K. Joo, K. H. Kang, G. Karyan, B. H. Kim, C. H. Kim,
  D. Y. Kim, S. H. Kim, Y.-K. Kim, K. Kinoshita, P. Kody\v{s}, T. Konno, S.
  Korpar, D. Kotchetkov, P. Kri\v{z}an, P. Krokovny, R. Kulasiri, M. Kumar, R.
  Kumar, K. Kumara, Y.-J. Kwon, K. Lalwani, S. C. Lee, J. Li, L. K. Li, Y. B.
  Li, L. Li Gioi, J. Libby, Z. Liptak, D. Liventsev, C. MacQueen, M. Masuda, T.
  Matsuda, M. Merola, K. Miyabayashi, R. Mizuk, T. J. Moon, R. Mussa, M. Nakao,
  A. Natochii, L. Nayak, M. Nayak, N. K. Nisar, S. Nishida, K. Ogawa, S. Ogawa,
  Y. Onuki, P. Oskin, G. Pakhlova, S. Pardi, C. W. Park, H. Park, S.-H. Park,
  S. Patra, T. K. Pedlar, R. Pestotnik, L. E. Piilonen, T. Podobnik, V. Popov,
  E. Prencipe, M. T. Prim, M. R\""ohrken, A. Rostomyan, N. Rout, G. Russo, D.
  Sahoo, Y. Sakai, S. Sandilya, A. Sangal, T. Sanuki, V. Savinov, G. Schnell,
  J. Schueler, C. Schwanda, A. J. Schwartz, Y. Seino, K. Senyo, M. E. Sevior,
  M. Shapkin, C. Sharma, J.-G. Shiu, B. Shwartz, F. Simon, E. Solovieva, M.
  Stari\v{c}, Z. S. Stottler, J. F. Strube, T. Sumiyoshi, M. Takizawa, K.
  Tanida, Y. Tao, F. Tenchini, M. Uchida, Y. Unno, S. Uno, Y. Usov, S. E.
  Vahsen, R. Van Tonder, G. Varner, K. E. Varvell, A. Vinokurova, V. Vorobyev,
  C. H. Wang, E. Wang, M.-Z. Wang, P. Wang, X. L. Wang, S. Watanuki, J.
  Wiechczynski, E. Won, X. Xu, B. D. Yabsley, W. Yan, H. Ye, J. H. Yin, Z. P.
  Zhang, V. Zhilich, and V. Zhukova (The Belle Collaboration)","Measurement of Branching Fraction and Search for $CP$ Violation in $B\to
  \phi \phi K$","8 pages, 6 figures, 4 tables, submitted to Phys. Rev. D","Phys. Rev. D 103, 052013 (2021)","10.1103/PhysRevD.103.052013","Belle Preprint 2020-20, KEK Preprint 2020-37","hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the measurement of branching fractions and $CP$-violation
asymmetries in $B\to \phi \phi K$ decays based on a $711\,{\rm fb}^{-1}$ data
sample containing $772\times 10^6$ $B\bar{B}$ events. The data were recorded at
the $\Upsilon (4S)$ resonance with the Belle detector at the KEKB
asymmetric-energy $e^+ e^-$ collider. For $B^+ \to \phi \phi K^+$, the
branching fraction and $CP$-violation asymmetry measured below the $\eta_{c}$
threshold ($m_{\phi\phi}<2.85\,{\rm GeV}/c^2$) are
$[3.43^{\,+\,0.48}_{\,-\,0.46}({\rm stat})\pm 0.22({\rm syst})] \times10^{-6}$
and $-0.02\pm0.11({\rm stat})\pm0.01({\rm syst})$, respectively. Similarly, the
branching fraction obtained for $B^0 \to\phi\phi K^0$ below the $\eta_{c}$
threshold is $[3.02^{\,+\,0.75}_{\,-\,0.66} ({\rm stat})\pm \,0.20({\rm
syst})]\times10^{-6}$. We also measure the $CP$-violation asymmetry for $B^+
\to\phi\phi K^+$ within the $\eta_{c}$ region ($m_{\phi\phi}\in
[2.94,3.02]\,{\rm GeV}/c^2$) to be $+0.12\pm0.12({\rm stat})\pm0.01({\rm
syst})$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:46:02 GMT""}]","2021-04-07"
"2101.07754","Robert Grimm","Robert Grimm, Julie Castillo-Rogez, Carol Raymond, Andrew R. Poppe","Feasibility of characterizing subsurface brines on Ceres by
  electromagnetic sounding",,,"10.1016/j.icarus.2021.114424",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ice-rich dwarf planet Ceres is the largest object in the main asteroid
belt and is thought to have a brine or mud layer at a depth of tens of
kilometers. Furthermore, recent surface deposits of brine-sourced material
imply shallow feeder structures such as sills or dikes. Inductive sounding of
Ceres can be performed using the solar wind as a source, as was done for the
Moon during Apollo. However, the magnetotelluric method -- measuring both
electric and magnetic fields at the surface -- is not sensitive to plasma
effects that were experienced for Apollo, which used an orbit-to-surface
magnetic transfer function. The highly conductive brine targets are readily
separable from the resistive ice and rock interior, such that the depth to deep
and shallow brines can be assessed simultaneously. The instrumentation will be
tested on the Moon in 2023 and is ready for implementation on a Ceres landed
mission.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:47:07 GMT""}]","2021-03-31"
"2101.07755","Vladislav Golyanik","Tolga Birdal, Vladislav Golyanik, Christian Theobalt, Leonidas Guibas","Quantum Permutation Synchronization","19 pages, 15 figures, 4 tables; web pages:
  https://vcai.mpi-inf.mpg.de/projects/QUANTUMSYNC/,
  https://quantumcomputervision.github.io/","Computer Vision and Pattern Recognition (CVPR) 2021",,,"quant-ph cs.CV cs.ET cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present QuantumSync, the first quantum algorithm for solving a
synchronization problem in the context of computer vision. In particular, we
focus on permutation synchronization which involves solving a non-convex
optimization problem in discrete variables. We start by formulating
synchronization into a quadratic unconstrained binary optimization problem
(QUBO). While such formulation respects the binary nature of the problem,
ensuring that the result is a set of permutations requires extra care. Hence,
we: (I) show how to insert permutation constraints into a QUBO problem and (ii)
solve the constrained QUBO problem on the current generation of the adiabatic
quantum computers D-Wave. Thanks to the quantum annealing, we guarantee global
optimality with high probability while sampling the energy landscape to yield
confidence estimates. Our proof-of-concepts realization on the adiabatic D-Wave
computer demonstrates that quantum machines offer a promising way to solve the
prevalent yet difficult synchronization problems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:51:02 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 14:57:46 GMT""}]","2021-11-29"
"2101.07756","Ziran Wang","Ziran Wang and Kyungtae Han and Prashant Han","Motion Estimation of Connected and Automated Vehicles under
  Communication Delay and Packet Loss of V2X Communications","Manuscript accepted as SAE technical paper",,"10.4271/2021-01-0107",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The emergence of the connected and automated vehicle (CAV) technology enables
numerous advanced applications in our transportation system, benefiting our
daily travels in terms of safety, mobility, and sustainability. However,
vehicular communication technologies such as Dedicated Short-Range
Communications (DSRC) or Cellular-Based Vehicle-to-Everything (C-V2X)
communications unavoidably introduce issues like communication delay and packet
loss, which will downgrade the performances of any CAV applications. In this
study, we propose a consensus-based motion estimation methodology to estimate
the vehicle motion when the vehicular communication environment is not ideal.
This methodology is developed based on the consensus-based feedforward/feedback
motion control algorithm, estimating the position and speed of a CAV in the
presence of communication delay and packet loss. The simulation study is
conducted in a traffic scenario of unsignalized intersections, where CAVs
coordinate with each other through V2X communications and cross intersections
without any full stop. Game engine-based human-in-the-loop simulation results
shows the proposed motion estimation methodology can cap the position
estimation error to 0.5 m during periodic packet loss and time-variant
communication delay.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:56:02 GMT""}]","2021-05-18"
"2101.07759","Margot Fitz Axen","Margot Fitz Axen and Julia Speicher and Aimee Hungerford and Chris L.
  Fryer","Cosmic Ray transport in mixed magnetic fields and their role on the
  observed anisotropies","14 pages, 13 figures","MNRAS 500-3(2021)3497-3510","10.1093/mnras/staa3500",,"astro-ph.HE","http://creativecommons.org/licenses/by-sa/4.0/","  There is a growing set of observational data demonstrating that cosmic rays
exhibit small-scale anisotropies (5-30 deg) with amplitude deviations lying
between 0.01-0.1 percent that of the average cosmic ray flux. A broad range of
models have been proposed to explain these anisotropies ranging from
finite-scale magnetic field structures to dark matter annihilation. The
standard diffusion transport methods used in cosmic ray propagation do not
capture the transport physics in a medium with finite-scale or coherent
magnetic field structures. Here, we present a Monte Carlo transport method,
applying it to a series of finite-scale magnetic field structures to determine
the requirements of such fields in explaining the observed cosmic
ray,small-scale anisotropies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 17:59:10 GMT""}]","2021-01-20"
"2101.07762","Arnaud Pierens","Arnaud Pierens","On the non-axisymmetric fragmentation of rings generated by the Secular
  Gravitational Instability","accepted in MNRAS",,"10.1093/mnras/stab183",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ringed structures have been observed in a variety of protoplanetary discs.
Among the processes that might be able to generate such features, the Secular
Gravitational Instability (SGI) is a possible candidate. It has also been
proposed that the SGI might lead to the formation of planetesimals during the
non-linear phase of the instability. In this context, we employ two-fluid
hydrodynamical simulations with self-gravity to study the non-axisymmetric,
non-linear evolution of ringed perturbations that grow under the action of the
SGI. We find that the non-linear evolution outcome of the SGI depends mainly on
the initial linear growth rate. For SGI growth rates smaller than typically
$\sigma \gtrsim 10^{-4}-10^{-5}\Omega$, dissipation resulting from dust
feedback introduces a $m=1$ spiral wave in the gas, even for Toomre gas
stability parameters $Q_g>2$ for which non-axisymmetric instabilities appear in
a purely gaseous disc. This one-armed spiral subsequently traps dust particles
until a dust-to-gas ratio $\epsilon \sim 1$ is achieved. For higher linear
growth rates, the dust ring is found to undergo gravitational collapse until
the bump in the surface density profile becomes strong enough to trigger the
formation of dusty vortices through the Rossby Wave Instability (RWI).
Enhancements in dust density resulting from this process are found to scale
with the linear growth rate, and can be such that the dust density is higher
than the Roche density, leading to the formation of bound clumps. Fragmentation
of axisymmetric rings produced by the SGI might therefore appear as a possible
process for the formation of planetesimals.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:06:34 GMT""}]","2021-02-03"
"2101.07763","Godwill Mbiti Kanyolo PhD","Godwill Mbiti Kanyolo and Titus Masese","Reproducing the asymptotic behaviour of galaxy rotation curves by a
  novel constraint in general relativity","13 pages, 1 figure",,,,"gr-qc astro-ph.GA cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cold dark matter paradigm has been posited as the standard explanation
for the non-Keplerian behavior of galaxy rotation curves, where for galaxies
satisfying the Tully-Fisher relation, the mass of the dark matter halo from a
large class of universal dark matter profiles ought to roughly increase
linearly with radial distance at large distances, $m(r) \sim r/nG$ ($G$ is the
gravitational constant and $n$ is a dimensionless parameter which depends on
the amount of baryonic matter $M$ within the galaxy). Despite numerous advances
in modeling galaxy formation and evolution, a scientific consensus on the
origin of the observed dependence of the dimensionless parameter $n =
(GMa_{0})^{-1/2}$ on the mass of baryonic matter $M$ within the galaxy (the
Tully-Fisher relation), and the connection of the cosmological constant
$\Lambda$ to the parameter $a_{0} \sim (\Lambda/3)^{1/2}$ remains elusive.
Here, we show that Einstein Field Equations can be remolded into
$\nabla_{\nu}\mathcal{K}^{\nu}_{\,\,\mu} = 8\pi
GM\Psi^{*}\mathcal{D}_{\mu}\Psi$, where $\mathcal{K}_{\mu\nu}$ is a complex
Hermitian tensor, $\mathcal{D}_{\mu}$ is a covariant derivative and $\Psi$ is a
complex-valued function. This avails a novel constraint,
$\nabla_{\mu}\nabla_{\nu}\mathcal{K}^{\mu\nu} = 0$ not necessarily available in
Einstein's General Relativity. In the weak-field regime, we can readily
reproduce the Tully-Fisher relation using the usual charge-less pressure-less
fluid. Moreover, our approach is equivalent to a Ginzburg-Landau theory of $n$
bosons, where the order parameter is normalized as $\int_{0}^{1/a_{0}} dr\,4\pi
r^2\Psi^*\Psi = n$ and $1/a_{0} \sim (\Lambda/3)^{-1/2}$ is the cut-off length
scale comparable to the size of the de Sitter universe. Our investigations
provide a framework that reproduces the mass-asymptotic speed relation in
galaxies within the cold dark matter paradigm.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:16:30 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 14:53:30 GMT""},{""version"":""v3"",""created"":""Thu, 8 Apr 2021 11:25:46 GMT""},{""version"":""v4"",""created"":""Sun, 30 May 2021 18:03:08 GMT""},{""version"":""v5"",""created"":""Thu, 3 Jun 2021 13:02:45 GMT""},{""version"":""v6"",""created"":""Tue, 7 Sep 2021 12:50:03 GMT""}]","2021-09-08"
"2101.07764","Sisi Jia","Sisi Jia (1), Siew Cheng Phua (2), Yuta Nihongaki (2), Yizeng Li (3
  and 5), Michael Pacella (1), Yi Li (1), Abdul M. Mohammed (1), Sean Sun (3),
  Takanari Inoue (2), Rebecca Schulman (1 and 4) ((1) Chemical and Biomolecular
  Engineering, Johns Hopkins University, Baltimore, USA, (2) Cell Biology,
  Johns Hopkins University School of Medicine, Baltimore, USA, (3) Mechanical
  Engineering, Johns Hopkins University, Baltimore, USA, (4) Computer Science,
  Johns Hopkins University, Baltimore, USA, (5) Department of Mechanical
  Engineering, Kennesaw State University, Marietta, USA)","Growth and site-specific organization of micron-scale biomolecular
  devices on living mammalian cells","20 pages, 5 figures",,"10.1038/s41467-021-25890-z",,"q-bio.BM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Mesoscale molecular assemblies on the cell surface, such as cilia and
filopodia, integrate information, control transport and amplify signals.
Synthetic devices mimicking these structures could sensitively monitor these
cellular functions and direct new ones. The challenges in creating such
devices, however are that they must be integrated with cells in a precise
kinetically controlled process and a device's structure and its precisely
structured cell interface must then be maintained during active cellular
function. Here we report the ability to integrate synthetic micro-scale
filaments, DNA nanotubes, into a cell's architecture by anchoring them by their
ends to specific receptors on the surfaces of mammalian cells. These filaments
can act as shear stress meters: how anchored nanotubes bend at the cell surface
quantitatively indicates the magnitude of shear stresses between 0-2 dyn per
cm2, a regime important for cell signaling. Nanotubes can also grow while
anchored to cells, thus acting as dynamic components of cells. This approach to
cell surface engineering, in which synthetic biomolecular assemblies are
organized within existing cellular architecture, could make it possible to
build new types of sensors, machines and scaffolds that can interface with,
control and measure properties of cells.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:17:39 GMT""}]","2021-10-27"
"2101.07765","Nasser Moazzen-Ahmadi","A.J. Barclay, A. Pietropolli Charmet, A.R.W. McKellar, and N.
  Moazzen-Ahmadi","Exploring the next step in micro-solvation of CO in water: Infrared
  spectra and structural calculations of (H2O)4- CO and (D2O)4- CO","27 page, 3 figures",,"10.1063/5.0038188",,"physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend studies of micro-solvation of carbon monoxide by a combination of
high-resolution IR spectroscopy and ab initio calculations. Spectra of the
(H2O)4-CO and (D2O)4-CO pentamers are observed in the C-O stretch fundamental
region (~2150 cm-1). The H2O containing spectrum is broadened by
predissociation, but that of D2O is sharp, enabling detailed analysis which
gives a precise band origin and rotational parameters. Ab initio calculations
are employed to confirm the assignment to (water)4-CO and to determine the
structure, in which the geometry of the (water)4 fragment is a cyclic ring very
similar to the isolated water tetramer. The CO fragment is located ""above"" the
ring plane, with a partial hydrogen bond between the C atom and one of the
""free"" protons (deuterons) of the water tetramer. Together with previous
results on D2O-CO, (D2O)2-CO, and (D2O)3-CO, this represents a probe of the
four initial steps in the solvation of carbon monoxide at high resolution.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:18:48 GMT""}]","2021-02-24"
"2101.07766","Louis Raynal","Louis Raynal, Till Hoffmann and Jukka-Pekka Onnela","Cost-based feature selection for network model choice","34 pages, 6 figures",,,,"stat.ME stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selecting a small set of informative features from a large number of possibly
noisy candidates is a challenging problem with many applications in machine
learning and approximate Bayesian computation. In practice, the cost of
computing informative features also needs to be considered. This is
particularly important for networks because the computational costs of
individual features can span several orders of magnitude. We addressed this
issue for the network model selection problem using two approaches. First, we
adapted nine feature selection methods to account for the cost of features. We
show for two classes of network models that the cost can be reduced by two
orders of magnitude without considerably affecting classification accuracy
(proportion of correctly identified models). Second, we selected features using
pilot simulations with smaller networks. This approach reduced the
computational cost by a factor of 50 without affecting classification accuracy.
To demonstrate the utility of our approach, we applied it to three different
yeast protein interaction networks and identified the best-fitting duplication
divergence model.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:21:06 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 08:32:39 GMT""},{""version"":""v3"",""created"":""Thu, 1 Sep 2022 19:42:25 GMT""}]","2022-09-05"
"2101.07767","Jack C. Gartside","Jack C. Gartside, Alex Vanstone, Troy Dion, Kilian D. Stenning, Daan
  M. Arroo, Hide Kurebayashi and Will R. Branford","Reconfigurable magnonic mode-hybridisation and spectral control in a
  bicomponent artificial spin ice",,,"10.1038/s41467-021-22723-x",,"cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Strongly-interacting nanomagnetic arrays are finding increasing use as model
host systems for reconfigurable magnonics. The strong inter-element coupling
allows for stark spectral differences across a broad microstate space due to
shifts in the dipolar field landscape. While these systems have yielded
impressive initial results, developing rapid, scaleable means to access abroad
range of spectrally-distinct microstates is an open research problem.We present
a scheme whereby square artificial spin ice is modified by widening a
'staircase' subset of bars relative to the rest of the array, allowing
preparation of any ordered vertex state via simple global-field protocols.
Available microstates range from the system ground-state to high-energy
'monopole' states, with rich and distinct microstate-specific magnon spectra
observed. Microstate-dependent mode-hybridisation and anticrossings are
observed at both remanence and in-field with dynamic coupling strength tunable
via microstate-selection. Experimental coupling strengths are found up to g /
2$\pi$ = 0.15 GHz. Microstate control allows fine mode-frequency shifting, gap
creation and closing, and active mode number selection.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:23:38 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 18:24:55 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 16:40:49 GMT""}]","2021-06-09"
"2101.07768","Ehsan Zabardast","Ehsan Zabardast, Julian Frattini, Javier Gonzalez-Huerta, Daniel
  Mendez, Tony Gorschek, Krzysztof Wnuk","Assets in Software Engineering: What are they after all?","Manuscript submitted to the Journal of Systems and Software",,"10.1016/j.jss.2022.111485",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the development and maintenance of software-intensive products or
services, we depend on various artefacts. Some of those artefacts, we deem
central to the feasibility of a project and the product's final quality.
Typically, these central artefacts are referred to as assets. However, despite
their central role in the software development process, little thought is yet
invested into what eventually characterises as an asset, often resulting in
many terms and underlying concepts being mixed and used inconsistently. A
precise terminology of assets and related concepts, such as asset degradation,
are crucial for setting up a new generation of cost-effective software
engineering practices.
  In this position paper, we critically reflect upon the notion of assets in
software engineering. As a starting point, we define the terminology and
concepts of assets and extend the reasoning behind them. We explore assets'
characteristics and discuss what asset degradation is as well as its various
types and the implications that asset degradation might bring for the planning,
realisation, and evolution of software-intensive products and services over
time.
  We aspire to contribute to a more standardised definition of assets in
software engineering and foster research endeavours and their practical
dissemination in a common, more unified direction.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:31:33 GMT""},{""version"":""v2"",""created"":""Sun, 24 Oct 2021 13:19:22 GMT""},{""version"":""v3"",""created"":""Wed, 23 Feb 2022 14:32:15 GMT""},{""version"":""v4"",""created"":""Wed, 11 May 2022 21:31:28 GMT""},{""version"":""v5"",""created"":""Mon, 11 Jul 2022 14:57:38 GMT""}]","2022-08-29"
"2101.07769","Peng Gao","Peng Gao, Xiaoyuan Liu, Edward Choi, Bhavna Soman, Chinmaya Mishra,
  Kate Farris, Dawn Song","A System for Automated Open-Source Threat Intelligence Gathering and
  Management","Accepted paper at SIGMOD 2021 demonstrations track",,,,"cs.CR cs.AI cs.CL cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To remain aware of the fast-evolving cyber threat landscape, open-source
Cyber Threat Intelligence (OSCTI) has received growing attention from the
community. Commonly, knowledge about threats is presented in a vast number of
OSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI
gathering and management platforms, however, have primarily focused on
isolated, low-level Indicators of Compromise. On the other hand, higher-level
concepts (e.g., adversary tactics, techniques, and procedures) and their
relationships have been overlooked, which contain essential knowledge about
threat behaviors that is critical to uncovering the complete threat scenario.
To bridge the gap, we propose SecurityKG, a system for automated OSCTI
gathering and management. SecurityKG collects OSCTI reports from various
sources, uses a combination of AI and NLP techniques to extract high-fidelity
knowledge about threat behaviors, and constructs a security knowledge graph.
SecurityKG also provides a UI that supports various types of interactivity to
facilitate knowledge graph exploration.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:31:35 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 20:50:51 GMT""}]","2021-03-02"
"2101.07770","Joshua L. Vincent","Joshua L. Vincent, Ramon Manzorro, Sreyas Mohan, Binh Tang, Dev Y.
  Sheth, Eero P. Simoncelli, David S. Matteson, Carlos Fernandez-Granda, and
  Peter A. Crozier","Developing and Evaluating Deep Neural Network-based Denoising for
  Nanoparticle TEM Images with Ultra-low Signal-to-Noise",,,"10.1017/S1431927621012678",,"cond-mat.mtrl-sci eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A deep convolutional neural network has been developed to denoise
atomic-resolution TEM image datasets of nanoparticles acquired using direct
electron counting detectors, for applications where the image signal is
severely limited by shot noise. The network was applied to a model system of
CeO2-supported Pt nanoparticles. We leverage multislice image simulations to
generate a large and flexible dataset for training and testing the network. The
proposed network outperforms state-of-the-art denoising methods by a
significant margin both on simulated and experimental test data. Factors
contributing to the performance are identified, including most importantly (a)
the geometry of the images used during training and (b) the size of the
network's receptive field. Through a gradient-based analysis, we investigate
the mechanisms learned by the network to denoise experimental images. This
shows that the network exploits global and local information in the noisy
measurements, for example, by adapting its filtering approach when it
encounters atomic-level defects at the nanoparticle surface. Extensive analysis
has been done to characterize the network's ability to correctly predict the
exact atomic structure at the nanoparticle surface. Finally, we develop an
approach based on the log-likelihood ratio test that provides a quantitative
measure of the agreement between the noisy observation and the atomic-level
structure in the network-denoised image.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:34:18 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 19:37:16 GMT""}]","2021-12-14"
"2101.07771","Grace Deng","Judy P. Che-Castaldo, R\'emi Cousin, Stefani Daryanto, Grace Deng,
  Mei-Ling E. Feng, Rajesh K. Gupta, Dezhi Hong, Ryan M. McGranaghan, Olukunle
  O. Owolabi, Tianyi Qu, Wei Ren, Toryn L. J. Schafer, Ashutosh Sharma,
  Chaopeng Shen, Mila Getmansky Sherman, Deborah A. Sunter, Lan Wang, David S.
  Matteson","Critical Risk Indicators (CRIs) for the electric power grid: A survey
  and discussion of interconnected effects",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electric power grid is a critical societal resource connecting multiple
infrastructural domains such as agriculture, transportation, and manufacturing.
The electrical grid as an infrastructure is shaped by human activity and public
policy in terms of demand and supply requirements. Further, the grid is subject
to changes and stresses due to solar weather, climate, hydrology, and ecology.
The emerging interconnected and complex network dependencies make such
interactions increasingly dynamic causing potentially large swings, thus
presenting new challenges to manage the coupled human-natural system. This
paper provides a survey of models and methods that seek to explore the
significant interconnected impact of the electric power grid and interdependent
domains. We also provide relevant critical risk indicators (CRIs) across
diverse domains that may influence electric power grid risks, including
climate, ecology, hydrology, finance, space weather, and agriculture. We
discuss the convergence of indicators from individual domains to explore
possible systemic risk, i.e., holistic risk arising from cross-domains
interconnections. Our study provides an important first step towards
data-driven analysis and predictive modeling of risks in the coupled
interconnected systems. Further, we propose a compositional approach to risk
assessment that incorporates diverse domain expertise and information, data
science, and computer science to identify domain-specific CRIs and their union
in systemic risk indicators.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:36:50 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 02:46:35 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 20:16:24 GMT""},{""version"":""v4"",""created"":""Wed, 9 Jun 2021 21:57:10 GMT""}]","2021-06-11"
"2101.07772","Yu Shi","Yu Shi, Edo Waks","Deterministic generation of multidimensional photonic cluster states
  using time-delay feedback","14 pages, 11 figures","Phys. Rev. A 104, 013703 (2021)","10.1103/PhysRevA.104.013703",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cluster states are useful in many quantum information processing
applications. In particular, universal measurement-based quantum computation
(MBQC) utilizes 2D cluster states, and topologically fault-tolerant MBQC
requires cluster states with three or higher dimensions. This work proposes a
protocol to deterministically generate multidimensional photonic cluster states
using a single atom-cavity system and time-delay feedback. The dimensionality
of the cluster state increases linearly with the number of time-delay feedback.
We firstly give a diagrammatic derivation of the tensor network states, which
is valuable in simulating matrix product states and projected entangled pair
states generated from sequential photons. Our method also provides a simple way
to bridge and analyze the experimental imperfections and the logical errors of
the generated states. In this method, we analyze the generated cluster states
under realistic experimental conditions and address both one-qubit and
two-qubit errors. Through numerical simulation, we observe an optimal
atom-cavity cooperativity for the fidelity of the generated states, which is
surprising given the prevailing assumption that higher cooperativity systems
are inherently better for photonic applications.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:36:51 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 18:06:14 GMT""}]","2021-07-08"
"2101.07773","Balasubramaniam Srinivasan","Balasubramaniam Srinivasan, Da Zheng, George Karypis","Learning over Families of Sets -- Hypergraph Representation Learning for
  Higher Order Tasks","Published as a conference paper at SIAM International Conference on
  Data Mining(SDM 2021)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph representation learning has made major strides over the past decade.
However, in many relational domains, the input data are not suited for simple
graph representations as the relationships between entities go beyond pairwise
interactions. In such cases, the relationships in the data are better
represented as hyperedges (set of entities) of a non-uniform hypergraph. While
there have been works on principled methods for learning representations of
nodes of a hypergraph, these approaches are limited in their applicability to
tasks on non-uniform hypergraphs (hyperedges with different cardinalities). In
this work, we exploit the incidence structure to develop a hypergraph neural
network to learn provably expressive representations of variable sized
hyperedges which preserve local-isomorphism in the line graph of the
hypergraph, while also being invariant to permutations of its constituent
vertices. Specifically, for a given vertex set, we propose frameworks for (1)
hyperedge classification and (2) variable sized expansion of partially observed
hyperedges which captures the higher order interactions among vertices and
hyperedges. We evaluate performance on multiple real-world hypergraph datasets
and demonstrate consistent, significant improvement in accuracy, over
state-of-the-art models.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:37:50 GMT""}]","2021-01-20"
"2101.07774","Adam Mate","Arthur K. Barnes, Adam Mate","Dynamic State Estimation for Radial Microgrid Protection","9 pages. 4 figures. 5 tables","Proceedings of the 2021 IEEE/IAS 57th Industrial and Commercial
  Power Systems Technical Conference, pp. 1-9, Apr. 2021","10.1109/ICPS51807.2021.9416613","LA-UR-20-30126","eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Microgrids are localized electrical grids with control capability that are
able to disconnect from the traditional grid to operate autonomously. They
strengthen grid resilience, help mitigate grid disturbances, and support a
flexible grid by enabling the integration of distributed energy resources.
Given the likely presence of critical loads, the proper protection of
microgrids is of vital importance; however, this is complicated in the case of
inverter-interfaced microgrids where low fault currents preclude the use of
conventional time-overcurrent protection. This paper introduces and
investigates the application of dynamic state estimation, a generalization of
differential protection, for the protection of radial portions of microgrids
(or distribution networks); both phasor-based and dynamic approaches are
investigated for protection. It is demonstrated through experiments on three
case-study systems that dynamic state estimation is capable of correctly
identifying model parameters for both normal and faulted operation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:38:22 GMT""},{""version"":""v2"",""created"":""Fri, 30 Dec 2022 16:51:12 GMT""}]","2023-01-02"
"2101.07775","Justine Devin","Justine Devin, Matthieu Renaud, Marianne Lemoine-Goumard and Georges
  Vasileiadis","Multiwavelength constraints on the unidentified Galactic TeV sources
  HESS J1427$-$608, HESS J1458$-$608, and new VHE $\gamma$-ray source
  candidates",,"A&A 647, A68 (2021)","10.1051/0004-6361/202039563",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The H.E.S.S. Galactic Plane Survey (HGPS) revealed 78 TeV sources among which
47 are not clearly associated with a known object. We present a multiwavelength
approach to constrain the origin of the emission from unidentified HGPS
sources. We present a generic pipeline that explores a large database of
multiwavelength archival data toward any region in the Galactic plane. Along
with a visual inspection of the retrieved multiwavelength observations to
search for faint and uncataloged counterparts, we derive a radio spectral index
that helps disentangle thermal from nonthermal emission and a mean magnetic
field through X-ray and TeV data in case of a leptonic scenario. We also search
for a spectral connection between the GeV and the TeV regimes with the
Fermi-LAT cataloged sources that may be associated with the unidentified HGPS
source. We complete the association procedure with catalogs of known objects
and with the source catalogs from instruments whose data are retrieved. The
method is applied on two unidentified sources, namely HESS J1427$-$608 and HESS
J1458$-$608, for which the multiwavelength constraints favor the pulsar wind
nebula (PWN) scenario. We model their broadband nonthermal spectra in a
leptonic scenario with a magnetic field $B \lesssim 10$ $\mu$G, which is
consistent with that obtained from ancient PWNe. We place both sources within
the context of the TeV PWN population to estimate the spin-down power and the
characteristic age of the putative pulsar. We also shed light on two possibly
significant $\gamma$-ray excesses in the HGPS: the first is located in the
south of the unidentified source HESS J1632$-$478 and the second is spatially
coincident with the synchrotron-emitting supernova remnant G28.6$-$0.1. The
multiwavelength counterparts found toward both $\gamma$-ray excesses make these
promising candidates for being new very-high energy $\gamma$-ray sources.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:42:33 GMT""}]","2021-03-17"
"2101.07776","Yuchen Xu","Yuchen Xu, Marie-Christine D\""uker, David S. Matteson","Testing Simultaneous Diagonalizability","35 pages, 7 figures",,"10.1080/01621459.2023.2202435",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes novel methods to test for simultaneous diagonalization of
possibly asymmetric matrices. Motivated by various applications, a two-sample
test as well as a generalization for multiple matrices are proposed. A partial
version of the test is also studied to check whether a partial set of
eigenvectors is shared across samples. Additionally, a novel algorithm for the
considered testing methods is introduced. Simulation studies demonstrate
favorable performance for all designs. Finally, the theoretical results are
utilized to decouple vector autoregression models into multiple univariate time
series, and to test for the same stationary distribution in recurrent Markov
chains. These applications are demonstrated using macroeconomic indices of 8
countries and streamflow data, respectively.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:43:25 GMT""}]","2023-04-17"
"2101.07777","Joseph Moeller","Joe Moeller","The Grothendieck Construction in Categorical Network Theory","Ph.D. Thesis, 151 pages",,,,"math.CT","http://creativecommons.org/licenses/by/4.0/","  In this thesis, we present a flexible framework for specifying and
constructing operads which are suited to reasoning about network construction.
The data used to present these operads is called a \emph{network model}, a
monoidal variant of Joyal's combinatorial species. The construction of the
operad required that we develop a monoidal lift of the Grothendieck
construction. We then demonstrate how concepts like priority and dependency can
be represented in this framework. For the former, we generalize Green's graph
products of groups to the context of universal algebra. For the latter, we
examine the emergence of monoidal fibrations from the presence of catalysts in
Petri nets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:43:31 GMT""}]","2021-01-20"
"2101.07778","C. S. Shahbazi","C. I. Lazaroiu and C. S. Shahbazi","The geometry and DSZ quantization of four-dimensional supergravity","19 pages","Letters in Mathematical Physics 113, 4 (2023)","10.1007/s11005-022-01626-y",,"math.DG hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We implement the Dirac-Schwinger-Zwanziger integrality condition on
four-dimensional classical ungauged supergravity and use it to obtain its
duality-covariant, gauge-theoretic, differential-geometric model on an oriented
four-manifold $M$ of arbitrary topology. Classical bosonic supergravity is
completely determined by a submersion $\pi$ over $M$ equipped with a complete
Ehresmann connection, a vertical euclidean metric, and a vertically-polarized
flat symplectic vector bundle $\Xi$. Building on these structures, we implement
the Dirac-Schwinger-Zwanziger integrality condition through the choice of an
element in the degree-two sheaf cohomology group with coefficients in a locally
constant sheaf $\mathcal{L}\subset \Xi$ valued in the groupoid of integral
symplectic spaces. We show that this data determines a Siegel principal bundle
$P_{\mathfrak{t}}$ of fixed type $\mathfrak{t}\in \mathbb{Z}^{n_v}$ whose
connections provide the global geometric description of the local
electromagnetic gauge potentials of the theory. Furthermore, we prove that the
Maxwell gauge equations of the theory reduce to the polarized self-duality
condition determined by $\Xi$ on the connections of $P_{\mathfrak{t}}$. In
addition, we investigate the continuous and discrete U-duality groups of the
theory, characterizing them through short exact sequences and realizing the
latter through the gauge group of $P_{\mathfrak{t}}$ acting on its adjoint
bundle. This elucidates the geometric origin of U-duality, which we explore in
several examples, illustrating its dependence on the topology of the fiber
bundles $\pi$ and $P_{\mathfrak{t}}$ as well as on the isomorphism type of
$\mathcal{L}$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:47:55 GMT""},{""version"":""v2"",""created"":""Thu, 12 Jan 2023 01:35:28 GMT""}]","2023-01-13"
"2101.07779","Bryce Cousins","A. L. Baxter, S. Y. BenZvi, W. Bonivento, A. Brazier, M. Clark, A.
  Coleiro, D. Collom, M. Colomer-Molla, B. Cousins, A. Delgado Orellana, D.
  Dornic, V. Ekimtcov, S. ElSayed, A. Gallo Rosso, P. Godwin, S. Griswold, A.
  Habig, S. Horiuchi, D. A. Howell, M. W. G. Johnson, M. Juric, J. P. Kneller,
  A. Kopec, C. Kopper, V. Kulikovskiy, M. Lamoureux, R. F. Lang, S. Li, M.
  Lincetto, W. Lindstrom, M. W. Linvill, C. McCully, J. Migenda, D.
  Milisavljevic, S. Nelson, R. Novoseltseva, E. O'Sullivan, D. Petravick, B. W.
  Pointon, N. Raj, A. Renshaw, J. Rumleskie, R. Tapia, J. C. L. Tseng, C. D.
  Tunnell, C. F. Vigorito, C. J. Virtue, C. Weaver, L. Winslow, R. Wolski, X.
  J. Xu, Y. Xu","Collaborative Experience between Scientific Software Projects using
  Agile Scrum Development","Revisions: in response to peer-review recommendations, most sections
  have been substantially expanded and reworked, five new figures have been
  added, and the title has been changed. Results unchanged",,"10.1002/spe.3120",,"cs.SE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing sustainable software for the scientific community requires
expertise in software engineering and domain science. This can be challenging
due to the unique needs of scientific software, the insufficient resources for
software engineering practices in the scientific community, and the complexity
of developing for evolving scientific contexts. While open-source software can
partially address these concerns, it can introduce complicating dependencies
and delay development. These issues can be reduced if scientists and software
developers collaborate. We present a case study wherein scientists from the
SuperNova Early Warning System collaborated with software developers from the
Scalable Cyberinfrastructure for Multi-Messenger Astrophysics project. The
collaboration addressed the difficulties of open-source software development,
but presented additional risks to each team. For the scientists, there was a
concern of relying on external systems and lacking control in the development
process. For the developers, there was a risk in supporting a user-group while
maintaining core development. These issues were mitigated by creating a second
Agile Scrum framework in parallel with the developers' ongoing Agile Scrum
process. This Agile collaboration promoted communication, ensured that the
scientists had an active role in development, and allowed the developers to
evaluate and implement the scientists' software requirements. The collaboration
provided benefits for each group: the scientists actuated their development by
using an existing platform, and the developers utilized the scientists'
use-case to improve their systems. This case study suggests that scientists and
software developers can avoid scientific computing issues by collaborating and
that Agile Scrum methods can address emergent concerns.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:54:34 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 17:08:03 GMT""},{""version"":""v3"",""created"":""Tue, 2 Aug 2022 21:21:19 GMT""}]","2022-08-04"
"2101.07780","Javier LLorca","B. Bell\'on, A. K. Boukellal, T. Isensee, O. M. Wellborn, K. P.
  Trumble, M. J. M. Krane, M. S. Titus, D. Tourret, J. LLorca","Multiscale prediction of microstructure length scales in metallic alloy
  casting",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we combine casting experiments and quantitative simulations
to present a novel multiscale modeling approach to predict local primary
dendritic spacings in metallic alloys solidified in conditions relevant to
industrial casting processes. To this end, primary dendritic spacings were
measured in instrumented casting experiments in Al-Cu alloys containing 1\,wt\%
and 4\,wt\% of Cu, and they were compared to spacing stability ranges and
average spacings in dendritic arrays simulated using phase-field (PF) and
dendritic needle network (DNN) models. It is first shown that PF and DNN lead
to similar results for the Al-1\,wt\%Cu alloy, using a dendrite tip selection
constant calculated with PF in the DNN simulations. PF simulations cannot
achieve quantitative predictions for the Al-4\,wt\%Cu alloy because they are
too computationally demanding due to the large separation of scale between tip
radius and diffusion length, a characteristic feature of non-dilute alloys.
Nevertheless, the results of DNN simulations for non-dilute Al-Cu alloys are in
overall good agreement with our experimental results as well as with those of
an extensive literature review. Simulations consistently suggest a widening of
the PDAS stability range with a decrease of the temperature gradient as the
microstructure goes from cellular-dendrites to well-developed hierarchical
dendrites.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:55:20 GMT""}]","2021-01-20"
"2101.07781","Cong Ma","Cong Ma, Banghua Zhu, Jiantao Jiao, Martin J. Wainwright","Minimax Off-Policy Evaluation for Multi-Armed Bandits",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of off-policy evaluation in the multi-armed bandit model
with bounded rewards, and develop minimax rate-optimal procedures under three
settings. First, when the behavior policy is known, we show that the Switch
estimator, a method that alternates between the plug-in and importance sampling
estimators, is minimax rate-optimal for all sample sizes. Second, when the
behavior policy is unknown, we analyze performance in terms of the competitive
ratio, thereby revealing a fundamental gap between the settings of known and
unknown behavior policies. When the behavior policy is unknown, any estimator
must have mean-squared error larger -- relative to the oracle estimator
equipped with the knowledge of the behavior policy -- by a multiplicative
factor proportional to the support size of the target policy. Moreover, we
demonstrate that the plug-in approach achieves this worst-case competitive
ratio up to a logarithmic factor. Third, we initiate the study of the partial
knowledge setting in which it is assumed that the minimum probability taken by
the behavior policy is known. We show that the plug-in estimator is optimal for
relatively large values of the minimum probability, but is sub-optimal when the
minimum probability is low. In order to remedy this gap, we propose a new
estimator based on approximation by Chebyshev polynomials that provably
achieves the optimal estimation error. Numerical experiments on both simulated
and real data corroborate our theoretical findings.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:55:29 GMT""}]","2021-01-20"
"2101.07782","Yifan Jing","Yifan Jing, Chieu-Minh Tran, Ruixiang Zhang","A nonabelian Brunn-Minkowski inequality","56 pages; incorporated referee comments, to appear in GAFA",,,,"math.GR math.CA math.CO math.FA math.MG","http://creativecommons.org/licenses/by/4.0/","  Henstock and Macbeath asked in 1953 whether the Brunn-Minkowski inequality
can be generalized to nonabelian locally compact groups; questions along the
same line were also asked by Hrushovski, McCrudden, and Tao. We obtain here
such an inequality and prove that it is sharp for helix-free locally compact
groups, which includes real linear algebraic groups, Nash groups, semisimple
Lie groups with finite center, solvable Lie groups, etc. The proof follows an
induction on dimension strategy; new ingredients include an understanding of
the role played by maximal compact subgroups of Lie groups, a necessary
modified form of the inequality which is also applicable to nonunimodular
locally compact groups, and a proportionated averaging trick.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:55:49 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 04:42:20 GMT""},{""version"":""v3"",""created"":""Mon, 8 May 2023 21:00:00 GMT""}]","2023-05-10"
"2101.07783","Adam Mate","Arthur K. Barnes, Adam Mate","Implementing Admittance Relaying for Microgrid Protection","9 pages. 21 figures. 4 tables","Proceedings of the 2021 IEEE/IAS 57th Industrial and Commercial
  Power Systems Technical Conference, pp. 1-9, Apr. 2021","10.1109/ICPS51807.2021.9416600","LA-UR-20-30128","eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The rapid increase of distributed energy resources has led to the widespread
deployment of microgrids. These flexible and efficient local energy grids are
able to operate in both grid-connected mode and islanded mode; they are
interfaced to the main power system by a fast semiconductor switch and commonly
make use of inverter-interfaced generation. This paper focuses on inverter
interfaced microgrids, which present a challenge for protection as they do not
provide the high short-circuit current necessary for conventional
time-overcurrent protection. The application of admittance relaying for the
protection of inverter-interfaced microgrids is investigated as a potential
solution. The comparison of analytical and simulated results of performed four
experiments prove the suitability of admittance relaying for microgrids
protection.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:58:01 GMT""},{""version"":""v2"",""created"":""Tue, 27 Dec 2022 12:18:08 GMT""}]","2022-12-29"
"2101.07784","Nicolas Englebert","Nicolas Englebert, Francesco De Lucia, Pedro Parra-Rivas, Carlos Mas
  Arab\'i, Pier-John Sazio, Simon-Pierre Gorza and Fran\c{c}ois Leo","Parametrically driven Kerr cavity solitons",,,"10.1038/s41566-021-00858-z",,"physics.optics nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal cavity solitons are optical pulses that propagate indefinitely in
nonlinear resonators. They are currently attracting a lot of attention, both
for their many potential applications and for their connection to other fields
of science. Cavity solitons are phase locked to a driving laser. This is what
distinguishes them from laser dissipative solitons and the main reason why they
are excellent candidates for precision applications such as optical atomic
clocks. To date, the focus has been on driving Kerr solitons close to their
carrier frequency, in which case a single stable localised solution exists for
fixed parameters. Here we experimentally demonstrate, for the first time, Kerr
cavity solitons excitation around twice their carrier frequency. In that
configuration, called parametric driving, two solitons of opposite phase may
coexist. We use a fibre resonator that incorporates a quadratically nonlinear
section and excite stable solitons by scanning the driving frequency. Our
experimental results are in excellent agreement with a seminal amplitude
equation, highlighting connections to hydrodynamic and mechanical systems,
amongst others. Furthermore, we experimentally confirm that two different
phase-locked solitons may be simultaneously excited and harness this
multiplicity to generate a string of random bits, thereby extending the pool of
applications of Kerr resonators to random number generators and Ising machines.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:58:15 GMT""}]","2021-11-10"
"2101.07785","Lorenzo Valvo","Lorenzo Valvo and Ugo Locatelli","Hamiltonian Control of Magnetic Field Lines: Computer Assisted Results
  Proving the Existence of KAM Barriers","Version 2",,,,"math.DS math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We reconsider a control theory for Hamiltonian systems, that was introduced
on the basis of KAM theory and applied to a model of magnetic field in previous
articles. By a combination of Frequency Analysis and of a rigorous (Computer
Assisted) KAM algorithm we prove that in the phase space of the magnetic field,
due to the control term, a set of invariant tori appear, and it acts as a
transport barrier. Our analysis, which is common (but often also limited) to
Celestial Mechanics, is based on a normal form approach; it is also quite
general and can be applied to quasi-integrable Hamiltonian systems satisfying a
few additional mild assumptions. As a novelty with respect to the works that in
the last two decades applied Computer Assisted Proofs into the framework of KAM
theory, we provide all the codes allowing to produce our results. They are
collected in a software package that is publicly available from the {\it
Mendeley Data} repository. All these codes are designed in such a way to be
easy-to-use, also for what concerns eventual adaptations for applications to
similar problems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:59:10 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 08:50:49 GMT""}]","2021-05-25"
"2101.07786","Ben Bartlett","Ben Bartlett, Avik Dutt, Shanhui Fan","Deterministic photonic quantum computation in a synthetic time dimension","19 pages, 8 figures","Optica 8 (12), 1515-1523 (2021)","10.1364/OPTICA.424258",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photonics offers unique advantages as a substrate for quantum information
processing, but imposes fundamental scalability challenges. Nondeterministic
schemes impose massive resource overheads, while deterministic schemes require
prohibitively many identical quantum emitters to realize sizeable quantum
circuits. Here we propose a scalable architecture for a photonic quantum
computer which needs minimal quantum resources to implement any quantum
circuit: a single coherently controlled atom. Optical switches endow a photonic
quantum state with a synthetic time dimension by modulating photon-atom
couplings. Quantum operations applied to the atomic qubit can be teleported
onto the photonic qubits via projective measurement, and arbitrary quantum
circuits can be compiled into a sequence of these teleported operators. This
design negates the need for many identical quantum emitters to be integrated
into a photonic circuit and allows effective all-to-all connectivity between
photonic qubits. The proposed device has a machine size which is independent of
quantum circuit depth, does not require single-photon detectors, operates
deterministically, and is robust to experimental imperfections.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:59:18 GMT""}]","2021-12-02"
"2101.07793","Carl Rodriguez","Carl L. Rodriguez, Kyle Kremer, Sourav Chatterjee, Giacomo Fragione,
  Abraham Loeb, Frederic A. Rasio, Newlin C. Weatherford, Claire S. Ye","The Observed Rate of Binary Black Hole Mergers can be Entirely Explained
  by Globular Clusters","4 pages, one figure, matches version in RNAAS","Res. Notes AAS 5 19 (2021)","10.3847/2515-5172/abdf54",,"astro-ph.HE gr-qc","http://creativecommons.org/licenses/by/4.0/","  Since the first signal in 2015, the gravitational-wave detections of merging
binary black holes (BBHs) by the LIGO and Virgo collaborations (LVC) have
completely transformed our understanding of the lives and deaths of compact
object binaries, and have motivated an enormous amount of theoretical work on
the astrophysical origin of these objects. We show that the phenomenological
fit to the redshift-dependent merger rate of BBHs from Abbott et al. (2020) is
consistent with a purely dynamical origin for these objects, and that the
current merger rate of BBHs from the LVC could be explained entirely with
globular clusters alone. While this does not prove that globular clusters are
the dominant formation channel, we emphasize that many formation scenarios
could contribute a significant fraction of the current LVC rate, and that any
analysis that assumes a single (or dominant) mechanism for producing BBH
mergers is implicitly using a specious astrophysical prior.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:17:47 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 16:27:49 GMT""}]","2021-01-28"
"2101.07795","Leigh Roberts Dr","Leigh A Roberts","On the derivation of the Khmaladze transforms",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Some 40 years ago Khmaladze introduced a transform which greatly facilitated
the distribution free goodness of fit testing of statistical hypotheses. In the
last decade, he has published a related transform, broadly offering an
alternative means to the same end. The aim of this paper is to derive these
transforms using relatively elementary means, making some simplifications, but
losing little in the way of generality. In this way it is hoped to make these
transforms more accessible and more widely used in statistical practice. We
also propose a change of name of the second transform to the Khmaladze
rotation, in order to better reflect its nature.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:13:24 GMT""}]","2021-01-21"
"2101.07796","Zeraoulia Rafik","Zeraoulia Rafik","A note on an open conjecture in rational dynamical system","I would be interest for any comments to improve the content of this
  research",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  This note is an attempt with the open conjecture $8$ proposed by the authors
of\cite{G. LADAS} which states: Assume $\alpha,\beta, \lambda \in [0,\infty)$.
Then every positive solution of the difference equation : \begin{equation*}
z_{n+1}=\frac{\alpha+z_{n}\beta +z_{n-1}\lambda}{z_{n-2}},\quad n=0,1,\ldots
\end{equation*} is bounded if and only if $\beta=\lambda$. We will use a
construction of sub-energy function and properties of Todd's difference
equation to disprove that conjecture in general.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:50:58 GMT""}]","2021-01-21"
"2101.07797","Mitsuru Kokubo","Mitsuru Kokubo (Princeton University)","Multiple giant eruptions and X-ray emission in the recoiling AGN/LBV
  candidate SDSS1133","Accepted for publication in MNRAS. 30 pages, 17 figures, 5 tables.
  Table 1 and optical spectra are available online as ancillary files for this
  preprint",,"10.1093/mnras/stac1685",,"astro-ph.HE astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive analysis of 20 years worth of multi-color
photometric light curves, multi-epoch optical spectra, and X-ray data of an
off-nuclear variable object SDSS1133 in Mrk 177 at $z=0.0079$. The UV-optical
light curves reveal that SDSS1133 experienced four outbursts in 2001, 2014,
2019, and 2021. The persistent UV-optical luminosity in the non-outbursting
state is $\sim 10^{41}$ erg/s with small-scale flux variations, and peak
luminosities during the outbursts reach $\sim 10^{42}$ erg/s. The optical
spectra exhibit enduring broad hydrogen Balmer P-Cygni profiles with the
absorption minimum at $\sim -2,000$ km/s, indicating the presence of fast
moving ejecta. {\it Chandra} detected weak X-ray emission at a $0.3-10$ keV
luminosity of $L_{X} = 4 \times 10^{38}$ erg/s after the 2019 outburst. These
lines of evidence suggests that SDSS1133 is an extreme luminous blue variable
(LBV) star experiencing multiple giant eruptions with interactions of the
ejected shell with different shells and/or circumstellar medium (CSM), and
disfavors the recoiling Active Galactic Nuclei (AGN) scenario suggested in the
literature. We suggest that pulsational pair-instability may provide a viable
explanation for the multiple energetic eruptions in SDSS1133. If the current
activity of SDSS1133 is a precursor of a supernova explosion, we may be able to
observe a few additional giant eruptions and then the terminal supernova
explosion or collapse to a massive black hole in future observations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jun 2022 20:35:14 GMT""}]","2022-06-20"
"2101.07798","Fumiya Maeda","Fumiya Maeda, Kouji Ohta, Yusuke Fujimoto, Asao Habe","Connection among environment, cloud-cloud collision speed, and star
  formation activity in the strongly barred galaxy NGC1300","13 pages, 9 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab130",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cloud-cloud collision (CCC) has been suggested as a mechanism to induce
massive star formation. Recent simulations suggest that a CCC speed is
different among galactic-scale environments, which is responsible for observed
differences in star formation activity. In particular, a high-speed CCC is
proposed as a cause of star formation suppression in the bar regions in barred
spiral galaxies. Focusing on the strongly barred galaxy NGC1300, we investigate
the CCC speed. We find the CCC speed in the bar and bar-end tend to be higher
than that in the arm. The estimated CCC speed is $\sim20~\rm km~s^{-1}$,
$\sim16~\rm km~s^{-1}$, and $\sim11~\rm km~s^{-1}$ in the bar, bar-end, and
arm, respectively. Although the star formation activity is different in the bar
and bar-end, the CCC speed and the number density of high-speed CCC with $>
20~\rm km~s^{-1}$ are high in both regions, implying the existence of other
parameters that control the star formation. The difference in molecular gas
mass (average density) of the giant molecular clouds (GMCs) between the bar
(lower mass and lower density) and bar-end (higher mass and higher density) may
be cause for the different star formation activity. Combining with our previous
study (Maeda et al.), the leading candidates of causes for the star formation
suppression in the bar in NGC1300 are the presence of a large amount of diffuse
molecular gases and high-speed CCCs between low mass GMCs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:00 GMT""}]","2021-01-21"
"2101.07799","Aisha Bachmann","Aisha Bachmann, Remco F.J. van der Burg, J\'er\'emy Fensch, Gabriel
  Brammer, Adam Muzzin","Low Surface Brightness Galaxies in z > 1 Galaxy Clusters: HST approaches
  the Progenitors of Local Ultra Diffuse Galaxies","Accepted for publication in A&A Letters, in press., 6 pages (+ 3
  pages in Appendices)","A&A 646, L12 (2021)","10.1051/0004-6361/202040097",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Ultra Diffuse Galaxies (UDGs), a type of large Low Surface Brightness (LSB)
galaxies with particularly large effective radii (r_eff > 1.5 kpc), are now
routinely studied in the local (z<0.1) universe. While they are found to be
abundant in clusters, groups, and in the field, their formation mechanisms
remain elusive and an active topic of debate. New insights may be found by
studying their counterparts at higher redshifts (z>1.0), even though
cosmological surface brightness dimming makes them particularly diffcult to
detect and study there. This work uses the deepest Hubble Space Telescope (HST)
imaging stacks of z > 1 clusters, namely: SPT-CL J2106-5844 and MOO J1014+0038.
These two clusters, at z=1.13 and z=1.23, were monitored as part of the HST
See-Change program. Compared to the Hubble Extreme Deep Field (XDF) as
reference field, we find statistical over-densities of large LSB galaxies in
both clusters. Based on stellar population modelling and assuming no size
evolution, we find that the faintest sources we can detect are about as bright
as expected for the progenitors of the brightest local UDGs. We find that the
LSBs we detect in SPT-CL J2106-5844 and MOO J1014-5844 already have old stellar
populations that place them on the red sequence. Correcting for incompleteness,
and based on an extrapolation of local scaling relations, we estimate that
distant UDGs are relatively under-abundant compared to local UDGs by a factor ~
3. A plausible explanation for the implied increase with time would be a
significant size growth of these galaxies in the last ~ 8 Gyr, as also
suggested by hydrodynamical simulations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:01 GMT""}]","2021-02-17"
"2101.07800","Stijn Debackere","Stijn N.B. Debackere, Joop Schaye, Henk Hoekstra","How baryons can significantly bias cluster count cosmology","17 pages, 11 figures. Updated wrong definition of spherical
  overdensity mass m200m, our calculations used the correct definition, as can
  be seen from the publicly-available code at
  https://github.com/StijnDebackere/lensing_haloes/blob/afe4f8699003/lensing_haloes/results.py#L311-L321
  . Mock data, including cosmology MAPs, available at
  https://doi.org/10.5281/zenodo.4469436",,"10.1093/mnras/stab1326",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We quantify two main pathways through which baryonic physics biases cluster
count cosmology. We create mock cluster samples that reproduce the baryon
content inferred from X-ray observations. We link clusters to their
counterparts in a dark matter-only universe, whose abundances can be predicted
robustly, by assuming the dark matter density profile is not significantly
affected by baryons. We derive weak lensing halo masses and infer the
best-fitting cosmological parameters $\Omega_\mathrm{m}$,
$S_8=\sigma_8(\Omega_\mathrm{m}/0.3)^{0.2}$, and $w_0$ from the mock cluster
sample. We find that because of the need to accommodate the change in the
density profile due to the ejection of baryons, weak lensing mass calibrations
are only unbiased if the concentration is left free when fitting the reduced
shear with NFW profiles. However, even unbiased total mass estimates give rise
to biased cosmological parameters if the measured mass functions are compared
with predictions from dark matter-only simulations. This bias dominates for
haloes with $m_\mathrm{500c} < 10^{14.5} \, h^{-1} \, \mathrm{M_\odot}$. For a
stage IV-like cluster survey without mass estimation uncertainties, an area
$\approx 15000 \, \mathrm{deg^2}$ and a constant mass cut of
$m_\mathrm{200m,min} = 10^{14} \, h^{-1} \, \mathrm{M_\odot}$, the biases are
$-11 \pm 1 \, \%$ in $\Omega_\mathrm{m}$, $-3.29 \pm 0.04 \, \%$ in $S_8$, and
$9 \pm 1.5 \, \%$ in $w_0$. The statistical significance of the baryonic bias
depends on how accurately the actual uncertainty on individual cluster mass
estimates is known. We suggest that rather than the total halo mass, the
(re-scaled) dark matter mass inferred from the combination of weak lensing and
observations of the hot gas, should be used for cluster count cosmology.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 14:36:56 GMT""},{""version"":""v3"",""created"":""Thu, 21 Jul 2022 12:07:53 GMT""}]","2022-07-22"
"2101.07801","Charles Law","Charles J. Law, Qizhou Zhang, Karin I. \""Oberg, Roberto
  Galv\'an-Madrid, Eric Keto, Hauyu Baobab Liu, Paul T. P. Ho","Sub-arcsecond Imaging of the Complex Organic Chemistry in Massive
  Star-forming Region G10.6-0.4","41 pages, 25 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abdeb8",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive star-forming regions exhibit an extremely rich and diverse chemistry,
which in principle provides a wealth of molecular probes, as well as
laboratories for interstellar prebiotic chemistry. Since the chemical structure
of these sources displays substantial spatial variation among species on small
scales (${\lesssim}10^4$ au), high angular resolution observations are needed
to connect chemical structures to local environments and inform astrochemical
models of massive star formation. To address this, we present ALMA 1.3 mm
observations toward OB cluster-forming region G10.6-0.4 (hereafter ""G10.6"") at
a resolution of 0.14$^{\prime\prime}$ (700 au). We find highly-structured
emission from complex organic molecules (COMs) throughout the central 20,000
au, including two hot molecular cores and several shells or filaments. We
present spatially-resolved rotational temperature and column density maps for a
large sample of COMs and warm gas tracers. These maps reveal a range of gas
substructure in both O- and N-bearing species. We identify several spatial
correlations that can be explained by existing models of COM formation,
including NH$_2$CHO/HNCO and CH$_3$OCHO/CH$_3$OCH$_3$, but also observe
unexpected distributions and correlations which suggest that our current
understanding of COM formation is far from complete. Importantly, complex
chemistry is observed throughout G10.6, rather than being confined to hot
cores. The COM composition appears to be different in the cores compared to the
more extended structures, which illustrates the importance of high spatial
resolution observations of molecular gas in elucidating the physical and
chemical processes associated with massive star formation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:01 GMT""}]","2021-03-31"
"2101.07802","Yunxiang Liao","Sankar Das Sarma and Yunxiang Liao","Know the enemy: 2D Fermi liquids","Contribution to the Philip W. Anderson Memorial Special Issue of
  Annals of Physics. 31 pages, 8 figures","Annals of Physics 435 (2021) 168495","10.1016/j.aop.2021.168495",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We describe an analytical theory investigating the regime of validity of the
Fermi liquid theory in interacting, via the long-range Coulomb coupling,
two-dimensional Fermi systems comparing it with with the corresponding 3D
systems. We find that the 2D Fermi liquid theory and 2D quasiparticles are
robust up to high energies and temperatures of the order of Fermi energy above
the Fermi surface, very similar to the corresponding three-dimensional
situation. We calculate the phase diagram in the frequency-temperature space
separating the collisionless ballistic regime and the collision-dominated
hydrodynamic regime for 2D and 3D interacting electron systems. We also provide
the temperature corrections up to third order for the renormalized effective
mass, and comment on the validity of 2D Wiedemann-Franz law and 2D
Kadawoki-Woods relation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 17:23:22 GMT""}]","2021-12-13"
"2101.07803","Adrian Carmona","Adrian Carmona, Christiane Scherb and Pedro Schwaller","Charming ALPs","v2: inclusion of constraints from CHARM and SN1987a. 20 pages, 7
  figures, 1 table",,"10.1007/JHEP08(2021)121","MITP-21-003","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Axion-like particles (ALPs) are ubiquitous in models of new physics
explaining some of the most pressing puzzles of the Standard Model. However,
until relatively recently, little attention has been paid to its interplay with
flavour. In this work, we study in detail the phenomenology of ALPs that
exclusively interact with up-type quarks at the tree-level, which arise in some
well-motivated ultra-violet completions such as QCD-like dark sectors or
Froggatt-Nielsen type models of flavour. Our study is performed in the
low-energy effective theory to highlight the key features of these scenarios in
a model independent way. We derive all the existing constraints on these models
and demonstrate how upcoming experiments at fixed-target facilities and the LHC
can probe a vast region of the parameter space, which is currently not excluded
by cosmological and astrophysical bounds. We also emphasize how a future
measurement of the currently unavailable meson decay $D \to \pi +
\rm{invisible}$ could complement these upcoming searches and help to probe a
large unexplored region of their parameter space.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 16:38:36 GMT""}]","2021-09-15"
"2101.07804","Po-Yao Chang","Hsiu-Chuan Hsu, Pok-Man Chiu, Po-Yao Chang","Disorder-induced topology in quench dynamics","10 pages, 8 figures","Phys. Rev. Research 3, 033242 (2021)","10.1103/PhysRevResearch.3.033242",,"cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We study the effect of strong disorder on topology and entanglement in quench
dynamics. Although disorder-induced topological phases have been well studied
in equilibrium, the disorder-induced topology in quench dynamics has not been
explored. In this work, we predict a disorder-induced topology of post-quench
states characterized by the quantized dynamical Chern number and the crossings
in the entanglement spectrum in $(1+1)$ dimensions. The dynamical Chern number
undergoes transitions from zero to unity, and back to zero when increasing the
disorder strength. The boundaries between different dynamical Chern numbers are
determined by delocalized critical points in the post-quench Hamiltonian with
the strong disorder. An experimental realization in quantum walks is discussed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 14:53:17 GMT""},{""version"":""v3"",""created"":""Sun, 30 May 2021 02:51:07 GMT""},{""version"":""v4"",""created"":""Mon, 13 Sep 2021 15:40:02 GMT""}]","2021-09-14"
"2101.07805","Liujun Zou","Liujun Zou, Yin-Chen He, Chong Wang","Stiefel Liquids: Possible Non-Lagrangian Quantum Criticality from
  Intertwined Orders","A summary of results can be found on pages 4-6","Phys. Rev. X 11, 031043 (2021)","10.1103/PhysRevX.11.031043",,"cond-mat.str-el cond-mat.quant-gas hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We propose a new type of quantum liquids, dubbed Stiefel liquids, based on
$2+1$ dimensional nonlinear sigma models on target space $SO(N)/SO(4)$,
supplemented with Wess-Zumino-Witten terms. We argue that the Stiefel liquids
form a class of critical quantum liquids with extraordinary properties, such as
large emergent symmetries, a cascade structure, and nontrivial quantum
anomalies. We show that the well known deconfined quantum critical point and
$U(1)$ Dirac spin liquid are unified as two special examples of Stiefel
liquids, with $N=5$ and $N=6$, respectively. Furthermore, we conjecture that
Stiefel liquids with $N>6$ are non-Lagrangian, in the sense that under
renormalization group they flow to infrared (conformally invariant) fixed
points that cannot be described by any renormalizable continuum Lagrangian.
Such non-Lagrangian states are beyond the paradigm of parton gauge mean-field
theory familiar in the study of exotic quantum liquids in condensed matter
physics. The intrinsic absence of (conventional or parton-like) mean-field
construction also means that, within the traditional approaches, it will be
difficult to decide whether a non-Lagrangian state can actually emerge from a
specific UV system (such as a lattice spin system). For this purpose we
hypothesize that a quantum state is emergible from a lattice system if its
quantum anomalies match with the constraints from the (generalized)
Lieb-Schultz-Mattis theorems. Based on this hypothesis, we find that some of
the non-Lagrangian Stiefel liquids can indeed be realized in frustrated quantum
spin systems, for example, on triangular or Kagome lattice, through the
intertwinement between non-coplanar magnetic orders and valence-bond-solid
orders.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 02:25:30 GMT""},{""version"":""v3"",""created"":""Wed, 25 Aug 2021 14:33:57 GMT""}]","2021-08-26"
"2101.07806","Thomas Richardson","T. R. G. Richardson, J. St\""ucker, R. E. Angulo, O. Hahn","Non-Halo Structures and their Effects on Gravitational Lensing","14 pages, 10 figures. MNRAS submitted. Comments welcome",,"10.1093/mnras/stac493",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Anomalies in the flux-ratios of the images of quadruply-lensed quasars have
been used to constrain the nature of dark matter. Assuming these lensing
perturbations are caused by dark matter haloes, it is currently possible to
constrain the mass of a hypothetical Warm Dark Matter (WDM) particle to be
$m_\chi > 5.2$ keV. However, the assumption that perturbations are only caused
by DM haloes might not be correct as other structures, such as filaments and
pancakes, exist and make up a significant fraction of the mass in the universe,
ranging between 5$\%$ -- 50$\%$ depending on the dark matter model. Using novel
fragmentation-free simulations of 1 and 3keV WDM cosmologies we study these
""non-halo"" structures and estimate their impact on flux-ratio observations. We
find that these structures display sharp density gradients with short
correlation lengths, and can contribute more to the lensing signal than all
haloes up to the half-mode mass combined, thus reducing the differences
expected among WDM models. We estimate that non-halo structures can be the
dominant cause of line-of-sight flux-ratio anomalies in very warm, but already
excluded, $m_x \sim 1 \rm{keV}$ scenarios. For colder cases $m_x \gtrsim 3
\rm{keV}$, we estimate that non-haloes can contribute about $5 - 10\%$ of the
total flux-ratio signal.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:04 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 16:42:19 GMT""}]","2022-03-09"
"2101.07807","Ivan Kukuljan Dr","Ivan Kukuljan","Continuum approach to real time dynamics of 1+1D gauge field theory: out
  of horizon correlations of the Schwinger model","9+7 pages, 7 figures. V2: Additional results added","Phys. Rev. D 104, 021702 (2021)","10.1103/PhysRevD.104.L021702",,"hep-th cond-mat.stat-mech gr-qc quant-ph","http://creativecommons.org/licenses/by/4.0/","  We develop a truncated Hamiltonian method to study nonequilibrium real time
dynamics in the Schwinger model - the quantum electrodynamics in D=1+1. This is
a purely continuum method that captures reliably the invariance under local and
global gauge transformations and does not require a discretisation of
space-time. We use it to study a phenomenon that is expected not to be
tractable using lattice methods: we show that the 1+1D quantum electrodynamics
admits the dynamical horizon violation effect which was recently discovered in
the case of the sine-Gordon model. Following a quench of the model, oscillatory
long-range correlations develop, manifestly violating the horizon bound. We
find that the oscillation frequencies of the out-of-horizon correlations
correspond to twice the masses of the mesons of the model suggesting that the
effect is mediated through correlated meson pairs. We also report on the
cluster violation in the massive version of the model, previously known in the
massless Schwinger model. The results presented here reveal a novel
nonequilibrium phenomenon in 1+1D quantum electrodynamics and make a first step
towards establishing that the horizon violation effect is present in gauge
field theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:07 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 09:41:19 GMT""}]","2021-07-21"
"2101.07808","Paul K. Faehrmann","Paul K. Faehrmann, Mark Steudtner, Richard Kueng, Maria Kieferova,
  Jens Eisert","Randomizing multi-product formulas for Hamiltonian simulation","24 pages, 6 figures","Quantum 6, 806 (2022)","10.22331/q-2022-09-19-806",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum simulation, the simulation of quantum processes on quantum computers,
suggests a path forward for the efficient simulation of problems in
condensed-matter physics, quantum chemistry, and materials science. While the
majority of quantum simulation algorithms are deterministic, a recent surge of
ideas has shown that randomization can greatly benefit algorithmic performance.
In this work, we introduce a scheme for quantum simulation that unites the
advantages of randomized compiling on the one hand and higher-order
multi-product formulas, as they are used for example in
linear-combination-of-unitaries (LCU) algorithms or quantum error mitigation,
on the other hand. In doing so, we propose a framework of randomized sampling
that is expected to be useful for programmable quantum simulators and present
two new multi-product formula algorithms tailored to it. Our framework reduces
the circuit depth by circumventing the need for oblivious amplitude
amplification required by the implementation of multi-product formulas using
standard LCU methods, rendering it especially useful for early quantum
computers used to estimate the dynamics of quantum systems instead of
performing full-fledged quantum phase estimation. Our algorithms achieve a
simulation error that shrinks exponentially with the circuit depth. To
corroborate their functioning, we prove rigorous performance bounds as well as
the concentration of the randomized sampling procedure. We demonstrate the
functioning of the approach for several physically meaningful examples of
Hamiltonians, including fermionic systems and the Sachdev-Ye-Kitaev model, for
which the method provides a favorable scaling in the effort.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:23 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 13:13:16 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 11:36:24 GMT""},{""version"":""v4"",""created"":""Thu, 8 Sep 2022 15:12:12 GMT""},{""version"":""v5"",""created"":""Fri, 30 Sep 2022 10:35:42 GMT""}]","2022-10-03"
"2101.07809","Mary E. Putman","Mary E. Putman (Columbia), Yong Zheng (UC-Berkeley), Adrian M.
  Price-Whelan (CCA), Jana Grcevich (Columbia), Amalya C. Johnson (Columbia),
  Erik Tollerud (STScI), Joshua E.G. Peek (STScI)","The Gas Content and Stripping of Local Group Dwarf Galaxies","26 pages, 7 figures, 3 tables, Accepted by ApJ",,"10.3847/1538-4357/abe391",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The gas content of the complete compilation of Local Group dwarf galaxies
(119 within 2 Mpc) is presented using HI survey data. Within the virial radius
of the Milky Way (224 kpc here), 53 of 55 dwarf galaxies are devoid of gas to
limits of M$_{\rm HI}<10^4$ M$_\odot$. Within the virial radius of M31 (266
kpc), 27 of 30 dwarf galaxies are devoid of gas (with limits typically $<10^5$
M$_\odot$). Beyond the virial radii of the Milky Way and M31, the majority of
the dwarf galaxies have detected HI gas and have HI masses higher than the
limits. When the relationship between gas content and distance is investigated
using a Local Group virial radius, more of the non-detected dwarf galaxies are
within this radius (85$\pm1$ of the 93 non-detected dwarf galaxies) than within
the virial radii of the Milky Way and M31. Using the Gaia proper motion
measurements available for 38 dwarf galaxies, the minimum gas density required
to completely strip them of gas is calculated. Halo densities between $10^{-5}$
and $5 \times 10^{-4}$ cm$^{-3}$ are typically required for instantaneous
stripping at perigalacticon. When compared to halo density with radius
expectations from simulations and observations, 80% of the dwarf galaxies with
proper motions are consistent with being stripped by ram pressure at Milky Way
pericenter. The results suggest a diffuse gaseous galactic halo medium is
important in quenching dwarf galaxies, and that a Local Group medium also
potentially plays a role.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:27 GMT""}]","2021-06-02"
"2101.07810","Ethan Nadler","Ethan O. Nadler, Simon Birrer, Daniel Gilman, Risa H. Wechsler,
  Xiaolong Du, Andrew Benson, Anna M. Nierenberg, Tommaso Treu","Dark Matter Constraints from a Unified Analysis of Strong Gravitational
  Lenses and Milky Way Satellite Galaxies","23 pages, 9 figures, 1 table. Updated to published version","ApJ 917, 7 (2021)","10.3847/1538-4357/abf9a3",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint analyses of small-scale cosmological structure probes are relatively
unexplored and promise to advance measurements of microphysical dark matter
properties using heterogeneous data. Here, we present a multidimensional
analysis of dark matter substructure using strong gravitational lenses and the
Milky Way (MW) satellite galaxy population, accounting for degeneracies in
model predictions and using covariances in the constraining power of these
individual probes for the first time. We simultaneously infer the projected
subhalo number density and the half-mode mass describing the suppression of the
subhalo mass function in thermal relic warm dark matter (WDM),
$M_{\mathrm{hm}}$, using the semianalytic model $\mathrm{\texttt{Galacticus}}$
to connect the subhalo population inferred from MW satellite observations to
the strong lensing host halo mass and redshift regime. Combining MW satellite
and strong lensing posteriors in this parameter space yields
$M_{\mathrm{hm}}<10^{7.0}\ M_{\mathrm{\odot}}$ (WDM particle mass
$m_{\mathrm{WDM}}>9.7\ \mathrm{keV}$) at $95\%$ confidence and disfavors
$M_{\mathrm{hm}}=10^{7.4}\ M_{\mathrm{\odot}}$ ($m_{\mathrm{WDM}}=7.4\
\mathrm{keV}$) with a 20:1 marginal likelihood ratio, improving limits on
$m_{\mathrm{WDM}}$ set by the two methods independently by $\sim 30\%$. These
results are marginalized over the line-of-sight contribution to the strong
lensing signal, the mass of the MW host halo, and the efficiency of subhalo
disruption due to baryons and are robust to differences in the disruption
efficiency between the MW and strong lensing regimes at the $\sim 10\%$ level.
This work paves the way for unified analyses of next-generation small-scale
structure measurements covering a wide range of scales and redshifts.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:27 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 16:43:51 GMT""}]","2021-08-10"
"2101.07811","Andreas Crivellin","Andreas Crivellin, Dario M\""uller and Luc Schnell","Combined Constraints on First Generation Leptoquarks","12 pages, 3 figures, 2 tables, missing factor 2 in non-resonant ATLAS
  bounds corrected","Phys. Rev. D 103, 115023 (2021)","10.1103/PhysRevD.103.115023","CERN-TH-2021-012, PSI-PR-21-01, ZU-TH 01/21","hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  In this article we perform a combined analysis of low energy precision
constraints and LHC searches for leptoquarks which couple to first generation
fermions. Considering all ten leptoquark representations, five scalar and five
vector ones, we study at the precision frontier the constraints from
$K\to\pi\nu\nu$, $K\to\pi e^+e^-$, $K^0-\bar K^0$ and $D^0-\bar D^0$ mixing, as
well as from experiments searching for parity violation (APV and QWEAK). We
include LHC searches for $s$-channel single resonant production, pair
production and Drell-Yan-like signatures of leptoquarks. Interestingly, we find
that the recent non-resonant di-lepton analysis of ATLAS provides stronger
bounds than the resonant searches recasted so far to constrain $t$-channel
production of leptoquarks. Taking into account all these bounds, we observe
that none of the leptoquark representations can address the so-called ""Cabibbo
angle anomaly"" via a direct contribution to super-allowed beta decays.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:28 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 14:34:46 GMT""}]","2021-06-23"
"2101.07812","Encieh Erfani","Encieh Erfani, Hamed Kameli and Shant Baghram","Primordial Black Holes in the Excursion Set Theory","17 pages, 5 figures, 1 table, accepted for publication in MNRAS",,"10.1093/mnras/stab1403",,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study primordial black holes (PBHs) formation in the excursion set theory
(EST) in a vast range of PBHs masses with and without confirmed constraints on
their abundance. In this work, we introduce a new concept of the first touch in
the context of EST for PBHs formation. This new framework takes into account
the earlier horizon reentry of smaller masses. Our study shows that in the EST,
it is possible to produce PBHs in different mass range, with enhanced power
spectrum, which could make up all dark matter. We also show that in a broad
blue-tilted power spectrum, the production of PBHs is dominated by smaller
masses. Our analysis put an upper limit $\sim\,$0.1 on the amplitude of the
curvature power spectrum at length scales relevant for PBHs formation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:28 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 19:53:22 GMT""}]","2021-05-26"
"2101.07813","Gian Giacomo Guerreschi","Gian Giacomo Guerreschi","Solving Quadratic Unconstrained Binary Optimization with
  divide-and-conquer and quantum algorithms",,,,,"quant-ph cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quadratic Unconstrained Binary Optimization (QUBO) is a broad class of
optimization problems with many practical applications. To solve its hard
instances in an exact way, known classical algorithms require exponential time
and several approximate methods have been devised to reduce such cost. With the
growing maturity of quantum computing, quantum algorithms have been proposed to
speed up the solution by using either quantum annealers or universal quantum
computers. Here we apply the divide-and-conquer approach to reduce the original
problem to a collection of smaller problems whose solutions can be assembled to
form a single Polynomial Binary Unconstrained Optimization instance with fewer
variables. This technique can be applied to any QUBO instance and leads to
either an all-classical or a hybrid quantum-classical approach. When quantum
heuristics like the Quantum Approximate Optimization Algorithm (QAOA) are used,
our proposal leads to a double advantage: a substantial reduction of quantum
resources, specifically an average of ~42% fewer qubits to solve MaxCut on
random 3-regular graphs, together with an improvement in the quality of the
approximate solutions reached.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:00:40 GMT""}]","2021-01-21"
"2101.07814","Vittorio Vitale","Vittorio Vitale, Andreas Elben, Richard Kueng, Antoine Neven, Jose
  Carrasco, Barbara Kraus, Peter Zoller, Pasquale Calabrese, Benoit Vermersch,
  Marcello Dalmonte","Symmetry-resolved dynamical purification in synthetic quantum matter","41 pages, 11 figures","SciPost Phys. 12, 106 (2022)","10.21468/SciPostPhys.12.3.106",,"cond-mat.stat-mech cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a quantum system initialized in a product state is subjected to either
coherent or incoherent dynamics, the entropy of any of its connected partitions
generically increases as a function of time, signalling the inevitable
spreading of (quantum) information throughout the system. Here, we show that,
in the presence of continuous symmetries and under ubiquitous experimental
conditions, symmetry-resolved information spreading is inhibited due to the
competition of coherent and incoherent dynamics: in given quantum number
sectors, entropy decreases as a function of time, signalling dynamical
purification. Such dynamical purification bridges between two distinct short
and intermediate time regimes, characterized by a log-volume and log-area
entropy law, respectively. It is generic to symmetric quantum evolution, and as
such occurs for different partition geometry and topology, and classes of
(local) Liouville dynamics. We then develop a protocol to measure
symmetry-resolved entropies and negativities in synthetic quantum systems based
on the random unitary toolbox, and demonstrate the generality of dynamical
purification using experimental data from trapped ion experiments [Brydges et
al., Science 364, 260 (2019)]. Our work shows that symmetry plays a key role as
a magnifying glass to characterize many-body dynamics in open quantum systems,
and, in particular, in noisy-intermediate scale quantum devices.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:01:09 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 11:42:13 GMT""},{""version"":""v3"",""created"":""Fri, 11 Feb 2022 16:55:54 GMT""}]","2022-03-30"
"2101.07815","DinhDuy Vu","Donovan Buterakos, DinhDuy Vu, Jiabin Yu, Sankar Das Sarma","Presence versus absence of Two-Dimensional Fermi Surface Anomalies","11 pages","Phys. Rev. B 103, 205154 (2021)","10.1103/PhysRevB.103.205154",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically consider Fermi surface anomalies manifesting in the
temperature dependent quasiparticle properties of two-dimensional (2D)
interacting electron systems, comparing and contrasting with the corresponding
3D Fermi liquid situation. In particular, employing microscopic many body
perturbative techniques, we obtain analytically the leading-order and the
next-to-leading-order interaction corrections to the renormalized effective
mass for three distinct physical interaction models: electron-phonon,
electron-paramagnon, and electron-electron Coulomb coupling. We find that the
2D renormalized effective mass does not develop any Fermi surface anomaly due
to electron-phonon interaction, manifesting $\mathcal{O}(T^2)$ temperature
correction and thus remaining consistent with the Sommerfeld expansion of the
non-interacting Fermi function, in contrast to the corresponding 3D situation
where the temperature correction to the renormalized effective mass has the
anomalous $T^2 \log T$ behavior. By contrast, both electron-paramagnon and
electron-electron interactions lead to the anomalous $\mathcal{O}(T)$
corrections to the 2D effective mass renormalization in contrast to $T^2 \log
T$ behavior in the corresponding 3D interacting systems. We provide detailed
analytical results, and comment on the conditions under which a $T^2 \log T$
term could possibly arise in the 2D quasiparticle effective mass from
electron-phonon interactions. We also compare results for the temperature
dependent specific heat in the interacting 2D and 3D Fermi systems, using the
close connection between the effective mass and specific heat.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:01:29 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 18:58:46 GMT""}]","2021-06-01"
"2101.07816","Ferhat Ozgur Catak","Umit Cali, Murat Kuzlu, Vinayak Sharma, Manisa Pipattanasomporn,
  Ferhat Ozgur Catak","Internet of Predictable Things (IoPT) Framework to Increase
  Cyber-Physical System Resiliency","13 pages",,,,"eess.SY cs.AI cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the last two decades, distributed energy systems, especially renewable
energy sources (RES), have become more economically viable with increasing
market share and penetration levels on power systems. In addition to
decarbonization and decentralization of energy systems, digitalization has also
become very important. The use of artificial intelligence (AI), advanced
optimization algorithms, Industrial Internet of Things (IIoT), and other
digitalization frameworks makes modern power system assets more intelligent,
while vulnerable to cybersecurity risks. This paper proposes the concept of the
Internet of Predictable Things (IoPT) that incorporates advanced data analytics
and machine learning methods to increase the resiliency of cyber-physical
systems against cybersecurity risks. The proposed concept is demonstrated using
a cyber-physical system testbed under a variety of cyber attack scenarios as a
proof of concept (PoC).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:01:56 GMT""}]","2021-01-21"
"2101.07817","Costantino Pacilio","Swetha Bhagwat, Costantino Pacilio","Merger-Ringdown Consistency: A New Test of Strong Gravity using Deep
  Learning","10 pages, 8 figures; v4: matches published version","Phys. Rev. D 104, 024030 (2021)","10.1103/PhysRevD.104.024030",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The gravitational waves emitted during the coalescence of binary black holes
are an excellent probe to test the behaviour of strong gravity. In this paper,
we propose a new test called the `merger-ringdown consistency test` that
focuses on probing the imprints of the dynamics in strong-gravity around the
black-holes during the plunge-merger and ringdown phase. Furthermore, we
present a scheme that allows us to efficiently combine information across
multiple ringdown observations to perform a statistical null test of GR using
the detected BH population. We present a proof-of-concept study for this test
using simulated binary black hole ringdowns embedded in the next-generation
ground-based detector noise. We demonstrate the feasibility of our test using a
deep learning framework, setting a precedence for performing precision tests of
gravity with neural networks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:02:06 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 17:14:19 GMT""},{""version"":""v3"",""created"":""Wed, 17 Feb 2021 17:21:44 GMT""},{""version"":""v4"",""created"":""Mon, 12 Jul 2021 12:32:41 GMT""}]","2021-07-13"
"2101.07818","Anton Pichler","Anton Pichler, J. Doyne Farmer","Simultaneous supply and demand constraints in input-output networks: The
  case of Covid-19 in Germany, Italy, and Spain","29 pages, 10 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Natural and anthropogenic disasters frequently affect both the supply and
demand side of an economy. A striking recent example is the Covid-19 pandemic
which has created severe disruptions to economic output in most countries.
These direct shocks to supply and demand will propagate downstream and upstream
through production networks. Given the exogenous shocks, we derive a lower
bound on total shock propagation. We find that even in this best case scenario
network effects substantially amplify the initial shocks. To obtain more
realistic model predictions, we study the propagation of shocks bottom-up by
imposing different rationing rules on industries if they are not able to
satisfy incoming demand. Our results show that economic impacts depend strongly
on the emergence of input bottlenecks, making the rationing assumption a key
variable in predicting adverse economic impacts. We further establish that the
magnitude of initial shocks and network density heavily influence model
predictions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:02:51 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 07:17:24 GMT""}]","2021-05-06"
"2101.07819","Michael Ching","Kristine Bauer, Matthew Burke, Michael Ching","Tangent infinity-categories and Goodwillie calculus","This version corrects a significant error in the original submission,
  which we are grateful to Thomas Nikolaus and Maxime Ramzi for pointing out.
  The definition of tangent infinity-category is now based on an
  *infinity*-category of Weil-algebras which has nontrivial higher morphisms.
  Other than that change to the underlying definition, all other results from
  the original version remain valid",,,,"math.CT math.AT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We make precise the analogy between Goodwillie's calculus of functors in
homotopy theory and the differential calculus of smooth manifolds by
introducing a higher-categorical framework of which both theories are examples.
That framework is an extension to infinity-categories of the tangent categories
of Cockett and Cruttwell (introduced originally by Rosick\'y). The basic data
of a tangent infinity-category consist of an endofunctor, that plays the role
of the tangent bundle construction, together with various natural
transformations that mimic structure possessed by the ordinary tangent bundles
of smooth manifolds.
  The role of the tangent bundle functor in Goodwillie calculus is played by
Lurie's tangent bundle for infinity-categories, introduced to generalize the
cotangent complexes of Andr\'e, Quillen and Illusie. We show that Lurie's
construction admits the additional structure maps and satisfies the conditions
needed to form a tangent infinity-category which we refer to as the Goodwillie
tangent structure.
  Cockett and Cruttwell (and others) have started to develop various aspects of
differential geometry in the abstract context of tangent categories, and we
begin to apply those ideas to Goodwillie calculus. For example, we show that
the role of Euclidean spaces in the calculus of manifolds is played in
Goodwillie calculus by the stable infinity-categories. We also show that
Goodwillie's n-excisive functors are the direct analogues of n-jets of smooth
maps between manifolds; to state that connection precisely, we develop a notion
of tangent (infinity,2)-category and show that Goodwillie calculus is best
understood in that context.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:03:02 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 15:21:16 GMT""},{""version"":""v3"",""created"":""Thu, 11 Aug 2022 02:01:46 GMT""},{""version"":""v4"",""created"":""Sat, 25 Feb 2023 22:06:04 GMT""}]","2023-02-28"
"2101.07820","Edward Oughton","Edward J Oughton and Niccol\`o Comini and Vivien Foster and Jim W Hall","Policy choices can help keep 4G and 5G universal broadband affordable",,,,,"econ.GN cs.CY cs.NI q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  The United Nations Broadband Commission has committed the international
community to accelerate universal broadband. However, the cost of meeting this
objective, and the feasibility of doing so on a commercially viable basis, are
not well understood. Using scenario analysis, this paper compares the global
cost-effectiveness of different infrastructure strategies for the developing
world to achieve universal 4G or 5G mobile broadband. Utilizing remote sensing
and demand forecasting, least-cost network designs are developed for eight
representative low and middle-income countries (Malawi, Uganda, Kenya, Senegal,
Pakistan, Albania, Peru and Mexico), the results from which form the basis for
aggregation to the global level. The cost of meeting a minimum 10 Mbps per user
is estimated at USD 1.7 trillion using 5G Non-Standalone, approximately 0.6% of
annual GDP for the developing world over the next decade. However, by creating
a favorable regulatory environment, governments can bring down these costs by
as much as three quarters, to USD 0.5 trillion (approximately 0.2% of annual
GDP), and avoid the need for public subsidy. Providing governments make
judicious choices, adopting fiscal and regulatory regimes conducive to lowering
costs, universal broadband may be within reach of most developing countries
over the next decade.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:04:41 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 15:16:57 GMT""},{""version"":""v3"",""created"":""Sun, 7 Feb 2021 17:23:26 GMT""},{""version"":""v4"",""created"":""Fri, 19 Feb 2021 21:32:50 GMT""}]","2021-02-23"
"2101.07821","Trystyn Berg","Trystyn A.M. Berg, Michele Fumagalli, Valentina D'Odorico, Sara L.
  Ellison, Sebastian Lopez, George D. Becker, Lise Christensen, Guido Cupani,
  Kelly D. Denney, Ruben Sanchez-Ramirez, Gabor Worseck","Sub-damped Lyman alpha systems in the XQ-100 survey II -- Chemical
  evolution at 2.4<z<4.3","Accepted for publication in MNRAS. 64 pages (20 pages of main text,
  44 pages of Figures in appendix). Machine-readable versions of Tables 2 and 3
  are available in the source files or available online on MNRAS",,"10.1093/mnras/stab184",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the measured gas-phase metal column densities in 155 sub-damped
Lyman alpha systems (subDLAs) with the aim to investigate the contribution of
subDLAs to the chemical evolution of the Universe. The sample was identified
within the absorber-blind XQ-100 quasar spectroscopic survey over the redshift
range 2.4<=z<=4.3. Using all available column densities of the ionic species
investigated (mainly CIV, SiII, MgII, SiIV, AlII, FeII, CII, and OI; in order
of decreasing detection frequency), we estimate the ionization-corrected
gas-phase metallicity of each system using Markov Chain Monte Carlo techniques
to explore a large grid of Cloudy ionization models. Without accounting for
ionization and dust depletion effects, we find that the HI-weighted gas-phase
metallicity evolution of subDLAs are consistent with damped Lyman alpha systems
(DLAs). When ionization corrections are included, subDLAs are systematically
more metal-poor than DLAs (between ~0.5 sigma and ~3 sigma significance) by up
to ~1.0 dex over the redshift range 3<=z<=4.3. The correlation of gas-phase
[Si/Fe] with metallicity in subDLAs appears to be consistent with that of DLAs,
suggesting that the two classes of absorbers have a similar relative dust
depletion pattern. As previously seen for Lyman limit systems, the gas-phase
[C/O] in subDLAs remains constantly solar for all metallicities indicating that
both subDLAs and Lyman limit systems could trace carbon-rich ejecta,
potentially in circumgalactic environments.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:09:51 GMT""}]","2021-02-03"
"2101.07822","Amy Sardone","Amy Sardone, D.J. Pisano, N. M. Pingel, Amidou Sorgho, Claude
  Carignan, W.J.G. de Blok","A Census of the Extended Neutral Hydrogen Around 18 MHONGOOSE Galaxies","Accepted, ApJ, Jan. 1, 2021",,"10.3847/1538-4357/abde45",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the analysis of the diffuse, low column density HI environment of
18 MHONGOOSE galaxies. We obtained deep observations with the Robert C. Byrd
Green Bank Telescope, and reached down to a 3sigma column density detection
limit of NHI=6.3x10^{17} cm^{-2} over a 20 km/s linewidth. We analyze the
environment around these galaxies, with a focus on HI gas that reaches column
densities below NHI=10^{19} cm^{-2}. We calculate the total amount of HI gas in
and around the galaxies revealing that nearly all of these galaxies contained
excess HI outside of their disks. We quantify the amount of diffuse gas in the
maps of each galaxy, defined by HI gas with column densities below 10^{19}
cm^{-2}, and find a large spread in percentages of diffuse gas. However, by
binning the percentage of diffuse HI into quarters, we find that the bin with
the largest number of galaxies is the lowest quartile (0-25\% diffuse HI). We
identified several galaxies which may be undergoing gas accretion onto the
galaxy disk using multiple methods of analysis, including azimuthally averaging
column densities beyond the disk, and identifying structure within our
integrated intensity (Moment 0) maps. We measured HI mass outside the disks of
most of our galaxies, with rising cumulative flux even at large radii. We also
find a strong correlation between the fraction of diffuse gas in a galaxy and
its baryonic mass, and test this correlation using both Spearman and Pearson
correlation coefficients. We see evidence of a dark matter halo mass threshold
of M_{halo}~10^{11.1} \msun{} in which galaxies with high fractions of diffuse
HI all reside below. It is in this regime in which cold-mode accretion should
dominate. Finally, we suggest a rotation velocity of v_{rot}~80 km\s as an
upper threshold to find diffuse gas-dominated galaxies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:10:22 GMT""}]","2021-04-07"
"2101.07823","Maria Lourdes Amig\'o","M. L. Amig\'o, Q. Stahl, A. Maljuk, A. U. B. Wolter, C. Hess, J. Geck,
  S. Wurmehl, S. Seiro, B. B\""uchner","The role of the nominal iron content in the structural, compositional
  and physical properties of BaFe$_{2+{\delta}}$S$_3$","11 pages, 8 figures","Phys. Rev. Materials 5, 094801 (2021)","10.1103/PhysRevMaterials.5.094801",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  BaFe$_2$S$_3$ is a quasi-one-dimensional antiferromagnetic insulator that
becomes superconducting under hydrostatic pressure. The magnetic ordering
temperature, $T_N$, as well as the presence of superconductivity have been
found to be sample dependent. It has been argued that the Fe content may play a
decisive role, with the use of 5%mol excess Fe being reportedly required during
the synthesis to optimize the magnetic ordering temperature and the
superconducting properties. However, it is yet unclear whether an Fe
off-stoichiometry is actually present in the samples, and how it affects the
structural, magnetic and transport properties. Here, we present a systematic
study of compositional, structural and physical properties of
BaFe$_{2+\delta}$S$_3$ as a function of the nominal Fe excess $\delta$. As
$\delta$ increases, we observe the presence of an increasing fraction of
secondary phases but no systematic change in the composition or crystal
structure of the main phase. Magnetic susceptibility curves are influenced by
the presence of magnetic secondary phases. The previously reported maximum of
$T_N$ at $\delta$=0.1 was not confirmed. Samples with nominal $\delta$=0
present the lowest $T_N$ and the resistivity anomaly at the highest temperature
$T^*$ while, for $\delta \geq 0.05$, both quantities and the transport gap are
seemingly $\delta$-independent. Finally, we show that crystals free of
ferromagnetic spurious phases can be obtained by remelting samples with nominal
$\delta$=0.05 in a Bridgman process.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:10:33 GMT""}]","2021-09-15"
"2101.07824","Firuz Kamalov","Firuz Kamalov, Aswani Cherukuri, Hana Sulieman, Fadi Thabtah, Akbar
  Hossain","Machine learning applications for COVID-19: A state-of-the-art review",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 pandemic has galvanized the machine learning community to create
new solutions that can help in the fight against the virus. The body of
literature related to applications of machine learning and artificial
intelligence to COVID-19 is constantly growing. The goal of this article is to
present the latest advances in machine learning research applied to COVID-19.
We cover four major areas of research: forecasting, medical diagnostics, drug
development, and contact tracing. We review and analyze the most successful
state of the art studies. In contrast to other existing surveys on the subject,
our article presents a high level overview of the current research that is
sufficiently detailed to provide an informed insight.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:12:45 GMT""}]","2021-01-21"
"2101.07825","Matteo Turchetta","Christopher K\""onig, Matteo Turchetta, John Lygeros, Alisa Rupenyan,
  Andreas Krause","Safe and Efficient Model-free Adaptive Control via Bayesian Optimization",,,,,"eess.SY cs.AI cs.LG cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adaptive control approaches yield high-performance controllers when a precise
system model or suitable parametrizations of the controller are available.
Existing data-driven approaches for adaptive control mostly augment standard
model-based methods with additional information about uncertainties in the
dynamics or about disturbances. In this work, we propose a purely data-driven,
model-free approach for adaptive control. Tuning low-level controllers based
solely on system data raises concerns on the underlying algorithm safety and
computational performance. Thus, our approach builds on GoOSE, an algorithm for
safe and sample-efficient Bayesian optimization. We introduce several
computational and algorithmic modifications in GoOSE that enable its practical
use on a rotational motion system. We numerically demonstrate for several types
of disturbances that our approach is sample efficient, outperforms constrained
Bayesian optimization in terms of safety, and achieves the performance optima
computed by grid evaluation. We further demonstrate the proposed adaptive
control approach experimentally on a rotational motion system.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:15:00 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 13:26:34 GMT""}]","2021-03-03"
"2101.07826","Francisca Concha-Ram\'irez","Francisca Concha-Ram\'irez, Martijn J. C Wilhelm, Simon Portegies
  Zwart","Evolution of circumstellar discs in young star-forming regions","Accepted for publication in MNRAS. 15 pages, 12 figures",,"10.1093/mnras/stac1733",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evolution of circumstellar discs is influenced by their surroundings. The
relevant processes include external photoevaporation due to nearby stars, and
dynamical truncations. The impact of these processes on disc populations
depends on the star-formation history and on the dynamical evolution of the
region. Since star formation history and the phase-space characteristics of the
stars are important for the evolution of the discs, we start simulating the
evolution of the star cluster with the results of molecular cloud collapse
simulations. In the simulation we form stars with circumstellar discs, which
can be affected by different processes. Our models account for the viscous
evolution of the discs, internal and external photoevaporation of gas, external
photoevaporation of dust, and dynamical truncations. All these processes are
resolved together with the dynamical evolution of the cluster, and the
evolution of the stars.
  An extended period of star formation, lasting for at least 2 Myr, results in
some discs being formed late. These late formed discs have a better chance of
survival because the cluster gradually expands with time, and a lower local
stellar density reduces the effects of photoevaporation and dynamical
truncation. Late formed discs can then be present in regions of high UV
radiation, solving the proplyd lifetime problem. We also find a considerable
fraction of discs that lose their gas content, but remain sufficiently rich in
solids to be able to form a rocky planetary system.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:15:15 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 14:47:20 GMT""},{""version"":""v3"",""created"":""Thu, 26 May 2022 09:44:16 GMT""}]","2022-07-20"
"2101.07827","Allison Matthews","A. M. Matthews, J. J. Condon, W. D. Cotton and T. Mauch","Source Counts Spanning Eight Decades of Flux Density at 1.4 GHz","19 pages, 13 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abdd37",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Brightness-weighted differential source counts $S^2 n(S)$ spanning the eight
decades of flux density between $0.25\,\mu\mathrm{Jy}$ and 25 Jy at 1.4 GHz
were measured from (1) the confusion brightness distribution in the MeerKAT
DEEP2 image below $10\,\mu\mathrm{Jy}$, (2) counts of DEEP2 sources between
$10\,\mu\mathrm{Jy}$ and $2.5\,\mathrm{mJy}$, and (3) counts of NVSS sources
stronger than $2.5\,\mathrm{mJy}$. We present our DEEP2 catalog of $1.7 \times
10^4$ discrete sources complete above $S = 10\,\mu\mathrm{Jy}$ over $\Omega =
1.04\,\mathrm{deg}^2$. The brightness-weighted counts converge as $S^2 n(S)
\propto S^{1/2}$ below $S = 10\,\mu\mathrm{Jy}$, so $>99\%$ of the $\Delta
T_\mathrm{b} \sim 0.06\,\mathrm{K}$ sky brightness produced by active galactic
nuclei and $\approx96\%$ of the $\Delta T_\mathrm{b} \sim 0.04\,\mathrm{K}$
added by star-forming galaxies has been resolved into sources with $S \geq
0.25\,\mu\mathrm{Jy}$. The $\Delta T_\mathrm{b} \approx 0.4\,\mathrm{K}$ excess
brightness measured by ARCADE 2 cannot be produced by faint sources smaller
than $\approx 50\,\mathrm{kpc}$ if they cluster like galaxies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:18:20 GMT""}]","2021-03-24"
"2101.07828","Haret Rosu","O. Cornejo-Perez, S.C. Mancas, H.C. Rosu, C.A. Rico-Olvera","Factorization method for some inhomogeneous Lienard equations","4 pages, 0 figures, published version","Rev. Mex. Fis. 67(3) 443-446 (2021)","10.31349/RevMexFis.67.443",,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain closed-form solutions of several inhomogeneous Lienard equations by
the factorization method. The two factorization conditions involved in the
method are turned into a system of first-order differential equations
containing the forcing term. In this way, one can find the forcing terms that
lead to integrable cases. Because of the reduction of order feature of
factorization, the solutions are simultaneously solutions of first-order
differential equations with polynomial nonlinearities. The illustrative
examples of Lienard solutions obtained in this way generically have rational
parts, and consequently display singularities.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:20:21 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 03:17:43 GMT""}]","2021-05-13"
"2101.07829","Souvik Bose","Souvik Bose, Jayant Joshi, Vasco M.J. Henriques and Luc Rouppe van der
  Voort","Spicules and downflows in the solar chromosphere","24 pages, 16 figures. Accepted for publication in Astronomy &
  Astrophysics. Some of the figures have been compressed to comply with arXiv
  requirements","A&A 647, A147 (2021)","10.1051/0004-6361/202040014",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  High-speed downflows have been observed in the solar transition region (TR)
and lower corona for many decades. Despite their abundance, it has been hard to
find signatures of such downflows in the solar chromosphere. In this work, we
target an enhanced network region that shows ample occurrences of rapid
spicular downflows in the \halpha\ spectral line that could potentially be
linked to high-speed TR downflowing counterparts. We used the $k$-means
algorithm to classify the spectral profiles of on-disk spicules in \halpha{}
and \cak{} data observed from the Swedish 1-m Solar Telescope (SST) and
employed an automated detection method based on advanced morphological image
processing operations to detect such downflowing features, in conjunction with
rapid blue-shifted and red-shifted excursions (RBEs and RREs). We report the
existence of a new category of RREs (termed as downflowing RRE) for the first
time that, contrary to earlier interpretation, are associated with
chromospheric field-aligned downflows moving towards the strong magnetic field
regions. Statistical analysis performed on nearly 20,000 RBEs and 15,000 RREs
(including the downflowing counterparts), detected in our 97~min long dataset,
shows that the downflowing RREs are very similar to RBEs and RREs except for
their oppositely directed plane-of-sky motion. Furthermore, we also find that
RBEs, RREs and downflowing RREs can be represented by a wide range of spectral
profiles with varying Doppler offsets, and \halpha{} line core widths, both
along and perpendicular to the spicule axis, that causes them to be associated
with multiple substructures that evolve together. We speculate that these rapid
plasma downflows could well be the chromospheric counterparts of the commonly
observed TR downflows.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:20:41 GMT""}]","2021-03-24"
"2101.07830","Armin Tavakoli","Armin Tavakoli","Semi-device-independent framework based on restricted distrust in
  prepare-and-measure experiments",,"Phys. Rev. Lett. 126, 210503 (2021)","10.1103/PhysRevLett.126.210503",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A semi-device-independent framework for prepare-and-measure experiments is
introduced in which an experimenter can tune the degree of distrust in the
performance of the quantum devices. In this framework, a receiver operates an
uncharacterised measurement device and a sender operates a preparation device
that emits states with a bounded fidelity with respect to a set of target
states. No assumption on Hilbert space dimension is required. The set of
quantum correlations is investigated and bounded from both the interior and the
exterior. Furthermore, the optimal performance of quantum state discrimination
with bounded distrust is derived and applied to certification of detection
efficiency. Quantum-over-classical advantages are demonstrated and the
magnitude of distrust compatible with such advantages is explored. Finally,
efficient schemes for semi-device-independent random number generation are
developed.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:23:16 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 15:08:18 GMT""}]","2021-05-26"
"2101.07831","Flora Dellinger","Flora Dellinger, Thomas Boulay, Diego Mendoza Barrenechea, Said
  El-Hachimi, Isabelle Leang, Fabian B\""urger","Multi-Task Network Pruning and Embedded Optimization for Real-time
  Deployment in ADAS","Accepted at workshop on Machine Learning for Autonomous Driving
  (NeurIPS 2020)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Camera-based Deep Learning algorithms are increasingly needed for perception
in Automated Driving systems. However, constraints from the automotive industry
challenge the deployment of CNNs by imposing embedded systems with limited
computational resources. In this paper, we propose an approach to embed a
multi-task CNN network under such conditions on a commercial prototype
platform, i.e. a low power System on Chip (SoC) processing four surround-view
fisheye cameras at 10 FPS.
  The first focus is on designing an efficient and compact multi-task network
architecture. Secondly, a pruning method is applied to compress the CNN,
helping to reduce the runtime and memory usage by a factor of 2 without
lowering the performances significantly. Finally, several embedded optimization
techniques such as mixed-quantization format usage and efficient data transfers
between different memory areas are proposed to ensure real-time execution and
avoid bandwidth bottlenecks. The approach is evaluated on the hardware
platform, considering embedded detection performances, runtime and memory
bandwidth. Unlike most works from the literature that focus on classification
task, we aim here to study the effect of pruning and quantization on a compact
multi-task network with object detection, semantic segmentation and soiling
detection tasks.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:29:38 GMT""}]","2021-01-22"
"2101.07832","Xingyi Li","Xingyi Li, Wenxuan Wu, Xiaoli Z. Fern, and Li Fuxin","The Devils in the Point Clouds: Studying the Robustness of Point Cloud
  Convolutions",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recently, there has been a significant interest in performing convolution
over irregularly sampled point clouds. Since point clouds are very different
from regular raster images, it is imperative to study the generalization of the
convolution networks more closely, especially their robustness under variations
in scale and rotations of the input data. This paper investigates different
variants of PointConv, a convolution network on point clouds, to examine their
robustness to input scale and rotation changes. Of the variants we explored,
two are novel and generated significant improvements. The first is replacing
the multilayer perceptron based weight function with much simpler third degree
polynomials, together with a Sobolev norm regularization. Secondly, for 3D
datasets, we derive a novel viewpoint-invariant descriptor by utilizing 3D
geometric properties as the input to PointConv, in addition to the regular 3D
coordinates. We have also explored choices of activation functions,
neighborhood, and subsampling methods. Experiments are conducted on the 2D
MNIST & CIFAR-10 datasets as well as the 3D SemanticKITTI & ScanNet datasets.
Results reveal that on 2D, using third degree polynomials greatly improves
PointConv's robustness to scale changes and rotations, even surpassing
traditional 2D CNNs for the MNIST dataset. On 3D datasets, the novel
viewpoint-invariant descriptor significantly improves the performance as well
as robustness of PointConv. We achieve the state-of-the-art semantic
segmentation performance on the SemanticKITTI dataset, as well as comparable
performance with the current highest framework on the ScanNet dataset among
point-based approaches.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:32:38 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 19:31:58 GMT""}]","2021-02-01"
"2101.07833","Melikasadat Emami","Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep
  Rangan, Alyson K. Fletcher","Implicit Bias of Linear RNNs","30 pages, 4 figures",,,,"cs.LG cs.NE cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contemporary wisdom based on empirical studies suggests that standard
recurrent neural networks (RNNs) do not perform well on tasks requiring
long-term memory. However, precise reasoning for this behavior is still
unknown. This paper provides a rigorous explanation of this property in the
special case of linear RNNs. Although this work is limited to linear RNNs, even
these systems have traditionally been difficult to analyze due to their
non-linear parameterization. Using recently-developed kernel regime analysis,
our main result shows that linear RNNs learned from random initializations are
functionally equivalent to a certain weighted 1D-convolutional network.
Importantly, the weightings in the equivalent model cause an implicit bias to
elements with smaller time lags in the convolution and hence, shorter memory.
The degree of this bias depends on the variance of the transition kernel matrix
at initialization and is related to the classic exploding and vanishing
gradients problem. The theory is validated in both synthetic and real data
experiments.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:39:28 GMT""}]","2021-01-21"
"2101.07834","Elias Katsoulis","Elias Katsoulis and Christopher Ramsey","The isomorphism problem for tensor algebras of multivariable dynamical
  systems","accepted version for Forum of Mathematics, Sigma",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We resolve the isomorphism problem for tensor algebras of unital
multivariable dynamical systems. Specifically we show that unitary equivalence
after a conjugation for multivariable dynamical systems is a complete invariant
for complete isometric isomorphisms between their tensor algebras. In
particular, this settles a conjecture of Davidson and Kakariadis relating to
work of Arveson from the sixties, and extends related work of Kakariadis and
Katsoulis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:41:59 GMT""},{""version"":""v2"",""created"":""Fri, 26 Aug 2022 16:35:24 GMT""}]","2022-08-29"
"2101.07835","Biagio Ricceri","Biagio Ricceri","An improvement of a saddle point theorem and some of its applications","arXiv admin note: text overlap with arXiv:1912.05798",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we establish an improved version of a saddle point theorem
([4]) removing a weak lower semicontinuity assumption at all. We then revisit
some of the applications of that theorem in the light of such an improvement.
For instance, we obtain the following very general result of local nature: Let
$(H,\langle\cdot,\cdot\rangle)$ be a real Hilbert space and $\Phi:B_{\rho}\to
H$ a $C^{1,1}$ function, with $\Phi(0)\neq 0$. Then, for each $r>0$ small
enough, there exist only two points points $x^*, u^*\in S_r$, such that
$$\max\{\langle \Phi(x^*),x^*-x\rangle, \langle \Phi(x),x^*-x\rangle\}< 0\ ,$$
for all $x\in B_r\setminus \{x^*\}$, $$\|\Phi(u^*)-u^*\|=dist(\Phi(u^*),B_r)$$
and $$\|\Phi(x)-u^*\|<\|\Phi(x)-x\|$$ for all $x\in B_r\setminus \{u^*\}$,
where $$B_r=\{x\in H : \|x\|\leq r\}$$ and $$S_r=\{x\in H : \|x\|=r\}\ .$$
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:42:17 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 20:56:16 GMT""},{""version"":""v3"",""created"":""Wed, 3 Mar 2021 20:52:30 GMT""},{""version"":""v4"",""created"":""Fri, 5 Nov 2021 08:35:51 GMT""}]","2021-11-08"
"2101.07836","Yoav Zigdon","Ram Brustein, Yoav Zigdon","Effective field theory for closed strings near the Hagedorn temperature","Typos corrected",,"10.1007/JHEP04(2021)107",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss interacting, closed, bosonic and superstrings in thermal
equilibrium at temperatures close to the Hagedorn temperature in flat space. We
calculate S-matrix elements of the strings at the Hagedorn temperature and use
them to construct a low-energy effective action for interacting strings near
the Hagedorn temperature. We show, in particular, that the four-point amplitude
of massless winding modes leads to a positive quartic interaction. Furthermore,
the effective field theory has a generalized conformal structure, namely, it is
conformally invariant when the temperature is assigned an appropriate scaling
dimension. Then, we show that the equations of motion resulting from the
effective action possess a winding-mode-condensate background solution above
the Hagedorn temperature and present a worldsheet conformal field theory,
similar to a Sine-Gordon theory, that corresponds to this solution. We find
that the Hagedorn phase transition in our setup is second order, in contrast to
a first-order transition that was found previously in different setups.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:44:11 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 13:47:09 GMT""}]","2021-04-28"
"2101.07837","Carlo Zanoni","Carlo Zanoni and Daniele Bortoluzzi","Estimation of the electrostatic effects in the LISA-Pathfinder critical
  test mass dynamics via the method of moments",,,"10.1109/TMECH.2021.3050766",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  LISA-Pathfinder is an ESA space mission flown between 2015 and 2017 to
demonstrate a technological maturity sufficient for building a gravitational
waves telescope in space, such as the Laser Interferometer Space Antenna
(LISA). A pair of cubic test masses is hosted inside the LISA-Pathfinder
spacecraft and shielded from any force other than the interplanetary
gravitational field. The purity of the shielding gives the performance of the
mission.
  There are a number of aspects that had to be confirmed in-flight. One of them
is the transition phase from the launch configuration, when the test masses are
locked, to the science free-falling configuration. Each test mass is initially
released from the mechanical constraints via a dedicated mechanism and then
captured by an electrostatic control system. In fact, each test mass is
surrounded by a set of electrodes for actuation and sensing purposes. The
performance criterion of the release is the final velocity of the test mass
relative to the spacecraft, with an upper threshold set to 5 $\mu m/s$. The
LISA-Pathfinder first in-flight release velocities highlighted an unexpected
dynamics with large linear and angular velocities. The electrostatic control
was successful, but only relying on a manual procedure that cannot be
considered as baseline for LISA.
  This paper helps investigating the in-flight non-compliance by dealing with
the modeling of the electrostatic environment around each test mass and its
contribution to the release and capture dynamics. The electrostatic model is
based on the method of moments, a boundary element numerical technique suitable
for estimating forces and capacitances between conductors. We also provide a
short overview of the method, which can be used for the analysis of other
phenomena within LISA and for the design of future gravitational waves
telescopes and space projects.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:58:25 GMT""}]","2021-01-21"
"2101.07838","Avinoam Mann","Avinoam Mann","On abelian subgroups of finite groups",,,,,"math.GR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider abelain subgroups of small index in finite groups. More
generally, we consider subgroups such that the product of their index by the
index of their centralizer is small.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:58:50 GMT""}]","2021-01-21"
"2101.07839","Dezs\H{o} Boda Dr.","D\'avid Fertig and Dezs\H{o} Boda and Istv\'an Szalai","The induced permittivity increment of electrorheological fluids in an
  applied electric field in association with chain formation: A Brownian
  Dynamics simulation study",,"Phys. Rev. E 103, 062608 (2021)","10.1103/PhysRevE.103.062608",,"cond-mat.soft cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We report Brownian Dynamics simulation results for the relative permittivity
of electrorheological (ER) fluids in an applied electric field. The relative
permittivity of an ER fluid can be calculated from the Clausius-Mosotti (CM)
equation in the small applied field limit. When a strong field is applied,
however, the ER spheres are organized into chains and assemblies of chains in
which case the ER spheres are polarized not only by the external field but by
each other. This manifests itself in an enhanced dielectric response, e.g., in
an increase in the relative permittivity. The correction to the relative
permittivity and the time dependence of this correction is simulated on the
basis of a model in which the ER particles are represented as polarizable
spheres. In this model, the spheres are also polarized by each other in
addition to the applied field. Our results are qualitatively similar to those
obtained by Horv\'ath and Szalai experimentally (\textit{Phys. Rev. E},
\textbf{86}, 061403, 2012). We report characteristic time constants obtained
from bi-exponential fits that can be associated with formation of pairs and
short chains as well as with aggregation of chains. The electric field
dependence of the induced dielectric increment reveals the same qualitative
behavior that experiments did: three regions with different slopes
corresponding to different aggregation processes are identified.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:58:50 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 11:36:58 GMT""}]","2021-06-16"
"2101.07840","Salome Schumacher","Lorenz Halbeisen, Riccardo Plati and Salome Schumacher","A New Weak Choice Principle",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For every natural number $n$ we introduce a new weak choice principle
$\mathrm{nRC_{fin}}$: Given any infinite set $x$, there is an infinite subset
$y\subseteq x$ and a selection function $f$ that chooses an $n$-element subset
from every finite $z\subseteq y$ containing at least $n$ elements. By
constructing new permutation models built on a set of atoms obtained as
Fra\""iss\'e limits, we will study the relation of $\mathrm{nRC_{fin}}$ to the
weak choice principles $\mathrm{RC_m}$ (that has already been studied by
Montenegro, Halbeisen and Tachtsis): Given any infinite set $x$, there is an
infinite subset $y\subseteq x$ with a choice function $f$ on the family of all
$m$-element subsets of $y$. Moreover, we prove a stronger analogue of
Montenegros results when we study the relation between $\mathrm{nRC_{fin}}$ and
$\mathrm{kC_{fin}^-}$ which is defined by: Given any infinite family
$\mathcal{F}$ of finite sets of cardinality greater than $k$, there is an
infinite subfamily $\mathcal{A}\subseteq \mathcal{F}$ with a selection function
$f$ that chooses a $k$-element subset from each $A\in\mathcal{A}$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 19:59:43 GMT""}]","2021-01-21"
"2101.07841","Meghan Cowan","Meghan Cowan, Deeksha Dangwal, Armin Alaghi, Caroline Trippel, Vincent
  T. Lee, Brandon Reagen","Porcupine: A Synthesizing Compiler for Vectorized Homomorphic Encryption",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Homomorphic encryption (HE) is a privacy-preserving technique that enables
computation directly on encrypted data. Despite its promise, HE has seen
limited use due to performance overheads and compilation challenges. Recent
work has made significant advances to address the performance overheads but
automatic compilation of efficient HE kernels remains relatively unexplored.
  This paper presents Porcupine, an optimizing compiler, and HE DSL named Quill
to automatically generate HE code using program synthesis. HE poses three major
compilation challenges: it only supports a limited set of SIMD-like operators,
it uses long-vector operands, and decryption can fail if ciphertext noise
growth is not managed properly. Quill captures the underlying HE operator
behavior that enables Porcupine to reason about the complex trade-offs imposed
by the challenges and generate optimized, verified HE kernels. To improve
synthesis time, we propose a series of optimizations including a sketch design
tailored to HE and instruction restriction to narrow the program search space.
We evaluate Procupine using a set of kernels and show speedups of up to 51%
(11% geometric mean) compared to heuristic-driven hand-optimized kernels.
Analysis of Porcupine's synthesized code reveals that optimal solutions are not
always intuitive, underscoring the utility of automated reasoning in this
domain.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:06:33 GMT""}]","2021-01-21"
"2101.07842","W Astar","W. Astar","An Analytical Expression for the Effective Area of the Step-Index
  Single-Mode Optical Fiber","Author has decided to withdraw this paper due to a significant error
  in section 4.3, which is concerned with the derivation of a propagation
  equation for the optical fiber. The error has no effect on the derivation of
  the effective area itself, however, and the derived expressions do indeed
  reduce to those already published by others, within a constant",,,,"physics.optics cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nonlinear coefficient {\gamma} of the step-index single-mode fiber (SMF)
is inversely proportional to the effective area of that fiber. An analytical
expression for the effective area of the hybrid HE11-mode of the SMF is derived
for the first time, using its exact electromagnetic field expressions. The
effective area is found in terms of generalized hypergeometric functions. A
simpler expression is also deduced under the weakly-guided fiber approximation,
and is found to be in agreement with established theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:07:00 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jan 2021 17:14:11 GMT""},{""version"":""v3"",""created"":""Wed, 10 Feb 2021 21:00:48 GMT""},{""version"":""v4"",""created"":""Wed, 3 Mar 2021 21:22:48 GMT""},{""version"":""v5"",""created"":""Fri, 2 Apr 2021 22:19:58 GMT""},{""version"":""v6"",""created"":""Fri, 7 Apr 2023 17:49:57 GMT""}]","2023-04-10"
"2101.07843","Bao-An Li","Bao-An Li","Tasting Nuclear Pasta Made with Classical Molecular Dynamics Simulations","Invited View & Perspective","Frontiers of Physics 16, 24302 (2021)","10.1007/s11467-020-1043-8",,"nucl-th astro-ph.HE nucl-ex","http://creativecommons.org/publicdomain/zero/1.0/","  Nuclear clusters or voids in the inner crust of neutron stars were predicted
to have various shapes collectively nicknamed nuclear pasta. The recent review
in Ref. \cite{Lopez1} by L\'opez, Dorso and Frank summarized their systematic
investigations into properties especially the morphological and thermodynamical
phase transitions of the nuclear pasta within a Classical Molecular Dynamics
model, providing further stimuli to find more observational evidences of the
predicted nuclear pasta in neutron stars.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:07:43 GMT""}]","2021-01-21"
"2101.07844","Timothy Verstraeten","Timothy Verstraeten, Pieter-Jan Daems, Eugenio Bargiacchi, Diederik M.
  Roijers, Pieter J.K. Libin, Jan Helsen","Scalable Optimization for Wind Farm Control using Coordination Graphs",,,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wind farms are a crucial driver toward the generation of ecological and
renewable energy. Due to their rapid increase in capacity, contemporary wind
farms need to adhere to strict constraints on power output to ensure stability
of the electricity grid. Specifically, a wind farm controller is required to
match the farm's power production with a power demand imposed by the grid
operator. This is a non-trivial optimization problem, as complex dependencies
exist between the wind turbines. State-of-the-art wind farm control typically
relies on physics-based heuristics that fail to capture the full load spectrum
that defines a turbine's health status. When this is not taken into account,
the long-term viability of the farm's turbines is put at risk. Given the
complex dependencies that determine a turbine's lifetime, learning a flexible
and optimal control strategy requires a data-driven approach. However, as wind
farms are large-scale multi-agent systems, optimizing control strategies over
the full joint action space is intractable. We propose a new learning method
for wind farm control that leverages the sparse wind farm structure to
factorize the optimization problem. Using a Bayesian approach, based on
multi-agent Thompson sampling, we explore the factored joint action space for
configurations that match the demand, while considering the lifetime of
turbines. We apply our method to a grid-like wind farm layout, and evaluate
configurations using a state-of-the-art wind flow simulator. Our results are
competitive with a physics-based heuristic approach in terms of demand error,
while, contrary to the heuristic, our method prolongs the lifetime of high-risk
turbines.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:12:30 GMT""}]","2021-01-21"
"2101.07845","Chang-An Li","Chang-An Li, Song-Bo Zhang, Jian Li, Bj\""orn Trauzettel","Higher-order Fabry-P\'erot Interferometer from Topological Hinge States","6+7 pages, 3+5 figures","Phys. Rev. Lett. 127, 026803 (2021)","10.1103/PhysRevLett.127.026803",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We propose an intrinsic 3D Fabry-P\'erot type interferometer, coined
""higher-order interferometer"", that utilizes the chiral hinge states of
second-order topological insulators and cannot be equivalently mapped to 2D
space because of higher-order topology. Quantum interference patterns in the
two-terminal conductance of this interferometer are controllable not only by
tuning the strength but also, particularly, by rotating the direction of the
magnetic field applied perpendicularly to the transport direction. Remarkably,
the conductance exhibits a characteristic beating pattern with multiple
frequencies with respect to field strength or direction. Our novel
interferometer provides feasible and robust magneto-transport signatures to
probe the particular hinge states of higher-order topological insulators.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:13:19 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 19:09:56 GMT""}]","2021-07-14"
"2101.07846","David C. Seal","Jochen Sch\""utz and David C. Seal and Jonas Zeifang","Parallel-in-time high-order multiderivative IMEX solvers","36 pages",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this work, we present a novel class of parallelizable high-order time
integration schemes for the approximate solution of additive ODEs. The methods
achieve high order through a combination of a suitable quadrature formula
involving multiple derivatives of the ODE's right-hand side and a
predictor-corrector ansatz. The latter approach is designed in such a way that
parallelism in time is made possible. We present thorough analysis as well as
numerical results that showcase scaling opportunities of methods from this
class of solvers.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:13:30 GMT""}]","2021-01-21"
"2101.07847","Bernd Finkbeiner","Borzoo Bonakdarpour and Bernd Finkbeiner","The Complexity of Monitoring Hyperproperties",,,"10.1109/CSF.2018.00019",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the runtime verification of hyperproperties, expressed in the
temporal logic HyperLTL, as a means to inspect a system with respect to
security polices. Runtime monitors for hyperproperties analyze trace logs that
are organized by common prefixes in the form of a tree-shaped Kripke structure,
or are organized both by common prefixes and by common suffixes in the form of
an acyclic Kripke structure. Unlike runtime verification techniques for trace
properties, where the monitor tracks the state of the specification but usually
does not need to store traces, a monitor for hyperproperties repeatedly model
checks the growing Kripke structure. This calls for a rigorous complexity
analysis of the model checking problem over tree-shaped and acyclic Kripke
structures. We show that for trees, the complexity in the size of the Kripke
structure is L-complete independently of the number of quantifier alternations
in the HyperLTL formula. For acyclic Kripke structures, the complexity is
PSPACE-complete (in the level of the polynomial hierarchy that corresponds to
the number of quantifier alternations). The combined complexity in the size of
the Kripke structure and the length of the HyperLTL formula is PSPACE-complete
for both trees and acyclic Kripke structures, and is as low as NC for the
relevant case of trees and alternation-free HyperLTL formulas. Thus, the size
and shape of both the Kripke structure and the formula have significant impact
on the complexity of the model checking problem.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:14:00 GMT""}]","2021-01-21"
"2101.07848","Farzam Hejazi Kookamari","Farzam Hejazi, Katarina Vuckovic, Nazanin Rahnavard","DyLoc: Dynamic Localization for Massive MIMO Using Predictive Recurrent
  Neural Networks","Source Code: https://github.com/FarzamHejaziK/DyLoc",,,,"cs.CV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a data-driven localization framework with high precision
in time-varying complex multipath environments, such as dense urban areas and
indoors, where GPS and model-based localization techniques come short. We
consider the angle-delay profile (ADP), a linear transformation of channel
state information (CSI), in massive MIMO systems and show that ADPs preserve
users' motion when stacked temporally. We discuss that given a static
environment, future frames of ADP time-series are predictable employing a video
frame prediction algorithm. We express that a deep convolutional neural network
(DCNN) can be employed to learn the background static scattering environment.
To detect foreground changes in the environment, corresponding to path blockage
or addition, we introduce an algorithm taking advantage of the trained DCNN.
Furthermore, we present DyLoc, a data-driven framework to recover distorted
ADPs due to foreground changes and to obtain precise location estimations. We
evaluate the performance of DyLoc in several dynamic scenarios employing
DeepMIMO dataset to generate geo-tagged CSI datasets for indoor and outdoor
environments. We show that previous DCNN-based techniques fail to perform with
desirable accuracy in dynamic environments, while DyLoc pursues localization
precisely. Moreover, simulations show that as the environment gets richer in
terms of the number of multipath, DyLoc gets more robust to foreground changes.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:15:34 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 15:47:51 GMT""}]","2021-01-25"
"2101.07849","Christof Wetterich","Christof Wetterich","Pregeometry and euclidean quantum gravity","Additional material on mode expansion., 24 pages",,"10.1016/j.nuclphysb.2021.115526",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Einstein's general relativity can emerge from pregeometry, with the metric
composed of more fundamental fields. We formulate euclidean pregeometry as a
$SO(4)$ - Yang-Mills theory. In addition to the gauge fields we include a
vector field in the vector representation of the gauge group. The gauge - and
diffeomorphism - invariant kinetic terms for these fields permit a well-defined
euclidean functional integral, in contrast to metric gravity with the
Einstein-Hilbert action. The propagators of all fields are well behaved at
short distances, without tachyonic or ghost modes. The long distance behavior
is governed by the composite metric and corresponds to general relativity. In
particular, the graviton propagator is free of ghost or tachyonic poles despite
the presence of higher order terms in a momentum expansion of the inverse
propagator. This pregeometry seems to be a valid candidate for euclidean
quantum gravity, without obstructions for analytic continuation to a Minkowski
signature of the metric.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:19:37 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 11:40:21 GMT""},{""version"":""v3"",""created"":""Sun, 19 Sep 2021 17:38:55 GMT""}]","2021-09-21"
"2101.07850","Kazem Azizi","K. Azizi, Y. Sarac, H. Sundu","Investigation of $P_{cs}(4459)^0$ pentaquark via its strong decay to
  $\Lambda J/\Psi$","10 Pages, 2 Figures and 2 Tables","Phys. Rev. D 103, 094033 (2021)","10.1103/PhysRevD.103.094033",,"hep-ph hep-ex hep-lat","http://creativecommons.org/licenses/by/4.0/","  Recently the observation of a new pentaquark state, the hidden-charmed
strange $P_{cs}(4459)^0$, was reported by the LHCb Collaboration. The
spin-parity quantum numbers of this state were not determined as a result of
insufficient statistics. To shed light on its quantum numbers, we investigate
its decay, $P_{cs}(4459)^0 \rightarrow J/\psi \Lambda $, the mode that this
state has been observed, within the QCD sum rule framework. We obtain the width
of this decay assigning the spin-parity quantum numbers of $P_{cs}(4459)^0$
state as $J^P=\frac{1}{2}^-$ and its substructure as diquark-diquark-antiquark.
To this end, we first calculate the strong coupling constants defining the
considered decay and then use them in the width calculations. The obtained
width is consistent with the experimental observation, confirming the quantum
numbers $J^P=\frac{1}{2}^-$ and compact pentaquark nature for $P_{cs}(4459)^0$
state.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:27:02 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 19:32:26 GMT""},{""version"":""v3"",""created"":""Wed, 21 Apr 2021 07:07:26 GMT""}]","2021-06-02"
"2101.07851","Aidan Arnold","Oliver S. Burrow, Paul F. Osborn, Edward Boughton, Francesco Mirando,
  David P. Burt, Paul F. Griffin, Aidan S. Arnold, and Erling Riis","Stand-alone vacuum cell for compact ultracold quantum technologies","6 pages, 2 figures, to appear in Applied Physics Letters","Appl. Phys. Lett. 119, 124002 (2021)","10.1063/5.0061010",,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact vacuum systems are key enabling components for cold atom
technologies, facilitating extremely accurate sensing applications. There has
been important progress towards a truly portable compact vacuum system, however
size, weight and power consumption can be prohibitively large, optical access
may be limited, and active pumping is often required. Here, we present a
centilitre-scale ceramic vacuum chamber with He-impermeable viewports and an
integrated diffractive optic, enabling robust laser cooling with light from a
single polarization-maintaining fibre. A cold atom demonstrator based on the
vacuum cell delivers $10^7$ laser-cooled $^{87}$Rb atoms per second, using
minimal electrical power. With continuous Rb gas emission active pumping yields
a $10^{-7}\,$mbar equilibrium pressure, and passive pumping stabilises to
$3\times 10^{-6}\,$mbar, with a $17\,$day time constant. A vacuum cell, with no
Rb dispensing and only passive pumping, has currently kept a similar pressure
for more than \ch{500 days}. The passive-pumping vacuum lifetime is several
years, estimated from short-term He throughput, with many foreseeable
improvements. This technology enables wide-ranging mobilization of ultracold
quantum metrology.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:29:44 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 16:49:15 GMT""}]","2021-09-21"
"2101.07852","Mikhail Mekhedkin Meskhi","Mikhail M. Meskhi, Adriano Rivolli, Rafael G. Mantovani, Ricardo
  Vilalta","Learning Abstract Task Representations",,"AAAI Workshop on Meta-Learning 2021",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  A proper form of data characterization can guide the process of
learning-algorithm selection and model-performance estimation. The field of
meta-learning has provided a rich body of work describing effective forms of
data characterization using different families of meta-features (statistical,
model-based, information-theoretic, topological, etc.). In this paper, we start
with the abundant set of existing meta-features and propose a method to induce
new abstract meta-features as latent variables in a deep neural network. We
discuss the pitfalls of using traditional meta-features directly and argue for
the importance of learning high-level task properties. We demonstrate our
methodology using a deep neural network as a feature extractor. We demonstrate
that 1) induced meta-models mapping abstract meta-features to generalization
performance outperform other methods by ~18% on average, and 2) abstract
meta-features attain high feature-relevance scores.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:31:02 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 17:43:34 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 20:07:20 GMT""}]","2021-02-01"
"2101.07853","Kelly Mack","Kelly Mack, Megan Hofmann, Udaya Lakshmi, Jerry Cao, Nayha Auradkar,
  Rosa I. Arriaga, Scott E. Hudson, Jennifer Mankoff","Rapid Convergence: The Outcomes of Making PPE during a Healthcare Crisis",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  The NIH 3D Print Exchange is a public and open source repository for
primarily 3D printable medical device designs with contributions from
expert-amateur makers, engineers from industry and academia, and clinicians. In
response to the COVID-19 pandemic, a collection was formed to foster
submissions of low-cost, local manufacture of personal protective equipment
(Personal Protective Equipment (PPE)). We systematically evaluated the 623
submissions in this collection to understand: what makers contributed, how they
were made, who made them, and key characteristics of their designs. Our
analysis reveals an immediate design convergence to derivatives of a few
initial designs affiliated with NIH partners (e.g., universities, the Veteran's
Health Administration, America Makes) and major for-profit groups (e.g.,
Prusa). The NIH worked to review safe and effective designs but was quickly
overloaded by derivative works. We found that the vast majority were never
reviewed (81.3%) while 10.4% of those reviewed were deemed safe for clinical
(5.6%) or community use (4.8%). Our work contributes insights into: the
outcomes of distributed, community-based, medical making; features the
community accepted as ""safe"" making; and how platforms can support regulated
maker activities in high-risk domains (e.g., healthcare).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:37:53 GMT""}]","2021-01-21"
"2101.07854","Kantaro Ohmori","Kantaro Ohmori","Replica Instantons from Axion-like Coupling","4+1 pages, 5 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find a phenomenon in a non-gravitational gauge theory analogous to the
replica wormhole in a quantum gravity theory. We consider a reservoir of a
scalar field coupled with a gauge theory contained in a region with a boundary
by an axion-like coupling. When the replica trick is used to compute the
entanglement entropy for a subregion in the reservoir, a tuple of instantons
distributed across the replica sheets gives a non-perturbative contribution. As
an explicit and solvable example, we consider a discrete scalar field coupled
to a 2d pure gauge theory and observe how the replica instantons reproduce the
entropy directly calculated from the reduced density matrix. In addition, we
notice that the entanglement entropy can detect the confinement of a 2d gauge
theory.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:39:09 GMT""}]","2021-01-21"
"2101.07855","Furkan Gursoy","Mahsun Alt{\i}n, Furkan G\""ursoy, Lina Xu","Machine-Generated Hierarchical Structure of Human Activities to Reveal
  How Machines Think",,"IEEE Access, vol. 9, pp. 18307-18317, 2021","10.1109/ACCESS.2021.3053084",,"cs.CV cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep-learning based computer vision models have proved themselves to be
ground-breaking approaches to human activity recognition (HAR). However, most
existing works are dedicated to improve the prediction accuracy through either
creating new model architectures, increasing model complexity, or refining
model parameters by training on larger datasets. Here, we propose an
alternative idea, differing from existing work, to increase model accuracy and
also to shape model predictions to align with human understandings through
automatically creating higher-level summarizing labels for similar groups of
human activities. First, we argue the importance and feasibility of
constructing a hierarchical labeling system for human activity recognition.
Then, we utilize the predictions of a black box HAR model to identify
similarities between different activities. Finally, we tailor hierarchical
clustering methods to automatically generate hierarchical trees of activities
and conduct experiments. In this system, the activity labels on the same level
will have a designed magnitude of accuracy and reflect a specific amount of
activity details. This strategy enables a trade-off between the extent of the
details in the recognized activity and the user privacy by masking some
sensitive predictions; and also provides possibilities for the use of formerly
prohibited invasive models in privacy-concerned scenarios. Since the hierarchy
is generated from the machine's perspective, the predictions at the upper
levels provide better accuracy, which is especially useful when there are too
detailed labels in the training set that are rather trivial to the final
prediction goal. Moreover, the analysis of the structure of these trees can
reveal the biases in the prediction model and guide future data collection
strategies.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:40:22 GMT""}]","2021-02-04"
"2101.07856","Daniel Paulusma","Barnaby Martin and Daniel Paulusma and Siani Smith","Colouring Graphs of Bounded Diameter in the Absence of Small Cycles",,,,,"math.CO cs.CC cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $k\geq 1$, a $k$-colouring $c$ of $G$ is a mapping from $V(G)$ to
$\{1,2,\ldots,k\}$ such that $c(u)\neq c(v)$ for any two non-adjacent vertices
$u$ and $v$. The $k$-Colouring problem is to decide if a graph $G$ has a
$k$-colouring. For a family of graphs ${\cal H}$, a graph $G$ is ${\cal
H}$-free if $G$ does not contain any graph from ${\cal H}$ as an induced
subgraph. Let $C_s$ be the $s$-vertex cycle. In previous work (MFCS 2019) we
examined the effect of bounding the diameter on the complexity of $3$-Colouring
for $(C_3,\ldots,C_s)$-free graphs and $H$-free graphs where $H$ is some
polyad. Here, we prove for certain small values of $s$ that $3$-Colouring is
polynomial-time solvable for $C_s$-free graphs of diameter $2$ and
$(C_4,C_s)$-free graphs of diameter $2$. In fact, our results hold for the more
general problem List $3$-Colouring. We complement these results with some
hardness result for diameter $4$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:42:11 GMT""}]","2021-01-21"
"2101.07857","Peter M. Frinchaboy","Benjamin Thompson, Peter M. Frinchaboy, Taylor Spoo, John Donor","The Binary INformation from Open Clusters Using SEDs (BINOCS) Project:
  Reliable Photometric Mass Determinations of Binary Star Systems in Clusters","22 pages, 21 figures, AJ accepted",,"10.3847/1538-3881/abde4c",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We introduce a new binary detection technique, Binary INformation from Open
Clusters using SEDs (binocs), which we show is able to determine reliable
stellar multiplicity and masses over a much larger mass range than current
approaches. This new technique determines accurate component masses of binary
and single systems of the open clusters main sequence by comparing observed
magnitudes from multiple photometric filters to synthetic star spectral energy
distributions (SEDs) allowing systematically probing the binary population for
low mass stars in clusters for 8 well-studied open clusters. We provide new
deep, infrared photometric catalogs (1.2 - 8.0 microns) for the key open
clusters NGC 1960 (M36), NGC 2099 (M37), NGC 2420, and NGC2682 (M67), using
observation from NOAO/NEWFIRM and Spitzer}/IRAC. Using these deep
multi-wavelength catalogs, the binocs method is applied to these clusters to
determine accurate component masses for unresolved cluster binaries. We explore
binary fractions as a function of cluster age, Galactic location and
metallicity.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:48:27 GMT""}]","2021-03-10"
"2101.07858","Axel Schild","Jakub Koc\'ak, Eli Kraisler, Axel Schild","Charge-transfer steps in Density Functional Theory from the perspective
  of the Exact Electron Factorization",,,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a molecule dissociates, the exact Kohn-Sham (KS) and Pauli potentials
may form step structures. Reproducing these steps correctly is central for the
description of dissociation and charge-transfer processes in density functional
theory (DFT): The steps align the KS eigenvalues of the dissociating subsystems
relative to each other and determine where electrons localize. While the step
height can be calculated from the asymptotic behavior of the KS orbitals, this
provides limited insight into what causes the steps. We give an explanation of
the steps with an exact mapping of the many-electron problem to a one-electron
problem, the exact electron factorizaton (EEF). The potentials appearing in the
EEF have a clear physical meaning that translates to the DFT potentials by
replacing the interacting many-electron system with the KS system. With a
simple model of a diatomic, we illustrate that the steps are a consequence of
spatial electron entanglement and are the result of a charge transfer. From
this mechanism, the step height can immediately be deduced. Moreover, two
methods to approximately reproduce the potentials during dissociation suggest
themselves. One is based on the states of the dissociated system, while the
other one is based on an analogy to the Born-Oppenheimer treatment of a
molecule. The latter method also shows that the steps connect adiabatic
potential energy surfaces. The view of DFT from the EEF thus provides a better
understanding of how many-electron effects are encoded in a one-electron theory
and how they can be modeled.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:49:58 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 14:40:15 GMT""}]","2021-03-23"
"2101.07859","Christian  Valqui","Juan Guti\'errez and Christian Valqui","Bi-traceable graphs, the intersection of three longest paths and
  Hippchen's conjecture",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $P,Q$ be longest paths in a simple graph. We analyze the possible
connections between the components of $P\cup Q\setminus (V(P)\cap V(Q))$ and
introduce the notion of a bi-traceable graph. We use the results for all the
possible configurations of the intersection points when $\#V(P)\cap V(Q)\le 5$
in order to prove that if the intersection of three longest paths $P,Q,R$ is
empty, then $\#(V(P)\cap V(Q))\ge 6$. We also prove Hippchen's conjecture for
$k\le 6$: If a graph $G$ is $k$-connected for $k\le 6$, and $P$ and $Q$ are
longest paths in $G$, then $\#(V(P)\cap V(Q))\ge 6$.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:51:56 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 15:59:22 GMT""},{""version"":""v3"",""created"":""Sun, 21 Mar 2021 01:36:37 GMT""},{""version"":""v4"",""created"":""Tue, 25 May 2021 01:17:49 GMT""}]","2021-05-26"
"2101.07860","Kristin Kirchner","David Bolin and Kristin Kirchner","Equivalence of measures and asymptotically optimal linear prediction for
  Gaussian random fields with fractional-order covariance operators","47 pages, 3 figures",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Gaussian measures $\mu, \tilde{\mu}$ on a separable Hilbert
space, with fractional-order covariance operators $A^{-2\beta}$ resp.
$\tilde{A}^{-2\tilde{\beta}}$, and derive necessary and sufficient conditions
on $A, \tilde{A}$ and $\beta, \tilde{\beta} > 0$ for I. equivalence of the
measures $\mu$ and $\tilde{\mu}$, and II. uniform asymptotic optimality of
linear predictions for $\mu$ based on the misspecified measure $\tilde{\mu}$.
These results hold, e.g., for Gaussian processes on compact metric spaces. As
an important special case, we consider the class of generalized
Whittle-Mat\'ern Gaussian random fields, where $A$ and $\tilde{A}$ are elliptic
second-order differential operators, formulated on a bounded Euclidean domain
$\mathcal{D}\subset\mathbb{R}^d$ and augmented with homogeneous Dirichlet
boundary conditions. Our outcomes explain why the predictive performances of
stationary and non-stationary models in spatial statistics often are
comparable, and provide a crucial first step in deriving consistency results
for parameter estimation of generalized Whittle-Mat\'ern fields.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:53:22 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 09:42:13 GMT""}]","2022-02-18"
"2101.07861","Radoslaw Pytlak","Radoslaw Pytlak, Damian Suski","Numerical procedure for optimal control of hybrid systems with sliding
  modes, Part II",,,,,"math.OC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  This paper concerns the numerical procedure for solving hybrid optimal
control problems with sliding modes. A sliding mode is coped with
differential-algebraic equations (DAEs) and that guarantees accurate tracking
of the sliding motion surface. In the second part of the paper we demonstrate
the correspondence between the discrete adjoint equations and the discretized
version of the continuous adjoint equations in the case of system equations
described by DAEs. We show that the discrete adjoint state trajectories
converge to their continuous counterparts. Next, we describe the application of
the proposed procedure to three optimal control problems. The first problem
concerns optimal control of a simple mechanical system with dry friction. The
second problem is related to the planning of a haemodialysis process. The third
problem concerns the optimal steering of a racing car.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:54:08 GMT""}]","2021-01-21"
"2101.07862","Jos\'e Manuel Rodr\'iguez-Seijo","J. M. Rodr\'iguez, R. Taboada-V\'azquez","Asymptotic analysis of a thin fluid layer flow between two moving
  surfaces",,,"10.1016/j.jmaa.2021.125735",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the behavior of an incompressible viscous fluid moving
between two very close surfaces also in motion. Using the asymptotic expansion
method we formally justify two models, a lubrication model and a shallow water
model, depending on the boundary conditions imposed. Finally, we discuss under
what conditions each of the models would be applicable.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:56:32 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jan 2021 20:51:51 GMT""},{""version"":""v3"",""created"":""Fri, 23 Apr 2021 18:43:30 GMT""},{""version"":""v4"",""created"":""Tue, 8 Mar 2022 18:01:14 GMT""}]","2022-03-09"
"2101.07863","Ivana G\'omez","Hugo Aimar, Ivana G\'omez","Boundedness and concentration of random singular integrals defined by
  wavelet summability kernels","16 pages",,,,"math.FA math.PR","http://creativecommons.org/licenses/by/4.0/","  We use Cram\'er-Chernoff type estimates in order to study the
Calder\'on-Zygmund structure of the kernels
$\sum_{I\in\mathcal{D}}a_I(\omega)\psi_I(x)\psi_I(y)$ where $a_I$ are
subgaussian independent random variables and $\{\psi_I: I\in\mathcal{D}\}$ is a
wavelet basis where $\mathcal{D}$ are the dyadic intervals in $\mathbb{R}$. We
consider both, the cases of standard smooth wavelets and the case of the Haar
wavelet.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:59:30 GMT""}]","2021-01-21"
"2101.07864","Chaeun Lee","Chaeun Lee, Seyoung Kim","SEMULATOR: Emulating the Dynamics of Crossbar Array-based Analog Neural
  System with Regression Neural Networks","10 pages, 7 figures, preprint",,,,"cs.LG cs.ET cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As deep neural networks require tremendous amount of computation and memory,
analog computing with emerging memory devices is a promising alternative to
digital computing for edge devices. However, because of the increasing
simulation time for analog computing system, it has not been explored. To
overcome this issue, analytically approximated simulators are developed, but
these models are inaccurate and narrow down the options for peripheral circuits
for multiply-accumulate operation (MAC). In this sense, we propose a
methodology, SEMULATOR (SiMULATOR by Emulating the analog computing block)
which uses a deep neural network to emulate the behavior of crossbar-based
analog computing system. With the proposed neural architecture, we
experimentally and theoretically shows that it emulates a MAC unit for neural
computation. In addition, the simulation time is incomparably reduced when it
compared to the circuit simulators such as SPICE.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:08:33 GMT""}]","2021-01-21"
"2101.07865","Jean-Baptiste Jeannin","Hossein Rastgoftar and Jean-Baptiste Jeannin","A Physics-Based Finite-State Abstraction for Traffic Congestion Control","7 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1912.00565",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper offers a finite-state abstraction of traffic coordination and
congestion in a network of interconnected roads (NOIR). By applying mass
conservation, we model traffic coordination as a Markov process. Model
Predictive Control (MPC) is applied to control traffic congestion through the
boundary of the traffic network. The optimal boundary inflow is assigned as the
solution of a constrained quadratic programming problem. Additionally, the
movement phases commanded by traffic signals are determined using receding
horizon optimization. In simulation, we show how traffic congestion can be
successfully controlled through optimizing boundary inflow and movement phases
at traffic network junctions.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:08:55 GMT""}]","2021-01-21"
"2101.07866","Weihan Zhang","Weihan Zhang, Bryan Pogorelsky, Mark Loveland, Trevor Wolf","Classification of COVID-19 X-ray Images Using a Combination of Deep and
  Handcrafted Features","5 pages, 5 figures",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Coronavirus Disease 2019 (COVID-19) demonstrated the need for accurate and
fast diagnosis methods for emergent viral diseases. Soon after the emergence of
COVID-19, medical practitioners used X-ray and computed tomography (CT) images
of patients' lungs to detect COVID-19. Machine learning methods are capable of
improving the identification accuracy of COVID-19 in X-ray and CT images,
delivering near real-time results, while alleviating the burden on medical
practitioners. In this work, we demonstrate the efficacy of a support vector
machine (SVM) classifier, trained with a combination of deep convolutional and
handcrafted features extracted from X-ray chest scans. We use this combination
of features to discriminate between healthy, common pneumonia, and COVID-19
patients. The performance of the combined feature approach is compared with a
standard convolutional neural network (CNN) and the SVM trained with
handcrafted features. We find that combining the features in our novel
framework improves the performance of the classification task compared to the
independent application of convolutional and handcrafted features.
Specifically, we achieve an accuracy of 0.988 in the classification task with
our combined approach compared to 0.963 and 0.983 accuracy for the handcrafted
features with SVM and CNN respectively.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:09:46 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 17:21:01 GMT""}]","2021-01-22"
"2101.07867","Ivana G\'omez","Hugo Aimar and Ivana G\'omez","Approximating the identity of convolution with random mean and random
  variance","12 pages",,,,"math.PR math.CA","http://creativecommons.org/licenses/by/4.0/","  We provide sufficient conditions on the profile $\varphi$, on the sequence of
random variables $\varepsilon_j>0$ and on the sequence of random vectors
$y_j\in\mathbb{R}^n$ such that
$\mathscr{E}\left(\frac{1}{\varepsilon_j^n(\omega)}\int_{z\in\mathbb{R}^n}\varphi\left(\frac{|x-z-y_j(\omega)|}{\varepsilon_j(\omega)}\right)f(z)
dz\right)\longrightarrow f(x)$ when $j\to\infty$ for almost every
$x\in\mathbb{R}^n$, $f\in L^p(\mathbb{R}^n)$, $1\leq p\leq\infty$, where
$\mathscr{E}$ denotes the expectation, $\varepsilon_j$ tends to
$0\in\mathbb{R}$ in law and $y_j$ tends to $\mathbf{0}\in\mathbb{R}^n$ in law.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:27:56 GMT""}]","2021-01-21"
"2101.07868","Jacob Schrum","Kirby Steckel and Jacob Schrum","Illuminating the Space of Beatable Lode Runner Levels Produced By
  Various Generative Adversarial Networks",,,,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) are capable of generating convincing
imitations of elements from a training set, but the distribution of elements in
the training set affects to difficulty of properly training the GAN and the
quality of the outputs it produces. This paper looks at six different GANs
trained on different subsets of data from the game Lode Runner. The quality
diversity algorithm MAP-Elites was used to explore the set of quality levels
that could be produced by each GAN, where quality was defined as being beatable
and having the longest solution path possible. Interestingly, a GAN trained on
only 20 levels generated the largest set of diverse beatable levels while a GAN
trained on 150 levels generated the smallest set of diverse beatable levels,
thus challenging the notion that more is always better when training GANs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:41:42 GMT""}]","2021-01-21"
"2101.07869","Nuno Crokidakis","Marcelo A. Pires, Andre L. Oestereich, Nuno Crokidakis, S\'ilvio M.
  Duarte Queir\'os","Antivax movement and epidemic spreading in the era of social networks:
  Nonmonotonic effects, bistability and network segregation","11 pages, 8 figures, to appear in PRE","Phys. Rev. E 104, 034302 (2021)","10.1103/PhysRevE.104.034302",,"physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  In this work, we address a multicoupled dynamics on complex networks with
tunable structural segregation. Specifically, we work on a networked epidemic
spreading under a vaccination campaign with agents in favor and against the
vaccine. Our results show that such coupled dynamics exhibits a myriad of
phenomena such as nonequilibrium transitions accompanied by bistability.
Besides we observe the emergence of an intermediate optimal segregation level
where the community structure enhances negative opinions over vaccination but
counterintuitively hinders - rather than favoring - the global disease
spreading. Thus, our results hint vaccination campaigns should avoid policies
that end up segregating excessively anti-vaccine groups so that they
effectively work as echo chambers in which individuals look to confirmation
without jeopardising the safety of the whole population.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:42:58 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 12:11:48 GMT""}]","2021-09-15"
"2101.07870","Lars Loetgering","Ruslan R\""ohrich, Femius Koenderink, Stefan Witte, Lars Loetgering","Spatial coherence control and analysis via micromirror-based mixed-state
  ptychography",,,"10.1088/1367-2630/abf389",,"physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Flexible and fast control of the phase and amplitude of coherent light,
enabled by digital micromirror devices (DMDs) and spatial light modulators
(SLMs), has been a driving force for recent advances in optical tweezers,
nonlinear microscopy, and wavefront shaping. In contrast, engineering spatially
partially coherent light remains widely elusive due to the lack of tools
enabling a joint analysis and control sequence. Here, we report an approach to
coherence engineering that combines a quasi-monochromatic, thermal source and a
DMD together with a ptychographic scanning microscope. The reported method
opens up new routes to low-cost coherence control, with applications in
micromanipulation, nanophotonics, and quantitative phase contrast imaging.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:47:10 GMT""}]","2021-07-07"
"2101.07871","Elio Marconi","Elio Marconi","Differentiability properties of the flow of 2d autonomous vector fields",,,"10.1016/j.jde.2021.08.025",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate under which assumptions the flow associated to autonomous
planar vector fields inherits the Sobolev or BV regularity of the vector field.
We consider nearly incompressible and divergence-free vector fields, taking
advantage in both cases of the underlying Hamiltonian structure. Finally we
provide an example of an autonomous planar Sobolev divergence-free vector
field, such that the corresponding regular Lagrangian flow has no bounded
variation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:47:41 GMT""}]","2021-12-20"
"2101.07872","Jean-Christophe Pain","Jean-Christophe Pain","Group theory and the link between expectation values of powers of $r$
  and Clebsch-Gordan coefficients",,,,,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent paper [J.-C. Pain, Opt. Spectrosc. ${\bf 218}$, 1105-1109
(2020)], we discussed the link between expectation values of powers of $r$ and
Clebsch-Gordan coefficients. In this short note we provide additional
information, reminding that such a connection is a direct consequence of group
theory. The hydrogenic radial wavefunctions form bases for infinite dimensional
representations of the algebra of the non-compact group $O(2,1)$ and the
expectation values $r^p$ and $r^{-p}$ ($p$ being positive) transform as tensors
with respect to this algebra. As shown a long time ago by Armstrong [L.
Armstrong Jr., J . Phys. (Paris) Suppl. C 4 ${\bf 31}$, 17 (1970)], analysis of
matrix elements of $r^p$ and $r^{-p}$ reveals that the Wigner-Eckart theorem is
valid for this group and that the corresponding Clebsch-Gordan coefficients are
proportional to the usual $SO(3)$ Clebsch-Gordan coefficients. This
proportionality provides simple explanations of the selection rules for
hydrogenic radial matrix elements pointed out by Pasternack and Sternheimer,
and the proportionality of hydrogenic expectation values of $r^p$ and $r^{-p}$
to $3jm$ symbols.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:48:16 GMT""}]","2021-01-21"
"2101.07873","Shuyang Yang","Shuyang Yang, Derek Dardzinski, Andrea Hwang, Dmitry I. Pikulin, Georg
  W. Winkler, Noa Marom","First principles feasibility assessment of a topological insulator at
  the InAs/GaSb interface",,"Phys. Rev. Materials 5, 084204 (2021)","10.1103/PhysRevMaterials.5.084204",,"physics.comp-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  First principles simulations are conducted to shed light on the question of
whether a two-dimensional topological insulator (2DTI) phase may be obtained at
the interface between InAs and GaSb. To this end, the InAs/GaSb interface is
compared and contrasted with the HgTe/CdTe interface. Density functional theory
(DFT) simulations of these interfaces are performed using a machine-learned
Hubbard U correction [npj Comput. Mater. 6, 180 (2020)]. For the HgTe/CdTe
interface our simulations show that band crossing is achieved and an inverted
gap is obtained at a critical thickness of 5.1 nm of HgTe, in agreement with
experiment and previous DFT calculations. In contrast, for InAs/GaSb the gap
narrows with increasing thickness of InAs; however the gap does not close for
interfaces with up to 50 layers (about 15 nm) of each material. When an
external electric field is applied across the InAs/GaSb interface, the
GaSb-derived valence band maximum is shifted up in energy with respect to the
InAs-derived conduction band minimum until eventually the bands cross and an
inverted gap opens. Our results show that it may be possible to reach the
topological regime at the InAs/GaSb interface under the right conditions.
However, it may be challenging to realize these conditions experimentally,
which explains the difficulty of experimentally demonstrating an inverted gap
in InAs/GaSb.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:50:06 GMT""}]","2021-08-25"
"2101.07874","Abtin Daghighi Ph.D.","Abtin Daghighi","On Rad\'o's theorem for polyanalytic functions",,,,,"math.CV","http://creativecommons.org/licenses/by-sa/4.0/","  We prove versions of Rad\'o's theorem for polyanalytic functions in one
variable and also on simply connected $\mathbb{C}$-convex domains in
$\mathbb{C}^n$. Let $\Omega\subset \mathbb{C}$ be a bounded, simply connected
domain and let $q\in \mathbb{Z}_+.$ Suppose at least one of the following
conditions holds true: (i) $g\in C^{q}(\Omega).$ (ii) $g\in C^\kappa(\Omega),$
for $\kappa=\min\{1,q-1\},$ such that $g$ is $q$-analytic on $\Omega\setminus
g^{-1}(0)$ and such that Re$g$ (Im$g$ respectively) is a solutions to the
$p'$-Laplace equation ($p''$-Laplace equation respectively) on $\Omega\setminus
g^{-1}(0)$, for some $p',p''>1$. Then $g$ agrees (Lebesgue) a.e.\ with a
function that is $q$-analytic on $\Omega.$ In the process we give a simple
proof of the fact that: If $f\in C^q(\Omega)$ is $q$-analytic on
$\Omega\setminus f^{-1}(0)$ then $f$ is $q$-analytic on $\Omega.$ The
extensions of the results to several complex variables are straightforward
using known techniques.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:29:45 GMT""}]","2021-01-21"
"2101.07877","Manuel Steve Mbankeu Patchou","Manuel Patchou and Benjamin Sliwa and Christian Wietfeld","Flying Robots for Safe and Efficient Parcel Delivery Within the COVID-19
  Pandemic",,,,,"cs.NI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The integration of small-scale Unmanned Aerial Vehicles (UAVs) into
Intelligent Transportation Systems (ITSs) will empower novel smart-city
applications and services. After the unforeseen outbreak of the COVID-19
pandemic, the public demand for delivery services has multiplied. Mobile
robotic systems inherently offer the potential for minimizing the amount of
direct human-to-human interactions with the parcel delivery process. The
proposed system-of-systems consists of various complex aspects such as
assigning and distributing delivery jobs, establishing and maintaining reliable
communication links between the vehicles, as well as path planning and mobility
control. In this paper, we apply a system-level perspective for identifying key
challenges and promising solution approaches for modeling, analysis, and
optimization of UAV-aided parcel delivery. We present a system-of-systems model
for UAV-assisted parcel delivery to cope with higher capacity requirements
induced by the COVID-19. To demonstrate the benefits of hybrid vehicular
delivery, we present a case study focusing on the prioritization of
time-critical deliveries such as medical goods. The results further confirm
that the capacity of traditional delivery fleets can be upgraded with drone
usage. Furthermore, we observe that the delay incurred by prioritizing
time-critical deliveries can be compensated with drone deployment. Finally,
centralized and decentralized communication approaches for data transmission
inside hybrid delivery fleets are compared.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:54:22 GMT""}]","2021-01-21"
"2101.07878","Alexandre Jannaud Mr","Alexandre Jannaud","Dehn-Seidel twist, $C^0$ symplectic topology and barcodes",,,,,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We initiate the study of the $C^0$ symplectic mapping class group, i.e. the
group of isotopy classes of symplectic homeomorphisms. We prove that none of
the different powers of the square of the Dehn-Seidel twist belong to the same
connected component of the group of symplectic homeomorphisms of certain
Liouville domains. This generalizes to the $C^0$ setting a celebrated result of
Seidel. In other words, we obtain the non-triviality of the $C^0$ symplectic
mapping class group in these domains and in fact an element of infinite order.
For that purpose, we develop a method coming from Floer theory and the theory
of barcodes. This builds on recent developments of $C^0$-symplectic topology.
In particular, we adapt and generalize to our context results by
Buhovsky-Humili\`ere-Seyfaddini and Kislev-Shelukhin.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:56:41 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 15:24:51 GMT""}]","2021-04-23"
"2101.07879","Loretta del Mercato","S. Prasad, A. Chandra, M. Cavo, E. Parasido, S. Fricke, Y. Lee, E.
  D'Amone, G. Gigli, C. Albanese, O. Rodriguez, L.L. del Mercato","Optical and magnetic resonance imaging approaches for investigating the
  tumour microenvironment: state-of-the-art review and future trends","36 pages, 13 figures","Nanotechnology, Volume 32, Number 6, 062001, 2021","10.1088/1361-6528/abc208",,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tumour microenvironment (TME) strongly influences tumorigenesis and
metastasis. Two of the most characterized properties of the TME are acidosis
and hypoxia, both of which are considered hallmarks of tumours as well as
critical factors in response to anticancer treatments. Currently, various
imaging approaches exist to measure acidosis and hypoxia in the TME, including
magnetic resonance imaging (MRI), positron emission tomography and optical
imaging. In this review, we will focus on the latest fluorescent-based methods
for optical sensing of cell metabolism and MRI as diagnostic imaging tools
applied both in vitro and in vivo. The primary emphasis will be on describing
the current and future uses of systems that can measure intra- and
extra-cellular pH and oxygen changes at high spatial and temporal resolution.
In addition, the suitability of these approaches for mapping tumour
heterogeneity, and assessing response or failure to therapeutics will also be
covered.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:03:37 GMT""}]","2021-01-21"
"2101.07880","Yusheng Luo","Yusheng Luo","On geometrically finite degenerations I: boundaries of main hyperbolic
  components","68 pages, 34 figures. Final version, to appear in J. Eur. Math. Soc.
  (JEMS)",,,,"math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a theory on the degenerations of Blaschke products
$\mathcal{B}_d$ to study the boundaries of hyperbolic components. We give a
combinatorial classification of geometrically finite polynomials on the
boundary of the main hyperbolic component $\mathcal{H}_d$ containing $z^d$. We
show the closure $\overline{\mathcal{H}_d}$ is not a topological manifold with
boundary for $d\geq 4$ by constructing self-bumps on its boundary.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:12:43 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 05:38:25 GMT""}]","2022-03-03"
"2101.07881","Carola Doerr","Fran\c{c}ois Cl\`ement, Carola Doerr, Lu\'is Paquete","Star Discrepancy Subset Selection: Problem Formulation and Efficient
  Approaches for Low Dimensions",,,,,"cs.CG cs.DS cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by applications in instance selection, we introduce the star
discrepancy subset selection problem, which consists of finding a subset of m
out of n points that minimizes the star discrepancy. First, we show that this
problem is NP-hard. Then, we introduce a mixed integer linear formulation
(MILP) and a combinatorial branch-and-bound (BB) algorithm for the star
discrepancy subset selection problem and we evaluate both approaches against
random subset selection and a greedy construction on different use-cases in
dimension two and three. Our results show that the MILP and BB are efficient in
dimension two for large and small $m/n$ ratio, respectively, and for not too
large n. However, the performance of both approaches decays strongly for larger
dimensions and set sizes.
  As a side effect of our empirical comparisons we obtain point sets of
discrepancy values that are much smaller than those of common low-discrepancy
sequences, random point sets, and of Latin Hypercube Sampling. This suggests
that subset selection could be an interesting approach for generating point
sets of small discrepancy value.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:24:41 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 10:40:17 GMT""}]","2022-01-05"
"2101.07882","Arne Laucht Dr.","Arne Laucht, Frank Hohls, Niels Ubbelohde, M Fernando Gonzalez-Zalba,
  David J Reilly, S{\o}ren Stobbe, Tim Schr\""oder, Pasquale Scarlino, Jonne V
  Koski, Andrew Dzurak, Chih-Hwan Yang, Jun Yoneda, Ferdinand Kuemmeth, Hendrik
  Bluhm, Jarryd Pla, Charles Hill, Joe Salfi, Akira Oiwa, Juha T Muhonen, Ewold
  Verhagen, Matthew D LaHaye, Hyun Ho Kim, Adam W Tsen, Dimitrie Culcer, Attila
  Geresdi, Jan A Mol, Varun Mohan, Prashant K Jain, and Jonathan Baugh","Roadmap on quantum nanotechnologies","Roadmap article with contributed sections and subsections on: 1.
  Metrology and sensing 2. Quantum light sources, cavities and detectors 3.
  Quantum computing with spins 4. Nano and opto-mechanics 5. Low-dimensional
  systems 6. Molecular devices 7. Nanoplasmonics (47 pages, 25 figures).
  Contains arXiv:1907.02625, arXiv:1907.07087, arXiv:2001.11119,
  arXiv:2011.13907","Nanotechnology 32, 162003 (2021)","10.1088/1361-6528/abb333","NBI QDev 2021","cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum phenomena are typically observable at length and time scales smaller
than those of our everyday experience, often involving individual particles or
excitations. The past few decades have seen a revolution in the ability to
structure matter at the nanoscale, and experiments at the single particle level
have become commonplace. This has opened wide new avenues for exploring and
harnessing quantum mechanical effects in condensed matter. These quantum
phenomena, in turn, have the potential to revolutionize the way we communicate,
compute and probe the nanoscale world. Here, we review developments in key
areas of quantum research in light of the nanotechnologies that enable them,
with a view to what the future holds. Materials and devices with nanoscale
features are used for quantum metrology and sensing, as building blocks for
quantum computing, and as sources and detectors for quantum communication. They
enable explorations of quantum behaviour and unconventional states in nano- and
opto-mechanical systems, low-dimensional systems, molecular devices,
nano-plasmonics, quantum electrodynamics, scanning tunnelling microscopy, and
more. This rapidly expanding intersection of nanotechnology and quantum
science/technology is mutually beneficial to both fields, laying claim to some
of the most exciting scientific leaps of the last decade, with more on the
horizon.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:27:29 GMT""}]","2021-04-27"
"2101.07883","Aaron Geller","Aaron M. Geller, Robert D. Mathieu, David W. Latham, Maxwell Pollack,
  Guillermo Torres and Emily M. Leiner","Stellar Radial Velocities in the Old Open Cluster M67 (NGC 2682). II.
  The Spectroscopic Binary Population","Accepted for publication in AJ; 13 figures, 7 tables",,"10.3847/1538-3881/abdd23",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present and analyse 120 spectroscopic binary and triple cluster members of
the old (4 Gyr) open cluster M67 (NGC 2682). As a cornerstone of stellar
astrophysics, M67 is a key cluster in the WIYN Open Cluster Study (WOCS);
radial-velocity (RV) observations of M67 are ongoing and extend back over 45
years, incorporating data from seven different telescopes, and allowing us to
detect binaries with orbital periods <~10^4 days. Our sample contains 1296
stars (604 cluster members) with magnitudes of 10 <= V <= 16.5 (about 1.3 to
0.7 Msolar), from the giants down to ~4 mag below the main-sequence turnoff,
and extends in radius to 30 arcminutes (7.4 pc at a distance of 850 pc, or ~7
core radii). This paper focuses primarily on the main-sequence binaries, but
orbital solutions are also presented for red giants, yellow giants and
sub-subgiants. Out to our period detection limit and within our magnitude and
spatial domain, we find a global main-sequence incompleteness-corrected binary
fraction of 34% +/- 3%, which rises to 70% +/- 17% in the cluster center. We
derive a tidal circularization period of P_circ = 11.0 +1.1 -1.0 days. We also
analyze the incompleteness-corrected distributions of binary orbital elements
and masses. The period distribution rises toward longer periods. The
eccentricity distribution, beyond P_circ, is consistent with a uniform
distribution. The mass-ratio distribution is also consistent with a uniform
distribution. Overall, these M67 binaries are closely consistent with similar
binaries in the galactic field, as well as the old (7 Gyr) open cluster NGC
188.
  WIYN Open Cluster Study. 83.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:30:12 GMT""}]","2021-03-24"
"2101.07884","Sean Carroll","Sean M. Carroll","The Quantum Field Theory on Which the Everyday World Supervenes","19 pages. Invited contribution to Levels of Reality: A Scientific and
  Metaphysical Investigation (Jerusalem Studies in Philosophy and History of
  Science), eds. Orly Shenker, Meir Hemmo, Stavros Iannidis, and Gal Vishne",,,"CALT 2021-005","physics.hist-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Effective Field Theory (EFT) is the successful paradigm underlying modern
theoretical physics, including the ""Core Theory"" of the Standard Model of
particle physics plus Einstein's general relativity. I will argue that EFT
grants us a unique insight: each EFT model comes with a built-in specification
of its domain of applicability. Hence, once a model is tested within some
domain (of energies and interaction strengths), we can be confident that it
will continue to be accurate within that domain. Currently, the Core Theory has
been tested in regimes that include all of the energy scales relevant to the
physics of everyday life (biology, chemistry, technology, etc.). Therefore, we
have reason to be confident that the laws of physics underlying the phenomena
of everyday life are completely known.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:34:14 GMT""}]","2021-01-21"
"2101.07885","Manuel Krannich","Manuel Krannich and Alexander Kupers","Embedding calculus for surfaces","29 pages, final version",,,,"math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove convergence of Goodwillie-Weiss' embedding calculus for spaces of
embeddings into a manifold of dimension at most two, so in particular for
diffeomorphisms between surfaces. We also relate the Johnson filtration of the
mapping class group of a surface to a certain filtration arising from embedding
calculus.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:34:40 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 21:29:07 GMT""},{""version"":""v3"",""created"":""Thu, 6 Oct 2022 08:55:01 GMT""}]","2022-10-07"
"2101.07886","Tyler Gordon","Tyler A. Gordon, James R. A. Davenport, Ruth Angus, Daniel
  Foreman-Mackey, Eric Agol, Kevin R. Covey, Marcel Ag\""ueros, and David
  Kipping","Stellar Rotation in the K2 Sample: Evidence for Modified Spindown","17 pages, 14 figures, submitted to ApJ, revised April 1, 2020",,"10.3847/1538-4357/abf63e",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We analyze light curves of 284,834 unique K2 targets using a Gaussian process
model with a quasi-periodic kernel function. By crossmatching K2 stars to
observations from Gaia Data Release 2, we have identified 69,627 likely
main-sequence stars. From these we select a subsample of 8,977 stars on the
main-sequence with highly precise rotation period measurements. With this
sample we recover the gap in the rotation period-color diagram first reported
by \cite{McQuillan2013}. While the gap was tentatively detected in
\cite{Reinhold2020}, this work represents the first robust detection of the gap
in K2 data for field stars. This is significant because K2 observed along many
lines of sight at wide angular separation, in contrast to Kepler's single line
of sight. Together with recent results for rotation in open clusters, we
interpret this gap as evidence for a departure from the $t^{-1/2}$ Skumanich
spin down law, rather than an indication of a bimodal star formation history.
We provide maximum likelihood estimates and uncertainties for all parameters of
the quasi-periodic light curve model for each of the 284,834 stars in our
sample.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:38:26 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 22:45:56 GMT""}]","2021-06-02"
"2101.07887","Yunseong Nam","Reinhold Bl\""umel, Nikodem Grzesiak, Nhung H. Nguyen, Alaina M. Green,
  Ming Li, Andrii Maksymov, Norbert M. Linke, Yunseong Nam","Efficient, stabilized two-qubit gates on a trapped-ion quantum computer",,"Phys. Rev. Lett. 126, 220503 (2021)","10.1103/PhysRevLett.126.220503",,"quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computing is currently limited by the cost of two-qubit entangling
operations. In order to scale up quantum processors and achieve a quantum
advantage, it is crucial to economize on the power requirement of two-qubit
gates, make them robust to drift in experimental parameters, and shorten the
gate times. In this paper, we present two methods, one exact and one
approximate, to construct optimal pulses for entangling gates on a pair of ions
within a trapped ion chain, one of the leading quantum computing architectures.
Our methods are direct, non-iterative, and linear, and can construct
gate-steering pulses requiring less power than the standard method by more than
an order of magnitude in some parameter regimes. The power savings may
generally be traded for reduced gate time and greater qubit connectivity.
Additionally, our methods provide increased robustness to mode drift. We
illustrate these trade-offs on a trapped-ion quantum computer.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:40:28 GMT""}]","2021-06-09"
"2101.07888","EPTCS","David I. Spivak (Massachusetts Institute of Technology), Jamie Vicary
  (University of Cambridge)","Proceedings of the 3rd Annual International Applied Category Theory
  Conference 2020",,"EPTCS 333, 2021","10.4204/EPTCS.333",,"cs.DM cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The third annual International Applied Category Theory Conference (ACT2020)
was planned to take place at MIT in Cambridge, Massachusetts USA. However, the
global COVID-19 pandemic made the prospect of holding a large in-person meeting
impossible, and the event was thus held completely online. Holding the talks
online had the new benefits of reducing carbon footprint, being inclusive of
people from more parts of the world, and producing higher-quality video talks,
which have been posted online for posterity.
  The ACT2020 contributions spanned a broad spectrum of application areas,
including databases, dynamical systems, functional programming, game theory,
lenses, neuroscience, probabilistic programming, natural language processing,
quantum mechanics, and cyberphysical systems. Papers featured a broad range of
categorical techniques.
  Papers in this Proceedings volume represents about half of the talks
presented at ACT2020. Being included in the proceedings vs. not is not an
indication of talk quality, but instead almost exclusively the choice of the
authors, e.g. to present work already published elsewhere.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:46:00 GMT""}]","2021-01-21"
"2101.07889","Mikaela Angelina Uy","Mikaela Angelina Uy, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman,
  Siddhartha Chaudhuri, Leonidas Guibas","Joint Learning of 3D Shape Retrieval and Deformation","CVPR '21 accepted paper",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel technique for producing high-quality 3D models that match
a given target object image or scan. Our method is based on retrieving an
existing shape from a database of 3D models and then deforming its parts to
match the target shape. Unlike previous approaches that independently focus on
either shape retrieval or deformation, we propose a joint learning procedure
that simultaneously trains the neural deformation module along with the
embedding space used by the retrieval module. This enables our network to learn
a deformation-aware embedding space, so that retrieved models are more amenable
to match the target after an appropriate deformation. In fact, we use the
embedding space to guide the shape pairs used to train the deformation module,
so that it invests its capacity in learning deformations between meaningful
shape pairs. Furthermore, our novel part-aware deformation module can work with
inconsistent and diverse part-structures on the source shapes. We demonstrate
the benefits of our joint training not only on our novel framework, but also on
other state-of-the-art neural deformation modules proposed in recent years.
Lastly, we also show that our jointly-trained method outperforms various
non-joint baselines.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:49:41 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 12:10:17 GMT""}]","2021-04-14"
"2101.07890","Timo Noack","Timo B. Noack, Vitaliy I. Vasyuchka, Anna Pomyalov, Victor S. L'vov,
  Alexander A. Serga, Burkard Hillebrands","Evolution of room-temperature magnon gas toward coherent Bose-Einstein
  condensate","6 pages, 2 figures","Phys. Rev. B 104, 100410 (2021)","10.1103/PhysRevB.104.L100410",,"cond-mat.mtrl-sci cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The appearance of spontaneous coherence is a fundamental feature of a
Bose-Einstein condensate and an essential requirement for possible applications
of the condensates for data processing and quantum computing. In the case of a
magnon condensate in a magnetic crystal, such computing can be performed even
at room temperature. So far, the process of coherence formation in a magnon
condensate was inaccessible. We study the evolution of magnon radiation spectra
by direct detection of microwave radiation emitted by magnons in a
parametrically driven yttrium iron garnet crystal. By using specially shaped
bulk samples, we show that the parametrically overpopulated magnon gas evolves
to a state, whose coherence is only limited by the natural magnon relaxation
into the crystal lattice.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:04:02 GMT""}]","2021-09-22"
"2101.07891","Homagni Saha","Homagni Saha, Fateme Fotouhif, Qisai Liu, Soumik Sarkar","A modular vision language navigation and manipulation framework for long
  horizon compositional tasks in indoor environment","16 pages",,,,"cs.CV cs.HC cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a new framework - MoViLan (Modular Vision and
Language) for execution of visually grounded natural language instructions for
day to day indoor household tasks. While several data-driven, end-to-end
learning frameworks have been proposed for targeted navigation tasks based on
the vision and language modalities, performance on recent benchmark data sets
revealed the gap in developing comprehensive techniques for long horizon,
compositional tasks (involving manipulation and navigation) with diverse object
categories, realistic instructions and visual scenarios with non-reversible
state changes. We propose a modular approach to deal with the combined
navigation and object interaction problem without the need for strictly aligned
vision and language training data (e.g., in the form of expert demonstrated
trajectories). Such an approach is a significant departure from the traditional
end-to-end techniques in this space and allows for a more tractable training
process with separate vision and language data sets. Specifically, we propose a
novel geometry-aware mapping technique for cluttered indoor environments, and a
language understanding model generalized for household instruction following.
We demonstrate a significant increase in success rates for long-horizon,
compositional tasks over the baseline on the recently released benchmark data
set-ALFRED.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:05:43 GMT""}]","2021-01-21"
"2101.07892","Wenbo Ge","Wenbo Ge, Paul M. Sass, Jiaqiang Yan, Seng Huat Lee, Zhiqiang Mao and
  Weida Wu","Direct evidence of ferromagnetism in MnSb2Te4",,"Phys. Rev. B 103, 134403 (2021)","10.1103/PhysRevB.103.134403",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We report the magnetic imaging of ferromagnetic domains in the van der Waals
single crystal MnSb2Te4 from two different sources using cryogenic magnetic
force microscopy. The magnetic field dependence of the domains reveals very
weak pinning of domain walls in MnSb2Te4, resulting in a negligibly small
magnetic hysteresis loop. The temperature dependence of the domain contrast
reveals a mean field like behavior, in good agreement with that of bulk
magnetization measurements.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:17:48 GMT""}]","2021-04-07"
"2101.07893","Athanasios Laliotis","J.C. de Aquino Carvalho, I. Maurin, H. Failache, D. Bloch, A. Laliotis","Velocity preserving transfer between highly excited atomic states: Black
  Body Radiation and Collisions","accepted for publication in Journal of Physics B: Atomic, Molecular
  and Optical Physics",,,,"physics.atom-ph quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the excitation redistribution from cesium $7\mathrm{P}_{1/2}$ or
$7\mathrm{P}_{3/2}$ to neighboring energy levels by Black Body Radiation (BBR)
and inter atomic collisions using pump-probe spectroscopy inside a vapor cell.
At low vapor densities we measure redistribution of the initial,
velocity-selected, atomic excitation by BBR. This preserves the selected atomic
velocities allowing us to perform high resolution spectroscopy of the
$\mathrm{6D\rightarrow 7F}$ transitions. This transfer mechanism could also be
used to perform sub-Doppler spectroscopy of the cesium highly-excited
$\mathrm{nG}$ levels. At high densities we observe interatomic collisions
redistributing the excitation within the cesium $\mathrm{7P}$ fine and
hyperfine structure. We show that $\mathrm{7P}$ redistribution involves
state-changing collisions that preserve the initial selection of atomic
velocities. These redistribution mechanisms can be of importance for
experiments probing high lying excited states in dense alkali vapor.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:17:50 GMT""}]","2021-01-21"
"2101.07894","Emilio Gallicchio","Joe Z. Wu, Solmaz Azimi, Sheenam Khuttan, Nanjie Deng, Emilio
  Gallicchio","Alchemical Transfer Approach to Absolute Binding Free Energy Estimation",,,,,"physics.chem-ph q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  The Alchemical Transfer Method (ATM) for the calculation of standard binding
free energies of non-covalent molecular complexes is presented. The method is
based on a coordinate displacement perturbation of the ligand between the
receptor binding site and the explicit solvent bulk, and a thermodynamic cycle
connected by a symmetric intermediate in which the ligand interacts with the
receptor and solvent environments with equal strength. While the approach is
alchemical, the implementation of ATM is as straightforward as for physical
pathway methods of binding. The method is applicable in principle with any
force field, it does not require splitting the alchemical transformations into
electrostatic and non-electrostatic steps, and it does not require soft-core
pair potentials. We have implemented ATM as a freely available and open-source
plugin of the OpenMM molecular dynamics library. The method and its
implementation are validated on the SAMPL6 SAMPLing host-guest benchmark set.
The work paves the way to streamlined alchemical relative and absolute binding
free energy implementations on many molecular simulation packages and with
arbitrary energy functions including polarizable, quantum-mechanical, and
artificial neural network potentials.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:20:12 GMT""}]","2021-01-21"
"2101.07895","Kelly Malone","HAWC Collaboration, A. Albert, R. Alfaro, C. Alvarez, J.D. \'Alvarez,
  J.R. Angeles Camacho, J.C. Arteaga-Vel\'azquez, K.P. Arunbabu, D. Avila
  Rojas, H.A. Ayala Solares, V. Baghmanyan, E. Belmont-Moreno, S.Y. BenZvi, C.
  Brisbois, K.S. Caballero-Mora, T. Capistr\'an, A. Carrami\~nana, S. Casanova,
  U. Cotti, J. Cotzomi, S. Couti\~no de Le\'on, E. De la Fuente, C. de Le\'on,
  R. Diaz Hernandez, B.L. Dingus, M.A. DuVernois, M. Durocher, J.C.
  D\'iaz-V\'elez, R.W. Ellsworth, K. Engel, C. Espinoza, K.L. Fan, M.
  Fern\'andez Alonso, N. Fraija, A. Galv\'an-G\'amez, J.A. Garc\'ia-Gonz\'alez,
  F. Garfias, G. Giacinti, M.M. Gonz\'alez, J.A. Goodman, J.P. Harding, S.
  Hernandez, B. Hona, D. Huang, F. Hueyotl-Zahuantitla, P. H\""untemeyer, A.
  Iriarte, A. Jardin-Blicq, V. Joshi, D. Kieda, A. Lara, W.H. Lee, J. Lee, H.
  Le\'on Vargas, J.T. Linnemann, A.L. Longinotti, G. Luis-Raya, J. Lundeen, K.
  Malone, V. Marandon, O. Martinez, J. Mart\'inez-Castro, J.A. Matthews, P.
  Miranda-Romagnoli, J.A. Morales-Soto, E. Moreno, M. Mostaf\'a, A. Nayerhoda,
  L. Nellen, M. Newbold, M.U. Nisa, R. Noriega-Papaqui, L. Olivera-Nieto, N.
  Omodei, A. Peisker, Y. P\'erez Araujo, E.G. P\'erez-P\'erez, C.D. Rho, Y.J.
  Roh, D. Rosa-Gonz\'alez, E. Ruiz-Velasco, H. Salazar, F. Salesa Greus, A.
  Sandoval, M. Schneider, H. Schoorlemmer, J. Serna-Franco, A.J. Smith, R.W.
  Springer, P. Surajbali, M. Tanner, K. Tollefson, I. Torres, R.
  Torres-Escobedo, R. Turner, F. Ure\~na-Mena, L. Villase\~nor, T. Weisgarber,
  E. Willox, H. Zhou","Evidence that Ultra-High-Energy Gamma Rays are a Universal Feature Near
  Powerful Pulsars","accepted by ApJL",,"10.3847/2041-8213/abf4dc",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The highest-energy known gamma-ray sources are all located within 0.5 degrees
of extremely powerful pulsars. This raises the question of whether
ultra-high-energy (UHE; $>$ 56 TeV) gamma-ray emission is a universal feature
expected near pulsars with a high spin-down power. Using four years of data
from the High Altitude Water Cherenkov (HAWC) Gamma-Ray Observatory, we present
a joint-likelihood analysis of ten extremely powerful pulsars to search for UHE
gamma-ray emission correlated with these locations. We report a significant
detection ($>$ 3$\sigma$), indicating that UHE gamma-ray emission is a generic
feature of powerful pulsars. We discuss the emission mechanisms of the gamma
rays and the implications of this result. The individual environment that each
pulsar is found in appears to play a role in the amount of emission.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:22:52 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 17:59:52 GMT""}]","2021-04-29"
"2101.07896","Nicholas Michael Ercolani","Nicholas M. Ercolani and Jonathan Ramalheira-Tsu","The Ghost-Box-Ball System: A Unified Perspective on Soliton Cellular
  Automata, the RSK Algorithm and Phase Shifts",,,"10.1016/j.physd.2021.132986",,"nlin.SI math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we introduce the ghost-box-ball system, which is an extended
version of the classical soliton cellular automaton. It is initially motivated
as a mechanism for making precise a connection between the Schensted insertion
(of the Robinson-Schensted-Knuth correspondence) and the dynamical process of
the box-ball system. In addition to this motivation, we explore generalisations
of classical notions of the box-ball system, including the solitonic
phenomenon, the asymptotic sorting property, and the invariant shape
construction. We analyse the ghost-box-ball system beyond its initial relevance
to the Robinson-Schensted-Knuth correspondence, unpacking its relationship to
its underlying dynamical evolution on a coordinatisation and using a mechanism
for augmenting a regular box-ball configuration to study the classical
ultradiscrete phase shift phenomenon.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:35:34 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 21:18:12 GMT""}]","2021-08-18"
"2101.07897","Vikram Sharma Mailthody","Vikram Sharma Mailthody and James Wei and Nicholas Chen and Mohammad
  Behnia and Ruihao Yao and Qihao Wang and Vedant Agrawal and Churan He and
  Lijian Wang and Leihao Chen and Amit Agarwal and Edward Richter and Wen-Mei
  Hwu and Christopher W. Fletcher and Jinjun Xiong and Andrew Miller and Sanjay
  Patel","Safer Illinois and RokWall: Privacy Preserving University Health Apps
  for COVID-19","Appears in the Workshop on Secure IT Technologies against
  COVID-19(CoronaDef) 2021",,,,"cs.CR cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  COVID-19 has fundamentally disrupted the way we live. Government bodies,
universities, and companies worldwide are rapidly developing technologies to
combat the COVID-19 pandemic and safely reopen society. Essential analytics
tools such as contact tracing, super-spreader event detection, and exposure
mapping require collecting and analyzing sensitive user information. The
increasing use of such powerful data-driven applications necessitates a secure,
privacy-preserving infrastructure for computation on personal data. In this
paper, we analyze two such computing infrastructures under development at the
University of Illinois at Urbana-Champaign to track and mitigate the spread of
COVID-19. First, we present Safer Illinois, a system for decentralized health
analytics supporting two applications currently deployed with widespread
adoption: digital contact tracing and COVID-19 status cards. Second, we
introduce the RokWall architecture for privacy-preserving centralized data
analytics on sensitive user data. We discuss the architecture of these systems,
design choices, threat models considered, and the challenges we experienced in
developing production-ready systems for sensitive data analysis.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:36:14 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 16:06:19 GMT""}]","2021-03-18"
"2101.07898","Lisa Kaltenegger","L. Kaltenegger, J. Pepper, P. M. Christodoulou, K. Stassun, S. Quinn,
  C. Burke","Around which stars can TESS detect Earth-like planets? The Revised TESS
  Habitable Zone Catalog","12 pages, 3 figures, 6 tables, accepted ApJ",,"10.3847/1538-3881/abe5a9",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the search for life in the cosmos, NASA's Transiting Exoplanet Survey
Satellite (TESS) mission has already monitored about 74% of the sky for
transiting extrasolar planets, including potentially habitable worlds. However,
TESS only observed a fraction of the stars long enough to be able to find
planets like Earth. We use the primary mission data - the first two years of
observations - and identify 4,239 stars within 210pc that TESS observed long
enough to see 3 transits of an exoplanet that receives similar irradiation to
Earth: 738 of these stars are located within 30pc. We provide reliable stellar
parameters from the TESS Input Catalog that incorporates Gaia DR2 and also
calculate the transit depth and radial velocity semi-amplitude for an
Earth-analog planet. Of the 4,239 stars in the Revised TESS HZ Catalog, 9 are
known exoplanet hosts - GJ 1061, GJ 1132, GJ 3512, GJ 685, Kepler-42, LHS 1815,
L98-59, RR Cae, TOI 700 - around which TESS could identify additional
Earth-like planetary companions. 37 additional stars host yet unconfirmed TESS
Objects of Interest: three of these orbit in the habitable zone - TOI 203, TOI
715, and TOI 2298. For a subset of 614 of the 4,239 stars, TESS has observed
the star long enough to be able to observe planets throughout the full
temperate, habitable zone out to the equivalent of Mars' orbit. Thus, the
Revised TESS Habitable Zone Catalog provides a tool for observers to prioritize
stars for follow-up observation to discover life in the cosmos. These stars are
the best path towards the discovery of habitable planets using the TESS mission
data.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:38:54 GMT""}]","2021-05-05"
"2101.07899","Fupin Yao","Fupin Yao","Cross-domain few-shot learning with unlabelled data",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Few shot learning aims to solve the data scarcity problem. If there is a
domain shift between the test set and the training set, their performance will
decrease a lot. This setting is called Cross-domain few-shot learning. However,
this is very challenging because the target domain is unseen during training.
Thus we propose a new setting some unlabelled data from the target domain is
provided, which can bridge the gap between the source domain and the target
domain. A benchmark for this setting is constructed using DomainNet
\cite{peng2018oment}. We come up with a self-supervised learning method to
fully utilize the knowledge in the labeled training set and the unlabelled set.
Extensive experiments show that our methods outperforms several baseline
methods by a large margin. We also carefully design an episodic training
pipeline which yields a significant performance boost.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:41:57 GMT""}]","2021-01-21"
"2101.07900","Huaxin Lin","Xuanlong Fu and Huaxin Lin","Non-amenable simple C*-algebras with tracial approximation",,,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct two types of unital separable simple $C^*$-alebras $A_z^{C_1}$
and $A_z^{C_2},$ one is exact but not amenable, and the other is non-exact.
Both have the same Elliott invariant as the Jiang-Su algebra, namely,
$A_z^{C_i}$ has a unique tracial state, $$(K_0(A_z^{C_i}), K_0(A_z^{C_i})_+,
[1_{A_z^{C_i}} ])=(\mathbb Z, \mathbb Z_+,1)$$ and $K_{1}(A_z^{C_i})=\{0\}$
($i=1,2$). We show that $A_z^{C_i}$ ($i=1,2$) is essentially tracially in the
class of separable ${\cal Z}$-stable $C^*$-alebras of nuclear dimension 1.
$A_z^{C_i}$ has stable rank one, strict comparison for positive elements and no
2-quasitrace other than the unique tracial state. We also produce models of
unital separable simple non-exact $C^*$-alebras which are essentially tracially
in the class of simple separable nuclear ${\cal Z}$-stable $C^*$-alebras and
the models exhaust all possible weakly unperforated Elliott invariants. We also
discuss some basic properties of essential tracial approximation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:47:17 GMT""}]","2021-01-21"
"2101.07901","Branden Stone","Charlie Miller and Branden Stone","Classifying Nearly Complete Intersection Ideals Generated in Degree Two","Results of undergraduate summer research at Hamilton College, 2019. 6
  pages",,,,"math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  Nearly complete intersection ideals were introduced by A. Boocher and J.
Seiner (2018) and defines a special class of monomial ideals in a polynomial
ring. These ideals were used to give a lower bound of the total sum of betti
numbers that appear a minimal free resolution of a monomial ideal. In this note
we give a graph theoretic classification of nearly complete intersection ideals
generated in degree two. In doing so, we define a novel graph operation (the
inversion) that is motivated by the definition of this new class of ideals.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:53:12 GMT""}]","2021-01-21"
"2101.07902","Andrew McNutt","Andrew McNutt, Ravi Chugh","Integrated Visualization Editing via Parameterized Declarative Templates","14 pages, 8 Figures, and a 4 page supplement with 4 figures and 1
  table","CHI Conference on Human Factors in Computing Systems (CHI '21),
  May 8-13, 2021, Yokohama, Japan","10.1145/3411764.3445356",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interfaces for creating visualizations typically embrace one of several
common forms. Textual specification enables fine-grained control, shelf
building facilitates rapid exploration, while chart choosing promotes immediacy
and simplicity. Ideally these approaches could be unified to integrate the
user- and usage-dependent benefits found in each modality, yet these forms
remain distinct. We propose parameterized declarative templates, a simple
abstraction mechanism over JSON-based visualization grammars, as a foundation
for multimodal visualization editors. We demonstrate how templates can
facilitate organization and reuse by factoring the more than 160 charts that
constitute Vega-Lite's example gallery into approximately 40 templates. We
exemplify the pliability of abstracting over charting grammars by implementing
-- as a template -- the functionality of the shelf builder Polestar (a
simulacra of Tableau) and a set of templates that emulate the Google Sheets
chart chooser. We show how templates support multimodal visualization editing
by implementing a prototype and evaluating it through an approachability study.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 23:56:59 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 16:00:39 GMT""}]","2021-01-27"
"2101.07903","Abtin Riasatian","Abtin Riasatian, Morteza Babaie, Danial Maleki, Shivam Kalra, Mojtaba
  Valipour, Sobhan Hemati, Manit Zaveri, Amir Safarpoor, Sobhan Shafiei, Mehdi
  Afshari, Maral Rasoolijaberi, Milad Sikaroudi, Mohd Adnan, Sultaan Shah,
  Charles Choi, Savvas Damaskinos, Clinton JV Campbell, Phedias Diamandis,
  Liron Pantanowitz, Hany Kashani, Ali Ghodsi, H.R. Tizhoosh","Fine-Tuning and Training of DenseNet for Histopathology Image
  Representation Using TCGA Diagnostic Slides",,,,,"eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Feature vectors provided by pre-trained deep artificial neural networks have
become a dominant source for image representation in recent literature. Their
contribution to the performance of image analysis can be improved through
finetuning. As an ultimate solution, one might even train a deep network from
scratch with the domain-relevant images, a highly desirable option which is
generally impeded in pathology by lack of labeled images and the computational
expense. In this study, we propose a new network, namely KimiaNet, that employs
the topology of the DenseNet with four dense blocks, fine-tuned and trained
with histopathology images in different configurations. We used more than
240,000 image patches with 1000x1000 pixels acquired at 20x magnification
through our proposed ""highcellularity mosaic"" approach to enable the usage of
weak labels of 7,126 whole slide images of formalin-fixed paraffin-embedded
human pathology samples publicly available through the The Cancer Genome Atlas
(TCGA) repository. We tested KimiaNet using three public datasets, namely TCGA,
endometrial cancer images, and colorectal cancer images by evaluating the
performance of search and classification when corresponding features of
different networks are used for image representation. As well, we designed and
trained multiple convolutional batch-normalized ReLU (CBR) networks. The
results show that KimiaNet provides superior results compared to the original
DenseNet and smaller CBR networks when used as feature extractor to represent
histopathology images.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:03:29 GMT""}]","2021-01-21"
"2101.07904","Xue Guang Zhang","Zhang XueGuang (NNU)","Evidence for Obscured broad \oiii Components in Type-2 AGN","5 pages, 5 figures, Accepted to be published in MNRAS",,,,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the manuscript, we report evidence on broad \oiii components apparently
obscured in Type-2 AGN under the framework of the Unified model, after checking
properties of broad \oiii emissions in large samples of Type-1 and Type-2 AGN
in SDSS DR12. We can well confirm the statistically lower flux ratios of the
broad to the core \oiii components in Type-2 AGN than in Type-1 AGN, which can
be naturally explained by stronger obscured broad \oiii components by central
dust torus in Type-2 AGN, unless the Unified model for AGN was not appropriate
to the narrow emission lines. The results provide further evidence to support
broad \oiii components coming from emission regions nearer to central BHs, and
also indicate the core \oiii component as the better indicator for central
activities in Type-2 AGN, due to few effects of obscuration on the core \oiii
component. Considering the broad \oiii components as signs of central outflows,
the results provide evidence for strong central outflows being preferentially
obscured in Type-2 AGN. Furthermore, the obscured broad \oiii component can be
applied to explain the different flux ratios of \oiiihb between Type-1 and
Type-2 AGN in the BPT diagram.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:05:00 GMT""}]","2021-01-21"
"2101.07905","Ryota Ikedo","Ryota Ikedo, Kazuhiro Hotta","Feature Sharing Cooperative Network for Semantic Segmentation","computer vision and pattern recognition",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, deep neural networks have achieved high ac-curacy in the
field of image recognition. By inspired from human learning method, we propose
a semantic segmentation method using cooperative learning which shares the
information resembling a group learning. We use two same networks and paths for
sending feature maps between two networks. Two networks are trained
simultaneously. By sharing feature maps, one of two networks can obtain the
information that cannot be obtained by a single network. In addition, in order
to enhance the degree of cooperation, we propose two kinds of methods that
connect only the same layer and multiple layers. We evaluated our proposed idea
on two kinds of networks. One is Dual Attention Network (DANet) and the other
one is DeepLabv3+. The proposed method achieved better segmentation accuracy
than the conventional single network and ensemble of networks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:22:00 GMT""}]","2021-01-21"
"2101.07906","Sandra Malpica","Daniel Martin, Sandra Malpica, Diego Gutierrez, Belen Masia and Ana
  Serrano","Multimodality in VR: A survey","35 pages (24 pages not including references), 10 figures, 4 tables",,"10.1145/3508361",,"cs.HC cs.GR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Virtual reality (VR) is rapidly growing, with the potential to change the way
we create and consume content. In VR, users integrate multimodal sensory
information they receive, to create a unified perception of the virtual world.
In this survey, we review the body of work addressing multimodality in VR, and
its role and benefits in user experience, together with different applications
that leverage multimodality in many disciplines. These works thus encompass
several fields of research, and demonstrate that multimodality plays a
fundamental role in VR; enhancing the experience, improving overall
performance, and yielding unprecedented abilities in skill and knowledge
transfer.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:29:23 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 09:58:51 GMT""},{""version"":""v3"",""created"":""Tue, 12 Apr 2022 09:26:01 GMT""}]","2022-04-13"
"2101.07907","Sergio Casas","Sergio Casas, Wenjie Luo, Raquel Urtasun","IntentNet: Learning to Predict Intention from Raw Sensor Data","CoRL 2018",,,,"cs.RO cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to plan a safe maneuver, self-driving vehicles need to understand
the intent of other traffic participants. We define intent as a combination of
discrete high-level behaviors as well as continuous trajectories describing
future motion. In this paper, we develop a one-stage detector and forecaster
that exploits both 3D point clouds produced by a LiDAR sensor as well as
dynamic maps of the environment. Our multi-task model achieves better accuracy
than the respective separate modules while saving computation, which is
critical to reducing reaction time in self-driving applications.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:31:52 GMT""}]","2021-01-21"
"2101.07908","Istv\'an Sug\'ar","Istvan P. Sugar","Electric energies of a charged sphere surrounded by electrolyte","13 pages, 3 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  By using the generalized version of the Shell Theorem analytical equations
are derived to calculate the electric energy of a charged sphere and the field
energy of the electrolyte inside and around the sphere. These electric energies
are calculated as a function of the ion concentration of the electrolyte. The
work needed to build up the charged sphere (i.e. the total charge-charge
interaction energy) decreases with increasing ion concentration of the
electrolyte because of the screening effect of the electrolyte on the
charge-charge interaction. The energy needed to build up the charged sphere
appears as sum of the field energy of the electrolyte and the polarization
energy of the electrolyte ions. At zero ion concentration the field energy of
the electrolyte is equal with the charge-charge interaction energy, while the
polarization energy is zero. At high ion concentrations 50% of the
charge-charge interaction energy appears as the polarization energy of ions,
25% as the field energy of the electrolyte inside the sphere and 25% as the
field energy of the electrolyte around the sphere.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:37:22 GMT""}]","2021-01-21"
"2101.07909","Thomas Hogancamp","Thomas Hogancamp","Broadening global families of anti-plane shear equilibria","21 pages, 2 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a global bifurcation theory for two classes of nonlinear elastic
materials. It is supposed that they are subjected to anti-plane shear
deformation and occupy an infinite cylinder in the reference configuration.
Curves of solutions to the corresponding elastostatic problem are constructed
using analytic global bifurcation theory. The curve associated with first class
is shown to exhibit broadening behavior, while for the second we find that the
governing equation undergoes a loss ellipticity in the limit. A sequence of
solutions undergoes broadening when their effective supports grow without
bound. This phenomena has received considerable attention in the context of
solitary water waves; it has been predicted numerically, yet it remains to be
proven rigorously. The breakdown of ellipticity is related to cracks and
instability making it an important aspect of the theory of failure mechanics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:39:21 GMT""}]","2021-01-21"
"2101.07910","Maryam Vahdat Pour","Maryam Vahdat Pour, Zhuo Li, Lei Ma, Hadi Hemmati","A Search-Based Testing Framework for Deep Neural Networks of Source Code
  Embedding","ICST 2021",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past few years, deep neural networks (DNNs) have been continuously
expanding their real-world applications for source code processing tasks across
the software engineering domain, e.g., clone detection, code search, comment
generation. Although quite a few recent works have been performed on testing of
DNNs in the context of image and speech processing, limited progress has been
achieved so far on DNN testing in the context of source code processing, that
exhibits rather unique characteristics and challenges.
  In this paper, we propose a search-based testing framework for DNNs of source
code embedding and its downstream processing tasks like Code Search. To
generate new test inputs, we adopt popular source code refactoring tools to
generate the semantically equivalent variants. For more effective testing, we
leverage the DNN mutation testing to guide the testing direction. To
demonstrate the usefulness of our technique, we perform a large-scale
evaluation on popular DNNs of source code processing based on multiple
state-of-the-art code embedding methods (i.e., Code2vec, Code2seq and
CodeBERT). The testing results show that our generated adversarial samples can
on average reduce the performance of these DNNs from 5.41% to 9.58%. Through
retraining the DNNs with our generated adversarial samples, the robustness of
DNN can improve by 23.05% on average. The evaluation results also show that our
adversarial test generation strategy has the least negative impact (median of
3.56%), on the performance of the DNNs for regular test data, compared to the
other methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:40:44 GMT""}]","2021-01-21"
"2101.07911","Baolei Liu","Baolei Liu, Jiayan Liao, Yiliao Song, Jie Lu, Jiajia Zhou, Fan Wang","Multiplexed structured illumination super-resolution imaging with
  time-domain upconversion nanoparticles","10 pages, 5 figures",,"10.1039/D1NA00765C",,"physics.optics cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emerging optical multiplexing within nanoscale shows super-capacity in
encoding information by using the time-domain fingerprints from uniform
nanoparticles. However, the optical diffraction limit compromises the decoding
throughput and accuracy of the nanoparticles during wide-field imaging. This,
in turn, challenges the quality of nanoparticles to afford the modulated
excitation condition, and further to retain the multiplexed optical
fingerprints for super-resolution multiplexing. Here we report a tailor-made
time-domain super-resolution method with the lifetime-engineered upconversion
nanoparticles for multiplexing. We demonstrate that the nanoparticles are
bright, uniform, and stable under structured illumination, which supports a
lateral resolution of 186 nm, less than 1/4th of the excitation wavelength. We
further develop a deep learning algorithm to coordinate with super-resolution
images for more accurate decoding compared to a numeric algorithm. We
demonstrate a three-channel sub-diffraction-limit imaging-based optical
multiplexing with decoding accuracies above 93% for each channel, and larger
than 60% accuracies for potential seven-channel multiplexing. The improved
resolution provides high throughput by resolving the particles within the
optical limit, which enables higher multiplexing capacity in space. This
time-domain super-resolution multiplexing opens a new horizon for handling the
growing amount of information content, diseases source, and security risk in
modern society
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:43:55 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 10:25:34 GMT""}]","2022-08-09"
"2101.07912","Johannes Klick","Johannes Klick, Robert Koch and Thomas Brandstetter","Epidemic? The Attack Surface of German Hospitals during the COVID-19
  Pandemic","Preprint for NATO CCDCOE Annual International Conference on Cyber
  Conflict (CyCon) [Paper submitted to Peer Review Process]",,,,"cs.CR cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In our paper we analyze the attack surface of German hospitals and healthcare
providers in 2020 during the COVID-19 Pandemic. The analysis looked at the
publicly visible attack surface utilizing a Distributed Cyber Recon System,
utilizing distributed Internet scanning, Big Data methods and scan data of
1,483 GB from more than 89 different global Internet scans. From the 1,555
identified German clinical entities, security posture analysis was conducted by
looking at more than 13,000 service banners for version identification and
subsequent CVE-based vulnerability identification. Primary analysis shows that
32 percent of the analyzed services were determined as vulnerable to various
degrees and 36 percent of all hospitals showed numerous vulnerabilities.
Further resulting vulnerability statistics were mapped against size of
organization and hospital bed count.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:45:02 GMT""}]","2021-01-21"
"2101.07913","Mohamed Ali Belabbas","Yinai Fan, Shenyu Liu and Mohamed-Ali Belabbas","Geometric Heat Flow Method for Legged Locomotion Planning",,,,,"math.OC cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose in this paper a motion planning method for legged robot locomotion
based on Geometric Heat Flow framework. The motion planning task is challenging
due to the hybrid nature of dynamics and contact constraints. We encode the
hybrid dynamics and constraints into Riemannian inner product, and this inner
product is defined so that short curves correspond to admissible motions for
the system. We rely on the affine geometric heat flow to deform an arbitrary
path connecting the desired initial and final states to this admissible motion.
The method is able to automatically find the trajectory of robot's center of
mass, feet contact positions and forces on uneven terrain.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:46:40 GMT""}]","2021-01-21"
"2101.07914","Jiang Wenqain","Wenqian Jiang, Junyang Jin","Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA
  data","10 pages, 6 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diagnosis of ice accretion on wind turbine blades is all the time a hard nut
to crack in condition monitoring of wind farms. Existing methods focus on
mechanism analysis of icing process, deviation degree analysis of feature
engineering. However, there have not been deep researches of neural networks
applied in this field at present. Supervisory control and data acquisition
(SCADA) makes it possible to train networks through continuously providing not
only operation parameters and performance parameters of wind turbines but also
environmental parameters and operation modes. This paper explores the
possibility that using convolutional neural networks (CNNs), generative
adversarial networks (GANs) and domain adaption learning to establish
intelligent diagnosis frameworks under different training scenarios.
Specifically, PGANC and PGANT are proposed for sufficient and non-sufficient
target wind turbine labeled data, respectively. The basic idea is that we
consider a two-stage training with parallel GANs, which are aimed at capturing
intrinsic features for normal and icing samples, followed by classification CNN
or domain adaption module in various training cases. Model validation on three
wind turbine SCADA data shows that two-stage training can effectively improve
the model performance. Besides, if there is no sufficient labeled data for a
target turbine, which is an extremely common phenomenon in real industrial
practices, the addition of domain adaption learning makes the trained model
show better performance. Overall, our proposed intelligent diagnosis frameworks
can achieve more accurate detection on the same wind turbine and more
generalized capability on a new wind turbine, compared with other machine
learning models and conventional CNNs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:46:52 GMT""}]","2022-04-01"
"2101.07915","Carlo Barbieri","Luigi Coraggio, Saori Pastore and Carlo Barbieri","Editorial: The Future of Nuclear Structure: Challenges and Opportunities
  in the Microscopic Description of Nuclei","Editorial for a Topical Review on ab initio nuclear theory being
  published on FRONTIERS in Physics; accepted version (in print)",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The past two decades have witnessed tremendous progress in the microscopic
description of atomic nuclei. The Topical Review `The Future of Nuclear
Structure' aims at summarizing the current state-of-the-art microscopic
calculations in Nuclear Theory and to give a useful reference for young
researches who wish to learn more about this exciting discipline.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:57:12 GMT""}]","2021-01-21"
"2101.07916","Keti Tenenblat","Fabio Nunes da Silva and Keti Tenenblat","Soliton Solutions to the Curve Shortening Flow on the 2-dimensional
  hyperbolic plane","22 pages, in English, 16 figures",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We show that a curve is a soliton solution to the curve shortening flow if
and only if its geodesic curvature can be written as the inner product between
its tangent vector field and a fixed vector of the 3-dimensional Minkowski
space. We use this characterization to provide a qualitative study of the
solitons. We show that for each fixed vector there is a 2-parameter family of
soliton solutions to the curve shortening flow on the 2-dimensional hyperbolic
space. Moreover, we prove that each soliton is defined on the entire real line,
it is embedded and its geodesic curvature converges to a constant at each end.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:03:46 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jan 2021 14:31:50 GMT""}]","2021-02-01"
"2101.07917","Jos\'e Villanueva","Mart\'in Molina and J.R. Villanueva","On the thermodynamics of the Hayward black hole","Accepted for publication in Class. Quantum Grav",,"10.1088/1361-6382/abdd47",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In light of the growing interest in the Hayward black hole solution, a
detailed study on the corresponding lapse function and its roots is presented.
The lapse function is expressed in terms of the classical Schwarzschild radius
$r_s$ and the Hayward's parameter $l$. Both of these quantities are used as
thermodynamic variables to find related thermodynamic quantities. In this
context, the variable $l$ is associated with a canonical conjugate variable
$\mathcal{F}_H$, and a free energy $\Xi$. Moreover, a second order phase
transition is found to appears at $l\approx0.333\,r_s$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:05:33 GMT""}]","2021-06-09"
"2101.07918","HongChien Yu","HongChien Yu, Zhuyun Dai, Jamie Callan","PGT: Pseudo Relevance Feedback Using a Graph-Based Transformer","Accepted at ECIR 2021 (short paper track)",,,,"cs.IR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most research on pseudo relevance feedback (PRF) has been done in vector
space and probabilistic retrieval models. This paper shows that
Transformer-based rerankers can also benefit from the extra context that PRF
provides. It presents PGT, a graph-based Transformer that sparsifies attention
between graph nodes to enable PRF while avoiding the high computational
complexity of most Transformer architectures. Experiments show that PGT
improves upon non-PRF Transformer reranker, and it is at least as accurate as
Transformer PRF models that use full attention, but with lower computational
costs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:07:47 GMT""}]","2021-01-21"
"2101.07919","Jonas Krampe","Alexander Braumann, Jonas Krampe, Jens-Peter Kreiss and Efstathios
  Paparoditis","Estimation of the Distribution of the Individual Reproduction Number:
  The Case of the COVID-19 Pandemic",,,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the problem of estimating the distribution of the individual
reproduction number governing the COVID-19 pandemic. Under the assumption that
this random variable follows a Negative Binomial distribution, we focus on
constructing estimators of the parameters of this distribution using reported
infection data and taking into account issues like under-reporting or the time
behavior of the infection and of the reporting processes. To this end, we
extract information from regionally dissaggregated data reported by German
health authorities, in order to estimate not only the mean but also the
variance of the distribution of the individual reproduction number. In contrast
to the mean, the latter parameter also depends on the unknown under-reporting
rate of the pandemic. The estimates obtained allow not only for a better
understanding of the time-varying behavior of the expected value of the
individual reproduction number but also of its dispersion, for the construction
of bootstrap confidence intervals and for a discussion of the implications of
different policy interventions. Our methodological investigations are
accompanied by an empirical study of the development of the COVID-19 pandemic
in Germany, which shows a strong overdispersion of the individual reproduction
number.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:17:56 GMT""}]","2021-01-21"
"2101.07920","Emre Sariyildiz","Emre Sariyildiz","A Guide to Design Disturbance Observer-based Motion Control Systems in
  Discrete-time Domain","IEEE International Conference on Mechatronics (ICM2021)",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper analyses and synthesises the Disturbance Observer (DOb) based
motion control systems in the discrete-time domain. By employing Bode Integral
Theorem, it is shown that continuous-time analysis methods fall-short in
explaining the dynamic behaviours of the DOb-based robust motion controllers
implemented by computers and microcontrollers. For example, continuous-time
analysis methods cannot explain why the robust stability and performance of the
digital motion controller deteriorate as the bandwidth of the DOb increases.
Therefore, unexpected dynamic responses (e.g., poor stability and performance,
and high-sensitivity to disturbances and noise) may be observed when the
parameters of the digital robust motion controller are tuned by using
continuous-time synthesis methods in practice. This paper also analytically
derives the robust stability and performance constraints of the DOb-based
motion controllers in the discrete-time domain. The proposed design constraints
allow one to systematically synthesise a high-performance digital robust motion
controller. The validity of the proposed analysis and synthesis methods are
verified by simulations.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:24:24 GMT""}]","2021-01-21"
"2101.07921","Petr Navratil","Sofia Quaglioni and Petr Navratil","Nuclear Resonances, Scattering and Reactions from First Principles:
  Progress and Prospects","9 pages, 7 figures (one more figure than in the published version)","Nuclear Physics News, 30:4, 12-16 (2020)","10.1080/10619127.2020.1752089",,"nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a brief overview of recent developments in ab initio calculations
of nuclear scattering and reactions with a focus on applications of the no-core
shell model with continuum method.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:33:58 GMT""}]","2021-01-21"
"2101.07922","Valeriia Cherepanova","Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan,
  John Dickerson, Gavin Taylor, Tom Goldstein","LowKey: Leveraging Adversarial Attacks to Protect Social Media Users
  from Facial Recognition","Published as a conference paper at ICLR 2021",,,,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Facial recognition systems are increasingly deployed by private corporations,
government agencies, and contractors for consumer services and mass
surveillance programs alike. These systems are typically built by scraping
social media profiles for user images. Adversarial perturbations have been
proposed for bypassing facial recognition systems. However, existing methods
fail on full-scale systems and commercial APIs. We develop our own adversarial
filter that accounts for the entire image processing pipeline and is
demonstrably effective against industrial-grade pipelines that include face
detection and large scale databases. Additionally, we release an easy-to-use
webtool that significantly degrades the accuracy of Amazon Rekognition and the
Microsoft Azure Face Recognition API, reducing the accuracy of each to below
1%.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:40:06 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 04:23:22 GMT""}]","2021-01-26"
"2101.07923","Fayin Wang","G. Q. Zhang, Zuo-Lin Tu, F. Y. Wang (NJU)","Possible periodic activity in the short bursts of SGR 1806-20:
  connection to fast radio bursts","14 pages, 4 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abdd27",,"astro-ph.HE","http://creativecommons.org/publicdomain/zero/1.0/","  Magnetars are highly magnetized neutron stars that are characterized by
recurrent emission of short-duration bursts in soft gamma-rays/hard X-rays.
Recently, FRB 200428 were found to be associated with an X-ray burst from a
Galactic magnetar. Two fast radio bursts (FRBs) show mysterious periodic
activity. However, whether magnetar X-ray bursts are periodic phenomena is
unclear. In this paper, we investigate the period of SGR 1806-20 activity. More
than 3000 short bursts observed by different telescopes are collected,
including the observation of RXTE, HETE-2, ICE and Konus. We consider the
observation windows and divide the data into two sub-samples to alleviate the
effect of unevenly sample. The epoch folding and Lomb-Scargle methods are used
to derive the period of short bursts. We find a possible period about $ 398.20
\pm 25.45 $ days. While other peaks exist in the periodograms. If the period is
real, the connection between short bursts of magnetars and FRBs should be
extensively investigated.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:54:48 GMT""}]","2021-03-17"
"2101.07924","Chengzhi Zhang","Heng Zhang, Chengzhi Zhang","Using Full-text Content of Academic Articles to Build a Methodology
  Taxonomy of Information Science in China",,,,,"cs.DL cs.CL","http://creativecommons.org/licenses/by/4.0/","  Research on the construction of traditional information science methodology
taxonomy is mostly conducted manually. From the limited corpus, researchers
have attempted to summarize some of the research methodology entities into
several abstract levels (generally three levels); however, they have been
unable to provide a more granular hierarchy. Moreover, updating the methodology
taxonomy is traditionally a slow process. In this study, we collected full-text
academic papers related to information science. First, we constructed a basic
methodology taxonomy with three levels by manual annotation. Then, the word
vectors of the research methodology entities were trained using the full-text
data. Accordingly, the research methodology entities were clustered and the
basic methodology taxonomy was expanded using the clustering results to obtain
a methodology taxonomy with more levels. This study provides new concepts for
constructing a methodology taxonomy of information science. The proposed
methodology taxonomy is semi-automated; it is more detailed than conventional
schemes and the speed of taxonomy renewal has been enhanced.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:56:43 GMT""}]","2021-01-21"
"2101.07925","Xing Lu","Xing Lu, Shanghuo Li, Adam Ginsburg, Steven N. Longmore, J. M.
  Diederik Kruijssen, Daniel L. Walker, Siyi Feng, Qizhou Zhang, Cara
  Battersby, Thushara Pillai, Elisabeth A. C. Mills, Jens Kauffmann, Yu Cheng,
  Shu-ichiro Inutsuka","ALMA Observations of Massive Clouds in the Central Molecular Zone:
  Ubiquitous Protostellar Outflows","43 pages, 25 figures, 3 tables, accepted for publication in ApJ",,"10.3847/1538-4357/abde3c",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We observe 1.3~mm spectral lines at 2000~AU resolution toward four massive
molecular clouds in the Central Molecular Zone of the Galaxy to investigate
their star formation activities. We focus on several potential shock tracers
that are usually abundant in protostellar outflows, including SiO, SO,
CH$_3$OH, H$_2$CO, HC$_3$N, and HNCO. We identify 43 protostellar outflows,
including 37 highly likely ones and 6 candidates. The outflows are found toward
both known high-mass star forming cores and less massive, seemingly quiescent
cores, while 791 out of the 834 cores identified based on the continuum do not
have detected outflows. The outflow masses range from less than 1~$M_\odot$ to
a few tens of $M_\odot$, with typical uncertainties of a factor of 70. We do
not find evidence of disagreement between relative molecular abundances in
these outflows and in nearby analogs such as the well-studied L1157 and
NGC7538S outflows. The results suggest that i) protostellar accretion disks
driving outflows ubiquitously exist in the CMZ environment, ii) the large
fraction of candidate starless cores is expected if these clouds are at very
early evolutionary phases, with a caveat on the potential incompleteness of the
outflows, iii) high-mass and low-mass star formation is ongoing simultaneously
in these clouds, and iv) current data do not show evidence of difference
between the shock chemistry in the outflows that determines the molecular
abundances in the CMZ environment and in nearby clouds.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:00:01 GMT""}]","2021-03-24"
"2101.07926","Irena Papst","Irena Papst, Kevin P. O'Keeffe, Steven H. Strogatz","Modeling the interplay between seasonal flu outcomes and individual
  vaccination decisions","20 pages, 6 figures",,,,"q-bio.PE math.DS","http://creativecommons.org/licenses/by/4.0/","  Seasonal influenza presents an ongoing challenge to public health. The rapid
evolution of the flu virus necessitates annual vaccination campaigns, but the
decision to get vaccinated or not in a given year is largely voluntary, at
least in the United States, and many people decide against it. In early
attempts to model these yearly flu vaccine decisions, it was often assumed that
individuals behave rationally, and do so with perfect information --
assumptions that allowed the techniques of classical economics and game theory
to be applied. However, the usual assumptions are contradicted by the emerging
empirical evidence about human decision-making behavior in this context. We
develop a simple model of coupled disease spread and vaccination dynamics that
instead incorporates experimental observations from social psychology to model
annual vaccine decision-making more realistically. We investigate
population-level effects of these new decision-making assumptions, with the
goal of understanding whether the population can self-organize into a state of
herd immunity, and if so, under what conditions. Our model agrees with
established results while also revealing more subtle population-level behavior,
including biennial oscillations about the herd immunity threshold.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:05:00 GMT""}]","2021-01-21"
"2101.07927","Yuanhao Gong","Yuanhao Gong, Wenming Tang, Lebin Zhou, Lantao Yu, Guoping Qiu","A Discrete Scheme for Computing Image's Weighted Gaussian Curvature",,,,,"cs.CV eess.IV eess.SP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weighted Gaussian Curvature is an important measurement for images. However,
its conventional computation scheme has low performance, low accuracy and
requires that the input image must be second order differentiable. To tackle
these three issues, we propose a novel discrete computation scheme for the
weighted Gaussian curvature. Our scheme does not require the second order
differentiability. Moreover, our scheme is more accurate, has smaller support
region and computationally more efficient than the conventional schemes.
Therefore, our scheme holds promise for a large range of applications where the
weighted Gaussian curvature is needed, for example, image smoothing, cartoon
texture decomposition, optical flow estimation, etc.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:15:51 GMT""}]","2021-01-21"
"2101.07928","Adam Mate","Adam Mate, Travis Hagan, Eduardo Cotilla-Sanchez, Ted K. A. Brekken,
  Annette Von Jouanne","Impacts of Earthquakes on Electrical Grid Resilience","5 pages. 1 figure. 1 table","Proceedings of the 2021 IEEE/IAS 57th Industrial and Commercial
  Power Systems Technical Conference, pp. 1-5, Apr. 2021","10.1109/ICPS51807.2021.9416632",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  One of the most complex and devastating disaster scenarios that the
U.S.~Pacific Northwest region and the state of Oregon faces is a large
magnitude Cascadia Subduction Zone earthquake event. The region's electrical
grid lacks in resilience against the destruction of a megathrust earthquake, a
powerful tsunami, hundreds of aftershocks and increased volcanic activity, all
of which are highly probable components of this hazard. This research seeks to
catalyze further understanding and improvement of resilience. By systematizing
power system related experiences of historical earthquakes, and collecting
practical and innovative ideas from other regions on how to enhance network
design, construction, and operation, important steps are being taken toward a
more resilient, earthquake-resistant grid. This paper presents relevant
findings in an effort to be an overview and a useful guideline for those who
are also working towards greater electrical grid resilience.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:17:08 GMT""},{""version"":""v2"",""created"":""Tue, 27 Dec 2022 12:17:59 GMT""}]","2022-12-29"
"2101.07929","Ruibing Jin","Ruibing Jin, Guosheng Lin, and Changyun Wen","Online Active Proposal Set Generation for Weakly Supervised Object
  Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To reduce the manpower consumption on box-level annotations, many weakly
supervised object detection methods which only require image-level annotations,
have been proposed recently. The training process in these methods is
formulated into two steps. They firstly train a neural network under weak
supervision to generate pseudo ground truths (PGTs). Then, these PGTs are used
to train another network under full supervision. Compared with fully supervised
methods, the training process in weakly supervised methods becomes more complex
and time-consuming. Furthermore, overwhelming negative proposals are involved
at the first step. This is neglected by most methods, which makes the training
network biased towards to negative proposals and thus degrades the quality of
the PGTs, limiting the training network performance at the second step. Online
proposal sampling is an intuitive solution to these issues. However, lacking of
adequate labeling, a simple online proposal sampling may make the training
network stuck into local minima. To solve this problem, we propose an Online
Active Proposal Set Generation (OPG) algorithm. Our OPG algorithm consists of
two parts: Dynamic Proposal Constraint (DPC) and Proposal Partition (PP). DPC
is proposed to dynamically determine different proposal sampling strategy
according to the current training state. PP is used to score each proposal,
part proposals into different sets and generate an active proposal set for the
network optimization. Through experiments, our proposed OPG shows consistent
and significant improvement on both datasets PASCAL VOC 2007 and 2012, yielding
comparable performance to the state-of-the-art results.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:20:48 GMT""}]","2021-01-21"
"2101.07930","Zhen Qin","Zhen Qin, Hai Wang, Yuben Qu, Haipeng Dai, and Zhenhua Wei","Air-Ground Collaborative Mobile Edge Computing: Architecture,
  Challenges, and Opportunities",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  By pushing computation, cache, and network control to the edge, mobile edge
computing (MEC) is expected to play a leading role in fifth generation (5G) and
future sixth generation (6G). Nevertheless, facing ubiquitous fast-growing
computational demands, it is impossible for a single MEC paradigm to
effectively support high-quality intelligent services at end user equipments
(UEs). To address this issue, we propose an air-ground collaborative MEC
(AGC-MEC) architecture in this article. The proposed AGC-MEC integrates all
potentially available MEC servers within air and ground in the envisioned 6G,
by a variety of collaborative ways to provide computation services at their
best for UEs. Firstly, we introduce the AGC-MEC architecture and elaborate
three typical use cases. Then, we discuss four main challenges in the AGC-MEC
as well as their potential solutions. Next, we conduct a case study of
collaborative service placement for AGC-MEC to validate the effectiveness of
the proposed collaborative service placement strategy. Finally, we highlight
several potential research directions of the AGC-MEC.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:21:35 GMT""}]","2021-01-21"
"2101.07931","Rohan Sukumaran","Joseph Bae, Rohan Sukumaran, Sheshank Shankar, Saurish Srivastava,
  Rohan Iyer, Aryan Mahindra, Qamil Mirza, Maurizio Arseni, Anshuman Sharma,
  Saras Agrawal, Orna Mukhopadhyay, Colin Kang, Priyanshi Katiyar, Apurv
  Shekhar, Sifat Hasan, Krishnendu Dasgupta, Darshan Gandhi, Sethuramen TV,
  Parth Patwa, Ishaan Singh, Abhishek Singh and Ramesh Raskar","MIT SafePaths Card (MiSaCa): Augmenting Paper Based Vaccination Cards
  with Printed Codes","8 pages, 4 Figures, 1 Table",,,,"cs.CY cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this early draft, we describe a user-centric, card-based system for
vaccine distribution. Our system makes use of digitally signed QR codes and
their use for phased vaccine distribution, vaccine
administration/record-keeping, immunization verification, and follow-up symptom
reporting. Furthermore, we propose and describe a complementary scanner app
system to be used by vaccination clinics, public health officials, and
immunization verification parties to effectively utilize card-based framework.
We believe that the proposed system provides a privacy-preserving and efficient
framework for vaccine distribution in both developed and developing regions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:22:56 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 16:55:23 GMT""}]","2021-01-22"
"2101.07932","Dominic Pesce","Dominic W. Pesce, Anil C. Seth, Jenny E. Greene, James A. Braatz,
  James J. Condon, Brian R. Kent, Davor Krajnovi\'c","A restless supermassive black hole in the galaxy J0437+2456","17 pages, 8 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abde3d",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the results from an observing campaign to confirm the peculiar
motion of the supermassive black hole (SMBH) in J0437+2456 first reported in
Pesce et al. (2018). Deep observations with the Arecibo Observatory have
yielded a detection of neutral hydrogen (HI) emission, from which we measure a
recession velocity of 4910 km s$^{-1}$ for the galaxy as a whole. We have also
obtained near-infrared integral field spectroscopic observations of the
galactic nucleus with the Gemini North telescope, yielding spatially resolved
stellar and gas kinematics with a central velocity at the innermost radii
($0.1^{\prime \prime} \approx 34$ pc) of 4860 km s$^{-1}$. Both measurements
differ significantly from the $\sim$4810 km s$^{-1}$ H$_2$O megamaser velocity
of the SMBH, supporting the prior indications of a velocity offset between the
SMBH and its host galaxy. However, the two measurements also differ
significantly from one another, and the galaxy as a whole exhibits a complex
velocity structure that implies the system has recently been dynamically
disturbed. These results make it clear that the SMBH is not at rest with
respect to the systemic velocity of the galaxy, though the specific nature of
the mobile SMBH -- i.e., whether it traces an ongoing galaxy merger, a binary
black hole system, or a gravitational wave recoil event -- remains unclear.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:27:10 GMT""}]","2021-03-24"
"2101.07933","Yuanhao Gong","Yuanhao Gong, Wenming Tang, Lebin Zhou, Lantao Yu, Guoping Qiu","Quarter Laplacian Filter for Edge Aware Image Processing",,,,,"eess.IV cs.CV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a quarter Laplacian filter that can preserve corners and
edges during image smoothing. Its support region is $2\times2$, which is
smaller than the $3\times3$ support region of Laplacian filter. Thus, it is
more local. Moreover, this filter can be implemented via the classical box
filter, leading to high performance for real time applications. Finally, we
show its edge preserving property in several image processing tasks, including
image smoothing, texture enhancement, and low-light image enhancement. The
proposed filter can be adopted in a wide range of image processing
applications.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:29:54 GMT""}]","2021-01-21"
"2101.07934","Xinyue Qi","Xinyue Qi, Shouhao Zhou, Christine Peterson, Yucai Wang, Xinying Fang,
  Michael L. Wang, Chan Shen","Meta-analysis of Censored Adverse Events",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Meta-analysis is a powerful tool for drug safety assessment by synthesizing
treatment-related toxicological findings from independent clinical trials.
However, published clinical studies may or may not report all adverse events
(AEs) if the observed number of AEs were fewer than a pre-specified
study-dependent cutoff. Subsequently, with censored information ignored, the
estimated incidence rate of AEs could be significantly biased. To address this
non-ignorable missing data problem in meta-analysis, we propose a Bayesian
multilevel regression model to accommodate the censored rare event data. The
performance of the proposed Bayesian model of censored data compared to other
existing methods is demonstrated through simulation studies under various
censoring scenarios. Finally, the proposed approach is illustrated using data
from a recent meta-analysis of 125 clinical trials involving PD-1/PD-L1
inhibitors with respect to their toxicity profiles.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:30:56 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 15:26:53 GMT""}]","2022-02-15"
"2101.07935","Kyle Crocker","Kyle Crocker, Joshua Johnson, Wolfgang Pfeifer, Carlos Castro, and
  Ralf Bundschuh","A quantitative model for a nanoscale switch accurately predicts thermal
  actuation behavior",,,,,"q-bio.BM physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manipulation of temperature can be used to actuate DNA origami nano-hinges
containing gold nanoparticles. We develop a physical model of this system that
uses partition function analysis of the interaction between the nano-hinge and
nanoparticle to predict the probability that the nano-hinge is open at a given
temperature. The model agrees well with experimental data and predicts
experimental conditions that allow the actuation temperature of the nano-hinge
to be tuned over a range of temperatures from $30$${}^{\circ}\mathrm{C}$ to
$45$${}^{\circ}\mathrm{C}$. Additionally, the model reveals surprising physical
constraints on the system. This combination of physical insight and predictive
potential is likely to inform future designs that integrate nanoparticles into
dynamic DNA origami structures. Furthermore, our modeling approach could be
expanded to consider the incorporation, stability, and actuation of other types
of functional elements or actuation mechanisms integrated into nucleic acid
devices.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:31:56 GMT""}]","2021-01-21"
"2101.07936","Longfei Yan","Longfei Yan, Yuhang Chen, Chong Han, and Jinhong Yuan","Joint Inter-path and Intra-path Multiplexing for Terahertz Widely-spaced
  Multi-subarray Hybrid Beamforming Systems","30 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) communications with multi-GHz bandwidth are envisioned as a
key technology for 6G systems. Ultra-massive (UM) MIMO with hybrid beamforming
architectures are widely investigated to provide a high array gain to overcome
the huge propagation loss. However, most of the existing hybrid beamforming
architectures can only utilize the multiplexing offered by the multipath
components, i.e., inter-path multiplexing, which is very limited due to the
spatially sparse THz channel. In this paper, a widely-spaced multi-subarray
(WSMS) hybrid beamforming architecture is proposed, which improves the
multiplexing gain by exploiting a new type of intra-path multiplexing provided
by the spherical-wave propagation among k widely-spaced subarrays, in addition
to the inter-path multiplexing. The resulting multiplexing gain of WSMS
architecture is k times of the existing architectures. To harness WSMS hybrid
beamforming, a novel design problem is formulated by optimizing the number of
subarrays, subarray spacing, and hybrid beamforming matrices to maximize the
spectral efficiency, which is decomposed into two subproblems. An optimal
closed-form solution is derived for the first hybrid beamforming subproblem,
while a dominant-line-of-sight-relaxation algorithm is proposed for the second
array configuration subproblem. Extensive simulation results demonstrate that
the WSMS architecture and proposed algorithms substantially enhance the
spectral efficiency and energy efficiency.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:42:57 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 11:45:40 GMT""}]","2021-06-09"
"2101.07937","Woong-Hee Lee","Woong-Hee Lee, Mustafa Ozger, Ursula Challita, and Ki Won Sung","Noise Learning Based Denoising Autoencoder",,,"10.1109/LCOMM.2021.3091800",,"cs.LG cs.AI eess.SP","http://creativecommons.org/licenses/by/4.0/","  This letter introduces a new denoiser that modifies the structure of
denoising autoencoder (DAE), namely noise learning based DAE (nlDAE). The
proposed nlDAE learns the noise of the input data. Then, the denoising is
performed by subtracting the regenerated noise from the noisy input. Hence,
nlDAE is more effective than DAE when the noise is simpler to regenerate than
the original data. To validate the performance of nlDAE, we provide three case
studies: signal restoration, symbol demodulation, and precise localization.
Numerical results suggest that nlDAE requires smaller latent space dimension
and smaller training dataset compared to DAE.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:45:13 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 10:13:31 GMT""}]","2022-01-24"
"2101.07938","Yiran He","Yiran He and Hoi-To Wai","Identifying First-order Lowpass Graph Signals using Perron Frobenius
  Theorem","5 pages, 11 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the blind identification of graph filters from
graph signals. Our aim is to determine if the graph filter generating the graph
signals is first-order lowpass without knowing the graph topology. Notice that
lowpass graph filter is a common prerequisite for applying graph signal
processing tools for sampling, denoising, and graph learning. Our method is
inspired by the Perron Frobenius theorem, which observes that for first-order
lowpass graph filter, the top eigenvector of output covariance would be the
only eigenvector with elements of the same sign. Utilizing this observation, we
develop a simple detector that answers if a given data set is produced by a
first-order lowpass graph filter. We analyze the effects of finite-sample,
graph size, observation noise, strength of lowpass filter, on the detector's
performance. Numerical experiments on synthetic and real data support our
findings.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:50:57 GMT""}]","2021-01-21"
"2101.07939","Shigeo Kawata","Yan-Jun Gu, Shigeo Kawata and Sergei V. Bulanov","Dynamic mitigation of filamentation instability and magnetic
  reconnection in sheet-current sustained plasma","13 pages, 10 figures",,,,"physics.plasm-ph physics.comp-ph physics.space-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dynamic mitigation is presented for filamentation instability and magnetic
reconnection in a plasm driven by a wobbling electron sheet current. The
wobbling current introduces an oscillating perturbation and smooths the
perturbation. The sheet current creates an anti-parallel magnetic field in
plasma. The initial small perturbation induces the electron beam filamentation
and the magnetic reconnection. When the wobbling or oscillation motion is added
to the sheet electron beam along the sheet current surface, the perturbation
phase is mixed and consequently the instability growth is delayed remarkably.
Normally plasma instabilities are discussed by the growth rate, because it
would be difficult to measure or detect the phase of the perturbations in
plasmas. However, the phase of perturbation can be controlled externally, for
example, by the driver wobbling motion. The superimposition of perturbations
introduced actively results in the perturbation smoothing, and the instability
growth can be reduced, like feed-forward control.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:51:41 GMT""}]","2021-01-21"
"2101.07940","Yihua Wang","Da Jiang, Yinping Pan, Shiyuan Wang, Yishi Lin, Connor M. Holland,
  John R. Kirtley, Xianhui Chen, Jun Zhao, Lei Chen, Shaoyu Yin, Yihua Wang","Observation of robust edge superconductivity in Fe(Se,Te) under strong
  magnetic perturbation",,"Science Bulletin, 2021, 66(5):425-432","10.1016/j.scib.2020.10.006",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The iron-chalcogenide high temperature superconductor Fe(Se,Te) (FST) has
been reported to exhibit complex magnetic ordering and nontrivial band topology
which may lead to novel superconducting phenomena. However, the recent studies
have so far been largely concentrated on its band and spin structures while its
mesoscopic electronic and magnetic response, crucial for future device
applications, has not been explored experimentally. Here, we used scanning
superconducting quantum interference device microscopy for its sensitivity to
both local diamagnetic susceptibility and current distribution in order to
image the superfluid density and supercurrent in FST. We found that in FST with
10% interstitial Fe, whose magnetic structure was heavily disrupted, bulk
superconductivity was significantly suppressed whereas edge still preserved
strong superconducting diamagnetism. The edge dominantly carried supercurrent
despite of a very long magnetic penetration depth. The temperature dependence
of the superfluid density and supercurrent distribution were distinctively
different between the edge and the bulk. Our Heisenberg modeling showed that
magnetic dopants stabilize anti-ferromagnetic spin correlation along the edge,
which may contribute towards its robust superconductivity. Our observations
hold implication for FST as potential platforms for topological quantum
computation and superconducting spintronics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:54:39 GMT""}]","2021-01-21"
"2101.07941","Enrico Valdinoci","Serena Dipierro and Enrico Valdinoci","Elliptic partial differential equations from an elementary viewpoint",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  These notes are the outcome of some courses taught to undergraduate and
graduate students from the University of Western Australia, the Pontif\'{\i}cia
Universidade Cat\'olica do Rio de Janeiro, the Indian Institute of Technology
Gandhinagar and the Ukrainian Catholic University in 2021 and 2022.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 02:58:17 GMT""},{""version"":""v10"",""created"":""Fri, 21 Oct 2022 09:17:18 GMT""},{""version"":""v11"",""created"":""Tue, 24 Jan 2023 23:25:56 GMT""},{""version"":""v12"",""created"":""Sat, 6 May 2023 13:36:44 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 05:42:35 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 12:04:19 GMT""},{""version"":""v4"",""created"":""Thu, 25 Nov 2021 14:09:47 GMT""},{""version"":""v5"",""created"":""Fri, 17 Dec 2021 07:59:13 GMT""},{""version"":""v6"",""created"":""Tue, 15 Mar 2022 03:29:22 GMT""},{""version"":""v7"",""created"":""Mon, 25 Apr 2022 09:30:31 GMT""},{""version"":""v8"",""created"":""Mon, 6 Jun 2022 09:27:23 GMT""},{""version"":""v9"",""created"":""Sat, 20 Aug 2022 09:48:01 GMT""}]","2023-05-09"
"2101.07942","Rishav Chakravarti","Rishav Chakravarti, Avirup Sil","Towards Confident Machine Reading Comprehension",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been considerable progress on academic benchmarks for the Reading
Comprehension (RC) task with State-of-the-Art models closing the gap with human
performance on extractive question answering. Datasets such as SQuAD 2.0 & NQ
have also introduced an auxiliary task requiring models to predict when a
question has no answer in the text. However, in production settings, it is also
necessary to provide confidence estimates for the performance of the underlying
RC model at both answer extraction and ""answerability"" detection. We propose a
novel post-prediction confidence estimation model, which we call Mr.C (short
for Mr. Confident), that can be trained to improve a system's ability to
refrain from making incorrect predictions with improvements of up to 4 points
as measured by Area Under the Curve (AUC) scores. Mr.C can benefit from a novel
white-box feature that leverages the underlying RC model's gradients.
Performance prediction is particularly important in cases of domain shift (as
measured by training RC models on SQUAD 2.0 and evaluating on NQ), where Mr.C
not only improves AUC, but also traditional answerability prediction (as
measured by a 5 point improvement in F1).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:02:12 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 04:32:30 GMT""}]","2021-02-25"
"2101.07943","Rafael Fernandes","Rafael M. Fernandes and Liang Fu","Charge-$4e$ superconductivity from multi-component nematic pairing:
  Application to twisted bilayer graphene","5 pages plus Supplementary Material","Phys. Rev. Lett. 127, 047001 (2021)","10.1103/PhysRevLett.127.047001",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that unconventional nematic superconductors with multi-component
order parameter in lattices with three-fold and six-fold rotational symmetries
support a charge-$4e$ vestigial superconducting phase above $T_c$. The
charge-$4e$ state, which is a condensate of four-electron bound states that
preserve the rotational symmetry of the lattice, is nearly degenerate with a
competing vestigial nematic state, which is non-superconducting and breaks the
rotational symmetry. This robust result is the consequence of a hidden discrete
symmetry in the Ginzburg-Landau theory, which permutes quantities in the gauge
sector and in the crystalline sector of the symmetry group. We argue that
random strain generally favors the charge-$4e$ state over the nematic phase, as
it acts as a random-mass to the former but as a random-field to the latter.
Thus, we propose that two-dimensional inhomogeneous systems displaying nematic
superconductivity, such as twisted bilayer graphene, provide a promising
platform to realize the elusive charge-$4e$ superconducting phase.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:02:32 GMT""}]","2021-07-28"
"2101.07944","Junming Liu","Tianyu Bai, Junming Liu","Invariant subspace of composition operators on Hardy space","23 pages",,,,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the invariant subspace of composition operators on Hardy space
$H^p$ where the composition operators corresponding to a function $\varphi$
that is a holomorphic self-map of $\mathbb D$. Firstly, we discuss composition
operators $C_\varphi$ on subspace $H_{\alpha,\beta}^p$ of Hardy space $H^p$. We
will explore the invariant subspaces for $C_\varphi$ in various special cases.
Secondly, we consider Beurling type invariant subspace for $C_\varphi$. When
$\theta$ is a inner function, we prove that $\theta H^p$ is invariant for
$C_\varphi$ if and only if $\displaystyle{\frac{\theta\circ\varphi}{\theta}}$
belongs to $\mathcal S(\mathbb D)$. Thirdly, we obtain that $z^nH^p$ is
nontrivial invariant subspace for Deddends algebras $\mathcal D_{C_\varphi}$
when $C_\varphi$ is a compact composition operator and $\varphi$ satisfies that
$\varphi(0)=0$ and $\parallel\varphi\parallel_\infty<1$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:03:09 GMT""}]","2021-01-21"
"2101.07945","Tao Wei","Tao Wei, Angelica I Aviles-Rivero, Shuo Wang, Yuan Huang, Fiona J
  Gilbert, Carola-Bibiane Sch\""onlieb, Chang Wen Chen","Beyond Fine-tuning: Classifying High Resolution Mammograms using
  Function-Preserving Transformations","10 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of classifying mammograms is very challenging because the lesion is
usually small in the high resolution image. The current state-of-the-art
approaches for medical image classification rely on using the de-facto method
for ConvNets - fine-tuning. However, there are fundamental differences between
natural images and medical images, which based on existing evidence from the
literature, limits the overall performance gain when designed with algorithmic
approaches. In this paper, we propose to go beyond fine-tuning by introducing a
novel framework called MorphHR, in which we highlight a new transfer learning
scheme. The idea behind the proposed framework is to integrate
function-preserving transformations, for any continuous non-linear activation
neurons, to internally regularise the network for improving mammograms
classification. The proposed solution offers two major advantages over the
existing techniques. Firstly and unlike fine-tuning, the proposed approach
allows for modifying not only the last few layers but also several of the first
ones on a deep ConvNet. By doing this, we can design the network front to be
suitable for learning domain specific features. Secondly, the proposed scheme
is scalable to hardware. Therefore, one can fit high resolution images on
standard GPU memory. We show that by using high resolution images, one prevents
losing relevant information. We demonstrate, through numerical and visual
experiments, that the proposed approach yields to a significant improvement in
the classification performance over state-of-the-art techniques, and is indeed
on a par with radiology experts. Moreover and for generalisation purposes, we
show the effectiveness of the proposed learning scheme on another large
dataset, the ChestX-ray14, surpassing current state-of-the-art techniques.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:04:07 GMT""}]","2021-01-21"
"2101.07946","Douglas Ulmer","Rachel Pries and Douglas Ulmer","Every $BT_1$ group scheme appears in a Jacobian","13 pages. This paper is derived from arxiv:2010.15160 which has been
  divided and streamlined",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p$ be a prime number and let $k$ be an algebraically closed field of
characteristic $p$. A $BT_1$ group scheme over $k$ is a finite commutative
group scheme which arises as the kernel of $p$ on a $p$-divisible
(Barsotti--Tate) group. Our main result is that every $BT_1$ scheme group over
$k$ occurs as a direct factor of the $p$-torsion group scheme of the Jacobian
of an explicit curve defined over $\mathbb{F}_p$. We also treat a variant with
polarizations. Our main tools are the Kraft classification of $BT_1$ group
schemes, a theorem of Oda, and a combinatorial description of the de Rham
cohomology of Fermat curves.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:15:27 GMT""}]","2021-01-21"
"2101.07947","Zekang Li","Zekang Li, Zongjia Li, Jinchao Zhang, Yang Feng and Jie Zhou","WeChat AI & ICT's Submission for DSTC9 Interactive Dialogue Evaluation
  Track","DSTC9@AAAI2021",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We participate in the DSTC9 Interactive Dialogue Evaluation Track (Gunasekara
et al. 2020) sub-task 1 (Knowledge Grounded Dialogue) and sub-task 2
(Interactive Dialogue). In sub-task 1, we employ a pre-trained language model
to generate topic-related responses and propose a response ensemble method for
response selection. In sub-task2, we propose a novel Dialogue Planning Model
(DPM) to capture conversation flow in the interaction with humans. We also
design an integrated open-domain dialogue system containing pre-process,
dialogue model, scoring model, and post-process, which can generate fluent,
coherent, consistent, and humanlike responses. We tie 1st on human ratings and
also get the highest Meteor, and Bert-score in sub-task 1, and rank 3rd on
interactive human evaluation in sub-task 2.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:19:50 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 03:03:52 GMT""}]","2021-06-07"
"2101.07948","Ziheng Wang","Ziheng Wang","SparseDNN: Fast Sparse Deep Learning Inference on CPUs",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO. Open source library at:
https://github.com/marsupialtail/sparsednn.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:27:35 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 03:45:54 GMT""},{""version"":""v3"",""created"":""Thu, 1 Jul 2021 20:23:23 GMT""},{""version"":""v4"",""created"":""Wed, 21 Jul 2021 01:30:07 GMT""}]","2021-07-22"
"2101.07949","Desong Kong","Desong Kong and Shuhuang Xiang","Fast linear barycentric rational interpolation for singular functions
  via scaled transformations","24 pages, 32 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, applied strictly monotonic increasing scaled maps, a kind of
well-conditioned linear barycentric rational interpolations are proposed to
approximate functions of singularities at the origin, such as $x^\alpha$ for
$\alpha \in (0,1)$ and $\log(x)$. It just takes $O(N)$ flops and can achieve
fast convergence rates with the choice the scaled parameter, where $N$ is the
maximum degree of the denominator and numerator. The construction of the
rational interpolant couples rational polynomials in the barycentric form of
second kind with the transformed Jacobi-Gauss-Lobatto points. Numerical
experiments are considered which illustrate the accuracy and efficiency of the
algorithms. The convergence of the rational interpolation is also considered.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:29:29 GMT""}]","2021-01-21"
"2101.07950","Anna Vaughan","Anna Vaughan, Will Tebbutt, J.Scott Hosking and Richard E. Turner","Convolutional conditional neural processes for local climate downscaling","26 pages, 12 figures",,,,"cs.LG physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new model is presented for multisite statistical downscaling of temperature
and precipitation using convolutional conditional neural processes (convCNPs).
ConvCNPs are a recently developed class of models that allow deep learning
techniques to be applied to off-the-grid spatio-temporal data. This model has a
substantial advantage over existing downscaling methods in that the trained
model can be used to generate multisite predictions at an arbitrary set of
locations, regardless of the availability of training data. The convCNP model
is shown to outperform an ensemble of existing downscaling techniques over
Europe for both temperature and precipitation taken from the VALUE
intercomparison project. The model also outperforms an approach that uses
Gaussian processes to interpolate single-site downscaling models at unseen
locations. Importantly, substantial improvement is seen in the representation
of extreme precipitation events. These results indicate that the convCNP is a
robust downscaling model suitable for generating localised projections for use
in climate impact studies, and motivates further research into applications of
deep learning techniques in statistical downscaling.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:45:21 GMT""}]","2021-01-21"
"2101.07951","Cuihua Shen","Cuihua Shen, Mona Kasra, James O'Brien","This photograph has been altered: Testing the effectiveness of image
  forensic labeling on news image credibility","Harvard Kennedy School (HKS) Misinformation Review (2021)",,"10.37016/mr-2020-72",,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Despite the ubiquity and proliferation of images and videos in online news
environments, much of the existing research on misinformation and its
correction is solely focused on textual misinformation, and little is known
about how ordinary users evaluate fake or manipulated images and the most
effective ways to label and correct such falsities. We designed a visual
forensic label of image authenticity, Picture-O-Meter, and tested the label's
efficacy in relation to its source and placement in an experiment with 2440
participants. Our findings demonstrate that, despite human beings' general
inability to detect manipulated images on their own, image forensic labels are
an effective tool for counteracting visual misinformation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:49:51 GMT""}]","2023-03-10"
"2101.07952","Jianfeng Wang","Wenqian Zhang, Jianfeng Wang","A best bound for $\lambda_2(G)$ to guarantee $\kappa(G) \geq 2$","10 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a connected $d$-regular graph with a given order and the second
largest eigenvalue $\lambda_2(G)$. Mohar and O (private communication) asked a
challenging problem: what is the best upper bound for $\lambda_2(G)$ which
guarantees that $\kappa(G) \geq t+1$, where $1 \leq t \leq d-1$ and $\kappa(G)$
is the vertex-connectivity of $G$, which was also mentioned by Cioab\u{a}. As a
starting point, we solve this problem in the case $t =1$, and characterize all
families of extremal graphs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:54:09 GMT""}]","2021-01-21"
"2101.07953","Aimin Li","Aimin Li, Shaohua Wu, Jian Jiao, Ning Zhang, and Qinyu Zhang","New Upper Bounds on the Error Probability under ML Decoding for Spinal
  Codes and the Joint Transmission-Decoding System Design",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spinal codes are a type of capacity-achieving rateless codes that have been
proved to approach the Shannon capacity over the additive white Gaussian noise
(AWGN) channel and the binary symmetric channel (BSC). In this paper, we aim to
analyze the bounds on the error probability of Spinal codes and design a joint
transmission-decoding system. First, in the finite block-length regime, we
derive new upper bounds on the Maximum Likelihood (ML) decoding error
probability for Spinal codes over both the AWGN channel and the BSC. Then,
based on the derived bounds, we formulate a rate maximization problem. As the
solution exhibits an incremental-tail-transmission pattern, we propose an
improved transmission scheme, referred to as the thresholded incremental tail
transmission (TITT) scheme. Moreover, we also develop a dynamic TITT-matching
decoding algorithm, called the bubble decoding with memory (BD-M) algorithm, to
reduce the decoding time complexity. The TITT scheme at the transmitter and the
BD-M algorithm at the receiver jointly constitute a dynamic
transmission-decoding system for Spinal code, improving its rate performance
and decoding throughput. Theoretical analysis and simulation results are
provided to verify the superiority of the derived bounds and the proposed joint
transmission-decoding system design.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:56:41 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 03:28:12 GMT""}]","2022-04-05"
"2101.07954","Lauren J Beesley","Lauren J Beesley and Jeremy M G Taylor","Accounting for not-at-random missingness through imputation stacking","See also: Supplementary Materials",,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Not-at-random missingness presents a challenge in addressing missing data in
many health research applications. In this paper, we propose a new approach to
account for not-at-random missingness after multiple imputation through
weighted analysis of stacked multiple imputations. The weights are easily
calculated as a function of the imputed data and assumptions about the
not-at-random missingness. We demonstrate through simulation that the proposed
method has excellent performance when the missingness model is correctly
specified. In practice, the missingness mechanism will not be known. We show
how we can use our approach in a sensitivity analysis framework to evaluate the
robustness of model inference to different assumptions about the missingness
mechanism, and we provide R package StackImpute to facilitate implementation as
part of routine sensitivity analyses. We apply the proposed method to account
for not-at-random missingness in human papillomavirus test results in a study
of survival for patients diagnosed with oropharyngeal cancer.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:14:57 GMT""}]","2021-01-21"
"2101.07955","Mounir Gaidi","Kais Daoudi, Mounir Gaidi, Soumya Columbus, Mohammed Shameer and
  Hussain Alawadhi","Highly sensitive silver decorated-graphene oxide-silicon nanowires
  hybrid SERS sensors for trace level detection of environmental pollutants",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we evaluated the sensing performance of silver
nanoprism/graphene oxide/silicon nanowires (AgNPr/GO/SiNWs) nanohybrid system
for effective detection of organic dye and herbicide residues in freshwater via
surface-enhanced Raman scattering (SERS). Homogenous and vertically aligned
SiNWs have been successfully synthesized using metal-assisted chemical etching
technique by varying the etching time from 10 to 30 min. AgNPr/GO/SiNW hybrids
were assembled by spin-coating of GO followed by drop-casting deposition of
AgNPr. The microstructures of AgNPr/GO/SiNWs are strongly affected by the
etching time of SiNWs, which in turn affected its SERS performance when
rhodamine 6G is used as an analyte molecule. Owing to the synergetic effects of
GO and AgNPr, SERS response of AgNPr/GO/SiNWs composites were found to be
superior compared to AgNPr/SiNWs. High efficiency of 6.1 x 1010 has been
achieved with AgNPr/GO/SiNWs based sensor fabricated with 30-min etched SiNWs
for rhodamine 6G. An effective way of rapid detection of drinking water
pollutants such as methylene blue and atrazine up to picomolar (10-12 M)
concentrations was demonstrated using these low-cost AgNPr/GO/SiNWs nanohybrids
SERS sensors.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:18:21 GMT""}]","2021-01-21"
"2101.07956","Seung Won Min","Seung Won Min, Kun Wu, Sitao Huang, Mert Hidayeto\u{g}lu, Jinjun
  Xiong, Eiman Ebrahimi, Deming Chen, Wen-mei Hwu","PyTorch-Direct: Enabling GPU Centric Data Access for Very Large Graph
  Neural Network Training with Irregular Accesses",,,,,"cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing adoption of graph neural networks (GNNs) in the machine
learning community, GPUs have become an essential tool to accelerate GNN
training. However, training GNNs on very large graphs that do not fit in GPU
memory is still a challenging task. Unlike conventional neural networks,
mini-batching input samples in GNNs requires complicated tasks such as
traversing neighboring nodes and gathering their feature values. While this
process accounts for a significant portion of the training time, we find
existing GNN implementations using popular deep neural network (DNN) libraries
such as PyTorch are limited to a CPU-centric approach for the entire data
preparation step. This ""all-in-CPU"" approach has negative impact on the overall
GNN training performance as it over-utilizes CPU resources and hinders GPU
acceleration of GNN training. To overcome such limitations, we introduce
PyTorch-Direct, which enables a GPU-centric data accessing paradigm for GNN
training. In PyTorch-Direct, GPUs are capable of efficiently accessing
complicated data structures in host memory directly without CPU intervention.
Our microbenchmark and end-to-end GNN training results show that PyTorch-Direct
reduces data transfer time by 47.1% on average and speeds up GNN training by up
to 1.6x. Furthermore, by reducing CPU utilization, PyTorch-Direct also saves
system power by 12.4% to 17.5% during training. To minimize programmer effort,
we introduce a new ""unified tensor"" type along with necessary changes to the
PyTorch memory allocator, dispatch logic, and placement rules. As a result,
users need to change at most two lines of their PyTorch GNN training code for
each tensor object to take advantage of PyTorch-Direct.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:24:39 GMT""}]","2021-01-21"
"2101.07957","Kei Takemura","Kei Takemura, Shinji Ito, Daisuke Hatano, Hanna Sumita, Takuro
  Fukunaga, Naonori Kakimura, Ken-ichi Kawarabayashi","Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits
  with Linear Payoff Functions",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The contextual combinatorial semi-bandit problem with linear payoff functions
is a decision-making problem in which a learner chooses a set of arms with the
feature vectors in each round under given constraints so as to maximize the sum
of rewards of arms. Several existing algorithms have regret bounds that are
optimal with respect to the number of rounds $T$. However, there is a gap of
$\tilde{O}(\max(\sqrt{d}, \sqrt{k}))$ between the current best upper and lower
bounds, where $d$ is the dimension of the feature vectors, $k$ is the number of
the chosen arms in a round, and $\tilde{O}(\cdot)$ ignores the logarithmic
factors. The dependence of $k$ and $d$ is of practical importance because $k$
may be larger than $T$ in real-world applications such as recommender systems.
In this paper, we fill the gap by improving the upper and lower bounds. More
precisely, we show that the C${}^2$UCB algorithm proposed by Qin, Chen, and Zhu
(2014) has the optimal regret bound $\tilde{O}(d\sqrt{kT} + dk)$ for the
partition matroid constraints. For general constraints, we propose an algorithm
that modifies the reward estimates of arms in the C${}^2$UCB algorithm and
demonstrate that it enjoys the optimal regret bound for a more general problem
that can take into account other objectives simultaneously. We also show that
our technique would be applicable to related problems. Numerical experiments
support our theoretical results and considerations.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:29:18 GMT""},{""version"":""v2"",""created"":""Sat, 27 Feb 2021 11:22:30 GMT""}]","2021-03-02"
"2101.07958","Medet Nursultanov","Medet Nursultanov, Justin C. Tzou, Leo Tzou","On the Mean First Arrival Time of Brownian Particles on Riemannian
  Manifolds",,,,,"math.PR math.AP","http://creativecommons.org/licenses/by/4.0/","  We use geometric microlocal methods to compute an asymptotic expansion of
mean first arrival time for Brownian particles on Riemannian manifolds. This
approach provides a robust way to treat this problem, which has thus far been
limited to very special geometries. This paper can be seen as the Riemannian
3-manifold version of the planar result of \cite{ammari} and thus enable us to
see the full effect of the local extrinsic boundary geometry on the mean
arrival time of the Brownian particles. Our approach also connects this
question to some of the recent progress on boundary rigidity and integral
geometry [23,20].
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:32:19 GMT""}]","2021-01-21"
"2101.07959","Long Chen","Long Chen, Junyu Dong and Huiyu Zhou","Class balanced underwater object detection dataset generated by
  class-wise style augmentation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Underwater object detection technique is of great significance for various
applications in underwater the scenes. However, class imbalance issue is still
an unsolved bottleneck for current underwater object detection algorithms. It
leads to large precision discrepancies among different classes that the
dominant classes with more training data achieve higher detection precisions
while the minority classes with fewer training data achieves much lower
detection precisions. In this paper, we propose a novel class-wise style
augmentation (CWSA) algorithm to generate a class-balanced underwater dataset
Balance18 from the public contest underwater dataset URPC2018. CWSA is a new
kind of data augmentation technique which augments the training data for the
minority classes by generating various colors, textures and contrasts for the
minority classes. Compare with previous data augmentation algorithms such
flipping, cropping and rotations, CWSA is able to generate a class balanced
underwater dataset with diverse color distortions and haze-effects.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:37:27 GMT""}]","2021-01-21"
"2101.07960","Jane Greenberg","Jane Greenberg, Xintong Zhao, Joseph Adair, Joan Boone and Xiaohua
  Tony Hu","HIVE-4-MAT: Advancing the Ontology Infrastructure for Materials Science","12 pages, 1 table, 7 figures, Presented at ""MTSR '20: 14th
  International Conference on Metadata and Semantics Research,"" and forthcoming
  in conference proceedings. Research supported by NSF OAC: #1940239",,,,"cs.DL cs.CL","http://creativecommons.org/licenses/by/4.0/","  Introduces HIVE-4-MAT - Helping Interdisciplinary Vocabulary Engineering for
Materials Science, an automatic linked data ontology application. Covers
contextual background for materials science, shared ontology infrastructures,
and reviews the knowledge extraction and indexing process. HIVE-4-MAT's
vocabulary browsing, term search and selection, and knowledge extraction and
indexing are reviewed, and plans to integrate named entity recognition.
Conclusion highlights next steps with relation extraction to support better
ontologies.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:40:09 GMT""}]","2021-01-21"
"2101.07961","Geunsik Lim","Geunsik Lim, MyungJoo Ham, Jijoong Moon, and Wook Song","LightSys: Lightweight and Efficient CI System for Improving Integration
  Speed of Software",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complexity and size increase of software has extended the delay for
developers as they wait for code analysis and code merge. With the larger and
more complex software, more developers nowadays are developing software with
large source code repositories. The tendency for software platforms to
immediately update software packages with feature updates and bug-fixes is a
significant obstacle. Continuous integration systems may help prevent software
flaws during the active development of software packages, even when they are
deployed and updated frequently. Herein, we present a portable and modular code
review automation system that inspects incoming code changes such as code
format and style, performance regression, static analysis, build and deployment
tests, and dynamic analysis before merging and changing code. The proposed
mechanisms are sufficiently lightweight to be hosted on a regular desktop
computer even for numerous developers. The resulting reduced costs allow
developers to apply the proposed mechanism to many source code repositories.
Experimental results demonstrate that the proposed mechanism drastically
reduces overheads and improves usability compared with conventional mechanisms:
execution time (6x faster), CPU usage (40% lower), memory consumption (1/180),
and no out-of-memory occurrence.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:40:41 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 02:12:18 GMT""},{""version"":""v3"",""created"":""Fri, 29 Jan 2021 07:03:48 GMT""}]","2021-02-01"
"2101.07962","Kentaro Saji","Yutaro Kabata and Kentaro Saji","Criteria for sharksfin and deltoid singularities from the plane into the
  plane and their applications","14 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give criteria for sharksfin and deltoid singularities from the plane into
the plane. We also give geometric meanings for the conditions in the criterion
of a sharksfin. As applications, we investigate such singularities appearing on
an orthogonal projection of a Whitney umbrella, and a sharksfin appearing on
planar motions with 2-degrees of freedom.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:41:12 GMT""}]","2021-01-21"
"2101.07963","Tianyu Li","Tianyu Li, Jia-Zheng Sun, Yong-Sheng Zhang, and Wei Yi","Non-Bloch quench dynamics","11 pages, 6 figures","Phys. Rev. Research 3, 023022 (2021)","10.1103/PhysRevResearch.3.023022",,"cond-mat.quant-gas cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the quench dynamics of non-Hermitian topological models with
non-Hermitian skin effects. Adopting the non-Bloch band theory and projecting
quench dynamics onto the generalized Brillouin zone, we find that emergent
topological structures, in the form of dynamic skyrmions, exist in the
generalized momentum-time domain, and are correlated with the non-Bloch
topological invariants of the static Hamiltonians. The skyrmion structures
anchor on the fixed points of dynamics whose existence are conditional on the
coincidence of generalized Brillouin zones of the pre- and post-quench
Hamiltonians. Global signatures of dynamic skyrmions, however, persist well
beyond such a condition, thus offering a general dynamic detection scheme for
non-Bloch topology in the presence of non-Hermitian skin effects. Applying our
theory to an experimentally relevant, non-unitary quantum walk, we explicitly
demonstrate how the non-Bloch topological invariants can be revealed through
the non-Bloch quench dynamics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:42:34 GMT""}]","2021-04-09"
"2101.07964","Xinyu Yao","Xinyu Yao, Joshua Pepper, B. Scott Gaudi, Paul A. Dalba, Jennifer A.
  Burt, Robert A. Wittenmyer, Diana Dragomir, Joseph E. Rodriguez, Steven
  Villanueva, Jr., Daniel J. Stevens, Keivan G. Stassun, David J. James","Following up TESS Single Transits With Archival Photometry and Radial
  Velocities","28 pages, 11 figures, accepted for publication in the Astronomical
  Journal",,"10.3847/1538-3881/abdb30",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  NASA's Transiting Exoplanet Survey Satellite (TESS) mission is expected to
discover hundreds of planets via single transits first identified in their
light curves. Determining the orbital period of these single transit candidates
typically requires a significant amount of follow-up work to observe a second
transit or measure a radial velocity orbit. In Yao et al. (2019), we developed
simulations that demonstrated the ability to use archival photometric data in
combination with TESS to ""precover"" the orbital period for these candidates
with a precision of several minutes, assuming circular orbits. In this work, we
incorporate updated models for TESS single transits, allowing for eccentric
orbits, along with an updated methodology to improve the reliability of the
results. Additionally, we explore how radial velocity (RV) observations can be
used to follow up single transit events, using strategies distinct from those
employed when the orbital period is known. We find that the use of an estimated
period based on a circular orbit to schedule reconnaissance RV observations can
efficiently distinguish eclipsing binaries from planets. For candidates that
pass reconnaissance RV observations, we simulate RV monitoring campaigns that
enable one to obtain an approximate orbital solution. We find this method can
regularly determine the orbital periods for planets more massive than 0.5 M_J
with orbital periods as long as 100 days.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:42:49 GMT""}]","2021-03-03"
"2101.07965","Jie Chen","Veronika Thost, Jie Chen","Directed Acyclic Graph Neural Networks","ICLR 2021. Code is available at https://github.com/vthost/DAGNN",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph-structured data ubiquitously appears in science and engineering. Graph
neural networks (GNNs) are designed to exploit the relational inductive bias
exhibited in graphs; they have been shown to outperform other forms of neural
networks in scenarios where structure information supplements node features.
The most common GNN architecture aggregates information from neighborhoods
based on message passing. Its generality has made it broadly applicable. In
this paper, we focus on a special, yet widely used, type of graphs -- DAGs --
and inject a stronger inductive bias -- partial ordering -- into the neural
network design. We propose the \emph{directed acyclic graph neural network},
DAGNN, an architecture that processes information according to the flow defined
by the partial order. DAGNN can be considered a framework that entails earlier
works as special cases (e.g., models for trees and models updating node
representations recurrently), but we identify several crucial components that
prior architectures lack. We perform comprehensive experiments, including
ablation studies, on representative DAG datasets (i.e., source code, neural
architectures, and probabilistic graphical models) and demonstrate the
superiority of DAGNN over simpler DAG architectures as well as general graph
architectures.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:50:16 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 18:18:07 GMT""},{""version"":""v3"",""created"":""Tue, 2 Feb 2021 18:45:44 GMT""}]","2021-02-03"
"2101.07966","Motohiko Ezawa","Motohiko Ezawa","Variational Quantum Support Vector Machine based on $\Gamma$ matrix
  expansion and Variational Universal-Quantum-State Generator","11 pages, 5 figures","Scientific Reports 12, 6758 (2022)","10.1038/s41598-022-10677-z",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We analyze a binary classification problem by using a support vector machine
based on variational quantum-circuit model. We propose to solve a linear
equation of the support vector machine by using a $\Gamma$ matrix expansion. In
addition, it is shown that an arbitrary quantum state is prepared by optimizing
a universal quantum circuit representing an arbitrary $U(2^N)$ based on the
steepest descent method. It may be a quantum generalization of
Field-Programmable-Gate Array (FPGA).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:50:39 GMT""}]","2022-10-24"
"2101.07967","Kentaro Saji","Kentaro Saji and Samuel P. dos Santos","Geometry of bifurcation sets of generic unfoldings of corank two
  functions","20 pages, 14 figures",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the geometry of bifurcation sets of generic unfoldings of
$D_4^\pm$-functions. Taking blow-ups, we show each of the bifurcation sets of
$D_4^\pm$-functions admit a parametrization as a surface in $R^3$. Using this
parametrization, we investigate the behavior of the Gaussian curvature and the
principal curvatures. Furthermore, we investigate the number of ridge curves
and subparabolic curves near their singular point.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:57:00 GMT""}]","2021-01-21"
"2101.07968","Shangming Cai","Shangming Cai, Dongsheng Wang, Haixia Wang, Yongqiang Lyu, Guangquan
  Xu, Xi Zheng and Athanasios V. Vasilakos","DynaComm: Accelerating Distributed CNN Training between Edges and Clouds
  through Dynamic Communication Scheduling","16 pages, 12 figures. IEEE Journal on Selected Areas in
  Communications",,"10.1109/JSAC.2021.3118419",,"cs.DC cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To reduce uploading bandwidth and address privacy concerns, deep learning at
the network edge has been an emerging topic. Typically, edge devices
collaboratively train a shared model using real-time generated data through the
Parameter Server framework. Although all the edge devices can share the
computing workloads, the distributed training processes over edge networks are
still time-consuming due to the parameters and gradients transmission
procedures between parameter servers and edge devices. Focusing on accelerating
distributed Convolutional Neural Networks (CNNs) training at the network edge,
we present DynaComm, a novel scheduler that dynamically decomposes each
transmission procedure into several segments to achieve optimal layer-wise
communications and computations overlapping during run-time. Through
experiments, we verify that DynaComm manages to achieve optimal layer-wise
scheduling for all cases compared to competing strategies while the model
accuracy remains untouched.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:09:41 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 03:39:19 GMT""}]","2021-10-11"
"2101.07969","Zheng Liu","Zheng Liu, Po-Ling Loh","Robust W-GAN-Based Estimation Under Wasserstein Contamination",,,,,"math.ST cs.IT cs.LG math.IT stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust estimation is an important problem in statistics which aims at
providing a reasonable estimator when the data-generating distribution lies
within an appropriately defined ball around an uncontaminated distribution.
Although minimax rates of estimation have been established in recent years,
many existing robust estimators with provably optimal convergence rates are
also computationally intractable. In this paper, we study several estimation
problems under a Wasserstein contamination model and present computationally
tractable estimators motivated by generative adversarial networks (GANs).
Specifically, we analyze properties of Wasserstein GAN-based estimators for
location estimation, covariance matrix estimation, and linear regression and
show that our proposed estimators are minimax optimal in many scenarios.
Finally, we present numerical results which demonstrate the effectiveness of
our estimators.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:15:16 GMT""}]","2021-01-21"
"2101.07970","Jun Li","Jun Li and Guang-Hai Guo","Measuring the primordial gravitational waves from cosmic microwave
  background and stochastic gravitational wave background observations",,,"10.1142/S0217732322500663",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We constrain the primordial gravitational waves from cosmic microwave
background (CMB) and stochastic gravitational wave background (SGWB)
observations. SGWB provides the latest way to explore the early universe and
the cosmological evolution which can be reflected by primordial gravitational
waves. We not only combine LIGO observations with CMB to measure primordial
gravitational waves, but also forecast the potential abilities of the LISA
detector and PTA projects. In the $\Lambda$CDM+$r$+$n_t$ model, the standard
six parameters change slightly from SGWB observations. While the constraints on
tensor-to-scalar ratio and tensor spectral index are improved obviously from
SGWB observations. FAST projects have a significant impact on tensor-to-scalar
ratio and tensor spectral index, namely $r<0.028$ and
$n_t=-0.41^{+0.64}_{-0.96}$ at $95\%$ confidence level.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:24:50 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 05:55:11 GMT""}]","2022-05-25"
"2101.07971","Muhammad Waqas","M. Waqas, G. X. Peng, Fu-Hu Liu","An evidence of triple kinetic freezeout scenario observed in all
  centrality intervals in Cu-Cu, Au-Au and Pb-Pb collisions at high energies",,"J. Phys. G, vol. 48, 075108, 2021","10.1088/1361-6471/abdd8d",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transverse momentum spectra of $\pi^+$, $K^+$, $p$, $K^0_s$, $\Lambda$, $\Xi$
or $\bar\Xi^+$ and $\Omega$ or $\bar\Omega^+$ or $\Omega+\bar\Omega$ in
Copper-Copper (Cu-Cu), Gold-Gold (Au-Au) and Lead-Lead (Pb-Pb) collisions at
200 GeV, 62.4 GeV and 2.76 TeV respectively, are analyzed in different
centrality bins by the blast wave model with Tsallis statistics. The model
results are approximately in agreement with the experimental data measured by
BRAHMS, STAR and ALICE Collaborations in special transverse momentum ranges.
Kinetic freeze out temperature, transverse flow velocity and kinetic freezeout
volume are extracted from the transverse momentum spectra of the particles. It
is observed that $\bar\Xi^+$ and $\Omega$ or $\bar\Omega^+$ or
$\Omega+\bar\Omega$ have larger kinetic freezeout temperature followed by
$K^+$, $K^0_s$ and $\Lambda$ than $\pi^+$ and $p$ due to smaller reaction
cross-sections of multi-strange and strange particles than non-strange
particles. The present work reveals the scenario of triple kinetic freezeout in
collisions at BRAHMS, STAR and ALICE Collaborations, however the transverse
flow velocity and kinetic freezeout volume are mass dependent and they decrease
with the increasing rest mass of the particle. In addition, the kinetic
freezeout temperature, transverse flow velocity and kinetic freezeout volume
are decreasing from central to peripheral collisions while the parameter q
increase from central to peripheral collisions, indicating the approach of
quick equilibrium in the central collisions. Besides, the kinetic freezeout
temperature and kinetic freezeout volume are observed to be larger in larger
collision system which shows its dependence on the size of the interacting
system, while transverse flow velocity increase with increasing energy.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:26:20 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jan 2021 08:06:08 GMT""}]","2021-06-13"
"2101.07972","Peter Stokes","Peter W. Stokes, Sean P. Foster, Madalyn J. E. Casey, Daniel G. Cocks,
  Olmo Gonz\'alez-Maga\~na, Jaime de Urquijo, Gustavo Garc\'ia, Michael J.
  Brunger, Ronald D. White","An improved set of electron-THFA cross sections refined through a neural
  network-based analysis of swarm data","37 pages, 19 figures, submitted to The Journal of Chemical Physics",,"10.1063/5.0043759",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review experimental and theoretical cross sections for electron transport
in $\alpha$-tetrahydrofurfuryl alcohol (THFA) and, in doing so, propose a
plausible complete set. To assess the accuracy and self-consistency of our
proposed set, we use the pulsed-Townsend technique to measure drift velocities,
longitudinal diffusion coefficients and effective Townsend first ionisation
coefficients for electron swarms in admixtures of THFA in argon, across a range
of density-reduced electric fields from 1 Td to 450 Td. These measurements are
then compared to simulated values derived from our proposed set using a
multi-term solution of Boltzmann's equation. We observe discrepancies between
the simulation and experiment, which we attempt to address by employing a
neural network model that is trained to solve the inverse swarm problem of
unfolding the cross sections underpinning our experimental swarm measurements.
What results from our neural network-based analysis is a refined set of
electron-THFA cross sections, which we confirm is of higher consistency with
our swarm measurements than that we initially proposed. We also use our data
base to calculate electron transport coefficients in pure THFA, across a range
of reduced electric fields from 0.001 Td to 10,000 Td.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:32:05 GMT""}]","2021-03-17"
"2101.07973","Varad Bhatnagar","Varad Bhatnagar, Prince Kumar, Sairam Moghili and Pushpak
  Bhattacharyya","Divide and Conquer: An Ensemble Approach for Hostile Post Detection in
  Hindi",,"CONSTRAINT @AAAI 2021 Combating Online Hostile Posts in Regional
  Languages during Emergency Situation pp244-255",,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently the NLP community has started showing interest towards the
challenging task of Hostile Post Detection. This paper present our system for
Shared Task at Constraint2021 on ""Hostile Post Detection in Hindi"". The data
for this shared task is provided in Hindi Devanagari script which was collected
from Twitter and Facebook. It is a multi-label multi-class classification
problem where each data instance is annotated into one or more of the five
classes: fake, hate, offensive, defamation, and non-hostile. We propose a two
level architecture which is made up of BERT based classifiers and statistical
classifiers to solve this problem. Our team 'Albatross', scored 0.9709 Coarse
grained hostility F1 score measure on Hostile Post Detection in Hindi subtask
and secured 2nd rank out of 45 teams for the task. Our submission is ranked 2nd
and 3rd out of a total of 156 submissions with Coarse grained hostility F1
score of 0.9709 and 0.9703 respectively. Our fine grained scores are also very
encouraging and can be improved with further finetuning. The code is publicly
available.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:38:07 GMT""}]","2021-05-06"
"2101.07974","Ishan Rajendrakumar Dave","Ishan Dave, Rohit Gupta, Mamshad Nayeem Rizve and Mubarak Shah","TCLR: Temporal Contrastive Learning for Video Representation","Accepted to Computer Vision and Image Understanding (CVIU) Journal",,"10.1016/j.cviu.2022.103406",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning has nearly closed the gap between supervised and
self-supervised learning of image representations, and has also been explored
for videos. However, prior work on contrastive learning for video data has not
explored the effect of explicitly encouraging the features to be distinct
across the temporal dimension. We develop a new temporal contrastive learning
framework consisting of two novel losses to improve upon existing contrastive
self-supervised video representation learning methods. The local-local temporal
contrastive loss adds the task of discriminating between non-overlapping clips
from the same video, whereas the global-local temporal contrastive aims to
discriminate between timesteps of the feature map of an input clip in order to
increase the temporal diversity of the learned features. Our proposed temporal
contrastive learning framework achieves significant improvement over the
state-of-the-art results in various downstream video understanding tasks such
as action recognition, limited-label action classification, and
nearest-neighbor video retrieval on multiple video datasets and backbones. We
also demonstrate significant improvement in fine-grained action classification
for visually similar classes. With the commonly used 3D ResNet-18 architecture
with UCF101 pretraining, we achieve 82.4\% (+5.1\% increase over the previous
best) top-1 accuracy on UCF101 and 52.9\% (+5.4\% increase) on HMDB51 action
classification, and 56.2\% (+11.7\% increase) Top-1 Recall on UCF101 nearest
neighbor video retrieval. Code released at github.com/DAVEISHAN/TCLR.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:38:16 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 13:28:27 GMT""},{""version"":""v3"",""created"":""Thu, 8 Apr 2021 15:39:49 GMT""},{""version"":""v4"",""created"":""Wed, 30 Mar 2022 06:36:50 GMT""}]","2022-03-31"
"2101.07975","Weijian Yang","Feng Tian, Junjie Hu, and Weijian Yang","GEOMScope: Large Field-of-view 3D Lensless Microscopy with Low
  Computational Complexity",,"Laser Photonics Rev. 15 (2021) 2100072","10.1002/lpor.202100072",,"physics.optics eess.IV","http://creativecommons.org/licenses/by/4.0/","  Recent development of lensless imagers has enabled three-dimensional (3D)
imaging through a thin piece of optics in close proximity to a camera sensor. A
general challenge of wide-field lensless imaging is the high computational
complexity and slow speed to reconstruct 3D objects through iterative
optimization process. Here, we demonstrated GEOMScope, a lensless 3D microscope
that forms image through a single layer of microlens array and reconstructs
objects through a geometrical-optics-based pixel back projection algorithm and
background suppressions. Compared to others, our method allows local
reconstruction, which significantly reduces the required computation resource
and increases the reconstruction speed by orders of magnitude. This enables
near real-time object reconstructions across a large volume of 23x23x5 mm^3,
with a lateral resolution of 40 um and axial resolution of 300 um. Our system
opens new avenues for broad biomedical applications such as endoscopy, which
requires both miniaturized device footprint and real-time high resolution
visualization.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:38:58 GMT""}]","2021-08-17"
"2101.07976","Dan Yang","Dan Yang, Xin Peng, Yusheng Lu, Haojie Huang, Weimin Zhong","Representation Evaluation Block-based Teacher-Student Network for the
  Industrial Quality-relevant Performance Modeling and Monitoring",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quality-relevant fault detection plays an important role in industrial
processes, while the current quality-related fault detection methods based on
neural networks main concentrate on process-relevant variables and ignore
quality-relevant variables, which restrict the application of process
monitoring. Therefore, in this paper, a fault detection scheme based on the
improved teacher-student network is proposed for quality-relevant fault
detection. In the traditional teacher-student network, as the features
differences between the teacher network and the student network will cause
performance degradation on the student network, representation evaluation block
(REB) is proposed to quantify the features differences between the teacher and
the student networks, and uncertainty modeling is used to add this difference
in modeling process, which are beneficial to reduce the features differences
and improve the performance of the student network. Accordingly, REB and
uncertainty modeling is applied in the teacher-student network named as
uncertainty modeling teacher-student uncertainty autoencoder (TSUAE). Then, the
proposed TSUAE is applied to process monitoring, which can effectively detect
faults in the process-relevant subspace and quality-relevant subspace
simultaneously. The proposed TSUAE-based fault detection method is verified in
two simulation experiments illustrating that it has satisfactory fault
detection performance compared to other fault detection methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:40:44 GMT""}]","2021-01-21"
"2101.07977","Govind Paneru","Jin Tae Park, Govind Paneru, Chulan Kwon, Steve Granick, and Hyuk Kyu
  Pak","Rapid-Prototyping a Brownian Particle in an Active Bath",,"Soft Matter, 2020,16, 8122-8127","10.1039/D0SM00828A",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Particles kicked by external forces to produce mobility distinct from thermal
diffusion are an iconic feature of the active matter problem. Here, we map this
onto a minimal model for experiment and theory covering the wide time and
length scales of usual active matter systems. A particle diffusing in a
harmonic potential generated by an optical trap is kicked by programmed forces
with time correlation at random intervals following the Poisson process. The
model's generic simplicity allows us to find conditions for which displacements
are Gaussian (or not), how diffusion is perturbed (or not) by kicks, and
quantifying heat dissipation to maintain the non-equilibrium steady state in an
active bath. The model reproduces experimental results of tracer mobility in an
active bath of swimming algal cells. It can be used as a stochastic dynamic
simulator for Brownian objects in various active baths without mechanistic
understanding, owing to the generic framework of the protocol.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:40:50 GMT""}]","2021-01-21"
"2101.07978","Zhi Chen","Zhi Chen, Yadan Luo, Ruihong Qiu, Sen Wang, Zi Huang, Jingjing Li,
  Zheng Zhang","Semantics Disentangling for Generalized Zero-Shot Learning","ICCV 2021 camera-ready",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized zero-shot learning (GZSL) aims to classify samples under the
assumption that some classes are not observable during training. To bridge the
gap between the seen and unseen classes, most GZSL methods attempt to associate
the visual features of seen classes with attributes or to generate unseen
samples directly. Nevertheless, the visual features used in the prior
approaches do not necessarily encode semantically related information that the
shared attributes refer to, which degrades the model generalization to unseen
classes. To address this issue, in this paper, we propose a novel semantics
disentangling framework for the generalized zero-shot learning task (SDGZSL),
where the visual features of unseen classes are firstly estimated by a
conditional VAE and then factorized into semantic-consistent and
semantic-unrelated latent vectors. In particular, a total correlation penalty
is applied to guarantee the independence between the two factorized
representations, and the semantic consistency of which is measured by the
derived relation network. Extensive experiments conducted on four GZSL
benchmark datasets have evidenced that the semantic-consistent features
disentangled by the proposed SDGZSL are more generalizable in tasks of
canonical and generalized zero-shot learning. Our source code is available at
https://github.com/uqzhichen/SDGZSL.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:46:21 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 02:28:44 GMT""},{""version"":""v3"",""created"":""Tue, 20 Apr 2021 01:56:59 GMT""},{""version"":""v4"",""created"":""Mon, 16 Aug 2021 04:25:32 GMT""},{""version"":""v5"",""created"":""Fri, 27 Aug 2021 05:16:02 GMT""}]","2021-08-30"
"2101.07979","Huan Cao","Huan Cao, Ning-ning Wang, Zhih-Ahn Jia, Chao Zhang, Yu Guo, Bi-Heng
  Liu, Yun-Feng Huang, Chuan-Feng Li, and Guang-Can Guo","Quantum simulation of indefinite causal order induced quantum
  refrigeration","17 pages, 13 figures, including 5 pages, 4 figures of maintext and 12
  pages, 9 figures of supplemental",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In the classical world, physical events always happen in a fixed causal
order. However, it was recently revealed that quantum mechanics allows events
to occur with indefinite causal order (ICO). In this study, we use an optical
quantum switch to experimentally investigate the application of ICO in
thermodynamic tasks. Specifically, we simulate the working system interacting
with two identical thermal reservoirs in an ICO, observing the quantum heat
extraction even though they are in thermal equilibrium where heat extraction is
unaccessible by traditional thermal contact. Using such a process, we simulate
an ICO refrigeration cycle and investigate its properties. We also show that by
passing through the ICO channel multiple times, one can extract more heat per
cycle and thus obtain a higher refrigeration performance. Our results suggest
that the causal nonseparability can be a powerful resource for quantum
thermodynamic tasks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:47:43 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 22:02:03 GMT""}]","2022-03-01"
"2101.07980","Shi Liu","Jiawei Huang, Xu Duan, Sunam Jeon, Youngkuk Kim, Jian Zhou, Jian Li,
  and Shi Liu","On-demand quantum spin Hall insulators controlled by two-dimensional
  ferroelectricity",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The coexistence of ferroelectric and topological orders in two-dimensional
(2D) atomic crystals allows non-volatile and switchable quantum spin Hall
states. Here we offer a general design principle for 2D bilayer
heterostructures that can host ferroelectricity and nontrivial band topology
simultaneously using only topologically trivial building blocks. The built-in
electric field arising from the out-of-plane polarization across the
heterostrucuture enables a robust control of the band gap size and band
inversion strength, which can be utilized to manipulate topological phase
transitions. Using first-principles calculations, we demonstrate a series of
bilayer heterostructures are 2D ferroelectric topological insulators (2DFETIs)
characterized with a direct coupling between band topology and polarization
state. We propose a few 2DFETI-based quantum electronics including domain-wall
quantum circuits and topological memristor.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:07:00 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 04:20:13 GMT""}]","2021-05-04"
"2101.07981","Cl\'ement Canonne","Jayadev Acharya, Cl\'ement L. Canonne, Cody Freitag, Ziteng Sun,
  Himanshu Tyagi","Inference under Information Constraints III: Local Privacy Constraints","To appear in the Special Issue on Privacy and Security of Information
  Systems of the IEEE Journal on Selected Areas in Information Theory (JSAIT),
  2021. Journal version of the AISTATS'19 paper ""Test without Trust: Optimal
  Locally Private Distribution Testing"" (arXiv:1808.02174), which it extends
  and supersedes",,,,"cs.DS cs.CR cs.DM math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study goodness-of-fit and independence testing of discrete distributions
in a setting where samples are distributed across multiple users. The users
wish to preserve the privacy of their data while enabling a central server to
perform the tests. Under the notion of local differential privacy, we propose
simple, sample-optimal, and communication-efficient protocols for these two
questions in the noninteractive setting, where in addition users may or may not
share a common random seed. In particular, we show that the availability of
shared (public) randomness greatly reduces the sample complexity. Underlying
our public-coin protocols are privacy-preserving mappings which, when applied
to the samples, minimally contract the distance between their respective
probability distributions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:07:49 GMT""}]","2021-01-21"
"2101.07982","Bao Tang Quoc","Jeff Morgan and Bao Quoc Tang","Global well-posedness for volume-surface reaction-diffusion systems","57 pages",,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  We study the global existence of classical solutions to volume-surface
reaction-diffusion systems with control of mass. Such systems appear naturally
from modeling evolution of concentrations or densities appearing both in a
volume domain and its surface, and therefore have attracted considerable
attention. Due to the characteristic volume-surface coupling, global existence
of solutions to general systems is a challenging issue. In particular, the
duality method, which is powerful in dealing with mass conserved systems in
domains, is not applicable on its own. In this paper, we introduce a new family
of $L^p$-energy functions and combine them with a suitable duality method for
volume-surface systems, to ultimately obtain global existence of classical
solutions under a general assumption called the \textit{intermediate sum
condition}. For systems that conserve mass, but do not satisfy this condition,
global solutions are shown under a quasi-uniform condition, that is, under the
assumption that the diffusion coefficients are close to each other. In the case
of mass dissipation, we also show that the solution is bounded uniformly in
time by studying the system on each time-space cylinder of unit size, and
showing that the solution is sup-norm bounded independently of the cylinder.
Applications of our results include global existence and boundedness for
systems arising from membrane protein clustering or activation of Cdc42 in cell
polarization.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:16:20 GMT""}]","2021-01-21"
"2101.07983","Takamasa Ando","Takamasa Ando, Kazuhiro Hotta","Cell image segmentation by Feature Random Enhancement Module",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is important to extract good features using an encoder to realize semantic
segmentation with high accuracy. Although loss function is optimized in
training deep neural network, far layers from the layers for computing loss
function are difficult to train. Skip connection is effective for this problem
but there are still far layers from the loss function. In this paper, we
propose the Feature Random Enhancement Module which enhances the features
randomly in only training. By emphasizing the features at far layers from loss
function, we can train those layers well and the accuracy was improved. In
experiments, we evaluated the proposed module on two kinds of cell image
datasets, and our module improved the segmentation accuracy without increasing
computational cost in test phase.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:16:46 GMT""}]","2021-01-21"
"2101.07984","Elijah Ogaro Nyakang'o","Elijah Ogaro Nyakang'o (1) and Kanhaiya Pandey (1) ((1) Department of
  Physics, Indian Institute of Technology Guwahati, Guwahati, Assam, India)","Resolving closely spaced levels for Doppler mismatched double resonance","15 pages, 14 figures","Phys. Rev. A 103, 013107 (2021)","10.1103/PhysRevA.103.013107",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present experimental techniques to resolve the closely
spaced hyperfine levels of a weak transition by eliminating the
residual/partial two-photon Doppler broadening and cross-over resonances in a
wavelength mismatched double resonance spectroscopy. The elimination of the
partial Doppler broadening is based on velocity induced population oscillation
(VIPO) and velocity selective saturation (VSS) effect followed by the
subtraction of the broad background of the two-photon spectrum. Since the VIPO
and VSS effect are the phenomena for near zero velocity group atoms, the
subtraction gives rise to Doppler-free peaks and the closely spaced hyperfine
levels of the $6\text{P}_{3/2}$ state in Rb are well resolved. The double
resonance experiment is conducted on
$5\text{S}_{1/2}\rightarrow5\text{P}_{3/2}$ strong transition (at 780~nm) and
$5\text{S}_{1/2}\rightarrow6\text{P}_{3/2}$ weak transition (at 420~nm) at room
temperature.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:16:50 GMT""}]","2021-01-21"
"2101.07985","Mingbao Lin","Mingbao Lin, Rongrong Ji, Shaojie Li, Yan Wang, Yongjian Wu, Feiyue
  Huang, Qixiang Ye","Network Pruning using Adaptive Exemplar Filters","Accepted by IEEE Transactions on Neural Networks and Learning Systems
  (IEEE TNNLS)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Popular network pruning algorithms reduce redundant information by optimizing
hand-crafted models, and may cause suboptimal performance and long time in
selecting filters. We innovatively introduce adaptive exemplar filters to
simplify the algorithm design, resulting in an automatic and efficient pruning
approach called EPruner. Inspired by the face recognition community, we use a
message passing algorithm Affinity Propagation on the weight matrices to obtain
an adaptive number of exemplars, which then act as the preserved filters.
EPruner breaks the dependency on the training data in determining the
""important"" filters and allows the CPU implementation in seconds, an order of
magnitude faster than GPU based SOTAs. Moreover, we show that the weights of
exemplars provide a better initialization for the fine-tuning. On VGGNet-16,
EPruner achieves a 76.34%-FLOPs reduction by removing 88.80% parameters, with
0.06% accuracy improvement on CIFAR-10. In ResNet-152, EPruner achieves a
65.12%-FLOPs reduction by removing 64.18% parameters, with only 0.71% top-5
accuracy loss on ILSVRC-2012. Our code can be available at
https://github.com/lmbxmu/EPruner.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:18:38 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 08:44:26 GMT""},{""version"":""v3"",""created"":""Sun, 4 Apr 2021 07:04:01 GMT""},{""version"":""v4"",""created"":""Wed, 26 May 2021 16:08:22 GMT""}]","2021-05-27"
"2101.07986","Jiaqi Zhao","Jiaqi Zhao, Yue Zhao, Craig O. Heinke","Chandra and HST Studies of Six Millisecond Pulsars in the Globular
  Cluster M13","9 pages, 5 figures, 3 tables. Accepted for publication in Monthly
  Notices of the Royal Astronomical Society (MNRAS)",,"10.1093/mnras/stab117",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse 55 ks of Chandra X-ray observations of the Galactic globular
cluster M13. Using the latest radio timing positions of six known millisecond
pulsars (MSPs) in M13 from Wang et al. (2020), we detect confident X-ray
counterparts to five of the six MSPs at X-ray luminosities of $L_X$(0.3-8
keV)$\sim 3 \times 10^{30} - 10^{31}~{\rm erg~s^{-1}}$, including the newly
discovered PSR J1641+3627F. There are limited X-ray counts at the position of
PSR J1641+3627A, for which we obtain an upper limit $L_X<1.3 \times
10^{30}~{\rm erg~s^{-1}}$. We analyse X-ray spectra of all six MSPs, which are
well-described by either a single blackbody or a single power-law model. We
also incorporate optical/UV imaging observations from the Hubble Space
Telescope (HST) and find optical counterparts to PSR J1641+3627D and
J1641+3627F. Our colour-magnitude diagrams indicate the latter contains a white
dwarf, consistent with the properties suggested by radio timing observations.
The counterpart to J1641+3627D is only visible in the V band; however, we argue
that the companion to J1641+3627D is also a white dwarf, since we see a
blackbody-like X-ray spectrum, while MSPs with nondegenerate companions
generally show non-thermal X-rays from shocks between the pulsar and companion
winds. Our work increases the sample of known X-ray and optical counterparts of
MSPs in globular clusters.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:19:01 GMT""}]","2021-01-27"
"2101.07987","Martin Bladt","Martin Bladt and Jorge Yslas","matrixdist: An R Package for Inhomogeneous Phase-Type Distributions",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inhomogeneous phase-type distributions (IPH) are a broad class of laws which
arise from the absorption times of Markov jump processes. In the
time-homogeneous particular case, we recover phase-type (PH) distributions. In
matrix notation, various functionals corresponding to their distributional
properties are explicitly available and succinctly described. As the number of
parameters increases, IPH distributions may converge weakly to any probability
measure on the positive real line, making them particularly attractive
candidates for statistical modelling purposes. Contrary to PH distributions,
the IPH class allows for a wide range of tail behaviours, which often leads to
adequate estimation with a moderate number of parameters. One of the main
difficulties in estimating PH and IPH distributions is their large number of
matrix parameters. This drawback is best handled through the
expectation-maximisation (EM) algorithm, exploiting the underlying and
unobserved Markov structure. The matrixdist package presents tools for IPH
distributions to efficiently evaluate functionals, simulate, and carry out
maximum likelihood estimation through a three-step EM algorithm. Aggregated and
right-censored data are supported by the fitting routines, and in particular,
one may estimate time-to-event data, histograms, or discretised theoretical
distributions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:20:41 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 10:23:39 GMT""}]","2021-01-26"
"2101.07988","Olga Moskvyak","Olga Moskvyak, Frederic Maire, Feras Dayoub, Mahsa Baktashmotlagh","Semi-supervised Keypoint Localization","accepted to ICLR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Knowledge about the locations of keypoints of an object in an image can
assist in fine-grained classification and identification tasks, particularly
for the case of objects that exhibit large variations in poses that greatly
influence their visual appearance, such as wild animals. However, supervised
training of a keypoint detection network requires annotating a large image
dataset for each animal species, which is a labor-intensive task. To reduce the
need for labeled data, we propose to learn simultaneously keypoint heatmaps and
pose invariant keypoint representations in a semi-supervised manner using a
small set of labeled images along with a larger set of unlabeled images.
Keypoint representations are learnt with a semantic keypoint consistency
constraint that forces the keypoint detection network to learn similar features
for the same keypoint across the dataset. Pose invariance is achieved by making
keypoint representations for the image and its augmented copies closer together
in feature space. Our semi-supervised approach significantly outperforms
previous methods on several benchmarks for human and animal body landmark
localization.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:23:08 GMT""}]","2021-01-21"
"2101.07989","Lingzhong Zeng","Lingzhong Zeng","Eigenvalue Inequalities for the Clamped Plate Problem of
  $\mathfrak{L}^{2}_{\nu}$ Operator","To appear in Science China Mathematics",,,,"math.DG math.AP","http://creativecommons.org/licenses/by/4.0/","  $\mathfrak{L}_{II}$ operator is introduced by Y.-L. Xin (\emph{Calculus of
Variations and Partial Differential Equations. 2015,
\textbf{54}(2):1995-2016)}, which is an important extrinsic elliptic
differential operator of divergence type and has profound geometric meaning. In
this paper, we extend $\mathfrak{L}_{II}$ operator to more general elliptic
differential operator $\mathfrak{L}_{\nu}$, and investigate the clamped plate
problem of bi-$\mathfrak{L}_{\nu}$ operator, which is denoted by
$\mathfrak{L}_{\nu}^{2}$, on the complete Riemannian manifolds. A general
formula of eigenvalues for the $\mathfrak{L}_{\nu}^{2}$ operator is
established. Applying this formula, we estimate the eigenvalues with lower
order on the Riemannian manifolds. As some further applications, we establish
some eigenvalue inequalities for this operator on the translating solitons with
respect to the mean curvature flows, submanifolds of the Euclidean spaces, unit
spheres and projective spaces. In particular, for the case of translating
solitons, all of the eigenvalue inequalities are universal.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:26:55 GMT""}]","2021-01-21"
"2101.07990","Haotian Li","Haotian Li, Min Xu, Yong Wang, Huan Wei, Huamin Qu","A Visual Analytics Approach to Facilitate the Proctoring of Online Exams","17 pages, 10 figures. Accepted at CHI2021",,"10.1145/3411764.3445294",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online exams have become widely used to evaluate students' performance in
mastering knowledge in recent years, especially during the pandemic of
COVID-19. However, it is challenging to conduct proctoring for online exams due
to the lack of face-to-face interaction. Also, prior research has shown that
online exams are more vulnerable to various cheating behaviors, which can
damage their credibility. This paper presents a novel visual analytics approach
to facilitate the proctoring of online exams by analyzing the exam video
records and mouse movement data of each student. Specifically, we detect and
visualize suspected head and mouse movements of students in three levels of
detail, which provides course instructors and teachers with convenient,
efficient and reliable proctoring for online exams. Our extensive evaluations,
including usage scenarios, a carefully-designed user study and expert
interviews, demonstrate the effectiveness and usability of our approach.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:27:40 GMT""}]","2021-01-21"
"2101.07991","Tomoharu Suda","Tomoharu Suda","Equivalence of topological dynamics without well-posedness","24 pages, to appear in Topology and its Applications",,"10.1016/j.topol.2022.108045",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The notion of topological equivalence plays an essential role in the study of
dynamical systems of flows. However, it is inherently difficult to generalize
this concept to systems without well-posedness in the sense of Hadamard. In
this study, we formulate a notion of ""topological equivalence"" between such
systems based on the axiomatic theory of topological dynamics proposed by
Yorke, and discuss its relation with the usual definition. During this process,
we generalize Yorke's theory to the action of topological groups.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:28:18 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 02:53:55 GMT""}]","2022-02-22"
"2101.07992","Lingzhong Zeng","Lingzhong Zeng and Zhouyuan Zeng","Eigenvalues of Xin-Laplacian on Complete Riemannian manifolds","All comments are welcome",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we firstly consider Dirichlet eigenvalue problem which is
related to Xin-Laplacian on the bounded domain of complete Riemannian
manifolds. By establishing the general formulas, combining with some results of
Chen and Cheng type, we prove some eigenvalue inequalities. As some
applications, we consider the eigenvalues on some Riemannian manifolds
admitting with special functions, the translating solitons, minimal
submanifolds on the Euclidean spaces, submanifolds on the unit spheres,
projective spaces and so on. In particular, for the case of translating
solitons, some eigenvalue inequalities are universal. Moreover, we investigate
the closed eigenvalue problem for the Xin-Laplacian and generalize the Reilly's
result on the first eigenvalue of the Laplace-Beltrami operator. As some
remarkable applications, we obtain a very sharp estimate for the upper bound of
the second nonzero eigenvalue(without counting multiplicities of eigenvalues)
of the Laplace-Beltrami operator on the minimal isoparametric hypersurfaces and
focal submanifolds in the unit sphere, which leads to a conjecture and is the
most fascinating part of this paper.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:33:43 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 03:01:22 GMT""}]","2022-02-08"
"2101.07993","Crystal Lee","Crystal Lee, Tanya Yang, Gabrielle Inchoco, Graham M. Jones, Arvind
  Satyanarayan","Viral Visualizations: How Coronavirus Skeptics Use Orthodox Data
  Practices to Promote Unorthodox Science Online","To appear in ACM CHI 2021; 18 pages, 4 figures, 1 table",,"10.1145/3411764.3445211",,"cs.HC cs.CY","http://creativecommons.org/licenses/by/4.0/","  Controversial understandings of the coronavirus pandemic have turned data
visualizations into a battleground. Defying public health officials,
coronavirus skeptics on US social media spent much of 2020 creating data
visualizations showing that the government's pandemic response was excessive
and that the crisis was over. This paper investigates how pandemic
visualizations circulated on social media, and shows that people who mistrust
the scientific establishment often deploy the same rhetorics of data-driven
decision-making used by experts, but to advocate for radical policy changes.
Using a quantitative analysis of how visualizations spread on Twitter and an
ethnographic approach to analyzing conversations about COVID data on Facebook,
we document an epistemological gap that leads pro- and anti-mask groups to draw
drastically different inferences from similar data. Ultimately, we argue that
the deployment of COVID data visualizations reflect a deeper sociopolitical
rift regarding the place of science in public life.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:36:47 GMT""}]","2021-01-21"
"2101.07994","Hongyu Zhou","Hongyu Zhou and Changliu Liu","Distributed Motion Coordination Using Convex Feasible Set Based Model
  Predictive Control","7 pages, 10 figures. ICRA 2021",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The implementation of optimization-based motion coordination approaches in
real world multi-agent systems remains challenging due to their high
computational complexity and potential deadlocks. This paper presents a
distributed model predictive control (MPC) approach based on convex feasible
set (CFS) algorithm for multi-vehicle motion coordination in autonomous
driving. By using CFS to convexify the collision avoidance constraints,
collision-free trajectories can be computed in real time. We analyze the
potential deadlocks and show that a deadlock can be resolved by changing
vehicles' desired speeds. The MPC structure ensures that our algorithm is
robust to low-level tracking errors. The proposed distributed method has been
tested in multiple challenging multi-vehicle environments, including
unstructured road, intersection, crossing, platoon formation, merging, and
overtaking scenarios. The numerical results and comparison with other
approaches (including a centralized MPC and reciprocal velocity obstacles) show
that the proposed method is computationally efficient and robust, and avoids
deadlocks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:41:53 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 03:41:48 GMT""}]","2021-06-03"
"2101.07995","Yaoxin Zhuo","Yaoxin Zhuo, Baoxin Li","FedNS: Improving Federated Learning for collaborative image
  classification on mobile clients",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) is a paradigm that aims to support loosely connected
clients in learning a global model collaboratively with the help of a
centralized server. The most popular FL algorithm is Federated Averaging
(FedAvg), which is based on taking weighted average of the client models, with
the weights determined largely based on dataset sizes at the clients. In this
paper, we propose a new approach, termed Federated Node Selection (FedNS), for
the server's global model aggregation in the FL setting. FedNS filters and
re-weights the clients' models at the node/kernel level, hence leading to a
potentially better global model by fusing the best components of the clients.
Using collaborative image classification as an example, we show with
experiments from multiple datasets and networks that FedNS can consistently
achieve improved performance over FedAvg.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:45:46 GMT""}]","2021-01-21"
"2101.07996","Xin Liu","Xin Liu, Yuang Li, Josh Fromm, Yuntao Wang, Ziheng Jiang, Alex
  Mariakakis, Shwetak Patel","SplitSR: An End-to-End Approach to Super-Resolution on Mobile Devices",,,,,"cs.HC cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Super-resolution (SR) is a coveted image processing technique for mobile apps
ranging from the basic camera apps to mobile health. Existing SR algorithms
rely on deep learning models with significant memory requirements, so they have
yet to be deployed on mobile devices and instead operate in the cloud to
achieve feasible inference time. This shortcoming prevents existing SR methods
from being used in applications that require near real-time latency. In this
work, we demonstrate state-of-the-art latency and accuracy for on-device
super-resolution using a novel hybrid architecture called SplitSR and a novel
lightweight residual block called SplitSRBlock. The SplitSRBlock supports
channel-splitting, allowing the residual blocks to retain spatial information
while reducing the computation in the channel dimension. SplitSR has a hybrid
design consisting of standard convolutional blocks and lightweight residual
blocks, allowing people to tune SplitSR for their computational budget. We
evaluate our system on a low-end ARM CPU, demonstrating both higher accuracy
and up to 5 times faster inference than previous approaches. We then deploy our
model onto a smartphone in an app called ZoomSR to demonstrate the first-ever
instance of on-device, deep learning-based SR. We conducted a user study with
15 participants to have them assess the perceived quality of images that were
post-processed by SplitSR. Relative to bilinear interpolation -- the existing
standard for on-device SR -- participants showed a statistically significant
preference when looking at both images (Z=-9.270, p<0.01) and text (Z=-6.486,
p<0.01).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:47:41 GMT""}]","2021-01-21"
"2101.07997","Zhanlin Liu","Zhanlin Liu and Youngjun Choe","Data-driven sparse polynomial chaos expansion for models with dependent
  inputs",,,,,"eess.SY cs.SY stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polynomial chaos expansions (PCEs) have been used in many real-world
engineering applications to quantify how the uncertainty of an output is
propagated from inputs. PCEs for models with independent inputs have been
extensively explored in the literature. Recently, different approaches have
been proposed for models with dependent inputs to expand the use of PCEs to
more real-world applications. Typical approaches include building PCEs based on
the Gram-Schmidt algorithm or transforming the dependent inputs into
independent inputs. However, the two approaches have their limitations
regarding computational efficiency and additional assumptions about the input
distributions, respectively. In this paper, we propose a data-driven approach
to build sparse PCEs for models with dependent inputs. The proposed algorithm
recursively constructs orthonormal polynomials using a set of monomials based
on their correlations with the output. The proposed algorithm on building
sparse PCEs not only reduces the number of minimally required observations but
also improves the numerical stability and computational efficiency. Four
numerical examples are implemented to validate the proposed algorithm.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:06:50 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 01:44:40 GMT""}]","2021-06-02"
"2101.07998","Clancy James","C.W. James, J.X. Prochaska, J.-P. Macquart, F. North-Hickey, K. W.
  Bannister, A. Dunning","The fast radio burst population evolves, consistent with the
  star-formation rate","8 pages, 2 tables, 3 figures. Revised from v1 to include (1+z)^-1
  time dilation in FRB rate",,"10.1093/mnrasl/slab117",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Fast radio bursts (FRBs) are extremely powerful sources of radio waves
observed at cosmological distances. We use a sophisticated model of FRB
observations -- presented in detail in a companion paper -- to fit FRB
population parameters using large samples of FRBs detected by ASKAP and Parkes,
including seven sources with confirmed host galaxies. Our fitted parameters
demonstrate that the FRB population evolves with redshift in a manner
consistent with, or faster than, the star-formation rate (SFR), ruling out a
non-evolving population at 99.9\% C.L. Our estimated maximum FRB energy is
$\log_{10} E_{\rm max} [{\rm erg}] = 41.84_{-0.18}^{+0.49}$ (68\% C.L.)
assuming a 1\,GHz emission bandwidth, with slope of the cumulative luminosity
distribution $\gamma=-1.16_{-0.12}^{+0.11}$. We find a log-mean host DM
contribution of $145_{-60}^{+64}$\,pc\,cm$^{-3}$ on top of a typical local (ISM
and halo) contribution of $\sim80$\,pc\,cm$^{-3}$, which is higher than most
literature values. These results are consistent with the model of FRBs arising
as the high-energy limit of magnetar bursts, but allow for FRB progenitors that
evolve faster than the SFR.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:14:15 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 03:08:19 GMT""}]","2021-11-17"
"2101.07999","Hiromu Yakura","Hiromu Yakura","No More Handshaking: How have COVID-19 pushed the expansion of
  computer-mediated communication in Japanese idol culture?","To appear in ACM CHI Conference on Human Factors in Computing Systems
  (CHI '21), May 8-13, 2021, Yokohama, Japan",,"10.1145/3411764.3445252",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Japanese idol culture, meet-and-greet events where fans were allowed to
handshake with an idol member for several seconds were regarded as its
essential component until the spread of COVID-19. Now, idol groups are
struggling in the transition of such events to computer-mediated communication
because these events had emphasized meeting face-to-face over communicating, as
we can infer from their length of time. I anticipated that investigating this
emerging transition would provide implications because their communication has
a unique characteristic that is distinct from well-studied situations, such as
workplace communication and intimate relationships. Therefore, I first
conducted a quantitative survey to develop a precise understanding of the
transition, and based on its results, had semi-structured interviews with idol
fans about their perceptions of the transition. The survey revealed distinctive
approaches, including one where fans gathered at a venue but were isolated from
the idol member by an acrylic plate and talked via a video call. Then the
interviews not only provided answers to why such an approach would be
reasonable but also suggested the existence of a large gap between conventional
offline events and emerging online events in their perceptions. Based on the
results, I discussed how we can develop interaction techniques to support this
transition and how we can apply it to other situations outside idol culture,
such as computer-mediated performing arts.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:14:59 GMT""}]","2021-01-21"
"2101.08000","Zhangzi Zhu","Zhangzi Zhu, Tianlei Wang, and Hong Qu","Macroscopic Control of Text Generation for Image Captioning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the fact that image captioning models have been able to generate
impressive descriptions for a given image, challenges remain: (1) the
controllability and diversity of existing models are still far from
satisfactory; (2) models sometimes may produce extremely poor-quality captions.
In this paper, two novel methods are introduced to solve the problems
respectively. Specifically, for the former problem, we introduce a control
signal which can control the macroscopic sentence attributes, such as sentence
quality, sentence length, sentence tense and number of nouns etc. With such a
control signal, the controllability and diversity of existing captioning models
are enhanced. For the latter problem, we innovatively propose a strategy that
an image-text matching model is trained to measure the quality of sentences
generated in both forward and backward directions and finally choose the better
one. As a result, this strategy can effectively reduce the proportion of
poorquality sentences. Our proposed methods can be easily applie on most image
captioning models to improve their overall performance. Based on the Up-Down
model, the experimental results show that our methods achieve BLEU-
4/CIDEr/SPICE scores of 37.5/120.3/21.5 on MSCOCO Karpathy test split with
cross-entropy training, which surpass the results of other state-of-the-art
methods trained by cross-entropy loss.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:20:07 GMT""}]","2021-01-21"
"2101.08001","Siyi Hu","Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang","UPDeT: Universal Multi-agent Reinforcement Learning via Policy
  Decoupling with Transformers","15 pages, 8 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in multi-agent reinforcement learning have been largely
limited in training one model from scratch for every new task. The limitation
is due to the restricted model architecture related to fixed input and output
dimensions. This hinders the experience accumulation and transfer of the
learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs
6 multi-agent games). In this paper, we make the first attempt to explore a
universal multi-agent reinforcement learning pipeline, designing one single
architecture to fit tasks with the requirement of different observation and
action configurations. Unlike previous RNN-based models, we utilize a
transformer-based model to generate a flexible policy by decoupling the policy
distribution from the intertwined input observation with an importance weight
measured by the merits of the self-attention mechanism. Compared to a standard
transformer block, the proposed model, named as Universal Policy Decoupling
Transformer (UPDeT), further relaxes the action restriction and makes the
multi-agent task's decision process more explainable. UPDeT is general enough
to be plugged into any multi-agent reinforcement learning pipeline and equip
them with strong generalization abilities that enables the handling of multiple
tasks at a time. Extensive experiments on large-scale SMAC multi-agent
competitive games demonstrate that the proposed UPDeT-based multi-agent
reinforcement learning achieves significant results relative to
state-of-the-art approaches, demonstrating advantageous transfer capability in
terms of both performance and training speed (10 times faster).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:24:24 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 05:12:07 GMT""},{""version"":""v3"",""created"":""Sun, 7 Feb 2021 10:28:41 GMT""}]","2021-02-09"
"2101.08002","Muhammad Shahid Iqbal","Muhammad Shahid Iqbal, Yalcin Sadi, Sinem Coleri","Minimum Length Scheduling for Multi-cell Full Duplex Wireless Powered
  Communication Networks",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate a novel minimum length scheduling problem to
determine the optimal power control, and scheduling for constant and continuous
rate models, while considering concurrent transmission of users, energy
causality, maximum transmit power and traffic demand constraints. The
formulated optimization problems are shown to be non-convex and combinatorial
in nature, thus, difficult to solve for the global optimum. As a solution
strategy, first, we propose optimal polynomial time algorithms for the power
control problem considering constant and continuous rate models based on the
evaluation of Perron-Frobenius conditions and usage of bisection method,
respectively. Then, the proposed optimal power control solutions are used to
determine the optimal transmission time for a subset of users that will be
scheduled by the scheduling algorithms. For the constant rate scheduling
problem, we propose a heuristic algorithm that aims to maximize the number of
concurrently transmitting users by maximizing the allowable interference on
each user without violating the signal-to-noise-ratio (SNR) requirements. For
the continuous rate scheduling problem, we define a penalty function
representing the advantage of concurrent transmission over individual
transmission of the users. Following the optimality analysis of the penalty
metric and demonstration of the equivalence between schedule length
minimization and minimization of the sum of penalties, we propose a heuristic
algorithm based on the allocation of the concurrently transmitting users with
the goal of minimizing the sum penalties over the schedule. Through extensive
simulations, we demonstrate that the proposed algorithm outperforms the
successive transmission and concurrent transmission of randomly selected users
for different HAP transmit powers, network densities and network size.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:25:19 GMT""}]","2021-01-21"
"2101.08003","Raj Gupta","Amrit Kumar, Raj Kumar Gupta, V. Manjuladevi, Ashutosh Joshi","Surface plasmon resonance for in-plane birefringence measurement of
  anisotropic thin organic film","13 pages, 5 figures, Plasmonics (Springer)",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The measurement of in-plane birefringence ($\Delta{n}$) of ultrathin film is
challenging due to a significant deviation of physical properties of materials
in ultrathin regime as compared to that in bulk state. Surface plasmon
resonance (SPR) phenomenon can be employed to measure change in refractive
index of ultrathin film at a very high resolution. This article discusses
simulation of SPR phenomenon in Kretschmann configuration for the measurement
of $\Delta{n}$ in organic thin film exhibiting nematic-like ordering on the two
dimensional gold surface. The distribution of plasmonic field on the gold
surface was found to be anisotropic. This suggested that the coupling plasmonic
field with that of organic thin film exhibiting nematic-like ordering on the
gold surface will be non-isotropic. Therefore, a non-zero difference in
resonance angle (RA) was obtained from SPR measurement performed along the
optic-axis (OA) and orthogonal to OA of the in-plane nematic ordering
($\Delta\theta$). A calibration surface showing the variation of
($\Delta\theta$) as a function of $\Delta{n}$ and thickness of thin organic
film consisting of shape anisotropic tilted molecules exhibiting nematic-like
ordering on gold surface was obtained. This calibration surface was employed
for the measurement of $\Delta{n}$ of single layer of Langmuir-Blodgett films
of cadmium stearate (CdSA) and 4'-octyl-4-biphenylcarbonitrile (8CB) deposited
on SPR chips. The thickness of the LB films was estimated using X-ray
reflectivity measurement and $\Delta\theta$ was measured using a home built SPR
instrument. The $\Delta{n}$ values were found to be 0.012 and 0.022 for
ultrathin films of CdSA and 8CB molecules, respectively.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:25:43 GMT""}]","2021-01-21"
"2101.08004","Jian Wang","Erica L.L. Liu, Jian Wang","The Generalized Tur\'{a}n Problem of Two Intersecting Cliques","20 pages,5 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $s<r$, let $B_{r,s}$ be the graph consisting of two copies of $K_r$,
which share exactly $s$ vertices. Denote by $ex(n, K_r, B_{r,s})$ the maximum
number of copies of $K_r$ in a $B_{r,s}$-free graph on $n$ vertices. In 1976,
Erd\H{o}s and S\'{o}s determined $ex(n,K_3,B_{3,1})$. Recently, Gowers and
Janzer showed that $ex(n,K_r,B_{r,r-1})=n^{r-1-o(1)}$. It is a natural question
to ask for $ex(n,K_r,B_{r,s})$ for general $r$ and $s$. In this paper, we
mainly consider the problem for $s=1$. Utilizing the Zykov's symmetrization, we
show that $ex(n,K_4, B_{4,1})=\lfloor (n-2)^2/4\rfloor$ for $n\geq 45$. For
$r\geq 5$ and $n$ sufficiently large, by the F\""{u}redi's structure theorem we
show that $ex(n,K_r,B_{r,1}) =\mathcal{N}(K_{r-2},T_{r-2}(n-2))$, where
$\mathcal{N}(K_{r-2},T_{r-2}(n-2))$ represents the number of copies of
$K_{r-2}$ in the $(r-2)$-partite Tur\'{a}n graph on $n-2$ vertices.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:27:24 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 12:47:41 GMT""}]","2021-06-09"
"2101.08005","Clancy James","C.W. James, J.X. Prochaska, J.-P. Macquart, F. North-Hickey, K.W.
  Bannister, A. Dunning","The z--DM distribution of fast radio bursts","23 pages, 17 figures, 8 tables",,"10.1093/mnras/stab3051",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We develop a sophisticated model of FRB observations, accounting for the
intrinsic cosmological gas distribution and host galaxy contributions, and give
the most detailed account yet of observational biases due to burst width,
dispersion measure, and the exact telescope beamshape. Our results offer a
significant increase in both accuracy and precision beyond those previously
obtained. Using results from ASKAP and Parkes, we present our best-fit FRB
population parameters in a companion paper. Here, we consider in detail the
expected and fitted distributions in redshift, dispersion measure, and
signal-to-noise. We estimate that the unlocalised ASKAP FRBs arise from
$z<0.5$, with between a third and a half within $z<0.1$. Our predicted
source-counts (""logN--logS"") distribution confirms previous indications of a
steepening index near the Parkes detection threshold of $1$\,Jy\,ms. We find no
evidence for a minimum FRB energy, and rule out $E_{\rm min} > 10^{38.5}$\,erg
at 90\% C.L. Importantly, we find that above a certain DM, observational biases
cause the Macquart (DM--z) relation to become inverted, implying that the
highest-DM events detected in the unlocalised Parkes and ASKAP samples are
unlikely to be the most distant. We do not expect our quantitative estimates in
this region to be accurate until it is directly probed with localised FRBs.
Since the cause of this effect is a well-understood observational bias however,
it is guaranteed to be present to some degree. Works assuming a 1--1 DM--z
relation may therefore derive erroneous results.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:27:32 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 03:22:11 GMT""}]","2021-11-17"
"2101.08006","Fatemeh Zahra Zeraat Gari","Amin Mosallanezhad, Fatemeh Zahra Zeraatgari, Liquan Mei, De-Fu Bu","Two-dimensional Inflow-Wind Solution of Hot Accretion Flow. I.
  Hydrodynamics","20 pages, 10 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abde49",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We solve the two-dimensional hydrodynamic equations of hot accretion flow in
the presence of the thermal conduction. The flow is assumed to be in
steady-state and axisymmetric, and self-similar approximation is adopted in the
radial direction. In this hydrodynamic study, we consider the viscous stress
tensor to mimic the effects of the magnetorotational instability for driving
angular momentum. We impose the physical boundary conditions at both the
rotation axis and the equatorial plane and obtain the solutions in the full $
r-\theta $ space. We have found that thermal conduction is indispensable term
for investigating the inflow-wind structure of the hot accretion flows with
very low mass accretion rates. One of the most interesting results here is that
the disc is convectively stable in hot accretion mode and in the presence of
the thermal conduction. Furthermore, the properties of wind and also its
driving mechanisms are studied. Our analytical results are consistent with
previous numerical simulations of hot accretion flow.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:28:20 GMT""}]","2021-03-24"
"2101.08007","Jose M. Pe\~na","Jose M. Pe\~na","On the Non-Monotonicity of a Non-Differentially Mismeasured Binary
  Confounder","arXiv admin note: text overlap with arXiv:2005.13245",,,,"stat.ME cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose that we are interested in the average causal effect of a binary
treatment on an outcome when this relationship is confounded by a binary
confounder. Suppose that the confounder is unobserved but a non-differential
binary proxy of it is observed. We identify conditions under which adjusting
for the proxy comes closer to the incomputable true average causal effect than
not adjusting at all. Unlike other works, we do not assume that the average
causal effect of the confounder on the outcome is in the same direction among
treated and untreated.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:42:54 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jan 2021 16:04:50 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 09:02:05 GMT""}]","2021-01-29"
"2101.08008","Prateek Bansal","Prateek Bansal, Rajeev Ranjan Kumar, Alok Raj, Subodh Dubey, Daniel J.
  Graham","Willingness to Pay and Attitudinal Preferences of Indian Consumers for
  Electric Vehicles",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consumer preference elicitation is critical to devise effective policies for
the diffusion of electric vehicles (EVs) in India. This study contributes to
the EV demand literature in the Indian context by (a) analysing the EV
attributes and attitudinal factors of Indian car buyers that determine
consumers' preferences for EVs, (b) estimating Indian consumers' willingness to
pay (WTP) to buy EVs with improved attributes, and c) quantifying how the
reference dependence affects the WTP estimates. We adopt a hybrid choice
modelling approach for the above analysis. The results indicate that accounting
for reference dependence provides more realistic WTP estimates than the
standard utility estimation approach. Our results suggest that Indian consumers
are willing to pay an additional USD 10-34 in the purchase price to reduce the
fast charging time by 1 minute, USD 7-40 to add a kilometre to the driving
range of EVs at 200 kilometres, and USD 104-692 to save USD 1 per 100
kilometres in operating cost. These estimates and the effect of attitudes on
the likelihood to adopt EVs provide insights about EV design, marketing
strategies, and pro-EV policies (e.g., specialised lanes and reserved parking
for EVs) to expedite the adoption of EVs in India.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:43:06 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 04:29:45 GMT""}]","2021-05-14"
"2101.08009","Danfeng Xiang","Danfeng Xiang, Xiaofeng Wang, Weili Lin, Jun Mo, Han Lin, Jamison
  Burke, Daichi Hiramatsu, Griffin Hosseinzadeh, D. Andrew Howell, Curtis
  McCully, Stefan Valenti, J\'ozsef Vink\'o, J. Craig Wheeler, Shuhrat A.
  Ehgamberdiev, Davron Mirzaqulov, Attila B\'odi, Zs\'ofia Bogn\'ar, Borb\'ala
  Cseh, Ott\'o Hanyecz, Bernadett Ign\'acz, Csilla Kalup, R\'eka
  K\""onyves-T\'oth, Levente Kriskovics, Andr\'as Ordasi, Andr\'as P\'al,
  Kriszti\'an S\'arneczky, B\'alint Seli, R\'obert Szak\'ats, T. Arranz-Heras,
  R. Benavides-Palencia, D. Cejudo-Mart\'inez, P. De la Fuente-Fern\'andez, A.
  Escart\'in-P\'erez, F. Garc\'ia-De la Cuesta, J.L. Gonz\'alez-Carballo, R.
  Gonz\'alez-Farf\'an, F. Lim\'on-Mart\'inez, A. Mantero, R. Naves-Nogu\'es, M.
  Morales-Aimar, V. R. Ru\'iz-Ru\'iz, F.C. Sold\'an-Alfaro, J. Valero-P\'erez,
  F. Violat-Bordonau, Tianmeng Zhang, Jujia Zhang, Xue Li, Zhihao Chen, Hanna
  Sai, and Wenxiong Li","The Peculiar Transient AT2018cow: A Possible Origin of A Type Ibn/IIn
  Supernova","Accepted for publication in ApJ",,"10.3847/1538-4357/abdeba",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present our photometric and spectroscopic observations on the peculiar
transient AT2018cow. The multi-band photometry covers from peak to $\sim$70
days and the spectroscopy ranges from 5 to $\sim$50 days. The rapid rise
($t_{\mathrm{r}}$$\lesssim$2.9 days), high luminosity
($M_{V,\mathrm{peak}}\sim-$20.8 mag) and fast decline after peak make AT2018cow
stand out of any other optical transients. While we find that its light curves
show high resemblance to those of type Ibn supernovae. Moreover, the spectral
energy distribution remains high temperature of $\sim$14,000 K after $\sim$15
days since discovery. The spectra are featureless in the first 10 days, while
some broad emission lines due to H, He, C and O emerge later, with velocity
declining from $\sim$14,000 km s$^{-1}$ to $\sim$3000 km s$^{-1}$ at the end of
our observations. Narrow and weak He I emission lines emerge in the spectra at
$t>$20 days since discovery. These emission lines are reminiscent of the
features seen in interacting supernovae like type Ibn and IIn subclasses. We
fit the bolometric light curves with a model of circumstellar interaction (CSI)
and radioactive decay (RD) of \Ni and find a good fit with ejecta mass
$M_{\mathrm{ej}}\sim$3.16 M$_{\odot}$, circumstellar material mass
$M_{\mathrm{CSM}}\sim$0.04 M$_{\odot}$, and ejected \Ni mass
$M_{^{56}\mathrm{Ni}}\sim$0.23 M$_{\odot}$. The CSM shell might be formed in an
eruptive mass ejection of the progenitor star. Furthermore, host environment of
AT2018cow implies connection of AT2018cow with massive stars. Combining
observational properties and the light curve fitting results, we conclude that
AT2018cow might be a peculiar interacting supernova originated from a massive
star.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:43:52 GMT""}]","2021-03-31"
"2101.08010","Zhenhao Cai","Zhenhao Cai and Yuan Zhang","Some Rigorous Results on the Phase Transition of Finitary Random
  Interlacement",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show several rigorous results on the phase transition of
Finitary Random Interlacement (FRI). For the high intensity regime, we show the
existence of a critical fiber length, and give the exact asymptotic of it as
intensity goes to infinity. At the same time, our result for the low intensity
regime proves the global existence of a non-trivial phase transition with
respect to the system intensity.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:58:54 GMT""}]","2021-01-21"
"2101.08011","Anca Muscholl","Sougata Bose, S.N. Krishna, Anca Muscholl, Gabriele Puppis","One-way resynchronizability of word transducers",,,,,"cs.FL cs.LO","http://creativecommons.org/licenses/by/4.0/","  The origin semantics for transducers was proposed in 2014, and led to various
characterizations and decidability results that are in contrast with the
classical semantics. In this paper we add a further decidability result for
characterizing transducers that are close to one-way transducers in the origin
semantics. We show that it is decidable whether a non-deterministic two-way
word transducer can be resynchronized by a bounded, regular resynchronizer into
an origin-equivalent one-way transducer. The result is in contrast with the
usual semantics, where it is undecidable to know if a non-deterministic two-way
transducer is equivalent to some one-way transducer.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:59:46 GMT""}]","2021-01-21"
"2101.08012","Shoulong Li","Shou-Long Li, Lijing Shao, Puxun Wu and Hongwei Yu","NANOGrav Signal from First-Order Confinement/Deconfinement Phase
  Transition in Different QCD Matters","latex, 12 pages, 2 figures; v2: minor corrections, references updated","Phys. Rev. D 104, 043510 (2021)","10.1103/PhysRevD.104.043510",,"astro-ph.CO gr-qc hep-ph hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  Recently, an indicative evidence of a stochastic process, reported by the
NANOGrav Collaboration based on the analysis of 12.5-year pulsar timing array
data which might be interpreted as a potential stochastic gravitational wave
signal, has aroused keen interest of theorists. The first-order color charge
confinement phase transition at the QCD scale could be one of the cosmological
sources for the NANOGrav signal. If the phase transition is flavor dependent
and happens sequentially, it is important to find that what kind of QCD matter
in which the first-order confinement/deconfinement phase transition happens is
more likely to be the potential source of the NANOGrav signal during the
evolution of the universe. In this paper, we would like to illustrate that the
NANOGrav signal could be generated from confinement/deconfinement transition in
either heavy static quarks with a zero baryon chemical potential, or quarks
with a finite baryon chemical potential. In contrast, the gluon confinement
could not possibly be the source for the NANOGrav signal according to the
current observation. Future observation will help to distinguish between
different scenarios.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:06:11 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 02:17:52 GMT""}]","2021-08-11"
"2101.08013","Quoc-Viet Pham","Prabadevi B, Quoc-Viet Pham, Madhusanka Liyanage, N Deepa, Mounik
  VVSS, Shivani Reddy, Praveen Kumar Reddy Maddikunta, Neelu Khare, Thippa
  Reddy Gadekallu, Won-Joo Hwang","Deep Learning for Intelligent Demand Response and Smart Grids: A
  Comprehensive Survey","This work has been submitted for possible publication. Any comments
  and suggestions are appreciated",,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electricity is one of the mandatory commodities for mankind today. To address
challenges and issues in the transmission of electricity through the
traditional grid, the concepts of smart grids and demand response have been
developed. In such systems, a large amount of data is generated daily from
various sources such as power generation (e.g., wind turbines), transmission
and distribution (microgrids and fault detectors), load management (smart
meters and smart electric appliances). Thanks to recent advancements in big
data and computing technologies, Deep Learning (DL) can be leveraged to learn
the patterns from the generated data and predict the demand for electricity and
peak hours. Motivated by the advantages of deep learning in smart grids, this
paper sets to provide a comprehensive survey on the application of DL for
intelligent smart grids and demand response. Firstly, we present the
fundamental of DL, smart grids, demand response, and the motivation behind the
use of DL. Secondly, we review the state-of-the-art applications of DL in smart
grids and demand response, including electric load forecasting, state
estimation, energy theft detection, energy sharing and trading. Furthermore, we
illustrate the practicality of DL via various use cases and projects. Finally,
we highlight the challenges presented in existing research works and highlight
important issues and potential directions in the use of DL for smart grids and
demand response.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:07:41 GMT""}]","2021-01-21"
"2101.08014","Iacovos Ioannou I.I.","Iacovos Ioannou, Christophoros Christophorou, Vasos Vassiliou, Andreas
  Pitsillides","5G D2D Transmission Mode Selection Performance & Cluster Limits
  Evaluation of Distributed Artificial Intelligence and Machine Learning
  Techniques",,,,,"cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  5G D2D Communication promises improvements in energy and spectral efficiency,
overall system capacity, and higher data rates. However, to achieve optimum
results it is important to select wisely the Transmission mode of the D2D
Device to form clusters in the most fruitful positions in terms of Sum Rate and
Power Consumption. Towards this end, this paper investigates the use of
Distributed Artificial Intelligence (DAI) and innovative to D2D, Machine
Learning (ML) approaches to achieve satisfactory results in terms of Spectral
Efficiency (SE), Power Consumption (PC) and execution time, with the creation
of clusters and backhauling D2D network under existing Base Station/Small Cell.
Additionally, one of the major factors that affect the creation of high-quality
clusters under a D2D network is the number of the Devices. Therefore, this
paper focuses on a small (<=200) number of Devices, with the purpose to
identify the limits of each approach in terms of number of devices.
Specifically, to identify where it is beneficial to form a cluster, investigate
the critical point that gains increases rapidly and at the end examine the
applicability of 5G requirements. Additionally, prior work presented a
Distributed Artificial Intelligence (DAI) Solution/Framework in D2D and a DAIS
Transmission Mode Selection (TMS) plan was proposed. In this paper DAIS is
further examined, improved in terms of thresholds evaluation, evaluated, and
compared with other approaches (AI/ML). The results obtained demonstrate the
exceptional performance of DAIS, compared to all other related approaches in
terms of SE, PC, execution time and cluster formation efficiency. Also, results
show that the investigated AI/ML approaches are also beneficial for
Transmission Mode Selection (TMS) in 5G D2D communication, even with a smaller
(i.e., >=5 D2D Relay,>=50 D2D Multi Hop Relay) numbers of devices as a lower
limits.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:11:08 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 10:59:35 GMT""},{""version"":""v3"",""created"":""Wed, 17 Feb 2021 16:22:46 GMT""},{""version"":""v4"",""created"":""Wed, 28 Apr 2021 05:55:28 GMT""}]","2021-04-29"
"2101.08015","S. Berceanu","Stefan Berceanu","Geodesics on the extended Siegel-Jacobi upper half-plane","27 pages, Latex, amsart, AMS fonts",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The semidirect product of the real Heisenberg group ${\rm H}_1(\mathbb{R})$
with ${\rm SL}(2,\mathbb{R})$, called the real Jacobi group
$G^J_1(\mathbb{R})$, admits a four-parameter invariant metric expressed in the
S-coordinates. We determine the geodesic equations on the extended
Siegel--Jacobi upper half-plane $\tilde{\mathcal{X}}^J_1
=\frac{G^J_1(\R)}{\rm{SO}(2)}\approx\mathcal{X}^J_1\times\mathbb{R}\approx
\mathcal{X}_1 \times\mathbb{R}^3$, where $\mathcal{X}^J_1$ ($\mathcal{X}_1)$
denotes the Siegel-Jacobi upper half-plane (respectively Siegel upper
half-plane). Equating successively with zero the values of the three parameters
in the geodesic equations on $\tilde{\mathcal{X}}^J_1$, we get the geodesic
equations on $\mathcal{X}^J_1$, $\mathcal{X}_1$ and ${\rm H}_1(\mathbb{R})$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:12:18 GMT""}]","2021-01-21"
"2101.08016","Stephen MacDonell","Paolo Tell, Jil Kl\""under, Steffen K\""upper, David Raffo, Stephen G.
  MacDonell, J\""urgen M\""unch, Dietmar Pfahl, Oliver Linssen and Marco Kuhrmann","What are Hybrid Development Methods Made Of? An Evidence-based
  Characterization","Conference, 11 pages, 8 figures, 3 tables","Proceedings of the International Conference on Software and
  Systems Process (ICSSP2019). Montr\'eal, Canada, IEEE Computer Society Press,
  pp.105-114","10.1109/ICSSP.2019.00022",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among the multitude of software development processes available, hardly any
is used by the book. Regardless of company size or industry sector, a majority
of project teams and companies use customized processes that combine different
development methods -- so-called hybrid development methods. Even though such
hybrid development methods are highly individualized, a common understanding of
how to systematically construct synergetic practices is missing. In this paper,
we make a first step towards devising such guidelines. Grounded in 1,467 data
points from a large-scale online survey among practitioners, we study the
current state of practice in process use to answer the question: What are
hybrid development methods made of? Our findings reveal that only eight methods
and few practices build the core of modern software development. This small set
allows for statistically constructing hybrid development methods. Using an 85%
agreement level in the participants' selections, we provide two examples
illustrating how hybrid development methods are characterized by the practices
they are made of. Our evidence-based analysis approach lays the foundation for
devising hybrid development methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:12:47 GMT""}]","2021-01-21"
"2101.08017","Magnus Jonsson","Shangzhi Chen, Stefano Rossi, Ravi Shanker, Giancarlo Cincotti,
  Sampath Gamage, Philipp Kuhne, Vallery Stanishev, Isak Engquist, Magnus
  Berggren, Jesper Edberg, Vanya Darakchieva and Magnus P. Jonsson","Redox-tunable structural colour images based on UV-patterned conducting
  polymers",,,,,"physics.optics cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Precise manipulation of light-matter interaction has enabled a wide variety
of approaches to create bright and vivid structural colours. Techniques
utilizing photonic crystals, Fabry-P\'erot cavities, plasmonics, or
high-refractive index dielectric metasurfaces have been studied for
applications ranging from optical coatings to reflective displays. However,
complicated fabrication procedures for sub-wavelength nanostructures, limited
active areas, and inherent absence of tunability with these approaches
significantly impede their further developments towards flexible, large-scale,
and switchable devices compatible with facile and cost-effective production.
Herein, we present a way to generate structural colours based on conducting
polymer thin films prepared on metallic surfaces via vapour phase
polymerization and ultraviolet (UV) light patterning. Varying the UV dose leads
to synergistic variation of film absorption and thickness, which generates
controllable colours from violet to red. Together with greyscale photomasks
this enables fabrication of high-resolution colour images using single exposure
steps. We further demonstrate spatiotemporal tuning of the structurally
coloured surfaces and images via electrochemical modulation of the polymer
redox state. The simple structure, facile fabrication, wide colour gamut, and
dynamic colour tuning make this concept competitive for future multi-functional
and smart displays.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:17:00 GMT""}]","2021-01-21"
"2101.08018","Zheng Fang","Xingyin Fu, Zheng Fang, Xizhen Xiao, Yijia He, Xiao Liu","Improved Signed Distance Function for 2D Real-time SLAM and Accurate
  Localization","7 pages, 9 figures, conference paper",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accurate mapping and localization are very important for many industrial
robotics applications. In this paper, we propose an improved Signed Distance
Function (SDF) for both 2D SLAM and pure localization to improve the accuracy
of mapping and localization. To achieve this goal, firstly we improved the
back-end mapping to build a more accurate SDF map by extending the update range
and building free space, etc. Secondly, to get more accurate pose estimation
for the front-end, we proposed a new iterative registration method to align the
current scan to the SDF submap by removing random outliers of laser scanners.
Thirdly, we merged all the SDF submaps to produce an integrated SDF map for
highly accurate pure localization. Experimental results show that based on the
merged SDF map, a localization accuracy of a few millimeters (5mm) can be
achieved globally within the map. We believe that this method is important for
mobile robots working in scenarios where high localization accuracy matters.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:28:19 GMT""}]","2021-01-21"
"2101.08019","Carlos del Ca\~nizo","Eduardo Fornies, Carlos del Canizo, Laura Mendez, Alejandro Souto,
  Antonio Perez-Vazquez, Daniel Garrain","UMG silicon for solar PV: from defects detection to PV module
  degradation","17 pages, 13 figures. Accepted in Solar Energy","Solar Energy 220 (2021) 354-362","10.1016/j.solener.2021.03.076",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Upgraded metallurgical grade silicon (UMG-Si) for photovoltaic (PV) solar
applications has been manufactured through the metallurgical route by means of
the process developed by Ferrosolar. In an ambitious mass production test,
performed in commercial solar cells and modules production lines, the silicon
was proven to be appropriate for photovoltaics applications (Fornies et al.,
2019 Mass production test of solar cells and modules made of 100% umg silicon.
20.76% record efficiency. Energies 12), reaching, in a conventional production
line, up to 20.76% of solar cell efficiency with multicrystalline cells made of
100% UMG silicon. In this paper we present more results from the mentioned
massive test. Defect engineering is being applied to improve the bulk lifetime
of the UMG wafers and to guide in the identification of the limiting defects in
the material. Moreover, the modules produced with 100% UMG silicon solar cells
were installed together with the modules produced in the same production line
with polysilicon material to assess the degradation of the UMG silicon when
compared to polysilicon. After 24 months of outdoor PV generation, the
degradation, in terms of Performance Ratio at 25C (25PR) diminution, has been
the same for both types of modules. Additionally, a Life Cycle Assessment (LCA)
has been performed for this UMG silicon and state-of-the-art Siemens
polysilicon to compare the environmental impact of both silicon feedstocks. The
results presented in this paper; chemical analysis of wafers, defect
engineering, low degradation, average efficiency and environmental assessment,
lead to a complete study of UMG silicon, confirming its potential to be used as
raw material for PV applications.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:35:01 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 17:09:17 GMT""}]","2021-04-14"
"2101.08020","Xie Luodi","Luodi Xie, Hong Shen, Jiaxin Ren","NEMR: Network Embedding on Metric of Relation","11 pages, 5 figures",,,,"cs.SI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network embedding maps the nodes of a given network into a low-dimensional
space such that the semantic similarities among the nodes can be effectively
inferred. Most existing approaches use inner-product of node embedding to
measure the similarity between nodes leading to the fact that they lack the
capacity to capture complex relationships among nodes. Besides, they take the
path in the network just as structural auxiliary information when inferring
node embeddings, while paths in the network are formed with rich user
informations which are semantically relevant and cannot be ignored. In this
paper, We propose a novel method called Network Embedding on the Metric of
Relation, abbreviated as NEMR, which can learn the embeddings of nodes in a
relational metric space efficiently. First, our NEMR models the relationships
among nodes in a metric space with deep learning methods including variational
inference that maps the relationship of nodes to a gaussian distribution so as
to capture the uncertainties. Secondly, our NEMR considers not only the
equivalence of multiple-paths but also the natural order of a single-path when
inferring embeddings of nodes, which makes NEMR can capture the multiple
relationships among nodes since multiple paths contain rich user information,
e.g., age, hobby and profession. Experimental results on several public
datasets show that the NEMR outperforms the state-of-the-art methods on
relevant inference tasks including link prediction and node classification.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:35:03 GMT""}]","2021-01-21"
"2101.08021","Nico Ebert","Nico Ebert, Kurt Alexander Ackermann, Bj\""orn Scheppler","Bolder is Better: Raising User Awareness through Salient and Concise
  Privacy Notices",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  This paper addresses the question whether the recently proposed approach of
concise privacy notices in apps and on websites is effective in raising user
awareness. To assess the effectiveness in a realistic setting, we included
concise notices in a fictitious but realistic fitness tracking app and asked
participants recruited from an online panel to provide their feedback on the
usability of the app as a cover story. Importantly, after giving feedback,
users were also asked to recall the data practices described in the notices.
The experimental setup included the variation of different levels of saliency
and riskiness of the privacy notices. Based on a total sample of 2,274
participants, our findings indicate that concise privacy notices are indeed a
promising approach to raise user awareness for privacy information when
displayed in a salient way, especially in case the notices describe risky data
practices. Our results may be helpful for regulators, user advocates and
transparency-oriented companies in creating or enforcing better privacy
transparency towards average users that do not read traditional privacy
policies.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:36:04 GMT""}]","2021-01-21"
"2101.08022","Tanyakarn Treeratanaphitak","Tanyakarn Treeratanaphitak and Nasser Mohieddin Abukhdeir","Diffuse-Interface Blended Method for Imposing Physical Boundaries in
  Two-Fluid Flows","Published in ACS Omega",,"10.1021/acsomega.3c00838",,"physics.flu-dyn cs.NA math.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multiphase flows are commonly found in chemical engineering processes such as
distillation columns, bubble columns, fluidized beds and heat exchangers. The
physical boundaries of domains in numerical simulations of multiphase flows are
generally defined by a conformal unstructured mesh which, depending on the
complexity of the physical system, results in time-consuming mesh generation
which frequently requires user-intervention. Furthermore, the resulting
conformal unstructured mesh could potentially contain a large number of skewed
elements, which is undesirable for numerical stability and accuracy. The
diffuse-interface approach allows for the use of a simple structured meshes to
be used while still capturing the desired physical (e.g., solid-fluid)
boundaries. In this work, a novel diffuse-interface method for the imposition
of physical boundaries is developed for the incompressible two-fluid multiphase
flow model. This model is appropriate for dispersed multiphase flows which are
pervasive in chemical engineering processes, in that this flow regime results
in high levels of mass and energy transfer between phases. A diffuse interface
is used to define the physical boundaries and boundary conditions are imposed
by blending the conservation equations from the two-fluid model with that of
the nondeformable solid. The results from the diffuse-interface method are
compared with results from a conformal unstructured mesh for different
interface functions and widths. For small interface widths, the accuracy of the
flow profile is unaffected by the choice of interface function and the phase
fraction distribution and flow behavior are within 3% compared to those from a
conformal mesh. As the interface width increases, the diffuse-interface
solution deviates from the conformal mesh solution in both the localized gas
fraction and the overall gas hold-up, resulting in a difference up to 30%.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:39:40 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 00:50:50 GMT""}]","2023-04-21"
"2101.08023","Erkan Bostanci","Fatih Ekinci, Erkan Bostanci, Ozlem Dagli and Mehmet Serdar Guzel","Analysis of Bragg Curve Parameters and Lateral Straggle for Proton and
  Carbon Beams",,,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heavy ions have varying effects on the target. The most important factor in
comparing this effect is Linear Energy Transfer (LET). Protons and carbons are
heavy ions with high LET. Since these ions lose energy through collisions as
they move through the tissue, their range is not long. This loss of energy
increases along the way, and the maximum energy loss is reached at the end of
the range. This whole process is represented by the Bragg curve. The input dose
of the Bragg curve, full width at half maximum (FWHM) value, Bragg peak
amplitude and position, and Penumbra thickness are important factors in
determining which particle is advantageous in tumor treatment. While heavy ions
move through the tissue, small deviations occur in their direction of travel
due to Coulomb collisions. These small deviations cause lateral straggle in the
dose profile. Lateral straggle is important in determining the type and energy
of the particle used in tumor treatments close to critical organs. In our
study, when the water phantom of protons and carbon beams with different
energies is taken into consideration, the input dose, FWHM value, peak
amplitude and position, penumbra thickness and lateral straggle are calculated
using the TRIM code and the results are compared with Monte Carlo (MC)
simulation. It was found that the proton has an average of 63% more FWHM and
53% more Penumbra than the carbon ion. The carbon ion has an average of 28-45
times greater Bragg peak amplitude at the same Bragg peak location than the
proton. It was observed that the proton scattered approximately 70% more in
lateral straggle. The difference was found to be around 1.32 mm. In line with
all these results, the most commonly used proton and carbon heavy ions in
hadron therapy applications were compared.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:40:19 GMT""}]","2021-01-21"
"2101.08024","Zhonghao Zhang","Zhonghao Zhang and Yipeng Liu and Xingyu Cao and Fei Wen and Ce Zhu","Scalable Deep Compressive Sensing",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning has been used to image compressive sensing (CS) for enhanced
reconstruction performance. However, most existing deep learning methods train
different models for different subsampling ratios, which brings additional
hardware burden. In this paper, we develop a general framework named scalable
deep compressive sensing (SDCS) for the scalable sampling and reconstruction
(SSR) of all existing end-to-end-trained models. In the proposed way, images
are measured and initialized linearly. Two sampling masks are introduced to
flexibly control the subsampling ratios used in sampling and reconstruction,
respectively. To make the reconstruction model adapt to any subsampling ratio,
a training strategy dubbed scalable training is developed. In scalable
training, the model is trained with the sampling matrix and the initialization
matrix at various subsampling ratios by integrating different sampling matrix
masks. Experimental results show that models with SDCS can achieve SSR without
changing their structure while maintaining good performance, and SDCS
outperforms other SSR methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:42:50 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 02:53:03 GMT""}]","2021-01-25"
"2101.08025","Magali Deleuil","M. Deleuil, D. Pollacco, C. Baruteau, H. Rauer, M. Blanc","Observational constraints on the formation and evolution of
  Neptune-class exoplanets","21 pages, 6 figures","Space Science Reviews, 2020, Volume 216, Issue 6, article id.105","10.1007/s11214-020-00726-2",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Among exoplanets, the small-size population constitutes the dominant one,
with a diversity of properties and compositions ranging from rocky to gas
dominated envelope. While a large fraction of them have masses and radii
similar to or smaller than Neptune, yet none share common properties in term of
orbital period and insulation with our ice giants. These exoplanets belong to
multi-planet systems where planets are closely packed within the first tenth of
AU and often exposed to strong irradiation from their host star. Their
formation process, subsequent evolution, and fate are still debated and trigger
new developments of planet formation models. This paper reviews the
characteristics and properties of this extended sample of planets with radii
between $\sim$ 1.6 and 4.0$_\oplus$. Even though we still lack real
Neptune/Uranus analogues, these exoplanets provide us with key observational
constraints that allow the formation of our ice giants to be placed in a more
general framework than the sole example of our solar system.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:46:38 GMT""}]","2021-01-21"
"2101.08026","Zhe Wang","Huarui Wu, Jing Song, Wei-Ren Chen, Kun Song, Lionel Porcar, Zhe Wang","Size and shape fluctuations of ultrasoft colloids","6 pages, 4 figures","Phys. Rev. Research 3, 033271 (2021)","10.1103/PhysRevResearch.3.033271",,"cond-mat.soft physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Ultrasoft colloidal particle fluctuates due to its flexibility. Such
fluctuation is essential for colloidal structure and dynamics, but is
challenging to quantify experimentally. We use dendrimers as a model system to
study the fluctuation of ultrasoft colloids. By considering the dynamic
polydispersity in the small-angle neutron scattering (SANS) model, and
introducing the fluctuation of invasive water into the contrast in SANS, we
reveal the fluctuating amplitudes of the size and shape of the dendrimer of
generation 6 at finite concentrations. The size fluctuation is suppressed while
the shape fluctuation increases as the weight fraction of dendrimers passes
11%. With neutron spin echo data, we suggest that such crossover originates
from the competition between the inter- and intra-particle dynamics. Further
investigation on lower-generation samples shows a contrary result, which
suggests a structural basis for these dynamic phenomena.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:47:03 GMT""}]","2021-09-29"
"2101.08027","Likai Liu","Likai Liu, Zechun Hu, Xiaoyu Duan, Nikhil Pathak","Data-Driven Distributionally Robust Optimization for Real-Time Economic
  Dispatch Considering Secondary Frequency Regulation Cost","This paper has been accepted by IEEE Transactions on Power Systems",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the large-scale integration of renewable power generation, frequency
regulation resources (FRRs) are required to have larger capacities and faster
ramp rates, which increases the cost of the frequency regulation ancillary
service. Therefore, it is necessary to consider the frequency regulation cost
and constraint along with real-time economic dispatch (RTED). In this paper, a
data-driven distributionally robust optimization (DRO) method for RTED
considering automatic generation control (AGC) is proposed. First, a
Copula-based AGC signal model is developed to reflect the correlations among
the AGC signal, load power and renewable generation variations. Secondly,
samples of the AGC signal are taken from its conditional probability
distribution under the forecasted load power and renewable generation
variations. Thirdly, a distributionally robust RTED model considering the
frequency regulation cost and constraint is built and transformed into a linear
programming problem by leveraging the Wasserstein metric-based DRO technique.
Simulation results show that the proposed method can reduce the total cost of
power generation and frequency regulation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:52:52 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 12:43:20 GMT""}]","2021-01-27"
"2101.08028","Jarah Evslin","Jarah Evslin and Hengyuan Guo","An Alternative to Collective Coordinates","6 pages, no figures","Phys. Rev. D 103, 041701 (2021)","10.1103/PhysRevD.103.L041701",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collective coordinates provide a powerful tool for separating collective and
elementary excitations, allowing both to be treated in the full quantum theory.
The price is a canonical transformation which leads to a complicated starting
point for subsequent calculations. Sometimes the collective behavior of a
soliton is simple but nontrivial, and one is interested in the elementary
excitations. We show that in this case an alternative prescription suffices, in
which the canonical transformation is not necessary. The use of a
nonperturbative operator which creates a soliton state allows the theory to be
constructed perturbatively in terms of the soliton normal modes. We show how
translation invariance may be perturbatively imposed. We apply this to
construct the two-loop ground state of an arbitrary scalar kink.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:56:02 GMT""}]","2021-02-17"
"2101.08029","Pierpaolo Vivo","Vito A R Susca, Pierpaolo Vivo, Reimer K\""uhn","Cavity and replica methods for the spectral density of sparse symmetric
  random matrices","52 pag., 5 fig. Typos fixed. Submission to SciPost","SciPost Phys. Lect. Notes 33 (2021)","10.21468/SciPostPhysLectNotes.33",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the problem of how to compute the spectral density of sparse
symmetric random matrices, i.e. weighted adjacency matrices of undirected
graphs. Starting from the Edwards-Jones formula, we illustrate the milestones
of this line of research, including the pioneering work of Bray and Rodgers
using replicas. We focus first on the cavity method, showing that it quickly
provides the correct recursion equations both for single instances and at the
ensemble level. We also describe an alternative replica solution that proves to
be equivalent to the cavity method. Both the cavity and the replica derivations
allow us to obtain the spectral density via the solution of an integral
equation for an auxiliary probability density function. We show that this
equation can be solved using a stochastic population dynamics algorithm, and we
provide its implementation. In this formalism, the spectral density is
naturally written in terms of a superposition of local contributions from nodes
of given degree, whose role is thoroughly elucidated. This paper does not
contain original material, but rather gives a pedagogical overview of the
topic. It is indeed addressed to students and researchers who consider entering
the field. Both the theoretical tools and the numerical algorithms are
discussed in detail, highlighting conceptual subtleties and practical aspects.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:57:18 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 14:38:35 GMT""},{""version"":""v3"",""created"":""Mon, 10 May 2021 08:26:01 GMT""},{""version"":""v4"",""created"":""Wed, 7 Jul 2021 08:03:50 GMT""}]","2021-08-11"
"2101.08030","Francesco Cartella","Francesco Cartella, Orlando Anunciacao, Yuki Funabiki, Daisuke
  Yamaguchi, Toru Akishita, Olivier Elshocht","Adversarial Attacks for Tabular Data: Application to Fraud Detection and
  Imbalanced Data","Will be published on Proceedings of the Workshop on Artificial
  Intelligence Safety (SafeAI 2021) co-located with 35th AAAI Conference on
  Artificial Intelligence (AAAI 2021)",,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Guaranteeing the security of transactional systems is a crucial priority of
all institutions that process transactions, in order to protect their
businesses against cyberattacks and fraudulent attempts. Adversarial attacks
are novel techniques that, other than being proven to be effective to fool
image classification models, can also be applied to tabular data. Adversarial
attacks aim at producing adversarial examples, in other words, slightly
modified inputs that induce the Artificial Intelligence (AI) system to return
incorrect outputs that are advantageous for the attacker. In this paper we
illustrate a novel approach to modify and adapt state-of-the-art algorithms to
imbalanced tabular data, in the context of fraud detection. Experimental
results show that the proposed modifications lead to a perfect attack success
rate, obtaining adversarial examples that are also less perceptible when
analyzed by humans. Moreover, when applied to a real-world production system,
the proposed techniques shows the possibility of posing a serious threat to the
robustness of advanced AI-based fraud detection procedures.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:58:29 GMT""}]","2021-01-21"
"2101.08031","Ming Gong","Qingling Zhu, Zheng-Hang Sun, Ming Gong, Fusheng Chen, Yu-Ran Zhang,
  Yulin Wu, Yangsen Ye, Chen Zha, Shaowei Li, Shaojun Guo, Haoran Qian,
  He-Liang Huang, Jiale Yu, Hui Deng, Hao Rong, Jin Lin, Yu Xu, Lihua Sun,
  Cheng Guo, Na Li, Futian Liang, Cheng-Zhi Peng, Heng Fan, Xiaobo Zhu, and
  Jian-Wei Pan","Observation of thermalization and information scrambling in a
  superconducting quantum processor","5 pages, 4 figures, and supplementary materials with 10 pages, 3
  tables and 14 figures","Phys. Rev. Lett. 128, 160502 (2022)","10.1103/PhysRevLett.128.160502",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding various phenomena in non-equilibrium dynamics of closed quantum
many-body systems, such as quantum thermalization, information scrambling, and
nonergodic dynamics, is a crucial for modern physics. Using a ladder-type
superconducting quantum processor, we perform analog quantum simulations of
both the $XX$ ladder and one-dimensional (1D) $XX$ model. By measuring the
dynamics of local observables, entanglement entropy and tripartite mutual
information, we signal quantum thermalization and information scrambling in the
$XX$ ladder. In contrast, we show that the $XX$ chain, as free fermions on a 1D
lattice, fails to thermalize, and local information does not scramble in the
integrable channel. Our experiments reveal ergodicity and scrambling in the
controllable qubit ladder, and opens the door to further investigations on the
thermodynamics and chaos in quantum many-body systems.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:00:09 GMT""}]","2022-04-22"
"2101.08032","Wanguang Yin","Wanguang Yin, Zhengming Ma, Quanying Liu","Riemannian Manifold Optimization for Discriminant Subspace Learning","13 pages, 4 figures, 6 tables",,,,"cs.LG eess.IV eess.SP","http://creativecommons.org/licenses/by-sa/4.0/","  Linear discriminant analysis (LDA) is a widely used algorithm in machine
learning to extract a low-dimensional representation of high-dimensional data,
it features to find the orthogonal discriminant projection subspace by using
the Fisher discriminant criterion. However, the traditional Euclidean-based
methods for solving LDA are easily convergent to spurious local minima and
hardly obtain an optimal solution. To address such a problem, in this paper, we
propose a novel algorithm namely Riemannian-based discriminant analysis (RDA)
for subspace learning. In order to obtain an explicit solution, we transform
the traditional Euclidean-based methods to the Riemannian manifold space and
use the trust-region method to learn the discriminant projection subspace. We
compare the proposed algorithm to existing variants of LDA, as well as the
unsupervised tensor decomposition methods on image classification tasks. The
numerical results suggest that RDA achieves state-of-the-art performance in
classification accuracy.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:13:34 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 07:17:29 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 02:37:14 GMT""}]","2021-07-21"
"2101.08033","Simon Portegies Zwart","Fedde Fagginger Auer (Leiden Observatory) and Simon Portegies Zwart
  (Leiden Observatory)","Lucky planets: how circum-binary planets survive the supernova in one of
  the inner-binary components","published in SciPost Astronomy, see
  https://scipost.org/SciPostAstro.2.1.002","SciPost Astro. 2, 002 (2022)","10.21468/SciPostAstro.2.1.002",,"astro-ph.EP astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  A planet hardly ever survives the supernova of the host star in a bound
orbit, because mass loss in the supernova and the natal kick imparted to the
newly formed compact object cause the planet to be ejected. A planet in orbit
around a binary has a considerably higher probability to survive the supernova
explosion of one of the inner binary stars. In those cases, the planet most
likely remains bound to the companion of the exploding star, whereas the
compact object is ejected. We estimate this to happen to $\sim 1/33$ the
circum-binary planetary systems. These planetary orbits tend to be highly
eccentric ($e \apgt 0.9$), and $\sim 20$\,\% of these planets have retrograde
orbits compared to their former binary. The probability that the planet as well
as the binary (now with a compact object) remains bound is about ten times
smaller ($\sim 3\cdot 10^{-3}$). We then expect the Milky way Galaxy to host
$\aplt 10$ x-ray binaries that are still orbited by a planet, and $\aplt 150$
planets that survived in orbit around the compact object's companion. These
numbers should be convolved with the fraction of massive binaries that is
orbited by a planet.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:15:30 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 07:37:44 GMT""},{""version"":""v3"",""created"":""Mon, 4 Apr 2022 08:21:16 GMT""}]","2022-04-05"
"2101.08034","Erkan Bostanci","Ozlem Dagli, Erkan Bostanci, O. Hakan Emmez, Fatih Ekinci and Emrah
  Celtikci","A Statistical Analysis of the Effect of Different Embolization Materials
  on Gamma Knife Arteriovenous Malformation Dose Distributions","We would like to withdraw our paper due to a disagreement between
  authors",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gamma Knife Radiosurgery (GKRS) is a treatment choice in newly diagnosed AVMs
and residual AVMs following endovascular interventions. Aim of this study is to
determine if commercially available liquid embolic agents reduce the radiation
dose to the target due to the attenuation of the 60Co beam. Doses accumulated
by three different embolization materials, namely: Onyx, cyanoacrylate and
polyvinyl alcohol (PVA) were analysed. A collimator helmet size of 8mm was
employed in a Monte-Carlo simulation implemented in Geant4 simulation toolkit.
Obtained dose accumulations were evaluated and results demonstrated
statistically significant differences in the dosimetries calculated.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:16:06 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 08:46:07 GMT""}]","2021-10-14"
"2101.08035","C. Maria Keet","C. Maria Keet","Bias in ontologies -- a preliminary assessment","10 pages, 4 figures, 2 tables, soon to be submitted to an
  international conference",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Logical theories in the form of ontologies and similar artefacts in computing
and IT are used for structuring, annotating, and querying data, among others,
and therewith influence data analytics regarding what is fed into the
algorithms. Algorithmic bias is a well-known notion, but what does bias mean in
the context of ontologies that provide a structuring mechanism for an
algorithm's input? What are the sources of bias there and how would they
manifest themselves in ontologies? We examine and enumerate types of bias
relevant for ontologies, and whether they are explicit or implicit. These eight
types are illustrated with examples from extant production-level ontologies and
samples from the literature. We then assessed three concurrently developed
COVID-19 ontologies on bias and detected different subsets of types of bias in
each one, to a greater or lesser extent. This first characterisation aims
contribute to a sensitisation of ethical aspects of ontologies primarily
regarding representation of information and knowledge.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:28:08 GMT""}]","2021-01-21"
"2101.08036","Alessandro Fazzari","Alessandro Fazzari","Weighted value distributions of the Riemann zeta function on the
  critical line","17 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a central limit theorem for $\log|\zeta(1/2+it)|$ with respect to
the measure $|\zeta^{(m)}(1/2+it)|^{2k}dt$ ($k,m\in\mathbb N$), assuming RH and
the asymptotic formula for twisted and shifted integral moments of zeta. Under
the same hypotheses, we also study a shifted case, looking at the measure
$|\zeta(1/2+it+i\alpha)|^{2k}dt$, with $\alpha\in(-1,1)$. Finally we prove
unconditionally the analogue result in the random matrix theory context.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:28:55 GMT""}]","2021-01-21"
"2101.08037","Shugo Yasuda","Shugo Yasuda","Effects of internal dynamics on chemotactic aggregation of bacteria",,,"10.1088/1478-3975/ac2048",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The effects of internal adaptation dynamics on the self-organized aggregation
of chemotactic bacteria are investigated by Monte Carlo (MC) simulations based
on a two-stream kinetic transport equation coupled with a reaction-diffusion
equation of the chemoattractant that bacteria produce. A remarkable finding is
a nonmonotonic behavior of the peak aggregation density with respect to the
adaptation time; more specifically, aggregation is the most enhanced when the
adaptation time is comparable to or moderately larger than the mean run time of
bacteria. Another curious observation is the formation of a trapezoidal
aggregation profile occurring at a very large adaptation time, where the biased
motion of individual cells is rather hindered at the plateau regimes due to the
boundedness of the tumbling frequency modulation. Asymptotic analysis of the
kinetic transport system is also carried out, and a novel asymptotic equation
is obtained at the large adaptation-time regime while the Keller-Segel type
equations are obtained when the adaptation time is moderate. Numerical
comparison of the asymptotic equations with MC results clarifies that
trapezoidal aggregation is well described by the novel asymptotic equation, and
the nonmonotonic behavior of the peak aggregation density is interpreted as the
transient of the asymptotic solutions between different adaptation time
regimes.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:32:59 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 02:57:23 GMT""},{""version"":""v3"",""created"":""Thu, 24 Jun 2021 10:57:08 GMT""}]","2021-10-07"
"2101.08038","Claire Burrin","Claire Burrin and Matthew Issac","Infinitely many twin prime polynomials of odd degree","To appear, American Mathematical Monthly",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the twin prime conjecture is still famously open, it holds true in the
setting of finite fields: There are infinitely many pairs of monic irreducible
polynomials over $\mathbb{F}_q$ that differ by a fixed constant, for each $q
\geq 3$. Elementary, constructive proofs were given for different cases by Hall
and Pollack. In the same spirit, we discuss the construction of a further
infinite family of twin prime tuples of odd degree, and its relations to the
existence of certain Wieferich primes and to arithmetic properties of the
combinatorial Bell numbers.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:34:37 GMT""}]","2021-01-21"
"2101.08039","Chang Liu","Zhuqing Jiang, Chang Liu, Ya'nan Wang, Kai Li, Aidong Men, Haiying
  Wang, Haiyong Luo","Bridge the Vision Gap from Field to Command: A Deep Learning Network
  Enhancing Illumination and Details",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the goal of tuning up the brightness, low-light image enhancement enjoys
numerous applications, such as surveillance, remote sensing and computational
photography. Images captured under low-light conditions often suffer from poor
visibility and blur. Solely brightening the dark regions will inevitably
amplify the blur, thus may lead to detail loss. In this paper, we propose a
simple yet effective two-stream framework named NEID to tune up the brightness
and enhance the details simultaneously without introducing many computational
costs. Precisely, the proposed method consists of three parts: Light
Enhancement (LE), Detail Refinement (DR) and Feature Fusing (FF) module, which
can aggregate composite features oriented to multiple tasks based on channel
attention mechanism. Extensive experiments conducted on several benchmark
datasets demonstrate the efficacy of our method and its superiority over
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:39:57 GMT""}]","2021-01-21"
"2101.08040","Jiasheng Tang","Fei Du, Bo Xu, Jiasheng Tang, Yuqi Zhang, Fan Wang, and Hao Li","1st Place Solution to ECCV-TAO-2020: Detect and Represent Any Object for
  Tracking",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the classical tracking-by-detection paradigm to this
tracking-any-object task. Solid detection results are first extracted from TAO
dataset. Some state-of-the-art techniques like \textbf{BA}lanced-\textbf{G}roup
\textbf{S}oftmax (\textbf{BAGS}\cite{li2020overcoming}) and
DetectoRS\cite{qiao2020detectors} are integrated during detection. Then we
learned appearance features to represent any object by training feature
learning networks. We ensemble several models for improving detection and
feature representation. Simple linking strategies with most similar appearance
features and tracklet-level post association module are finally applied to
generate final tracking results. Our method is submitted as \textbf{AOA} on the
challenge website. Code is available at
https://github.com/feiaxyt/Winner_ECCV20_TAO.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:42:32 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 08:38:31 GMT""}]","2021-02-02"
"2101.08041","David J. Pr\""omel","Rafa{\l} M. {\L}ochowski, Nicolas Perkowski, David J. Pr\""omel","One-dimensional game-theoretic differential equations",,"Int. J. Approx. Reason.: Probability and Statistics: Foundations
  and History. In honor of Glenn Shafer, vol. 141, p. 11--27, 2022",,,"math.PR q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a very brief introduction to typical paths and the corresponding
It\^o type integration. Relying on this robust It\^o integration, we prove an
existence and uniqueness result for one-dimensional differential equations
driven by typical paths with non-Lipschitz continuous coefficients in the
spirit of Yamada--Watanabe as well as an approximation result in the spirit of
Doss--Sussmann.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:45:06 GMT""}]","2022-01-19"
"2101.08042","Sandi Klav\v{z}ar","Paul Manuel and Bo\v{s}tjan Bre\v{s}ar and Sandi Klav\v{z}ar","The geodesic-transversal problem",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A maximal geodesic in a graph is a geodesic (alias shortest path) which is
not a subpath of a longer geodesic. The geodesic-transversal problem in a graph
$G$ is introduced as the task to find a smallest set $S$ of vertices of $G$
such that each maximal geodesic has at least one vertex in $S$. The minimum
cardinality of such a set is the geodesic-transversal number ${\rm gt}(G)$ of
$G$. It is proved that ${\rm gt}(G) = 1$ if and only if $G$ is a subdivided
star and that the geodesic-transversal problem is NP-complete. Fast algorithms
to determine the geodesic-transversal number of trees and of spread cactus
graphs are designed, respectively.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:45:16 GMT""}]","2021-01-21"
"2101.08043","Arka Chatterjee","Prantik Nandi, Arka Chatterjee, Sandip K. Chakrabarti and Broja G.
  Dutta","Long term X-Ray Observations of Seyfert 1 Galaxy Ark 120: On the origin
  of soft-excess","Communicated with MNRAS. The revised version will be updated soon.
  Comments are welcome",,"10.1093/mnras/stab1699",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the long-term X-ray spectral and temporal analysis of a 'bare-type
AGN' Ark 120. We consider the observations from XMM-Newton, Suzaku, Swift, and
NuSTAR from 2003 to 2018. The spectral properties of this source are studied
using various phenomenological and physical models present in the literature.
We report (a) the variations of several physical parameters, such as the
temperature and optical depth of the electron cloud, the size of the Compton
cloud, and accretion rate for the last fifteen years. The spectral variations
are explained from the change in the accretion dynamics; (b) the X-ray time
delay between 0.2-2 keV and 3-10 keV light-curves exhibited zero-delay in 2003,
positive delay of 4.71 \pm 2.1 ks in 2013, and negative delay of 4.15 \pm 1.5
ks in 2014. The delays are explained considering Comptonization, reflection,
and light-crossing time; (c) the long term intrinsic luminosities obtained
using nthcomp, of the soft-excess and the primary continuum show a correlation
with a Pearson Correlation Coefficient of 0.922. This indicates that the
soft-excess and the primary continuum are originated from the same physical
process. From a physical model fitting, we infer that the soft excess for Ark
120 could be due to a small number of scatterings in the Compton cloud. Using
Monte-Carlo simulations, we show that indeed the spectra corresponding to fewer
scatterings could provide a steeper soft-excess power-law in the 0.2-3 keV
range. Simulated luminosities are found to be in agreement with the observed
values.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:49:36 GMT""}]","2021-07-14"
"2101.08044","Deheng Cai","Deheng Cai, Wei Liu, Linong Ji, Dawei Shi","Bayesian Optimization Assisted Meal Bolus Decision Based on Gaussian
  Processes Learning and Risk-Sensitive Control",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Effective postprandial glucose control is important to glucose management for
subjects with diabetes mellitus. In this work, a data-driven meal bolus
decision method is proposed without the need of subject-specific glucose
management parameters. The postprandial glucose dynamics is learnt using
Gaussian process regression. Considering the asymmetric risks of hyper- and
hypoglycemia and the uncertainties in the predicted glucose trajectories, an
asymmetric risk-sensitive cost function is designed. Bayesian optimization is
utilized to solve the optimization problem, since the gradient of the cost
function is unavailable. The proposed approach is evaluated using the 10-adult
cohort of the FDA-accepted UVA/Padova T1DM simulator and compared with the
standard insulin bolus calculator. For the case of announced meals, the
proposed method achieves satisfactory and similar performance in terms of mean
glucose and percentage time in [70, 180] mg/dL without increasing the risk of
hypoglycemia. Similar results are observed for the case without the meal
information (assuming that the patient follows a consistent diet) and the case
of basal rate mismatches. In addition, advisory-mode analysis is performed
based on clinical data, which indicates that the method can determine safe and
reasonable meal boluses in real clinical settings. The results verify the
effectiveness and robustness of the proposed method and indicate the
feasibility of achieving improved postprandial glucose regulation through a
data-driven optimal control method.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:52:59 GMT""}]","2021-01-21"
"2101.08045","Mareike Wolff","Mareike Wolff","A class of Newton maps with Julia sets of Lebesgue measure zero","44 pages, 5 figures",,,,"math.DS math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $g(z)=\int_0^zp(t)\exp(q(t))\,dt+c$ where $p,q$ are polynomials and
$c\in\mathbb{C}$, and let $f$ be the function from Newton's method for $g$. We
show that under suitable assumptions the Julia set of $f$ has Lebesgue measure
zero. Together with a theorem by Bergweiler, our result implies that $f^n(z)$
converges to zeros of $g$ almost everywhere in $\mathbb{C}$ if this is the case
for each zero of $g''$. In order to prove our result, we establish general
conditions ensuring that Julia sets have Lebesgue measure zero.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:59:37 GMT""}]","2021-01-21"
"2101.08046","Jack Ratcliffe","Jack Ratcliffe, Francesco Soave, Nick Bryan-Kinns, Laurissa Tokarchuk,
  Ildar Farkhatdinov","Extended Reality (XR) Remote Research: a Survey of Drawbacks and
  Opportunities",,,"10.1145/3411764.3445170",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Extended Reality (XR) technology - such as virtual and augmented reality - is
now widely used in Human Computer Interaction (HCI), social science and
psychology experimentation. However, these experiments are predominantly
deployed in-lab with a co-present researcher. Remote experiments, without
co-present researchers, have not flourished, despite the success of remote
approaches for non-XR investigations. This paper summarises findings from a
30-item survey of 46 XR researchers to understand perceived limitations and
benefits of remote XR experimentation. Our thematic analysis identifies
concerns common with non-XR remote research, such as participant recruitment,
as well as XR-specific issues, including safety and hardware variability. We
identify potential positive affordances of XR technology, including leveraging
data collection functionalities builtin to HMDs (e.g. hand, gaze tracking) and
the portability and reproducibility of an experimental setting. We suggest that
XR technology could be conceptualised as an interactive technology and a
capable data-collection device suited for remote experimentation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:02:29 GMT""}]","2021-01-21"
"2101.08047","Ebrahim Soori","M. Ghadampour, E. Soori","Two generalized strong convergence algorithms for the variational
  inequality problems in Banach spaces","20",,,,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, two generalized algorithms for solving the variational
inequality problem in Banach spaces are proposed. Then the strong convergence
of the sequences generated by these algorithms will be proved under the
suitable conditions. Finally, using MATLAB software, we provide some numerical
examples to illustrate our results.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:06:37 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 17:52:53 GMT""},{""version"":""v3"",""created"":""Sun, 23 May 2021 12:13:11 GMT""}]","2021-05-25"
"2101.08048","Reuben Binns Dr","Nitin Agrawal, Reuben Binns, Max Van Kleek, Kim Laine, Nigel Shadbolt","Exploring Design and Governance Challenges in the Development of
  Privacy-Preserving Computation",,,"10.1145/3411764.3445677",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Homomorphic encryption, secure multi-party computation, and differential
privacy are part of an emerging class of Privacy Enhancing Technologies which
share a common promise: to preserve privacy whilst also obtaining the benefits
of computational analysis. Due to their relative novelty, complexity, and
opacity, these technologies provoke a variety of novel questions for design and
governance. We interviewed researchers, developers, industry leaders,
policymakers, and designers involved in their deployment to explore
motivations, expectations, perceived opportunities and barriers to adoption.
This provided insight into several pertinent challenges facing the adoption of
these technologies, including: how they might make a nebulous concept like
privacy computationally tractable; how to make them more usable by developers;
and how they could be explained and made accountable to stakeholders and wider
society. We conclude with implications for the development, deployment, and
responsible governance of these privacy-preserving computation techniques.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:07:17 GMT""}]","2021-01-21"
"2101.08049","Luka \v{Z}nidari\v{c}","Luka \v{Z}nidari\v{c}, Gjorgji Nusev, Bertrand Morel, Julie Mougin,
  {\DJ}ani Juri\v{c}i\'c and Pavle Bo\v{s}koski","Evaluating uncertainties in electrochemical impedance spectra of solid
  oxide fuel cells","28 pages, 18 figures. Submitted to: Applied Energy",,"10.1016/j.apenergy.2021.117101",,"stat.CO cs.LG stat.AP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Electrochemical impedance spectroscopy (EIS) is a widely used tool for
characterization of fuel cells and other electrochemical conversion systems.
When applied to the on-line monitoring in the context of in-field applications,
the disturbances, drifts and sensor noise may cause severe distortions in the
evaluated spectra, especially in the low-frequency part. Failure to ignore the
random effects can result in misinterpreted spectra and, consequently, in
misleading diagnostic reasoning. This fact has not been often addressed in the
research so far. In this paper, we propose an approach to the quantification of
the spectral uncertainty, which relies on evaluating the uncertainty of the
equivalent circuit model (ECM). We apply the computationally efficient
variational Bayes (VB) method and compare the quality of the results with those
obtained with the Markov chain Monte Carlo (MCMC) algorithm. Namely, MCMC
algorithm returns accurate distributions of the estimated model parameters,
while VB approach provides the approximate distributions. By using simulated
and real data we show that approximate results provided by VB approach,
although slightly over-optimistic, are still close to the more realistic MCMC
estimates. A great advantage of the VB method for online monitoring is low
computational load, which is several orders of magnitude lower compared to
MCMC. The performance of VB algorithm is demonstrated on a case of ECM
parameters estimation in a 6 cell solid oxide fuel cell (SOFC) stack. The
complete numerical implementation for recreating the results can be found at
https://repo.ijs.si/lznidaric/variational-bayes-supplementary-material.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:07:32 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 12:22:32 GMT""},{""version"":""v3"",""created"":""Wed, 5 May 2021 11:35:23 GMT""}]","2021-07-21"
"2101.08050","Anna S. Von Der Heydt","Anna S. von der Heydt, Peter Ashwin, Charles D.Camp, Michel Crucifix,
  Henk A. Dijkstra, Peter Ditlevsen, Timothy M. Lenton","Quantification and interpretation of the climate variability record",,"Global and Planetary Change (2021), Vol. 197, article number
  103399","10.1016/j.gloplacha.2020.103399",,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  The spectral view of variability is a compelling and adaptable tool for
understanding variability of the climate. In Mitchell (1976) seminal paper, it
was used to express, on one graph with log scales, a very wide range of climate
variations from millions of years to days. The spectral approach is
particularly useful for suggesting causal links between forcing variability and
climate response variability. However, a substantial degree of variability is
intrinsic and the Earth system may respond to external forcing in a complex
manner. There has been an enormous amount of work on understanding climate
variability over the last decades. Hence in this paper, we address the
question: Can we (after 40 years) update the Mitchell (1976) diagram and
provide it with a better interpretation? By reviewing both the extended
observations available for such a diagram and new methodological developments
in the study of the interaction between internal and forced variability over a
wide range of timescales, we give a positive answer to this question. In
addition, we review alternative approaches to the spectral decomposition and
pose some challenges for a more detailed quantification of climate variability.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:10:38 GMT""}]","2021-01-21"
"2101.08051","Hayder Al-Hraishawi","Hayder Al-Hraishawi and Symeon Chatzinotas and Bj\""orn Ottersten","Broadband Non-Geostationary Satellite Communication Systems: Research
  Challenges and Key Opportunities",,,"10.1109/ICCWorkshops50388.2021.9473786",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Besides conventional geostationary (GSO) satellite broadband communication
services, non-geostationary (NGSO) satellites are envisioned to support various
new communication use cases from countless industries. These new scenarios
bring many unprecedented challenges that will be discussed in this paper
alongside with several potential future research opportunities. NGSO systems
are known for various advantages, including their important features of low
cost, lower propagation delay, smaller size, and lower losses in comparison to
GSO satellites. However, there are still many deployment challenges to be
tackled to ensure seamless integration not only with GSO systems but also with
terrestrial networks. In this paper, we discuss several key challenges
including satellite constellation and architecture designs, coexistence with
GSO systems in terms of spectrum access and regulatory issues, resource
management algorithms, and NGSO networking requirements. Additionally, the
latest progress in provisioning secure communication via NGSO systems is
discussed. Finally, this paper identifies multiple important open issues and
research directions to inspire further studies towards the next generation of
satellite networks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:11:31 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 11:06:25 GMT""}]","2023-05-30"
"2101.08052","Kimberley Timmins","Kimberley M. Timmins, Irene C. van der Schaaf, Ynte M. Ruigrok,
  Birgitta K. Velthuis, Hugo J. Kuijf","Variational Autoencoders with a Structural Similarity Loss in Time of
  Flight MRAs","SPIE Medical Imaging 2021",,"10.1117/12.2580705",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Time-of-Flight Magnetic Resonance Angiographs (TOF-MRAs) enable visualization
and analysis of cerebral arteries. This analysis may indicate normal variation
of the configuration of the cerebrovascular system or vessel abnormalities,
such as aneurysms. A model would be useful to represent normal cerebrovascular
structure and variabilities in a healthy population and to differentiate from
abnormalities. Current anomaly detection using autoencoding convolutional
neural networks usually use a voxelwise mean-error for optimization. We propose
optimizing a variational-autoencoder (VAE) with structural similarity loss
(SSIM) for TOF-MRA reconstruction. A patch-trained 2D fully-convolutional VAE
was optimized for TOF-MRA reconstruction by comparing vessel segmentations of
original and reconstructed MRAs. The method was trained and tested on two
datasets: the IXI dataset, and a subset from the ADAM challenge. Both trained
networks were tested on a dataset including subjects with aneurysms. We
compared VAE optimization with L2-loss and SSIM-loss. Performance was evaluated
between original and reconstructed MRAs using mean square error, mean-SSIM,
peak-signal-to-noise-ratio and dice similarity index (DSI) of segmented
vessels. The L2-optimized VAE outperforms SSIM, with improved reconstruction
metrics and DSIs for both datasets. Optimization using SSIM performed best for
visual image quality, but with discrepancy in quantitative reconstruction and
vascular segmentation. The larger, more diverse IXI dataset had overall better
performance. Reconstruction metrics, including SSIM, were lower for MRAs
including aneurysms. A SSIM-optimized VAE improved the visual perceptive image
quality of TOF-MRA reconstructions. A L2-optimized VAE performed best for
TOF-MRA reconstruction, where the vascular segmentation is important. SSIM is a
potential metric for anomaly detection of MRAs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:13:57 GMT""}]","2021-02-24"
"2101.08053","Benjamin Marussig","Benjamin Marussig","Fast formation and assembly of isogeometric Galerkin matrices for
  trimmed patches",,,,,"cs.CE cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work explores the application of the fast assembly and formation
strategy from [8, 17] to trimmed bi-variate parameter spaces. Two concepts for
the treatment of basis functions cut by the trimming curve are investigated:
one employs a hybrid Gauss-point-based approach, and the other computes
discontinuous weighted quadrature rules. The concepts' accuracy and efficiency
are examined for the formation of mass matrices and their application to
L2-projection. Significant speed-ups compared to standard element by element
finite element formation are observed. There is no clear preference between the
concepts proposed. While the discontinuous weighted scheme scales favorably
with the degree of the basis, it also requires additional effort for computing
the quadrature weights. The hybrid Gauss approach does not have this overhead,
which is determined by the complexity of the trimming curve. Hence, it is
well-suited for moderate degrees, whereas discontinuous-weightedquadrature has
potential for high degrees, in particular, if the related weights are computed
in parallel.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:14:41 GMT""}]","2021-01-21"
"2101.08054","Ying Xu Dr.","Ying Xu and Zhihua Qu","Voltage Inference for and Coordination of Distributed Voltage Controls
  in Extremely-High DER-Penetration Distribution Networks",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unique problems and phenomena in the distributed voltage control of
large-scale power distribution systems with extremely-high DER-penetration are
targeted in this paper. First, a DER-explicit distribution network model and
voltage sensitivity are derived. Based on that, a voltage inference method is
implemented to fill the gap of measurement insufficiency in the grid-edge
areas. Then, autonomous Q control being implemented in each local area, a
$\overline{Q}$-coordinated P control is designed to coordinate the reactive and
real power controls. All the algorithms have been tested in standard and
synthetic systems, and have expected results. Moreover, an open-source software
platform, which integrates the modeling of communication networks, DER
controls, and power networks, is developed to enable the distributed control
and optimization algorithms in the grid simulation of the large-scale
distribution systems.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:20:39 GMT""}]","2021-01-21"
"2101.08055","Fredrik Nilsson","Fredrik Nilsson and Ferdi Aryasetiawan","Effects of dynamical screening on the BCS-BEC crossover in double
  bilayer graphene: Density functional theory for exciton bilayers","6 pages and 3 figures (main article), 16 pages and 2 figures
  (Supplemental)","Phys. Rev. Materials 5, 050801 (2021)","10.1103/PhysRevMaterials.5.L050801",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a gap equation for bilayer excitonic systems based on density
functional theory and benchmark our results against quantum Monte-Carlo
simulations and recent experiments on double bilayer graphene. The gap equation
has a mean-field form but includes a consistent treatment of dynamical
screening. We show that the gap survives at much higher densities than
previously thought from mean-field estimates which gives strong indications
that the double-bilayer graphene systems at zero magnetic field can be used as
model systems to investigate the BCS-BEC crossover. Furthermore, we show that
Josephson-like transfer of pairs can be substantial for small band gaps and
densities.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:35:59 GMT""}]","2021-05-19"
"2101.08056","Thomas Blazek Dr. techn.","Richard Pr\""uller, Thomas Blazek, Stefan Pratschner, Markus Rupp","On the Parametrization and Statistics of Propagation Graphs","5 pages, 3 figures, accepted for publication at EuCAP 2021",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Propagation graphs (PGs) serve as a frequency-selective, spatially consistent
channel model suitable for fast channel simulations in a scattering
environment. So far, however, the parametrization of the model, and its
consequences, have received little attention. In this contribution, we propose
a new parametrization for PGs that adheres to the doubly exponentially decaying
cluster structure of the Saleh-Valenzuela (SV) model. We show how to compute
the newly proposed internal model parameters based on an approximation of the
$K$-factor and the two decay rates from the SV model. Furthermore, via the
singular values of multiple-input multiple-output (MIMO) channels, we compare
the degrees of freedom (DoF) between our new and another frequently used
parametrization. Specifically, we compare the DoF loss when the distance
between antennas within the transmitter and receiver arrays or the average
distance between scatterers decreases. Based on this comparison, it is shown
that, in contrast to the typical parametrization, our newly proposed
parametrization loses DoF in both scenarios, as one would expect from a
spatially consistent channel model.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:40:02 GMT""}]","2021-01-21"
"2101.08057","Yekini Shehu","Yekini Shehu and Olaniyi. S. Iyiola","Weak Convergence for Variational Inequalities with Inertial-Type Method","22 pages, 19 figures",,"10.1080/00036811.2020.1736287",,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Weak convergence of inertial iterative method for solving variational
inequalities is the focus of this paper. The cost function is assumed to be
non-Lipschitz and monotone. We propose a projection-type method with inertial
terms and give weak convergence analysis under appropriate conditions. Some
test results are performed and compared with relevant methods in the literature
to show the efficiency and advantages given by our proposed methods.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:43:13 GMT""}]","2021-01-21"
"2101.08058","Bryce Kerr","Bryce Kerr","On the cubic Weyl sum",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain an estimate for the cubic Weyl sum which improves the bound
obtained from Weyl differencing for short ranges of summation. In particular,
we show that for any $\varepsilon>0$ there exists some $\delta>0$ such that for
any coprime integers $a,q$ and real number $\gamma$ we have \begin{align*}
\sum_{1\le n \le N}e\left(\frac{an^3}{q}+\gamma n\right)\ll (qN)^{1/4}
q^{-\delta}, \end{align*} provided $q^{1/3+\varepsilon}\le N \le
q^{1/2-\varepsilon}$. Our argument builds on some ideas of Enflo.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:44:39 GMT""}]","2021-01-21"
"2101.08059","Panagiotis Tolias","P. Tolias and F. Lucco Castello","Description of longitudinal modes in moderately coupled Yukawa systems
  with the static local field correction","6 pages, 3 figures","Phys. Plasmas 28, 034502 (2021)","10.1063/5.0044871",,"cond-mat.soft physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In moderately coupled Yukawa fluids, longitudinal mode dispersion is
determined by the competition between kinetic and potential effects. In a
recent paper [Khrapak and Cou\""edel, Phys. Rev. E 102, 033207 (2020)], a
semi-phenomenological dispersion relation was constructed by the ad-hoc
addition of the Bohm-Gross kinetic term to the generalized instantaneous excess
bulk modulus, which showed very good agreement with simulations. In this paper,
a nearly identical dispersion relation is derived in a rigorous manner based on
a dielectric formulation with static local field corrections. At moderate
coupling, this formalism is revealed to be more accurate than other successful
theoretical approaches.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:47:17 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2021 12:00:18 GMT""},{""version"":""v3"",""created"":""Tue, 16 Feb 2021 18:27:55 GMT""}]","2021-03-10"
"2101.08060","Franz Wegner","Franz Wegner","The Collatz Problem generalized to 3x+k","Main paper 13 pages; Supplement (278 pages) contains a list of limit
  cycles up to k=9997",,,,"math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Collatz problem with $3x+k$ is revisited. Positive and negative limit
cycles are given up to k=9997 starting with $x_0=-2\cdot10^7...+2\cdot10^7$. A
simple relation between the probability distribution for the Syracuse iterates
for various k (not divisible by 2 and 3) is obtained. From this it follows that
the oscillation considered by Tao 2019 ( arXiv:1909.03562v2 ) does not depend
on k. Thus this piece of the proof of his theorem 1.3 ""Almost all Collatz
orbits attain almost bounded values"" holds for all k not divisible by 2 and 3.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:51:28 GMT""}]","2021-01-21"
"2101.08061","Eduardo C\'esar Garrido-Merch\'an","Lucia Asencio-Mart\'in, Eduardo C. Garrido-Merch\'an","A Similarity Measure of Gaussian Process Predictive Distributions",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some scenarios require the computation of a predictive distribution of a new
value evaluated on an objective function conditioned on previous observations.
We are interested on using a model that makes valid assumptions on the
objective function whose values we are trying to predict. Some of these
assumptions may be smoothness or stationarity. Gaussian process (GPs) are
probabilistic models that can be interpreted as flexible distributions over
functions. They encode the assumptions through covariance functions, making
hypotheses about new data through a predictive distribution by being fitted to
old observations. We can face the case where several GPs are used to model
different objective functions. GPs are non-parametric models whose complexity
is cubic on the number of observations. A measure that represents how similar
is one GP predictive distribution with respect to another would be useful to
stop using one GP when they are modelling functions of the same input space. We
are really inferring that two objective functions are correlated, so one GP is
enough to model both of them by performing a transformation of the prediction
of the other function in case of inverse correlation. We show empirical
evidence in a set of synthetic and benchmark experiments that GPs predictive
distributions can be compared and that one of them is enough to predict two
correlated functions in the same input space. This similarity metric could be
extremely useful used to discard objectives in Bayesian many-objective
optimization.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:52:48 GMT""}]","2021-01-21"
"2101.08062","Geunsik Lim","Geunsik Lim, Donghyun Kang, and Young Ik Eom","Thread Evolution Kit for Optimizing Thread Operations on CE/IoT Devices",,,"10.1109/TCE.2020.3033328",,"cs.OS cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most modern operating systems have adopted the one-to-one thread model to
support fast execution of threads in both multi-core and single-core systems.
This thread model, which maps the kernel-space and user-space threads in a
one-to-one manner, supports quick thread creation and termination in
high-performance server environments. However, the performance of time-critical
threads is degraded when multiple threads are being run in low-end CE devices
with limited system resources. When a CE device runs many threads to support
diverse application functionalities, low-level hardware specifications often
lead to significant resource contention among the threads trying to obtain
system resources. As a result, the operating system encounters challenges, such
as excessive thread context switching overhead, execution delay of
time-critical threads, and a lack of virtual memory for thread stacks. This
paper proposes a state-of-the-art Thread Evolution Kit (TEK) that consists of
three primary components: a CPU Mediator, Stack Tuner, and Enhanced Thread
Identifier. From the experiment, we can see that the proposed scheme
significantly improves user responsiveness (7x faster) under high CPU
contention compared to the traditional thread model. Also, TEK solves the
segmentation fault problem that frequently occurs when a CE application
increases the number of threads during its execution.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:54:59 GMT""}]","2021-01-21"
"2101.08063","Benjamin Perret","Benjamin Perret (LIGM), Jean Cousty (LIGM)","Component Tree Loss Function: Definition and Optimization",,,,,"cs.LG cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we propose a method to design loss functions based on
component trees which can be optimized by gradient descent algorithms and which
are therefore usable in conjunction with recent machine learning approaches
such as neural networks. We show how the altitudes associated to the nodes of
such hierarchical image representations can be differentiated with respect to
the image pixel values. This feature is used to design a generic loss function
that can select or discard image maxima based on various attributes such as
extinction values. The possibilities of the proposed method are demonstrated on
simulated and real image filtering.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:55:37 GMT""}]","2021-01-21"
"2101.08064","Joaquim Ortega-Cerd\`a","Jorge Antezana, Jordi Marzo and Joaquim Ortega-Cerd\`a","Interpolation by multivariate polynomials in convex domains","17 pages","Comput. Methods Funct. Theory 21 (2021), no. 4, 831-849","10.1007/s40315-021-00410-8",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Omega$ be a convex open set in $\mathbb R^n$ and let $\Lambda_k$ be a
finite subset of $\Omega$. We find necessary geometric conditions for
$\Lambda_k$ to be interpolating for the space of multivariate polynomials of
degree at most $k$. Our results are asymptotic in $k$. The density conditions
obtained match precisely the necessary geometric conditions that sampling sets
are known to satisfy, and they are expressed in terms of the equilibrium
potential of the convex set. Moreover, we prove that in the particular case of
the unit ball, for $k$ large enough, there is no family of orthogonal
reproducing kernels in the space of polynomials of degree at most $k$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:58:42 GMT""}]","2022-10-04"
"2101.08065","Matthieu Fradelizi","Matthieu Fradelizi, Elie Nakhle (UPEC UP12)","The functional form of Mahler conjecture for even log-concave functions
  in dimension $2$",,,,,"math.FA math.MG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $\Phi$ : R n $\rightarrow$ R $\cup$ {+$\infty$} be an even convex
function and L$\Phi$ be its Legendre transform. We prove the functional form of
Mahler conjecture concerning the functional volume product P ($\Phi$) = e
--$\Phi$ e --L$\Phi$ in dimension 2: we give the sharp lower bound of this
quantity and characterize the equality case. The proof uses the computation of
the derivative in t of P (t$\Phi$) and ideas due to Meyer [M] for unconditional
convex bodies, adapted to the functional case by Fradelizi-Meyer [FM2] and
extended for symmetric convex bodies in dimension 3 by Iriyeh-Shibata [IS] (see
also [FHMRZ]).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:02:40 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 15:15:35 GMT""}]","2023-04-12"
"2101.08066","Hatice Zeybek","Hatice Zeybek, Yasar Sozen","A note on Reidemeister Torsion of G-Anosov Representations","14 pages , 2 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article considers $G$-Anosov representations of a fixed closed oriented
Riemann surface $\Sigma$ of genus at least $2$. Here, $G$ is the Lie group
$\text{PSp}(2n,\mathbb{R}$), $\text{PSO}(n,n)$ or $\text{PSO}(n,n+1)$. It
proves that Reidemeister torsion (R-torsion) associated to $\Sigma$ with
coefficients in the adjoint bundle representations of such representations is
well-defined. Moreover, by using symplectic chain complex method, it
establishes a novel formula for R-torsion of such representations in terms of
the Atiyah-Bott-Goldman symplectic form corresponding to the Lie group $G$.
Furtermore, it applies the results to Hitchin components, in particular,
Teichm\""{u}ller space.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:02:44 GMT""}]","2021-01-21"
"2101.08067","Valentin Petit","Valentin Petit (LMB)","Non-divisible point on a two-parameter family of elliptic curves",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let n be a positive integer and t a non-zero integer. We consider the
elliptic curve over Q given by E : y 2 = x 3 + tx 2 -- n 2 (t + 3n 2)x + n 6.
It is a special case of an elliptic surface studied recently by Bettin, David
and Delaunay [2] and it generalizes Washington's family. The point (0, n 3)
belongs to E(Q) and we obtain some results about its nondivisibility in E(Q).
Our work extends to this two-parameter family of elliptic curves a previous
study of Duquesne (mainly stated for n = 1 and t > 0).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:04:42 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 07:36:47 GMT""}]","2021-08-23"
"2101.08068","Maximilien Germain","Maximilien Germain, Huy\^en Pham, Xavier Warin","Neural networks-based algorithms for stochastic control and PDEs in
  finance","arXiv admin note: substantial text overlap with arXiv:2006.01496",,,,"math.OC q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents machine learning techniques and deep reinforcement
learningbased algorithms for the efficient resolution of nonlinear partial
differential equations and dynamic optimization problems arising in investment
decisions and derivative pricing in financial engineering. We survey recent
results in the literature, present new developments, notably in the fully
nonlinear case, and compare the different schemes illustrated by numerical
tests on various financial applications. We conclude by highlighting some
future research directions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:06:23 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 08:03:23 GMT""}]","2021-04-19"
"2101.08069","Beno\^it Epinat","Valentina Abril-Melgarejo, Beno\^it Epinat, Wilfried Mercier, Thierry
  Contini, Leindert A. Boogaard, Jarle Brinchmann, Hayley Finley, L\'eo
  Michel-Dansac, Emmy Ventou, Philipe Amram, Davor Krajnovi\'c, Guillaume
  Mahler, Juan C. B. Pineda, Johan Richard","The Tully-Fisher relation in dense groups at $z \sim 0.7$ in the MAGIC
  survey","Accepted for publication in Astronomy & Astrophysics","A&A 647, A152 (2021)","10.1051/0004-6361/202038818",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galaxies in dense environments are subject to interactions and mechanisms
which directly affect their evolution by lowering their gas fractions and
reducing their star-forming capacity earlier than their isolated counterparts.
The aim of our project is to get new insights about the role of environment on
the stellar and baryonic content of galaxies using a kinematic approach,
through the study of the Tully-Fisher relation (TFR). We study a sample of
galaxies in 8 groups spanning a redshift range of $0.5<z<0.8$ and located in 10
pointings of the MAGIC MUSE Guaranteed Time Observations program. We perform a
morpho-kinematics analysis of this sample and set up a selection based on
galaxy size, [OII] emission line doublet signal-to-noise ratio, bulge-to-disk
ratio and nuclear activity to construct a robust kinematic sample of 67
star-forming galaxies. This selection considerably reduces the number of
outliers in the TFR, which are predominantly dispersion-dominated galaxies. Our
results suggest a significant offset of the TFR zero-point between galaxies in
low- and high-density environments, whatever kinematics estimator is used. This
can be interpreted as a decrease of either stellar mass by $\sim 0.05 - 0.3$
dex or an increase of rotation velocity by $\sim 0.02 - 0.06$ dex for galaxies
in groups, depending on the samples used for comparison. We also studied the
stellar and baryon mass fractions within stellar disks and found they both
increase with stellar mass, the trend being more pronounced for the stellar
component alone. These fractions do not exceed 50%. We show that this evolution
of the TFR is consistent either with a decrease of star formation or with a
contraction of the mass distribution due to the environment. These two effects
probably act together with their relative contribution depending on the mass
regime.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:08:04 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 15:29:36 GMT""},{""version"":""v3"",""created"":""Mon, 15 May 2023 19:19:03 GMT""}]","2023-05-17"
"2101.08070","Yulia Goldenberg","Yulia Goldenberg and Noam Tractinsky","Towards the Right Direction in BiDirectional User Interfaces","Accepted to CHI 2021",,"10.1145/3411764.3445461",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hundreds of millions of speakers of bidirectional (BiDi) languages rely on
writing systems that mix the native right-to-left script with left-to-right
strings. The global reach of interactive digital technologies requires special
attention to these people, whose perception of interfaces is affected by this
script mixture. However, empirical research on this topic is scarce. Although
leading software vendors provide guidelines for BiDi design, bidirectional
interfaces demonstrate inconsistent and incorrect directionality of UI
elements, which may cause user confusion and errors. Through a websites'
review, we identified problematic UI items and considered reasons for their
existence. In an online survey with 234 BiDi speakers, we observed that in many
cases, users' direction preferences were inconsistent with the guidelines. The
findings provide potential insights for design rules and empirical evidence for
the problem's complexity, suggesting the need for further empirical research
and greater attention by the HCI community to the BiDi design problem.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:10:35 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 22:13:08 GMT""}]","2021-01-27"
"2101.08071","Werner Bernreuther","Werner Bernreuther, Long Chen, Otto Nachtmann","The electric dipole moment of the tau lepton revisited","Two tables, one figure, and references added. Version to be published
  in Phys. Rev. D","Phys. Rev. D 103, 096011 (2021)","10.1103/PhysRevD.103.096011","TTK-21-3","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We reconsider the issue of the search for a nonzero electric dipole form
factor (EDM) $d_\tau(s)$ using optimal observables in $\tau^+\tau^-$ production
by $e^+ e^-$ collisions in the center-of-mass energy range from the $\tau$-pair
threshold to about $\sqrt{s} \sim 15$ GeV. We discuss the general formalism of
optimal observables and apply it to two $CP$-odd observables that are sensitive
to the real and imaginary part of $d_\tau(s)$, respectively. We compute the
expectation values and covariances of these optimal $CP$ observables for
  $\tau$-pair production at $\sqrt{s}=10.58$ GeV with subsequent decays of
$\tau^\pm$ into major leptonic or semihadronic modes. For the $\tau$ decays to
two pions and three charged pions we take the full kinematic information of the
hadronic system into account. Assuming that the Belle II experiment at the KEKB
accelerator will eventually
  analyze data corresponding to an integrated luminosity of 50 ab$^{-1}$ and
applying acceptance cuts on the final-state pions we find that 1~s.d.
sensitivities $\delta {\rm Re} d_\tau = 6.8 \times 10^{-20}$ e cm and $\delta
{\rm} Im d_\tau = 4.0 \times 10^{-20}$ e cm can be obtained with events where
both $\tau$'s decay semihadronically.
  In the ideal case where no cuts on the final-state particles are applied we
find with 50 ab$^{-1}$ at $\sqrt{s}=10.58$ GeV corresponding to $4.5 \times
10^{10}$ $\tau^+ \tau^-$ events the 1 s.d. sensitivities $\delta {\rm Re}
d_\tau = 5.8 \times 10^{-20}$ e cm and $\delta {\rm} Im d_\tau = 3.2 \times
10^{-20}$ e cm, again for events where both $\tau$ leptons decay
semihadronically. Furthermore, we analyze the potential magnitude of the $\tau$
EDM form factor in the type-II two-Higgs doublet extension and in two scalar
leptoquark extensions of the Standard Model.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:12:55 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 11:43:00 GMT""}]","2021-05-19"
"2101.08072","Hertzog Bester Ph. D.","Hertzog L. Bester, Audrey Repetti, Simon Perkins, Oleg M. Smirnov,
  Jonathan S. Kenyon","A practical preconditioner for wide-field continuum imaging of radio
  interferometric data","ADASS 2020 proceedings to be published in ASP conference series",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The celebrated CLEAN algorithm has been the cornerstone of deconvolution
algorithms in radio interferometry almost since its conception in the 1970s.
For all its faults, CLEAN is remarkably fast, robust to calibration artefacts
and in its ability to model point sources. We demonstrate how the same
assumptions that afford CLEAN its speed can be used to accelerate more
sophisticated deconvolution algorithms.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:18:44 GMT""}]","2021-01-21"
"2101.08073","Thomas Bittar","Thomas Bittar (CERMICS, EDF R\&D PRISME), Pierre Carpentier (OC),
  Jean-Philippe Chancelier (CERMICS), J\'er\^ome Lonchampt (EDF R&D PRISME)","The stochastic Auxiliary Problem Principle in Banach spaces:
  measurability and convergence",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stochastic Auxiliary Problem Principle (APP) algorithm is a general
Stochastic Approximation (SA) scheme that turns the resolution of an original
optimization problem into the iterative resolution of a sequence of auxiliary
problems. This framework has been introduced to design
decomposition-coordination schemes but also encompasses many well-known SA
algorithms such as stochastic gradient descent or stochastic mirror descent. We
study the stochastic APP in the case where the iterates lie in a Banach space
and we consider an additive error on the computation of the subgradient of the
objective. In order to derive convergence results or efficiency estimates for a
SA scheme, the iterates must be random variables. This is why we prove the
measurability of the iterates of the stochastic APP algorithm. Then, we extend
convergence results from the Hilbert space case to the Banach space case.
Finally, we derive efficiency estimates for the function values taken at the
averaged sequence of iterates or at the last iterate, the latter being obtained
by adapting the concept of modified Fej{\'e}r monotonicity to our framework.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:21:42 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 14:33:05 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 08:17:34 GMT""}]","2022-05-23"
"2101.08074","Chao Yan","Chao Yan, Xiaojia Xiang, Chang Wang, Zhen Lan","Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs
  Using Deep Reinforcement Learning","Accepted for publication in the proceedings of the 2021 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2021)",,,,"eess.SY cs.AI cs.LG cs.MA cs.SY","http://creativecommons.org/licenses/by/4.0/","  Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is
still a challenge due to kinematic complexity and environmental uncertainty. In
this paper, we deal with the decentralized flocking and collision avoidance
problem through deep reinforcement learning (DRL). Specifically, we formulate a
decentralized DRL-based decision making framework from the perspective of every
follower, where a collision avoidance mechanism is integrated into the flocking
controller. Then, we propose a novel reinforcement learning algorithm PS-CACER
for training a shared control policy for all the followers. Besides, we design
a plug-n-play embedding module based on convolutional neural networks and the
attention mechanism. As a result, the variable-length system state can be
encoded into a fixed-length embedding vector, which makes the learned DRL
policy independent with the number and the order of followers. Finally,
numerical simulation results demonstrate the effectiveness of the proposed
method, and the learned policies can be directly transferred to semi-physical
simulation without any parameter finetuning.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:23:35 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 11:37:13 GMT""}]","2021-07-26"
"2101.08075","Javier Falc\'o","Javier Falc\'o, Paul M. Gauthier","Asymptotic first boundary value problem for elliptic operators",,,,,"math.CV math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1955, Lehto showed that, for every measurable function $\psi$ on the unit
circle $\mathbb T,$ there is a function $f$ holomorphic in the unit disc,
having $\psi$ as radial limit a.e. on $\mathbb T.$ We consider an analogous
problem for solutions $f$ of homogenous elliptic equations $Pf=0$ and, in
particular, for holomorphic functions on Riemann surfaces and harmonic
functions on Riemannian manifolds.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:24:11 GMT""}]","2021-01-21"
"2101.08076","Jevgenijs Ivanovs","Mogens Bladt and Jevgenijs Ivanovs","Fluctuation theory for one-sided L\'evy processes with a
  matrix-exponential time horizon",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is an abundance of useful fluctuation identities for one-sided L\'evy
processes observed up to an independent exponentially distributed time horizon.
We show that all the fundamental formulas generalize to time horizons having
matrix exponential distributions, and the structure is preserved. Essentially,
the positive killing rate is replaced by a matrix with eigenvalues in the right
half of the complex plane which, in particular, applies to the positive root of
the Laplace exponent and the scale function. Various fundamental properties of
thus obtained matrices and functions are established, resulting in an easy to
use toolkit. An important application concerns deterministic time horizons
which can be well approximated by concentrated matrix exponential
distributions. Numerical illustrations are also provided.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:26:11 GMT""}]","2021-01-21"
"2101.08077","Cl\'ement Canc\`es","Sabrina Bassetto, Cl\'ement Canc\`es, Guillaume Ench\'ery, Quang-Huy
  Tran","Upstream mobility Finite Volumes for the Richards equation in
  heterogenous domains",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the Richards equation in a heterogeneous domain,
each subdomain of which is homogeneous and represents a rocktype. Our first
contribution is to rigorously prove convergence toward a weak solution of
cell-centered finite-volume schemes with upstream mobility and without
Kirchhoff's transform. Our second contribution is to numerically demonstrate
the relevance of locally refining the grid at the interface between subregions,
where discontinuities occur, in order to preserve an acceptable accuracy for
the results computed with the schemes under consideration.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:30:34 GMT""}]","2021-01-21"
"2101.08078","Matthieu Alfaro","Matthieu Alfaro (LMRS), Gwena\""el Peltier (IMAG)","Populations facing a nonlinear environmental gradient: steady states and
  pulsating fronts",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a population structured by a spacevariable and a phenotypical
trait, submitted to dispersion,mutations, growth and nonlocal competition. This
population is facing an {\it environmental gradient}: to survive at location
$x$, an individual must have a trait close to some optimal trait $y_{opt}(x)$.
Our main focus is to understand the effect of a {\it nonlinear} environmental
gradient. We thus consider a nonlocal parabolic equation for the distribution
of the population, with $y_{opt}(x) = \varepsilon\theta(x)$, $0<\vert
\varepsilon \vert \ll 1$. We construct steady states solutions and, when
$\theta$ is periodic, pulsating fronts. This requires the combination of
rigorous perturbation techniques based on a careful application of the implicit
function theorem in rather intricate function spaces. To deal with the
phenotypic trait variable $y$ we take advantage of a Hilbert basis of
$L^{2}(\mathbb{R})$ made of eigenfunctions of an underlying Schr\""odinger
operator, whereas to deal with the space variable $x$ we use the Fourier series
expansions. Our mathematical analysis reveals, in particular, how both the
steady states solutions and the fronts (speed and profile) are distorted by the
nonlinear environmental gradient, which are important biological insights.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:32:03 GMT""}]","2021-01-21"
"2101.08079","Houcine Chougrani","Houcine Chougrani, Steven Kisseleff, Wallace A. Martins and Symeon
  Chatzinotas","NB-IoT Random Access for Non-Terrestrial Networks","We got minor revisions, we addressed them and this is the updated
  version",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The satellite component is recognized as a promising solution to complement
and extend the coverage of future Internet of things (IoT) terrestrial networks
(TNs). In this context, a study item to integrate satellites into narrowband
IoT (NB-IoT) systems has been approved within the 3rd Generation Partnership
Project (3GPP) standardization body. However, as NB-IoT systems were initially
conceived for TNs, their basic design principles and operation might require
some key modifications when incorporating the satellite component. These
changes in NB-IoT systems, therefore, need to be carefully implemented in order
to guarantee a seamless integration of both TN and non-terrestrial network
(NTN) for a global coverage. This paper addresses this adaptation for the
random access (RA) step in NB-IoT systems, which is in fact the most
challenging aspect in the NTN context, for it deals with multi-user
time-frequency synchronization and timing advance for data scheduling. In
particular, we propose an RA technique which is robust to typical satellite
channel impairments, including long delays, significant Doppler effects, and
wide beams, without requiring any modification to the current NBIoT RA
waveform. Performance evaluations demonstrate the proposal's capability of
addressing different NTN configurations recently defined by 3GPP for the 5G new
radio system.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:36:42 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 15:03:46 GMT""}]","2021-09-30"
"2101.08080","Boris Thibert","Anatole Gallou\""et (LJK), Quentin Merigot (LMO), Boris Thibert (LJK)","A Damped Newton Algorithm for Generated Jacobian Equations",,,,,"cs.CG cs.NA math.AP math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generated Jacobian Equations have been introduced by Trudinger [Disc. cont.
dyn. sys (2014), pp. 1663-1681] as a generalization of Monge-Amp{\`e}re
equations arising in optimal transport. In this paper, we introduce and study a
damped Newton algorithm for solving these equations in the semi-discrete
setting, meaning that one of the two measures involved in the problem is
finitely supported and the other one is absolutely continuous. We also present
a numerical application of this algorithm to the near-field parallel refractor
problem arising in non-imaging problems.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:37:05 GMT""}]","2021-01-21"
"2101.08081","Peter Trifonov","Peter Trifonov","Recursive Trellis Processing of Large Polarization Kernels","Submitted to ISIT2021",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  A reduced complexity algorithm is presented for computing the log-likelihood
ratios arising in the successive cancellation decoder for polar codes with
large kernels of arbitrary dimension. The proposed algorithm exploits recursive
trellis representation of the codes generated by submatrices of the
polarization kernel, and enables codes based on large kernels to provide better
performance compared to the codes based on Arikan kernel with the same decoding
complexity.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:37:38 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 14:49:11 GMT""}]","2021-01-29"
"2101.08082","Tristan Gauti\'e","Tristan Gauti\'e, Jean-Philippe Bouchaud, Pierre Le Doussal","Matrix Kesten Recursion, Inverse-Wishart Ensemble and Fermions in a
  Morse Potential","44 pages, 5 figures, 6 appendices","J. Phys. A: Math. Theor. 54 255201 (2021)","10.1088/1751-8121/abfc7f",,"cond-mat.stat-mech cond-mat.dis-nn math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The random variable $1+z_1+z_1z_2+\dots$ appears in many contexts and was
shown by Kesten to exhibit a heavy tail distribution. We consider natural
extensions of this variable and its associated recursion to $N \times N$
matrices either real symmetric $\beta=1$ or complex Hermitian $\beta=2$. In the
continuum limit of this recursion, we show that the matrix distribution
converges to the inverse-Wishart ensemble of random matrices. The full dynamics
is solved using a mapping to $N$ fermions in a Morse potential, which are
non-interacting for $\beta=2$. At finite $N$ the distribution of eigenvalues
exhibits heavy tails, generalizing Kesten's results in the scalar case. The
density of fermions in this potential is studied for large $N$, and the
power-law tail of the eigenvalue distribution is related to the properties of
the so-called determinantal Bessel process which describes the hard edge
universality of random matrices. For the discrete matrix recursion, using free
probability in the large $N$ limit, we obtain a self-consistent equation for
the stationary distribution. The relation of our results to recent works of
Rider and Valk\'o, Grabsch and Texier, as well as Ossipov, is discussed.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:39:16 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 14:04:10 GMT""}]","2021-08-03"
"2101.08083","Marouane Il Idrissi","Marouane Il Idrissi, Vincent Chabridon, Bertrand Iooss","Developments and applications of Shapley effects to reliability-oriented
  sensitivity analysis with correlated inputs",,,,,"math.ST stat.AP stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reliability-oriented sensitivity analysis methods have been developed for
understanding the influence of model inputs relative to events which
characterize the failure of a system (e.g., a threshold exceedance of the model
output). In this field, the target sensitivity analysis focuses primarily on
capturing the influence of the inputs on the occurrence of such a critical
event. This paper proposes new target sensitivity indices, based on the Shapley
values and called ""target Shapley effects"", allowing for interpretable
sensitivity measures under dependent inputs. Two algorithms (one based on Monte
Carlo sampling, and a given-data algorithm based on a nearest-neighbors
procedure) are proposed for the estimation of these target Shapley effects
based on the $\ell^2$ norm. Additionally, the behavior of these target Shapley
effects are theoretically and empirically studied through various toy-cases.
Finally, the application of these new indices in two real-world use-cases (a
river flood model and a COVID-19 epidemiological model) is discussed.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:39:24 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 12:01:07 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 08:43:25 GMT""}]","2021-05-20"
"2101.08084","Sarath Raman Nair","Sarath Raman Nair, Lachlan J. Rogers, David J. Spence, Richard P.
  Mildren, Fedor Jelezko, Andrew D. Greentree, Thomas Volz, and Jan Jeske","Absorptive laser threshold magnetometry: combining visible diamond Raman
  lasers and nitrogen-vacancy centres",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a high-sensitivity magnetometry scheme based on a diamond Raman
laser with visible pump absorption by an ensemble of coherently microwave
driven negatively charged nitrogen-vacancy centres (NV) in the same diamond
crystal. The NV centres' absorption and emission are spin-dependent. We show
how the varying absorption of the NV centres changes the Raman laser output. A
shift in the diamond Raman laser threshold and output occurs with the external
magnetic-field and microwave driving. We develop a theoretical framework
including steady-state solutions to describe the effects of coherently driven
NV centres in a diamond Raman laser. We discuss that such a laser working at
the threshold can be employed for magnetic-field sensing. In contrast to
previous studies on NV magnetometry with visible laser absorption, the laser
threshold magnetometry method is expected to have low technical noise, due to
low background light in the measurement signal. For magnetic-field sensing, we
project a shot-noise limited DC sensitivity of a few
$\mathrm{pT}/\sqrt{\mathrm{Hz}}$ in a well-calibrated cavity with realistic
parameters. This sensor employs the broad visible absorption of NV centres and
unlike previous laser threshold magnetometry proposals it does not rely on
active NV centre lasing or an infrared laser medium at the specific wavelength
of the NV centre's infrared absorption line.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:40:20 GMT""}]","2021-01-21"
"2101.08085","Xiatian Zhu","Xiatian Zhu and Antoine Toisoul and Juan-Manuel Perez-Rua and Li Zhang
  and Brais Martinez and Tao Xiang","Few-shot Action Recognition with Prototype-centered Attentive Learning","10 pages, 4 figures","BMVC 2021",,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Few-shot action recognition aims to recognize action classes with few
training samples. Most existing methods adopt a meta-learning approach with
episodic training. In each episode, the few samples in a meta-training task are
split into support and query sets. The former is used to build a classifier,
which is then evaluated on the latter using a query-centered loss for model
updating. There are however two major limitations: lack of data efficiency due
to the query-centered only loss design and inability to deal with the support
set outlying samples and inter-class distribution overlapping problems. In this
paper, we overcome both limitations by proposing a new Prototype-centered
Attentive Learning (PAL) model composed of two novel components. First, a
prototype-centered contrastive learning loss is introduced to complement the
conventional query-centered learning objective, in order to make full use of
the limited training samples in each episode. Second, PAL further integrates a
hybrid attentive learning mechanism that can minimize the negative impacts of
outliers and promote class separation. Extensive experiments on four standard
few-shot action benchmarks show that our method clearly outperforms previous
state-of-the-art methods, with the improvement particularly significant (10+\%)
on the most challenging fine-grained action recognition benchmark.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:48:12 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 23:39:54 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 16:22:37 GMT""},{""version"":""v4"",""created"":""Sun, 28 Mar 2021 17:15:14 GMT""}]","2021-10-26"
"2101.08086","Jules Tilly Mr","Jules Tilly, Ryan J. Marshman, Anupam Mazumdar, Sougato Bose","Qudits for Witnessing Quantum Gravity Induced Entanglement of Masses
  Under Decoherence","15 pages, 20 figures, 2 tables",,"10.1103/PhysRevA.104.052416",,"quant-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  Recently a theoretical and an experimental protocol known as quantum gravity
induced entanglement of masses (QGEM) has been proposed to test the quantum
nature of gravity using two mesoscopic masses each placed in a superposition of
two locations. If, after eliminating all non-gravitational interactions between
them, the particles become entangled, one can conclude that the gravitational
potential is induced via a quantum mediator, i.e. a virtual graviton. In this
paper, we examine a range of different experimental set-ups, considering
different geometries and the number of spatially superposed states taken, in
order to determine which would generate entanglement faster. We conclude that
without decoherence, and given a maximum distance $\Delta x$ between any two
spatial states of a superposition, a set of two qubits placed in spatial
superposition parallel to one another will outperform all other models given
realistic experimental parameters. Furthermore, when a sufficiently high
decoherence rate is introduced, multi-component superpositions can outperform
the two-qubit set-up. This is further verified with an experimental simulation,
showing that $O(10^3)$ measurements are required to reject the no entanglement
hypothesis with a parallel qubits set-up without decoherence at a 99.9$\%$
confidence level. The number of measurements increases when decoherence is
introduced. When the decoherence rate reaches $0.125$~Hz, 6-dimensional qudits
are required as the two-qubit system entanglement cannot be witnessed anymore.
However, in this case, $O(10^6)$ measurements will be required. One can group
the witness operators to measure in order to reduce the number of measurements
(up to ten-fold). However, this may be challenging to implement experimentally.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:50:12 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 13:17:31 GMT""}]","2021-11-24"
"2101.08087","Mohammad Kasra Habib","Mohammad Kasra Habib","The Challenges of Persian User-generated Textual Content: A Machine
  Learning-Based Approach","12 Pages bib inc., 5 Figures and 5 Tables",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over recent years a lot of research papers and studies have been published on
the development of effective approaches that benefit from a large amount of
user-generated content and build intelligent predictive models on top of them.
This research applies machine learning-based approaches to tackle the hurdles
that come with Persian user-generated textual content. Unfortunately, there is
still inadequate research in exploiting machine learning approaches to
classify/cluster Persian text. Further, analyzing Persian text suffers from a
lack of resources; specifically from datasets and text manipulation tools.
Since the syntax and semantics of the Persian language is different from
English and other languages, the available resources from these languages are
not instantly usable for Persian. In addition, recognition of nouns and
pronouns, parts of speech tagging, finding words' boundary, stemming or
character manipulations for Persian language are still unsolved issues that
require further studying. Therefore, efforts have been made in this research to
address some of the challenges. This presented approach uses a
machine-translated datasets to conduct sentiment analysis for the Persian
language. Finally, the dataset has been rehearsed with different classifiers
and feature engineering approaches. The results of the experiments have shown
promising state-of-the-art performance in contrast to the previous efforts; the
best classifier was Support Vector Machines which achieved a precision of
91.22%, recall of 91.71%, and F1 score of 91.46%.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:57:59 GMT""}]","2021-01-21"
"2101.08088","Ticijana Ban Dr.sc.","Mateo Kruljac, Danijel Buhin, Domagoj Kovacic, Vjekoslav Vulic, Damir
  Aumiler, and Ticijana Ban","Frequency-comb-induced radiation pressure force in dense atomic clouds","8 pages, 4 figures",,"10.1364/JOSAB.449798",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the frequency comb induced radiation pressure force acting on
a cloud of cold $^{87}$Rb atoms. Reduction and spectral broadening of the
frequency comb force are observed as the cloud's optical thickness is
increased. Since the radiation pressure force is uniquely determined by light
scattered by an atomic cloud, we discuss different scattering mechanisms, and
point to the shadow effect as the dominant mechanism affecting FC-induced force
in resonantly excited dense atomic clouds. Our results improve the
understanding of the interaction of frequency comb light with many-atom
ensembles, which is essential for novel frequency comb applications in
simultaneous multi-species cooling, multi-mode quantum memories, and multi-mode
atom-light interfaces.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 11:58:57 GMT""},{""version"":""v2"",""created"":""Mon, 22 Nov 2021 14:55:37 GMT""}]","2022-05-04"
"2101.08089","Marat Timirgazin","M. A. Timirgazin and A. K. Arzhnikov","Generalization properties of restricted Boltzmann machine for
  short-range order","21 pages, 11 figures",,,,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The restricted Boltzmann machine (RBM) is used to investigate short-range
order in binary alloys. The network is trained on the data collected by Monte
Carlo simulations for a simple Ising-like binary alloy model and used to
calculate the Warren--Cowley short-range order parameter and other
thermodynamic properties. We demonstrate that RBM not only reproduces the order
parameters for the alloy concentration at which it was trained, but can also
predict them for any other concentrations.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:01:13 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 12:15:16 GMT""},{""version"":""v3"",""created"":""Fri, 16 Apr 2021 07:46:13 GMT""},{""version"":""v4"",""created"":""Fri, 6 Aug 2021 10:52:12 GMT""},{""version"":""v5"",""created"":""Fri, 29 Oct 2021 08:49:13 GMT""}]","2021-11-01"
"2101.08090","Stefan Schr\""oer","Dino Lorenzini, Stefan Schr\""oer","Discriminant groups of wild cyclic quotient singularities","44 pages","Alg. Number Th. 17 (2023) 1017-1068","10.2140/ant.2023.17.1017",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let p be prime. We describe explicitly the resolution of singularities of
several families of wild Z/pZ-quotient singularities in dimension two,
including families that generalize the quotient singularities of type E_6, E_7,
and E_8 from p=2 to arbitrary characteristics. We prove that for odd primes,
any power of p can appear as the determinant of the intersection matrix of a
wild Z/pZ-quotient singularity. We also provide evidence towards the conjecture
that in this situation one may choose the wild action to be ramified precisely
at the origin.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:01:37 GMT""}]","2023-05-10"
"2101.08091","Xiaoqi Huang","H. Weld, X. Huang, S. Long, J. Poon, S. C. Han (School of Computer
  Science, The University of Sydney)","A survey of joint intent detection and slot-filling models in natural
  language understanding","33 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intent classification and slot filling are two critical tasks for natural
language understanding. Traditionally the two tasks have been deemed to proceed
independently. However, more recently, joint models for intent classification
and slot filling have achieved state-of-the-art performance, and have proved
that there exists a strong relationship between the two tasks. This article is
a compilation of past work in natural language understanding, especially joint
intent classification and slot filling. We observe three milestones in this
research so far: Intent detection to identify the speaker's intention, slot
filling to label each word token in the speech/text, and finally, joint intent
classification and slot filling tasks. In this article, we describe trends,
approaches, issues, data sets, evaluation metrics in intent classification and
slot filling. We also discuss representative performance values, describe
shared tasks, and provide pointers to future work, as given in prior works. To
interpret the state-of-the-art trends, we provide multiple tables that describe
and summarise past research along different dimensions, including the types of
features, base approaches, and dataset domain used.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:15:11 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 05:08:26 GMT""},{""version"":""v3"",""created"":""Mon, 22 Feb 2021 03:25:17 GMT""}]","2021-02-23"
"2101.08092","Chunshan Lin","Chunshan Lin","An effective field theory of holographic dark energy","18 pages, no figure; v2: minor revision, results unchanged; v3:
  published version, a few remarks added, a few typos corrected","JCAP07(2021)003","10.1088/1475-7516/2021/07/003",,"hep-th astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  A general covariant local field theory of the holographic dark energy model
is presented. It turns out the low energy effective theory of the holographic
dark energy is the massive gravity theory whose graviton has 3 polarisations,
including one scalar mode and two tensor modes. The Compton wavelength is the
size of the future event horizon of the universe. The UV-IR correspondence in
the holographic dark energy model stems from the scalar graviton's strong
coupling at the energy scale that marks the breaking down of the effective
field theory.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:17:30 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 11:35:51 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jul 2021 16:47:13 GMT""}]","2021-07-06"
"2101.08093","Hugo Th\'eveniaut","Hugo Th\'eveniaut and Evert van Nieuwenburg","A NEAT Quantum Error Decoder","10 pages, 7 figures","SciPost Phys. 11, 005 (2021)","10.21468/SciPostPhys.11.1.005",,"quant-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the use of the evolutionary NEAT algorithm for the
optimization of a policy network that performs quantum error decoding on the
toric code, with bitflip and depolarizing noise, one qubit at a time. We find
that these NEAT-optimized network decoders have similar performance to
previously reported machine-learning based decoders, but use roughly three to
four orders of magnitude fewer parameters to do so.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:22:57 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 08:21:58 GMT""}]","2021-07-14"
"2101.08094","Balazs Patkos","D\'aniel Gerbner, Bal\'azs Patk\'os","Generalized Tur\'an problems for complete bipartite graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For graph $G$, $F$ and integer $n$, the generalized Tu\'an number $ex(n,G,F)$
denotes the maximum number of copies of $G$ that an $F$-free $n$-vertex graph
can have. We study this parameter when both $G$ and $F$ are complete bipartite
graphs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:33:46 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 15:37:13 GMT""}]","2021-05-12"
"2101.08095","Jesse Sigal","Jesse Sigal","Automatic Differentiation via Effects and Handlers: An Implementation in
  Frank","Appeared as short paper in PEPM'21, see
  https://www.youtube.com/watch?v=BmBSJFkfL2M for associated talk",,,,"cs.PL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Automatic differentiation (AD) is an important family of algorithms which
enables derivative based optimization. We show that AD can be simply
implemented with effects and handlers by doing so in the Frank language. By
considering how our implementation behaves in Frank's operational semantics, we
show how our code performs the dynamic creation of programs during evaluation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:34:25 GMT""}]","2021-01-21"
"2101.08096","Daniel Bakucz Can\'ario","Daniel Bakucz Can\'ario, Michael Klaiber, Karen Z. Hatsagortsyan,
  Christoph H. Keitel","The role of reflections in the generation of a time delay in strong
  field ionization","14 pages, 11 figures","Phys. Rev. A 104, 033103 (2021)","10.1103/PhysRevA.104.033103",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The problem of time delay in tunneling ionization is revisited. The origin of
time delay at the tunnel exit is analysed, underlining the two faces of the
concept of the tunnelling time delay: the time delay around the tunnel exit and
the asymptotic time delay at a detector. We show that the former time delay, in
the sense of a delay in the peak of the wavefunction, exists as a matter of
principle and arises due to the sub-barrier interference of the reflected and
transmitted components of the tunneling electronic wavepacket. We exemplify
this by describing the tunnelling ionization of an electron bound by a
short-range potential within the strong field approximation in a ""deep
tunnelling"" regime. If sub-barrier reflections are extracted from this
wavefunction, then the time delay of the peak is shown to vanish. Thus, we
assert that the disturbance of the tunnelling wavepacket by the reflection from
the surface of the barrier causes a time delay in the neighbourhood of the
tunnel exit.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:37:04 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 09:52:39 GMT""}]","2021-09-14"
"2101.08097","Alexander Schlager","A. Schlager, M. G\""otsch, R. J. Chapman, S. Frick, H. Thiel, H.
  Suchomel, M. Kamp, S. H\""ofling, C. Schneider and G. Weihs","Difference-frequency generation in an AlGaAs Bragg-reflection waveguide
  using an on-chip electrically-pumped quantum dot laser",,,"10.1088/2040-8986/ac13ae",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear frequency conversion is ubiquitous in laser engineering and quantum
information technology. A long-standing goal in photonics is to integrate
on-chip semiconductor laser sources with nonlinear optical components.
Engineering waveguide lasers with spectra that phase-match to nonlinear
processes on the same device is a formidable challenge. Here, we demonstrate
difference-frequency generation in an AlGaAs Bragg reflection waveguide which
incorporates the gain medium for the pump laser in its core. We include quantum
dot layers in the AlGaAs waveguide that generate electrically driven laser
light at ~790 nm, and engineer the structure to facilitate nonlinear processes
at this wavelength. We perform difference-frequency generation between 1540 nm
and 1630 nm using the on-chip laser, which is enabled by the broad modal
phase-matching of the AlGaAs waveguide, and measure normalized conversion
efficiencies up to $(0.64\pm0.21)$ %/W/cm$^2$. Our work demonstrates a pathway
towards devices that utilize on-chip active elements and strong optical
nonlinearities to enable highly integrated photonic systems-on-chip.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:43:41 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 07:40:28 GMT""},{""version"":""v3"",""created"":""Wed, 14 Jul 2021 07:46:47 GMT""},{""version"":""v4"",""created"":""Mon, 7 Feb 2022 10:49:35 GMT""}]","2022-02-08"
"2101.08098","Aryapoor Masood","Masood Aryapoor","Noncommutative Henselizations",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  In this paper, the familiar notion of a Henselian pair is extended to the
noncommutative case. Furthermore, the problem of Henselizations is studied in
the noncommutative context, and it is shown that every (not necessarily
commutative) pair which is Hausdorff with respect to a certain topology has a
left (and right) Henselization.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:48:38 GMT""}]","2021-01-21"
"2101.08099","Vincenzo Amato","Vincenzo Amato, Andrea Gentile, Alba Lia Masiello","Comparison results for solutions to p-Laplace equations with Robin
  boundary conditions",,"Annali di Matematica (2021)","10.1007/s10231-021-01153-y",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In the last decades comparison results of Talenti type for Elliptic Problems
with Dirichlet boundary conditions have been widely investigated. In this
paper, we generalize the results obtained in arXiv:1909.11950 to the case of
p-Laplace operator with Robin boundary conditions. The point-wise comparison,
obtained in arXiv:1909.11950 only in the planar case, holds true in any
dimension if p is sufficiently small.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:50:14 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 10:58:27 GMT""}]","2021-09-20"
"2101.08100","Weixuan Zhang","Weixuan Zhang, Marco Tognon, Lionel Ott, Roland Siegwart, and Juan
  Nieto","Active Model Learning using Informative Trajectories for Improved
  Closed-Loop Control on Real Robots",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Model-based controllers on real robots require accurate knowledge of the
system dynamics to perform optimally. For complex dynamics, first-principles
modeling is not sufficiently precise, and data-driven approaches can be
leveraged to learn a statistical model from real experiments. However, the
efficient and effective data collection for such a data-driven system on real
robots is still an open challenge. This paper introduces an optimization
problem formulation to find an informative trajectory that allows for efficient
data collection and model learning. We present a sampling-based method that
computes an approximation of the trajectory that minimizes the prediction
uncertainty of the dynamics model. This trajectory is then executed, collecting
the data to update the learned model. In experiments we demonstrate the
capabilities of our proposed framework when applied to a complex
omnidirectional flying vehicle with tiltable rotors. Using our informative
trajectories results in models which outperform models obtained from
non-informative trajectory by 13.3\% with the same amount of training data.
Furthermore, we show that the model learned from informative trajectories
generalizes better than the one learned from non-informative trajectories,
achieving better tracking performance on different tasks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:54:26 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 13:34:39 GMT""}]","2021-05-17"
"2101.08101","Alexander Blokh","Sourav Bhattacharya, Alexander Blokh, Dierk Schleicher","Unicritical Laminations","35 pages, 1 figure; keywords: complex dynamics, circle dynamics,
  laminations",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thurston introduced \emph{invariant (quadratic) laminations} in his 1984
preprint as a vehicle for understanding the connected Julia sets and the
parameter space of quadratic polynomials. Important ingredients of his analysis
of the angle doubling map $\sigma_2$ on the unit circle $\mathbb{S}^1$ were the
Central Strip Lemma, non-existence of wandering polygons, the transitivity of
the first return map on vertices of periodic polygons, and the non-crossing of
minors of quadratic invariant laminations. We use Thurston's methods to prove
similar results for \emph{unicritical} laminations of arbitrary degree $d$ and
to show that the set of so-called \emph{minors} of unicritical laminations
themselves form a \emph{Unicritical Minor Lamination} $\mathrm{UML}_d$. In the
end we verify the \emph{Fatou conjecture} for the unicritical laminations and
extend the \emph{Lavaurs algorithm} onto $\mathrm{UML}_d$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:55:46 GMT""}]","2021-01-21"
"2101.08102","Severin Kacianka","Severin Kacianka and Alexander Pretschner","Designing Accountable Systems","accepted for publication at the ACM Conference on Fairness,
  Accountability, and Transparency (ACM FAccT) 2021",,"10.1145/3442188.3445905",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accountability is an often called for property of technical systems. It is a
requirement for algorithmic decision systems, autonomous cyber-physical
systems, and for software systems in general. As a concept, accountability goes
back to the early history of Liberalism and is suggested as a tool to limit the
use of power. This long history has also given us many, often slightly
differing, definitions of accountability. The problem that software developers
now face is to understand what accountability means for their systems and how
to reflect it in a system's design. To enable the rigorous study of
accountability in a system, we need models that are suitable for capturing such
a varied concept. In this paper, we present a method to express and compare
different definitions of accountability using Structural Causal Models. We show
how these models can be used to evaluate a system's design and present a small
use case based on an autonomous car.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:59:03 GMT""}]","2021-04-30"
"2101.08103","Daniel Hatton","D. Hatton, C. T. H. Davies, J. Koponen, G. P. Lepage, A. T. Lytle","Bottomonium precision tests from full lattice QCD: hyperfine splitting,
  $\Upsilon$ leptonic width and $b$ quark contribution to $e^+e^- \rightarrow$
  hadrons","16 pages, 9 figures Version accepted by PRD: Appendix with tables of
  fit parameters that allow the dependence on heavy quark mass of the hyperfine
  splitting and decay constants to be reconstructed added","Phys. Rev. D 103, 054512 (2021)","10.1103/PhysRevD.103.054512",,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the mass difference between the $\Upsilon$ and $\eta_b$ and the
$\Upsilon$ leptonic width from lattice QCD using the Highly Improved Staggered
Quark formalism for the $b$ quark and including $u$, $d$, $s$ and $c$ quarks in
the sea. We have results for lattices with lattice spacing as low as 0.03 fm
and multiple heavy quark masses, enabling us to map out the heavy quark mass
dependence and determine values at the $b$ quark mass. Our results are:
$M_{\Upsilon} -M_{\eta_b} = 57.5(2.3)(1.0) \,\mathrm{MeV}$ (where the second
uncertainty comes from neglect of quark-line disconnected correlation
functions) and decay constants, $f_{\eta_b}=724(12)$ MeV and $f_{\Upsilon}
=677.2(9.7)$ MeV, giving $\Gamma(\Upsilon \rightarrow e^+e^-) = 1.292(37)(3)
\,\mathrm{keV}$. The hyperfine splitting and leptonic width are both in good
agreement with experiment, and provide the most accurate lattice QCD results to
date for these quantities by some margin. At the same time results for the time
moments of the vector-vector correlation function can be compared to values for
the $b$ quark contribution to $\sigma(e^+e^- \rightarrow \mathrm{hadrons})$
determined from experiment. Moments 4--10 provide a 2\% test of QCD and yield a
$b$ quark contribution to the anomalous magnetic moment of the muon of
0.300(15)$\times 10^{-10}$. Our results, covering a range of heavy quark
masses, may also be useful to constrain QCD-like composite theories for beyond
the Standard Model physics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:01:10 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 19:49:15 GMT""}]","2021-03-31"
"2101.08104","Till Schulz","Till Hendrik Schulz, Tam\'as Horv\'ath, Pascal Welke, Stefan Wrobel","A Generalized Weisfeiler-Lehman Graph Kernel","n/a",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Weisfeiler-Lehman graph kernels are among the most prevalent graph
kernels due to their remarkable time complexity and predictive performance.
Their key concept is based on an implicit comparison of neighborhood
representing trees with respect to equality (i.e., isomorphism). This binary
valued comparison is, however, arguably too rigid for defining suitable
similarity measures over graphs. To overcome this limitation, we propose a
generalization of Weisfeiler-Lehman graph kernels which takes into account the
similarity between trees rather than equality. We achieve this using a
specifically fitted variation of the well-known tree edit distance which can
efficiently be calculated. We empirically show that our approach significantly
outperforms state-of-the-art methods in terms of predictive performance on
datasets containing structurally more complex graphs beyond the typically
considered molecular graphs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:03:51 GMT""}]","2021-01-21"
"2101.08105","Jing Zhou","Jing Zhou, Jun Chen, Le Zhang, Jialun Ping, Xun Chen","Holographic Schwinger Effect in Anisotropic Media",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the guage/gravity correspondence, we discuss the holographic Schwinger
effect in anisotropic backgrond. First of all, we compute the separating length
of the particle-antiparticle pairs at different anisotropic background which is
specified by dynamical exponent $\nu$ with the isotropic case is $\nu= 1$. Then
it is found that the maximum separating length $x$ decreases with the
increasing of dynamical exponent $\nu$. This can be regarded as the virtual
particles become real ones more easily. Subsequently, we find that the
potential barrier is reduced by dynamical exponent $\nu$, warp factor
coefficient $c$ and chemical potential $\mu$ at small distance. Moreover, we
also find the critical electric field is reduced by the chemical potential and
dynamical exponent, but enhanced by the warp factor coefficient.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:07:14 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 05:04:55 GMT""},{""version"":""v3"",""created"":""Wed, 4 May 2022 12:47:38 GMT""},{""version"":""v4"",""created"":""Fri, 6 May 2022 03:40:43 GMT""}]","2022-05-09"
"2101.08106","Lingyun Feng","Lingyun Feng, Minghui Qiu, Yaliang Li, Hai-Tao Zheng, Ying Shen","Learning to Augment for Data-Scarce Domain BERT Knowledge Distillation","AAAI2021",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Despite pre-trained language models such as BERT have achieved appealing
performance in a wide range of natural language processing tasks, they are
computationally expensive to be deployed in real-time applications. A typical
method is to adopt knowledge distillation to compress these large pre-trained
models (teacher models) to small student models. However, for a target domain
with scarce training data, the teacher can hardly pass useful knowledge to the
student, which yields performance degradation for the student models. To tackle
this problem, we propose a method to learn to augment for data-scarce domain
BERT knowledge distillation, by learning a cross-domain manipulation scheme
that automatically augments the target with the help of resource-rich source
domains. Specifically, the proposed method generates samples acquired from a
stationary distribution near the target data and adopts a reinforced selector
to automatically refine the augmentation strategy according to the performance
of the student. Extensive experiments demonstrate that the proposed method
significantly outperforms state-of-the-art baselines on four different tasks,
and for the data-scarce domains, the compressed student models even perform
better than the original large teacher model, with much fewer parameters (only
${\sim}13.3\%$) when only a few labeled examples available.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:07:39 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 12:27:58 GMT""}]","2021-06-22"
"2101.08107","Chih-Whi Chen","Chih-Whi Chen","Whittaker modules for classical Lie superalgebras","29 pages, version 2, minor revision. Comments welcome",,"10.1007/s00220-021-04159-y",,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify simple Whittaker modules for classical Lie superalgebras in terms
of their parabolic decompositions. We establish a type of Mili\v{c}i\'c-Soergel
equivalence of a category of Whittaker modules and a category of Harish-Chandra
bimodules. For classical Lie superalgebras of type I, we reduce the problem of
composition factors of standard Whittaker modules to that of Verma modules in
their BGG categories $\mathcal O$. As a consequence, the composition series of
standard Whittaker modules over the general linear Lie superalgebras
$\mathfrak{gl}(m|n)$ and the ortho-symplectic Lie superalgebras
$\mathfrak{osp}(2|2n)$ can be computed via the Kazhdan-Lusztig combinatorics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:07:57 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 13:09:35 GMT""}]","2021-08-18"
"2101.08108","Emanuele Bottazzi","Emanuele Bottazzi","Describing limits of integrable functions as grid functions of
  nonstandard analysis",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In functional analysis, there are different notions of limit for a bounded
sequence of $L^1$ functions. Besides the pointwise limit, that does not always
exist, the behaviour of a bounded sequence of $L^1$ functions can be described
in terms of its weak-$\star$ limit or by introducing a measure-valued notion of
limit in the sense of Young measures. Working in Robinson's framework of
analysis with infinitesimals, we show that for every bounded sequence
$\{z_n\}_{n \in \mathbb{N}}$ of $L^1$ functions there exists a function of a
hyperfinite domain (i.e.\ a grid function) that represents both the
weak-$\star$ and the Young measure limits of the sequence. This result has
relevant applications to the study of nonlinear PDEs. We discuss the example of
an ill-posed forward-backward parabolic equation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:08:25 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 08:19:47 GMT""}]","2021-04-13"
"2101.08109","Smitha Rao","H S Smitha Rao, Swarnamala Sirsi and Karthik Bharath","Joint quasiprobability distribution on the measurement outcomes of
  MUB-driven operators",,,"10.1016/j.physleta.2021.127378",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We propose a method to define quasiprobability distributions for general
spin-$j$ systems of dimension $n=2j+1$, where $n$ is a prime or power of prime.
The method is based on a complete set of orthonormal commuting operators
related to Mutually Unbiased Bases which enable (i) a parameterisation of the
density matrix and (ii) construction of measurement operators that can be
physically realised. As a result we geometrically characterise the set of
states for which the quasiprobability distribution is non-negative, and can be
viewed as a joint distribution of classical random variables assuming values in
a finite set of outcomes. The set is an $(n^2-1)$-dimensional convex polytope
with $n+1$ vertices as the only pure states, $n^{n+1}$ number of higher
dimensional faces, and $n^3(n+1)/2$ edges.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:10:26 GMT""}]","2021-05-03"
"2101.08110","Jimmy Johansson","Jimmy Johansson","Polynomial interpolation and residue currents",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  We show that a global holomorphic section of $\mathscr{O}(d)$ restricted to a
closed complex subspace $X \subset \mathbb{P}^n$ has an interpolant if and only
if it satisfies a set of moment conditions that involves a residue current
associated with a locally free resolution of $\mathscr{O}_X$. When $X$ is a
finite set of points in $\mathbb{C}^n \subset \mathbb{P}^n$ this can be
interpreted as a set of linear conditions that a function on $X$ has to satisfy
in order to have a polynomial interpolant of degree at most $d$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:15:18 GMT""}]","2021-01-21"
"2101.08111","Manuel Marques-Pita PhD","Santosh Manicka, Manuel Marques-Pita, Luis M. Rocha","Effective connectivity determines the critical dynamics of biochemical
  networks","22 pages, 7 figures",,,,"q-bio.MN nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Living systems operate in a critical dynamical regime -- between order and
chaos -- where they are both resilient to perturbation, and flexible enough to
evolve. To characterize such critical dynamics, the established 'structural
theory' of criticality uses automata network connectivity and node bias (to be
on or off) as tuning parameters. This parsimony in the number of parameters
needed sometimes leads to uncertain predictions about the dynamical regime of
both random and systems biology models of biochemical regulation. We derive a
more accurate theory of criticality by accounting for canalization, the
existence of redundancy that buffers automata response to inputs -- a known
mechanism that buffers the expression of traits, keeping them close to optimal
states despite genetic and environmental perturbations. The new 'canalization
theory' of criticality is based on a measure of effective connectivity. It
contributes to resolving the problem of finding precise ways to design or
control network models of biochemical regulation for desired dynamical
behavior. Our analyses reveal that effective connectivity significantly
improves the prediction of critical behavior in random automata network
ensembles. We also show that the average effective connectivity of a large
battery of systems biology models is much lower than the connectivity of their
original interaction structure. This suggests that canalization has been
selected to dynamically reduce and homogenize the seemingly heterogeneous
connectivity of biochemical networks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:16:39 GMT""}]","2022-01-28"
"2101.08112","Salom\'ee Marion Tschopp","S.M. Tschopp and J.M. Brader","Fundamental measure theory of inhomogeneous two-body correlation
  functions",,"Phys. Rev. E 103, 042103 (2021)","10.1103/PhysRevE.103.042103",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  For the three-dimensional hard-sphere model we investigate the inhomogeneous
two-body correlations predicted by Rosenfeld's fundamental measure theory. For
the special cases in which the density has either planar or spherical symmetry
we provide analytic formulae for the Hankel and Legendre transforms,
respectively, of the inhomogeneous two-body direct correlation function as
explicit functionals of the density. When combined with the Ornstein-Zernike
relation our analytical results allow for rapid calculation of inhomogeneous
hard-sphere density correlations in real-space. These provide not only
information about the packing structures of the hard-sphere system, but also
form an essential building-block for constructing perturbation theories of more
realistic models.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:17:36 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 13:42:11 GMT""}]","2021-04-15"
"2101.08113","Shuta Nakajima","Cl\'ement Cosco and Shuta Nakajima","A variational formula for large deviations in First-passage percolation
  under tail estimates","This preprint supersedes arXiv:1912.13212. 36 pages, 2 figures, v2",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider first passage percolation with identical and independent weight
distributions and first passage time ${\rm T}$. In this paper, we study the
upper tail large deviations $\mathbb{P}({\rm T}(0,nx)>n(\mu+\xi))$, for $\xi>0$
and $x\neq 0$ with a time constant $\mu$ and a dimension $d$, for weights that
satisfy a tail assumption $ \beta_1\exp{(-\alpha t^r)}\leq \mathbb
P(\tau_e>t)\leq \beta_2\exp{(-\alpha t^r)}.$ When $r\leq 1$ (this includes the
well-known Eden growth model), we show that the upper tail large deviation
decays as $\exp{(-(2d\xi +o(1))n)}$. When $1< r\leq d$, we find that the rate
function can be naturally described by a variational formula, called the
discrete p-Capacity, and we study its asymptotics. For $r<d$, we show that the
large deviation event ${\rm T}(0,nx)>n(\mu+\xi)$ is described by a localization
of high weights around the origin. The picture changes for $r\geq d$ where the
configuration is not anymore localized.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:20:59 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 16:29:46 GMT""},{""version"":""v3"",""created"":""Wed, 1 Feb 2023 15:52:17 GMT""}]","2023-02-02"
"2101.08114","Jose Manuel Gomez-Perez","Andres Garcia-Silva and Jose Manuel Gomez-Perez","Classifying Scientific Publications with BERT -- Is Self-Attention a
  Feature Selection Method?","Paper accepted for publication at ECIR2021",,,,"cs.CL cs.AI cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the self-attention mechanism of BERT in a fine-tuning scenario
for the classification of scientific articles over a taxonomy of research
disciplines. We observe how self-attention focuses on words that are highly
related to the domain of the article. Particularly, a small subset of
vocabulary words tends to receive most of the attention. We compare and
evaluate the subset of the most attended words with feature selection methods
normally used for text classification in order to characterize self-attention
as a possible feature selection approach. Using ConceptNet as ground truth, we
also find that attended words are more related to the research fields of the
articles. However, conventional feature selection methods are still a better
option to learn classifiers from scratch. This result suggests that, while
self-attention identifies domain-relevant terms, the discriminatory information
in BERT is encoded in the contextualized outputs and the classification layer.
It also raises the question whether injecting feature selection methods in the
self-attention mechanism could further optimize single sequence classification
using transformers.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:22:26 GMT""}]","2021-01-21"
"2101.08115","Lei Zhang","Hsin-yuan Huang and Lei Zhang","On Liouville systems at critical parameters, Part 2: Multiple bubbles","27 pages",,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we continue to consider the generalized Liouville system: $$
\Delta_g u_i+\sum_{j=1}^n a_{ij}\rho_j\left(\frac{h_j e^{u_j}}{\int h_j
e^{u_j}}- {1} \right)=0\quad\text{in \,}M,\quad i\in I=\{1,\cdots,n\}, $$ where
$(M,g)$ is a Riemann surface $M$ with volume $1$, $h_1,..,h_n$ are positive
smooth functions and $\rho_j\in \mathbb R^+$($j\in I$). In previous works
Lin-Zhang identified a family of hyper-surfaces $\Gamma_N$ and proved a priori
estimates for $\rho=(\rho_1,..,\rho_n)$ in areas separated by $\Gamma_N$. Later
Lin-Zhang also calculated the leading term of $\rho^k-\rho$ where $\rho\in
\Gamma_1$ is the limit of $\rho^k$ on $\Gamma_1$ and $\rho^k$ is the parameter
of a bubbling sequence. This leading term is particularly important for
applications but it is very hard to be identified if $\rho^k$ tends to a higher
order hypersurface $\Gamma_N$ ($N>1$). Over the years numerous attempts have
failed but in this article we overcome all the stumbling blocks and completely
solve the problem under the most general context: We not only capture the
leading terms of $\rho^k-\rho\in \Gamma_N$, but also reveal new robustness
relations of coefficient functions at different blowup points.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:22:42 GMT""}]","2021-01-21"
"2101.08117","Giordano Cintia","Lasha Berezhiani, Giordano Cintia, Max Warkentin","Core Fragmentation in Simplest Superfluid Dark Matter Scenario","14 pages, 3 figures; V2: Minor edits, Journal version",,"10.1016/j.physletb.2021.136422",,"astro-ph.CO astro-ph.GA hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the structure of galactic halos within a scalar dark matter model,
endowed with a repulsive quartic self-interaction, capable of undergoing the
superfluid phase transition in high-density regions. We demonstrate that the
thermalized cores are prone to fragmentation into superfluid droplets due to
the Jeans instability. Furthermore, since cores of astrophysical size may be
generated only when most of the particles comprising the halo reside in a
highly degenerate phase-space, the well-known bound on the dark matter
self-interaction cross section inferred from the collision of clusters needs to
be revised, accounting for the enhancement of the interaction rate due to
degeneracy. As a result, generation of kpc-size superfluid solitons, within the
parameter subspace consistent with the Bullet Cluster bound, requires dark
matter particles to be ultra-light.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:27:45 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 11:48:54 GMT""}]","2021-09-08"
"2101.08118","Sazzad Ali Biswas","Sazzad Ali Biswas","An extension of Deligne-Henniart's twisting formula and its applications",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F/\mathbb{Q}_p$ be a non-Archimedean local field, and $G_F$ be the
absolute Galois group of $F$. Let $\rho_1$ and $\rho_2$ be two finite
dimensional complex representations of $G_F$. Let $\psi$ be a nontrivial
additive character of $F$. Then question is:
  What is the twisting formula for the root number
$W(\rho_1\otimes\rho_2,\psi)$?
  In general, answer of this question is not known yet. But if one of $\rho_i
(i=1,2)$ is one-dimensional with ""sufficiently"" large conductor, then Deligne
gave a twisting formula for $W(\rho_1\otimes\rho_2,\psi)$. Later Deligne and
Henniart give a general twisting formula for a zero dimensional virtual
representation twisted by a finite dimensional representation of $G_F$. In this
paper, first we extend Deligne's twisting formula for Heisenberg representation
of dimension prime $p$, then we further extend Deligne-Henniart's result.
  Finally, we give two very important applications of our twisting formula --
invariant formula of local root numbers for U-isotropic Heisenberg
representations and a converse theorem in the Galois side.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:34:35 GMT""}]","2021-01-21"
"2101.08119","Apoorva Bajaj","Apoorva Bajaj","Review of Machine Learning Applications in Wireless Communications",,,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  This paper looks at various aspects of Machine Learning (ML) applications in
wireless communication technologies, focusing mainly on fifth-generation (5G)
and millimeter wave (mmWave) technologies. This paper includes the summaries of
3 papers on machine learning applications in wireless communication technology.
The paper deals with the need for integration of machine learning in wireless
communication, types of machine learning techniques used in wireless
communication, advantages and potential of ML in wireless communication, and
implementation parameters of ML in wireless communication, as well as a study
on RSS-Based Classification of usage in indoor millimeter-wave wireless
networks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:36:58 GMT""}]","2021-01-21"
"2101.08120","Xiankui Meng","Xiankui Meng, Xiangyu Zhou","On the restriction formula",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\varphi$ be a quasi-psh function on a complex manifold $X$ and let
$S\subset X$ be a complex submanifold. Then the multiplier ideal sheaves
$\mathcal{I}(\varphi|_S)\subset\mathcal{I}(\varphi)|_{S}$ and the complex
singularity exponents $c_{x}\left(\varphi|_{S}\right)\leqslant c_{x}(\varphi)$
by Ohsawa-Takegoshi $L^{2}$ extension theorem. An interesting question is to
know whether it is possible to get equalities in the above formulas. In the
present article, we show that the answer is positive when $S$ is chosen outside
a measure zero set in a suitable projective space.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:37:24 GMT""}]","2021-01-21"
"2101.08121","S. Dhara SKD","Santanu Parida, Madhusmita Sahoo, Abharana N, Raphael M. Tromer,
  Douglas S. Galvao, Sandip Dhara","Effect of Oxygen and Aluminium Incorporation on Local Structure of GaN
  Nanowires: Insight from Extended X-ray Absorption Fine Structure Analysis","27 pages, 7 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A thorough investigation of local structure, influencing macroscopic
properties of the solid is of potential interest. We investigated the local
structure of GaN nanowires (NWs) with different native defect concentration
synthesized by the chemical vapor deposition technique. Extended X-ray
absorption fine structure (EXAFS) analysis and semi-empirical and the density
functional theory (DFT) calculations were used to address the effect of dopant
incorporation along with other defects on the co-ordination number and bond
length values. The decrease of the bond length values along preferential
crystal axes in the local tetrahedral structure of GaN emphasizes the preferred
lattice site for oxygen doping. The preferential bond length contraction is
corroborated by the simulations. We have also studied the impact on the local
atomic configuration of GaN NWs with Al incorporation. AlxGa1-xN NWs are
synthesized via novel ion beam techniques of ion beam mixing and
post-irradiation diffusion process. The change in the local tetrahedral
structure of GaN with Al incorporation is investigated by EXAFS analysis. The
analysis provides a clear understanding of choosing a suitable process for
ternary III-nitride random alloy formation. The local structure study with the
EXAFS analysis is corroborated with the observed macroscopic properties studied
using Raman spectroscopy.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:38:41 GMT""}]","2021-01-21"
"2101.08122","Devis Tuia","Marrit Leenstra, Diego Marcos, Francesca Bovolo, Devis Tuia","Self-supervised pre-training enhances change detection in Sentinel-2
  imagery","Presented at the Pattern Recognition and Remote Sensing (PRRS)
  workshop in ICPR, 2021","Part of the Lecture Notes in Computer Science book series (LNCS,
  volume 12667), 2021",,,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While annotated images for change detection using satellite imagery are
scarce and costly to obtain, there is a wealth of unlabeled images being
generated every day. In order to leverage these data to learn an image
representation more adequate for change detection, we explore methods that
exploit the temporal consistency of Sentinel-2 times series to obtain a usable
self-supervised learning signal. For this, we build and make publicly available
(https://zenodo.org/record/4280482) the Sentinel-2 Multitemporal Cities Pairs
(S2MTCP) dataset, containing multitemporal image pairs from 1520 urban areas
worldwide. We test the results of multiple self-supervised learning methods for
pre-training models for change detection and apply it on a public change
detection dataset made of Sentinel-2 image pairs (OSCD).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:47:25 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 20:43:10 GMT""}]","2021-04-13"
"2101.08123","Panagiotis Kourtesis P.K.","Panagiotis Kourtesis, Simona Collina, Leonidas A.A. Doumas, and Sarah
  E. MacPherson","Technological Competence is a Precondition for Effective Implementation
  of Virtual Reality Head Mounted Displays in Human Neuroscience: A
  Technological Review and Meta-analysis","Published in Frontiers in Human Neuroscience, 4 Figures, 4 Tables","2019,Frontiers in Human Neuroscience, 13, p.342","10.3389/fnhum.2019.00342",,"cs.HC cs.CY cs.MM","http://creativecommons.org/licenses/by/4.0/","  Immersive virtual reality (VR) emerges as a promising research and clinical
tool. However, several studies suggest that VR induced adverse symptoms and
effects (VRISE) may undermine the health and safety standards, and the
reliability of the scientific results. In the current literature review, the
technical reasons for the adverse symptomatology are investigated to provide
suggestions and technological knowledge for the implementation of VR
head-mounted display (HMD) systems in cognitive neuroscience. The technological
systematic literature indicated features pertinent to display, sound, motion
tracking, navigation, ergonomic interactions, user experience, and computer
hardware that should be considered by the researchers. Subsequently, a
meta-analysis of 44 neuroscientific or neuropsychological studies involving VR
HMD systems was performed. The meta-analysis of the VR studies demonstrated
that new generation HMDs induced significantly less VRISE and marginally fewer
dropouts.Importantly, the commercial versions of the new generation HMDs with
ergonomic interactions had zero incidents of adverse symptomatology and
dropouts. HMDs equivalent to or greater than the commercial versions of
contemporary HMDs accompanied with ergonomic interactions are suitable for
implementation in cognitive neuroscience. In conclusion, researchers
technological competency, along with meticulous methods and reports pertinent
to software, hardware, and VRISE, are paramount to ensure the health and safety
standards and the reliability of neuroscientific results.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:48:11 GMT""}]","2021-01-21"
"2101.08124","Jiang Cao","Jiang Cao and {\DJ}or{\dj}e Dangi\'c and Jos\'e D. Querales-Flores and
  Stephen Fahy and Ivana Savi\'c","Electron-phonon coupling and electronic thermoelectric properties of
  n-type PbTe driven near the soft-mode phase transition via lattice expansion","8 pages, 7 figures","Phys. Rev. B 104, 045202 (2021)","10.1103/PhysRevB.104.045202",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  IV-VI materials are some of the most efficient bulk thermoelectric materials
due to their proximity to soft-mode phase transitions, which leads to low
lattice thermal conductivity. It has been shown that the lattice thermal
conductivity of PbTe can be considerably reduced by bringing PbTe closer to the
phase transition e.g. via lattice expansion. However, the effect of soft phonon
modes on the electronic thermoelectric properties of such system remains
unknown. Using first principles calculations, we show that the soft zone center
transverse optical phonons do not deteriorate the electronic thermoelectric
properties of PbTe driven closer to the phase transition via lattice expansion
due to external stress, and thus enhance the thermoelectric figure of merit. We
find that the optical deformation potentials change very weakly as the
proximity to the phase transition increases, but the population and scattering
phase space of soft phonon modes increase. Nevertheless, scattering between
electronic states near the band edge and soft optical phonons remains
relatively weak even very near the phase transition.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:49:50 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 22:02:29 GMT""}]","2021-07-21"
"2101.08125","Zhi-Wei Fang","Jia-Li Zhang and Zhi-Wei Fang and Hai-Wei Sun","Exponential-sum-approximation technique for variable-order
  time-fractional diffusion equations",,"Journal of Applied Mathematics and Computing,2021",,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the variable-order (VO) time-fractional diffusion
equations. For a VO function $\alpha(t)\in(0,1)$, we develop an
exponential-sum-approximation (ESA) technique to approach the VO Caputo
fractional derivative. The ESA technique keeps both the quadrature exponents
and the number of exponentials in the summation unchanged at the different time
levels. Approximating parameters are properly selected to achieve efficient
accuracy. Compared with the general direct method, the proposed method reduces
the storage requirement from $\mathcal{O}(n)$ to $\mathcal{O}(\log^2 n)$ and
the computational cost from $\mathcal{O}(n^2)$ to $\mathcal{O}(n\log^2 n)$,
respectively, with $n$ being the number of the time levels. When this fast
algorithm is exploited to construct a fast ESA scheme for the VO
time-fractional diffusion equations, the computational complexity of the
proposed scheme is only of $\mathcal{O}(mn\log^2 n)$ with
$\mathcal{O}(m\log^2n)$ storage requirement, where $m$ denotes the number of
spatial grids. Theoretically, the unconditional stability and error analysis of
the fast ESA scheme are given. The effectiveness of the proposed algorithm is
verified by numerical examples.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:50:47 GMT""}]","2021-03-09"
"2101.08126","Vincent Divol","Vincent Divol","A short proof on the rate of convergence of the empirical measure for
  the Wasserstein distance",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We provide a short proof that the Wasserstein distance between the empirical
measure of a n-sample and the estimated measure is of order n^-(1/d), if the
measure has a lower and upper bounded density on the d-dimensional flat torus.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:53:57 GMT""}]","2021-01-21"
"2101.08127","Victor H. Blanco Vihubladu","Victor H. Blanco, Ver\'onica Calder\'on","Effect of undecided agents on an opinion-forming model","9 pages, 8 figures",,,,"physics.soc-ph nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effect of undecided agents is studied within populations in an
opinion-forming dynamic, varying the number of undecided agents for different
proportions of populations in a complete opinion-exchange network. The result
is that the dynamic depends on the number of undecided agents, with 10\% of the
undecided population potentially affecting the change in consensus and then
becoming linear with a negative slope.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:54:07 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 00:18:19 GMT""},{""version"":""v3"",""created"":""Sat, 17 Apr 2021 20:27:49 GMT""},{""version"":""v4"",""created"":""Thu, 20 May 2021 15:34:16 GMT""},{""version"":""v5"",""created"":""Tue, 22 Jun 2021 01:48:19 GMT""}]","2021-06-23"
"2101.08128","Robert Ehrlich","R. Ehrlich","5 Reasons to expect an 8 MeV line in the SN 1987A neutrino spectrum",,,,,"astro-ph.HE astro-ph.SR hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Evidence was previously reported for an 8 MeV neutrino line associated with
SN 1987A based on an analysis of 997 events recorded in the Kamiokande-II
detector on the day of the supernova. That claimed line, however, occurred at
the peak of the background spectrum, and both had a similar shape, making the
claim tenuous at best. Here the claim is buttressed by providing five reasons
to expect such an 8 MeV neutrino line. A final section of the paper concerns
the ongoing KATRIN experiment to find the neutrino mass, which might provide
additional support for the line, should it validate a controversial 3 + 3 model
of the neutrino masses, including a tachyonic (m2 < 0) mass.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:36:40 GMT""},{""version"":""v10"",""created"":""Mon, 9 Aug 2021 22:59:53 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 12:22:15 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jan 2021 21:45:51 GMT""},{""version"":""v4"",""created"":""Thu, 4 Feb 2021 15:11:09 GMT""},{""version"":""v5"",""created"":""Mon, 8 Feb 2021 18:19:56 GMT""},{""version"":""v6"",""created"":""Sun, 14 Feb 2021 22:38:41 GMT""},{""version"":""v7"",""created"":""Tue, 23 Feb 2021 11:37:43 GMT""},{""version"":""v8"",""created"":""Fri, 5 Mar 2021 11:42:17 GMT""},{""version"":""v9"",""created"":""Mon, 2 Aug 2021 16:58:36 GMT""}]","2021-08-11"
"2101.08129","Mohammad Shehab","Mohammad Shehab, Hirley Alves, Eduard A. Jorswieck, Endrit Dosti, and
  Matti Latva-aho","Effective Energy Efficiency of Ultra-reliable Low Latency Communication",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective Capacity defines the maximum communication rate subject to a
specific delay constraint, while effective energy efficiency (EEE) indicates
the ratio between effective capacity and power consumption. We analyze the EEE
of ultra-reliable networks operating in the finite blocklength regime. We
obtain a closed form approximation for the EEE in quasi-static Nakagami-$m$
(and Rayleigh as sub-case) fading channels as a function of power, error
probability, and latency. Furthermore, we characterize the QoS constrained EEE
maximization problem for different power consumption models, which shows a
significant difference between finite and infinite blocklength coding with
respect to EEE and optimal power allocation strategy. As asserted in the
literature, achieving ultra-reliability using one transmission consumes huge
amount of power, which is not applicable for energy limited IoT devices. In
this context, accounting for empty buffer probability in machine type
communication (MTC) and extending the maximum delay tolerance jointly enhances
the EEE and allows for adaptive retransmission of faulty packets. Our analysis
reveals that obtaining the optimum error probability for each transmission by
minimizing the non-empty buffer probability approaches EEE optimality, while
being analytically tractable via Dinkelbach's algorithm. Furthermore, the
results illustrate the power saving and the significant EEE gain attained by
applying adaptive retransmission protocols, while sacrificing a limited
increase in latency.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:55:26 GMT""}]","2021-01-21"
"2101.08130","Alexander Stroh","Matthias Schniewind, Alexander Stroh, Bradley P. Ladewig, Pascal
  Friederich","Machine learning for rapid discovery of laminar flow channel wall
  modifications that enhance heat transfer",,,,,"physics.flu-dyn cs.LG","http://creativecommons.org/licenses/by/4.0/","  The calculation of heat transfer in fluid flow in simple flat channels is a
relatively easy task for various simulations methods. However, once the channel
geometry becomes more complex, numerical simulations become a bottleneck in
optimizing wall geometries. We present a combination of accurate numerical
simulations of arbitrary, non-flat channels and machine learning models
predicting drag coefficient and Stanton number. We show that convolutional
neural networks can accurately predict the target properties at a fraction of
the time of numerical simulations. We use the CNN models in a virtual
high-throughput screening approach to explore a large number of possible,
randomly generated wall architectures. We find that S-shaped channel geometries
are Pareto-optimal, a result which seems intuitive, but was not obvious before
analysing the data. The general approach is not only applicable to simple flow
setups as presented here, but can be extended to more complex tasks, such as
multiphase or even reactive unit operations in chemical engineering.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:14:02 GMT""}]","2021-01-21"
"2101.08132","Chris Mitchell","Chris J Mitchell","The (in)security of some recently proposed lightweight key distribution
  schemes","This version adds a brief critique of a related paper on secure
  multiparty computation",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two recently published papers propose some very simple key distribution
schemes designed to enable two or more parties to establish a shared secret key
with the aid of a third party. Unfortunately, as we show, most of the schemes
are inherently insecure and all are incompletely specified - moreover, claims
that the schemes are inherently lightweight are shown to be highly misleading.
We also briefly critique a somewhat related very recent paper by the same
authors that uses similar techniques to achieve what are claimed to be secure
multiparty computations.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:57:48 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jan 2021 16:55:05 GMT""},{""version"":""v3"",""created"":""Sat, 13 Mar 2021 12:21:58 GMT""}]","2021-03-16"
"2101.08133","Artem Shelmanov","Artem Shelmanov, Dmitri Puzyrev, Lyubov Kupriyanova, Denis Belyakov,
  Daniil Larionov, Nikita Khromov, Olga Kozlova, Ekaterina Artemova, Dmitry V.
  Dylov, and Alexander Panchenko","Active Learning for Sequence Tagging with Deep Pre-trained Models and
  Bayesian Uncertainty Estimates","In Proceedings of the 16th Conference of the European Chapter of the
  Association for Computational Linguistics (EACL-2021)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Annotating training data for sequence tagging of texts is usually very
time-consuming. Recent advances in transfer learning for natural language
processing in conjunction with active learning open the possibility to
significantly reduce the necessary annotation budget. We are the first to
thoroughly investigate this powerful combination for the sequence tagging task.
We conduct an extensive empirical study of various Bayesian uncertainty
estimation methods and Monte Carlo dropout options for deep pre-trained models
in the active learning framework and find the best combinations for different
types of models. Besides, we also demonstrate that to acquire instances during
active learning, a full-size Transformer can be substituted with a distilled
version, which yields better computational performance and reduces obstacles
for applying deep active learning in practice.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:59:25 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 15:50:11 GMT""}]","2021-02-19"
"2101.08134","Mohamed Abdelfattah","Mohamed S. Abdelfattah, Abhinav Mehrotra, {\L}ukasz Dudziak, Nicholas
  D. Lane","Zero-Cost Proxies for Lightweight NAS","ICLR 2021",,,,"cs.LG cs.AI cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Neural Architecture Search (NAS) is quickly becoming the standard methodology
to design neural network models. However, NAS is typically compute-intensive
because multiple models need to be evaluated before choosing the best one. To
reduce the computational power and time needed, a proxy task is often used for
evaluating each model instead of full training. In this paper, we evaluate
conventional reduced-training proxies and quantify how well they preserve
ranking between multiple models during search when compared with the rankings
produced by final trained accuracy. We propose a series of zero-cost proxies,
based on recent pruning literature, that use just a single minibatch of
training data to compute a model's score. Our zero-cost proxies use 3 orders of
magnitude less computation but can match and even outperform conventional
proxies. For example, Spearman's rank correlation coefficient between final
validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82,
compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy).
Finally, we use these zero-cost proxies to enhance existing NAS search
algorithms such as random search, reinforcement learning, evolutionary search
and predictor-based search. For all search methodologies and across three
different NAS datasets, we are able to significantly improve sample efficiency,
and thereby decrease computation, by using our zero-cost proxies. For example
on NAS-Bench-101, we achieved the same accuracy 4$\times$ quicker than the best
previous result. Our code is made public at:
https://github.com/mohsaied/zero-cost-nas.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:59:52 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 10:43:12 GMT""}]","2021-03-22"
"2101.08135","Eduardo Sanz","I. Sanchez-Burgos, P. Montero de Hijes, P. Rosales-Pelaez, C. Vega, E.
  Sanz","Equivalence between condensation and boiling in a Lennard Jones fluid","10 figures, 110 references","Physical Review E, 102, 062609, 2020","10.1103/PhysRevE.102.062609",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Condensation and boiling are phase transitions highly relevant to industry,
geology or atmospheric science. These phase transitions are initiated by the
nucleation of a drop in a supersaturated vapor and of a bubble in an
overstretched liquid respectively. The surface tension between both phases,
liquid and vapor, is a key parameter in the development of such nucleation
stage. Whereas the surface tension can be readily measured for a flat
interface, there are technical and conceptual limitations to obtain it for the
curved interface of the nucleus. On the technical side, it is quite difficult
to observe a critical nucleus in experiments. From a conceptual point of view,
the interfacial free energy depends on the choice of the dividing surface,
being the surface of tension the one relevant for nucleation. We bypass the
technical limitation by performing simulations of a Lennard Jones fluid where
we equilibrate critical nuclei (both drops and bubbles). Regarding the
conceptual hurdle, we find the relevant cluster size by searching the radius
that correctly predicts nucleation rates and nucleation free energy barriers
when combined with Classical Nucleation Theory. With such definition of the
cluster size we find the same value of the surface tension for drops and
bubbles of a given radius. Thus, condensation and boiling can be viewed as two
sides of the same coin. Finally, we combine the data coming from drops and
bubbles to obtain, via two different routes, estimates of the Tolman length, a
parameter that allows describing the curvature dependence of the surface
tension in a theoretical framework.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:02:23 GMT""}]","2021-01-21"
"2101.08140","Mustafa Senay","Mustafa Senay","The effects of q-statistics on cosmology","5 pages",,"10.1016/j.physletb.2021.136536",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Considering Verlinde's entropic gravity proposal, we focus the effects of
fermionic $q$ deformation on the Einstein's field equations and Friedmann
equations. For this purpose, we represent the thermodynamical properties of the
deformed fermion gas model in two-dimensional space. To describe the behavior
of the quantum black holes, deformed Einstein field equations are derived with
the help of deformed entropy function. Moreover, deformed Friedmann equations
are investigated by using Friedmann-Robertson-Walker (FRW) metric. We also
present the effective ones of the energy density, the pressure, and the
equation of state for the dark energy. Lastly, we derive an analytical
expression of the effective density parameter of dark energy.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:14:34 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 18:31:28 GMT""},{""version"":""v3"",""created"":""Sun, 4 Apr 2021 15:56:15 GMT""}]","2021-07-28"
"2101.08141","Srinivasan Arunachalam","Srinivasan Arunachalam and Penghui Yao","Positive spectrahedra: Invariance principles and Pseudorandom generators","63 pages. v2: Minor revisions and Improvements in presentation",,,,"cs.CC math.CO","http://creativecommons.org/licenses/by/4.0/","  In a recent work, O'Donnell, Servedio and Tan (STOC 2019) gave explicit
pseudorandom generators (PRGs) for arbitrary $m$-facet polytopes in $n$
variables with seed length poly-logarithmic in $m,n$, concluding a sequence of
works in the last decade, that was started by Diakonikolas, Gopalan, Jaiswal,
Servedio, Viola (SICOMP 2010) and Meka, Zuckerman (SICOMP 2013) for fooling
linear and polynomial threshold functions, respectively. In this work, we
consider a natural extension of PRGs for intersections of positive
spectrahedrons. A positive spectrahedron is a Boolean function
$f(x)=[x_1A^1+\cdots +x_nA^n \preceq B]$ where the $A^i$s are $k\times k$
positive semidefinite matrices. We construct explicit PRGs that $\delta$-fool
""regular"" width-$M$ positive spectrahedrons (i.e., when none of the $A^i$s are
dominant) over the Boolean space with seed length $\textsf{poly}(\log k,\log n,
M, 1/\delta)$.
  Our main technical contributions are the following: We first prove an
invariance principle for positive spectrahedra via the well-known Lindeberg
method. As far as we are aware such a generalization of the Lindeberg method
was unknown. Second, we prove an upper bound on noise sensitivity and a
Littlewood-Offord theorem for positive spectrahedra. Using these results, we
give applications for constructing PRGs for positive spectrahedra, learning
theory, discrepancy sets for positive spectrahedra (over the Boolean cube) and
PRGs for intersections of structured polynomial threshold functions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:05:49 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 19:56:24 GMT""}]","2021-06-03"
"2101.08143","Wanyue Xu","Wanyue Xu, Qi Bao, Zhongzhi Zhang","Fast Evaluation for Relevant Quantities of Opinion Dynamics",,"Proceedings of The Web Conference 2021, pp.2037-2045","10.1145/3442381.3449812",,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the main subjects in the field of social networks is to quantify
conflict, disagreement, controversy, and polarization, and some quantitative
indicators have been developed to quantify these concepts. However, direct
computation of these indicators involves the operations of matrix inversion and
multiplication, which make it computationally infeasible for large-scale graphs
with millions of nodes. In this paper, by reducing the problem of computing
relevant quantities to evaluating $\ell_2$ norms of some vectors, we present a
nearly linear time algorithm to estimate all these quantities. Our algorithm is
based on the Laplacian solvers, and has a proved theoretical guarantee of error
for each quantity. We execute extensive numerical experiments on a variety of
real networks, which demonstrate that our approximation algorithm is efficient
and effective, scalable to large graphs having millions of nodes.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:07:38 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 15:19:51 GMT""}]","2021-06-15"
"2101.08144","Irina Afanasieva","V.I. Ardilanov and V.A. Murzin and I.V. Afanasieva and N.G. Ivaschenko
  and M.A. Pritychenko","Development of Large-Format Camera Systems Based on the Latest
  Generation Sensors for the 6-m Telescope","To be published in: I.I. Romanyuk, I.A. Yakunin, A.F. Valeev, and
  D.O. Kudryavtsev (eds), Ground-Based Astronomy in Russia. 21st Century,
  Proceedings of the All-Russian Conference, ISBN: 978-5-6045062-0-2",,"10.26119/978-5-6045062-0-2_2020_115",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The design and implementation of astronomical cameras based on the
large-format CCD and CMOS detectors is described in this paper. The Dinacon-5
controller is used for work with the CCDs and to achieve high performance and
low noise. A new controller is designed for CMOS sensors. The main
characteristics of the provided systems are estimated on the basis of
experimental data. The spatial autocorrelation analysis is applied for PSF
estimation. The obtained test results are presented.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:08:47 GMT""}]","2021-01-21"
"2101.08145","Antoine Jacquier Dr.","Vimal Raval and Antoine Jacquier","The Log Moment formula for implied volatility","12 pages",,,,"q-fin.PR math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the foundational Moment Formula proved by Roger Lee fifteen years
ago. We show that when the underlying stock price martingale admits finite
log-moments E[|log(S)|^q] for some positive q, the arbitrage-free growth in the
left wing of the implied volatility smile is less constrained than Lee's bound.
The result is rationalised by a market trading discretely monitored variance
swaps wherein the payoff is a function of squared log-returns, and requires no
assumption for the underlying martingale to admit any negative moment. In this
respect, the result can derived from a model-independent setup. As a byproduct,
we relax the moment assumptions on the stock price to provide a new proof of
the notorious Gatheral-Fukasawa formula expressing variance swaps in terms of
the implied volatility.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:10:02 GMT""}]","2021-01-21"
"2101.08146","Panagiotis Kourtesis P.K.","Panagiotis Kourtesis, Simona Collina, Leonidas A.A. Doumas, and Sarah
  E. MacPherson","Validation of the Virtual Reality Neuroscience Questionnaire: Maximum
  Duration of Immersive Virtual Reality Sessions Without the Presence of
  Pertinent Adverse Symptomatology","Published in Frontier in Human Neuroscience","2019.Frontiers in human neuroscience, 13, p.417","10.3389/fnhum.2019.00417",,"cs.HC cs.CY cs.MM","http://creativecommons.org/licenses/by/4.0/","  Research suggests that the duration of a VR session modulates the presence
and intensity of VRISE, but there are no suggestions regarding the appropriate
maximum duration of VR sessions. The implementation of high-end VR HMDs in
conjunction with ergonomic VR software seems to mitigate the presence of VRISE
substantially. However, a brief tool does not currently exist to appraise and
report both the quality of software features and VRISE intensity
quantitatively. The VRNQ was developed to assess the quality of VR software in
terms of user experience, game mechanics, in-game assistance, and VRISE. Forty
participants aged between 28 and 43 years were recruited (18 gamers and 22
non-gamers) for the study. They participated in 3 different VR sessions until
they felt weary or discomfort and subsequently filled in the VRNQ. Our results
demonstrated that VRNQ is a valid tool for assessing VR software as it has good
convergent, discriminant, and construct validity. The maximum duration of VR
sessions should be between 55-70 minutes when the VR software meets or exceeds
the parsimonious cut-offs of the VRNQ and the users are familiarized with the
VR system. Also. the gaming experience does not seem to affect how long VR
sessions should last. Also, while the quality of VR software substantially
modulates the maximum duration of VR sessions, age and education do not.
Finally, deeper immersion, better quality of graphics and sound, and more
helpful in-game instructions and prompts were found to reduce VRISE intensity.
The VRNQ facilitates the brief assessment and reporting of the quality of VR
software features and/or the intensity of VRISE, while its minimum and
parsimonious cut-offs may appraise the suitability of VR software. The findings
of this study contribute to the establishment of rigorous VR methods that are
crucial for the viability of immersive VR as a research and clinical tool.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:10:44 GMT""}]","2021-01-21"
"2101.08147","Barry Mant","Barry Mant, Ersin Yurtsever, Lola Gonz\'alez-S\'anchez, Roland Wester
  and Franco A. Gianturco","Vibrational Quenching of CN- in Collisions with He and Ar","arXiv admin note: substantial text overlap with arXiv:2010.14288",,"10.1063/5.0039854",,"physics.atom-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The vibrational quenching cross sections and corresponding low-temperature
rate constants for the v = 1 and v = 2 states of CN- colliding with He and Ar
atoms have been computed ab initio using new three dimensional potential energy
surfaces. Little work has so far been carried out on low-energy vibrationally
inelastic collisions for anions with neutral atoms. The cross sections and
rates calculated at energies and temperatures relevant for both ion traps and
astrochemical modelling, are found by the present calculations to be even
smaller than those of the similar C2- /He and C2-/Ar systems which are in turn
of the order of those existing for the collisions involving neutral diatom-atom
systems. The implications of our finding in the present case rather small
computed rate constants are discussed for their possible role in the dynamics
of molecular cooling and in the evolution of astrochemical modelling networks.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:11:36 GMT""}]","2021-03-17"
"2101.08148","Kazuya Fujimoto","Kazuya Fujimoto, Ryusuke Hamazaki, Yuki Kawaguchi","Dynamical Scaling of Surface Roughness and Entanglement Entropy in
  Disordered Fermion Models","27 pages, 15 figures","Phys. Rev. Lett. 127, 090601 (2021)","10.1103/PhysRevLett.127.090601",,"cond-mat.quant-gas cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Localization is one of the most fundamental interference phenomena caused by
randomness, and its universal aspects have been extensively explored from the
perspective of one-parameter scaling mainly for static properties. We
numerically study dynamics of fermions on disordered onedimensional potentials
exhibiting localization and find dynamical one-parameter scaling for surface
roughness, which represents particle-number fluctuations at a given
lengthscale, and for entanglement entropy when the system is in delocalized
phases. This dynamical scaling corresponds to the Family-Vicsek scaling
originally developed in classical surface growth, and the associated scaling
exponents depend on the type of disorder. Notably, we find that partially
localized states in the delocalized phase of the random-dimer model lead to
anomalous scaling, where destructive interference unique to quantum systems
leads to exponents unknown for classical systems and clean systems.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:13:20 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 14:34:49 GMT""}]","2021-09-01"
"2101.08149","Anna Chiara Lai","Simone Cacace, Anna Chiara Lai, and Paola Loreti","Constrained reachability problems for a planar manipulator",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address an optimal reachability problem for a planar manipulator in a
constrained environment. After introducing the optmization problem in full
generality, we practically embed the geometry of the workspace in the problem,
by considering some classes of obstacles. To this end, we present an analytical
approximation of the distance function from the ellipse. We then apply our
method to particular models of hyper-redundant and soft manipulators, by also
presenting some numerical experiments.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:16:27 GMT""}]","2021-01-21"
"2101.08150","Coralie Neub\""user","Coralie Neub\""user, Jan Kieseler, Paul Lujan","Optimising longitudinal and lateral calorimeter granularity for software
  compensation in hadronic showers using deep neural networks",,,"10.1140/epjc/s10052-022-10031-7",,"physics.ins-det","http://creativecommons.org/publicdomain/zero/1.0/","  We investigate the effect of longitudinal and transverse calorimeter
segmentation on event-by-event software compensation for hadronic showers. To
factorize out sampling and electronics effects, events are simulated in which a
single charged pion is shot at a homogenous lead glass calorimeter, split into
longitudinal and transverse segments of varying size. As an approximation of an
optimal reconstruction, a neural network-based energy regression is trained.
The architecture is based on blocks of convolutional kernels customized for
shower energy regression using local energy densities; biases at the edges of
the training dataset are mitigated using a histogram technique. With this
approximation, we find that a longitudinal and transverse segment size less
than or equal to 0.5 and 1.3 nuclear interaction lengths, respectively, is
necessary to achieve an optimal energy measurement. In addition, an intrinsic
energy resolution of $8\%/\sqrt{E}$ for pion showers is observed.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:17:28 GMT""}]","2022-02-01"
"2101.08151","Thien Nguyen","Thien Nguyen, Lindsay Bassman, Dmitry Lyakh, Alexander McCaskey,
  Vicente Leyton-Ortega, Raphael Pooser, Wael Elwasif, Travis S. Humble, and
  Wibe A. de Jong","Composable Programming of Hybrid Workflows for Quantum Simulation",,,"10.1109/ICSA-C52384.2021.00028",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a composable design scheme for the development of hybrid
quantum/classical algorithms and workflows for applications of quantum
simulation. Our object-oriented approach is based on constructing an expressive
set of common data structures and methods that enable programming of a broad
variety of complex hybrid quantum simulation applications. The abstract core of
our scheme is distilled from the analysis of the current quantum simulation
algorithms. Subsequently, it allows a synthesis of new hybrid algorithms and
workflows via the extension, specialization, and dynamic customization of the
abstract core classes defined by our design. We implement our design scheme
using the hardware-agnostic programming language QCOR into the QuaSiMo library.
To validate our implementation, we test and show its utility on commercial
quantum processors from IBM, running some prototypical quantum simulations.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:20:14 GMT""}]","2022-01-07"
"2101.08152","Daochen Zha","Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu","Rank the Episodes: A Simple Approach for Exploration in
  Procedurally-Generated Environments","Accepted by ICLR 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exploration under sparse reward is a long-standing challenge of model-free
reinforcement learning. The state-of-the-art methods address this challenge by
introducing intrinsic rewards to encourage exploration in novel states or
uncertain environment dynamics. Unfortunately, methods based on intrinsic
rewards often fall short in procedurally-generated environments, where a
different environment is generated in each episode so that the agent is not
likely to visit the same state more than once. Motivated by how humans
distinguish good exploration behaviors by looking into the entire episode, we
introduce RAPID, a simple yet effective episode-level exploration method for
procedurally-generated environments. RAPID regards each episode as a whole and
gives an episodic exploration score from both per-episode and long-term views.
Those highly scored episodes are treated as good exploration behaviors and are
stored in a small ranking buffer. The agent then imitates the episodes in the
buffer to reproduce the past good exploration behaviors. We demonstrate our
method on several procedurally-generated MiniGrid environments, a
first-person-view 3D Maze navigation task from MiniWorld, and several sparse
MuJoCo tasks. The results show that RAPID significantly outperforms the
state-of-the-art intrinsic reward strategies in terms of sample efficiency and
final performance. The code is available at https://github.com/daochenzha/rapid
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:22:01 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 15:48:12 GMT""}]","2021-02-05"
"2101.08153","Daniel Kroening","Mirco Giacobbe, Mohammadhosein Hasanbeig, Daniel Kroening, Hjalmar
  Wijk","Shielding Atari Games with Bounded Prescience","To appear at AAMAS 2021",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep reinforcement learning (DRL) is applied in safety-critical domains such
as robotics and autonomous driving. It achieves superhuman abilities in many
tasks, however whether DRL agents can be shown to act safely is an open
problem. Atari games are a simple yet challenging exemplar for evaluating the
safety of DRL agents and feature a diverse portfolio of game mechanics. The
safety of neural agents has been studied before using methods that either
require a model of the system dynamics or an abstraction; unfortunately, these
are unsuitable to Atari games because their low-level dynamics are complex and
hidden inside their emulator. We present the first exact method for analysing
and ensuring the safety of DRL agents for Atari games. Our method only requires
access to the emulator. First, we give a set of 43 properties that characterise
""safe behaviour"" for 30 games. Second, we develop a method for exploring all
traces induced by an agent and a game and consider a variety of sources of game
non-determinism. We observe that the best available DRL agents reliably satisfy
only very few properties; several critical properties are violated by all
agents. Finally, we propose a countermeasure that combines a bounded
explicit-state exploration with shielding. We demonstrate that our method
improves the safety of all agents over multiple properties.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:22:04 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 14:08:01 GMT""}]","2021-01-25"
"2101.08154","Xiaopei Zhu","Xiaopei Zhu, Xiao Li, Jianmin Li, Zheyao Wang, Xiaolin Hu","Fooling thermal infrared pedestrian detectors in real world using small
  bulbs","Documents officially published by AAAI 2021, including the main text
  and supplementary material",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal infrared detection systems play an important role in many areas such
as night security, autonomous driving, and body temperature detection. They
have the unique advantages of passive imaging, temperature sensitivity and
penetration. But the security of these systems themselves has not been fully
explored, which poses risks in applying these systems. We propose a physical
attack method with small bulbs on a board against the state of-the-art
pedestrian detectors. Our goal is to make infrared pedestrian detectors unable
to detect real-world pedestrians. Towards this goal, we first showed that it is
possible to use two kinds of patches to attack the infrared pedestrian detector
based on YOLOv3. The average precision (AP) dropped by 64.12% in the digital
world, while a blank board with the same size caused the AP to drop by 29.69%
only. After that, we designed and manufactured a physical board and
successfully attacked YOLOv3 in the real world. In recorded videos, the
physical board caused AP of the target detector to drop by 34.48%, while a
blank board with the same size caused the AP to drop by 14.91% only. With the
ensemble attack techniques, the designed physical board had good
transferability to unseen detectors. We also proposed the first physical
multispectral (infrared and visible) attack. By using a combination method, we
successfully hide from the visible light and infrared object detection systems
at the same time.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:26:09 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 09:39:53 GMT""}]","2023-05-30"
"2101.08155","Markus Wallinger","Markus Wallinger, Ben Jacobsen, Stephen Kobourov and Martin
  N\""ollenburg","On the Readability of Abstract Set Visualizations","in IEEE Transactions on Visualization and Computer Graphics (2021).
  Supplementary material can be found on https://osf.io/nvd8e/",,"10.1109/TVCG.2021.3074615",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Set systems are used to model data that naturally arises in many contexts:
social networks have communities, musicians have genres, and patients have
symptoms. Visualizations that accurately reflect the information in the
underlying set system make it possible to identify the set elements, the sets
themselves, and the relationships between the sets. In static contexts, such as
print media or infographics, it is necessary to capture this information
without the help of interactions. With this in mind, we consider three
different systems for medium-sized set data, LineSets, EulerView, and
MetroSets, and report the results of a controlled human-subjects experiment
comparing their effectiveness. Specifically, we evaluate the performance, in
terms of time and error, on tasks that cover the spectrum of static set-based
tasks. We also collect and analyze qualitative data about the three different
visualization systems. Our results include statistically significant
differences, suggesting that MetroSets performs and scales better.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:26:15 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 13:50:25 GMT""}]","2022-02-17"
"2101.08156","Yuki Fujimoto","Yuki Fujimoto, Kenji Fukushima, Koichi Murase","Extensive Studies of the Neutron Star Equation of State from the Deep
  Learning Inference with the Observational Data Augmentation","45 pages, 25 figures","JHEP 03 (2021) 273","10.1007/JHEP03(2021)273",,"nucl-th astro-ph.HE astro-ph.IM cs.LG hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss deep learning inference for the neutron star equation of state
(EoS) using the real observational data of the mass and the radius. We make a
quantitative comparison between the conventional polynomial regression and the
neural network approach for the EoS parametrization. For our deep learning
method to incorporate uncertainties in observation, we augment the training
data with noise fluctuations corresponding to observational uncertainties.
Deduced EoSs can accommodate a weak first-order phase transition, and we make a
histogram for likely first-order regions. We also find that our observational
data augmentation has a byproduct to tame the overfitting behavior. To check
the performance improved by the data augmentation, we set up a toy model as the
simplest inference problem to recover a double-peaked function and monitor the
validation loss. We conclude that the data augmentation could be a useful
technique to evade the overfitting without tuning the neural network
architecture such as inserting the dropout.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:27:12 GMT""}]","2021-06-14"
"2101.08157","Thorsten Hesjedal","L. Gladczuk, L. Gladczuk, P. Dluzewski, K. Lasek, P. Aleshkevych, D.
  M. Burn, G. van der Laan, T. Hesjedal","Spin-current mediated exchange coupling in MgO-based magnetic tunnel
  junctions","11 pages, 7 figures","Phys. Rev. B 103, 064416 (2021)","10.1103/PhysRevB.103.064416",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Heterostructures composed of ferromagnetic layers that are mutually
interacting through a nonmagnetic spacer are at the core of magnetic sensor and
memory devices. In the present study, layer-resolved ferromagnetic resonance
was used to investigate the coupling between the magnetic layers of a
Co/MgO/Permalloy magnetic tunnel junction. Two magnetic resonance peaks were
observed for both magnetic layers, as probed at the Co and Ni L3 x-ray
absorption edges, showing a strong interlayer interaction through the
insulating MgO barrier. A theoretical model based on the
Landau-Lifshitz-Gilbert-Slonczewski equation was developed, including exchange
coupling and spin pumping between the magnetic layers. Fits to the experimental
data were carried out, both with and without a spin pumping term, and the
goodness of the fit was compared using a likelihood ratio test. This rigorous
statistical approach provides an unambiguous proof of the existence of
interlayer coupling mediated by spin pumping.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:33:53 GMT""}]","2021-02-17"
"2101.08158","Yifan Zhang","Yi-Fan Zhang, Weiqiang Ren, Zhang Zhang, Zhen Jia, Liang Wang, Tieniu
  Tan","Focal and Efficient IOU Loss for Accurate Bounding Box Regression",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In object detection, bounding box regression (BBR) is a crucial step that
determines the object localization performance. However, we find that most
previous loss functions for BBR have two main drawbacks: (i) Both $\ell_n$-norm
and IOU-based loss functions are inefficient to depict the objective of BBR,
which leads to slow convergence and inaccurate regression results. (ii) Most of
the loss functions ignore the imbalance problem in BBR that the large number of
anchor boxes which have small overlaps with the target boxes contribute most to
the optimization of BBR. To mitigate the adverse effects caused thereby, we
perform thorough studies to exploit the potential of BBR losses in this paper.
Firstly, an Efficient Intersection over Union (EIOU) loss is proposed, which
explicitly measures the discrepancies of three geometric factors in BBR, i.e.,
the overlap area, the central point and the side length. After that, we state
the Effective Example Mining (EEM) problem and propose a regression version of
focal loss to make the regression process focus on high-quality anchor boxes.
Finally, the above two parts are combined to obtain a new loss function, namely
Focal-EIOU loss. Extensive experiments on both synthetic and real datasets are
performed. Notable superiorities on both the convergence speed and the
localization accuracy can be achieved over other BBR losses.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:33:58 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 02:43:52 GMT""}]","2022-07-19"
"2101.08159","Egwe Murphy E.","N. O. Okeke and M. E. Egwe","Cohomogeneity One Groupoid Analysis of the Dynamical System of Rings of
  Continuous Functions","31 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the group $G(1)$ of invertible elements and the maximal ideals
$\mathfrak{m}_x$ of the commutative algebra $C(X)$ of real-valued functions on
a compact regular space $X$, we define a Borel action of the algebra on the
measure space $(X,\mu)$ with $\mu$ a Radon measure. The zero sets $Z(X)$ of the
algebra $C(X)$ is used to study the ergodicity of the $G(1)$-action via its
action on the maximal ideals $\mathfrak{m}_x$ which defines an action groupoid
$\mathcal{G} = \mathfrak{m}_x \ltimes G(1)$ trivialized on $X$. The resulting
measure groupoid $(\mathcal{G},\mathcal{C})$ is used to define a proper action
on the generalized space $\mathcal{M}(X)$. The existence of slice at each point
of $\mathcal{M}(X)$ present it as a cohomogeneity-one $\mathcal{G}$-space. The
dynamical system of the algebra $C(X)$ is defined by the action of the measure
groupoid $(\mathcal{G},\mathcal{C}) \times \mathcal{M}(X) \to \mathcal{M}(X)$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:34:25 GMT""}]","2021-01-21"
"2101.08160","Mirko Leomanni","Mirko Leomanni, Gianni Bianchini, Andrea Garulli, Renato Quartullo","Optimal Low-Thrust Orbit Transfers Made Easy: A Direct Approach",,"Journal of Spacecraft and Rockets, 2021","10.2514/1.A34949",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optimization of low-thrust, multi-revolution orbit transfer trajectories
is often regarded as a difficult problem in modern astrodynamics. In this
paper, a flexible and computationally efficient approach is presented for the
optimization of low-thrust orbit transfers under eclipse constraints. The
proposed approach leverages a new dynamic model of the orbital motion and a
Lyapunov-based initial guess generation scheme that is very easy to tune. A
multi-objective, single-phase formulation of the optimal control problem is
devised, which provides a convenient way to trade off fuel consumption and time
of flight. A distinctive feature of such a formulation is that it requires no
prior information about the structure of the optimal solution. Simulation
results for two benchmark orbit transfer scenarios indicate that minimum-time,
minimum-fuel and mixed time/fuel-optimal instances of the control problem can
be readily solved via direct collocation, while incurring a significantly lower
computational demand with respect to existing techniques.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:34:59 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 09:19:06 GMT""}]","2021-07-20"
"2101.08162","Steven Miller","George Clark, Alex Gonye and Steven J Miller","Lessons from the German Tank Problem","Version 2.1, 17 pages, 9 figures, to appear in the Mathematical
  Intelligencer, fixed two typos",,,,"stat.OT math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  During World War II the German army used tanks to devastating advantage. The
Allies needed accurate estimates of their tank production and deployment. They
used two approaches to find these values: spies, and statistics. This note
describes the statistical approach. Assuming the tanks are labeled
consecutively starting at 1, if we observe $k$ serial numbers from an unknown
number $N$ of tanks, with the maximum observed value $m$, then the best
estimate for $N$ is $m(1 + 1/k) - 1$. This is now known as the German Tank
Problem, and is a terrific example of the applicability of mathematics and
statistics in the real world. The first part of the paper reproduces known
results, specifically deriving this estimate and comparing its effectiveness to
that of the spies. The second part presents a result we have not found in print
elsewhere, the generalization to the case where the smallest value is not
necessarily 1. We emphasize in detail why we are able to obtain such clean,
closed-form expressions for the estimates, and conclude with an appendix
highlighting how to use this problem to teach regression and how statistics can
help us find functional relationships.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:52:02 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 11:50:37 GMT""}]","2021-01-22"
"2101.08163","Norbert Hungerb\""uhler","Lorenz Halbeisen, Norbert Hungerb\""uhler","Pairing Pythagorean Pairs","11 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A pair $(a, b)$ of positive integers is a pythagorean pair if $a^2 + b^2 =
\Box$ (i.e., $a^2 + b^2$ is a square). A pythagorean pair $(a, b)$ is called a
double-pythapotent pair if there is another pythagorean pair $(k,l)$ such that
$(ak,bl)$ is a pythagorean pair, and it is called a quadratic pythapotent pair
if there is another pythagorean pair $(k,l)$ which is not a multiple of
$(a,b)$, such that $(a^2k,b^2l)$ is a pythagorean pair. To each pythagorean
pair $(a, b)$ we assign an elliptic curve $\Gamma_{a,b}$ with torsion group
$\mathbb Z/2\mathbb Z\times\mathbb Z/4\mathbb Z$, such that $\Gamma_{a,b}$ has
positive rank if and only if $(a, b)$ is a double-pythapotent pair. Similarly,
to each pythagorean pair $(a, b)$ we assign an elliptic curve $\Gamma_{a^2
,b^2}$ with torsion group $\mathbb Z/2\mathbb Z\times\mathbb Z/8\mathbb Z$,
such that $\Gamma_{a^2,b^2}$ has positive rank if and only if $(a,b)$ is a
quadratic pythapotent pair. Moreover, in the later case we obtain that every
elliptic curve $\Gamma$ with torsion group $\mathbb Z/2\mathbb Z\times\mathbb
Z/8\mathbb Z$ is isomorphic to a curve of the form $\Gamma_{a^2 ,b^2}$ , where
$(a,b)$ is a pythagorean pair. As a side-result we get that if $(a,b)$ is a
double-pythapotent pair, then there are infinitely many pythagorean pairs $(k,
l)$, not multiples of each other, such that $(ak, bl)$ is a pythagorean pair;
the analogous result holds for quadratic pythapotent pairs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:42:17 GMT""}]","2021-01-21"
"2101.08164","Prabir Mitra","Prabir K. Mitra (USO/PRL), Bhuwan Joshi (USO/PRL)","Successive occurrences of quasi-circular ribbon flares in a
  fan-spine-like configuration involving hyperbolic flux tube","20 pages, 11 figures, 3 tables; accepted for publication in Monthly
  Notices of the Royal Astronomical Society",,"10.1093/mnras/stab175",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a comprehensive analysis of the formation and evolution of a
fan-spine-like configuration that developed over a complex photospheric
configuration where dispersed negative polarity regions were surrounded by
positive polarity regions. This unique photospheric configuration, analogous to
the geological ""atoll"" shape, hosted four homologous flares within its
boundary. Computation of the degree of squashing factor (Q) maps clearly
revealed an elongated region of high Q-values between the inner and outer
spine-like lines, implying the presence of an hyperbolic flux tube (HFT). The
coronal region associated with the photospheric atoll configuration was
distinctly identified in the form of a diffused dome-shaped bright structure
directly observed in EUV images. A filament channel resided near the boundary
of the atoll region. The activation and eruption of flux ropes from the
filament channel led to the onset of four eruptive homologous quasi-circular
ribbon flares within an interval of $\approx$11 hours. During the interval of
the four flares, we observed continuous decay and cancellation of negative
polarity flux within the atoll region. Accordingly, the apparent length of the
HFT gradually reduced to a null-point-like configuration before the fourth
flare. Prior to each flare, we observed localised brightening beneath the
filaments which, together with flux cancellation, provided support for the
tether-cutting model of solar eruption. The analysis of magnetic decay index
revealed favourable conditions for the eruption, once the pre-activated flux
ropes attained the critical heights for torus instability.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:43:55 GMT""}]","2021-02-03"
"2101.08165","Wentao Xie","Wentao Xie, Guanghui Ren, Si Liu","Video Relation Detection with Trajectory-aware Multi-modal Features",,,"10.1145/3394171.3416284",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video relation detection problem refers to the detection of the relationship
between different objects in videos, such as spatial relationship and action
relationship. In this paper, we present video relation detection with
trajectory-aware multi-modal features to solve this task.
  Considering the complexity of doing visual relation detection in videos, we
decompose this task into three sub-tasks: object detection, trajectory proposal
and relation prediction. We use the state-of-the-art object detection method to
ensure the accuracy of object trajectory detection and multi-modal feature
representation to help the prediction of relation between objects. Our method
won the first place on the video relation detection task of Video Relation
Understanding Grand Challenge in ACM Multimedia 2020 with 11.74\% mAP, which
surpasses other methods by a large margin.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:49:02 GMT""}]","2021-01-21"
"2101.08166","Panagiotis Kourtesis P.K.","Panagiotis Kourtesis, Danai Korre, Simona Collina, Leonidas A.A.
  Doumas, and Sarah E. MacPherson","Guidelines for the Development of Immersive Virtual Reality Software for
  Cognitive Neuroscience and Neuropsychology: The Development of Virtual
  Reality Everyday Assessment Lab (VR-EAL)","Published in Frontier in Computer Science","Frontiers in Computer Science, 1, p.12 (2020)","10.3389/fcomp.2019.00012",,"cs.HC cs.CY cs.MM","http://creativecommons.org/licenses/by/4.0/","  Virtual reality (VR) head-mounted displays (HMD) appear to be effective
research tools, which may address the problem of ecological validity in
neuropsychological testing. However, their widespread implementation is
hindered by VR induced symptoms and effects (VRISE) and the lack of skills in
VR software development. This study offers guidelines for the development of VR
software in cognitive neuroscience and neuropsychology, by describing and
discussing the stages of the development of Virtual Reality Everyday Assessment
Lab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques
for evaluating cognitive functions within a realistic storyline are discussed.
The utility of various assets in Unity, software development kits, and other
software are described so that cognitive scientists can overcome challenges
pertinent to VRISE and the quality of the VR software. In addition, this pilot
study attempts to evaluate VR-EAL in accordance with the necessary criteria for
VR software for research purposes. The VR neuroscience questionnaire (VRNQ;
Kourtesis et al., 2019b) was implemented to appraise the quality of the three
versions of VR-EAL in terms of user experience, game mechanics, in-game
assistance, and VRISE. Twenty-five participants aged between 20 and 45 years
with 12-16 years of full-time education evaluated various versions of VR-EAL.
The final version of VR-EAL achieved high scores in every sub-score of the VRNQ
and exceeded its parsimonious cut-offs. It also appeared to have better in-game
assistance and game mechanics, while its improved graphics substantially
increased the quality of the user experience and almost eradicated VRISE. The
results substantially support the feasibility of the development of effective
VR research and clinical software without the presence of VRISE during a
60-minute VR session.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:55:57 GMT""}]","2021-01-21"
"2101.08167","Khaled Zaouk","Khaled Zaouk, Fei Song, Chenghao Lyu and Yanlei Diao","Neural-based Modeling for Performance Tuning of Spark Data Analytics",,,,,"cs.DC cs.DB cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cloud data analytics has become an integral part of enterprise business
operations for data-driven insight discovery. Performance modeling of cloud
data analytics is crucial for performance tuning and other critical operations
in the cloud. Traditional modeling techniques fail to adapt to the high degree
of diversity in workloads and system behaviors in this domain. In this paper,
we bring recent Deep Learning techniques to bear on the process of automated
performance modeling of cloud data analytics, with a focus on Spark data
analytics as representative workloads. At the core of our work is the notion of
learning workload embeddings (with a set of desired properties) to represent
fundamental computational characteristics of different jobs, which enable
performance prediction when used together with job configurations that control
resource allocation and other system knobs. Our work provides an in-depth study
of different modeling choices that suit our requirements. Results of extensive
experiments reveal the strengths and limitations of different modeling methods,
as well as superior performance of our best performing method over a
state-of-the-art modeling tool for cloud analytics.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 14:58:55 GMT""}]","2021-01-21"
"2101.08168","Stefan Kindermann","Stefan Kindermann","Optimal-order convergence of Nesterov acceleration for linear ill-posed
  problems",,,"10.1088/1361-6420/abf5bc",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We show that Nesterov acceleration is an optimal-order iterative
regularization method for linear ill-posed problems provided that a parameter
is chosen accordingly to the smoothness of the solution. This result is proven
both for an a priori stopping rule and for the discrepancy principle. The
essential tool to obtain this result is a representation of the residual
polynomials via Gegenbauer polynomials.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:00:46 GMT""}]","2021-07-07"
"2101.08169","Paulo Andr\'e Lima de Castro","Paulo Andr\'e Lima de Castro","mt5se: An Open Source Framework for Building Autonomous Trading Robots","This paper replaces an old version of the framework, called mt5b3,
  which is now deprecated",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Autonomous trading robots have been studied in artificial intelligence area
for quite some time. Many AI techniques have been tested for building
autonomous agents able to trade financial assets. These initiatives include
traditional neural networks, fuzzy logic, reinforcement learning but also more
recent approaches like deep neural networks and deep reinforcement learning.
Many developers claim to be successful in creating robots with great
performance when simulating execution with historical price series, so called
backtesting. However, when these robots are used in real markets frequently
they present poor performance in terms of risks and return. In this paper, we
propose an open source framework (mt5se) that helps the development,
backtesting, live testing and real operation of autonomous traders. We built
and tested several traders using mt5se. The results indicate that it may help
the development of better traders. Furthermore, we discuss the simple
architecture that is used in many studies and propose an alternative multiagent
architecture. Such architecture separates two main concerns for portfolio
manager (PM) : price prediction and capital allocation. More than achieve a
high accuracy, a PM should increase profits when it is right and reduce loss
when it is wrong. Furthermore, price prediction is highly dependent of asset's
nature and history, while capital allocation is dependent only on analyst's
prediction performance and assets' correlation. Finally, we discuss some
promising technologies in the area.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:01:02 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 12:19:21 GMT""},{""version"":""v3"",""created"":""Tue, 28 Jun 2022 23:14:56 GMT""}]","2022-06-30"
"2101.08170","Qingyun Sun","Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Yuanxing Ning, Phillip S.
  Yu, Lifang He","SUGAR: Subgraph Neural Network with Reinforcement Pooling and
  Self-Supervised Mutual Information Mechanism","Accepted by The Web Conference (WWW) 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph representation learning has attracted increasing research attention.
However, most existing studies fuse all structural features and node attributes
to provide an overarching view of graphs, neglecting finer substructures'
semantics, and suffering from interpretation enigmas. This paper presents a
novel hierarchical subgraph-level selection and embedding based graph neural
network for graph classification, namely SUGAR, to learn more discriminative
subgraph representations and respond in an explanatory way. SUGAR reconstructs
a sketched graph by extracting striking subgraphs as the representative part of
the original graph to reveal subgraph-level patterns. To adaptively select
striking subgraphs without prior knowledge, we develop a reinforcement pooling
mechanism, which improves the generalization ability of the model. To
differentiate subgraph representations among graphs, we present a
self-supervised mutual information mechanism to encourage subgraph embedding to
be mindful of the global graph structural properties by maximizing their mutual
information. Extensive experiments on six typical bioinformatics datasets
demonstrate a significant and consistent improvement in model quality with
competitive performance and interpretability.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:06:16 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 08:57:10 GMT""},{""version"":""v3"",""created"":""Mon, 24 May 2021 06:08:47 GMT""}]","2021-05-25"
"2101.08171","Armin Scrinzi","Armin Scrinzi","tRecX -- an environment for solving time-dependent Schr\""odinger-like
  problems",,"Computer Physics Communications 2021, 108146","10.1016/j.cpc.2021.108146",,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  TRecX is a C++ code for solving generalized inhomogeneous time-dependent
Schr\""odinger-type equations $id\Psi/dt = H[t,\Psi] + \Phi$ in arbitrary
dimensions and in a variety of coordinate systems. The operator $H[t,\Psi]$ may
have simple non-linearities, as in Gross-Pitaevskii and Hartree(-Fock)
problems. Primary application of tRecX has been non-perturbative strong-field
single and double photo-electron emission in atomic and molecular physics. The
code is designed for large-scale {\it ab initio} calculations, for exploring
models, and for advanced teaching in computational physics. Distinctive
numerical methods are the time-dependent surface flux method for the
computation of single and double emission spectra and exterior complex scaling
for absorption. Wave functions and operators are handled by tree-structures
with the systematic use of recursion on the coarse-grain level. Numerical,
analytic, and grid-based discretizations can be combined and are treated on the
same abstract level. Operators are specified in the input using a script
language including symbolic algebra. User-friendly in- and output, error
safety, and documentation are integrated by design.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:06:55 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 08:50:04 GMT""}]","2021-11-08"
"2101.08172","Lorena Acu\~na","Lorena Acu\~na, Magali Deleuil, Olivier Mousis, Emmanuel Marcq,
  Ma\""eva Levesque and Artyom Aguichine","Characterisation of the hydrospheres of TRAPPIST-1 planets","11 pages, 7 figures. Accepted by Astronomy & Astrophysics (in press)","A&A 647, A53 (2021)","10.1051/0004-6361/202039885",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Context. Planetary mass and radius data are showing a wide variety in
densities of low-mass exoplanets. This includes sub-Neptunes, whose low
densities can be explained with the presence of a volatile-rich layer. Water is
one of the most abundant volatiles, which can be in the form of different
phases depending on the planetary surface conditions. To constrain their
composition and interior structure, it is required to develop models that
calculate accurately the properties of water at its different phases. Aims. We
present an interior structure model that includes a multiphase water layer with
steam, supercritical and condensed phases. We derive the constraints for
planetary compositional parameters and their uncertainties, focusing on the
multiplanetary system TRAPPIST-1, which presents both warm and temperate
planets. Methods. We use a 1D steam atmosphere in radiative-convective
equilibrium with an interior whose water layer is in supercritical phase
self-consistently. For temperate surface conditions, we implement liquid and
ice Ih to ice VII phases in the hydrosphere. We adopt a MCMC inversion scheme
to derive the probability distributions of core and water compositional
parameters Results. We refine the composition of all planets and derive
atmospheric parameters for planets b and c. The latter would be in a
post-runaway greenhouse state and could be extended enough to be probed by
space mission such as JWST. Planets d to h present condensed ice phases, with
maximum water mass fractions below 20%. Conclusions. The derived amounts of
water for TRAPPIST-1 planets show a general increase with semi-major axis, with
the exception of planet d. This deviation from the trend could be due to
formation mechanisms, such as migration and an enrichment of water in the
region where planet d formed, or an extended CO$_{2}$-rich atmosphere.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:07:31 GMT""}]","2021-03-10"
"2101.08173","Mykhaylo Tyomkyn","Asaf Shapira, Mykhaylo Tyomkyn","Quasirandom Graphs and the Pantograph Equation","To appear in Amer. Math. Monthly",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The pantograph differential equation and its solution, the deformed
exponential function, are remarkable objects that appear in areas as diverse as
combinatorics, number theory, statistical mechanics, and electrical
engineering. In this article we describe a new surprising application of these
objects in graph theory, by showing that the set of all cliques is not forcing
for quasirandomness. This provides a natural example of an infinite family of
graphs, which is not forcing, and answers a natural question posed by P. Horn.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:12:34 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 10:58:40 GMT""}]","2021-05-26"
"2101.08174","Angus Siberry Mr","Angus Siberry, David Hambley, Anna Adamska, Ross Springell","A mathematical model to describe the alpha dose rate from a UO2 surface",,,"10.1016/j.radphyschem.2021.109359",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model to determine the dose rate of a planar alpha-emitting surface, has
been developed. The approach presented is a computationally efficient
mathematical model using stopping range data from the Stopping Ranges of Ions
in Matter (SRIM) software. The alpha dose rates as a function of distance from
irradiated UO2 spent fuel surfaces were produced for bench-marking with
previous modelling attempts. This method is able to replicate a Monte Carlo
(MCNPX) study of an irradiated UO2 fuel surface within 0.6 % of the resulting
total dose rate and displays a similar dose profile.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:14:02 GMT""}]","2021-02-05"
"2101.08175","Silvia Montagna","Patric Dolmeta, Raffaele Argiento, Silvia Montagna","Bayesian GARCH Modeling of Functional Sports Data",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  The use of statistical methods in sport analytics has gained a rapidly
growing interest over the last decade, and nowadays is common practice. In
particular, the interest in understanding and predicting an athlete's
performance throughout his/her career is motivated by the need to evaluate the
efficacy of training programs, anticipate fatigue to prevent injuries and
detect unexpected of disproportionate increases in performance that might be
indicative of doping. Moreover, fast evolving data gathering technologies
require up to date modelling techniques that adapt to the distinctive features
of sports data. In this work, we propose a hierarchical Bayesian model for
describing and predicting the evolution of performance over time for shot put
athletes. To account for seasonality and heterogeneity in recorded results, we
rely both on a smooth functional contribution and on a linear mixed effect
model with heteroskedastic errors to represent the athlete-specific
trajectories. The resulting model provides an accurate description of the
performance trajectories and helps specifying both the intra- and
inter-seasonal variability of measurements. Further, the model allows for the
prediction of athletes' performance in future seasons. We apply our model to an
extensive real world data set on performance data of professional shot put
athletes recorded at elite competitions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:16:10 GMT""}]","2021-01-21"
"2101.08176","Denis Boyda","Michael S. Albergo, Denis Boyda, Daniel C. Hackett, Gurtej Kanwar,
  Kyle Cranmer, S\'ebastien Racani\`ere, Danilo Jimenez Rezende, Phiala E.
  Shanahan","Introduction to Normalizing Flows for Lattice Field Theory","38 pages, 5 numbered figures, Jupyter notebook included as ancillary
  file",,,"MIT-CTP/5272","hep-lat cond-mat.stat-mech cs.LG","http://creativecommons.org/licenses/by/4.0/","  This notebook tutorial demonstrates a method for sampling Boltzmann
distributions of lattice field theories using a class of machine learning
models known as normalizing flows. The ideas and approaches proposed in
arXiv:1904.12072, arXiv:2002.02428, and arXiv:2003.06413 are reviewed and a
concrete implementation of the framework is presented. We apply this framework
to a lattice scalar field theory and to U(1) gauge theory, explicitly encoding
gauge symmetries in the flow-based approach to the latter. This presentation is
intended to be interactive and working with the attached Jupyter notebook is
recommended.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:16:28 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 20:10:00 GMT""},{""version"":""v3"",""created"":""Fri, 6 Aug 2021 14:14:21 GMT""}]","2021-08-09"
"2101.08179","Angela D. V. Di Virgilio dr","Angela D.V. Di Virgilio, Umberto Giacomelli, Andrea Simonelli,
  Giuseppe Terreni, Andrea Basti, Nicol\`o Beverini, Giorgio Carelli, Donatella
  Ciampini, Francesco Fuso, Enrico Maccioni, Paolo Marsili, Carlo Altucci,
  Francesco Bajardi, Salvatore Capozziello, Raffaele Velotta, Alberto Porzio,
  Antonello Ortolan","Reaching the sensitivity limit of a Sagnac gyroscope through linear
  regression analysis","13 pages, 7 figures, regular paper",,"10.1140/epjc/s10052-021-09199-1",,"gr-qc physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  The sensitivity to angular rotation of the top class Sagnac gyroscope
GINGERINO is carefully investigated with standard statistical means, using 103
days of continuous operation and the available geodesic measurements of the
Earth angular rotation rate. All features of the Earth rotation rate are
correctly reproduced. The sensitivity of fractions of frad/s is attained for
long term runs. This excellent sensitivity and stability put Sagnac gyroscopes
at the forefront for fundamental physics, in particular for tests of general
relativity and Lorentz violation, where the sensitivity plays the key role to
provide reliable data for deeper theoretical investigations. The achieved
sensitivity overcomes the conventionally expected one for Sagnac ring laser
gyroscopes.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:22:15 GMT""}]","2021-05-26"
"2101.08180","Moritz Heindl","Moritz Heindl and Leticia Gonz\'alez","Validating Fewest-Switches Surface Hopping in the Presence of Laser
  Fields","45 pages and 10 Figures in the main manuscript",,"10.1063/5.0044807",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The capability of fewest-switches surface hopping (FSSH) to describe
non-adiabatic dynamics of small and medium sized molecules under explicit
excitation with external fields is evaluated. Different parameters in FSSH and
combinations thereof are benchmarked against multi-configurational time
dependent Hartree (MCTDH) reference calculations using SO$_2$ and
2-thiocytosine as model, yet realistic, molecular systems. Qualitatively, we
find that FSSH is able to reproduce the trends in the MCTDH dynamics with (and
without) an explicit external field; however, no set of FSSH parameters is
ideal. An adequate treatment of the overcoherence in FSSH is identified as the
driving factor to improve the description of the excitation process with
respect to the MCTDH reference. Here two corrections were tested, the
augmented-FSSH (AFSSH) and the energy-based decoherence correction. A
dependence on the employed basis is detected for the AFSSH algorithm,
performing better when spin-orbit and external laser field couplings are
treated as off-diagonal elements instead of projecting them onto the diagonal
of the Hamilton operator. In the presence of an electric field, the excited
state dynamics was found to depend strongly on the vector used to rescale the
kinetic energy along after a transition between surfaces. For SO$_2$,
recurrence of the excited wave packet throughout the duration of the applied
laser pulse is observed for long laser pulses (>100~fs), resulting in
additional interferences not captured by FSSH and only visible in variational
multi-configurational Gaussian when utilizing a large amount of gaussian basis
functions. This feature essentially vanishes when going towards larger
molecules, such as 2-thiocytosine, where this effect is barely visible in a
laser pulse with a full width at half maximum of 200~fs.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:24:54 GMT""}]","2021-04-21"
"2101.08181","Julien Lange","Mario Bravetti, Julien Lange, Gianluigi Zavattaro","Fair Refinement for Asynchronous Session Types (extended version)",,,,,"cs.PL cs.LO","http://creativecommons.org/licenses/by/4.0/","  Session types are widely used as abstractions of asynchronous message passing
systems. Refinement for such abstractions is crucial as it allows improvements
of a given component without compromising its compatibility with the rest of
the system. In the context of session types, the most general notion of
refinement is the asynchronous session subtyping, which allows to anticipate
message emissions but only under certain conditions. In particular,
asynchronous session subtyping rules out candidates subtypes that occur
naturally in communication protocols where, e.g., two parties simultaneously
send each other a finite but unspecified amount of messages before removing
them from their respective buffers. To address this shortcoming, we study fair
compliance over asynchronous session types and fair refinement as the relation
that preserves it. This allows us to propose a novel variant of session
subtyping that leverages the notion of controllability from service contract
theory and that is a sound characterisation of fair refinement. In addition, we
show that both fair refinement and our novel subtyping are undecidable. We also
present a sound algorithm, and its implementation, which deals with examples
that feature potentially unbounded buffering.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:29:27 GMT""}]","2021-01-21"
"2101.08182","Arno Klenke","A. Klenke, M. M\""uller, H. Stark, F. Stutzki, C. Hupel, T. Schreiber,
  A. T\""unnermann, J. Limpert","Coherently combined 16 channel multicore fiber laser system",,,"10.1364/OL.43.001519",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a coherently combined laser amplifier with 16 channels from a
multicore fiber in a proof-of-principle demonstration. Filled aperture beam
splitting and combination together with temporal phasing is realized in a
compact and low-component-count setup. Combined average power of up to 70 W
with 40 ps pulses are achieved with combination efficiencies around 80%.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:29:39 GMT""}]","2021-01-21"
"2101.08183","Mingshuai Dong","Mingshuai Dong, Shimin Wei, Xiuli Yu, Jianqin Yin","Mask-GD Segmentation Based Robotic Grasp Detection",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reliability of grasp detection for target objects in complex scenes is a
challenging task and a critical problem that needs to be solved urgently in
practical application. At present, the grasp detection location comes from
searching the feature space of the whole image. However, the cluttered
background information in the image impairs the accuracy of grasping detection.
In this paper, a robotic grasp detection algorithm named MASK-GD is proposed,
which provides a feasible solution to this problem. MASK is a segmented image
that only contains the pixels of the target object. MASK-GD for grasp detection
only uses MASK features rather than the features of the entire image in the
scene. It has two stages: the first stage is to provide the MASK of the target
object as the input image, and the second stage is a grasp detector based on
the MASK feature. Experimental results demonstrate that MASK-GD's performance
is comparable with state-of-the-art grasp detection algorithms on Cornell
Datasets and Jacquard Dataset. In the meantime, MASK-GD performs much better in
complex scenes.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:30:34 GMT""}]","2021-01-21"
"2101.08184","Paolo Baldan","Paolo Baldan, Richard Eggert, Barbara K\""onig, Tommaso Padoan","Fixpoint Theory -- Upside Down",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Knaster-Tarski's theorem, characterising the greatest fixpoint of a monotone
function over a complete lattice as the largest post-fixpoint, naturally leads
to the so-called coinduction proof principle for showing that some element is
below the greatest fixpoint (e.g., for providing bisimilarity witnesses). The
dual principle, used for showing that an element is above the least fixpoint,
is related to inductive invariants. In this paper we provide proof rules which
are similar in spirit but for showing that an element is above the greatest
fixpoint or, dually, below the least fixpoint. The theory is developed for
non-expansive monotone functions on suitable lattices of the form
$\mathbb{M}^Y$, where $Y$ is a finite set and $\mathbb{M}$ an MV-algebra, and
it is based on the construction of (finitary) approximations of the original
functions. We show that our theory applies to a wide range of examples,
including termination probabilities, metric transition systems, behavioural
distances for probabilistic automata and bisimilarity. Moreover it allows us to
determine original algorithms for solving simple stochastic games.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:31:01 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 11:09:43 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 07:57:11 GMT""},{""version"":""v4"",""created"":""Mon, 25 Jul 2022 13:59:43 GMT""},{""version"":""v5"",""created"":""Wed, 19 Apr 2023 10:41:15 GMT""},{""version"":""v6"",""created"":""Thu, 20 Apr 2023 07:27:42 GMT""},{""version"":""v7"",""created"":""Thu, 27 Apr 2023 12:58:27 GMT""},{""version"":""v8"",""created"":""Tue, 6 Jun 2023 14:06:36 GMT""}]","2023-06-07"
"2101.08185","Arno Klenke","Steffen H\""adrich, Marco Kienel, Michael M\""uller, Arno Klenke, Jan
  Rothhardt, Robert Klas, Thomas Gottschall, Tino Eidam, Andr\'as Drozdy,
  P\'eter J\'oj\'art, Zolt\'an V\'arallyay, Eric Cormier, K\'aroly Osvay,
  Andreas T\""unnermann, Jens Limpert","Energetic sub-2-cycle laser with 220 W average power",,,"10.1364/OL.41.004332",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-cycle lasers are essential for many research areas such as attosecond
physics that promises to address fundamental questions in science and
technology. Therefore, further advancements are connected to significant
progress in the underlying laser technology. Here, two-stage nonlinear
compression of a 660 W femtosecond fiber laser system is utilized to achieve
unprecedented average power levels of energetic ultrashort or even few-cycle
laser pulses. In a first compression step 408 W, 320 uJ, 30fs pulses are
achieved, which can be further compressed to 216 W, 170 uJ, 6.3 fs pulses in a
second compression stage. This is the highest average power few-cycle laser
system presented so far. It is expected to significantly advance the fields of
high harmonic generation and attosecond science.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:31:10 GMT""}]","2021-01-21"
"2101.08186","Subhajit Barman","Subhajit Barman and Bibhas Ranjan Majhi","Radiative process of two entangled uniformly accelerated atoms in a
  thermal bath: a possible case of anti-Unruh event","Minor modifications, to appear in JHEP","JHEP 03 (2021) 245","10.1007/JHEP03(2021)245",,"gr-qc hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the radiative process of two entangled two-level atoms uniformly
accelerated in a thermal bath, coupled to a massless scalar field. First, using
the positive frequency Wightman function from the Minkowski modes with a
Rindler transformation we provide the transition probabilities for the
transitions from maximally entangled symmetric and anti-symmetric Bell states
to the collective excited state in $(1+1)$ and $(1+3)$ dimensions. We observe a
possible case of \emph{anti-Unruh-like} event in these transition
probabilities, though the $(1+1)$ and $(1+3)$ dimensional results are not
completely equivalent. We infer that thermal bath plays a major role in the
occurrence of the anti-Unruh-like effect, as it is also present in the
transition probabilities corresponding to a single detector in this case.
Second, we have considered the Green's functions in terms of the Rindler modes
with the vacuum of Unruh modes for estimating the same. Here the anti-Unruh
effect appears only for the transition from the anti-symmetric state to the
collective excited state. It is noticed that here the $(1+1)$ and $(1+3)$
dimensional results are equivalent, and for a single detector, we do not
observe any anti-Unruh effect. This suggests that the entanglement between the
states of the atoms is the main cause for the observed anti-Unruh effect in
this case. In going through the investigation, we find that the transition
probability for a single detector case is symmetric under the interchange
between the thermal bath's temperature and the Unruh temperature for Rindler
mode analysis; whereas this is not the case for Minkowski mode. We further
comment on whether this observation may shed light on the analogy between an
accelerated observer and a real thermal bath. An elaborate investigation for
the classifications of our observed anti-Unruh effects is also thoroughly
demonstrated.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:31:13 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 10:00:19 GMT""}]","2021-05-25"
"2101.08187","Mohsen Asgharzadeh","Mohsen Asgharzadeh","Cohomological splitting, realization, and finiteness",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We search for some splitting (resp. finiteness) criteria of a given module
$M$ over a local ring $(R,\fm,k)$ in terms of the splitting (resp. finiteness)
property of certain cohomological functors evaluated at $M$. In particular, we
deal with the cohomological splitting question posted by Vasconcelos. We
present a connection from our approach to the realization problem of Nunke.
This is equipped with several applications. For instance, we recover some
results of Jensen (and others) by applying simple methods. Additional
applications, including a computation of the projective dimension of some
injective modules, are given. This enables us to extend some results of Matlis
(resp. Osofsky) on the projective dimension of $E_R(k)$ (resp. $\mathcal{Q}$)
from Cohen-Macaulay rings (resp. regular rings) to non-Cohen-Macaulay (resp.
Cohen-Macaulay) rings.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:31:28 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 15:33:42 GMT""},{""version"":""v3"",""created"":""Thu, 9 Jun 2022 14:40:23 GMT""},{""version"":""v4"",""created"":""Tue, 28 Jun 2022 14:16:26 GMT""},{""version"":""v5"",""created"":""Mon, 11 Jul 2022 07:50:26 GMT""},{""version"":""v6"",""created"":""Tue, 20 Dec 2022 14:17:43 GMT""}]","2022-12-21"
"2101.08188","Vartan Choulakian","Vartan Choulakian and Jacques Allard (Universit\'e de Moncton, Canada)","Uncovering and Displaying the Coherent Groups of Rank Data by
  Exploratory Riffle Shuffling","34 pages, 12 figures, 15 tables",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Let n respondents rank order d items, and suppose that d << n. Our main task
is to uncover and display the structure of the observed rank data by an
exploratory riffle shuffling procedure which sequentially decomposes the n
voters into a finite number of coherent groups plus a noisy group : where the
noisy group represents the outlier voters and each coherent group is composed
of a finite number of coherent clusters. We consider exploratory riffle
shuffling of a set of items to be equivalent to optimal two blocks seriation of
the items with crossing of some scores between the two blocks. A riffle
shuffled coherent cluster of voters within its coherent group is essentially
characterized by the following facts : a) Voters have identical first TCA
factor score, where TCA designates taxicab correspondence analysis, an L1
variant of correspondence analysis ; b) Any preference is easily interpreted as
riffle shuffling of its items ; c) The nature of different riffle shuffling of
items can be seen in the structure of the contingency table of the first-order
marginals constructed from the Borda scorings of the voters ; d) The first TCA
factor scores of the items of a coherent cluster are interpreted as Borda scale
of the items. We also introduce a crossing index, which measures the extent of
crossing of scores of voters between the two blocks seriation of the items. The
novel approach is explained on the benchmarking SUSHI data set, where we show
that this data set has a very simple structure, which can also be communicated
in a tabular form.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:34:33 GMT""}]","2021-01-21"
"2101.08189","Alexey Scherbakov","Dmytro D. Yaremkevich, Alexey V. Scherbakov, Serhii M. Kukhtaruk,
  Tetiana L. Linnik, Nikolay E. Khokhlov, Felix Godejohann, Olga A. Dyatlova,
  Achim Nadzeyka, Debi P. Pattnaik, Mu Wang, Syamashree Roy, Richard P.
  Campion, Andrew W. Rushforth, Vitalyi E. Gusev, Andrey V. Akimov, and Manfred
  Bayer","Protected Long-Distance Guiding of Hypersound Underneath a
  Nano-Corrugated Surface","18 pages (inc. references), 5 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Within a new paradigm for communications on the nanoscale, high-frequency
surface acoustic waves are becoming effective data carrier and encoder. On-chip
communications require acoustic wave propagation along nano-corrugated surfaces
which strongly scatter traditional Rayleigh waves. Here we propose the delivery
of information using subsurface acoustic waves with hypersound frequencies ~20
GHz, which is a nanoscale analogue of subsurface sound waves in the ocean. A
bunch of subsurface hypersound modes is generated by pulsed optical excitation
in a multilayer semiconductor structure with a metallic nanograting on top. The
guided hypersound modes propagate coherently beneath the nanograting, retaining
the surface imprinted information, on a distance of more than 50 {\mu}m which
essentially exceeds the propagation length of Rayleigh waves. The concept is
suitable for interfacing single photon emitters, such as buried quantum dots,
carrying coherent spin excitations in magnonic devices, and encoding the
signals for optical communications at the nanoscale.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:34:55 GMT""}]","2021-01-21"
"2101.08190","Maksim Zhukovskii","Maria Krivoshapko, Maksim Zhukovskii","Maximum induced forests in random graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that with high probability maximum sizes of induced forests in dense
binomial random graphs are concentrated in two consecutive values.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:36:31 GMT""}]","2021-01-21"
"2101.08191","Hariom Sharma","Hariom Sharma, R. K. Sharma","Existence of Primitive Normal Pairs with One Prescribed Trace over
  Finite Fields",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Given $m, n, q\in \mathbb{N}$ such that $q$ is a prime power and $m\geq 3$,
$a\in \mathbb{F}_q$, we establish a sufficient condition for the existence of
primitive pair $(\alpha, f(\alpha))$ in $\mathbb{F}_{q^m}$ such that $\alpha$
is normal over $\mathbb{F}_q$ and
$\text{Tr}_{\mathbb{F}_{q^m}/\mathbb{F}_q}(\alpha^{-1})=a$, where $f(x)\in
\mathbb{F}_{q^m}(x)$ is a rational function of degree sum $n$. Further, when
$n=2$ and $q=5^k$ for some $k\in \mathbb{N}$, such a pair definitely exists for
all $(q, m)$ apart from at most $20$ choices.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:40:51 GMT""}]","2021-01-21"
"2101.08192","Ilkyoo Choi","Ilkyoo Choi, Minseong Kim, Kiwon Seo","Brick partition problems in three dimensions","8 pages, 3 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A $d$-dimensional brick is a set $I_1\times \cdots \times I_d$ where each
$I_i$ is an interval. Given a brick $B$, a brick partition of $B$ is a
partition of $B$ into bricks. A brick partition $\mathcal{P}_d$ of a
$d$-dimensional brick is $k$-piercing if every axis-parallel line intersects at
least $k$ bricks in $\mathcal{P}_d$. Bucic et al. explicitly asked the minimum
size $p(d, k)$ of a $k$-piercing brick partition of a $d$-dimensional brick.
The answer is known to be $4(k-1)$ when $d=2$. Our first result almost
determines $p(3, k)$. Namely, we construct a $k$-piercing brick partition of a
$3$-dimensional brick with $12k-15$ parts, which is off by only $1$ from the
known lower bound. As a generalization of the above question, we also seek the
minimum size $s(d, k)$ of a brick partition $\mathcal{P}_d$ of a
$d$-dimensional brick where each axis-parallel plane intersects at least $k$
bricks in $\mathcal{P}_d$. We resolve the question in the $3$-dimensional case
by determining $s(3, k)$ for all $k$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:42:24 GMT""}]","2021-01-21"
"2101.08193","Matjaz Perc","Valerio Capraro, Matjaz Perc","Mathematical foundations of moral preferences","34 pages; accepted for publication in Journal of the Royal Society
  Interface","J. R. Soc. Interface 18, 20200880 (2021)","10.1098/rsif.2020.0880",,"physics.soc-ph cs.GT","http://creativecommons.org/licenses/by/4.0/","  One-shot anonymous unselfishness in economic games is commonly explained by
social preferences, which assume that people care about the monetary payoffs of
others. However, during the last ten years, research has shown that different
types of unselfish behaviour, including cooperation, altruism, truth-telling,
altruistic punishment, and trustworthiness are in fact better explained by
preferences for following one's own personal norms - internal standards about
what is right or wrong in a given situation. Beyond better organising various
forms of unselfish behaviour, this moral preference hypothesis has recently
also been used to increase charitable donations, simply by means of
interventions that make the morality of an action salient. Here we review
experimental and theoretical work dedicated to this rapidly growing field of
research, and in doing so we outline mathematical foundations for moral
preferences that can be used in future models to better understand selfless
human actions and to adjust policies accordingly. These foundations can also be
used by artificial intelligence to better navigate the complex landscape of
human morality.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:47:38 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 14:42:51 GMT""}]","2021-06-10"
"2101.08194","Alessandro Celestini","Massimo Bernaschi, Alessandro Celestini, Marco Cianfriglia, Stefano
  Guarino, Flavio Lombardi, Enrico Mastrostefano","Onion under Microscope: An in-depth analysis of the Tor network",,"World Wide Web volume 25 (2022)","10.1007/s11280-022-01044-z",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tor is an anonymity network that allows offering and accessing various kinds
of resources, known as hidden services, while guaranteeing sender and receiver
anonymity. The Tor web is the set of web resources that exist on the Tor
network, and Tor websites are part of the so-called dark web. Recent research
works have evaluated Tor security, evolution over time, and thematic
organization. Nevertheless, few information are available about the structure
of the graph defined by the network of Tor websites. The limited number of Tor
entry points that can be used to crawl the network renders the study of this
graph far from being simple. In this paper we aim at better characterizing the
Tor Web by analyzing three crawling datasets collected over a five-month time
frame. On the one hand, we extensively study the global properties of the Tor
Web, considering two different graph representations and verifying the impact
of Tor's renowned volatility. We present an in depth investigation of the key
features of the Tor Web graph showing what makes it different from the surface
Web graph. On the other hand, we assess the relationship between contents and
structural features. We analyse the local properties of the Tor Web to better
characterize the role different services play in the network and to understand
to which extent topological features are related to the contents of a service.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:48:16 GMT""}]","2023-02-16"
"2101.08195","Matthew Chantry","Matthew Chantry and Sam Hatfield and Peter Duben and Inna Polichtchouk
  and Tim Palmer","Machine learning emulation of gravity wave drag in numerical weather
  forecasting",,,"10.1029/2021MS002477",,"physics.ao-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We assess the value of machine learning as an accelerator for the
parameterisation schemes of operational weather forecasting systems,
specifically the parameterisation of non-orographic gravity wave drag.
Emulators of this scheme can be trained to produce stable and accurate results
up to seasonal forecasting timescales. Generally, more complex networks produce
more accurate emulators. By training on an increased complexity version of the
existing parameterisation scheme we build emulators that produce more accurate
forecasts. {For medium range forecasting we find evidence our emulators are
more accurate} than the version of the parametrisation scheme that is used for
operational predictions. Using the current operational CPU hardware our
emulators have a similar computational cost to the existing scheme, but are
heavily limited by data movement. On GPU hardware our emulators perform ten
times faster than the existing scheme on a CPU.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:58:16 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 15:00:37 GMT""}]","2021-08-11"
"2101.08196","Qing Zou","Qing Zou, Abdul Haseeb Ahmed, Prashant Nagpal, Sarv Priya, Rolf
  Schulte, Mathews Jacob","Variational manifold learning from incomplete data: application to
  multislice dynamic MRI",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  Current deep learning-based manifold learning algorithms such as the
variational autoencoder (VAE) require fully sampled data to learn the
probability density of real-world datasets. Once learned, the density can be
used for a variety of tasks, including data imputation. However, fully sampled
data is often unavailable in a variety of problems, including the recovery of
dynamic and high-resolution MRI data considered in this work. To overcome this
problem, we introduce a novel variational approach to learn a manifold from
undersampled data. The VAE uses a decoder fed by latent vectors, drawn from a
conditional density estimated from the fully sampled images using an encoder.
Since fully sampled images are not available in our setting, we approximate the
conditional density of the latent vectors by a parametric model whose
parameters are estimated from the undersampled measurements using
back-propagation. We use the framework for the joint alignment and recovery of
multislice free breathing and ungated cardiac MRI data from highly undersampled
measurements. Most of the current self-gating and manifold cardiac MRI
approaches consider the independent recovery of images from each slice; these
methods are not capable of exploiting the inter-slice redundancies in the
datasets and require sophisticated post-processing or manual approaches to
align the images from different slices. By contrast, the proposed scheme is
able to align the multislice data and exploit the redundancies. Experimental
results demonstrate the utility of the proposed scheme in dynamic imaging
alignment and reconstructions.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:58:48 GMT""},{""version"":""v2"",""created"":""Sat, 20 Mar 2021 14:44:27 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 17:15:18 GMT""}]","2021-12-13"
"2101.08238","Ammarah Farooq","Ammarah Farooq, Muhammad Awais, Josef Kittler, Syed Safwan Khalid","AXM-Net: Implicit Cross-Modal Feature Alignment for Person
  Re-identification","AAAI-2022 (Oral Paper)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-modal person re-identification (Re-ID) is critical for modern video
surveillance systems. The key challenge is to align cross-modality
representations induced by the semantic information present for a person and
ignore background information. This work presents a novel convolutional neural
network (CNN) based architecture designed to learn semantically aligned
cross-modal visual and textual representations. The underlying building block,
named AXM-Block, is a unified multi-layer network that dynamically exploits the
multi-scale knowledge from both modalities and re-calibrates each modality
according to shared semantics. To complement the convolutional design,
contextual attention is applied in the text branch to manipulate long-term
dependencies. Moreover, we propose a unique design to enhance visual part-based
feature coherence and locality information. Our framework is novel in its
ability to implicitly learn aligned semantics between modalities during the
feature learning stage. The unified feature learning effectively utilizes
textual data as a super-annotation signal for visual representation learning
and automatically rejects irrelevant information. The entire AXM-Net is trained
end-to-end on CUHK-PEDES data. We report results on two tasks, person search
and cross-modal Re-ID. The AXM-Net outperforms the current state-of-the-art
(SOTA) methods and achieves 64.44\% Rank@1 on the CUHK-PEDES test set. It also
outperforms its competitors by $>$10\% in cross-viewpoint text-to-image Re-ID
scenarios on CrossRe-ID and CUHK-SYSU datasets.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:06:39 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 15:28:49 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jul 2022 23:20:12 GMT""}]","2022-07-22"
"2101.08257","Bernd Finkbeiner","Borzoo Bonakdarpour and Bernd Finkbeiner","Program Repair for Hyperproperties","arXiv admin note: text overlap with arXiv:2101.07847",,"10.1007/978-3-030-31784-3_25",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the repair problem for hyperproperties specified in the temporal
logic HyperLTL. Hyperproperties are system properties that relate multiple
computation traces. This class of properties includes information flow policies
like noninterference and observational determinism. The repair problem is to
find, for a given Kripke structure, a substructure that satisfies a given
specification. We show that the repair problem is decidable for HyperLTL
specifications and finite-state Kripke structures. We provide a detailed
complexity analysis for different fragments of HyperLTL and different system
types: tree-shaped, acyclic, and general Kripke structures.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:21:36 GMT""}]","2021-01-22"
"2101.08258","Ethan Ancell","Ethan Ancell, Brennan Bean","Autocart -- spatially-aware regression trees for ecological and spatial
  modeling","20 pages, 10 figures",,,,"q-bio.QM cs.LG","http://creativecommons.org/licenses/by/4.0/","  Many ecological and spatial processes are complex in nature and are not
accurately modeled by linear models. Regression trees promise to handle the
high-order interactions that are present in ecological and spatial datasets,
but fail to produce physically realistic characterizations of the underlying
landscape. The ""autocart"" (autocorrelated regression trees) R package extends
the functionality of previously proposed spatial regression tree methods
through a spatially aware splitting function and novel adaptive inverse
distance weighting method in each terminal node. The efficacy of these autocart
models, including an autocart extension of random forest, is demonstrated on
multiple datasets. This highlights the ability of autocart to model complex
interactions between spatial variables while still providing physically
realistic representations of the landscape.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:36:21 GMT""}]","2021-01-22"
"2101.08259","Emre Sariyildiz","Emre Sariyildiz","Acceleration Measurement Enhances the Bandwidth of Disturbance Observer
  in Motion Control Systems","IEEE International Conference on Mechatronics (ICM2021). arXiv admin
  note: text overlap with arXiv:2101.07920",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The trade-off between the noise-sensitivity and the performance of
disturbance estimation is well-known in the Disturbance Observer- (DOb-) based
motion control systems. As the bandwidth of the DOb increases, not only the
performance but also the frequency range of disturbance estimation improves yet
the motion controller becomes more sensitive to the noise of measurement
system. This trade-off is generally explained by considering only the noise of
sensors such as encoders. However, the digital implementation of the robust
motion controller may significantly influence the noise sensitivity and
performance of disturbance estimation in practice. This paper shows that the
conventional DOb implemented by estimating velocity is subject to waterbed
effect when the design parameters (i.e., sampling-time, nominal plant
parameters and the bandwidth of the DOb) are not properly tuned in the digital
motion controller synthesis. Therefore, the bandwidth of disturbance estimation
is limited by waterbed effect in addition to the noise of velocity measurement
system. To facilitate the digital motion controller synthesis, the design
constraints of the conventional DOb are analytically derived in this paper.
When the digital motion controller is implemented by estimating acceleration,
waterbed effect does not occur, and good robust stability and performance can
be achieved for all values of the design parameters of the acceleration
measurement-based DOb. The bandwidth of disturbance estimation, however, cannot
be freely increased due to the noise of acceleration sensors in practice. By
employing Bode Integral Theorem in the discrete-time domain, the design
constraints of the DOb-based digital motion control systems are clearly
explained and it is shown that acceleration measurement can be used to enhance
the bandwidth of the DOb, i.e., the performance and frequency range of
disturbance estimation.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:27:23 GMT""}]","2021-01-22"
"2101.08260","Weihua Deng Professor","Daxin Nie and Weihua Deng","Local discontinuous Galerkin method for the fractional diffusion
  equation with integral fractional Laplacian","11 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we provide a framework of designing the local discontinuous
Galerkin scheme for integral fractional Laplacian $(-\Delta)^{s}$ with
$s\in(0,1)$ in two dimensions. We theoretically prove and numerically verify
the numerical stability and convergence of the scheme with the convergence rate
no worse than $\mathcal{O}(h^{k+\frac{1}{2}})$.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:59:05 GMT""}]","2021-01-22"
"2101.08261","V. G. Gurzadyan","A. Stepanian, Sh. Khlghatyan, V.G. Gurzadyan","Black hole shadow to probe modified gravity","7 pages, Eur. Phys. J. Plus (in press)","Eur. Phys. J. Plus 136, 127 (2021)","10.1140/epjp/s13360-021-01119-2",,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We study the black hole's shadow for Schwarzschild - de Sitter and Kerr - de
Sitter metrics with the contribution of the cosmological constant \Lambda.
Based on the reported parameters of the M87* black hole shadow we obtain
constraints for the $\Lambda$ and show the agreement with the cosmological
data. It is shown that, the coupling of the \Lambda-term with the spin
parameter reveals peculiarities for the photon spheres and hence for the
shadows. Within the parametrized post-Newtonian formalism the constraint for
the corresponding \Lambda-determined parameter is obtained.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 03:17:17 GMT""}]","2021-01-29"
"2101.08262","Iacovos Ioannou I.I.","Iacovos Ioannou, Christophoros Christophorou, Vasos Vassiliou, Andreas
  Pitsillides","Performance Evaluation of Transmission Mode Selection in D2D
  communication","arXiv admin note: text overlap with arXiv:2101.08014","2021 11th IFIP International Conference on New Technologies,
  Mobility and Security (NTMS)","10.1109/NTMS49979.2021.9432648",,"cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Device to Device (D2D) Communication is expected to be a core part of the
forthcoming 5G Mobile Communication Networks as it promises improvements in
energy efficiency, spectral efficiency, overall system capacity, and higher
data rates with the use of the same frequencies for different D2D transmissions
in short communication distances within the Cell. However, in order to achieve
optimum results, it is important, among others, to select wisely the
Transmission Mode of the D2D Device. Towards this end, our previous work
proposed an intelligent Transmission mode selection approach in a framework
that is utilizing Artificial Intelligence (AI) BDIx agents to collectively
satisfy the D2D challenges in a Distributed Artificial Intelligent (DAI) manner
autonomously and independently. In this paper, as a first step, a literature
review focused on related Transmission mode approaches, is performed. Then, our
investigated Transmission mode selection approach is further explained with
formulas and evaluated based on different threshold values and investigated how
these can affect the overall spectral efficiency and power usage of the network
in order to achieve the maximum performance. The investigated thresholds(i.e.
D2D Device Weighted Data Rate (WDR) and the D2D Device Battery Power Level) and
metrics(i.e. WDR) are also further analyzed and formulated. In addition, the
effect the transmission power of the D2D links has on the total spectral
efficiency and total power consumption of the network, is also examined. This
evaluation results arise some interesting findings that can contribute in other
approaches that utilized similar or same thresholds. Also, the results obtained
demonstrate that with the right tuning of the thresholds and transmission
power, one can achieve a significant improvement in the network power usage and
total spectral efficiency.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:37:11 GMT""}]","2021-05-24"
"2101.08648","Shohei Satake","Shohei Satake","On high-girth expander graphs with localized eigenvectors","7 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main purpose of this paper is to construct high-girth regular expander
graphs with localized eigenvectors for general degrees, which is inspired by a
recent work due to Alon, Ganguly and Srivastava (to appear in Israel J. Math.).
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:16:47 GMT""}]","2021-01-22"
"2101.08649","Sayan Goswami","Aninda Chakraborty and Sayan Goswami","An abstract formulation of image partition regularity","Have to be refined more",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Inspired by the paper [1] of V. Bergelson, John H.Johnson Jr., J. Moreira, we
formulate an abstract version of image partition regularity. To establish the
result we have used a variant of first entry condition and for infinite case we
contained our work to Milliken-Taylor system.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 13:54:48 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 10:29:26 GMT""}]","2021-02-02"
"2101.08650","K. G. Anusree","K.G. Anusree, D. Bhattacharya, A.R. Rao, S. Vadawale, V. Bhalerao, A.
  Vibhute","AstroSat-CZTI as a hard X-ray Pulsar Monitor","Accepted for publication in the Journal of Astrophysics and
  Astronomy, 8 pages, 3 figures, 3 tables",,"10.1007/s12036-021-09707-5",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Cadmium Zinc Telluride Imager (CZTI) is an imaging instrument onboard
AstroSat. This instrument operates as a nearly open all-sky detector above ~60
keV, making possible long integrations irrespective of the spacecraft pointing.
We present a technique based on the AstroSat-CZTI data to explore the hard
X-ray characteristics of the $\gamma$-ray pulsar population. We report highly
significant ($\sim 30\sigma$) detection of hard X-ray (60--380 keV) pulse
profile of the Crab pulsar using $\sim$5000 ks of CZTI observations within 5 to
70 degrees of Crab position in the sky, using a custom algorithm developed by
us. Using Crab as our test source, we estimate the off-axis sensitivity of the
instrument and establish AstroSat-CZTI as a prospective tool in investigating
hard X-ray characteristics of $\gamma$-ray pulsars as faint as 10 mCrab.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:31:13 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 16:59:20 GMT""}]","2021-07-07"
"2101.08651","Vincent Huin","Vincent Huin (JPArc, ICM), Mathieu Barbier (ICM), Alexandra Durr
  (ICM), Isabelle Le Ber (IM2A, ICM)","Reply: Early-onset phenotype of bi-allelic GRN mutations","Brain - A Journal of Neurology , Oxford University Press (OUP), 2020",,"10.1093/brain/awaa415",,"q-bio.GN q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We would like to reply to Neuray et al. who report a series of five new
patients from four unrelated families with bi-allelic mutations of GRN. Their
work nicely completes the few existing reports of similar cases, and refers to
our recent publication describing six homozygous GRN pathogenic variant
carriers with divergent phenotypes and ages at onset (Huin et al., 2020). In
summary, the Letter from Neuray et al., reports valuable findings that lead to
better define CLN11 due to bi-allelic GRN pathogenic variants. Despite the
small sample number that does not allow statistical analysis, the authors
underlined the occurrence of cognitive deterioration and epilepsy. Further
study of the CLN11 families with functional brain imaging and
neuropsychological examinations may be highly informative for the understanding
and the clinical characterization of this rare disease.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:37:10 GMT""}]","2021-01-22"
"2101.08652","Ting Xue","Kari Vilonen and Ting Xue","A note on Hessenberg varieties",,,,,"math.RT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a short proof based on Lusztig's generalized Springer correspondence
of some results of [BrCh,BaCr,P].
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:35:06 GMT""}]","2021-01-22"
"2101.08653","Andrew Cai","Andrew Cai","Ratios of Naruse-Newton Coefficients Obtained from Descent Polynomials","27 pages, 4 figures. Comments are welcome!",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Naruse-Newton coefficients, which are obtained from expanding
descent polynomials in a Newton basis introduced by Jiradilok and McConville.
These coefficients $C_0, C_1, \ldots$ form an integer sequence associated to
each finite set of positive integers. For fixed nonnegative integers $a<b$, we
examine the set $R_{a, b}$ of all ratios $\frac{C_a}{C_b}$ over finite sets of
positive integers. We characterize finite sets for which $\frac{C_a}{C_b}$ is
minimized and provide a construction to prove $R_{a, b}$ is unbounded above. We
use this construction to obtain results on the closure of $R_{a, b}$. We also
examine properties of Naruse-Newton coefficients associated with doubleton
sets, such as unimodality and log-concavity. Finally, we find an explicit
formula for all ratios $\frac{C_a}{C_b}$ of Naruse-Newton coefficients
associated with ribbons of staircase shape.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 01:47:17 GMT""}]","2021-01-22"
"2101.08655","Leonardo Milhomem Franco Christino","Leonardo Christino, Martha D. Ferreira and Fernando V. Paulovich","Q4EDA: A Novel Strategy for Textual Information Retrieval Based on User
  Interactions with Visual Representations of Time Series","12 Figures, 21 pages, submitted to Information 2022 special issue:
  Trends and Opportunities in Visualization and Visual Analytics","Information 13 (2022), no. 8: 368","10.3390/info13080368",,"cs.HC cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowing how to construct text-based Search Queries (SQs) for use in Search
Engines (SEs) such as Google or Wikipedia has become a fundamental skill.
Though much data are available through such SEs, most structured datasets live
outside their scope. Visualization tools aid in this limitation, but no such
tools come close to the sheer amount of information available through
general-purpose SEs. To fill this gap, this paper presents Q4EDA, a novel
framework that converts users' visual selection queries executed on top of time
series visual representations, providing valid and stable SQs to be used in
general-purpose SEs and suggestions of related information. The usefulness of
Q4EDA is presented and validated by users through an application linking a
Gapminder's line-chart replica with a SE populated with Wikipedia documents,
showing how Q4EDA supports and enhances exploratory analysis of United Nations
world indicators. Despite some limitations, Q4EDA is unique in its proposal and
represents a real advance towards providing solutions for querying textual
information based on user interactions with visual representations.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:13:44 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 16:20:07 GMT""}]","2022-08-03"
"2101.08743","Wenjie Chen","Wenjie Chen, Shengcai Liu, and Ke Tang","A New Knowledge Gradient-based Method for Constrained Bayesian
  Optimization","14 pages, 0 figures",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black-box problems are common in real life like structural design, drug
experiments, and machine learning. When optimizing black-box systems,
decision-makers always consider multiple performances and give the final
decision by comprehensive evaluations. Motivated by such practical needs, we
focus on constrained black-box problems where the objective and constraints
lack known special structure, and evaluations are expensive and even with
noise. We develop a novel constrained Bayesian optimization approach based on
the knowledge gradient method ($c-\rm{KG}$). A new acquisition function is
proposed to determine the next batch of samples considering optimality and
feasibility. An unbiased estimator of the gradient of the new acquisition
function is derived to implement the $c-\rm{KG}$ approach.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:00:38 GMT""}]","2021-01-22"
"2101.08865","Stepan Paul","Stepan Paul","The Flat Klein Bottle Rendered in Curved-Crease Origami",,,,,"math.HO math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a simple and concrete way of visualizing in three dimensions a
""flat"" Klein bottle -- one whose local intrinsic geometry is the same as that
of a flat plane -- which preserves most its topological and geometric
structure. Concretely, the flatness property means that a small patch of the
surface around any point can be flattened to a patch of the plane without
stretching or compressing. Thus we can use the medium of curved-crease origami
with inelastic film to make a model which, except for its self-intersections,
necessarily has the flatness property, even along its folded edges. As such,
the sculpture presented here illustrates both the flatness, and, through its
coloring, the non-orientability of a Klein bottle.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:39:34 GMT""}]","2021-01-25"
"2101.08866","Eric Grinberg","Eric L. Grinberg","Nilpotents Leave No Trace -- A Matrix Mystery for Pandemic Times","6 pages, 1 figure",,,,"math.HO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Reopening a cold case, inspector Echelon, high-ranking in the Row Operations
Center, is searching for a lost linear map, known to be nilpotent. When a
partially decomposed matrix is unearthed, he reconstructs its reduced form,
finding it singular. But were its roots nilpotent?
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 21:57:59 GMT""}]","2021-01-25"
"2101.08880","Bernd Finkbeiner","Borzoo Bonakdarpour and Bernd Finkbeiner","Controller Synthesis for Hyperproperties","arXiv admin note: text overlap with arXiv:2101.08257",,"10.1109/CSF49147.2020.00033",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the problem of controller synthesis for hyperproperties
specified in the temporal logic HyperLTL. Hyperproperties are system properties
that relate multiple execution traces. Hyperproperties can elegantly express
information-flow policies like noninterference and observational determinism.
The controller synthesis problem is to automatically design a controller for a
plant that ensures satisfaction of a given specification in the presence of the
environment or adversarial actions. We show that the controller synthesis
problem is decidable for HyperLTL specifications and finite-state plants. We
provide a rigorous complexity analysis for different fragments of HyperLTL and
different system types: tree-shaped, acyclic, and general graphs.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:29:07 GMT""}]","2021-01-25"
"2101.09155","Rozarija Miki\'c","Rozarija Miki\'c, {\DJ}ilda Pe\v{c}ari\'c and Josip Pe\v{c}ari\'c","Some inequalities of the Edmundson-Lah-Ribaric type for 3-convex
  functions with applications","arXiv admin note: text overlap with arXiv:1809.08813",,,,"math.GM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we derive some Edmundson-Lah-Ribari\v{c} type inequalities for
positive linear functionals and 3-convex functions. Main results are applied to
the generalized f-divergence functional. Examples with Zipf Mandelbrot law are
used to illustrate the results. In addition, obtained results are utilized in
constructing some families of exponentially convex functions and Stolarsky-type
means.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:43:00 GMT""}]","2021-01-25"
"2101.09156","Antoine Rignon-Bret","Antoine Rignon-Bret","Thermodynamics of light emission","6 pages, comments are welcome",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Some interactions between classical or quantum fields and matter are known to
be irreversible processes. Here we associate an entropy to the electromagnetic
field from well-known notions of statistical quantum mechanics, in particular
the notion of diagonal entropy. We base our work on the study of spontaneous
emission and light diffusion. We obtain a quantity which allows to quantify
irreversibility for a quantum and classical description of the electromagnetic
field, that we can study and interpret from a thermodynamical point of view.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:05:19 GMT""}]","2021-01-25"
"2101.09161","Jonas Oppenlaender","Jonas Oppenlaender, Elina Kuosmanen, Andr\'es Lucero, Simo Hosio","Hardhats and Bungaloos: Comparing Crowdsourced Design Feedback with Peer
  Design Feedback in the Classroom","14 pages. CHI Conference on Human Factors in Computing Systems (CHI
  '21), May 8-13, 2021",,"10.1145/3411764.3445380",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feedback is an important aspect of design education, and crowdsourcing has
emerged as a convenient way to obtain feedback at scale. In this paper, we
investigate how crowdsourced design feedback compares to peer design feedback
within a design-oriented HCI class and across two metrics: perceived quality
and perceived fairness. We also examine the perceived monetary value of
crowdsourced feedback, which provides an interesting contrast to the typical
requester-centric view of the value of labor on crowdsourcing platforms. Our
results reveal that the students (N=106) perceived the crowdsourced design
feedback as inferior to peer design feedback in multiple ways. However, they
also identified various positive aspects of the online crowds that peers cannot
provide. We discuss the meaning of the findings and provide suggestions for
teachers in HCI and other researchers interested in crowd feedback systems on
using crowds as a potential complement to peers.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 08:51:12 GMT""}]","2021-01-25"
"2101.09171","Lorenzo Giannelli Dr.","Lorenzo Giannelli","Bit Commitment in Operational Probabilistic Theories","Master thesis project. Supervisors: Prof. Giacomo Mauro D'Ariano and
  Dr. Alessandro Tosini. arXiv admin note: text overlap with arXiv:0905.3801,
  arXiv:quant-ph/0605224, arXiv:0908.1583 by other authors",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The aim of this thesis project is to investigate the bit commitment protocol
in the framework of operational probabilistic theories. In particular a careful
study is carried on the feasibility of bit commitment in the non-local boxes
theory. New aspects of the theory are also presented.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:35:35 GMT""}]","2021-01-25"
"2101.09196","Giorgi Tutberidze","G. Tutberidze","Sharp $\left( H_{p},L_{p}\right) $ type inequalities of maximal
  operators of $T$ means with respect to Vilenkin systems with monotone
  coefficients","arXiv admin note: substantial text overlap with arXiv:1504.05974,
  arXiv:1803.00627 by other authors",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove and discuss some new $\left( H_{p},L_{p}\right)$ type
inequalities of maximal operators of $T$ means with respect to the Vilenkin
systems with monotone coefficients. We also apply these inequalities to prove
strong convergence theorems of such $T$ means. We also show that these results
are the best possible in a special sense. As applications, both some well-known
and new results are pointed out.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 09:13:46 GMT""}]","2021-01-25"
"2101.09262","Manish Shrimali","Shiva Dixit, Sayantan Nag Chowdhury, Dibakar Ghosh, and Manish Dev
  Shrimali","Dynamic interaction induced explosive death",,,"10.1209/0295-5075/133/40003",,"nlin.AO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Most previous studies on coupled dynamical systems assume that all
interactions between oscillators take place uniformly in time, but in reality,
this does not necessarily reflect the usual scenario. The heterogeneity in the
timings of such interactions strongly influences the dynamical processes. Here,
we introduce a time-evolving state-space dependent coupling among an ensemble
of identical coupled oscillators, where individual units are interacting only
when the mean state of the system lies within a certain proximity of the phase
space. They interact globally with mean-field diffusive coupling in a certain
vicinity and behave like uncoupled oscillators with self-feedback in the
remaining complementary subspace. Interestingly due to this occasional
interaction, we find that the system shows an abrupt explosive transition from
oscillatory to death state. Further, in the explosive death transitions, the
oscillatory state and the death state coexist over a range of coupling
strengths near the transition point. We explore our claim using Van der pol,
FitzHughNagumo and Lorenz oscillators with dynamic mean field interaction. The
dynamic interaction mechanism can explain sudden suppression of oscillations
and concurrence of oscillatory and steady state in biological as well as
technical systems.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 18:01:40 GMT""}]","2021-05-26"
"2101.09359","Geunsik Lim","Geunsik Lim, Changwoo Min, and YoungIk Eom","Load-Balancing for Improving User Responsiveness on Multicore Embedded
  Systems",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most commercial embedded devices have been deployed with a single processor
architecture. The code size and complexity of applications running on embedded
devices are rapidly increasing due to the emergence of application business
models such as Google Play Store and Apple App Store. As a result, a
high-performance multicore CPUs have become a major trend in the embedded
market as well as in the personal computer market. Due to this trend, many
device manufacturers have been able to adopt more attractive user interfaces
and high-performance applications for better user experiences on the multicore
systems. In this paper, we describe how to improve the real-time performance by
reducing the user waiting time on multicore systems that use a partitioned
per-CPU run queue scheduling technique. Rather than focusing on naive
load-balancing scheme for equally balanced CPU usage, our approach tries to
minimize the cost of task migration by considering the importance level of
running tasks and to optimize per-CPU utilization on multicore embedded
systems. Consequently, our approach improves the real-time characteristics such
as cache efficiency, user responsiveness, and latency. Experimental results
under heavy background stress show that our approach reduces the average
scheduling latency of an urgent task by 2.3 times.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 07:30:13 GMT""}]","2021-01-26"
"2101.10127","Jean-Pierre Luminet","Jean-Pierre Luminet (Aix-Marseille Universit\'e, CNRS, Laboratoire
  d'Astrophysique de Marseille, France)","The Dark Matter Enigma","11 pages","Inference - The International Review of Science Vol. 5(3),
  September 2020",,,"physics.pop-ph astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this pedestrian approach I give my personal point of view on the various
problems posed by dark matter in the universe. After a brief historical
overview I discuss the various solutions stemming from high energy particle
physics, and the current status of experimental research on candidate particles
(WIMPS). In the absence of direct evidence, the theories can still be evaluated
by comparing their implications for the formation of galaxies, clusters and
superclusters of galaxies against astronomical observations. I conclude briefly
with the attempts to circumvent the dark matter problem by modifying the laws
of gravity.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 15:01:04 GMT""}]","2021-01-26"
"2101.10129","Shihe Yu","Shihe Yu, Yafen Liu, Pu Yang, Ruimin Ji, Guifeng Zhu Bo Zhou, Xuzhong
  Kang, Rui Yan, Yang Zou, Ye Dai","Neutronics Analysis for MSR Cell with Different Fuel Salt Channel
  Geometry",,,,,"physics.app-ph nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  The neutronic properties of Molten Salt Reactor are different from that of
traditional solid-fuel reactors due to its nuclear fuel particularity. Based
upon MCNP code, the influence of the size and shape of fuel salt channel on
neutron physics of MSR cell was studied systematically in this work. The
results show that the infinite multiplication factors increases first and then
decreases with the change of graphite cell size under the condition of given
fuel volume fraction. In the case of the same FVF and average chord length,
when the average chord length is relatively small, the k values with different
fuel salt channel shapes are in good agreement; when the average chord length
is relatively large, the k values with different fuel salt channel shapes are
greatly different. In addition, some examples of practical application of this
work are illustrated in the end, including cell selection for the core and
thermal expansion displacement analysis of the cell.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:30:35 GMT""}]","2021-01-26"
"2101.10130","Abdullah Kurkcu","Abdullah Kurkcu, Ilgin Gokasar, Onur Kalan, Alperen Timurogullari,
  Burak Altin","Insights into the Impact of COVID-19 on Bicycle Usage in Colorado
  Counties","5457 words, 6 tables, 8 figures",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronavirus, which emerged in China towards the end of 2019 and subsequently
influenced the whole world, has changed the daily lives of people to a great
extent. In many parts of the world, in both cities and rural areas, people have
been forced to stay home weeks. They have only been allowed to leave home for
fundamental needs such as food and health needs, and most started to work from
home. In this period, very few people, including essential workers, had to
leave their homes. Avoiding social contact is proven to be the best method to
reduce the spread of the novel Coronavirus. Because of the COVID-19 pandemic,
people are adapting their behavior to this new reality, and it may change the
type of public events people perform and how people go to these activities.
Consumer behaviors have been altered during the pandemic. While people try to
avoid gatherings, they also stayed away from mass transport modes and turned to
private modes of transportation more -- private cars, private taxis and
bike-sharing systems; even walking became more popular. In this study, we
attempt to analyze how the use of bicycling has changed -- pre- and
post-pandemic -- using open data sources and investigating how socio-economics
characteristics affect this change. The results showed that average income,
average education level, and total population are the most crucial variables
for the Pandemic to Transition period and the Transition to the Normalization
period.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 04:55:03 GMT""}]","2021-01-26"
"2101.10131","Yutaro Goto","Yutaro Goto, Hajime Ishihara, and Nobuhiko Yokoshi","Twisted light-induced spin-spin interaction in a chiral helimagnet",,"New J. Phys. 23 053004 (2021)","10.1088/1367-2630/abf613",,"cond-mat.mes-hall cond-mat.other physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate how the orbital angular momentum of light can
affect a chiral magnetic order. Here, we consider a metallic chiral helimagnet,
which is under stationary radiation of a resonant optical vortex beam. We
propose a novel interaction between local spins considering microscopic
interactions between an optical vortex and electrons. This vortex-induced
interaction modulates the chiral magnetic order in an entirely different way
than an external magnetic field does. Our spin modulation technique may pave a
route to create a unique topological or chiral structure for future
opto-spintronics devices.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 06:37:04 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 04:27:56 GMT""}]","2021-05-27"
"2101.10132","Brahim Hnich","Salma Chaieb and Brahim Hnich and Ali Ben Mrad","Obsolete Personal Information Update System for the Prevention of Falls
  among Elderly Patients","The article is submitted for review to the journal ""Decision Support
  Systems"" on January 19, 2021",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Falls are a common problem affecting the older adults and a major public
health issue. Centers for Disease Control and Prevention, and World Health
Organization report that one in three adults over the age of 65 and half of the
adults over 80 fall each year. In recent years, an ever-increasing range of
applications have been developed to help deliver more effective falls
prevention interventions. All these applications rely on a huge elderly
personal database collected from hospitals, mutual health, and other
organizations in caring for elderly. The information describing an elderly is
continually evolving and may become obsolete at a given moment and contradict
what we already know on the same person. So, it needs to be continuously
checked and updated in order to restore the database consistency and then
provide better service. This paper provides an outline of an Obsolete personal
Information Update System (OIUS) designed in the context of the elderly-fall
prevention project. Our OIUS aims to control and update in real-time the
information acquired about each older adult, provide on-demand consistent
information and supply tailored interventions to caregivers and fall-risk
patients. The approach outlined for this purpose is based on a polynomial-time
algorithm build on top of a causal Bayesian network representing the elderly
data. The result is given as a recommendation tree with some accuracy level. We
conduct a thorough empirical study for such a model on an elderly personal
information base. Experiments confirm the viability and effectiveness of our
OIUS.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 00:15:14 GMT""}]","2021-01-26"
"2101.10133","Pum Walters","Pum Walters, Michael Nieweg, James Watson","Learning Outcome Oriented Programmatic Assessment","11 pages (17 including references and appendices). To be published",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  This paper describes considerations behind the organisation of a third
semester BSc education. The project aims to facilitate a feedback-oriented
environment using assessment for learning and for incremental measure of
learner progress [Vleuten et al, 2012, ""A model for programmatic assessment fit
for purpose""]. Learning outcomes encourage higher order cognitive skills,
following [Biggs & Tang, 2011,""Teaching for quality learning at university:
what the student does""]. Embracing [Dochy et al. 2018, ""Creating Impact Through
Future Learning: The High Impact Learning that Lasts (HILL) Model""], several
mechanisms encourage focus and motivation.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:36:53 GMT""}]","2021-01-26"
"2101.10135","Mike Garrett","Michael A. Garrett","Expanding World Views: Can SETI expand its own horizons and that of Big
  History too?","10 pages, 5 figures, Chapter 4 of Expanding Worldviews: Astrobiology,
  Big History and Cosmic Perspectives (to be published by Springer, ed. Ian A.
  Crawford), based on a presentation made at a meeting of the same title,
  organised by Ian Crawford at Birkbeck College (19-20 September 2019)",,"10.1007/978-3-030-70482-7_5",,"physics.pop-ph","http://creativecommons.org/licenses/by/4.0/","  The Search for Extraterrestrial Intelligence (SETI) is a research activity
that started in the late 1950s, predating the arrival of ""Big History"" and
""Astrobiology"" by several decades. Many elements first developed as part of the
original SETI narrative are now incorporated in both of these emergent fields.
However, SETI still offers the widest possible perspective, since the topic
naturally leads us to consider not only the future development of our own
society but also the forward trajectories (and past histories) of many other
intelligent extraterrestrial forms. In this paper, I present a provocative view
of Big History, its rapid convergent focus on our own planet and society, its
oversimplified and incomplete view of events in cosmic history, and its limited
appreciation of how poorly we understand some aspects of the physical world.
Astrophysicists are also not spared - in particular those who wish to
understand the nature of the universe in ""splendid isolation"", only looking
outwards and upwards. SETI can help re-expand all of our horizons but the
discovery of extraterrestrial intelligence may also require its own
practitioners to abandon preconceptions of what constitutes intelligent,
sentient, thinking minds.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:45:14 GMT""}]","2021-08-04"
"2101.10838","Mehmet Ilter","Mehmet C. Ilter, Alexis A. Dowhuszko, Jyri H\""am\""al\""ainen and Risto
  Wichman","Visible light communication-based monitoring for indoor environments
  using unsupervised learning",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visible Light Communication~(VLC) systems provide not only illumination and
data communication, but also indoor monitoring services if the effect that
different events create on the received optical signal is properly tracked. For
this purpose, the Channel State Information that a VLC receiver computes to
equalize the subcarriers of the OFDM signal can be also reused to train an
Unsupervised Learning classifier. This way, different clusters can be created
on the collected CSI data, which could be then mapped into relevant events
to-be-monitored in the indoor environments, such as the presence of a new
object in a given position or the change of the position of a given object.
When compared to supervised learning algorithms, the proposed approach does not
need to add tags in the training data, simplifying notably the implementation
of the machine learning classifier. The practical validation the monitoring
approach was done with the aid of a software-defined VLC link based on OFDM, in
which a copy of the intensity modulated signal coming from a Phosphor-converted
LED was captured by a pair of Photodetectors~(PDs). The performance evaluation
of the experimental VLC-based monitoring demo achieved a positioning accuracy
in the few-centimeter-range, without the necessity of deploying a large number
of sensors and/or adding a VLC-enabled sensor on the object to-be-tracked.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:30:24 GMT""}]","2021-01-27"
"2101.10839","Rajib Biswas","Nilutpal Bora, Rajib Biswas","Spatial variation of Coda Q in Kopili fault zone of northeast India as a
  probe for heterogeneous media","17 pages, 3 figures",,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Kopili fault has been experiencing higher seismic and tectonic activity ([1],
[2]) during the recent years. These kinds of active tectonics can be inspected
by examining coda-wave attenuation and its dependence with frequency. Here, we
report spatial variation of coda attenuation of this region. The obtained
results reveal that there is velocity anomaly at depth 210-220 km as there
arises sharp changes in attenuation coefficient ({\gamma}) and frequency
parameter (n) which are supported by available data reported by other
researchers for this region.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 10:50:12 GMT""}]","2021-01-27"
"2101.10841","Yong-Goo Shin","Seung Park, Yoon-Jae Yeo, and Yong-Goo Shin","PConv: Simple yet Effective Convolutional Layer for Generative
  Adversarial Network","Submitted to journal, arXiv admin note: text overlap with
  arXiv:1911.10979",,"10.1007/s00521-021-06846-2",,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel convolutional layer, called perturbed convolution
(PConv), which focuses on achieving two goals simultaneously: improving the
generative adversarial network (GAN) performance and alleviating the
memorization problem in which the discriminator memorizes all images from a
given dataset as training progresses. In PConv, perturbed features are
generated by randomly disturbing an input tensor before performing the
convolution operation. This approach is simple but surprisingly effective.
First, to produce a similar output even with the perturbed tensor, each layer
in the discriminator should learn robust features having a small local
Lipschitz value. Second, since the input tensor is randomly perturbed during
the training procedure like the dropout in neural networks, the memorization
problem could be alleviated. To show the generalization ability of the proposed
method, we conducted extensive experiments with various loss functions and
datasets including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet. The
quantitative evaluations demonstrate that PConv effectively boosts the
performance of GAN and conditional GAN in terms of Frechet inception distance
(FID).
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 22:05:13 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 11:32:20 GMT""},{""version"":""v3"",""created"":""Sun, 7 Nov 2021 23:41:38 GMT""}]","2021-12-23"
"2101.11105","Paul Novello","Paul Novello (CEA, Inria, X), Ga\""el Po\""ette (CEA), David Lugato
  (CEA), Pietro Congedo (Inria, X)","A Taylor Based Sampling Scheme for Machine Learning in Computational
  Physics","Second Workshop on Machine Learning and the Physical Sciences
  (NeurIPS 2019), Vancouver, Canada. arXiv admin note: substantial text overlap
  with arXiv:2101.07561",,,,"physics.comp-ph math-ph math.MP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) is increasingly used to construct surrogate models for
physical simulations. We take advantage of the ability to generate data using
numerical simulations programs to train ML models better and achieve accuracy
gain with no performance cost. We elaborate a new data sampling scheme based on
Taylor approximation to reduce the error of a Deep Neural Network (DNN) when
learning the solution of an ordinary differential equations (ODE) system.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 12:56:09 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 12:48:18 GMT""}]","2021-01-29"
"2101.11469","Minsu Jang","Minsu Jang, Sangwon Seo, Dohyung Kim, Jaeyeon Lee, Jaehong Kim,
  Jun-Hwan Ahn","VOTE400(Voide Of The Elderly 400 Hours): A Speech Dataset to Study Voice
  Interface for Elderly-Care","3 pages, 7 tables",,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by/4.0/","  This paper introduces a large-scale Korean speech dataset, called VOTE400,
that can be used for analyzing and recognizing voices of the elderly people.
The dataset includes about 300 hours of continuous dialog speech and 100 hours
of read speech, both recorded by the elderly people aged 65 years or over. A
preliminary experiment showed that speech recognition system trained with
VOTE400 can outperform conventional systems in speech recognition of elderly
people's voice. This work is a multi-organizational effort led by ETRI and
MINDs Lab Inc. for the purpose of advancing the speech recognition performance
of the elderly-care robots.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:28:05 GMT""}]","2021-01-28"
"2102.04217","Rajvardhan Oak","Rajvardhan Oak and Zubair Shafiq","The Fault in the Stars: Understanding Underground Incentivized Review
  Services","This work is in submission to USENIX 2023",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Product reviews play an important role in rankings and impact customers'
purchasing decisions on e-commerce sites. There exists a thriving ecosystem of
incentivized reviews on e-commerce marketplaces -- reviews written by real
customers in exchange for free products. While some e-commerce marketplaces
themselves support incentivized review programs to solicit honest high-quality
reviews, there are parallel underground services that sellers can use to
commission fake positive reviews from real customers in exchange for free
products. Despite anecdotal reports, our understanding of how these
incentivized services operate and, crucially, how are they able to resist
takedown efforts is lacking. In this paper, we conduct a quantitative and
qualitative study of incentivized review services by infiltrating an
underground incentivized review service geared towards Amazon.com. On a dataset
of 1600 products seeking incentivized reviews, we first demonstrate the
ineffectiveness of off-the-shelf fake review detection as well as Amazon's
existing countermeasures. Through a survey of more than 70 participants of this
underground incentivized review service, we uncover fairly sophisticated
recruitment, execution, and reporting mechanisms they use to scale their
operation while resisting takedown attempts.
","[{""version"":""v1"",""created"":""Wed, 20 Jan 2021 05:30:14 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 20:06:24 GMT""},{""version"":""v3"",""created"":""Thu, 13 Oct 2022 23:00:03 GMT""}]","2022-10-17"
"2102.04301","Khaled Khleifat Dr","H.A Qaralleh, M.O. Al-Limoun, A. Khlaifat, K.M. Khleifat, N.
  Al-Tawarah, K.Y. Alsharafa, H.A. Abu-Harirah","Antibacterial and antibiofilm activities of a traditional herbal formula
  against respiratory infection causing bacteria","8 pages, 4 tables, 2 figures","Antibacterial and Antibiofilm Activities of a Traditional Herbal
  Formula against Respiratory Infection Causing Bacteria. Trop J Nat Prod Res.
  2020; 4(9):527-534","10.26538/tjnpr/v4i9.6",,"q-bio.OT","http://creativecommons.org/publicdomain/zero/1.0/","  The plants, Althaea officinalis, Tilia cordata and Psidium guaja have been
used traditionally to treat respiratory infection symptoms. Flowers of A.
officinalis and leaves of T. cordata and P. guaja have been used to treat
cough, sore throat, catarrh, oral and pharyngeal mucosa irritation. Therefore,
this study was designed to examine the antibacterial and antibiofilm effects of
these plants individually as well as in combination, as a formula against
respiratory infections causing pathogens. The tested pathogens were Extended
Spectrum Beta-Lactamase producing Escherichia coli (ESBL), Beta-Lactamase
producing Escherichia coli (BL), Beta-Lactamase producing Klebsiella pneumoniae
(BL), Beta-Lactamase producing Pseudomonas aeruginosa (BL), Enterobacter
cloacae, and Beta-Lactamase producing Staphylococcus aureus (BL). The tested
plants were extracted using ethanol and then fractionated using different
polarity solvents (hexane, ethyl acetate and water). Disc diffusion and
microdilution (Minimum Inhibitory Concentration) methods were used to evaluate
the antibacterial activity while the antibiofilm activity was tested using
crystal violet assay. The results showed that A. officinalis and T. cordata
extracts and fractions exhibited weak antibacterial activity having MIC values
ranged from 6.25 to 12.5 mg/mL. P. guaja exhibited moderate antibacterial
activity with MIC values ranged from 6.25 to 1.56 mg/mL. Combination between
these plants extracts and fractions in equal proportion provides stronger
antibacterial (with MIC values ranged from 6.25 to 0.8 mg/mL) and antibiofilm
activities (MBIC50 was 0.2 mg/mL). Therefore, this study provides a valuable
scientific knowledge to support the use of plants in combination rather than
individually.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 20:34:55 GMT""}]","2021-02-09"
"2104.14344","T. P. Singh","Abhinash Kumar Roy, Anmol Sahu and Tejinder P. Singh","Trace dynamics, and a ground state in spontaneous quantum gravity","18 pages, published in Mod. Phys. Lett. A","Modern Physics Letters A 36 (2021) 2150019","10.1142/S021773232150019X",,"physics.gen-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We have recently proposed a Lagrangian in trace dynamics, to describe a
possible unification of gravity, Yang-Mills fields, and fermions, at the Planck
scale. This Lagrangian for the unified entity - called the aikyon - is
invariant under global unitary transformations, and as a result possesses a
novel conserved charge, known as the Adler-Millard charge. In the present
paper, we derive an eigenvalue equation, analogous to the time-independent
Schr\""{o}dinger equation, for the Hamiltonian of the theory. We show that in
the emergent quantum theory, the energy eigenvalues of the aikyon are
characterised in terms of a fundamental frequency times Planck's constant. The
eigenvalues of this equation can, in principle, determine the values of the
parameters of the standard model. We also report a ground state, in this theory
of spontaneous quantum gravity, which could characterise a non-singular initial
epoch in quantum cosmology.
","[{""version"":""v1"",""created"":""Tue, 19 Jan 2021 16:29:15 GMT""}]","2021-05-24"

"2101.09179","Sitabhra Sinha","Chandrashekar Kuyyamudi, Shakti N. Menon and Sitabhra Sinha","Contact-mediated cellular communication supplements positional
  information to regulate spatial patterning during development","6 pages, 3 figures + 6 pages Supplementary Information","Phys. Rev. E 103, 062409 (2021)","10.1103/PhysRevE.103.062409",,"q-bio.TO nlin.PS physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Development in multi-cellular organisms is marked by a high degree of spatial
organization of the cells attaining distinct fates in the embryo. We show that
receptor-ligand interaction between cells in close physical proximity
adaptively regulates the local process of selective gene expression in the
presence of a global field set up by a diffusing morphogen that provides
positional cues. This allows information from the cellular neighborhood to be
incorporated into the emergent thresholds of morphogen concentration that
dictate cell fate, consistent with recent experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:03:36 GMT""}]","2021-06-30"
"2101.09180","Zhonggang Zeng","Zhonggang Zeng","A Newton's Iteration Converges Quadratically to Nonisolated Solutions
  Too",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The textbook Newton's iteration is practically inapplicable on solutions of
nonlinear systems with singular Jacobians. By a simple modification, a novel
extension of Newton's iteration regains its local quadratic convergence toward
nonisolated solutions that are semiregular as properly defined regardless of
whether the system is square, underdetermined or overdetermined while Jacobians
can be rank-deficient. Furthermore, the iteration serves as a regularization
mechanism for computing singular solutions from empirical data. When a system
is perturbed, its nonisolated solutions can be altered substantially or even
disappear. The iteration still locally converges to a stationary point that
approximates a singular solution of the underlying system with an error bound
in the same order of the data accuracy. Geometrically, the iteration
approximately approaches the nearest point on the solution manifold. The method
simplifies the modeling of nonlinear systems by permitting nonisolated
solutions and enables a wide range of applications in algebraic computation.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:04:02 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 04:35:21 GMT""},{""version"":""v3"",""created"":""Fri, 30 Dec 2022 03:27:54 GMT""}]","2023-01-02"
"2101.09181","Namig Guliyev","Namig J. Guliyev, Vugar E. Ismailov","Approximation capability of two hidden layer feedforward neural networks
  with fixed weights","13 pages, 3 figures; this article uses the algorithm from
  arXiv:1708.06219; for associated SageMath worksheet, see
  https://sites.google.com/site/njguliyev/papers/tlfn","Neurocomputing, 316 (2018), 262-269","10.1016/j.neucom.2018.07.075",,"cs.NE cs.IT cs.NA math.IT math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We algorithmically construct a two hidden layer feedforward neural network
(TLFN) model with the weights fixed as the unit coordinate vectors of the
$d$-dimensional Euclidean space and having $3d+2$ number of hidden neurons in
total, which can approximate any continuous $d$-variable function with an
arbitrary precision. This result, in particular, shows an advantage of the TLFN
model over the single hidden layer feedforward neural network (SLFN) model,
since SLFNs with fixed weights do not have the capability of approximating
multivariate functions.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:04:35 GMT""}]","2021-01-25"
"2101.09182","Mustapha Ziane","Mustapha Ziane and Morad El Baz","On the negativity of the Wigner function as a measure of entanglement
  under quantum polarization converter devices",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the behaviour of the Negativity of Wigner Function (NWF) as a
measure of entanglement in non-Gaussian states under quantum polarisation
converter devices. We analyze comparatively this quantity with other measures
of entanglement in a system prepared in a superposition of two-mode coherent
states. We show that the (WF) can be identified as a quantifier of non-Gaussian
entanglement.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:11:06 GMT""}]","2021-01-25"
"2101.09183","Sancharee Basak","Sancharee Basak and Ayanendranath Basu","The extended Bregman divergence and parametric estimation",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Minimization of suitable statistical distances~(between the data and model
densities) has proved to be a very useful technique in the field of robust
inference. Apart from the class of $\phi$-divergences of \cite{a} and \cite{b},
the Bregman divergence (\cite{c}) has been extensively used for this purpose.
However, since the data density must have a linear presence in the cross
product term of the Bregman divergence involving both the data and model
densities, several useful divergences cannot be captured by the usual Bregman
form. In this respect, we provide an extension of the ordinary Bregman
divergence by considering an exponent of the density function as the argument
rather than the density function itself. We demonstrate that many useful
divergence families, which are not ordinarily Bregman divergences, can be
accommodated within this extended description. Using this formulation, one can
develop many new families of divergences which may be useful in robust
inference. In particular, through an application of this extension, we propose
the new class of the GSB divergence family. We explore the applicability of the
minimum GSB divergence estimator in discrete parametric models. Simulation
studies as well as conforming real data examples are given to demonstrate the
performance of the estimator and to substantiate the theory developed.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:11:09 GMT""}]","2021-01-25"
"2101.09184","Michele Nazareth da Costa","M. Nazareth da Costa, R. Attux, A. Cichocki, J. M. T. Romano","Tensor-Train Networks for Learning Predictive Modeling of
  Multidimensional Data","34 pages, 16 figures",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we firstly apply the Train-Tensor (TT) networks to construct a
compact representation of the classical Multilayer Perceptron, representing a
reduction of up to 95% of the coefficients. A comparative analysis between
tensor model and standard multilayer neural networks is also carried out in the
context of prediction of the Mackey-Glass noisy chaotic time series and NASDAQ
index. We show that the weights of a multidimensional regression model can be
learned by means of TT network and the optimization of TT weights is a more
robust to the impact of coefficient initialization and hyper-parameter setting.
Furthermore, an efficient algorithm based on alternating least squares has been
proposed for approximating the weights in TT-format with a reduction of
computational calculus, providing a much faster convergence than the well-known
adaptive learning-method algorithms, widely applied for optimizing neural
networks.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:14:38 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 08:56:33 GMT""},{""version"":""v3"",""created"":""Tue, 30 Mar 2021 11:50:04 GMT""}]","2021-03-31"
"2101.09185","Vishal Bhardwaj Mr.","Vishal Bhardwaj, Niladri Banerjee, Ashok K. Ganguli and Ratnamala
  Chatterjee","Structural and transport properties of 4f electron doped Y1-x(Dy)xPdBi
  topological semi-metallic thin films","20 pages, 11 figures",,"10.1063/5.0063996",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the effect of 4f electron doping on structural, electrical and
magneto-transport properties of Dy doped half Heusler Y1-x(Dy)xPdBi (x =0, 0.2,
0.5, 1) thin films grown by pulsed laser deposition. The Dy doping leads to
lattice contraction which increases from 0% for the parent x =0 sample to
approx 1.3% for x=1 sample with increase in Dy doping. The electrical transport
measurements show a typical semi-metallic behaviour in the temperature range 3K
to 300K and a sharp drop in resistivity at low temperatures (less than 3K) for
all the samples. Magnetotransport measurements and Shubnikov de-Hass
oscillations at high magnetic fields demonstrate that for these topologically
non-trivial samples, Dy doping induced lattice contraction plays an active role
in modifying the Fermi surface, carrier concentration and the effective
electron mass. There is an uniform suppression of the onset of
superconductivity with increased Dy doping which is possibly related to the
increasing local exchange field arising from the 4f electrons in Dy. Our
results indicate that we can tune various band structure parameters of YPdBi by
f electron doping and strained thin films of Y1-x(Dy)xPdBi show surface
dominated relativistic carrier transport at low temperatures.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:15:27 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 02:34:27 GMT""}]","2021-10-04"
"2101.09187","Costantino De Angelis","Andrea Tognazzi, Kirill I. Okhlopkov, Attilio Zilli, Davide Rocco,
  Luca Fagiani, Erfan Mafakheri, Monica Bollani, Marco Finazzi, Michele
  Celebrano, Maxim R. Shcherbakov, Andrey A. Fedyanin, Costantino de Angelis","Third-harmonic light polarization control in magnetically-resonant
  silicon metasurfaces",,,"10.1364/OE.419829",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Nonlinear metasurfaces have become prominent tools for controlling and
engineering light at the nanoscale. Usually, the polarization of the total
generated third harmonic is studied. However, diffraction orders may present
different polarizations. Here, we design an high quality factor silicon
metasurface for third harmonic generation and perform back focal plane imaging
of the diffraction orders, which present a rich variety of polarization states.
Our results demonstrate the possibility of tailoring the polarization of the
generated nonlinear diffraction orders paving the way to a higher degree of
wavefront control.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:17:59 GMT""}]","2021-04-21"
"2101.09188","Jhonatan Tavori","Jhonatan Tavori and Hanoch Levy","Super-Spreaders Out, Super-Spreading In: The Effects of Infectiousness
  Heterogeneity and Lockdowns on Herd Immunity","25 pages, 6 figures",,,,"q-bio.PE cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, [8] has proposed that heterogeneity of infectiousness (and
susceptibility) across individuals in infectious diseases, plays a major role
in affecting the Herd Immunity Threshold (HIT). Such heterogeneity has been
observed in COVID-19 and is recognized as overdispersion (or
""super-spreading""). The model of [8] suggests that super-spreaders contribute
significantly to the effective reproduction factor, R, and that they are likely
to get infected and immune early in the process. Consequently, under R_0 = 3
(attributed to COVID-19), the Herd Immunity Threshold (HIT) is as low as 5%, in
contrast to 67% according to the traditional models [1, 2, 4, 10]. This work
follows up on [8] and proposes that heterogeneity of infectiousness
(susceptibility) has two ""faces"" whose mix affects dramatically the HIT: (1)
Personal-Trait-, and (2) Event-Based- Infectiousness (Susceptibility). The
former is a personal trait of specific individuals (super-spreaders) and is
nullified once those individuals are immune (as in [8]). The latter is
event-based (e.g cultural super-spreading events) and remains effective
throughout the process, even after the super-spreaders immune. We extend [8]'s
model to account for these two factors, analyze it and conclude that the HIT is
very sensitive to the mix between (1) and (2), and under R_0 = 3 it can vary
between 5% and 67%. Preliminary data from COVID-19 suggests that herd immunity
is not reached at 5%. We address operational aspects and analyze the effects of
lockdown strategies on the spread of a disease. We find that herd immunity (and
HIT) is very sensitive to the lockdown type. While some lockdowns affect
positively the disease blocking and increase herd immunity, others have adverse
effects and reduce the herd immunity.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:19:16 GMT""}]","2023-04-20"
"2101.09189","Luis Moch\'an","C. A. Ospina-Delacruz, V. Agarwal, and W. L. Moch\'an","Analytical Model for the Current Density in the Electrochemical
  Synthesis of Porous Silicon Structures with a Lateral Gradient","19 pages, 13 figures","Optical Materials, Volume 113, 110859 (2021)","10.1016/j.optmat.2021.110859",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Layered optical devices with a lateral gradient can be fabricated through
electrochemical synthesis of porous silicon (PS) using a position dependent
etching current density $\bm j(\bm r_\|)$. Predicting the local value of $\bm
j(\bm r_\|)$ and the corresponding porosity $p(\bm r_\|)$ and etching rate
$v(\bm r_\|)$ is desirable for their systematic design. We develop a simple
analytical model for the calculation of $\bm j(\bm r_\|)$ within a prism shaped
cell. Graded single layer PS samples were synthesized and their local
calibration curves $p$ vs $\bm j$ and $v$ vs $\bm j$ were obtained from our
model and their reflectance spectra. The agreement found between the
calibration curves from different samples shows that from one sample we could
obtain full calibration curves which may be used to predict, design, and
fabricate more complex non-homogeneous multilayered devices with lateral
gradients for manifold applications.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:21:22 GMT""}]","2021-02-24"
"2101.09190","Antony Orth","Antony Orth, Kathleen L. Sampson, Kayley Ting, Jonathan Boisvert,
  Chantal Paquet","Correcting ray distortion in tomographic additive manufacturing",,,"10.1364/OE.419795",,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Light-based additive manufacturing techniques enable a rapid transition from
object design to production. In these approaches, a 3D object is typically
built by successive polymerization of 2D layers in a photocurable resin. A
recently demonstrated technique, however, uses tomographic dose patterning to
establish a 3D light dose distribution within a cylindrical glass vial of
photoresin. Lensing distortion from the cylindrical vial is currently mitigated
by either an index matching bath around the print volume or a cylindrical lens.
In this work, we show that these hardware approaches to distortion correction
are unnecessary. Instead, we demonstrate how the lensing effect can be
computationally corrected by resampling the parallel-beam radon transform into
an aberrated geometry. We also demonstrate a more general application of our
computational approach by correcting for non-telecentricity inherent in most
optical projection systems. We expect that our results will underpin a more
simple and flexible class of tomographic 3D printers where deviations from the
assumed parallel-beam projection geometry are rectified computationally.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:21:23 GMT""}]","2021-04-07"
"2101.09191","Rupak Chatterjee","Anadijiban Das and Rupak Chatterjee","Discrete phase space and continuous time relativistic quantum mechanics
  II: Peano circles, hyper-tori phase cells, and fibre bundles","22 pages, 11 figures; minor typos corrected and extra comments added
  about Peano circles and quantum gravity",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The discrete phase space and continuous time representation of relativistic
quantum mechanics is further investigated here as a continuation of paper I
[1]. The main mathematical construct used here will be that of an area-filling
Peano curve. We show that the limit of a sequence of a class of Peano curves is
a Peano circle denoted as $\bar{S}^{1}_{n}$, a circle of radius $\sqrt{2n+1}$
where $n \in \{0,1,\cdots\}$. We interpret this two-dimensional Peano circle in
our framework as a phase cell inside our two-dimensional discrete phase plane.
We postulate that a first quantized Planck oscillator, being very light, and
small beyond current experimental detection, occupies this phase cell
$\bar{S}^{1}_{n}$. The time evolution of this Peano circle sweeps out a
two-dimensional vertical cylinder analogous to the world-sheet of string
theory. Extending this to three dimensional space, we introduce a
$(2+2+2)$-dimensional phase space hyper-tori $\bar{S}^{1}_{n^1} \times
\bar{S}^{1}_{n^2} \times \bar{S}^{1}_{n^3}$ as the appropriate phase cell in
the physical dimensional discrete phase space. A geometric interpretation of
this structure in state space is given in terms of product fibre bundles. We
also study free scalar Bosons in the background $[(2+2+2)+1]$-dimensional
discrete phase space and continuous time state space using the relativistic
partial difference-differential Klein-Gordon equation. The second quantized
field quantas of this system can cohabit with the tiny Planck oscillators
inside the $\bar{S}^{1}_{n^1} \times \bar{S}^{1}_{n^2} \times
\bar{S}^{1}_{n^3}$ phase cells for eternity. Finally, a generalized free second
quantized Klein-Gordon equation in a higher $[(2+2+2)N+1]$-dimensional discrete
state space is explored. The resulting discrete phase space dimension is
compared to the significant spatial dimensions of some of the popular models of
string theory.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:24:49 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 14:16:55 GMT""}]","2021-11-05"
"2101.09192","Sadegh Pouriyan Zadeh","Dariush Bahrami, Sadegh Pouriyan Zadeh","Gravity Optimizer: a Kinematic Approach on Optimization in Deep Learning",,,,,"cs.LG cs.AI math.OC","http://creativecommons.org/licenses/by/4.0/","  We introduce Gravity, another algorithm for gradient-based optimization. In
this paper, we explain how our novel idea change parameters to reduce the deep
learning model's loss. It has three intuitive hyper-parameters that the best
values for them are proposed. Also, we propose an alternative to moving
average. To compare the performance of the Gravity optimizer with two common
optimizers, Adam and RMSProp, five standard datasets were trained on two VGGNet
models with a batch size of 128 for 100 epochs. Gravity hyper-parameters did
not need to be tuned for different models. As will be explained more in the
paper, to investigate the direct impact of the optimizer itself on loss
reduction no overfitting prevention technique was used. The obtained results
show that the Gravity optimizer has more stable performance than Adam and
RMSProp and gives greater values of validation accuracy for datasets with more
output classes like CIFAR-100 (Fine).
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:27:34 GMT""}]","2021-01-25"
"2101.09193","Petra Bevandi\'c","Petra Bevandi\'c, Ivan Kre\v{s}o, Marin Or\v{s}i\'c, Sini\v{s}a
  \v{S}egvi\'c","Dense outlier detection and open-set recognition based on training with
  noisy negative images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolutional models often produce inadequate predictions for inputs
foreign to the training distribution. Consequently, the problem of detecting
outlier images has recently been receiving a lot of attention. Unlike most
previous work, we address this problem in the dense prediction context in order
to be able to locate outlier objects in front of in-distribution background.
Our approach is based on two reasonable assumptions. First, we assume that the
inlier dataset is related to some narrow application field (e.g.~road driving).
Second, we assume that there exists a general-purpose dataset which is much
more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels
from the general-purpose dataset as noisy negative training samples since most
(but not all) of them are outliers. We encourage the model to recognize borders
between known and unknown by pasting jittered negative patches over inlier
training images. Our experiments target two dense open-set recognition
benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition
dataset (StreetHazard). Extensive performance evaluation indicates competitive
potential of the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:31:36 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 17:08:29 GMT""}]","2022-02-08"
"2101.09194","Nathan Cooper","Nathan Cooper, Carlos Bernal-C\'ardenas, Oscar Chaparro, Kevin Moran,
  Denys Poshyvanyk","It Takes Two to Tango: Combining Visual and Textual Information for
  Detecting Duplicate Video-Based Bug Reports","13 pages and 1 figure. Published at ICSE'21",,,,"cs.SE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a bug manifests in a user-facing application, it is likely to be exposed
through the graphical user interface (GUI). Given the importance of visual
information to the process of identifying and understanding such bugs, users
are increasingly making use of screenshots and screen-recordings as a means to
report issues to developers. However, when such information is reported en
masse, such as during crowd-sourced testing, managing these artifacts can be a
time-consuming process. As the reporting of screen-recordings in particular
becomes more popular, developers are likely to face challenges related to
manually identifying videos that depict duplicate bugs. Due to their graphical
nature, screen-recordings present challenges for automated analysis that
preclude the use of current duplicate bug report detection techniques. To
overcome these challenges and aid developers in this task, this paper presents
Tango, a duplicate detection technique that operates purely on video-based bug
reports by leveraging both visual and textual information. Tango combines
tailored computer vision techniques, optical character recognition, and text
retrieval. We evaluated multiple configurations of Tango in a comprehensive
empirical evaluation on 4,860 duplicate detection tasks that involved a total
of 180 screen-recordings from six Android apps. Additionally, we conducted a
user study investigating the effort required for developers to manually detect
duplicate video-based bug reports and compared this to the effort required to
use Tango. The results reveal that Tango's optimal configuration is highly
effective at detecting duplicate video-based bug reports, accurately ranking
target duplicate videos in the top-2 returned results in 83% of the tasks.
Additionally, our user study shows that, on average, Tango can reduce developer
effort by over 60%, illustrating its practicality.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:36:19 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 16:55:22 GMT""}]","2021-02-08"
"2101.09195","Xinran Li","Devin Caughey, Allan Dafoe, Xinran Li, Luke Miratrix","Randomization Inference beyond the Sharp Null: Bounded Null Hypotheses
  and Quantiles of Individual Treatment Effects",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomization (a.k.a. permutation) inference is typically interpreted as
testing Fisher's ""sharp"" null hypothesis that all effects are exactly zero.
This hypothesis is often criticized as uninteresting and implausible. We show,
however, that many randomization tests are also valid for a ""bounded"" null
hypothesis under which effects are all negative (or positive) for all units but
otherwise heterogeneous. The bounded null is closely related to important
concepts such as monotonicity and Pareto efficiency. Inverting tests of this
hypothesis yields confidence intervals for the maximum (or minimum) individual
treatment effect. We then extend randomization tests to infer other quantiles
of individual effects, which can be used to infer the proportion of units with
effects larger (or smaller) than any threshold. The proposed confidence
intervals for all quantiles of individual effects are simultaneously valid, in
the sense that no correction due to multiple analyses is needed. In sum, we
provide a broader justification for Fisher randomization tests, and develop
exact nonparametric inference for quantiles of heterogeneous individual
effects. We illustrate our methods with simulations and applications, where we
find that Stephenson rank statistics often provide the most informative
results.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:39:06 GMT""}]","2021-01-25"
"2101.09197","Jennifer Pohle","Jennifer Pohle, Timo Adam and Larissa T. Beumer","Flexible estimation of the state dwell-time distribution in hidden
  semi-Markov models","Main manuscript with 16 pages and supplementary material with 6 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hidden semi-Markov models generalise hidden Markov models by explicitly
modelling the time spent in a given state, the so-called dwell time, using some
distribution defined on the natural numbers. While the (shifted) Poisson and
negative binomial distribution provide natural choices for such distributions,
in practice, parametric distributions can lack the flexibility to adequately
model the dwell times. To overcome this problem, a penalised maximum likelihood
approach is proposed that allows for a flexible and data-driven estimation of
the dwell-time distributions without the need to make any distributional
assumption. This approach is suitable for direct modelling purposes or as an
exploratory tool to investigate the latent state dynamics. The feasibility and
potential of the suggested approach is illustrated by modelling muskox
movements in northeast Greenland using GPS tracking data. The proposed method
is implemented in the R-package PHSMM which is available on CRAN.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:41:02 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 08:19:52 GMT""}]","2021-02-17"
"2101.09201","Gernot Gruber","G. Gruber (1), C. Urgell (1), A. Tavernarakis (1), A. Stavrinadis (1),
  S. Tepsic (1), C. Magen (2 and 3), S. Sangiao (2 and 3), J. M. de Teresa (2
  and 3), P. Verlot (4), A. Bachtold (1) ((1) ICFO, Castelldefels (Barcelona),
  Spain, (2) ICMA, Universidad de Zaragoza, Zaragoza, Spain, (3) LMA,
  Universidad de Zaragoza, Zaragoza, Spain, (4) School of Physics and
  Astronomy, The University of Nottingham, Nottingham, United Kingdom)","Mass sensing for the advanced fabrication of nanomechanical resonators","Published in Nano Letters","Nano Letters 19 (2019) 6987-6992","10.1021/acs.nanolett.9b02351",,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report on a nanomechanical engineering method to monitor matter growth in
real time via e-beam electromechanical coupling. This method relies on the
exceptional mass sensing capabilities of nanomechanical resonators. Focused
electron beam induced deposition (FEBID) is employed to selectively grow
platinum particles at the free end of singly clamped nanotube cantilevers. The
electron beam has two functions: it allows both to grow material on the
nanotube and to track in real time the deposited mass by probing the
noise-driven mechanical resonance of the nanotube. On the one hand, this
detection method is highly effective as it can resolve mass deposition with a
resolution in the zeptogram range; on the other hand, this method is simple to
use and readily available to a wide range of potential users, since it can be
operated in existing commercial FEBID systems without making any modification.
The presented method allows to engineer hybrid nanomechanical resonators with
precisely tailored functionality. It also appears as a new tool for studying
growth dynamics of ultra-thin nanostructures, opening new opportunities for
investigating so far out-of-reach physics of FEBID and related methods.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:42:06 GMT""}]","2021-01-25"
"2101.09202","Zeeshan Saeed","Zeeshan Saeed and Christian Maria Firrone and Teresa Maria Berruti","Joint Identification through Hybrid Models Improved by Correlations","42 pages. Post-print (accepted author's manuscript) submitted to
  Elsevier's Journal of Sound and Vibration","Journal of Sound and Vibration Journal of Sound and Vibration,
  Volume 494, 3 March 2021, 115889","10.1016/j.jsv.2020.115889",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In mechanical systems coupled with joints, accurate prediction of the joint
characteristics is extremely important. Despite years of research, a lot is yet
to be learnt about the joints' interface dynamics. The problem becomes even
more difficult when the interface Degrees-of-Freedom (DoF) are inaccessible for
Frequency Response Function (FRF) measurements. This is, for example, the case
of bladed-disk systems with dove-tail or fir-tree type joints. Therefore, an
FRF based expansion method called System Equivalent Model Mixing (SEMM) is used
to obtain expanded interface dynamics. The method uses numerical and
experimental sub-models of each component and their assembly to produce the
respective expanded or hybrid sub-models. By applying substructure decoupling
to these sub-models, the joint can be identified. However, the joint can be
noisy due to expansion and measurement errors which propagate to the hybrid
sub-models. In this paper, a correlation based approach is proposed in the SEMM
method wherein the quality of the expanded sub-models is improved. In this new
approach, several expanded models are generated systematically using different
combinations of the experimental FRFs and computing a parameter, Frequency
Response Assurance Criteria (FRAC), to evaluate quality of the contribution of
the different measurements. The lowest correlated channels or FRFs can be
filtered out based on a certain threshold value of FRAC. Using the improved
hybrid sub-models, the joint identification also shows a remarkable
improvement. The test object for the method is an assembly of disk and one
blade with a dove-tail joint.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:42:48 GMT""}]","2021-01-25"
"2101.09203","Hans Christian \""Ottinger","Hans Christian \""Ottinger","Coordinate conditions and field equations for pure composite gravity","12 pages, 2 figures",,,,"gr-qc math-ph math.MP physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Whenever an alternative theory of gravity is formulated in a background
Minkowski space, the conditions characterizing admissible coordinate systems,
in which the alternative theory of gravity may be applied, play an important
role. We here propose Lorentz covariant coordinate conditions for the composite
theory of pure gravity developed from the Yang-Mills theory based on the
Lorentz group, thereby completing this previously proposed higher derivative
theory of gravity. The physically relevant static isotropic solutions are
determined by various methods, the high-precision predictions of general
relativity are reproduced, and an exact black-hole solution with mildly
singular behavior is found.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:48:02 GMT""}]","2021-01-25"
"2101.09207","Fabian Otto","Fabian Otto, Philipp Becker, Ngo Anh Vien, Hanna Carolin Ziesche, and
  Gerhard Neumann","Differentiable Trust Region Layers for Deep Reinforcement Learning","Accepted at ICLR 2021, camera ready version",,,,"cs.LG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trust region methods are a popular tool in reinforcement learning as they
yield robust policy updates in continuous and discrete action spaces. However,
enforcing such trust regions in deep reinforcement learning is difficult.
Hence, many approaches, such as Trust Region Policy Optimization (TRPO) and
Proximal Policy Optimization (PPO), are based on approximations. Due to those
approximations, they violate the constraints or fail to find the optimal
solution within the trust region. Moreover, they are difficult to implement,
often lack sufficient exploration, and have been shown to depend on seemingly
unrelated implementation choices. In this work, we propose differentiable
neural network layers to enforce trust regions for deep Gaussian policies via
closed-form projections. Unlike existing methods, those layers formalize trust
regions for each state individually and can complement existing reinforcement
learning algorithms. We derive trust region projections based on the
Kullback-Leibler divergence, the Wasserstein L2 distance, and the Frobenius
norm for Gaussian distributions. We empirically demonstrate that those
projection layers achieve similar or better results than existing methods while
being almost agnostic to specific implementation choices. The code is available
at https://git.io/Jthb0.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:52:06 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 08:44:43 GMT""}]","2021-03-10"
"2101.09208","Kaveh Eftekharinasab","Kaveh Eftekharinasab","Some applications of transversality for infinite dimensional manifolds",,"Proceedings of the International Geometry Center, Vol. 14, No. 121
  (2021) 137-153","10.15673/tmgc.v14i2.1939",,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We present some transversality results for a category of Fr\'{e}chet
manifolds, the so-called $MC^k$-Fr\'{e}chet manifolds. In this context, we
apply the obtained transversality results to construct the degree of nonlinear
Fredholm mappings by virtue of which we prove a rank theorem, an invariance of
domain theorem and a Bursuk-Ulam type theorem.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:52:59 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 19:45:19 GMT""}]","2021-10-01"
"2101.09209","Rico Visser","Rico G. Visser, Joanna Dr\k{a}\.zkowska, Carsten Dominik","The radial structure of planetary bodies formed by the streaming
  instability","15 pages, accepted in A&A on January 21, 2021","A&A 647, A126 (2021)","10.1051/0004-6361/202039769",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comets and small planetesimals are believed to contain primordial building
blocks in the form of millimeter to centimeter sized pebbles. One of the viable
growing mechanisms to form these small bodies is through the streaming
instability (SI) in which pebbles cluster and gravitationally collapse towards
a planetesimal or comet in the presence of gas drag. However, most SI
simulations are global and lack the resolution to follow the final collapse
stage of a pebble cloud within its Hill radius. We aim to track the collapse of
a gravitationally bound pebble cloud subject to mutual collisions and gas drag
with the representative particle approach. We determine the radial pebble size
distribution of the collapsed core and the impact of mutual pebble collisions
on the pebble size distribution. We find that virial equilibrium is never
reached during the cloud evolution and that, in general, pebbles with given
Stokes number (St) collapse towards an optically thick core in a sequence from
aerodynamically largest to aerodynamically smallest. We show that at the
location for which the core becomes optically thick, the terminal velocity is
well below the fragmentation threshold velocity. While collisional processing
is negligible during cloud evolution, the collisions that do occur are
sticking. These results support the observations that comets and small
planetary bodies are composed of primordial pebbles in the milimeter to
centimeter size range
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:53:00 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 12:59:47 GMT""}]","2021-03-24"
"2101.09210","Bedangadas Mohanty Dr.","Bedangadas Mohanty and Nu Xu","QCD Critical Point and High Baryon Density Matter","10 pages, 6 figures and Presented at workshop on ""Criticality in QCD
  and the Hadron Resonance Gas"", Wroclaw (online), July 29-31, 2020. arXiv
  admin note: text overlap with arXiv:2009.03006",,,,"nucl-ex hep-ex hep-ph nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  We report the latest results on the search for the QCD critical point in the
QCD phase diagram through high energy heavy-ion collisions. The measurements
discussed are based on the higher moments of the net-proton multiplicity
distributions in heavy-ion collisions. A non-monotonic variation in the product
of kurtosis times the variance of the net-proton distribution is observed as a
function of the collision energy with 3$\sigma$ significance. We also discuss
the results of the thermal model in explaining the measured particle yield
ratios in heavy-ion collisions and comparison of the different variants of
hardon resonance gas model calculation to the data on higher moments of
net-proton distributions. We end with a note that the upcoming programs in high
baryon density regime at various experimental facilities will complete the
search for the QCD critical point through heavy-ion collisions.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:53:51 GMT""}]","2021-01-25"
"2101.09211","Chunhao Liang","Chunhao Liang, Sergey A. Ponomarenko, Fei Wang and Yangjian Cai","Temporal boundary solitons and extreme super-thermal light statistics",,"Phys. Rev. Lett. 127, 053901 (2021)","10.1103/PhysRevLett.127.053901",,"physics.optics nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discover the formation of a temporal boundary soliton (TBS) in the close
proximity of a temporal boundary, moving in a nonlinear optical medium, upon
high-intensity pulse collision with the boundary. We show that the TBS
excitation causes giant intensity fluctuations in reflection (transmission)
from (through) the temporal boundary even for very modest input pulse intensity
fluctuations. We advance a statistical theory of the phenomenon and show that
the TBS emerges as an extremely rare event in a nonintegrable nonlinear system,
heralded by colossal intensity fluctuations with unprecedented magnitudes of
the normalized intensity autocorrelation function of the reflected/transmitted
pulse ensemble.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:54:06 GMT""}]","2021-08-04"
"2101.09212","V. Balaji","V. Balaji, Y. Pandey","On a ""Wonderful"" Bruhat-Tits group scheme","In the revised version, most of Section 3 is rewritten for accuracy.
  The main Theorems remain the same",,,,"math.RT math.AG","http://creativecommons.org/licenses/by/4.0/","  In this note we make a universal construction of Bruhat-Tits group scheme on
wonderful embeddings of adjoint groups in the absolute and relative settings
and of adjoint Kac-Moody groups. These have natural classifying properties
reflecting the orbit structure on the wonderful embeddings.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:56:35 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 11:53:25 GMT""}]","2021-06-25"
"2101.09213","Sukadev Sahoo","P. Maji, S. Mahata, S. Biswas and S. Sahoo","Lepton polarization asymmetry in $B_(s,d)^*$ arrow ${\mu}^+ {\mu}^-$
  with new Z' couplings",,,"10.1007/s10773-022-05118-6",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the effect of non-universal $Z'$ boson on the rare leptonic decay
modes of $B_s^*$ mesons, mediated by $b arrow sll$ quark transition. Rare B
decays are sensitive to various new physics operators. As B mesons are
composite particles, such decay modes of the excited states are ideal for
probing new physics beyond the standard model. We have constrained our model
parameters from $B_(s,d)-$ {B bar(s,d)}$ mixing data to predict the lepton
polarization asymmetry of $B_(s,d)^*$ arrow ${\mu}^+ {\mu}^-$ channel. It is
found that this asymmetry deviates from its SM prediction along with the
$Z'$effect
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:56:40 GMT""}]","2022-06-22"
"2101.09214","Ni Zhan","Ni Zhan, Yijia Sun, Aman Jakhar, He Liu","Graphical Models for Financial Time Series and Portfolio Selection","Published at ACM International Conference on AI in Finance (ICAIF
  '20)",,,,"cs.LG q-fin.CP","http://creativecommons.org/licenses/by/4.0/","  We examine a variety of graphical models to construct optimal portfolios.
Graphical models such as PCA-KMeans, autoencoders, dynamic clustering, and
structural learning can capture the time varying patterns in the covariance
matrix and allow the creation of an optimal and robust portfolio. We compared
the resulting portfolios from the different models with baseline methods. In
many cases our graphical strategies generated steadily increasing returns with
low risk and outgrew the S&P 500 index. This work suggests that graphical
models can effectively learn the temporal dependencies in time series data and
are proved useful in asset management.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:56:54 GMT""}]","2021-01-25"
"2101.09215","James Mason","James Paul Mason, Phillip C. Chamberlin, Daniel Seaton, Joan
  Burkepile, Robin Colaninno, Karin Dissauer, Francis G. Eparvier, Yuhong Fan,
  Sarah Gibson, Andrew R. Jones, Christina Kay, Michael Kirk, Richard Kohnert,
  W. Dean Pesnell, Barbara J. Thompson, Astrid M. Veronig, Matthew J. West,
  David Windt, Thomas N. Woods","SunCET: A compact EUV instrument to fill a critical observational gap","22 pages, 12 figures, 5 tables, in press at Journal of Space Weather
  and Space Climate special issue called ""Space Weather Instrumentation""",,,,"astro-ph.SR astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Sun Coronal Ejection Tracker (SunCET) is an extreme ultraviolet imager
and spectrograph instrument concept for tracking coronal mass ejections through
the region where they experience the majority of their acceleration: the
difficult-to-observe middle corona. It contains a wide field of view (0-4~\Rs)
imager and a 1~\AA\ spectral-resolution-irradiance spectrograph spanning
170-340~\AA. It leverages new detector technology to read out different areas
of the detector with different integration times, resulting in what we call
""simultaneous high dynamic range"", as opposed to the traditional high dynamic
range camera technique of subsequent full-frame images that are then combined
in post-processing. This allows us to image the bright solar disk with short
integration time, the middle corona with a long integration time, and the
spectra with their own, independent integration time. Thus, SunCET does not
require the use of an opaque or filtered occulter. SunCET is also compact --
$\sim$15 $\times$ 15 $\times$ 10~cm in volume -- making it an ideal instrument
for a CubeSat or a small, complementary addition to a larger mission. Indeed,
SunCET is presently in a NASA-funded, competitive Phase A as a CubeSat and has
also been proposed to NASA as an instrument onboard a 184 kg Mission of
Opportunity.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:57:55 GMT""}]","2021-01-25"
"2101.09216","Jonatan Lenells","Elliot Blackstone, Christophe Charlier, Jonatan Lenells","The Bessel kernel determinant on large intervals and Birkhoff's ergodic
  theorem","33 pages",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bessel process models the local eigenvalue statistics near $0$ of certain
large positive definite matrices. In this work, we consider the probability
\begin{align*} \mathbb{P}\Big( \mbox{there are no points in the Bessel process
on } (0,x_{1})\cup(x_{2},x_{3})\cup\cdots\cup(x_{2g},x_{2g+1}) \Big),
\end{align*} where $0<x_{1}<\cdots<x_{2g+1}$ and $g \geq 0$ is any non-negative
integer. We obtain asymptotics for this probability as the size of the
intervals becomes large, up to and including the oscillations of order $1$. In
these asymptotics, the most intricate term is a one-dimensional integral along
a linear flow on a $g$-dimensional torus, whose integrand involves ratios of
Riemann $\theta$-functions associated to a genus $g$ Riemann surface. We
simplify this integral in two generic cases: (a) If the flow is ergodic, we
compute the leading term in the asymptotics of this integral explicitly using
Birkhoff's ergodic theorem. (b) If the linear flow has certain ""good
Diophantine properties"", we obtain improved estimates on the error term in the
asymptotics of this integral. In the case when the flow is both ergodic and has
""good Diophantine properties"" (which is always the case for $g=1$, and ""almost
always"" the case for $g \geq 2$), these results can be combined, yielding
particularly precise and explicit large gap asymptotics.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:59:19 GMT""}]","2021-01-25"
"2101.09218","Federico Cacciafesta","Jonathan Ben-Artzi, Federico Cacciafesta, Anne-Sophie de Suzzoni,
  Junyong Zhang","Global Strichartz estimates for the Dirac equation on symmetric spaces","38 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study global-in-time, weighted Strichartz estimates for the
Dirac equation on warped product spaces in dimension $n\geq3$. In particular,
we prove estimates for the dynamics restricted to eigenspaces of the Dirac
operator on the compact spin manifolds defining the ambient manifold under some
explicit sufficient condition on the metric, and estimates with loss of angular
derivatives for general initial data in the setting of spherically symmetric
and asymptotically flat manifolds.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:03:56 GMT""}]","2021-01-25"
"2101.09219","Charlie Vanaret","Charlie Vanaret, Philipp Seufert, Jan Schwientek, Gleb Karpov, Gleb
  Ryzhakov, Ivan Oseledets, Norbert Asprion, Michael Bortz","Two-phase approaches to optimal model-based design of experiments: how
  many experiments and which ones?",,"Computers & Chemical Engineering, Volume 146, March 2021, 107218","10.1016/j.compchemeng.2020.107218",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-based experimental design is attracting increasing attention in
chemical process engineering. Typically, an iterative procedure is pursued: an
approximate model is devised, prescribed experiments are then performed and the
resulting data is exploited to refine the model. To help to reduce the cost of
trial-and-error approaches, strategies for model-based design of experiments
suggest experimental points where the expected gain in information for the
model is the largest. It requires the resolution of a large nonlinear,
generally nonconvex, optimization problem, whose solution may greatly depend on
the starting point. We present two discretization strategies that can assist
the experimenter in setting the number of relevant experiments and performing
an optimal selection, and we compare them against two pattern-based strategies
that are independent of the problem. The validity of the approaches is
demonstrated on an academic example and two test problems from chemical
engineering including a vapor liquid equilibrium and reaction kinetics.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:07:11 GMT""}]","2021-01-25"
"2101.09220","Masaya Fukami","Masaya Fukami, Denis R. Candido, David D. Awschalom, Michael E.
  Flatt\'e","Opportunities for long-range magnon-mediated entanglement of spin qubits
  via on- and off-resonant coupling","PRX Quantum in press, 10 pages, 5 figures","PRX Quantum 2, 040314 (2021)","10.1103/PRXQuantum.2.040314",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to manipulate entanglement between multiple spatially-separated
qubits is essential for quantum information processing. Although
nitrogen-vacancy (NV) centers in diamond provide a promising qubit platform,
developing scalable two-qubit gates remains a well-known challenge. To this
end, magnon-mediated entanglement proposals have attracted attention due to
their long-range spin-coherent propagation. Optimal device geometries and gate
protocols of such schemes, however, have yet to be determined. Here we predict
strong long-distance ($>\mu$m) NV-NV coupling via magnon modes with
cooperativities exceeding unity in ferromagnetic bar and waveguide structures.
Moreover, we explore and compare on-resonant transduction and off-resonant
virtual-magnon exchange protocols, and discuss their suitability for generating
or manipulating entangled states at low temperatures ($T\lesssim 150$ mK) under
realistic experimental conditions. This work will guide future experiments that
aim to entangle spin qubits in solids with magnon excitations.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:09:12 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 21:36:51 GMT""}]","2021-11-03"
"2101.09221","Cl\'ement Girod","C. Girod, D. LeBoeuf, A. Demuer, G. Seyfarth, S. Imajo, K. Kindo, Y.
  Kohama, M. Lizaire, A. Legros, A. Gourgout, H. Takagi, T. Kurosawa, M. Oda,
  N. Momono, J. Chang, S. Ono, G.-q. Zheng, C. Marcenat, L. Taillefer and T.
  Klein","Normal state specific heat in the cuprates La$_{2-x}$Sr$_x$CuO$_4$ and
  Bi$_{2+y}$Sr$_{2-x-y}$La$_x$CuO$_{6+\delta}$ near the critical point of the
  pseudogap phase","8 pages, 6 figures","Phys. Rev. B 103, 214506 (2021)","10.1103/PhysRevB.103.214506",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The specific heat $C$ of the cuprate superconductors La$_{2-x}$Sr$_x$CuO$_4$
and Bi$_{2+y}$Sr$_{2-x-y}$La$_x$CuO$_{6+\delta}$ was measured at low
temperature (down to $0.5~{\rm K}$), for dopings $p$ close to $p^\star$, the
critical doping for the onset of the pseudogap phase. A magnetic field up to
$35~{\rm T}$ was applied to suppress superconductivity, giving direct access to
the normal state at low temperature, and enabling a determination of $C_e$, the
electronic contribution to the normal-state specific heat, at $T \to 0$. In
La$_{2-x}$Sr$_x$CuO$_4$ at $x=p = 0.22$, $0.24$ and $0.25$, $C_e / T =
15-16~{\rm mJmol}^{-1}{\rm K}^{-2}$ at $T = 2~{\rm K}$, values that are twice
as large as those measured at higher doping ($p > 0.3$) and lower doping ($p <
0.15$). This confirms the presence of a broad peak in the doping dependence of
$C_e$ at $p^\star\simeq 0.19$, as previously reported for samples in which
superconductivity was destroyed by Zn impurities. Moreover, at those three
dopings, we find a logarithmic growth as $T \to 0$, such that $C_e / T \sim
{\rm B}\ln(T_0/T)$. The peak vs $p$ and the logarithmic dependence vs $T$ are
the two typical thermodynamic signatures of quantum criticality. In the very
different cuprate Bi$_{2+y}$Sr$_{2-x-y}$La$_x$CuO$_{6+\delta}$, we again find
that $C_e / T \sim {\rm B}\ln(T_0/T$) at $p \simeq p^\star$, strong evidence
that this $\ln(1/T)$ dependence - first discovered in the cuprates
La$_{1.8-x}$Eu$_{0.2}$Sr$_x$CuO$_4$ and La$_{1.6-x}$Nd$_{0.4}$Sr$_x$CuO$_4$ -
is a universal property of the pseudogap critical point. All four materials
display similar values of the $\rm B$ coefficient, indicating that they all
belong to the same universality class.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:10:57 GMT""}]","2021-06-16"
"2101.09223","Richard Waltrich","Richard Waltrich, Hamza Abudayyeh, Boaz Lubotzky, Elena S. Steiger,
  Konstantin G. Fehler, Niklas Lettner, Valery A. Davydov, Viatcheslav N.
  Agafonov, Ronen Rapaport, Alexander Kubanek","A Robust Coherent Single-Photon Interface for Moderate- NA Optics Based
  on SiV Center in Nanodiamonds and a Plasmonic Bullseye Antenna",,,,,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent exchange of single photons is at the heart of applied Quantum
Optics. The negatively-charged silicon vacancy center in diamond is among most
promising sources for coherent single photons. Its large Debye-Waller factor,
short lifetime and extraordinary spectral stability is unique in the field of
solid-state single photon sources. However, the excitation and detection of
individual centers requires high numerical aperture optics which, combined with
the need for cryogenic temperatures, puts technical overhead on experimental
realizations. Here, we investigate a hybrid quantum photonics platform based on
silicon-vacancy center in nanodiamonds and metallic bullseye antenna to realize
a coherent single-photon interface that operates efficiently down to low
numerical aperture optics with an inherent resistance to misalignment.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:12:28 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 09:42:02 GMT""}]","2021-02-23"
"2101.09224","Yshai Avishai","Y. Avishai and Y. B. Band","Chiral Bloch states in single layer graphene with Rashba spin-orbit
  coupling: Spectrum and spin current density","six pages five figures. arXiv admin note: text overlap with
  arXiv:2012.10971","Phys. Rev. B 104, 075414 (2021)","10.1103/PhysRevB.104.075414",,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  We study the Bloch spectrum and spin physics of 2D massless Dirac electrons
in single layer graphene subject to a one dimensional periodic Kronig-Penney
potential and Rashba spin-orbit coupling. The Klein paradox exposes novel
features in the band dispersion and in graphene spintronics. In particular it
is shown that: (1) The Bloch energy dispersion $\veps(p)$ has unusual
structure: There are {\it two Dirac points} at Bloch momenta $\pm p \ne 0$ and
a narrow band emerges between the wide valence and conduction bands. (2) The
charge current and the spin density vector vanish. (3) Yet, all the
non-diagonal elements of the spin current density tensor are finite and their
magnitude increases linearly with the spin-orbit strength. In particular, there
is a spin density current whose polarization is perpendicular to the graphene
plane. (4) The spin density currents are space-dependent, hence their
continuity equation includes a finite spin torque density.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:15:24 GMT""}]","2021-08-18"
"2101.09225","Mehmet Dedeoglu","Mehmet Dedeoglu, Sen Lin, Zhaofeng Zhang, Junshan Zhang","Continual Learning of Generative Models with Limited Data: From
  Wasserstein-1 Barycenter to Adaptive Coalescence",,,,,"cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Learning generative models is challenging for a network edge node with
limited data and computing power. Since tasks in similar environments share
model similarity, it is plausible to leverage pre-trained generative models
from the cloud or other edge nodes. Appealing to optimal transport theory
tailored towards Wasserstein-1 generative adversarial networks (WGAN), this
study aims to develop a framework which systematically optimizes continual
learning of generative models using local data at the edge node while
exploiting adaptive coalescence of pre-trained generative models. Specifically,
by treating the knowledge transfer from other nodes as Wasserstein balls
centered around their pre-trained models, continual learning of generative
models is cast as a constrained optimization problem, which is further reduced
to a Wasserstein-1 barycenter problem. A two-stage approach is devised
accordingly: 1) The barycenters among the pre-trained models are computed
offline, where displacement interpolation is used as the theoretic foundation
for finding adaptive barycenters via a ""recursive"" WGAN configuration; 2) the
barycenter computed offline is used as meta-model initialization for continual
learning and then fast adaptation is carried out to find the generative model
using the local samples at the target edge node. Finally, a weight
ternarization method, based on joint optimization of weights and threshold for
quantization, is developed to compress the generative model further.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:15:39 GMT""}]","2021-01-25"
"2101.09226","Hermann Schulz-Baldes","Nora Doll, Hermann Schulz-Baldes","Skew localizer and $\mathbb{Z}_2$-flows for real index pairings","numerous minor corrections, added references, to appear in Adv. Math",,,,"math-ph math.KT math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real index pairings of projections and unitaries on a separable Hilbert space
with a real structure are defined when the projections and unitaries fulfill
symmetry relations invoking the real structure, namely projections can be real,
quaternionic, even or odd Lagrangian and unitaries can be real, quaternionic,
symmetric or anti-symmetric. There are $64$ such real index pairings of real
$K$-theory with real $K$-homology. For $16$ of them, the Noether index of the
pairing vanishes, but there is a secondary $\mathbb{Z}_2$-valued invariant. The
first set of results provides index formulas expressing each of these $16$
$\mathbb{Z}_2$-valued pairings as either an orientation flow or a half-spectral
flow. The second and main set of results constructs the skew localizer for a
pairing stemming from a Fredholm module and shows that the
$\mathbb{Z}_2$-invariant can be computed as the sign of its Pfaffian and in $8$
of the cases as the sign of the determinant of its off-diagonal entry. This is
of relevance for the numerical computation of invariants of topological
insulators.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:16:13 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 19:06:45 GMT""}]","2021-08-17"
"2101.09227","Sriram Rao","Sriram Rao, Ashish Mahabal, Niyanth Rao, and Cauligi Raghavendra","Nigraha: Machine-learning based pipeline to identify and evaluate planet
  candidates from TESS","15 pages, 18 figures, and 6 tables. Accepted for publication as a
  full paper in Monthly Notices of the Royal Astronomical Society","journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {502}, number = {2}, pages = {2845-2858}, year = {2021}, month =
  {01}, issn = {0035-8711},","10.1093/mnras/stab203",,"astro-ph.EP astro-ph.IM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Transiting Exoplanet Survey Satellite (TESS) has now been operational for
a little over two years, covering the Northern and the Southern hemispheres
once. The TESS team processes the downlinked data using the Science Processing
Operations Center pipeline and Quick Look pipeline to generate alerts for
follow-up. Combined with other efforts from the community, over two thousand
planet candidates have been found of which tens have been confirmed as planets.
We present our pipeline, Nigraha, that is complementary to these approaches.
Nigraha uses a combination of transit finding, supervised machine learning, and
detailed vetting to identify with high confidence a few planet candidates that
were missed by prior searches. In particular, we identify high signal to noise
ratio (SNR) shallow transits that may represent more Earth-like planets. In the
spirit of open data exploration we provide details of our pipeline, release our
supervised machine learning model and code as open source, and make public the
38 candidates we have found in seven sectors. The model can easily be run on
other sectors as is. As part of future work we outline ways to increase the
yield by strengthening some of the steps where we have been conservative and
discarded objects for lack of a datum or two.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:17:54 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 14:04:53 GMT""}]","2021-02-23"
"2101.09228","Dmitri Panyushev I","Dmitri I. Panyushev","Nilpotent orbits and mixed gradings of semisimple Lie algebras","23 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\sigma$ be an involution of a complex semisimple Lie algebra $\mathfrak
g$ and $\mathfrak g=\mathfrak g_0\oplus\mathfrak g_1$ the related $\mathbb
Z_2$-grading. We study relations between nilpotent $G_0$-orbits in $\mathfrak
g_0$ and the respective $G$-orbits in $\mathfrak g$. If $e\in\mathfrak g_0$ is
nilpotent and $\{e,h,f\}\subset\mathfrak g_0$ is an $\mathfrak{sl}_2$-triple,
then the semisimple element $h$ yields a $\mathbb Z$-grading of $\mathfrak g$.
Our main tool is the combined $\mathbb Z\times\mathbb Z_2$-grading of
$\mathfrak g$, which is called a mixed grading. We prove, in particular, that
if $e_\sigma$ is a regular nilpotent element of $\mathfrak g_0$, then the
weighted Dynkin diagram of $e_\sigma$, $\mathcal D(e_\sigma)$, has only
isolated zeros. It is also shown that if $G{\cdot}e_\sigma\cap\mathfrak
g_1\ne\varnothing$, then the Satake diagram of $\sigma$ has only isolated black
nodes and these black nodes occur among the zeros of $\mathcal D(e_\sigma)$.
Using mixed gradings related to $e_\sigma$, we define an inner involution
$\check\sigma$ such that $\sigma$ and $\check\sigma$ commute. Here we prove
that the Satake diagrams for both $\check\sigma$ and $\sigma\check\sigma$ have
isolated black nodes.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:20:03 GMT""}]","2021-01-25"
"2101.09229","Sven-Torben Stahn","Sven-Torben Stahn","Periodic self maps and thick ideals in the stable motivic homotopy
  category over $\mathbb{C}$ at odd primes",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we study thick ideals defined by periodic self maps in the
stable motivic homotopy category over $\mathbb{C}$. In addition, we extend some
results of Ruth Joachimi about the relation between thick ideals defined by
motivic Morava K-theories and the preimages of the thick ideals in the stable
homotopy category under Betti realization.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:21:38 GMT""}]","2021-01-25"
"2101.09230","Ni Zhan","Ni Zhan","Where does the Stimulus go? Deep Generative Model for Commercial Banking
  Deposits",,"NeurIPS 2020 workshop on ML for Economic Policy",,,"cs.LG econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This paper examines deposits of individuals (""retail"") and large companies
(""wholesale"") in the U.S. banking industry, and how these deposit types are
impacted by macroeconomic factors, such as quantitative easing (QE). Actual
data for deposits by holder are unavailable. We use a dataset on banks'
financial information and probabilistic generative model to predict industry
retail-wholesale deposit split from 2000 to 2020. Our model assumes account
balances arise from separate retail and wholesale lognormal distributions and
fit parameters of distributions by minimizing error between actual bank metrics
and simulated metrics using the model's generative process. We use time-series
regression to forward predict retail-wholesale deposits as function of loans,
retail loans, and reserve balances at Fed banks. We find increase in reserves
(representing QE) increases wholesale but not retail deposits, and increase in
loans increase both wholesale and retail deposits evenly. The result shows that
QE following the 2008 financial crisis benefited large companies more than
average individuals, a relevant finding for economic decision making. In
addition, this work benefits bank management strategy by providing forecasting
capability for retail-wholesale deposits.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:22:47 GMT""}]","2021-01-25"
"2101.09231","Fabio Valerio Massoli","Donato Cafarelli, Fabio Valerio Massoli, Fabrizio Falchi, Claudio
  Gennaro, Giuseppe Amato","Expression Recognition Analysis in the Wild",,,,,"cs.CV cs.HC cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Facial Expression Recognition(FER) is one of the most important topic in
Human-Computer interactions(HCI). In this work we report details and
experimental results about a facial expression recognition method based on
state-of-the-art methods. We fine-tuned a SeNet deep learning architecture
pre-trained on the well-known VGGFace2 dataset, on the AffWild2 facial
expression recognition dataset. The main goal of this work is to define a
baseline for a novel method we are going to propose in the near future. This
paper is also required by the Affective Behavior Analysis in-the-wild (ABAW)
competition in order to evaluate on the test set this approach. The results
reported here are on the validation set and are related on the Expression
Challenge part (seven basic emotion recognition) of the competition. We will
update them as soon as the actual results on the test set will be published on
the leaderboard.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:28:31 GMT""}]","2021-01-25"
"2101.09232","Yota Maeda","Yota Maeda","Modularity of special cycles on unitary Shimura varieties over CM-fields","13 pages",,"10.4064/aa210202-12-4",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the modularity of the generating series of special cycles on unitary
Shimura varieties over CM-fields of degree $2d$ associated with a Hermitian
form in $n+1$ variables whose signature is $(n,1)$ at $e$ real places and
$(n+1,0)$ at the remaining $d-e$ real places for $1\leq e <d$. For $e=1$, Liu
proved the modularity and Xia showed the absolute convergence of the generating
series. On the other hand, Bruinier constructed regularized theta lifts on
orthogonal groups over totally real fields and proved the modularity of special
divisors on orthogonal Shimura varieties. By using Bruinier's result, we work
on the problem for $e=1$ and give an another proof of Liu's proof. For $e>1$,
we prove that the generating series of special cycles of codimension $er$ in
the Chow group is a Hermitian modular form of weight $n+1$ and genus $r$,
assuming the Beilinson-Bloch conjecture with respect to orthogonal Shimura
varieties. Our result is a generalization of $\textit{Kudla's modularity
conjecture}$, solved by Liu unconditionally when $e=1$.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:31:13 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 08:45:54 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jan 2021 09:37:56 GMT""},{""version"":""v4"",""created"":""Mon, 23 Aug 2021 10:13:32 GMT""}]","2022-06-09"
"2101.09233","Andrew Spieker","Andrew J. Spieker, Joseph A.C. Delaney, Robyn L. McClelland","Semi-parametric estimation of biomarker age trends with endogenous
  medication use in longitudinal data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In cohort studies, non-random medication use can pose barriers to estimation
of the natural history trend in a mean biomarker value (namely, the association
between a predictor of interest and a biomarker outcome that would be observed
in the absence of biomarker-specific treatment). Common causes of treatment and
outcomes are often unmeasured, obscuring our ability to easily account for
medication use with commonly invoked assumptions such as ignorability. Further,
absent some variable satisfying the exclusion restriction, use of instrumental
variable approaches may be difficult to justify. Heckman's hybrid model with
structural shift (sometimes referred to less specifically as the treatment
effects model) can be used to correct endogeneity bias via a homogeneity
assumption (i.e., that average treatment effects do not vary across covariates)
and parametric specification of a joint model for the outcome and treatment. In
recent work, we relaxed the homogeneity assumption by allowing observed
covariates to serve as treatment effect modifiers. While this method has been
shown to be reasonably robust in settings of cross-sectional data, application
of this methodology to settings of longitudinal data remains unexplored. We
demonstrate how the assumptions of the treatment effects model can be extended
to accommodate clustered data arising from longitudinal studies. Our proposed
approach is semi-parametric in nature in that valid inference can be obtained
without the need to specify the longitudinal correlation structure. As an
illustrative example, we use data from the Multi-Ethnic Study of
Atherosclerosis to evaluate trends in low-density lipoprotein by age and
gender. We confirm that our generalization of the treatment effects model can
serve as a useful tool to uncover natural history trends in longitudinal data
that are obscured by endogenous treatment.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:36:49 GMT""}]","2021-01-25"
"2101.09234","Kristof Bal","Kristof M. Bal","Nucleation rates from small scale atomistic simulations and transition
  state theory",,"J. Chem. Phys. 155, 144111 (2021)","10.1063/5.0063398",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The evaluation of nucleation rates from molecular dynamics trajectories is
hampered by the slow nucleation time scale and impact of finite size effects.
Here, we show that accurate nucleation rates can be obtained in a very general
fashion relying only on the free energy barrier, transition state theory (TST),
and a simple dynamical correction for diffusive recrossing. In this setup, the
time scale problem is overcome by using enhanced sampling methods, in casu
metadynamics, whereas the impact of finite size effects can be naturally
circumvented by reconstructing the free energy surface from an appropriate
ensemble. Approximations from classical nucleation theory are avoided. We
demonstrate the accuracy of the approach by calculating macroscopic rates of
droplet nucleation from argon vapor, spanning sixteen orders of magnitude and
in excellent agreement with literature results, all from simulations of very
small (512 atom) systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:39:45 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 16:57:44 GMT""},{""version"":""v3"",""created"":""Mon, 19 Apr 2021 14:46:03 GMT""},{""version"":""v4"",""created"":""Wed, 14 Jul 2021 13:31:41 GMT""},{""version"":""v5"",""created"":""Fri, 24 Sep 2021 13:53:30 GMT""}]","2021-11-03"
"2101.09235","Martin Dehn","M. H. Dehn, J. K. Shenton, D. J. Arseneau, W. A. MacFarlane, G. D.
  Morris, A. Maign\'e, N. A. Spaldin, and R. F. Kiefl","Local Electronic Structure and Dynamics of Muon-Polaron Complexes in
  Fe$_2$O$_3$",,"Phys. Rev. Lett. 126 037202 (2021)","10.1103/PhysRevLett.126.037202",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We perform detailed muon spin rotation ($\mu$SR) measurements in the classic
antiferromagnet Fe$_2$O$_3$ and explain the spectra by considering dynamic
population and dissociation of charge-neutral muon-polaron complexes. We show
that charge-neutral muon states in Fe$_2$O$_3$, despite lacking the signatures
typical of charge-neutral muonium centers in nonmagnetic materials, have a
significant impact on the measured $\mu$SR frequencies and relaxation rates.
Our identification of such polaronic muon centers in Fe$_2$O$_3$ suggests that
isolated hydrogen (H) impurities form analogous complexes, and that H
interstitials may be a source of charge carrier density in Fe$_2$O$_3$.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:41:44 GMT""}]","2021-01-25"
"2101.09236","J\'er\'emy Chastenet","Jeremy Chastenet, Karin Sandstrom, I-Da Chiang, Brandon S. Hensley,
  Bruce T. Draine, Karl D. Gordon, Eric W. Koch, Adam K. Leroy, Dyas Utomo, and
  Thomas G. Williams","Benchmarking Dust Emission Models in M101","Accepted for publication in ApJ -- 28 pp (12 figures) + appendices",,"10.3847/1538-4357/abe942",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a comparative study of four physical dust models and two
single-temperature modified blackbody models by fitting them to the resolved
WISE, Spitzer, and Herschel photometry of M101 (NGC 5457). Using identical data
and a grid-based fitting technique, we compare the resulting dust and radiation
field properties derived from the models. We find that the dust mass yielded by
the different models can vary by up to factor of 3 (factor of 1.4 between
physical models only), although the fits have similar quality. Despite
differences in their definition of the carriers of the mid-IR aromatic
features, all physical models show the same spatial variations for the
abundance of that grain population. Using the well determined metallicity
gradient in M101 and resolved gas maps, we calculate an approximate upper limit
on the dust mass as a function of radius. All physical dust models are found to
exceed this maximum estimate over some range of galactocentric radii. We show
that renormalizing the models to match the same Milky Way high latitude cirrus
spectrum and abundance constraints can reduce the dust mass differences between
models and bring the total dust mass below the maximum estimate at all radii.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:42:15 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 15:40:21 GMT""}]","2021-05-19"
"2101.09237","Alexey Tikan","Kenichi Komagata, Alexey Tikan, Aleksandr Tusnin, Johann
  Riemensberger, Mikhail Churaev, Hairun Guo, Tobias J. Kippenberg","Dissipative Kerr solitons in a photonic dimer on both sides of
  exceptional point","19 pages, 10 figures",,"10.1038/s42005-021-00661-w",,"physics.optics nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exceptional points are a ubiquitous concept widely present in
driven-dissipative coupled systems described by a non-Hermitian Hamiltonian. It
is characterized by the degeneracy of the Hamiltonian's eigenvalues and
coalescence of corresponding eigenvectors. Recent developments demonstrated
that exceptional points can play an important role in photonics. However, to
date, exceptional points have been extensively examined in the systems
supporting only a few optical modes, thereby leaving the observation of
collective (multimode) effects outside of the scope of study. In the present
paper, we analyze the role of exceptional points in nonlinear multimode
photonics. Specifically, we provide insights into complex nonlinear dynamics
arising in a continuous wave-driven pair of strongly coupled nonlinear
micro-resonators (i.e. a nonlinear photonic dimer) operating in the multimode
regime. Investigating this system, which is known to possess exceptional
points, we find two fundamentally different nonlinear regimes of operation
corresponding to effective parity-time symmetric and broken parity-time
symmetry states. We demonstrate that the photonic dimer can be critically
coupled to a bus waveguide, thereby, providing an efficient generation of the
dissipative Kerr solitons on both sides of the exceptional point. The
parity-time symmetric case, which corresponds to a pair of symmetrically split
resonances, has been recently shown to exhibit a variety of emergent phenomena
including gear soliton generation, symmetry breaking, and soliton hopping.
Dissipative solitons generation in the parity-time symmetry broken case -
leading to the dissipation splitting - up to now remains unexplored.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:45:41 GMT""}]","2022-08-17"
"2101.09238","Beyza Dabak","Beyza Dabak, Ahmed Hareedy, Alexei Ashikhmin, Robert Calderbank","Unequal Error Protection Achieves Threshold Gains on BEC and BSC via
  Higher Fidelity Messages","8 pages (double column), 3 figures, submitted to the IEEE
  International Symposium on Information Theory (ISIT)",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Because of their capacity-approaching performance, graph-based codes have a
wide range of applications, including communications and storage. In these
codes, unequal error protection (UEP) can offer performance gains with limited
rate loss. Recent empirical results in magnetic recording (MR) systems show
that extra protection for the parity bits of a low-density parity-check (LDPC)
code via constrained coding results in significant density gains. In
particular, when UEP is applied via more reliable parity bits, higher fidelity
messages of parity bits are spread to all bits by message passing algorithm,
enabling performance gains. Threshold analysis is a tool to measure the
effectiveness of a graph-based code or coding scheme. In this paper, we provide
a theoretical analysis of this UEP idea using extrinsic information transfer
(EXIT) charts in the binary erasure channel (BEC) and the binary symmetric
channel (BSC). We use EXIT functions to investigate the effect of change in
mutual information of parity bits on the overall coding scheme. We propose a
setup in which parity bits of a repeat-accumulate (RA) LDPC code have lower
erasure or crossover probabilities than input information bits. We derive the
a-priori and extrinsic mutual information functions for check nodes and
variable nodes of the code. After applying our UEP setup to the information
functions, we formulate a linear programming problem to find the optimal degree
distribution that maximizes the code rate under the decoding convergence
constraint. Results show that UEP via higher fidelity parity bits achieves up
to about $17\%$ and $28\%$ threshold gains on BEC and BSC, respectively.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:46:42 GMT""}]","2021-01-25"
"2101.09239","Li Ge","Jose D. H. Rivero and Li Ge","Pseudo-chirality: a manifestation of Noether's theorem in non-Hermitian
  systems","5 pages, 3 figures, with separate Supplemental Materials","Phys. Rev. Lett. 125, 083902 (2020)","10.1103/PhysRevLett.125.083902",,"quant-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Noether's theorem relates constants of motion to the symmetries of the
system. Here we investigate a manifestation of Noether's theorem in
non-Hermitian systems, where the inner product is defined differently from
quantum mechanics. In this framework, a generalized symmetry which we term
pseudo-chirality emerges naturally as the counterpart of symmetries defined by
a commutation relation in quantum mechanics. Using this observation, we reveal
previously unidentified constants of motion in non-Hermitian systems with
parity-time and chiral symmetries. We further elaborate the disparate
implications of pseudo-chirality induced constant of motion: It signals the
pair excitation of a generalized ""particle"" and the corresponding ""hole"" but
vanishes universally when the pseudo-chiral operator is anti-symmetric. This
disparity, when manifested in a non-Hermitian topological lattice with the
Landau gauge, depends on whether the lattice size is even or odd. We further
discuss previously unidentified symmetries of this non-Hermitian topological
system, and we reveal how its constant of motion due to pseudo-chirality can be
used as an indicator of whether a pure chiral edge state is excited.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:51:15 GMT""}]","2021-01-25"
"2101.09240","Tao Peng","Tao Peng, Xingchen Zhao, Yanhua Shih, and Marlan O. Scully","High order Coherence Functions and Spectral Distributions as given by
  the Quantum Theory of Laser Radiation",,,"10.3389/fphy.2021.657333",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We propose and demonstrate a method for measuring the time evolution of the
off-diagonal elements $\rho_{n,n+k}(t)$ of the reduced density matrix obtained
from the quantum theory of the laser. The decay rates of the off-diagonal
matrix element $\rho_{n,n+k}(t)$ (k=2,3) are measured for the first time and
compared with that of $\rho_{n,n+1}(t)$, which corresponds to the linewidth of
the laser. The experimental results agree with the quantum theory of the laser.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:52:19 GMT""}]","2021-04-22"
"2101.09241","Wojciech Jamroga","Wojciech Jamroga","A Survey of Requirements for COVID-19 Mitigation Strategies. Part II:
  Elicitation of Requirements",,,,,"cs.CY cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The COVID-19 pandemic has influenced virtually all aspects of our lives.
Across the world, countries have applied various mitigation strategies, based
on social, political, and technological instruments. We postulate that
multi-agent systems can provide a common platform to study (and balance) their
essential properties. We also show how to obtain a comprehensive list of the
properties by ""distilling"" them from media snippets. Finally, we present a
preliminary take on their formal specification, using ideas from multi-agent
logics.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:52:20 GMT""}]","2021-01-25"
"2101.09242","Noemi Frusciante","Noemi Frusciante","Signatures of $f(Q)$-gravity in cosmology","8 pages, 6 figures, accepted for publication in PRD",,"10.1103/PhysRevD.103.044021",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the impact on cosmological observables of $f(Q)$-gravity, a
specific class of modified gravity models in which gravity is described by the
non-metricity scalar, $Q$. In particular we focus on a specific model which is
indistinguishable from the $\Lambda$-cold-dark-matter ($\Lambda$CDM) model at
the background level, while showing peculiar and measurable signatures at
linear perturbation level. These are attributed to a time-dependent Planck mass
and are regulated by a single dimensionless parameter, $\alpha$. In comparison
to the $\Lambda$CDM model, we find for positive values of $\alpha$ a suppressed
matter power spectrum and lensing effect on the Cosmic Microwave Background
radiation (CMB) angular power spectrum and an enhanced integrated-Sachs-Wolfe
tail of CMB temperature anisotropies. The opposite behaviors are present when
the $\alpha$ parameter is negative. We also investigate the modified
Gravitational Waves (GWs) propagation and show the prediction of the GWs
luminosity distance compared to the standard electromagnetic one. Finally, we
infer the accuracy on the free parameter of the model with standard sirens at
future GWs detectors.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:53:37 GMT""}]","2021-02-24"
"2101.09243","Bruno Benedetti","Bruno Benedetti, Lisa Seccia, and Matteo Varbaro","Hamiltonian paths, unit-interval complexes, and determinantal facet
  ideals","41 pages, 5 figures; improved and extended version, with Main Theorem
  V, Lemma 48, and Corollary 81 added, plus minor corrections and
  strengthenings",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study d-dimensional generalizations of three mutually related topics in
graph theory: Hamiltonian paths, (unit) interval graphs, and binomial edge
ideals. We provide partial high-dimensional generalizations of Ore and Posa's
sufficient conditions for a graph to be Hamiltonian. We introduce a hierarchy
of combinatorial properties for simplicial complexes that generalize
unit-interval, interval, and co-comparability graphs. We connect these
properties to the already existing notions of determinantal facet ideals and
Hamiltonian paths in simplicial complexes. Some important consequences of our
work are:
  (1) Every almost-closed strongly-connected d-dimensional simplicial complex
is traceable. (This extends the well-known result ""unit-interval connected
graphs are traceable"".)
  (2) Every almost-closed d-complex that remains strongly connected after the
deletion of d or less vertices, is Hamiltonian. (This extends the fact that
""unit-interval 2-connected graphs are Hamiltonian"".)
  (3) Unit-interval complexes are characterized, among traceable complexes, by
the property that the minors defining their determinantal facet ideal form a
Groebner basis for a diagonal term order which is compatible with the
traceability of the complex. (This corrects a recent theorem by Ene et al.,
extends a result by Herzog and others, and partially answers a question by
Almousa-Vandebogert.)
  (4) Only the d-skeleton of the simplex has a determinantal facet ideal with
linear resolution. (This extends the result by Kiani and Saeedi-Madani that
""only the complete graph has a binomial edge ideal with linear resolution"".)
  (5) The determinantal facet ideals of all under-closed and semi-closed
complexes have a square-free initial ideal with respect to lex. In
characteristic p, they are even F-pure.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:54:49 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 13:10:43 GMT""}]","2021-04-13"
"2101.09244","Zitao Shen","Zitao Shen, Yoonkwon Yi, Anusha Bompelli, Fang Yu, Yanshan Wang, Rui
  Zhang","Extracting Lifestyle Factors for Alzheimer's Disease from Clinical Notes
  Using Deep Learning with Weak Supervision",,,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Since no effective therapies exist for Alzheimer's disease (AD), prevention
has become more critical through lifestyle factor changes and interventions.
Analyzing electronic health records (EHR) of patients with AD can help us
better understand lifestyle's effect on AD. However, lifestyle information is
typically stored in clinical narratives. Thus, the objective of the study was
to demonstrate the feasibility of natural language processing (NLP) models to
classify lifestyle factors (e.g., physical activity and excessive diet) from
clinical texts. We automatically generated labels for the training data by
using a rule-based NLP algorithm. We conducted weak supervision for pre-trained
Bidirectional Encoder Representations from Transformers (BERT) models on the
weakly labeled training corpus. These models include the BERT base model,
PubMedBERT(abstracts + full text), PubMedBERT(only abstracts), Unified Medical
Language System (UMLS) BERT, Bio BERT, and Bio-clinical BERT. We performed two
case studies: physical activity and excessive diet, in order to validate the
effectiveness of BERT models in classifying lifestyle factors for AD. These
models were compared on the developed Gold Standard Corpus (GSC) on the two
case studies. The PubmedBERT(Abs) model achieved the best performance for
physical activity, with its precision, recall, and F-1 scores of 0.96, 0.96,
and 0.96, respectively. Regarding classifying excessive diet, the Bio BERT
model showed the highest performance with perfect precision, recall, and F-1
scores. The proposed approach leveraging weak supervision could significantly
increase the sample size, which is required for training the deep learning
models. The study also demonstrates the effectiveness of BERT models for
extracting lifestyle factors for Alzheimer's disease from clinical notes.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:55:03 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 03:42:00 GMT""}]","2021-01-26"
"2101.09245","Sandra Carillo Prof. Dr.","Sandra Carillo, Cornelia Schiebold","B\""acklund transformations: a tool to study Abelian and non-Abelian
  nonlinear evolution equations","14 pages, 6 figures, conference FASNET 2020 (online)",,"10.1142/9781800611368_0006",,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The KdV eigenfunction equation is considered: some explicit solutions are
constructed. These, to the best of the authors' knowledge, new solutions
represent an example of the powerfulness of the method devised. Specifically,
B\""acklund transformation are applied to reveal algebraic properties enjoyed by
nonlinear evolution equations they connect. Indeed, B\""acklund transformations,
well known to represent a key tool in the study of nonlinear evolution
equations, are shown to allow the construction of a net of nonlinear links,
termed ""B\""acklund chart"", connecting Abelian as well as non Abelian equations.
The present study concerns third order nonlinear evolution equations which are
all connected to the KdV equation. In particular, the Abelian wide B\""acklund
chart connecting these nonlinear evolution equations is recalled. Then, the
links, originally established in the case of Abelian equations, are shown to
conserve their validity when non Abelian counterparts are considered. In
addition, the non-commutative case reveals a richer structure related to the
multiplicity of non-Abelian equations which correspond to the same Abelian one.
Reduction from the nc to the commutative case allow to show the connection of
the KdV equation with KdV eigenfunction equation, in the ""scalar"" case.
  Finally, recently obtained matrix solutions of the mKdV equations are
recalled.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:55:49 GMT""}]","2023-05-01"
"2101.09246","Hamid Abban","Hamid Abban and Ziquan Zhuang","Seshadri constants and K-stability of Fano manifolds","Small changes after referee report. To appear in Duke Math Journal",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We give a lower bound of the $\delta$-invariants of ample line bundles in
terms of Seshadri constants. As applications, we prove the uniform K-stability
of infinitely many families of Fano hypersurfaces of arbitrarily large index,
as well as the uniform K-stability of most families of smooth Fano threefolds
of Picard number one.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:56:55 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 10:31:30 GMT""}]","2022-04-28"
"2101.09247","Martin Campos Pinto","Martin Campos Pinto, Katharina Kormann, Eric Sonnendr\""ucker","Variational Framework for Structure-Preserving Electromagnetic
  Particle-In-Cell Methods","37 pages, 18 figures",,,,"math.NA cs.CE cs.NA math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we apply a discrete action principle for the Vlasov--Maxwell
equations in a structure-preserving particle-field discretization framework. In
this framework the finite-dimensional electromagnetic potentials and fields are
represented in a discrete de Rham sequence involving general finite element
spaces, and the particle-field coupling is represented by a set of projection
operators that commute with the differential operators. With a minimal number
of assumptions which allow for a variety of finite elements and shape functions
for the particles, we show that the resulting variational scheme has a general
discrete Poisson structure and thus leads to a semi-discrete Hamiltonian
system. By introducing discrete interior products we derive a second type of
space discretization which is momentum preserving, based on the same finite
elements and shape functions. We illustrate our method by applying it to spline
finite elements, and to a new spectral discretization where the particle-field
coupling relies on discrete Fourier transforms.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:58:31 GMT""}]","2021-01-27"
"2101.09248","Antonio Leitao","A. Leitao","Semiconductors and Dirichlet-to-Neumann maps","13 pages, 2 figures","Computational and Applied Mathematics 25 (2006), no. 2-3, 187-203","10.1590/S0101-82052006000200005",,"math.AP cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the problem of identifying discontinuous doping profiles in
semiconductor devices from data obtained by the stationary voltage-current (VC)
map. The related inverse problem correspond to the inverse problem for the
Dirichlet-to-Neumann (DN) map with partial data.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:00:06 GMT""}]","2021-01-25"
"2101.09249","Sebastian Braun","Sebastian Braun, Hannes Gamper, Chandan K.A. Reddy, Ivan Tashev","Towards efficient models for real-time deep noise suppression",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With recent research advancements, deep learning models are becoming
attractive and powerful choices for speech enhancement in real-time
applications. While state-of-the-art models can achieve outstanding results in
terms of speech quality and background noise reduction, the main challenge is
to obtain compact enough models, which are resource efficient during inference
time. An important but often neglected aspect for data-driven methods is that
results can be only convincing when tested on real-world data and evaluated
with useful metrics. In this work, we investigate reasonably small recurrent
and convolutional-recurrent network architectures for speech enhancement,
trained on a large dataset considering also reverberation. We show interesting
tradeoffs between computational complexity and the achievable speech quality,
measured on real recordings using a highly accurate MOS estimator. It is shown
that the achievable speech quality is a function of network complexity, and
show which models have better tradeoffs.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:00:39 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 12:31:27 GMT""}]","2021-05-20"
"2101.09250","Sabyasachi Pal Dr.","Manoj Mandal and Sabyasachi Pal","Detection of Low-Frequency QPO From X-ray Pulsar XTE J1858+034 During
  Outburst in 2019 with NuSTAR","7 pages, comments are welcome",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the timing properties of XTE J1858+034 using the Nuclear
Spectroscopic Telescope Array (NuSTAR) and Burst Alert Telescope onboard Swift
during the outburst in October--November 2019. We have investigated for
Quasi-Periodic Oscillation (QPO) during the outburst and detected a
low-frequency QPO at $\sim$196 mHz with $\sim$6% RMS variability from the
NuSTAR observation. The QPO is fitted and explained with the model - power law
and a Lorentzian component. We have also studied the variation of QPO frequency
with energy. The beat frequency model and Keplerian frequency model both are
suitable to explain the origin of the QPOs for the source. Regular pulsations
and QPOs are found to be stronger in high energy which suits the beat frequency
model. The variation of the hardness ratio is studied over the outburst which
does not show any significant variation.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:01:18 GMT""}]","2021-01-25"
"2101.09251","Fernando Espinoza Dr","F. Espinoza (1) Department of Physics and Astronomy, Hofstra
  University, Hempstead, NY. USA. (2) Department of Chemistry and
  Physics-Adolescence Education, SUNY Old Westbury, Old Westbury, NY. USA","How to Deal with Fake News: Visualizing Disinformation","Four figures explaining the proposed mechanism that describe wave
  properties and behavior. The quantitative details are kept to a minimum so as
  to highlight the relevance of the treatment of disinformation as a wave, to
  the larger public sphere",,,,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The current public sense of anxiety in dealing with disinformation as
manifested by so-called fake news is acutely displayed by the reaction to
recent events prompted by a belief in conspiracies among certain groups. A
model to deal with disinformation is proposed; it is based on a demonstration
of the analogous behavior of disinformation to that of wave phenomena. Two
criteria form the basis to combat the deleterious effects of disinformation:
the use of a refractive medium based on skepticism as the default mode, and
polarization as a filter mechanism to analyze its merits based on evidence.
Critical thinking is enhanced since the first one tackles the pernicious effect
of the confirmation bias, and the second the tendency towards attribution, both
of which undermine our efforts to think and act rationally. The benefits of
such a strategy include an epistemic reformulation of disinformation as an
independently existing phenomenon, that removes its negative connotations when
perceived as being possessed by groups or individuals.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:03:57 GMT""}]","2021-01-25"
"2101.09252","Marko Budi\v{s}i\'c","Aishah Albarakati, Marko Budi\v{s}i\'c, Rose Crocker, Juniper
  Glass-Klaiber, Sarah Iams, John Maclean, Noah Marshall, Colin Roberts, Erik
  S. Van Vleck","Model and Data Reduction for Data Assimilation: Particle Filters
  Employing Projected Forecasts and Data with Application to a Shallow Water
  Model","30 pages, 13 figures, 3 tables To appear in Computers & Mathematics
  with Applications, 2021,ISSN 0898-1221",,"10.1016/j.camwa.2021.05.026",,"math.DS math.OC nlin.CD physics.ao-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The understanding of nonlinear, high dimensional flows, e.g, atmospheric and
ocean flows, is critical to address the impacts of global climate change. Data
Assimilation techniques combine physical models and observational data, often
in a Bayesian framework, to predict the future state of the model and the
uncertainty in this prediction. Inherent in these systems are noise (Gaussian
and non-Gaussian), nonlinearity, and high dimensionality that pose challenges
to making accurate predictions. To address these issues we investigate the use
of both model and data dimension reduction based on techniques including
Assimilation in Unstable Subspaces, Proper Orthogonal Decomposition, and
Dynamic Mode Decomposition. Algorithms that take advantage of projected
physical and data models may be combined with Data Analysis techniques such as
Ensemble Kalman Filter and Particle Filter variants. The projected Data
Assimilation techniques are developed for the optimal proposal particle filter
and applied to the Lorenz'96 and Shallow Water Equations to test the efficacy
of our techniques in high dimensional, nonlinear systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:10:05 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 13:57:20 GMT""}]","2021-06-10"
"2101.09253","Vera De Vos","V. de Vos, K.M. Timmins, I.C. van der Schaaf, Y. Ruigrok, B.K.
  Velthuis, H.J. Kuijf","Automatic Cerebral Vessel Extraction in TOF-MRA Using Deep Learning","Preprint for the SPIE Medical Imaging, Image Processing Conference
  2021",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning approaches may help radiologists in the early diagnosis and
timely treatment of cerebrovascular diseases. Accurate cerebral vessel
segmentation of Time-of-Flight Magnetic Resonance Angiographs (TOF-MRAs) is an
essential step in this process. This study investigates deep learning
approaches for automatic, fast and accurate cerebrovascular segmentation for
TOF-MRAs. The performance of several data augmentation and selection methods
for training a 2D and 3D U-Net for vessel segmentation was investigated in five
experiments: a) without augmentation, b) Gaussian blur, c) rotation and
flipping, d) Gaussian blur, rotation and flipping and e) different input patch
sizes. All experiments were performed by patch-training both a 2D and 3D U-Net
and predicted on a test set of MRAs. Ground truth was manually defined using an
interactive threshold and region growing method. The performance was evaluated
using the Dice Similarity Coefficient (DSC), Modified Hausdorff Distance and
Volumetric Similarity, between the predicted images and the interactively
defined ground truth. The segmentation performance of all trained networks on
the test set was found to be good, with DSC scores ranging from 0.72 to 0.83.
Both the 2D and 3D U-Net had the best segmentation performance with Gaussian
blur, rotation and flipping compared to other experiments without augmentation
or only one of those augmentation techniques. Additionally, training on larger
patches or slices gave optimal segmentation results. In conclusion, vessel
segmentation can be optimally performed on TOF-MRAs using a trained 3D U-Net on
larger patches, where data augmentation including Gaussian blur, rotation and
flipping was performed on the training data.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:11:34 GMT""}]","2021-01-25"
"2101.09254","Emilio Pisanty","Rodrigo Guti\'errez-Cuevas and Emilio Pisanty","Optical polarization skyrmionic fields in free space",,"J. Opt. 23, 024004 (2021)","10.1088/2040-8986/abe8b2",,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We construct optical beams in free space with robust skyrmionic structures in
their polarization fields, both in the electric spin vector for near-circular
fields and in the polarization direction for near-linear fields, and for both
Bloch (spiral) and N\'eel (hedgehog) textures. These structures are made
possible by the spin-orbit coupling of tightly-focused nonparaxial optics as
applied to higher-order Full-Poincar\'e beams, as well as by standing-wave
configurations comprising forwards- and backwards-propagating waves. Our
constructions show near-uniform circular and linear polarizations, providing a
high degree of topological protection in the absence of nonlinear interactions.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:14:18 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 14:45:02 GMT""}]","2022-03-18"
"2101.09255","Oleksii Mikulenko","Kyrylo Bondarenko, Alexey Boyarsky, Juraj Klaric, Oleksii Mikulenko,
  Oleg Ruchayskiy, Vsevolod Syvolap, and Inar Timiryasov","An allowed window for heavy neutral leptons below the kaon mass","30 pages, 10 figures",,"10.1007/JHEP07(2021)193",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The extension of the Standard Model with two gauge-singlet Majorana fermions
can simultaneously explain two beyond-the-Standard-model phenomena: neutrino
masses and oscillations, as well as the origin of the matter-antimatter
asymmetry in the Universe. The parameters of such a model are constrained by
the neutrino oscillation data, direct accelerator searches, big bang
nucleosynthesis, and requirement of successful baryogenesis. We show that the
combination of all these constraints still leaves an allowed region in the
parameter space below the kaon mass. This region can be probed by the further
searches of NA62, DUNE, or SHiP experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:16:24 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 12:24:18 GMT""}]","2021-07-29"
"2101.09256","Jacek Niemiec","Arianna Ligorini, Jacek Niemiec, Oleh Kobzar, Masanori Iwamoto, Artem
  Bohdan, Martin Pohl, Yosuke Matsumoto, Takanobu Amano, Shuichi Matsukiyo,
  Masahiro Hoshino","Mildly relativistic magnetized shocks in electron-ion plasmas -- II.
  Particle acceleration and heating","11 pages, 11 figures; This is a pre-copyedited, author-produced PDF
  of an article accepted for publication in MNRAS following peer review",,"10.1093/mnras/stab220",,"astro-ph.HE physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle acceleration and heating at mildly relativistic magnetized shocks in
electron-ion plasma are investigated with unprecedentedly high-resolution
two-dimensional particle-in-cell simulations that include ion-scale shock
rippling. Electrons are super-adiabatically heated at the shock, and most of
the energy transfer from protons to electrons takes place at or downstream of
the shock. We are the first to demonstrate that shock rippling is crucial for
the energization of electrons at the shock. They remain well below
equipartition with the protons. The downstream electron spectra are
approximately thermal with a limited supra-thermal power-law component. Our
results are discussed in the context of wakefield acceleration and the
modelling of electromagnetic radiation from blazar cores.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:16:43 GMT""}]","2021-02-03"
"2101.09257","Mirela Silva","Mirela Silva, Daniela Oliveira","Brazilian Favela Women: How Your Standard Solutions for Technology Abuse
  Might Actually Harm Them","Accepted in SOUPS 5th Workshop on Inclusive Privacy and Security
  (WIPS 2020)",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Brazil is home to over 200M people, the majority of which have access to the
Internet. Over 11M Brazilians live in favelas, or informal settlements with no
outside government regulation, often ruled by narcos or militias. Victims of
intimate partner violence (IPV) in these communities are made extra vulnerable
not only by lack of access to resources, but by the added layer of violence
caused by criminal activity and police confrontations. In this paper, we use an
unintended harms framework to analyze the unique online privacy needs of favela
women and present research questions that we urge tech abuse researchers to
consider.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:17:56 GMT""}]","2021-01-25"
"2101.09258","Yang Song","Yang Song and Conor Durkan and Iain Murray and Stefano Ermon","Maximum Likelihood Training of Score-Based Diffusion Models","NeurIPS 2021 (Spotlight)",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Score-based diffusion models synthesize samples by reversing a stochastic
process that diffuses data to noise, and are trained by minimizing a weighted
combination of score matching losses. The log-likelihood of score-based
diffusion models can be tractably computed through a connection to continuous
normalizing flows, but log-likelihood is not directly optimized by the weighted
combination of score matching losses. We show that for a specific weighting
scheme, the objective upper bounds the negative log-likelihood, thus enabling
approximate maximum likelihood training of score-based diffusion models. We
empirically observe that maximum likelihood training consistently improves the
likelihood of score-based diffusion models across multiple datasets, stochastic
processes, and model architectures. Our best models achieve negative
log-likelihoods of 2.83 and 3.76 bits/dim on CIFAR-10 and ImageNet 32x32
without any data augmentation, on a par with state-of-the-art autoregressive
models on these tasks.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:22:29 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 04:42:19 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 04:48:04 GMT""},{""version"":""v4"",""created"":""Thu, 21 Oct 2021 00:06:11 GMT""}]","2021-10-22"
"2101.09259","Eva Zmazek","Eva Zmazek","Strong edge geodetic problem on grids",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $G=(V(G),E(G))$ be a simple graph. A set $S \subseteq V(G)$ is a strong
edge geodetic set if there exists an assignment of exactly one shortest path
between each pair of vertices from $S$, such that these shortest paths cover
all the edges $E(G)$. The cardinality of a smallest strong edge geodetic set is
the strong edge geodetic number $\text{sge}(G)$ of $G$. In this paper, the
strong edge geodetic problem is studied on the Cartesian product of two paths.
The exact value of the strong edge geodetic number is computed for $P_n \,
\square \, P_2$, $P_n \, \square \, P_3$ and $P_n \, \square \, P_4$. Some
general upper bounds for $\text{sge}(P_n \, \square \, P_m)$ are also proved.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:22:35 GMT""}]","2021-01-25"
"2101.09260","Adrien Leleu","A. Leleu, Y. Alibert, N. C. Hara, M. J. Hooton, T. G. Wilson, P.
  Robutel, J.-B. Delisle, J. Laskar, S. Hoyer, C. Lovis, E. M. Bryant, E.
  Ducrot, J. Cabrera, L. Delrez, J. S. Acton, V. Adibekyan, R. Allart, C.
  Allende Prieto, R. Alonso, D. Alves, D. R. Anderson, D. Angerhausen, G.
  Anglada Escud\'e, J. Asquier, D. Barrado, S. C. C. Barros, W. Baumjohann, D.
  Bayliss, M. Beck, T. Beck, A. Bekkelien, W. Benz, N. Billot, A. Bonfanti, X.
  Bonfils, F. Bouchy, V. Bourrier, G. Bou\'e, A. Brandeker, C. Broeg, M. Buder,
  A. Burdanov, M. R. Burleigh, T. B\'arczy, A. C. Cameron, S. Chamberlain, S.
  Charnoz, B. F. Cooke, C. Corral Van Damme, A. C. M. Correia, S. Cristiani, M.
  Damasso, M. B. Davies, M. Deleuil, O. D. S. Demangeon, B.-O. Demory, P. Di
  Marcantonio, G. Di Persio, X. Dumusque, D. Ehrenreich, A. Erikson, P.
  Figueira, A. Fortier, L. Fossati, M. Fridlund, D. Futyan, D. Gandolfi, A.
  Garc\'ia Mu\~noz, L. J. Garcia, S. Gill, E. Gillen, M. Gillon, M. R. Goad,
  J.I. Gonz\'alez Hern\'andez, M. Guedel, M. N. G\""unther, J. Haldemann, B.
  Henderson, K. Heng, A. E. Hogan, K. Isaak, E. Jehin, J. S. Jenkins, A.
  Jord\'an, L. Kiss, M. H. Kristiansen, K. Lam, B. Lavie, A. Lecavelier des
  Etangs, M. Lendl, J. Lillo-Box, G. Lo Curto, D. Magrin, C. J. A. P. Martins,
  P. F. L. Maxted, J. McCormac, A. Mehner, G. Micela, P. Molaro, M. Moyano, C.
  A. Murray, V. Nascimbeni, N. J. Nunes, G. Olofsson, H. P. Osborn, M. Oshagh,
  R. Ottensamer, I. Pagano, E. Pall\'e, P. P. Pedersen, F. A. Pepe, C.M.
  Persson, G. Peter, G. Piotto, G. Polenta, D. Pollacco, E. Poretti, F. J.
  Pozuelos, D. Queloz, R. Ragazzoni, N. Rando, F. Ratti, H. Rauer, L. Raynard,
  R. Rebolo, C. Reimers, I. Ribas, N. C. Santos, G. Scandariato, J. Schneider,
  D. Sebastian, M. Sestovic, A. E. Simon, A. M. S. Smith, S. G. Sousa, A.
  Sozzetti, M. Steller, A. Su\'arez Mascare\~no, Gy. M. Szab\'o, D.
  S\'egransan, N. Thomas, S. Thompson, R. H. Tilbrook, A. Triaud, O. Turner, S.
  Udry, V. Van Grootel, H. Venus, F. Verrecchia, J. I. Vines, N. A. Walton, R.
  G. West, P. J. Wheatley, D. Wolter and M. R. Zapatero Osorio","Six transiting planets and a chain of Laplace resonances in TOI-178",,,"10.1051/0004-6361/202039767",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Determining the architecture of multi-planetary systems is one of the
cornerstones of understanding planet formation and evolution. Resonant systems
are especially important as the fragility of their orbital configuration
ensures that no significant scattering or collisional event has taken place
since the earliest formation phase when the parent protoplanetary disc was
still present. In this context, TOI-178 has been the subject of particular
attention since the first TESS observations hinted at a 2:3:3 resonant chain.
Here we report the results of observations from CHEOPS, ESPRESSO, NGTS, and
SPECULOOS with the aim of deciphering the peculiar orbital architecture of the
system. We show that TOI-178 harbours at least six planets in the super-Earth
to mini-Neptune regimes, with radii ranging from 1.152(-0.070/+0.073) to
2.87(-0.13/+0.14) Earth radii and periods of 1.91, 3.24, 6.56, 9.96, 15.23, and
20.71 days. All planets but the innermost one form a 2:4:6:9:12 chain of
Laplace resonances, and the planetary densities show important variations from
planet to planet, jumping from 1.02(+0.28/-0.23) to 0.177(+0.055/-0.061) times
the Earth's density between planets c and d. Using Bayesian interior structure
retrieval models, we show that the amount of gas in the planets does not vary
in a monotonous way, contrary to what one would expect from simple formation
and evolution models and unlike other known systems in a chain of Laplace
resonances. The brightness of TOI-178 allows for a precise characterisation of
its orbital architecture as well as of the physical nature of the six presently
known transiting planets it harbours. The peculiar orbital configuration and
the diversity in average density among the planets in the system will enable
the study of interior planetary structures and atmospheric evolution, providing
important clues on the formation of super-Earths and mini-Neptunes.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:24:11 GMT""}]","2021-01-25"
"2101.09261","Michael Wilbur","Michael Wilbur, Philip Pugliese, Aron Laszka, Abhishek Dubey","Efficient Data Management for Intelligent Urban Mobility Systems","5 pages, 3 figures",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern intelligent urban mobility applications are underpinned by
large-scale, multivariate, spatiotemporal data streams. Working with this data
presents unique challenges of data management, processing and presentation that
is often overlooked by researchers. Therefore, in this work we present an
integrated data management and processing framework for intelligent urban
mobility systems currently in use by our partner transit agencies. We discuss
the available data sources and outline our cloud-centric data management and
stream processing architecture built upon open-source publish-subscribe and
NoSQL data stores. We then describe our data-integrity monitoring methods. We
then present a set of visualization dashboards designed for our transit agency
partners. Lastly, we discuss how these tools are currently being used for
AI-driven urban mobility applications that use these tools.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:28:04 GMT""}]","2021-01-25"
"2101.09263","Shinhoo Kang","Shinhoo Kang, Emil M. Constantinescu, Hong Zhang, Robert L. Jacob","Mass-Conserving Implicit-Explicit Methods for Coupled Compressible
  Navier-Stokes Equations","39 pages, 6 tables, 10 figures",,"10.1016/j.cma.2021.113988",,"math.NA cs.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Earth system models are composed of coupled components that separately model
systems such as the global atmosphere, ocean, and land surface. While these
components are well developed, coupling them in a single system can be a
significant challenge. Computational efficiency, accuracy, and stability are
principal concerns. In this study, we focus on these issues. In particular,
implicit-explicit (IMEX) tight and loose coupling strategies are explored for
handling different time scales. For a simplified model for the air-sea
interaction problem, we consider coupled compressible Navier-Stokes equations
with an interface condition. Under the rigid-lid assumption, horizontal
momentum and heat flux are exchanged through the interface. Several numerical
experiments are presented to demonstrate the stability of the coupling schemes.
We show both numerically and theoretically that our IMEX coupling methods are
mass conservative for a coupled compressible Navier-Stokes system with the
rigid-lid condition.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:30:18 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 16:08:56 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 15:31:16 GMT""}]","2021-07-07"
"2101.09264","Vihangkumar Naik","Vihangkumar V. Naik and Alberto Bemporad","Exact and Heuristic Methods with Warm-start for Embedded Mixed-Integer
  Quadratic Programming Based on Accelerated Dual Gradient Projection",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Small-scale Mixed-Integer Quadratic Programming (MIQP) problems often arise
in embedded control and estimation applications. Driven by the need for
algorithmic simplicity to target computing platforms with limited memory and
computing resources, this paper proposes a few approaches to solving MIQPs,
either to optimality or suboptimally. We specialize an existing Accelerated
Dual Gradient Projection (GPAD) algorithm to effectively solve the Quadratic
Programming (QP) relaxation that arise during Branch and Bound (B&B) and
propose a generic framework to warm-start the binary variables which reduces
the number of QP relaxations. Moreover, in order to find an integer feasible
combination of the binary variables upfront, two heuristic approaches are
presented: ($i$) without using B&B, and ($ii$) using B&B with a significantly
reduced number of QP relaxations. Both heuristic approaches return an integer
feasible solution that may be suboptimal but involve a much reduced computation
effort. Such a feasible solution can be either implemented directly or used to
set an initial upper bound on the optimal cost in B&B. Through different hybrid
control and estimation examples involving binary decision variables, we show
that the performance of the proposed methods, although very simple to code, is
comparable to that of state-of-the-art MIQP solvers.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:31:57 GMT""}]","2021-01-25"
"2101.09265","Matthew Radue","Matthew S. Radue, Sungha Baek, Azadeh Farzaneh, K. J. Dwyer, Quinn
  Campbell, Andrew D. Baczewski, Ezra Bussmann, George T. Wang, Yifei Mo,
  Shashank Misra, R. E. Butera","AlCl$_{3}$-dosed Si(100)-2$\times$1: Adsorbates, chlorinated Al chains,
  and incorporated Al","35 pages, 8 figures",,"10.1021/acs.jpcc.1c00691",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adsorption of AlCl$_{3}$ on Si(100) and the effect of annealing the
AlCl$_{3}$-dosed substrate was studied to reveal key surface processes for the
development of atomic-precision acceptor-doping techniques. This investigation
was performed via scanning tunneling microscopy (STM), X-ray photoelectron
spectroscopy (XPS), and density functional theory (DFT) calculations. At room
temperature, AlCl$_{3}$ readily adsorbed to the Si substrate dimers and
dissociated to form a variety of species. Annealing of the AlCl$_{3}$-dosed
substrate at temperatures below 450 $^{\circ}$C produced unique chlorinated
aluminum chains (CACs) elongated along the Si(100) dimer row direction. An
atomic model for the chains is proposed with supporting DFT calculations. Al
was incorporated into the Si substrate upon annealing at 450 $^{\circ}$C and
above, and Cl desorption was observed for temperatures beyond 450 $^{\circ}$C.
Al-incorporated samples were encapsulated in Si and characterized by secondary
ion mass spectrometry (SIMS) depth profiling to quantify the Al atom
concentration, which was found to be in excess of 10$^{20}$ cm$^{-3}$ across a
$\sim$2.7 nm thick $\delta$-doped region. The Al concentration achieved here
and the processing parameters utilized promote AlCl$_{3}$ as a viable gaseous
precursor for novel acceptor-doped Si materials and devices for quantum
computing.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:32:20 GMT""}]","2021-08-19"
"2101.09266","Willie Wai-Yeung Wong","Audrey Rosevear and Samuel Sottile and Willie WY Wong","Geodesic motion on $\mathsf{SL}(n)$ with the Hilbert-Schmidt metric","3 figures; report from SURIEM 2020 Summer REU program. v2: journal
  accepted manuscript","La Matematica (2021)","10.1007/s44007-021-00002-x",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the geometry of geodesics on $\mathsf{SL}(n)$, equipped with the
Hilbert-Schmidt metric which makes it a Riemannian manifold. These geodesics
are known to be related to affine motions of incompressible ideal fluids. The
$n = 2$ case is special and completely integrable, and the geodesic motion was
completely described by Roberts, Shkoller, and Sideris; when $n = 3$, Sideris
demonstrated some interesting features of the dynamics and analyzed several
classes of explicit solutions. Our analysis shows that the geodesics in higher
dimensions exhibit much more complex dynamics. We generalize the
Virial-identity-based criterion of unboundedness of geodesic given by Sideris,
and use it to give an alternative proof of the classification of geodesics in
2D obtained by Roberts--Shkoller--Sideris. We study several explicit families
of solutions in general dimensions that generalize those found by Sideris in
3D. We additionally classify all ""exponential type"" geodesics, and use it to
demonstrate the existence of purely rotational solutions whenever $n$ is even.
Finally, we study ""block diagonal"" solutions using a new formulation of the
geodesic equation in first order form, that isolates the conserved angular
momenta. This reveals the existence of a rich family of bounded geodesic
motions in even dimension $n \geq 4$. This in particular allows us to conclude
that the generalization of the swirling and shear flows of Sideris to even
dimensions $n \geq 4$ are in fact dynamically unstable.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:34:21 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 15:40:27 GMT""}]","2021-11-24"
"2101.09267","Oskar Schneider","Andreas B\""armann, Oskar Schneider","Set characterizations and convex extensions for geometric convex-hull
  proofs",,"Math. Program. (2021)","10.1007/s10107-021-01705-3",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, we consider Zuckerberg's method for geometric
convex-hull proofs introduced in [Geometric proofs for convex hull defining
formulations, Operations Research Letters 44(5), 625-629 (2016)]. It has only
been scarcely adopted in the literature so far, despite the great flexibility
in designing algorithmic proofs for the completeness of polyhedral descriptions
that it offers. We suspect that this is partly due to the rather heavy
algebraic framework its original statement entails. This is why we present a
much more lightweight and accessible approach to Zuckerberg's proof technique,
building on ideas from [Extended formulations for convex hulls of some bilinear
functions, Discrete Optimization 36, 100569 (2020)]. We introduce the concept
of set characterizations to replace the set-theoretic expressions needed in the
original version and to facilitate the construction of algorithmic proof
schemes. Along with this, we develop several different strategies to conduct
Zuckerberg-type convex-hull proofs. Very importantly, we also show that our
concept allows for a significant extension of Zuckerberg's proof technique.
While the original method was only applicable to 0/1-polytopes, our extended
framework allows to treat arbitrary polyhedra and even general convex sets. We
demonstrate this increase in expressive power by characterizing the convex hull
of Boolean and bilinear functions over polytopal domains. All results are
illustrated with indicative examples to underline the practical usefulness and
wide applicability of our framework.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:39:29 GMT""}]","2021-09-16"
"2101.09268","Mehdi Yazdi","Mehdi Yazdi","Non-negative integral matrices with given spectral radius and controlled
  dimension","The referee's suggestions are incorporated; in particular an upper
  bound for the Perron--Frobenius degree is derived from the main result. See
  Theorem 1.6. To appear in Ergodic Theory and Dynamical Systems",,,,"math.DS math.NT math.RA","http://creativecommons.org/licenses/by/4.0/","  A celebrated theorem of Lind states that a positive real number is equal to
the spectral radius of some integral primitive matrix, if and only if, it is a
Perron algebraic integer. Given a Perron number $p$, we prove that there is an
integral irreducible matrix with spectral radius $p$, and with dimension
bounded above in terms of the algebraic degree, the ratio of the first two
largest Galois conjugates, and arithmetic information about the ring of
integers of its number field. This arithmetic information can be taken to be
either the discriminant or the minimal Hermite-like thickness. Equivalently,
given a Perron number $p$, there is an irreducible shift of finite type with
entropy $\log(p)$ defined as an edge shift on a graph whose number of vertices
is bounded above in terms of the aforementioned data.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:41:08 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 12:23:16 GMT""},{""version"":""v3"",""created"":""Sun, 10 Oct 2021 13:15:28 GMT""}]","2021-10-12"
"2101.09269","Jean-Claude Bouret","Jean-Claude Bouret, Fabrice Martins, Desmond John Hillier, Wagner
  Marcolino, Helio Rocha-Pinto, Cyril Georgy, Thierry Lanz, Ivan Hubeny","Massive stars in the Small Magellanic Cloud : Evolution, rotation and
  surface abundances","30 pages. 28 figures, 6 tables. Accepted in A&A. English edited
  version","A&A 647, A134 (2021)","10.1051/0004-6361/202039890",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolutionary and physical properties of evolved O stars in the
Small Magellanic Cloud (SMC), with a special focus on their surface abundances
to investigate the efficiency of rotational mixing as a function of age,
rotation and global metallicity. We analyse the UV + optical spectra of
thirteen SMC O-type giants and supergiants, using the stellar atmosphere code
CMFGEN to derive photospheric and wind properties. We compare the inferred
properties to theoretical predictions from evolution models. For a more
comprehensive analysis, we interpret the results together with those we
obtained for O-type dwarfs in a former study. Most dwarfs lie in the early
phases of the main-sequence. For a given initial mass, giants are farther along
the evolutionary tracks, confirming that they are more evolved than dwarfs.
Supergiants have higher initial masses and are located past the terminal age
main-sequence. We find no clear trend of a mass discrepancy, regardless of the
diagram that was used to estimate the evolutionary mass. CNO abundances are
consistent with nucleosynthesis from the CNO cycle. Comparisons to theoretical
predictions reveal that the initial mixture is important when the observed
trends in the N/C versus N/O diagram are to be reproduced. A trend for stronger
chemical evolution for more evolved objects is observed. More massive stars,
are on average, more chemically enriched at a given evolutionary phase,
qualitatively consistent with evolutionary models. Abundance ratios supports
the theoretical prediction that massive stars at low metallicity are more
chemically processed than their Galactic counterparts. Finally, models
including rotation generally reproduce the surface abundances and rotation
rates when different initial rotational velocities are considered.
Nevertheless, there are objects for which a stronger braking and/or more
efficient mixing is required.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:42:19 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 14:26:59 GMT""}]","2021-03-24"
"2101.09270","Ivan Derkach","Ivan Derkach, Vladyslav C Usenko","Applicability of Squeezed-and Coherent-State Continuous-Variable Quantum
  Key Distribution over Satellite Links","15 pages, 6 figures, 1 table","Entropy 2021, 23(1), 55","10.3390/e23010055",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We address the applicability of quantum key distribution with
continuous-variable coherent and squeezed states over long-distance
satellite-based links, considering low Earth orbits and taking into account
strong varying channel attenuation, atmospheric turbulence and finite data
ensemble size effects. We obtain tight security bounds on the untrusted excess
noise on the channel output, which suggest that substantial efforts aimed at
setup stabilization and reduction of noise and loss are required, or the
protocols can be realistically implemented over satellite links once either
individual or passive collective attacks are assumed. Furthermore, splitting
the satellite pass into discrete segments and extracting the key from each
rather than from the overall single pass allows one to effectively improve
robustness against the untrusted channel noise and establish a secure key under
active collective attacks. We show that feasible amounts of optimized signal
squeezing can substantially improve the applicability of the protocols allowing
for lower system clock rates and aperture sizes and resulting in higher
robustness against channel attenuation and noise compared to the coherent-state
protocol
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:44:54 GMT""}]","2021-01-25"
"2101.09271","Eliana Duarte","Eliana Duarte, Liam Solus","Representation of Context-Specific Causal Models with Observational and
  Interventional Data","28 pages, supplementary material 15 pages",,,,"math.ST math.CO stat.ME stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of representing causal models that encode
context-specific information for discrete data using a proper subclass of
staged tree models which we call CStrees. We show that the context-specific
information encoded by a CStree can be equivalently expressed via a collection
of DAGs. As not all staged tree models admit this property, CStrees are a
subclass that provides a transparent, intuitive and compact representation of
context-specific causal information. We prove that CStrees admit a global
Markov property which yields a graphical criterion for model equivalence
generalizing that of Verma and Pearl for DAG models. These results extend to
the general interventional model setting, making CStrees the first family of
context-specific models admitting a characterization of interventional model
equivalence. We also provide a closed-form formula for the maximum likelihood
estimator of a CStree and use it to show that the Bayesian information
criterion is a locally consistent score function for this model class. The
performance of CStrees is analyzed on both simulated and real data, where we
see that modeling with CStrees instead of general staged trees does not result
in a significant loss of predictive accuracy, while affording DAG
representations of context-specific causal information.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:48:29 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 17:10:20 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 18:08:42 GMT""}]","2022-01-13"
"2101.09272","Tong Zhou","Tong Zhou, Matthieu C. Dartiailh, Kasra Sardashti, Jong E. Han, Alex
  Matos-Abiague, Javad Shabani, and Igor Zutic","Fusion of Majorana Bound States with Mini-Gate Control in
  Two-Dimensional Systems","10 pages, 7 figures; Accepted in Nature Communications","Nature Communications 13, 1738-1747 (2022)","10.1038/s41467-022-29463-6",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.stat-mech cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hallmark of topological superconductivity is the non-Abelian statistics of
Majorana bound states (MBS), its chargeless zero-energy emergent
quasiparticles. The resulting fractionalization of a single electron, stored
nonlocally as a two spatially-separated MBS, provides a powerful platform for
implementing fault-tolerant topological quantum computing. However, despite
intensive efforts, experimental support for MBS remains indirect and does not
probe their non-Abelian statistics. Here we propose how to overcome this
obstacle in mini-gate controlled planar Josephson junctions (JJs) and
demonstrate non-Abelian statistics through MBS fusion, detected by charge
sensing using a quantum point contact, based on dynamical simulations. The
feasibility of preparing, manipulating, and fusing MBS in two-dimensional (2D)
systems is supported in our experiments which demonstrate the gate control of
topological transition and superconducting properties with five mini gates in
InAs/Al-based JJs. While we focus on this well-established platform, where the
topological superconductivity was already experimentally detected, our proposal
to identify elusive non-Abelian statistics motivates also further MBS studies
in other gate-controlled 2D systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:52:13 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 07:15:34 GMT""},{""version"":""v3"",""created"":""Thu, 17 Mar 2022 17:34:18 GMT""}]","2022-04-26"
"2101.09273","Tim Waters","Tim Waters, Daniel Proga, and Randall Dannen","Multiphase AGN winds from X-ray irradiated disk atmospheres","Published in ApJ. Simulations viewable at
  https://trwaters.github.io/multiphaseAGNdiskwinds/ Companion paper
  arXiv:2103.06497",,"10.3847/1538-4357/abfbe6",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The mechanism of thermal driving for launching mass outflows is
interconnected with classical thermal instability (TI). In a recent paper, we
demonstrated that as a result of this interconnectedness, radial wind solutions
of X-ray heated flows are prone to becoming clumpy. In this paper, we first
show that the Bernoulli function determines whether or not the entropy mode can
grow due to TI in dynamical flows. Based on this finding, we identify a
critical `unbound' radius beyond which TI should accompany thermal driving. Our
numerical disk wind simulations support this result and reveal that clumpiness
is a consequence of buoyancy disrupting the stratified structure of steady
state solutions. Namely, instead of a smooth transition layer separating the
highly ionized disk wind from the cold phase atmosphere below, hot bubbles
formed from TI rise up and fragment the atmosphere. These bubbles first appear
within large scale vortices that form below the transition layer, and they
result in the episodic production of distinctive cold phase structures referred
to as irradiated atmospheric fragments (IAFs). Upon interacting with the wind,
IAFs advect outward and develop extended crests. The subsequent disintegration
of the IAFs takes place within a turbulent wake that reaches high elevations
above the disk. We show that this dynamics has the following observational
implications: dips in the absorption measure distribution are no longer
expected within TI zones and there can be a less sudden desaturation of X-ray
absorption lines such as \OVIII as well as multiple absorption troughs in
\FeXXVK.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:53:25 GMT""},{""version"":""v2"",""created"":""Sun, 25 Apr 2021 06:01:16 GMT""},{""version"":""v3"",""created"":""Thu, 17 Jun 2021 08:50:05 GMT""}]","2021-06-23"
"2101.09274","Robert-Jan Slager","Gunnar. F. Lange, Adrien Bouhon, Robert-Jan Slager","Subdimensional topologies, indicators and higher order phases","11+4pages; 8+3 figures","Phys. Rev. B 103, 195145 (2021)","10.1103/PhysRevB.103.195145",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The study of topological band structures have sparked prominent research
interest the past decade, culminating in the recent formulation of rather
prolific classification schemes that encapsulate a large fraction of phases and
features. Within this context we recently reported on a class of unexplored
topological structures that thrive on the concept of {\it sub-dimensional
topology}. Although such phases have trivial indicators and band
representations when evaluated over the complete Brillouin zone, they have
stable or fragile topologies within sub-dimensional spaces, such as planes or
lines. This perspective does not just refine classification pursuits, but can
result in observable features in the full dimensional sense. In three spatial
dimensions (3D), for example, sub-dimensional topologies can be characterized
by non-trivial planes, having general topological invariants, that are
compensated by Weyl nodes away from these planes. As a result, such phases have
3D stable characteristics such as Weyl nodes, Fermi arcs and edge states that
can be systematically predicted by sub-dimensional analysis. Within this work
we further elaborate on these concepts. We present refined representation
counting schemes and address distinctive bulk-boundary effects, that include
momentum depended (higher order) edge states that have a signature dependence
on the perpendicular momentum. As such, we hope that these insights might spur
on new activities to further deepen the understanding of these unexplored
phases.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:55:14 GMT""}]","2021-05-21"
"2101.09275","Ian Hutchinson","I H Hutchinson","Synthetic Multidimensional Plasma Electron Hole Equilibria",,,"10.1063/5.0045296",,"physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Methods for constructing synthetic multidimensional electron hole equilibria
without using particle simulation are investigated. Previous approaches have
various limitations and approximations that make them unsuitable within the
context of expected velocity diffusion near the trapped-passing boundary. An
adjustable model of the distribution function is introduced that avoids
unphysical singularities there, and yet is sufficiently tractable analytically
to enable prescription of the potential spatial profiles. It is shown why
simple models of the charge density as being a function only of potential
cannot give solitary multidimensional electron holes, in contradiction of prior
suppositions. Fully self-consistent axisymmetric electron holes in the
drift-kinetic limit of electron motion (negligible gyro-radius) are constructed
and their properties relevant to observational interpretation and
finite-gyro-radius theory are discussed.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:57:34 GMT""}]","2021-06-30"
"2101.09276","Seokhwan Kim","Seokhwan Kim, Mihail Eric, Behnam Hedayatnia, Karthik Gopalakrishnan,
  Yang Liu, Chao-Wei Huang, Dilek Hakkani-Tur","Beyond Domain APIs: Task-oriented Conversational Modeling with
  Unstructured Knowledge Access Track in DSTC9","To be presented at AAAI-21 DSTC9 Workshop. arXiv admin note:
  substantial text overlap with arXiv:2006.03533, arXiv:2011.06486",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most prior work on task-oriented dialogue systems are restricted to a limited
coverage of domain APIs, while users oftentimes have domain related requests
that are not covered by the APIs. This challenge track aims to expand the
coverage of task-oriented dialogue systems by incorporating external
unstructured knowledge sources. We define three tasks: knowledge-seeking turn
detection, knowledge selection, and knowledge-grounded response generation. We
introduce the data sets and the neural baseline models for three tasks. The
challenge track received a total of 105 entries from 24 participating teams. In
the evaluation results, the ensemble methods with different large-scale
pretrained language models achieved high performances with improved knowledge
selection capability and better generalization into unseen data.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:57:56 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 17:23:35 GMT""},{""version"":""v3"",""created"":""Thu, 4 Feb 2021 00:08:27 GMT""}]","2021-02-05"
"2101.09277","James Webb","James L. Webb, Andreas F. L. Poulsen, Robert Staacke, Jan Meijer,
  Kirstine Berg-S{\o}rensen, Ulrik Lund Andersen, Alexander Huck","Laser threshold magnetometry using green light absorption by diamond
  nitrogen vacancies in an external cavity laser",,"Phys. Rev. A 103, 062603 (2021)","10.1103/PhysRevA.103.062603",,"quant-ph physics.app-ph physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  Nitrogen vacancy (NV) centers in diamond have attracted considerable recent
interest for use in quantum sensing, promising increased sensitivity for
applications ranging from geophysics to biomedicine. Conventional sensing
schemes involve monitoring the change in red fluorescence from the NV center
under green laser and microwave illumination. Due to the strong fluorescence
background from emission in the NV triplet state and low relative contrast of
any change in output, sensitivity is severely restricted by a high optical shot
noise level. Here, we propose a means to avoid this issue, by using the change
in green pump absorption through the diamond as part of a semiconductor
external cavity laser run close to lasing threshold. We show theoretical
sensitivity to magnetic field on the pT/sqrt(Hz) level is possible using a
diamond with an optimal density of NV centers. We discuss the physical
requirements and limitations of the method, particularly the role of amplified
spontaneous emission near threshold and explore realistic implementations using
current technology.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:58:05 GMT""}]","2021-06-09"
"2101.09278","Matthew Novack","Tristan Buckmaster, Nader Masmoudi, Matthew Novack, Vlad Vicol","Non-conservative $H^{\frac 12-}$ weak solutions of the incompressible 3D
  Euler equations","155 pages, 11 figures, typos corrected",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  For any positive regularity parameter $\beta < \frac 12$, we construct
non-conservative weak solutions of the 3D incompressible Euler equations which
lie in $H^{\beta}$ uniformly in time. In particular, we construct solutions
which have an $L^2$-based regularity index \emph{strictly larger} than $\frac
13$, thus deviating from the $H^{\frac{1}{3}}$-regularity corresponding to the
Kolmogorov-Obhukov $\frac 53$ power spectrum in the inertial range.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:58:35 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jun 2022 18:15:22 GMT""}]","2022-06-15"
"2101.09279","Koushik Chowdhury","Koushik Chowdhury, Mir Ahmad Iraj","Predicting Autism Spectrum Disorder Using Machine Learning Classifiers",,"2020 International Conference on Recent Trends on Electronics,
  Information, Communication & Technology (RTEICT), Bangalore, India, 2020, pp.
  324-327","10.1109/RTEICT49044.2020.9315717","CFP20F77-ART","cs.LG","http://creativecommons.org/licenses/by/4.0/","  Autism Spectrum Disorder (ASD) is on the rise and constantly growing. Earlier
identify of ASD with the best outcome will allow someone to be safe and healthy
by proper nursing. Humans can hardly estimate the present condition and stage
of ASD by measuring primary symptoms. Therefore, it is being necessary to
develop a method that will provide the best outcome and measurement of ASD.
This paper aims to show several measurements that implemented in several
classifiers. Among them, Support Vector Machine (SVM) provides the best result
and under SVM, there are also some kernels to perform. Among them, the Gaussian
Radial Kernel gives the best result. The proposed classifier achieves 95%
accuracy using the publicly available standard ASD dataset.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:58:58 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 21:24:38 GMT""}]","2021-01-28"
"2101.09280","Fabian Grusdt","A. Bohrdt, E. Demler, F. Grusdt","Rotational Resonances and Regge Trajectories in Lightly Doped
  Antiferromagnets","12 pages, 10 pages supplementary, 12 figures",,"10.1103/PhysRevLett.127.197004",,"cond-mat.str-el cond-mat.quant-gas hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the nature of charge carriers in doped Mott insulators holds
the key to unravelling puzzling properties of strongly correlated electron
systems, including cuprate superconductors. Several theoretical models
suggested that dopants can be understood as bound states of partons, the
analogues of quarks in high-energy physics. However, direct signatures of
spinon-chargon bound states are lacking, both in experiment and theory. Here we
numerically identify long-lived rotational resonances at low doping, which
directly reveal the microscopic structure of spinon-chargon bound states.
Similar to Regge trajectories reflecting the quark structure of mesons, we
establish a linear dependence of the rotational energy on the super-exchange
coupling. Rotational excitations are strongly suppressed in standard
angle-resolved photo-emission (ARPES) spectra, but we propose a multi-photon
rotational extension of ARPES where they have strong spectral weight. Our
findings suggest that multi-photon spectroscopy experiments should provide new
insights into emergent universal features of strongly correlated electron
systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:59:35 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 10:43:17 GMT""}]","2021-11-17"
"2101.09281","Daegene Koh","Daegene Koh, Tom Abel, Karsten Jedamzik","First Star Formation in the Presence of Primordial Magnetic Fields","8 pages, 6 figures, submitted to ApJL",,"10.3847/2041-8213/abe8dd",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  It has been recently claimed that primordial magnetic fields could relieve
the cosmological Hubble tension. We consider the impact of such fields on the
formation of the first cosmological objects, mini-halos forming stars, for
present-day field strengths in the range of $2\times 10^{-12}$ - $2\times
10^{-10}$ G. These values correspond to initial ratios of Alv\'en velocity to
the speed of sound of $v_a/c_s\approx 0.03 - 3$. We find that when $v_a/c_s\ll
1$, the effects are modest. However, when $v_a\sim c_s$, the starting time of
the gravitational collapse is delayed and the duration extended as much as by
$\Delta$z = 2.5 in redshift. When $v_a > c_s$, the collapse is completely
suppressed and the mini-halos continue to grow and are unlikely to collapse
until reaching the atomic cooling limit. Employing current observational limits
on primordial magnetic fields we conclude that inflationary produced primordial
magnetic fields could have a significant impact on first star formation,
whereas post-inflationary produced fields do not.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:59:59 GMT""}]","2021-03-17"
"2101.09283","Long Wang","Long Wang, Michiko S. Fujii and Ataru Tanikawa","Impact of initial mass functions on the dynamical channel of
  gravitational wave sources","10 pages, 12 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab1157",,"astro-ph.HE astro-ph.GA astro-ph.SR gr-qc","http://creativecommons.org/licenses/by/4.0/","  Dynamically formed black hole (BH) binaries (BBHs) are important sources of
gravitational waves (GWs). Globular clusters (GCs) provide a major environment
to produce such BBHs, but the total mass of the known GCs is small compared to
that in the Galaxy; thus, the fraction of BBHs formed in GCs is also small.
However, this assumes that GCs contain a canonical initial mass function (IMF)
similar to that of field stars. This might not be true because several studies
suggest that extreme dense and metal-poor environment can result in top-heavy
IMFs, where GCs may originate. Although GCs with top-heavy IMFs were easily
disrupted or have become dark clusters, the contribution to the GW sources can
be significant. Using a high-performance and accurate $N$-body code,
\textsc{petar}, we investigate the effect of varying IMFs by carrying out four
star-by-star simulations of dense GCs with the initial mass of $5\times10^5
M_\odot$ and the half-mass radius of $2$~pc. We find that the BBH merger rate
does not monotonically correlate with the slope of IMFs. Due to a rapid
expansion, top-heavy IMFs lead to less efficient formation of merging BBHs. The
formation rate continuously decreases as the cluster expands because of the
dynamical heating caused by BHs. However, in star clusters with a top-heavier
IMF, the total number of BHs is larger, and therefore, the final contribution
to merging BBHs can still be more than from clusters with the standard IMF, if
the initial cluster mass and density is higher than those used in our model.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:53:06 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 13:42:23 GMT""}]","2021-04-22"
"2101.09287","Nicholas Rodd","Jeff A. Dror, Hitoshi Murayama, Nicholas L. Rodd","The Cosmic Axion Background","31 pages, 11 figures, v3: corrected the source term for resonant
  cavity instruments, conclusions unchanged","Phys. Rev. D 103, 115004 (2021)","10.1103/PhysRevD.103.115004",,"hep-ph astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  Existing searches for cosmic axions relics have relied heavily on the axion
being non-relativistic and making up dark matter. However, light axions can be
copiously produced in the early Universe and remain relativistic today, thereby
constituting a Cosmic $\textit{axion}$ Background (C$a$B). As prototypical
examples of axion sources, we consider thermal production, dark-matter decay,
parametric resonance, and topological defect decay. Each of these has a
characteristic frequency spectrum that can be searched for in axion direct
detection experiments. We focus on the axion-photon coupling and study the
sensitivity of current and future versions of ADMX, HAYSTAC, DMRadio, and
ABRACADABRA to a C$a$B, finding that the data collected in search of dark
matter can be repurposed to detect axion energy densities well below limits set
by measurements of the energy budget of the Universe. In this way, direct
detection of relativistic relics offers a powerful new opportunity to learn
about the early Universe and, potentially, discover the axion.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 00:36:15 GMT""},{""version"":""v3"",""created"":""Wed, 9 Nov 2022 16:57:34 GMT""}]","2022-11-10"
"2101.09288","Benedetta Spina","Benedetta Spina, Cristiano Porciani, Carlo Schimd","The HI-halo mass relation at redshift $z \sim 1$ from the Minkowski
  functionals of 21 cm intensity maps","13 pages, 9 figures. Section 6 added to address the comments of the
  reviewer, no changes in the results","Monthly Notices of the Royal Astronomical Society, Volume 505,
  Issue 3, August 2021, Pages 3492-3504","10.1093/mnras/stab1555",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mean and the scatter of the HI content of a dark-matter halo as a
function of the halo mass are useful statistics that can be used to test models
of structure and galaxy formation. We investigate the possibility of
constraining this HI-halo mass relation (HIHMR) from intensity maps of the
redshifted 21 cm line. In particular, we use the geometry and topology of the
brightness-temperature isocontours in a single frequency channel as quantified
by the Minkowski functionals. First, we generate mock maps from a large N-body
simulation considering the impact of thermal noise and foreground removal. We
then use the Fisher information formalism to forecast constraints on a
parametric model for the HIHMR. We consider a 20,000 deg$^2$ survey (originally
proposed for dark-energy science) conducted with the Square Kilometre Array
Phase 1 (SKA-1) MID observatory operating in single-dish mode. For a channel
bandwidth of 2 MHz, we show that an integration time of a few$\,\times\,10^4$ s
per pointing is sufficient to image the smoothed HI distribution at redshift $z
\simeq 1$ and to measure the HIHMR in a nearly optimal way from the Minkowski
functionals. Tighter constraints on some of the parameters can be obtained by
using also an independent measurement of the mean HI density. Combining the
results from different frequency channels provides exquisite constraints on the
evolution of the HIHMR, especially in the central frequency range of the data
cube.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 13:48:41 GMT""}]","2021-06-21"
"2101.09289","Romy Rodr\'iguez","Romy Rodriguez Martinez, Daniel J. Stevens, B. Scott Gaudi, Joseph G.
  Schulze, Wendy R. Panero, Jennifer A. Johnson, Ji Wang","Analytic Estimates of the Achievable Precision on the Physical
  Properties of Transiting Planets Using Purely Empirical Measurements","15 pages, 2 figures, Submitted to ApJ",,"10.3847/1538-4357/abe941",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We present analytic estimates of the fractional uncertainties on the mass,
radius, surface gravity, and density of a transiting planet, using only
empirical or semi-empirical measurements. We first express these parameters in
terms of transit photometry and radial velocity (RV) observables, as well as
the stellar radius $R_{\star}$, if required. In agreement with previous
results, we find that, assuming a circular orbit, the surface gravity of the
planet ($g_p$) depends only on empirical transit and RV parameters; namely, the
planet period $P$, the transit depth $\delta$, the RV semi-amplitude
$K_{\star}$, the transit duration $T$, and the ingress/egress duration $\tau$.
However, the planet mass and density depend on all these quantities, plus
$R_{\star}$. Thus, an inference about the planet mass, radius, and density must
rely upon an external constraint such as the stellar radius. For bright stars,
stellar radii can now be measured nearly empirically by using measurements of
the stellar bolometric flux, the effective temperature, and the distance to the
star via its parallax, with the extinction $A_V$ being the only free parameter.
For any given system, there is a hierarchy of achievable precisions on the
planetary parameters, such that the planetary surface gravity is more
accurately measured than the density, which in turn is more accurately measured
than the mass. We find that surface gravity provides a strong constraint on the
core mass fraction of terrestrial planets. This is useful, given that the
surface gravity may be one of the best measured properties of a terrestrial
planet.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:00:02 GMT""}]","2021-04-28"
"2101.09290","David Sutter","Christophe Piveteau, David Sutter, Stefan Woerner","Quasiprobability decompositions with reduced sampling overhead","v2: 22 pages, 9 figures; published version","npj Quantum Inf, 2022","10.1038/s41534-022-00517-3",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum error mitigation techniques can reduce noise on current quantum
hardware without the need for fault-tolerant quantum error correction. For
instance, the quasiprobability method simulates a noise-free quantum computer
using a noisy one, with the caveat of only producing the correct expected
values of observables. The cost of this error mitigation technique manifests as
a sampling overhead which scales exponentially in the number of corrected
gates. In this work, we present a new algorithm based on mathematical
optimization that aims to choose the quasiprobability decomposition in a
noise-aware manner. This directly leads to a significantly lower basis of the
sampling overhead compared to existing approaches. A key element of the novel
algorithm is a robust quasiprobability method that allows for a tradeoff
between an approximation error and the sampling overhead via semidefinite
programming.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 15:27:15 GMT""}]","2022-02-01"
"2101.09291","Vincent Pelgrims","V. Pelgrims, S. E. Clark, B. S. Hensley, G. V. Panopoulou, V.
  Pavlidou, K. Tassis, H.K. Eriksen, I. K. Wehus","Evidence for Line-of-Sight Frequency Decorrelation of Polarized Dust
  Emission in $Planck$ Data","17 pages, 15 figures. Accepted for publication by A&A","A&A 647, A16 (2021)","10.1051/0004-6361/202040218",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by-sa/4.0/","  If a single line of sight (LOS) intercepts multiple dust clouds of different
spectral energy distributions and magnetic field orientations, the frequency
scaling of each of the Stokes $Q$ and $U$ parameters of thermal dust emission
may be different (""LOS frequency decorrelation""). We present first evidence for
LOS frequency decorrelation in $Planck$ data. We use independent,
neutral-hydrogen--measurements of the number of clouds per LOS and the magnetic
field orientation in each cloud to select two sets of sightlines: (i) a target
sample (pixels likely to exhibit LOS frequency decorrelation); (ii) a control
sample (pixels lacking complex LOS structure). We test the null hypothesis that
LOS frequency decorrelation is not detectable in $Planck$ 353 and 217~GHz
polarization data at high Galactic latitudes. The data reject this hypothesis
at high significance. The detection is robust against choice of CMB map and
map-making pipeline. The observed change in polarization angle due to LOS
frequency decorrelation is detectable above the $Planck$ noise level. The
probability that the detected effect is due to noise alone ranges from $5\times
10^{-2}$ to $4\times 10^{-7}$, depending on the CMB subtraction algorithm and
treatment of residual systematics; correcting for residual systematics
increases the significance of the effect. The LOS decorrelation effect is
stronger for sightlines with more misaligned magnetic fields, as expected. We
estimate that an intrinsic variation of $\sim15\%$ in the ratio of 353 to
217~GHz polarized emission between clouds is sufficient to reproduce the
measured effect. Our finding underlines the importance of ongoing studies to
map the 3D structure of the magnetized dusty ISM that could help component
separation methods to account for frequency decorrelation effects in CMB
polarization studies.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:00:15 GMT""}]","2021-03-10"
"2101.09292","Hamideh Shakeripour","Hamideh Shakeripour, Seyed Sajjad Hosseini, Seyedeh Sara Ghotb, Behnaz
  Hadi-Sichani, Sepideh Pourasad","Magnetic doping effects on the superconductivity of Y1-xMxBa2Cu3O7-d (M
  = Fe, Co, Ni)","28 pages, 8 figures",,"10.1016/j.ceramint.2020.12.176",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The discovery of superconductivity in copper oxide compounds has attracted
considerable attention over the past three decades. The high transition
temperature in these compounds, exhibiting proximity to an antiferromagnetic
order in their phase diagrams, remains one of the main areas of research. The
present study attempts to introduce Fe, Co and Ni magnetic impurities into the
superconducting Y-123 with the aim of exploring the transition temperature
behavior. The solid-state synthesis is exploited to prepare fully oxygenated
Y1-xMxBa2Cu3O7 (M = Co, Fe, Ni) samples with low levels of doping (0< x <
0.03). Systematic measurements are then employed to assess the synthesized
samples using AC magnetic susceptibility, electrical resistivity and X-ray
diffraction. The measurements revealed an increase in Tc as a result of
magnetic substitution for Y. However, the study of non-magnetic dopings on the
fully oxygenated Y1-xM'xBa2Cu3O7 (M' = Ca, Sr) samples showed a decrease in Tc.
Quantitative XRD analysis further suggested that the internal pressure could
have minor effects on the increase in Tc. The normal state resistivity vs
temperature showed a linear profile, confirming that the samples are at an
optimal doping of the carrier concentration.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:01:35 GMT""}]","2021-01-26"
"2101.09293","Xiangyu Gao","Xiangyu Gao, Sumit Roy, and Guanbin Xing","MIMO-SAR: A Hierarchical High-resolution Imaging Algorithm for mmWave
  FMCW Radar in Autonomous Driving","13 pages","IEEE Transactions on Vehicular Technology, 2021",,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter-wave radars are being increasingly integrated into commercial
vehicles to support advanced driver-assistance system features. A key
shortcoming for present-day vehicular radar imaging is poor azimuth resolution
(for side-looking operation) due to the form factor limits on antenna size and
placement. In this paper, we propose a solution via a new multiple-input and
multiple-output synthetic aperture radar (MIMO-SAR) imaging technique, that
applies coherent SAR principles to vehicular MIMO radar to improve the
side-view (angular) resolution. The proposed 2-stage hierarchical MIMO-SAR
processing workflow drastically reduces the computation load while preserving
image resolution. To enable coherent processing over the synthetic aperture, we
integrate a radar odometry algorithm that estimates the trajectory of
ego-radar. The MIMO-SAR algorithm is validated by both simulations and real
experiment data collected by a vehicle-mounted radar platform.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:05:50 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 03:37:16 GMT""}]","2021-06-07"
"2101.09294","Eddie Yang","Eddie Yang, Margaret E. Roberts","Censorship of Online Encyclopedias: Implications for NLP Models","Accepted for publication at ACM FAccT 2021",,"10.1145/3442188.3445916",,"cs.CL cs.AI cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  While artificial intelligence provides the backbone for many tools people use
around the world, recent work has brought to attention that the algorithms
powering AI are not free of politics, stereotypes, and bias. While most work in
this area has focused on the ways in which AI can exacerbate existing
inequalities and discrimination, very little work has studied how governments
actively shape training data. We describe how censorship has affected the
development of Wikipedia corpuses, text data which are regularly used for
pre-trained inputs into NLP algorithms. We show that word embeddings trained on
Baidu Baike, an online Chinese encyclopedia, have very different associations
between adjectives and a range of concepts about democracy, freedom, collective
action, equality, and people and historical events in China than its regularly
blocked but uncensored counterpart - Chinese language Wikipedia. We examine the
implications of these discrepancies by studying their use in downstream AI
applications. Our paper shows how government repression, censorship, and
self-censorship may impact training data and the applications that draw from
them.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:09:53 GMT""}]","2021-01-26"
"2101.09295","Alan D. Rendall","Lisa Maria Kreusser and Alan D. Rendall","Autophosphorylation and the dynamics of the activation of Lck",,,,,"q-bio.MN math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lck (lymphocyte-specific protein tyrosine kinase) is an enzyme which plays a
number of important roles in the function of immune cells. It belongs to the
Src family of kinases which are known to undergo autophosphorylation. It turns
out that this leads to a remarkable variety of dynamical behaviour which can
occur during their activation. We prove that in the presence of
autophosphorylation one phenomenon, bistability, already occurs in a
mathematical model for a protein with a single phosphorylation site. We further
show that a certain model of Lck exhibits oscillations. Finally we discuss the
relations of these results to models in the literature which involve Lck and
describe specific biological processes, such as the early stages of T cell
activation and the stimulation of T cell responses resulting from the
suppression of PD-1 signalling which is important in immune checkpoint therapy
for cancer.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:11:12 GMT""}]","2021-01-26"
"2101.09296","Minsik Han","Minsik Han","Misiurewicz polynomials for rational maps with nontrivial automorphisms
  II","11 pages, 1 figure",,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper continues discussions in the author's previous paper about the
Misiurewicz polynomials defined for a family of degree $d \ge 2$ rational maps
with an automorphism group containing the cyclic group of order $d$. In
particular, we extend the sufficient conditions that the Misiurewicz
polynomials are irreducible over $\mathbb{Q}$. We also prove that the
Misiurewicz polynomials always have an irreducible factor of large degree.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:12:45 GMT""}]","2021-01-26"
"2101.09297","Keith Zirkle","Keith W. Zirkle, Marie-Abele Bind, Jenise L. Swall, and David C.
  Wheeler","Addressing Spatially Structured Interference in Causal Analysis Using
  Propensity Scores","37 pages, 7 figures, being submitted",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Environmental epidemiologists are increasingly interested in establishing
causality between exposures and health outcomes. A popular model for causal
inference is the Rubin Causal Model (RCM), which typically seeks to estimate
the average difference in study units' potential outcomes. An important
assumption under RCM is no interference; that is, the potential outcomes of one
unit are not affected by the exposure status of other units. The no
interference assumption is violated if we expect spillover or diffusion of
exposure effects based on units' proximity to other units and several other
causal estimands arise. Air pollution epidemiology typically violates this
assumption when we expect upwind events to affect downwind or nearby locations.
This paper adapts causal assumptions from social network research to address
interference and allow estimation of both direct and spillover causal effects.
We use propensity score-based methods to estimate these effects when
considering the effects of the Environmental Protection Agency's 2005
nonattainment designations for particulate matter with aerodynamic diameter
less than 2.5 micrograms per cubic meter (PM2.5) on lung cancer incidence using
county-level data obtained from the Surveillance, Epidemiology, and End Results
(SEER) Program. We compare these methods in a rigorous simulation study that
considers both spatially autocorrelated variables, interference, and missing
confounders. We find that pruning and matching based on the propensity score
produces the highest probability coverage of the true causal effects and lower
mean squared error. When applied to the research question, we found protective
direct and spillover causal effects.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:12:53 GMT""}]","2021-01-26"
"2101.09298","Kaiwen Liu","Kaiwen Liu, Nan Li, Ilya Kolmanovsky, Denise Rizzo, and Anouck Girard","Safe Learning Reference Governor: Theory and Application to Fuel Truck
  Rollover Avoidance","16 pages, 18 figures",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a learning reference governor (LRG) approach to enforce
state and control constraints in systems for which an accurate model is
unavailable, and this approach enables the reference governor to gradually
improve command tracking performance through learning while enforcing the
constraints during learning and after learning is completed. The learning can
be performed either on a black-box type model of the system or directly on the
hardware. After introducing the LRG algorithm and outlining its theoretical
properties, this paper investigates LRG application to fuel truck (tank truck)
rollover avoidance. Through simulations based on a fuel truck model that
accounts for liquid fuel sloshing effects, we show that the proposed LRG can
effectively protect fuel trucks from rollover accidents under various operating
conditions.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:13:11 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 20:16:20 GMT""}]","2021-09-10"
"2101.09299","Scott O'Connor","S. O'Connor, Z. D. Crawford, J. Verboncoeur, J. Lugisland, B. Shanker","A Set of Benchmark Tests for Validation of 3D Particle In Cell Methods",,,"10.1109/TPS.2021.3072353",,"physics.comp-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the particle-in-cell (PIC) method is quite mature, verification and
validation of both newly developed methods and individual codes has largely
focused on an idiosyncratic choice of a few test cases. Many of these test
cases involve either one- or two-dimensional simulations. This is either due to
availability of (quasi) analytic solutions or historical reasons. Additionally,
tests often focus on investigation of particular physics problems, such as
particle emission or collisions, and do not necessarily study the combined
impact of the suite of algorithms necessary for a full featured PIC code. As
three dimensional (3D) codes become the norm, there is a lack of benchmarks
test that can establish the validity of these codes; existing papers either do
not delve into the details of the numerical experiment or provide other
measurable numeric metrics (such as noise) that are outcomes of the simulation.
This paper seeks to provide several test cases that can be used for validation
and bench-marking of particle in cell codes in 3D. We focus on examples that
are collisionless, and can be run with a reasonable amount of computational
power. Four test cases are presented in significant detail; these include,
basic particle motion, beam expansion, adiabatic expansion of plasma, and two
stream instability. All presented cases are compared either against existing
analytical data or other codes. We anticipate that these cases should help fill
the void of bench-marking and validation problems and help the development of
new particle in cell codes.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:18:26 GMT""}]","2021-05-19"
"2101.09300","Yingfang Yuan","Yingfang Yuan and Wenjun Wang and George M. Coghill and Wei Pang","A Novel Genetic Algorithm with Hierarchical Evaluation Strategy for
  Hyperparameter Optimisation of Graph Neural Networks",,,,,"cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Graph representation of structured data can facilitate the extraction of
stereoscopic features, and it has demonstrated excellent ability when working
with deep learning systems, the so-called Graph Neural Networks (GNNs).
Choosing a promising architecture for constructing GNNs can be transferred to a
hyperparameter optimisation problem, a very challenging task due to the size of
the underlying search space and high computational cost for evaluating
candidate GNNs. To address this issue, this research presents a novel genetic
algorithm with a hierarchical evaluation strategy (HESGA), which combines the
full evaluation of GNNs with a fast evaluation approach. By using full
evaluation, a GNN is represented by a set of hyperparameter values and trained
on a specified dataset, and root mean square error (RMSE) will be used to
measure the quality of the GNN represented by the set of hyperparameter values
(for regression problems). While in the proposed fast evaluation process, the
training will be interrupted at an early stage, the difference of RMSE values
between the starting and interrupted epochs will be used as a fast score, which
implies the potential of the GNN being considered. To coordinate both types of
evaluations, the proposed hierarchical strategy uses the fast evaluation in a
lower level for recommending candidates to a higher level, where the full
evaluation will act as a final assessor to maintain a group of elite
individuals. To validate the effectiveness of HESGA, we apply it to optimise
two types of deep graph neural networks. The experimental results on three
benchmark datasets demonstrate its advantages compared to Bayesian
hyperparameter optimization.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:19:59 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 11:38:54 GMT""}]","2021-01-27"
"2101.09301","Ting Wang","Xinyang Zhang, Ren Pang, Shouling Ji, Fenglong Ma, Ting Wang","i-Algebra: Towards Interactive Interpretability of Deep Neural Networks","Accepted by the 35th AAAI Conference on Artificial Intelligence (AAAI
  '21)",,,,"cs.LG cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing explanations for deep neural networks (DNNs) is essential for their
use in domains wherein the interpretability of decisions is a critical
prerequisite. Despite the plethora of work on interpreting DNNs, most existing
solutions offer interpretability in an ad hoc, one-shot, and static manner,
without accounting for the perception, understanding, or response of end-users,
resulting in their poor usability in practice. In this paper, we argue that DNN
interpretability should be implemented as the interactions between users and
models. We present i-Algebra, a first-of-its-kind interactive framework for
interpreting DNNs. At its core is a library of atomic, composable operators,
which explain model behaviors at varying input granularity, during different
inference stages, and from distinct interpretation perspectives. Leveraging a
declarative query language, users are enabled to build various analysis tools
(e.g., ""drill-down"", ""comparative"", ""what-if"" analysis) via flexibly composing
such operators. We prototype i-Algebra and conduct user studies in a set of
representative analysis tasks, including inspecting adversarial inputs,
resolving model inconsistency, and cleansing contaminated data, all
demonstrating its promising usability.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:22:57 GMT""}]","2021-01-26"
"2101.09302","Chiara Stuardi","C. Stuardi, A. Bonafede, L. Lovisari, P. Dom\'inguez-Fern\'andez, F.
  Vazza, M. Br\""uggen, R.J. van Weeren and F. de Gasperin","The intra-cluster magnetic field in the double relic galaxy cluster
  Abell 2345","20 pages, 13 figures, 6 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab218",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic fields are ubiquitous in galaxy clusters, yet their radial profile,
power spectrum, and connection to host cluster properties are poorly known.
Merging galaxy clusters hosting diffuse polarized emission in the form of radio
relics offer a unique possibility to study the magnetic fields in these complex
systems. In this paper, we investigate the intra-cluster magnetic field in
Abell 2345. This cluster hosts two radio relics that we detected in
polarization with 1-2 GHz JVLA observations. X-ray XMM-Newton images show a
very disturbed morphology. We derived the Rotation Measure (RM) of five
polarized sources within $\sim$ 1 Mpc from the cluster center applying the RM
synthesis. Both, the average RM and the RM dispersion radial profiles probe the
presence of intra-cluster magnetic fields. Using the thermal electron density
profile derived from X-ray analysis and simulating a 3D magnetic field with
fluctuations following a power spectrum derived from magneto-hydrodynamical
cosmological simulations, we build mock RM images of the cluster. We
constrained the magnetic field profile in the eastern radio relic sector by
comparing simulated and observed RM images. We find that, within the framework
of our model, the data require a magnetic field scaling with thermal electron
density as $B(r)\propto n_e(r)$. The best model has a central magnetic field
(within a 200 kpc radius) of $2.8\pm0.1$ $\mu$G. The average magnetic field at
the position of the eastern relic is $\sim$0.3 $\mu$G, a factor 2.7 lower than
the equipartition estimate.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:24:51 GMT""}]","2021-02-03"
"2101.09303","Davide Rossini","Antonio D'Abbruzzo and Davide Rossini","Self-consistent microscopic derivation of Markovian master equations for
  open quadratic quantum systems","17 pages, 2 figures. Final version","Phys. Rev. A 103, 052209 (2021)","10.1103/PhysRevA.103.052209",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a rigorous construction of Markovian master equations for a wide
class of quantum systems that encompass quadratic models of finite size,
linearly coupled to an environment modeled by a set of independent thermal
baths. Our theory can be applied for both fermionic and bosonic models in any
number of physical dimensions, and does not require any particular spatial
symmetry of the global system. We show that, for non-degenerate systems under a
full secular approximation, the effective Lindblad operators are the normal
modes of the system, with coupling constants that explicitly depend on the
transformation matrices that diagonalize the Hamiltonian. Both the dynamics and
the steady-state (guaranteed to be unique) properties can be obtained with a
polynomial amount of resources in the system size. We also address the particle
and energy current flowing through the system in a minimal two-bath scheme and
find that they hold the structure of Landauer's formula, being
thermodynamically consistent.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:25:17 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 15:00:32 GMT""}]","2021-05-18"
"2101.09304","Serge Aleshin-Guendel","Serge Aleshin-Guendel, Mauricio Sadinle, Jon Wakefield","The Central Role of the Identifying Assumption in Population Size
  Estimation","58 pages. The material presented in Appendix A previously appeared in
  an unpublished preprint written by the first author: arXiv:2008.09865",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of estimating the size of a population based on a subset of
individuals observed across multiple data sources is often referred to as
capture-recapture or multiple-systems estimation. This is fundamentally a
missing data problem, where the number of unobserved individuals represents the
missing data. As with any missing data problem, multiple-systems estimation
requires users to make an untestable identifying assumption in order to
estimate the population size from the observed data. If an appropriate
identifying assumption cannot be found for a data set, no estimate of the
population size should be produced based on that data set, as models with
different identifying assumptions can produce arbitrarily different population
size estimates -- even with identical observed data fits. Approaches to
multiple-systems estimation often do not explicitly specify identifying
assumptions. This makes it difficult to decouple the specification of the model
for the observed data from the identifying assumption and to provide
justification for the identifying assumption. We present a re-framing of the
multiple-systems estimation problem that leads to an approach which decouples
the specification of the observed-data model from the identifying assumption,
and discuss how common models fit into this framing. This approach takes
advantage of existing software and facilitates various sensitivity analyses. We
demonstrate our approach in a case study estimating the number of civilian
casualties in the Kosovo war. Code used to produce this manuscript is available
at https://github.com/aleshing/central-role-of-identifying-assumptions.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:30:20 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 23:24:50 GMT""}]","2022-06-22"
"2101.09305","Irit Huq-Kuruvilla","Irit Huq-Kuruvilla","Multiplicative Quantum Cobordism Theory","13 pages",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a twisting theorem for nodal classes in permutation-equivariant
quantum $K$-theory, and combine it with existing theorems of Givental to obtain
a twisting result for general characteristic classes of the virtual tangent
bundle. Using this result, we develop complex cobordism-valued Gromov-Witten
invariants defined via $K$-theory, and relate those invariants to $K$-theoretic
ones via the quantization of suitable symplectic transformations. The resulting
theory is a $K$-theoretic analogue of the quantum cobordism theory developed by
Givental and Coates. Using the universality of cobordism theory, we study the
example of ""Hirzebruch $K$-theory"", which is the cohomology theory determined
by the Hirzebruch $\chi_{-y}$-genus.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:36:38 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 01:44:31 GMT""}]","2021-01-27"
"2101.09306","Brendon G. Anderson","Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi","Towards Optimal Branching of Linear and Semidefinite Relaxations for
  Neural Network Robustness Certification","This is an extension of our IEEE CDC 2020 conference paper
  arXiv:2004.00570",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study certifying the robustness of ReLU neural networks
against adversarial input perturbations. To diminish the relaxation error
suffered by the popular linear programming (LP) and semidefinite programming
(SDP) certification methods, we take a branch-and-bound approach to propose
partitioning the input uncertainty set and solving the relaxations on each part
separately. We show that this approach reduces relaxation error, and that the
error is eliminated entirely upon performing an LP relaxation with a partition
intelligently designed to exploit the nature of the ReLU activations. To scale
this approach to large networks, we consider using a coarser partition whereby
the number of parts in the partition is reduced. We prove that computing such a
coarse partition that directly minimizes the LP relaxation error is NP-hard. By
instead minimizing the worst-case LP relaxation error, we develop a closed-form
branching scheme. We extend the analysis to the SDP, where the feasible set
geometry is exploited to design a branching scheme that minimizes the
worst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin
breast cancer diagnosis classifiers demonstrate significant increases in the
percentages of test samples certified. By independently increasing the input
size and the number of layers, we empirically illustrate under which regimes
the branched LP and branched SDP are best applied.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:36:40 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 21:54:16 GMT""}]","2023-02-06"
"2101.09307","Noah Forman","Noah Forman, Soumik Pal, Douglas Rizzolo, Matthias Winkel","Ranked masses in two-parameter Fleming-Viot diffusions","20 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In previous work, we constructed Fleming--Viot-type measure-valued diffusions
(and diffusions on a space of interval partitions of the unit interval $[0,1]$)
that are stationary with the Poisson--Dirichlet laws with parameters
$\alpha\in(0,1)$ and $\theta\geq 0$. In this paper, we complete the proof that
these processes resolve a conjecture by Feng and Sun (2010) by showing that the
processes of ranked atom sizes (or of ranked interval lengths) of these
diffusions are members of a two-parameter family of diffusions introduced by
Petrov (2009), extending a model by Ethier and Kurtz (1981) in the case
$\alpha=0$. The latter diffusions are continuum limits of up-down Chinese
restaurant processes.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:49:02 GMT""}]","2021-01-26"
"2101.09308","Pablo Miguel Piaggi","Pablo M. Piaggi and Roberto Car","Enhancing the formation of ionic defects to study the ice Ih/XI
  transition with molecular dynamics simulations","17 pages, 9 figures","Mol. Phys. 2021, e1916634","10.1080/00268976.2021.1916634",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ice Ih, the common form of ice in the biosphere, contains proton disorder.
Its proton-ordered counterpart, ice XI, is thermodynamically stable below 72 K.
However, even below this temperature the formation of ice XI is kinetically
hindered and experimentally it is obtained by doping ice with KOH. Doping
creates ionic defects that promote the migration of protons and the associated
change in proton configuration. In this article, we mimic the effect of doping
in molecular dynamics simulations using a bias potential that enhances the
formation of ionic defects. The recombination of the ions thus formed proceeds
through fast migration of the hydroxide and results in the jump of protons
along a hydrogen bond loop. This provides a physical and expedite way to change
the proton configuration, and to accelerate diffusion in proton configuration
space. A key ingredient of this approach is a machine learning potential
trained with density functional theory data and capable of modeling molecular
dissociation. We exemplify the usefulness of this idea by studying the
order-disorder transition using an appropriate order parameter to distinguish
the proton environments in ice Ih and XI. We calculate the changes in free
energy, enthalpy, and entropy associated with the transition. Our estimated
entropy agrees with experiment within the error bars of our calculation.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:49:43 GMT""}]","2021-06-18"
"2101.09309","Yohan Eguillon","Yohan Eguillon, Bruno Lacabanne, Damien Tromeur-Dervout","F3ORNITS: A Flexible Variable Step Size Non-Iterative Co-simulation
  Method handling Subsystems with Hybrid Advanced Capabilities",,,,,"math.NA cs.CE cs.NA cs.PF","http://creativecommons.org/publicdomain/zero/1.0/","  This paper introduces the F3ORNITS non-iterative co-simulation algorithm in
which F3 stands for the 3 flexible aspects of the method: flexible polynomial
order representation of coupling variables, flexible time-stepper applying
variable co-simulation step size rules on subsystems allowing it and flexible
scheduler orchestrating the meeting times among the subsystems and capable of
asynchronousness when subsystems constraints requires it. The motivation of the
F3ORNITS method is to accept any kind of co-simulation model, including any
kind of subsystem, regardless on their available capabilities. Indeed, one the
major problems in industry is that the subsystems usually have constraints or
lack of advanced capabilities making it impossible to implement most of the
advanced co-simulation algorithms on them. The method makes it possible to
preserve the dynamics of the coupling constraints when necessary as well as to
avoid breaking C1 smoothness at communication times, and also to adapt the
co-simulation step size in a way that is robust both to zero-crossing variables
(contrary to classical relative error-based criteria) and to jumps. Two test
cases are presented to illustrate the robustness of the F3ORNITS method as well
as its higher accuracy than the non-iterative Jacobi coupling algorithm (the
most commonly used method in industry) for a smaller number of co-simulation
steps.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:58:24 GMT""}]","2021-01-26"
"2101.09310","Mercedes Gimeno-Segovia","Sara Bartolucci, Patrick Birchall, Hector Bombin, Hugo Cable, Chris
  Dawson, Mercedes Gimeno-Segovia, Eric Johnston, Konrad Kieling, Naomi
  Nickerson, Mihir Pant, Fernando Pastawski, Terry Rudolph and Chris Sparrow","Fusion-based quantum computation",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce fusion-based quantum computing (FBQC) - a model of universal
quantum computation in which entangling measurements, called fusions, are
performed on the qubits of small constant-sized entangled resource states. We
introduce a stabilizer formalism for analyzing fault tolerance and computation
in these schemes. This framework naturally captures the error structure that
arises in certain physical systems for quantum computing, such as photonics.
FBQC can offer significant architectural simplifications, enabling hardware
made up of many identical modules, requiring an extremely low depth of
operations on each physical qubit and reducing classical processing
requirements. We present two pedagogical examples of fault-tolerant schemes
constructed in this framework and numerically evaluate their threshold under a
hardware agnostic fusion error model including both erasure and Pauli error. We
also study an error model of linear optical quantum computing with
probabilistic fusion and photon loss. In FBQC the non-determinism of fusion is
directly dealt with by the quantum error correction protocol, along with other
errors. We find that tailoring the fault-tolerance framework to the physical
system allows the scheme to have a higher threshold than schemes reported in
literature. We present a ballistic scheme which can tolerate a 10.4%
probability of suffering photon loss in each fusion.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:00:22 GMT""}]","2021-01-26"
"2101.09311","Elena Tutubalina Dr.","Zulfat Miftahutdinov, Artur Kadurin, Roman Kudrin, and Elena
  Tutubalina","Drug and Disease Interpretation Learning with Biomedical Entity
  Representation Transformer","Accepted to the 43rd European Conference on Information Retrieval
  (ECIR 2021)",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Concept normalization in free-form texts is a crucial step in every
text-mining pipeline. Neural architectures based on Bidirectional Encoder
Representations from Transformers (BERT) have achieved state-of-the-art results
in the biomedical domain. In the context of drug discovery and development,
clinical trials are necessary to establish the efficacy and safety of drugs. We
investigate the effectiveness of transferring concept normalization from the
general biomedical domain to the clinical trials domain in a zero-shot setting
with an absence of labeled data. We propose a simple and effective two-stage
neural approach based on fine-tuned BERT architectures. In the first stage, we
train a metric learning model that optimizes relative similarity of mentions
and concepts via triplet loss. The model is trained on available labeled
corpora of scientific abstracts to obtain vector embeddings of concept names
and entity mentions from texts. In the second stage, we find the closest
concept name representation in an embedding space to a given clinical mention.
We evaluated several models, including state-of-the-art architectures, on a
dataset of abstracts and a real-world dataset of trial records with
interventions and conditions mapped to drug and disease terminologies.
Extensive experiments validate the effectiveness of our approach in knowledge
transfer from the scientific literature to clinical trials.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:01:25 GMT""}]","2021-01-26"
"2101.09312","Jafar Ghazanfarian","Jafar Ghazanfarian, Mohammad Mostafa Mohammadi, Kenji Uchino","Piezoelectric Energy Harvesting: a Systematic Review of Reviews",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In the last decade, an explosive attention has been paid to piezoelectric
harvesters due to their flexibility in design and increasing need to
small-scale energy generation. As a result, various energy review papers have
been presented by many researchers to cover different aspects of
piezoelectric-based energy harvesting, including piezo-materials, modeling
approaches, and design points for various applications. Most of such papers
tried to shed light on recent progresses in related interdisciplinary fields,
and to pave the road for future prospects of development of such technologies.
However, there are some missing parts, overlaps, or even some contradictions in
the review papers. In the present review of review articles, recommendations
for future research directions suggested by the review papers have been
systematically summed up under one umbrella. In the final section, topics for
missing review papers, concluding remarks on outlooks and possible research
topics, and strategy-misleading contents have been presented. The review papers
have been evaluated based on merits and subcategories and authors' choice
papers have been presented for each section based on clear classification
criteria.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:05:13 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 12:15:12 GMT""}]","2021-10-20"
"2101.09313","James O' Neill","James O' Neill and Danushka Bollegala","$k$-Neighbor Based Curriculum Sampling for Sequence Prediction","arXiv admin note: substantial text overlap with arXiv:1809.05916",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Multi-step ahead prediction in language models is challenging due to the
discrepancy between training and test time processes. At test time, a sequence
predictor is required to make predictions given past predictions as the input,
instead of the past targets that are provided during training. This difference,
known as exposure bias, can lead to the compounding of errors along a generated
sequence at test time. To improve generalization in neural language models and
address compounding errors, we propose \textit{Nearest-Neighbor Replacement
Sampling} -- a curriculum learning-based method that gradually changes an
initially deterministic teacher policy to a stochastic policy. A token at a
given time-step is replaced with a sampled nearest neighbor of the past target
with a truncated probability proportional to the cosine similarity between the
original word and its top $k$ most similar words. This allows the learner to
explore alternatives when the current policy provided by the teacher is
sub-optimal or difficult to learn from. The proposed method is straightforward,
online and requires little additional memory requirements. We report our
findings on two language modelling benchmarks and find that the proposed method
further improves performance when used in conjunction with scheduled sampling.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:07:29 GMT""}]","2021-01-26"
"2101.09314","Junxu Li","Junxu Li, Zixuan Hu and Sabre Kais","A practical quantum encryption protocol with varying encryption
  configurations","11pages, 6 figures (supplementary materials excluded)","Phys. Rev. Research 3, 023251 (2021)","10.1103/PhysRevResearch.3.023251",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum communication is an important application that derives from the
burgeoning field of quantum information and quantum computation. Focusing on
secure communication, quantum cryptography has two major directions of
development, namely quantum key distribution and quantum encryption. In this
work we propose a quantum encryption protocol that utilizes a quantum algorithm
to create blocks of ciphertexts based on quantum states. The main feature of
our quantum encryption protocol is that the encryption configuration of each
block is determined by the previous blocks, such that additional security is
provided. We then demonstrate our method by an example model encrypting the
English alphabet, with numerical simulation results showing the large error
rate of a mock attack by a potential adversary. With possible future
improvements in mind, our quantum encryption protocol is a capable addition to
the toolbox of quantum cryptography.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:09:03 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 20:04:00 GMT""}]","2021-08-31"
"2101.09315","Borja Rodr\'iguez G\'alvez","Borja Rodr\'iguez-G\'alvez, Germ\'an Bassi, Ragnar Thobaben, and
  Mikael Skoglund","Tighter expected generalization error bounds via Wasserstein distance","29 pages: 9 of the main text, 3 of references, and 17 of appendices.
  Presented at ITR3 at ICML 2021. Accepted at NeurIPS 2021",,,,"stat.ML cs.IT cs.LG math.IT","http://creativecommons.org/licenses/by/4.0/","  This work presents several expected generalization error bounds based on the
Wasserstein distance. More specifically, it introduces full-dataset,
single-letter, and random-subset bounds, and their analogues in the randomized
subsample setting from Steinke and Zakynthinou [1]. Moreover, when the loss
function is bounded and the geometry of the space is ignored by the choice of
the metric in the Wasserstein distance, these bounds recover from below (and
thus, are tighter than) current bounds based on the relative entropy. In
particular, they generate new, non-vacuous bounds based on the relative
entropy. Therefore, these results can be seen as a bridge between works that
account for the geometry of the hypothesis space and those based on the
relative entropy, which is agnostic to such geometry. Furthermore, it is shown
how to produce various new bounds based on different information measures
(e.g., the lautum information or several $f$-divergences) based on these bounds
and how to derive similar bounds with respect to the backward channel using the
presented proof techniques.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:13:59 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 21:55:00 GMT""}]","2022-03-29"
"2101.09316","Leonardo Guidoni","Francesco Benfenati, Guglielmo Mazzola, Chiara Capecci, Panagiotis Kl.
  Barkoutsos, Pauline J. Ollitrault, Ivano Tavernelli and Leonardo Guidoni","Improved accuracy on noisy devices by non-unitary Variational Quantum
  Eigensolver for chemistry applications","9 pages, 8 figures",,,,"quant-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a modification of the Variational Quantum Eigensolver algorithm
for electronic structure optimization using quantum computers, named
non-unitary Variational Quantum Eigensolver (nu-VQE), in which a non-unitary
operator is combined with the original system Hamiltonian leading to a new
variational problem with a simplified wavefunction Ansatz. In the present work,
we use, as non-unitary operator, the Jastrow factor, inspired from classical
Quantum Monte Carlo techniques for simulation of strongly correlated electrons.
The method is applied to prototypical molecular Hamiltonians for which we
obtain accurate ground state energies with shallower circuits, at the cost of
an increased number of measurements. Finally, we also show that this method
achieves an important error mitigation effect that drastically improves the
quality of the results for VQE optimizations on today's noisy quantum
computers. The absolute error in the calculated energy within our scheme is one
order of magnitude smaller than the corresponding result using traditional VQE
methods, with the same circuit depth.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:17:37 GMT""}]","2021-01-26"
"2101.09317","Chien-Chung Chan","Arvind Srinivasan, Chien-Chung Chan","Short Secret Sharing Using Repeatable Random Sequence Generators",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a new secret sharing algorithm that provides the storage
efficiency of an Information Dispersal Algorithm (IDA) while providing perfect
secret sharing. We achieve this by mixing the input message with random bytes
generated using Repeatable Random Sequence Generator (RRSG). We also use the
data from the RRSG to provide random polynomial evaluation points and
optionally compute the polynomials on random isomorphic fields rather than a
single fixed field.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:19:31 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 22:49:50 GMT""}]","2021-02-23"
"2101.09318","F. Patricia Medina","F. Patricia Medina, Randy Paffenroth","Machine Learning in LiDAR 3D point clouds","21 pages, 12 figures",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  LiDAR point clouds contain measurements of complicated natural scenes and can
be used to update digital elevation models, glacial monitoring, detecting
faults and measuring uplift detecting, forest inventory, detect shoreline and
beach volume changes, landslide risk analysis, habitat mapping, and urban
development, among others. A very important application is the classification
of the 3D cloud into elementary classes. For example, it can be used to
differentiate between vegetation, man-made structures, and water. Our goal is
to present a preliminary comparison study for the classification of 3D point
cloud LiDAR data that includes several types of feature engineering. In
particular, we demonstrate that providing context by augmenting each point in
the LiDAR point cloud with information about its neighboring points can improve
the performance of downstream learning algorithms. We also experiment with
several dimension reduction strategies, ranging from Principal Component
Analysis (PCA) to neural network-based auto-encoders, and demonstrate how they
affect classification performance in LiDAR point clouds. For instance, we
observe that combining feature engineering with a dimension reduction a method
such as PCA, there is an improvement in the accuracy of the classification with
respect to doing a straightforward classification with the raw data.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:23:23 GMT""}]","2021-01-26"
"2101.09319","Fabien Vignes-Tourneret","Sergei Chmutov, Fabien Vignes-Tourneret","On a conjecture of Gross, Mansour and Tucker",,"Europ. J. Comb.97 (2021)","10.1016/j.ejc.2021.103368",,"math.CO math.GT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Partial duality is a duality of ribbon graphs relative to a subset of their
edges generalizing the classical Euler-Poincare duality. This operation often
changes the genus. Recently J.L.Gross, T.Mansour, and T.W.Tucker formulated a
conjecture that for any ribbon graph different from plane trees and their
partial duals, there is a subset of edges partial duality relative to which
does change the genus. A family of counterexamples was found by Qi Yan and
Xian'an Jin. In this note we prove that essentially these are the only
counterexamples.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:25:18 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 14:43:08 GMT""}]","2021-07-06"
"2101.09320","Dominic Neu","Dominic A. Neu, Johannes Lahann and Peter Fettke","A systematic literature review on state-of-the-art deep learning methods
  for process prediction","Accepted for publication with Artificial Intelligence Review (initial
  Submission 13.07.20). Document is identical to that of the previous version",,"10.1007/s10462-021-09960-8",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Process mining enables the reconstruction and evaluation of business
processes based on digital traces in IT systems. An increasingly important
technique in this context is process prediction. Given a sequence of events of
an ongoing trace, process prediction allows forecasting upcoming events or
performance measurements. In recent years, multiple process prediction
approaches have been proposed, applying different data processing schemes and
prediction algorithms. This study focuses on deep learning algorithms since
they seem to outperform their machine learning alternatives consistently.
Whilst having a common learning algorithm, they use different data
preprocessing techniques, implement a variety of network topologies and focus
on various goals such as outcome prediction, time prediction or control-flow
prediction. Additionally, the set of log-data, evaluation metrics and baselines
used by the authors diverge, making the results hard to compare. This paper
attempts to synthesise the advantages and disadvantages of the procedural
decisions in these approaches by conducting a systematic literature review.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:26:40 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 11:23:08 GMT""}]","2021-06-09"
"2101.09321","Maria A. Zuluaga","Vien Ngoc Dang and Francesco Galati and Rosa Cortese and Giuseppe Di
  Giacomo and Viola Marconetto and Prateek Mathur and Karim Lekadir and Marco
  Lorenzi and Ferran Prados and Maria A. Zuluaga","Vessel-CAPTCHA: an efficient learning framework for vessel annotation
  and segmentation",,,"10.1016/j.media.2021.102263",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning techniques for 3D brain vessel image segmentation have not been
as successful as in the segmentation of other organs and tissues. This can be
explained by two factors. First, deep learning techniques tend to show poor
performances at the segmentation of relatively small objects compared to the
size of the full image. Second, due to the complexity of vascular trees and the
small size of vessels, it is challenging to obtain the amount of annotated
training data typically needed by deep learning methods. To address these
problems, we propose a novel annotation-efficient deep learning vessel
segmentation framework. The framework avoids pixel-wise annotations, only
requiring weak patch-level labels to discriminate between vessel and non-vessel
2D patches in the training set, in a setup similar to the CAPTCHAs used to
differentiate humans from bots in web applications. The user-provided weak
annotations are used for two tasks: 1) to synthesize pixel-wise pseudo-labels
for vessels and background in each patch, which are used to train a
segmentation network, and 2) to train a classifier network. The classifier
network allows to generate additional weak patch labels, further reducing the
annotation burden, and it acts as a noise filter for poor quality images. We
use this framework for the segmentation of the cerebrovascular tree in
Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The
results show that the framework achieves state-of-the-art accuracy, while
reducing the annotation time by ~77% w.r.t. learning-based segmentation methods
using pixel-wise labels for training.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:29:23 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 14:09:45 GMT""},{""version"":""v3"",""created"":""Fri, 29 Jan 2021 09:44:51 GMT""},{""version"":""v4"",""created"":""Tue, 20 Jul 2021 12:39:31 GMT""}]","2021-11-04"
"2101.09322","Dongming Mei","R. Panth, W.-Z. Wei, D.-M. Mei, J. Liu, S. Bhattarai, H. Mei, M. Raut,
  P. Acharya, K. Kooi, G.-J. Wang","Implication of the Temperature-Dependent Charge Barrier Height of
  Amorphous Germanium Contact Detector in Searching for Rare Event Physics","8 pages, 8 figures, and 2 tables",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exploration of germanium (Ge) detectors with amorphous Ge (a-Ge) contacts
has drawn attention to the searches for rare-event physics such as dark matter
and neutrinoless double-beta decay. The charge barrier height (CBH) of the a-Ge
contacts deposited on the detector surface is crucial to suppress the leakage
current of the detector in order to achieve la ow-energy detection threshold
and high-energy resolution. The temperature-dependent CBH of a-Ge contacts for
three Ge detectors is analyzed to study the bulk leakage current (BLC)
characteristics. The detectors were fabricated at the University of South
Dakota using homegrown crystals. The CBH is determined from the BLC when the
detectors are operated in the reverse bias mode with a guard-ring structure,
which separates the BLC from the surface leakage current (SLC). The results
show that CBH is temperature dependent. The direct relation of the CBH
variation to temperature is related to the barrier inhomogeneities created on
the interface of a-Ge and crystalline Ge. The inhomogeneities that occur at the
interface were analyzed using the Gaussian distribution model for three
detectors. The CBH of a-Ge contact is projected to zero temperature. The
implication of the CBH at zero temperature is discussed for Ge detectors with
a-Ge contacts in searching for rare-event physics.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:34:29 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 21:21:31 GMT""}]","2021-04-06"
"2101.09323","Bridget Torsey","Bridget M. Torsey, Steven J. Weinstein, David S. Ross, and Nathaniel
  S. Barlow","The effect of pressure fluctuations on the shapes of thinning liquid
  curtains",,"Journal of Fluid Mechanics, 910, A38 (2021)","10.1017/jfm.2020.1038",,"physics.flu-dyn","http://creativecommons.org/licenses/by-sa/4.0/","  We consider the time-dependent response of a gravitationally-thinning
inviscid liquid sheet (a coating curtain) leaving a vertical slot to sinusoidal
ambient pressure disturbances. The theoretical investigation employs the
hyperbolic partial differential equation developed by \cite{weinp1}. The
response of the curtain is characterized by the slot Weber number, $W_{e_0} =
\rho q V/2\sigma$, where $V$ is the speed of the curtain at the slot, $q$ is
the volumetric flow rate per unit width, $\sigma$ is the surface tension, and
$\rho$ is the fluid density. Flow disturbances travel along characteristics
with speeds relative to the curtain of $\pm \sqrt{uV/W_{e_0}}$, where $u =
\sqrt{V^2 + 2gx}$ is the curtain speed at a distance $x$ downstream from the
slot. When the flow is subcritical ($W_{e_0} < 1$), upstream traveling
disturbances near the slot affect the curtain centerline, and the slope of the
curtain centerline at the slot oscillates with an amplitude that is a function
of $W_{e_0}$. In contrast, all disturbances travel downstream in supercritical
curtains ($W_{e_0} > 1$) and the slope of the curtain at the slot is vertical.
Here, we specifically examine the curtain response under supercritical and
subcritical flow conditions near $W_{e_0} = 1$ to deduce whether there is a
substantial change in the overall shape and magnitude of the curtain responses.
Despite the local differences in the curtain solution near the slot, we find
that subcritical and supercritical curtains have similar responses for all
imposed sinusoidal frequencies.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:37:57 GMT""}]","2021-01-26"
"2101.09324","Hadi Zanddizari","Hadi Zanddizari, Behnam Zeinali, and J. Morris Chang","Generating Black-Box Adversarial Examples in Sparse Domain",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Applications of machine learning (ML) models and convolutional neural
networks (CNNs) have been rapidly increased. Although state-of-the-art CNNs
provide high accuracy in many applications, recent investigations show that
such networks are highly vulnerable to adversarial attacks. The black-box
adversarial attack is one type of attack that the attacker does not have any
knowledge about the model or the training dataset, but it has some input data
set and their labels. In this paper, we propose a novel approach to generate a
black-box attack in sparse domain whereas the most important information of an
image can be observed. Our investigation shows that large sparse (LaS)
components play a critical role in the performance of image classifiers. Under
this presumption, to generate adversarial example, we transfer an image into a
sparse domain and put a threshold to choose only k LaS components. In contrast
to the very recent works that randomly perturb k low frequency (LoF)
components, we perturb k LaS components either randomly (query-based) or in the
direction of the most correlated sparse signal from a different class. We show
that LaS components contain some middle or higher frequency components
information which leads fooling image classifiers with a fewer number of
queries. We demonstrate the effectiveness of this approach by fooling six
state-of-the-art image classifiers, the TensorFlow Lite (TFLite) model of
Google Cloud Vision platform, and YOLOv5 model as an object detection
algorithm. Mean squared error (MSE) and peak signal to noise ratio (PSNR) are
used as quality metrics. We also present a theoretical proof to connect these
metrics to the level of perturbation in the sparse domain.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:45:33 GMT""},{""version"":""v2"",""created"":""Fri, 15 Oct 2021 14:24:45 GMT""}]","2021-10-18"
"2101.09325","Maxim Shcherbakov R.","Melissa Bosch, Maxim R. Shcherbakov, Kanghee Won, Hong-Seok Lee, Young
  Kim, Gennady Shvets","Electrically actuated varifocal lens based on liquid-crystal-embedded
  dielectric metasurfaces",,,"10.1021/acs.nanolett.1c00356",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact varifocal lenses are essential to various imaging and vision
technologies. However, existing varifocal elements typically rely on
mechanically-actuated systems with limited tuning speeds and scalability. Here,
an ultrathin electrically controlled varifocal lens based on a liquid crystal
(LC) encapsulated semiconductor metasurface is demonstrated. Enabled by the
field-dependent LC anisotropy, applying a voltage bias across the LC cell
modifies the local phase response of the silicon meta-atoms, in turn modifying
the focal length of the metalens. In a numerical implementation, a
voltage-actuated metalens with continuous zoom and up to 20% total focal shift
is demonstrated. The concept of LC-based metalens is experimentally verified
through the design and fabrication of a bifocal metalens that facilitates
high-contrast switching between two discrete focal lengths upon application of
a 3.2 V$_{\rm pp}$ voltage bias. Owing to their ultrathin thickness and
adaptable design, LC-driven semiconductor metasurfaces open new opportunities
for compact varifocal lensing in a diversity of modern imaging applications.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:45:50 GMT""}]","2021-05-26"
"2101.09326","P. Christopher Staecker","P. Christopher Staecker","Partitions of $n$-valued maps",,,,,"math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An $n$-valued map is a set-valued continuous function $f$ such that $f(x)$
has cardinality $n$ for every $x$. Some $n$-valued maps will ""split"" into a
union of $n$ single-valued maps. Characterizations of splittings has been a
major theme in the topological theory of $n$-valued maps.
  In this paper we consider the more general notion of ""partitions"" of an
$n$-valued map, in which a given map is decomposed into a union of other maps
which may not be single-valued. We generalize several splitting
characterizations which will describe partitions in terms of mixed
configuration spaces and mixed braid groups, and connected components of the
graph of $f$. We demonstrate the ideas with some examples on tori.
  We also discuss the fixed point theory of $n$-valued maps and their
partitions, and make some connections to the theory of finite-valued maps due
to Crabb.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:48:25 GMT""}]","2021-01-26"
"2101.09327","Antonio Leitao","S. Kindermann, A. Leitao","On regularization methods for inverse problems of dynamic type","24 pages, 3 figures","Numerical Functional Analysis and Optimization 27 (2006), no. 2,
  139-160","10.1080/01630560600569973",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider new regularization methods for linear inverse
problems of dynamic type. These methods are based on dynamic programming
techniques for linear quadratic optimal control problems. Two different
approaches are followed: a continuous and a discrete one. We prove
regularization properties and also obtain rates of convergence for the methods
derived from both approaches. A numerical example concerning the dynamic EIT
problem is used to illustrate the theoretical results.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:50:45 GMT""}]","2021-01-26"
"2101.09328","Michael Walton","Andrew Fuchs, Michael Walton, Theresa Chadwick, Doug Lange","Theory of Mind for Deep Reinforcement Learning in Hanabi",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  The partially observable card game Hanabi has recently been proposed as a new
AI challenge problem due to its dependence on implicit communication
conventions and apparent necessity of theory of mind reasoning for efficient
play. In this work, we propose a mechanism for imbuing Reinforcement Learning
agents with a theory of mind to discover efficient cooperative strategies in
Hanabi. The primary contributions of this work are threefold: First, a formal
definition of a computationally tractable mechanism for computing hand
probabilities in Hanabi. Second, an extension to conventional Deep
Reinforcement Learning that introduces reasoning over finitely nested theory of
mind belief hierarchies. Finally, an intrinsic reward mechanism enabled by
theory of mind that incentivizes agents to share strategically relevant private
knowledge with their teammates. We demonstrate the utility of our algorithm
against Rainbow, a state-of-the-art Reinforcement Learning agent.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 20:56:42 GMT""}]","2021-01-26"
"2101.09329","Travis Cuvelier","Travis C. Cuvelier and Takashi Tanaka","Rate of Prefix-free Codes in LQG Control Systems with Side Information","Accepted for publication at CISS 2021","Proceedings of the 55th Annual Conference on Information Sciences
  and Systems (CISS) March 2021",,,"cs.IT cs.SY eess.SP eess.SY math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study an LQG control system where one of two feedback
channels is discrete and incurs a communication cost. We assume that a decoder
(co-located with the controller) can make noiseless measurements of a subset of
the state vector (referred to as side information) meanwhile a remote encoder
(co-located with a sensor) can make arbitrary measurements of the entire state
vector, but must convey its measurements to the decoder over a noiseless binary
channel. Use of the channel incurs a communication cost, quantified as the
time-averaged expected length of prefix-free binary codeword. We study the
tradeoff between the communication cost and control performance. The
formulation motivates a constrained directed information minimization problem,
which can be solved via convex optimization. Using the optimization, we propose
a quantizer design and a subsequent achievability result.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:01:04 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 23:48:34 GMT""},{""version"":""v3"",""created"":""Wed, 17 Mar 2021 18:14:58 GMT""}]","2021-03-19"
"2101.09330","Leonardo Santos","Leonardo Santos","Microscopic Dynamics of Nonlinear Fokker-Planck Equations",,"Phys. Rev. E 103, 032106 (2021)","10.1103/PhysRevE.103.032106",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach to describe the effective microscopic dynamics of
(power-law) nonlinear Fokker-Planck equations. Our formalism is based on a
nonextensive generalization of the Wiener process. This allow us to obtain, in
addition to significant physical insights, several analytical results with
great simplicity. Indeed, we obtain analytical solutions for a nonextensive
version of Brownian free-particle and Ornstein-Uhlenbeck process, and explain
anomalous diffusive behaviours in terms of memory effects in a nonextensive
generalization of Gaussian white noise. Finally, we apply the develop formalism
to model thermal noise in electric circuits.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:03:48 GMT""}]","2021-03-17"
"2101.09332","Perrot K\'evin","Viet-Ha Nguyen and K\'evin Perrot","Rikudo is NP-complete",,,,,"cs.DM cs.CC","http://creativecommons.org/licenses/by/4.0/","  Rikudo is a number-placement puzzle, where the player is asked to complete a
Hamiltonian path on a hexagonal grid, given some clues (numbers already placed
and edges of the path). We prove that the game is complete for NP, even if the
puzzle has no hole. When all odd numbers are placed it is in P, whereas it is
still NP-hard when all numbers of the form $3k+1$ are placed.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:07:22 GMT""}]","2021-01-26"
"2101.09333","Shenjie Huang","Shenjie Huang and Majid Safari","SPAD-Based Optical Wireless Communication with Signal Pre-Distortion and
  Noise Normalization",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, there has been a growing interest in exploring the
application of single-photon avalanche diode (SPAD) in optical wireless
communication (OWC). As a photon counting detector, SPAD can provide much
higher sensitivity compared to the other commonly used photodetectors. However,
SPAD-based receivers suffer from significant dead-time-induced non-linear
distortion and signal dependent noise. In this work, we propose a novel
SPAD-based OWC system in which the non-linear distortion caused by dead time
can be successfully eliminated by the pre-distortion of the signal at the
transmitter. In addition, another system with joint pre-distortion and noise
normalization functionality is proposed. Thanks to the additional noise
normalization process, for the transformed signal at the receiver, the
originally signal dependent noise becomes signal independent so that the
conventional signal detection techniques designed for AWGN channels can be
employed to decode the signal. Our numerical results demonstrate the
superiority of the proposed SPAD-based systems compared to the existing systems
in terms of BER performance and achievable data rate.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:11:27 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 22:36:20 GMT""}]","2022-02-14"
"2101.09334","Ruofan Wu","Ruofan Wu, Zhikai Yao, Jennie Si and He (Helen) Huang","Robotic Knee Tracking Control to Mimic the Intact Human Knee Profile
  Based on Actor-critic Reinforcement Learning",,,"10.1109/JAS.2021.1004272",,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address a state-of-the-art reinforcement learning (RL) control approach to
automatically configure robotic prosthesis impedance parameters to enable
end-to-end, continuous locomotion intended for transfemoral amputee subjects.
Specifically, our actor-critic based RL provides tracking control of a robotic
knee prosthesis to mimic the intact knee profile. This is a significant advance
from our previous RL based automatic tuning of prosthesis control parameters
which have centered on regulation control with a designer prescribed robotic
knee profile as the target. In addition to presenting the complete tracking
control algorithm based on direct heuristic dynamic programming (dHDP), we
provide an analytical framework for the tracking controller with constrained
inputs. We show that our proposed tracking control possesses several important
properties, such as weight convergence of the learning networks, Bellman
(sub)optimality of the cost-to-go value function and control input, and
practical stability of the human-robot system under input constraint. We
further provide a systematic simulation of the proposed tracking control using
a realistic human-robot system simulator, the OpenSim, to emulate how the dHDP
enables level ground walking, walking on different terrains and at different
paces. These results show that our proposed dHDP based tracking control is not
only theoretically suitable, but also practically useful.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:11:29 GMT""}]","2023-03-31"
"2101.09335","Emilio Pisanty","Gregory S. J. Armstrong, Margarita A. Khokhlova, Marie Labeye, Andrew
  S. Maxwell, Emilio Pisanty, and Marco Ruberti","Dialogue on analytical and ab initio methods in attoscience","Proceedings of the round-table panel discussion 'Quantum Battle 3 -
  Numerical vs Analytical Methods' at the Quantum Battles in Attoscience online
  conference (https://www.quantumbattles.com/), the livestream for which can be
  found at https://www.youtube.com/watch?v=VJnFfHVDym4","Eur. Phys. J. D 75, 209 (2021)","10.1140/epjd/s10053-021-00207-3",,"quant-ph physics.atom-ph physics.comp-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  The perceived dichotomy between analytical and ab initio approaches to theory
in attosecond science is often seen as a source of tension and misconceptions.
This Topical Review compiles the discussions held during a round-table panel at
the 'Quantum Battles in Attoscience' CECAM virtual workshop, to explore the
sources of tension and attempt to dispel them. We survey the main theoretical
tools of attoscience -- covering both analytical and numerical methods -- and
we examine common misconceptions, including the relationship between ab initio
approaches and the broader numerical methods, as well as the role of numerical
methods in 'analytical' techniques. We also evaluate the relative advantages
and disadvantages of analytical as well as numerical and ab initio methods,
together with their role in scientific discovery, told through the case studies
of two representative attosecond processes: non-sequential double ionisation
and resonant high-harmonic generation. We present the discussion in the form of
a dialogue between two hypothetical theoreticians, a numericist and an
analytician, who introduce and challenge the broader opinions expressed in the
attoscience community.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:13:35 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 10:38:31 GMT""},{""version"":""v3"",""created"":""Tue, 10 Aug 2021 19:13:45 GMT""}]","2021-08-12"
"2101.09336","Hadjer Benmeziane","Hadjer Benmeziane, Kaoutar El Maghraoui, Hamza Ouarnoughi, Smail Niar,
  Martin Wistuba, Naigang Wang","A Comprehensive Survey on Hardware-Aware Neural Architecture Search","Submitted to Proceedings of IEEE",,,,"cs.LG cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Architecture Search (NAS) methods have been growing in popularity.
These techniques have been fundamental to automate and speed up the time
consuming and error-prone process of synthesizing novel Deep Learning (DL)
architectures. NAS has been extensively studied in the past few years. Arguably
their most significant impact has been in image classification and object
detection tasks where the state of the art results have been obtained. Despite
the significant success achieved to date, applying NAS to real-world problems
still poses significant challenges and is not widely practical. In general, the
synthesized Convolution Neural Network (CNN) architectures are too complex to
be deployed in resource-limited platforms, such as IoT, mobile, and embedded
systems. One solution growing in popularity is to use multi-objective
optimization algorithms in the NAS search strategy by taking into account
execution latency, energy consumption, memory footprint, etc. This kind of NAS,
called hardware-aware NAS (HW-NAS), makes searching the most efficient
architecture more complicated and opens several questions.
  In this survey, we provide a detailed review of existing HW-NAS research and
categorize them according to four key dimensions: the search space, the search
strategy, the acceleration technique, and the hardware cost estimation
strategies. We further discuss the challenges and limitations of existing
approaches and potential future directions. This is the first survey paper
focusing on hardware-aware NAS. We hope it serves as a valuable reference for
the various techniques and algorithms discussed and paves the road for future
research towards hardware-aware NAS.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:13:46 GMT""}]","2021-01-26"
"2101.09337","Shuo Liu","Shuo Liu, Nirupam Gupta, Nitin H. Vaidya","Approximate Byzantine Fault-Tolerance in Distributed Optimization","40 pages, 5 figures, and 1 table. The report is an important
  extension to prior work https://dl.acm.org/doi/abs/10.1145/3382734.3405748,
  and arXiv:2003.09675; Added an extra experiment section in machine learning",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the problem of Byzantine fault-tolerance in distributed
multi-agent optimization. In this problem, each agent has a local cost
function, and in the fault-free case, the goal is to design a distributed
algorithm that allows all the agents to find a minimum point of all the agents'
aggregate cost function. We consider a scenario where some agents might be
Byzantine faulty that renders the original goal of computing a minimum point of
all the agents' aggregate cost vacuous. A more reasonable objective for an
algorithm in this scenario is to allow all the non-faulty agents to compute the
minimum point of only the non-faulty agents' aggregate cost. Prior work shows
that if there are up to $f$ (out of $n$) Byzantine agents then a minimum point
of the non-faulty agents' aggregate cost can be computed exactly if and only if
the non-faulty agents' costs satisfy a certain redundancy property called
$2f$-redundancy. However, $2f$-redundancy is an ideal property that can be
satisfied only in systems free from noise or uncertainties, which can make the
goal of exact fault-tolerance unachievable in some applications. Thus, we
introduce the notion of $(f,\epsilon)$-resilience, a generalization of exact
fault-tolerance wherein the objective is to find an approximate minimum point
of the non-faulty aggregate cost, with $\epsilon$ accuracy. This approximate
fault-tolerance can be achieved under a weaker condition that is easier to
satisfy in practice, compared to $2f$-redundancy. We obtain necessary and
sufficient conditions for achieving $(f,\epsilon)$-resilience characterizing
the correlation between relaxation in redundancy and approximation in
resilience. In case when the agents' cost functions are differentiable, we
obtain conditions for $(f,\epsilon)$-resilience of the distributed
gradient-descent method when equipped with robust gradient aggregation.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:14:25 GMT""},{""version"":""v2"",""created"":""Sat, 3 Apr 2021 22:40:32 GMT""},{""version"":""v3"",""created"":""Thu, 15 Apr 2021 05:57:41 GMT""},{""version"":""v4"",""created"":""Mon, 7 Jun 2021 22:39:01 GMT""}]","2021-06-09"
"2101.09338","Jaime Romero-Barrientos","Jaime Romero-Barrientos","Time-dependent Monte Carlo in fissile systems with beta-delayed neutron
  precursors","134 pages, 38 figures. A dissertation submitted in partial
  fulfillmentof the requirements for the degree of Doctor of Philosophy
  (Physical Sciences) at the University of Chile. 2021",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the field of nuclear reactor physics, transient phenomena are usually
studied using deterministic or hybrids methods. These methods require many
approximations, such as: geometry, time and energy discretizations, material
homogenization and assumption of diffusion conditions, among others. In this
context, Monte Carlo simulations are specially adequate to study these
problems. Challenges presented when using Monte Carlo simulations in space-time
kinetics in fissile systems are the different time-scales involved in prompt
and delayed neutron emission, which implies that results obtained have a large
variance associated if an analog Monte Carlo simulation is utilized.
Furthermore, in both deterministic and Monte Carlo simulations delayed neutron
precursors are grouped in a $6$- or $8$- group structure, but nowadays there is
not a solid reason to keep this aggregation. In this work, and for the first
time, individual precursor data is implemented in a Monte Carlo simulation,
explicitly including the time dependence related to the $\beta$-delayed neutron
emission. This was accomplished by modifying the open source Monte Carlo code
OpenMC. In the modified code -- Time Dependent OpenMC or OpenMC(TD) -- time
dependency related to delayed neutron emission originated from $\beta$-decay
was addressed. Continuous energy neutron cross-sections data used comes from
JEFF-$3$.$1$.$1$ library. Individual precursor data was taken from
JEFF-$3$.$1$.$1$ (cumulative yields) and ENDF-B/VIII.$0$ (delayed neutron
emission probabilities and delayed neutron energy spectra). OpenMC(TD) was
tested in: i) a monoenergetic system; ii) an energy dependent unmoderated
system where the precursors were taken individually or in a group structure;
and finally iii) a light-water moderated energy dependent system, using
$6$-groups, $50$ and $40$ individual precursors.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:19:19 GMT""}]","2021-01-26"
"2101.09339","Antonio Leitao","S. Kindermann, A. Leitao","On regularization methods based on dynamic programming techniques","21 pages, 2 figures","Applicable Analysis 86 (2007), no. 5, 611-632","10.1080/00036810701354953",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we investigate the connection between regularization theory
for inverse problems and dynamic programming theory. This is done by developing
two new regularization methods, based on dynamic programming techniques. The
aim of these methods is to obtain stable approximations to the solution of
linear inverse ill-posed problems. We follow two different approaches and
derive a continuous and a discrete regularization method. Regularization
properties for both methods are proved as well as rates of convergence. A
numerical benchmark problem concerning integral operators with convolution
kernels is used to illustrate the theoretical results.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:21:46 GMT""}]","2021-01-26"
"2101.09340","Erdogan Aydin","Sultan Aldirmaz-Colak, Erdogan Aydin, Yasin Celik, Yusuf Acar,
  Ertugrul Basar","Pulse Index Modulation","5 pages, submitted for publication",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Emerging systems such as Internet-of-things (IoT) and machine-to-machine
(M2M) communications have strict requirements on the power consumption of used
equipments and associated complexity in the transceiver design. As a result,
multiple-input multiple-output (MIMO) solutions might not be directly suitable
for these system due to their high complexity, inter-antenna synchronization
(IAS) requirement, and high inter-antenna interference (IAI) problems. In order
to overcome these problems, we propose two novel index modulation (IM) schemes,
namely pulse index modulation (PIM) and generalized PIM (GPIM) for single-input
single-output (SISO) schemes. The proposed models use well-localized and
orthogonal Hermite-Gaussian pulses for data transmission and provide high
spectral efficiency owing to the Hermite-Gaussian pulse indices. Besides, it
has been shown via analytical derivations and computer simulations that the
proposed PIM and GPIM systems have better error performance and considerable
signal-to-noise ratio (SNR) gain compared to existing spatial modulation (SM),
quadrature SM (QSM), and traditional M-ary systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:34:00 GMT""}]","2021-01-26"
"2101.09341","Helmut B\""olcskei","V. Vla\v{c}i\'c, C. Aubel, H. B\""olcskei","Beurling-type density criteria for system identification",,,,,"cs.IT cs.SY eess.SY math.FA math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper addresses the problem of identifying a linear time-varying (LTV)
system characterized by a (possibly infinite) discrete set of delay-Doppler
shifts without a lattice (or other geometry-discretizing) constraint on the
support set. Concretely, we show that a class of such LTV systems is
identifiable whenever the upper uniform Beurling density of the delay-Doppler
support sets, measured uniformly over the class, is strictly less than 1/2. The
proof of this result reveals an interesting relation between LTV system
identification and interpolation in the Bargmann-Fock space. Moreover, we show
that this density condition is also necessary for classes of systems invariant
under time-frequency shifts and closed under a natural topology on the support
sets. We furthermore show that identifiability guarantees robust recovery of
the delay-Doppler support set, as well as the weights of the individual
delay-Doppler shifts, both in the sense of asymptotically vanishing
reconstruction error for vanishing measurement error.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:44:12 GMT""}]","2021-01-26"
"2101.09342","Viacheslav Klimenko","V. V. Klimenko, A. V. Ivanchik","Influence of radiative pumping on the HD rotational level populations in
  diffuse molecular clouds of the interstellar medium","9 pages, 5 figures, 3 tables","Astronomy Letters, 2020, Vol. 46, Iss. 4, pp. 224-234","10.1134/S1063773720040064",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a theoretical calculation of the influence of ultraviolet
radiative pumping on the excitation of the rotational levels of the ground
vibrational state for HD molecules under conditions of the cold diffuse
interstellar medium (ISM). Two main excitation mechanisms have been taken into
account in our analysis: (i) collisions with atoms and molecules and (ii)
radiative pumping by the interstellar ultraviolet (UV) radiation field. The
calculation of the radiative pumping rate coefficients $\Gamma_{\rm ij}$
corresponding to Drane's model of the field of interstellar UV radiation,
taking into account the self-shielding of HD molecules, is performed. We found
that the population of the first HD rotational level ($J = 1$) is determined
mainly by radiative pumping rather than by collisions if the thermal gas
pressure $p_{\rm
th}\le10^4\left(\frac{I_{\rm{UV}}}{1}\right)\,\mbox{K\,cm}^{-3}$ and the column
density of HD is lower than $\log N({\rm{HD}})<15$. Under this constraint the
populations of rotational levels of HD turns out to be as well a more sensitive
indicator of the UV radiation intensity than the fine-structure levels of
atomic carbon. We suggest that taking into account radiative pumping of HD
rotational levels may be important for the problem of the cooling of primordial
gas at high redshift: ultraviolet radiation from first stars can increase the
rate of HD cooling of the primordial gas in the early Universe.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:46:34 GMT""}]","2021-01-26"
"2101.09343","Bin Han","Amina Lejla Ibrahimpasic, Bin Han, and Hans D. Schotten","AI-Empowered VNF Migration as a Cost-Loss-Effective Solution for Network
  Resilience","Accepted by the IEEE WCNC 2021 Workshop on Intelligent Computing and
  Caching at the Network Edge","2021 IEEE Wireless Communications and Networking Conference
  Workshops (WCNCW)","10.1109/WCNCW49093.2021.9420029",,"cs.NI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With a wide deployment of Multi-Access Edge Computing (MEC) in the Fifth
Generation (5G) mobile networks, virtual network functions (VNF) can be
flexibly migrated between difference locations, and therewith significantly
enhances the network resilience to counter the degradation in quality of
service (QoS) due to network function outages. A balance has to be taken
carefully, between the loss reduced by VNF migration and the operations cost
generated thereby. To achieve this in practical scenarios with realistic user
behavior, it calls for models of both cost and user mobility. This paper
proposes a novel cost model and a AI-empowered approach for a rational
migration of stateful VNFs, which minimizes the sum of operations cost and
potential loss caused by outages, and is capable to deal with the complex
realistic user mobility patterns.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:47:41 GMT""}]","2021-11-30"
"2101.09344","Moallison Cavalcante","Helena Bragan\c{c}a, Moallison F. Cavalcante, R. G. Pereira and Maria
  C. O. Aguiar","Quench dynamics and relaxation of a spin coupled to interacting leads","11 pages, 5 figures","Phys. Rev. B 103, 125152 (2021)","10.1103/PhysRevB.103.125152",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a quantum quench in which a magnetic impurity is suddenly coupled to
Hubbard chains, whose low-energy physics is described by Tomonaga-Luttinger
liquid theory. Using the time-dependent density-matrix renormalization-group
(tDMRG) technique, we analyze the propagation of charge, spin and entanglement
in the chains after the quench and relate the light-cone velocities to the
dispersion of holons and spinons. We find that the local magnetization at the
impurity site decays faster if we increase the interaction in the chains, even
though the spin velocity decreases. We derive an analytical expression for the
relaxation of the impurity magnetization which is in good agreement with the
tDMRG results at intermediate timescales, providing valuable insight into the
time evolution of the Kondo screening cloud in interacting systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:50:31 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 14:14:23 GMT""}]","2021-03-31"
"2101.09345","Fouzi Harrag","Fouzi Harrag, Maria Debbah, Kareem Darwish, Ahmed Abdelali","BERT Transformer model for Detecting Arabic GPT2 Auto-Generated Tweets",,"Proceedings of the Fifth Arabic Natural Language Processing
  Workshop (WANLP @ COLING 2020)",,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  During the last two decades, we have progressively turned to the Internet and
social media to find news, entertain conversations and share opinion. Recently,
OpenAI has developed a ma-chine learning system called GPT-2 for Generative
Pre-trained Transformer-2, which can pro-duce deepfake texts. It can generate
blocks of text based on brief writing prompts that look like they were written
by humans, facilitating the spread false or auto-generated text. In line with
this progress, and in order to counteract potential dangers, several methods
have been pro-posed for detecting text written by these language models. In
this paper, we propose a transfer learning based model that will be able to
detect if an Arabic sentence is written by humans or automatically generated by
bots. Our dataset is based on tweets from a previous work, which we have
crawled and extended using the Twitter API. We used GPT2-Small-Arabic to
generate fake Arabic Sentences. For evaluation, we compared different recurrent
neural network (RNN) word embeddings based baseline models, namely: LSTM,
BI-LSTM, GRU and BI-GRU, with a transformer-based model. Our new
transfer-learning model has obtained an accuracy up to 98%. To the best of our
knowledge, this work is the first study where ARABERT and GPT2 were combined to
detect and classify the Arabic auto-generated texts.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:50:38 GMT""}]","2021-01-26"
"2101.09346","Shixiang Chen","Shixiang Chen, Alfredo Garcia, Mingyi Hong, Shahin Shahrampour","On the Local Linear Rate of Consensus on the Stiefel Manifold",,,,,"math.OC cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  We study the convergence properties of Riemannian gradient method for solving
the consensus problem (for an undirected connected graph) over the Stiefel
manifold. The Stiefel manifold is a non-convex set and the standard notion of
averaging in the Euclidean space does not work for this problem. We propose
Distributed Riemannian Consensus on Stiefel Manifold (DRCS) and prove that it
enjoys a local linear convergence rate to global consensus. More importantly,
this local rate asymptotically scales with the second largest singular value of
the communication matrix, which is on par with the well-known rate in the
Euclidean space. To the best of our knowledge, this is the first work showing
the equality of the two rates. The main technical challenges include (i)
developing a Riemannian restricted secant inequality for convergence analysis,
and (ii) to identify the conditions (e.g., suitable step-size and
initialization) under which the algorithm always stays in the local region.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:52:38 GMT""}]","2021-01-26"
"2101.09347","Iyanuoluwa Emiola","Iyanuoluwa Emiola, Laurent Njilla and Chinwendu Enyioha","On Distributed Optimization in the Presence of Malicious Agents",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider an unconstrained distributed optimization problem
over a network of agents, in which some agents are adversarial. We solve the
problem via gradient-based distributed optimization algorithm and characterize
the effect of the adversarial agents on the convergence of the algorithm to the
optimal solution. The attack model considered is such that agents locally
perturb their iterates before broadcasting it to neighbors; and we analyze the
case in which the adversarial agents cooperate in perturbing their estimates
and the case where each adversarial agent acts independently. Based on the
attack model adopted in the paper, we show that the solution converges to the
neighborhood of the optimal solution and depends on the magnitude of the attack
(perturbation) term. The analyses presented establishes conditions under which
the malicious agents have enough information to obstruct convergence to the
optimal solution by the non-adversarial agents.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:59:58 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 06:14:03 GMT""}]","2021-03-22"
"2101.09348","Franklin Mingzhe Li","Franklin Mingzhe Li, Di Laura Chen, Mingming Fan, Khai N. Truong","""I Choose Assistive Devices That Save My Face"" A Study on Perceptions of
  Accessibility and Assistive Technology Use Conducted in China","Proceedings of the 2021 CHI Conference on Human Factors in Computing
  Systems (CHI '21)",,"10.1145/3411764.3445321",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Despite the potential benefits of assistive technologies (ATs) for people
with various disabilities, only around 7% of Chinese with disabilities have had
an opportunity to use ATs. Even for those who have used ATs, the abandonment
rate was high. Although China has the world's largest population with
disabilities, prior research exploring how ATs are used and perceived, and why
ATs are abandoned have been conducted primarily in North America and Europe. In
this paper, we present an interview study conducted in China with 26 people
with various disabilities to understand their practices, challenges,
perceptions, and misperceptions of using ATs. From the study, we learned about
factors that influence AT adoption practices (e.g., misuse of accessible
infrastructure, issues with replicating existing commercial ATs), challenges
using ATs in social interactions (e.g., Chinese stigma), and misperceptions
about ATs (e.g., ATs should overcome inaccessible social infrastructures).
Informed by the findings, we derive a set of design considerations to bridge
the existing gaps in AT design (e.g., manual vs. electronic ATs) and to improve
ATs' social acceptability in China.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:06:29 GMT""}]","2021-01-26"
"2101.09349","Theodore Yoder","Rahul Sarkar and Theodore J. Yoder","A graph-based formalism for surface codes and twists","47 pages + appendix, 20 figures",,,,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Twist defects in surface codes can be used to encode more logical qubits,
improve the code rate, and implement logical gates. In this work we provide a
rigorous formalism for constructing surface codes with twists generalizing the
well-defined homological formalism introduced by Kitaev for describing CSS
surface codes. In particular, we associate a surface code to \emph{any} graph
$G$ embedded on \emph{any} 2D-manifold, in such a way that (1) qubits are
associated to the vertices of the graph, (2) stabilizers are associated to
faces, (3) twist defects are associated to odd-degree vertices. In this way, we
are able to reproduce the variety of surface codes, with and without twists, in
the literature and produce some new examples. We also calculate and bound
various code properties such as the rate and distance in terms of topological
graph properties such as genus, systole, and face-width.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:08:56 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 20:44:17 GMT""}]","2023-03-23"
"2101.09350","Lucrezia Cossetti","Biagio Cassano, Lucrezia Cossetti, Luca Fanelli","Eigenvalue bounds and spectral stability of Lam\'e operators with
  complex potentials",,,,,"math.SP math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to providing quantitative bounds on the location of
eigenvalues, both discrete and embedded, of non self-adjoint Lam\'e operators
of elasticity $-\Delta^\ast + V$ in terms of suitable norms of the potential
$V$. In particular, this allows to get sufficient conditions on the size of the
potential such that the point spectrum of the perturbed operator remains empty.
In three dimensions we show full spectral stability under suitable
form-subordinated perturbations: we prove that the spectrum is purely
continuous and coincides with the non negative semi-axis as in the free case.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:11:02 GMT""}]","2021-01-26"
"2101.09358","Kabir Suara","Andrea Giudici, Kabir Suara, Tarmo Soomere and Richard Brown","Tracking areas with increased likelihood of surface particle aggregation
  in the Gulf of Finland: A first look at persistent Lagrangian Coherent
  Structures (LCS)","25 Pages, 5 Figure, Accepted to be published in the Journal of Marine
  Systems",,"10.1016/j.jmarsys.2021.103514",,"physics.ao-ph physics.flu-dyn physics.geo-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We explore the possibility to identify areas of intense patch formation from
floating items due to systematic convergence of surface velocity fields by
means of a visual comparison of Lagrangian Coherent Structures (LCS) and
estimates of areas prone to patch formation using the concept of Finite-Time
Compressibility (FTC, a generalisation of the notion of time series of
divergence). The LCSs are evaluated using the Finite Time Lyapunov Exponent
(FTLE) method. The test area is the Gulf of Finland (GoF) in the Baltic Sea. A
basin-wide spatial average of backward FTLE is calculated for the GoF for the
first time. This measure of the mixing strength displays a clear seasonal
pattern. The evaluated backward FTLE features are linked with potential patch
formation regions with high FTC levels. It is shown that areas hosting frequent
upwelling or downwelling have consistently stronger than average mixing
intensity. The combination of both methods, FTC and LCS, has the potential of
being a powerful tool to identify the formation of patches of pollution at the
sea surface.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:09:57 GMT""}]","2021-02-11"
"2101.09363","John Baez","John C. Baez, Kenny Courser and Christina Vasilakopoulou","Structured versus Decorated Cospans","39 pages, version for Compositionality","Compositionality 4, 3 (2022)","10.32408/compositionality-4-3",,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One goal of applied category theory is to understand open systems. We compare
two ways of describing open systems as cospans equipped with extra data. First,
given a functor $L \colon \mathsf{A} \to \mathsf{X}$, a ""structured cospan"" is
a diagram in $\mathsf{X}$ of the form $L(a) \rightarrow x \leftarrow L(b)$. If
$\mathsf{A}$ and $\mathsf{X}$ have finite colimits and $L$ preserves them, it
is known that there is a symmetric monoidal double category whose objects are
those of $\mathsf{A}$ and whose horizontal 1-cells are structured cospans.
Second, given a pseudofunctor $F \colon \mathsf{A} \to \mathbf{Cat}$, a
""decorated cospan"" is a diagram in $\mathsf{A}$ of the form $a \rightarrow m
\leftarrow b$ together with an object of $F(m)$. Generalizing the work of Fong,
we show that if $\mathsf{A}$ has finite colimits and $F \colon (\mathsf{A},+)
\to (\mathsf{Cat},\times)$ is symmetric lax monoidal, there is a symmetric
monoidal double category whose objects are those of $\mathsf{A}$ and whose
horizontal 1-cells are decorated cospans. We prove that under certain
conditions, these two constructions become isomorphic when we take $\mathsf{X}
= \int F$ to be the Grothendieck category of $F$. We illustrate these ideas
with applications to electrical circuits, Petri nets, dynamical systems and
epidemiological modeling.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:18:10 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 22:47:59 GMT""},{""version"":""v3"",""created"":""Fri, 22 Apr 2022 21:22:01 GMT""},{""version"":""v4"",""created"":""Tue, 30 Aug 2022 18:32:12 GMT""}]","2022-09-01"
"2101.09364","William Faris","William G. Faris","Rooted tree graphs and the Butcher group: Combinatorics of elementary
  perturbation theory","32 pages with 12 figures, to appear in Festschrift for Charles M.
  Newman","Sojourns in Probability Theory and Statistical Physics II (Vladas
  Sidoravicius, editor), Springer Proceedings in Mathematics & Statistics 299,
  Springer, Singapore, 2019, pp. 135-166",,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The perturbation expansion of the solution of a fixed point equation or of an
ordinary differential equation may be expressed as a power series in the
perturbation parameter. The terms in this series are indexed by rooted trees
and depend on a parameter in the equation in a way determined by the structure
of the tree. Power series of this form may be considered more generally; there
are two interesting and useful group structures on these series, corresponding
to operations of composition and substitution. The composition operation
defines the Butcher group, an infinite dimensional group that was first
introduced in the context of numerical analysis. This survey discusses various
ways of realizing these rooted trees: as labeled rooted trees, or increasing
labeled rooted trees, or unlabeled rooted trees. It is argued that the simplest
framework is to use labeled rooted trees.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:18:56 GMT""}]","2021-03-30"
"2101.09365","Vasudevan Nagendra","Vasudevan Nagendra, Abhishek Pokala, Arani Bhattacharya, Samir Das","MAVERICK: Proactively detecting network control plane bugs using
  structural outlierness",,,,,"cs.CR cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proactive detection of network configuration bugs is important to ensure its
proper functioning and reduce cost of network administrator. In this research,
we propose to build the control plane verification engine MAVERICK that detects
the bugs in the network control plane i.e., network device configurations and
control plane states. MAVERICK automatically infers signatures for the control
plane configurations (e.g., ACLs, route-maps, route-policies and so on) and
states that allows administrators to automatically detect bugs with minimal
human intervention. MAVERICK achieves this by effectively leveraging any
structural deviation i.e., outliers in the network configurations that is
organized as simple or complexly nested key-value pairs. The outliers that are
calculated using signature-based outlier detection mechanism are further
characterized for its severity and ranked or re-prioritized according to their
criticality. We consider a wide set of heuristics and domain expertise factors
for effectively to reduce both false positives and false negatives.Our
evaluation on four medium to large-scale enterprise networks show that MAVERICK
can automatically detect the bugs present in the network with approximately 75%
accuracy. Further-more, With minimal administrator input i.e., with a few
minutes of signature re-tuning, MAVERICK allows the administrators to
effectively detect approximately 94 - 100% of the bugs present in the network,
thereby ranking down less severe bugs and removing false positives.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:23:31 GMT""}]","2021-01-26"
"2101.09366","David Pelosi","David Pelosi, Nicola Tomassetti, Matteo Duranti","Development of a web application for monitoring solar activity and
  cosmic radiation","4 pages, 1 Figure","IL NUOVO CIMENTO 44 C (2021) 97","10.1393/ncc/i2021-21097-2",,"physics.space-ph astro-ph.SR hep-ph","http://creativecommons.org/licenses/by/4.0/","  The flux of cosmic rays (CRs) in the heliosphere is subjected to remarkable
time variations caused by the 11-year cycle of solar activity. To help the
study of this effect, we have developed a web application (Heliophysics Virtual
Observatory) that collects real-time data on solar activity, interplanetary
plasma, and charged radiation from several space missions or observatories. As
we will show, our application can be used to visualize, manipulate, and
download updated data on sunspots, heliospheric magnetic fields, solar wind,
and neutron monitors counting rates. Data and calculations are automatically
updated on daily basis. A nowcasting for the energy spectrum of CR protons
near-Earth is also provided using calculations and real-time neutron monitor
data as input.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:24:31 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 14:36:42 GMT""}]","2021-09-02"
"2101.09367","Thomas Haettel","Thomas Haettel","Injective metrics on buildings and symmetric spaces","16 pages. v4: Final version, to appear in Bull LMS",,,,"math.MG math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we show that the Goldman-Iwahori metric on the space of all
norms on a fixed vector space satisfies the Helly property for balls. On the
non-Archimedean side, we deduce that most classical Bruhat-Tits buildings may
be endowed with a natural piecewise $\ell^\infty$ metric which is injective. We
also prove that most classical semisimple groups over non-Archimedean local
fields act properly and cocompactly on Helly graphs. This gives another proof
of biautomaticity for their uniform lattices. On the Archimedean side, we
deduce that most classical symmetric spaces of non-compact type may be endowed
with a natural invariant Finsler metric, restricting to an $\ell^\infty$ on
each flat, which is coarsely injective. We also prove that most classical
semisimple groups over Archimedean local fields act properly and cocompactly on
injective metric spaces. We identify the injective hull of the symmetric space
of $\operatorname{GL}(n,\mathbb{R})$ as the space of all norms on
$\mathbb{R}^n$. The only exception is the special linear group: if $n=3$ or $n
\geq 5$ and $\mathbb{K}$ is a local field, we show that
$\operatorname{SL}(n,\mathbb{K})$ does not act properly and coboundedly on an
injective metric space.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:26:41 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 20:30:20 GMT""},{""version"":""v3"",""created"":""Mon, 21 Mar 2022 11:05:49 GMT""},{""version"":""v4"",""created"":""Sun, 1 May 2022 19:29:10 GMT""}]","2022-05-03"
"2101.09368","Jens Kaiser","Jens Kaiser, Sinan Kurtyigit, Serge Kotchourko, Dominik Schlechtweg","Effects of Pre- and Post-Processing on type-based Embeddings in Lexical
  Semantic Change Detection","9 pages, 16 figures, 3 tables",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Lexical semantic change detection is a new and innovative research field. The
optimal fine-tuning of models including pre- and post-processing is largely
unclear. We optimize existing models by (i) pre-training on large corpora and
refining on diachronic target corpora tackling the notorious small data
problem, and (ii) applying post-processing transformations that have been shown
to improve performance on synchronic tasks. Our results provide a guide for the
application and optimization of lexical semantic change detection models across
various learning scenarios.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:34:15 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 19:32:24 GMT""}]","2021-01-28"
"2101.09369","Gil de Oliveira-Neto","G. Oliveira-Neto and L. Fazza Marcon","Complete noncommutativity in a cosmological model with radiation","The paper has 35 pages and 14 figures","Eur. Phys. J. Plus 136, 584 (2021)","10.1140/epjp/s13360-021-01587-6",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to try explaining the present accelerated expansion of the universe,
we consider the most complete noncommutativity, of a certain type, in a
Friedmann-Robertson-Walker cosmological model, coupled to a perfect fluid. We
use the ADM formalism in order to write the gravitational Hamiltonian of the
model and the Schutz's formalism in order to write the perfect fluid
Hamiltonian. The noncommutativity is introduced by four nontrivial Poisson
brackets between all geometrical as well as matter variables of the model. Each
nontrivial Poisson bracket is associated to a noncommutative parameter. We
recover the description in terms of commutative variables by introducing four
variables transformations that depend on the noncommutative parameters. Using
those variables transformations, we rewrite the total noncommutative
Hamiltonian of the model in terms of commutative variables. From the resulting
Hamiltonian, we obtain the scale factor dynamical equations for a generic
perfect fluid. In order to solve these equations, we restrict our attention to
a model where the perfect fluid is radiation. The solutions depend on six
parameters: the four noncommutative parameters, a parameter associated with the
fluid energy $C$, and the curvature parameter $k$. They also depend on the
initial conditions of the model variables. We compare the noncommutative
solutions to the corresponding commutative ones and determine how the former
ones differ from the latter ones. The comparison shows that the noncommutative
model is very useful for describing the accelerated expansion of the universe.
We also obtain estimates for one of the noncommutative parameters.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:39:04 GMT""}]","2021-06-23"
"2101.09370","Rituraj Rituraj","Rituraj, Meir Orenstein, Shanhui Fan","Photonic Chern insulators from two-dimensional atomic lattices
  interacting with a single surface plasmon polariton",,"Phys. Rev. B 103, 125423 (2021)","10.1103/PhysRevB.103.125423",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the polaritonic bandstructure of two-dimensional atomic lattices
coupled to a single excitation of a surface plasmon polariton mode. We show the
possibility of realizing topological gaps with different Chern numbers by
having resonant atomic transitions to excited states with different angular
momentum. We employ a computational method based on the recently proposed
Dirichlet-to-Neumann (DtN) map technique which accurately models non-Markovian
dynamics as well as interactions involving higher-order electric and magnetic
multipole transitions. We design topologically robust edge states which are
used to achieve unidirectional emission and non-reciprocal transmission of
single photons. We also point out the challenges in realizing bands with higher
Chern numbers in such systems.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:42:00 GMT""}]","2021-03-31"
"2101.09371","Ryan Rubenzahl","Ryan A. Rubenzahl, Fei Dai, Andrew W. Howard, Ashley Chontos, Steven
  Giacalone, Jack Lubin, Lee J. Rosenthal, Howard Isaacson, Natalie M. Batalha,
  Ian J. M. Crossfield, Courtney Dressing, Benjamin Fulton, Daniel Huber,
  Stephen R. Kane, Erik A Petigura, Paul Robertson, Arpita Roy, Lauren M.
  Weiss, Corey Beard, Michelle L. Hill, Andrew Mayo, Teo Mo\v{c}nik, Joseph M.
  Akana Murphy, and Nicholas Scarsdale","The TESS-Keck Survey IV: A Retrograde, Polar Orbit for the
  Ultra-Low-Density, Hot Super-Neptune WASP-107b","13 pages, 6 figures, to be published in The Astronomical Journal","2021 AJ 161 119","10.3847/1538-3881/abd177",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We measured the Rossiter-McLaughlin effect of WASP-107b during a single
transit with Keck/HIRES. We found the sky-projected inclination of WASP-107b's
orbit, relative to its host star's rotation axis, to be $|\lambda| =
{118}^{+38}_{-19}$ degrees. This confirms the misaligned/polar orbit that was
previously suggested from spot-crossing events and adds WASP-107b to the
growing population of hot Neptunes in polar orbits around cool stars. WASP-107b
is also the fourth such planet to have a known distant planetary companion. We
examined several dynamical pathways by which this companion could have induced
such an obliquity in WASP-107b. We find that nodal precession and disk
dispersal-driven tilting can both explain the current orbital geometry while
Kozai-Lidov cycles are suppressed by general relativity. While each hypothesis
requires a mutual inclination between the two planets, nodal precession
requires a much larger angle which for WASP-107 is on the threshold of
detectability with future Gaia astrometric data. As nodal precession has no
stellar type dependence, but disk dispersal-driven tilting does, distinguishing
between these two models is best done on the population level. Finding and
characterizing more extrasolar systems like WASP-107 will additionally help
distinguish whether the distribution of hot-Neptune obliquities is a dichotomy
of aligned and polar orbits or if we are uniformly sampling obliquities during
nodal precession cycles.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:44:43 GMT""}]","2021-02-17"
"2101.09372","Chao He","Chao He, Jianyu Lin, Jintao Chang, Jacopo Antonello, Ben Dai, Jingyu
  Wang, Jiahe Cui, Ji Qi, Min Wu, Daniel S. Elson, Peng Xi, Andrew Forbes and
  Martin J. Booth","Full Poincar\'e polarimetry enabled through physical inference",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While polarisation sensing is vital in many areas of research, with
applications spanning from microscopy to aerospace, traditional approaches are
limited by method-related error amplification or accumulation, placing
fundamental limitations on precision and accuracy in single-shot polarimetry.
Here, we put forward a new measurement paradigm to circumvent this, introducing
the notion of a universal full Poincar\'e generator to map all polarisation
analyser states into a single vectorially structured light field, allowing all
vector components to be analysed in a single-shot with theoretically
user-defined precision. To demonstrate the advantage of our approach, we use a
common GRIN optic as our mapping device and show mean errors of <1% for each
vector component, enhancing the sensitivity by around three times, allowing us
to sense weak polarisation aberrations not measurable by traditional
single-shot techniques. Our work paves the way for next-generation polarimetry,
impacting a wide variety of applications relying on weak vector measurement.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:47:38 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 21:23:24 GMT""},{""version"":""v3"",""created"":""Thu, 15 Sep 2022 14:33:31 GMT""}]","2022-09-16"
"2101.09373","Xiaowei Hu","Xiaowei Hu, Peng Li","Relief and Stimulus in A Cross-sector Multi-product Scarce Resource
  Supply Chain Network",,"Transportation Research Part E: Logistics and Transportation
  Review, 168, 102932 (2022)",,,"econ.TH econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  In the era of a growing population, systemic changes to the world, and the
rising risk of crises, humanity has been facing an unprecedented challenge of
resource scarcity. Confronting and addressing the issues concerning the scarce
resource's conservation, competition, and stimulation by grappling its
characteristics and adopting viable policy instruments calls the
decision-maker's attention with a paramount priority. In this paper, we develop
the first general decentralized cross-sector supply chain network model that
captures the unique features of scarce resources under a unifying fiscal policy
scheme. We formulate the problem as a network equilibrium model with
finite-dimensional variational inequality theories. We then characterize the
network equilibrium with a set of classic theoretical properties, as well as
with a set of properties that are novel to the network games application
literature, namely, the lowest eigenvalue of the game Jacobian. Lastly, we
provide a series of illustrative examples, including a medical glove supply
network, to showcase how our model can be used to investigate the efficacy of
the imposed policies in relieving supply chain distress and stimulating
welfare. Our managerial insights inform and expand the political dialogues on
fiscal policy design, public resource legislation, social welfare
redistribution, and supply chain practice toward sustainability.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:48:41 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 04:41:55 GMT""},{""version"":""v3"",""created"":""Tue, 22 Nov 2022 05:20:52 GMT""}]","2022-11-23"
"2101.09374","Fanghua Ye","Fanghua Ye, Jarana Manotumruksa, Qiang Zhang, Shenghui Li, Emine
  Yilmaz","Slot Self-Attentive Dialogue State Tracking","11 pages, to appear at The Web Conference (WWW) 2021",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An indispensable component in task-oriented dialogue systems is the dialogue
state tracker, which keeps track of users' intentions in the course of
conversation. The typical approach towards this goal is to fill in multiple
pre-defined slots that are essential to complete the task. Although various
dialogue state tracking methods have been proposed in recent years, most of
them predict the value of each slot separately and fail to consider the
correlations among slots. In this paper, we propose a slot self-attention
mechanism that can learn the slot correlations automatically. Specifically, a
slot-token attention is first utilized to obtain slot-specific features from
the dialogue context. Then a stacked slot self-attention is applied on these
features to learn the correlations among slots. We conduct comprehensive
experiments on two multi-domain task-oriented dialogue datasets, including
MultiWOZ 2.0 and MultiWOZ 2.1. The experimental results demonstrate that our
approach achieves state-of-the-art performance on both datasets, verifying the
necessity and effectiveness of taking slot correlations into consideration.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:48:51 GMT""}]","2021-01-26"
"2101.09375","Wenjun Liu","Wenjun Liu, Chang Liu, Guang Chen, Peng Hang, Alois Knoll","Gaussian Process-Based Model Predictive Control for Overtaking",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel framework for addressing the challenge of
autonomous overtaking and obstacle avoidance, which incorporates the overtaking
path planning into Gaussian Process-based model predictive control (GPMPC).
Compared with the conventional control strategies, this approach has two main
advantages. Firstly, combining Gaussian Process (GP) regression with a nominal
model allows for learning from model mismatch and unmodeled dynamics, which
enhances a simple model and delivers significantly better results. Due to the
approximation for propagating uncertainties, we can furthermore satisfy the
constraints and thereby safety of the vehicle is ensured. Secondly, we convert
the geometric relationship between the ego vehicle and other obstacle vehicles
into the constraints. Without relying on a higherlevel path planner, this
approach substantially reduces the computational burden. In addition, we
transform the state constraints under the model predictive control (MPC)
framework into a soft constraint and incorporate it as relaxed barrier function
into the cost function, which makes the optimizer more efficient. Simulation
results reveal the usefulness of the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:05:51 GMT""}]","2021-01-26"
"2101.09376","Aaron Hertzmann","Aaron Hertzmann","The Role of Edges in Line Drawing Perception","Accepted to _Perception_","Perception. 2021;50(3):266-275","10.1177/0301006621994407",,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has often been conjectured that the effectiveness of line drawings can be
explained by the similarity of edge images to line drawings. This paper
presents several problems with explaining line drawing perception in terms of
edges, and how the recently-proposed Realism Hypothesis of Hertzmann (2020)
resolves these problems. There is nonetheless existing evidence that edges are
often the best features for predicting where people draw lines; this paper
describes how the Realism Hypothesis can explain this evidence.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:22:05 GMT""}]","2021-03-15"
"2101.09377","Brian Collier","Steve Bradlow, Brian Collier, Oscar Garcia-Prada, Peter Gothen,
  Andr\'e Oliveira","A general Cayley correspondence and higher Teichm\""uller spaces","66 pages, 4 figures, comments welcome",,,,"math.AG math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new class of $\mathfrak{sl}_2$-triples in a complex simple Lie
algebra $\mathfrak{g}$, which we call magical. Such an $\mathfrak{sl}_2$-triple
canonically defines a real form and various decompositions of $\mathfrak{g}$.
Using this decomposition data, we explicitly parameterize special connected
components of the moduli space of Higgs bundles on a compact Riemann surface
$X$ for an associated real Lie group, hence also of the corresponding character
variety of representations of $\pi_1X$ in the associated real Lie group. This
recovers known components when the real group is split, Hermitian of tube type,
or $\mathrm{SO}_{p,q}$ with $1<p\leq q$, and also constructs previously unknown
components for the quaternionic real forms of $\mathrm{E}_6$, $\mathrm{E}_7$,
$\mathrm{E}_8$ and $\mathrm{F}_4$. The classification of magical
$\mathfrak{sl}_2$-triples is shown to be in bijection with the set of
$\Theta$-positive structures in the sense of Guichard--Wienhard, thus the
mentioned parameterization conjecturally detects all examples of higher
Teichm\""uller spaces. Indeed, we discuss properties of the surface group
representations obtained from these Higgs bundle components and their relation
to $\Theta$-positive Anosov representations, which indicate that this
conjecture holds.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:23:22 GMT""}]","2021-01-26"
"2101.09378","Bianca Trov\`o","Bianca Trov\`o and Nazzareno Massari","Ants-Review: a Protocol for Incentivized Open Peer-Reviews on Ethereum","8 pages, 1 figure, to appear as ""B. Trov\`o, N. Massari
  (forthcoming). Ants-Review: a Protocol for Incentivized Open Peer-Reviews on
  Ethereum. In: Bartosz Balis, Dora B. Heras et al. (eds) Euro-Par 2020:
  Parallel Processing Workshops. Euro-Par 2020. Lecture Notes in Computer
  Science, Springer, Cham.""",,"10.1007/978-3-030-71593-9_2",,"cs.DL cs.CR cs.CY cs.DC cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peer-review is a necessary and essential quality control step for scientific
publications but lacks proper incentives. Indeed, the process, which is very
costly in terms of time and intellectual investment, not only is not
remunerated by the journals but is also not openly recognized by the academic
community as a relevant scientific output for a researcher. Therefore,
scientific dissemination is affected in timeliness, quality, and fairness.
Here, to solve this issue, we propose a blockchain-based incentive system that
rewards scientists for peer-reviewing other scientists' work and that builds up
trust and reputation. We designed a privacy-oriented protocol of smart
contracts called Ants-Review that allows authors to issue a bounty for open
anonymous peer-reviews on Ethereum. If requirements are met, peer-reviews will
be accepted and paid by the approver proportionally to their assessed quality.
To promote ethical behavior and inclusiveness the system implements a gamified
mechanism that allows the whole community to evaluate the peer-reviews and vote
for the best ones.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:32:41 GMT""}]","2021-03-17"
"2101.09379","Ulugbek Kamilov","Jiaming Liu, Yu Sun, Weijie Gan, Xiaojian Xu, Brendt Wohlberg, and
  Ulugbek S. Kamilov","SGD-Net: Efficient Model-Based Deep Learning with Theoretical Guarantees",,,"10.1109/TCI.2021.3085534",,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep unfolding networks have recently gained popularity in the context of
solving imaging inverse problems. However, the computational and memory
complexity of data-consistency layers within traditional deep unfolding
networks scales with the number of measurements, limiting their applicability
to large-scale imaging inverse problems. We propose SGD-Net as a new
methodology for improving the efficiency of deep unfolding through stochastic
approximations of the data-consistency layers. Our theoretical analysis shows
that SGD-Net can be trained to approximate batch deep unfolding networks to an
arbitrary precision. Our numerical results on intensity diffraction tomography
and sparse-view computed tomography show that SGD-Net can match the performance
of the batch network at a fraction of training and testing complexity.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:33:11 GMT""}]","2021-06-04"
"2101.09380","Filippo Mazzoli","Filippo Mazzoli","The infimum of the dual volume of convex co-compact hyperbolic
  $3$-manifolds","Updated introduction. To appear in Geometry & Topology",,,,"math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the infimum of the dual volume of the convex core of a convex
co-compact hyperbolic $3$-manifold with incompressible boundary coincides with
the infimum of the Riemannian volume of its convex core, as we vary the
geometry by quasi-isometric deformations. We deduce a linear lower bound of the
volume of the convex core of a quasi-Fuchsian manifold in terms of the length
of its bending measured lamination, with optimal multiplicative constant.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:34:52 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 15:17:47 GMT""}]","2022-01-27"
"2101.09381","Ruizhong Wei","Sai Swaroop Madugula and Ruizhong Wei","An Enhanced Passkey Entry Protocol for Secure Simple Pairing in
  Bluetooth","13 pages, 5 figures, original paper",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a simple enhancement for the passkey entry protocol
in the authentication stage 1 of Secure Simple Pairing using preexisting
cryptographic hash functions and random integer generation present in the
protocol. The new protocol is more secure and efficient than previous known
protocols. Our research mainly focuses on strengthening the passkey entry
protocol and protecting the devices against passive eavesdropping and active
Man-in-the-middle (MITM) attacks in both Bluetooth Basic Rate/Enhanced Data
Rate (BR/EDR) and Bluetooth Low Energy (Bluetooth LE). This method can be used
for any device which uses the passkey entry protocol.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:36:22 GMT""}]","2021-01-26"
"2101.09382","Krzysztof Szajowski","Krzysztof J. Szajowski and Kinga W{\l}odarczyk","A measure of the importance of roads based on topography and traffic
  intensity","35 pages, 7 figures",,,,"math.OC cs.GR math.ST stat.AP stat.TH","http://creativecommons.org/licenses/by/4.0/","  Mathematical models of street traffic allowing assessment of the importance
of their individual segments for the functionality of the street system is
considering. Based on methods of cooperative games and the reliability theory
the suitable measure is constructed. The main goal is to analyze methods for
assessing the importance (rank) of road fragments, including their functions. A
relevance of these elements for effective accessibility for the entire system
will be considered.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:53:49 GMT""}]","2021-06-23"
"2101.09383","Anthony Quas","James Campbell and Alexandra Deane and Anthony Quas","The Lightning Model","To appear: J. Theor. Prob",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We introduce a non-standard model for percolation on the integer lattice
$\mathbb Z^2$. Randomly assign to each vertex $a \in \mathbb Z^2$ a potential,
denoted $\phi_a$, chosen independently and uniformly from the interval $[0,
1]$. For fixed $\epsilon \in [0,1]$, draw a directed edge from vertex $a$ to a
nearest-neighbor vertex $b$ if $\phi_b < \phi_a + \epsilon$, yielding a
directed subgraph of the infinite directed graph $\overrightarrow{G}$ whose
vertex set is $\mathbb Z^2$, with nearest-neighbor edge set. We define notions
of weak and strong percolation for our model, and observe that when $\epsilon =
0$ the model fails to percolate weakly, while for $\epsilon = 1$ it percolates
strongly. We show that there is a positive $\epsilon_0$ so that for $0 \le
\epsilon \le \epsilon_0$, the model fails to percolate weakly, and that when
$\epsilon > p_\text{site}$, the critical probability for standard site
percolation in $\mathbb Z^2$, the model percolates strongly. We study the
number of infinite strongly connected clusters occurring in a typical
configuration. We show that for these models of percolation on directed graphs,
there are some subtle issues that do not arise for undirected percolation.
Although our model does not have the finite energy property, we are able to
show that, as in the standard model, the number of infinite strongly connected
clusters is almost surely 0, 1 or $\infty$.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:09:31 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 20:24:49 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 18:07:44 GMT""}]","2021-10-26"
"2101.09384","Brandilyn Stigler","Anyu Zhang, Jingzhen Hu, Qingzhong Liang, Elena S. Dimitrova,
  Brandilyn Stigler","Algebraic Model Selection and Experimental Design in Biological Data
  Science","22 pages, 8 figures, 6 tables",,,,"math.AG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Design of experiments and model selection, though essential steps in data
science, are usually viewed as unrelated processes in the study and analysis of
biological networks. Not accounting for their inter-relatedness has the
potential to introduce bias and increase the risk of missing salient features
in the modeling process. We propose a data-driven computational framework to
unify experimental design and model selection for discrete data sets and
minimal polynomial models. We use a special affine transformation, called a
linear shift, to provide both the data sets and the polynomial terms that form
a basis for a model. This framework enables us to address two important
questions that arise in biological data science research: finding the data
which identify a set of known interactions and finding identifiable
interactions given a set of data. We present the theoretical foundation for a
web-accessible database. As an example, we apply this methodology to a
previously constructed pharmacodynamic model of epidermal derived growth factor
receptor (EGFR) signaling.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:12:34 GMT""}]","2021-01-26"
"2101.09385","Joshua Kroll","Joshua A. Kroll","Outlining Traceability: A Principle for Operationalizing Accountability
  in Computing Systems","To be published in the Proceedings of the 2021 ACM Conference on
  Fairness, Accountability, and Transparency (FAccT'21)",,"10.1145/3442188.3445937",,"cs.CY cs.AI cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Accountability is widely understood as a goal for well governed computer
systems, and is a sought-after value in many governance contexts. But how can
it be achieved? Recent work on standards for governable artificial intelligence
systems offers a related principle: traceability. Traceability requires
establishing not only how a system worked but how it was created and for what
purpose, in a way that explains why a system has particular dynamics or
behaviors. It connects records of how the system was constructed and what the
system did mechanically to the broader goals of governance, in a way that
highlights human understanding of that mechanical operation and the decision
processes underlying it. We examine the various ways in which the principle of
traceability has been articulated in AI principles and other policy documents
from around the world, distill from these a set of requirements on software
systems driven by the principle, and systematize the technologies available to
meet those requirements. From our map of requirements to supporting tools,
techniques, and procedures, we identify gaps and needs separating what
traceability requires from the toolbox available for practitioners. This map
reframes existing discussions around accountability and transparency, using the
principle of traceability to show how, when, and why transparency can be
deployed to serve accountability goals and thereby improve the normative
fidelity of systems and their development processes.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:13:20 GMT""}]","2021-08-23"
"2101.09386","Jinbo Ren","Pietro Corvaja, Andrei Rapinchuk, Jinbo Ren, Umberto Zannier","Non-virtually abelian anisotropic linear groups are not boundedly
  generated","Final version; to appear in Invent. Math",,"10.1007/s00222-021-01064-y",,"math.GR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that if a linear group $\Gamma \subset \mathrm{GL}_n(K)$ over a
field $K$ of characteristic zero is boundedly generated by semi-simple
(diagonalizable) elements then it is virtually solvable. As a consequence, one
obtains that infinite $S$-arithmetic subgroups of absolutely almost simple
anisotropic algebraic groups over number fields are never boundedly generated.
Our proof relies on Laurent's theorem from Diophantine geometry and properties
of generic elements.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:13:47 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 13:43:04 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jul 2021 19:47:45 GMT""}]","2022-01-19"
"2101.09387","Changhao Shi","Changhao Shi, Chester Holtz and Gal Mishne","Online Adversarial Purification based on Self-Supervision","Accepted to ICLR 2021",,,,"cs.LG cs.CR cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks are known to be vulnerable to adversarial examples,
where a perturbation in the input space leads to an amplified shift in the
latent network representation. In this paper, we combine canonical supervised
learning with self-supervised representation learning, and present
Self-supervised Online Adversarial Purification (SOAP), a novel defense
strategy that uses a self-supervised loss to purify adversarial examples at
test-time. Our approach leverages the label-independent nature of
self-supervised signals and counters the adversarial perturbation with respect
to the self-supervised tasks. SOAP yields competitive robust accuracy against
state-of-the-art adversarial training and purification methods, with
considerably less training complexity. In addition, our approach is robust even
when adversaries are given knowledge of the purification defense strategy. To
the best of our knowledge, our paper is the first that generalizes the idea of
using self-supervised signals to perform online test-time purification.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:19:52 GMT""}]","2022-01-02"
"2101.09388","Rebecca Martin","Rebecca G. Martin, Zhaohuan Zhu, Philip J. Armitage, Chao-Chin Yang
  and Hans Baehr","Kozai-Lidov oscillations triggered by a tilt instability of detached
  circumplanetary discs","Accepted for publication in MNRAS",,"10.1093/mnras/stab232",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Circumplanetary discs can be linearly unstable to the growth of disc tilt in
the tidal potential of the star-planet system. We use three-dimensional
hydrodynamical simulations to characterize the disc conditions needed for
instability, together with its long term evolution. Tilt growth occurs for disc
aspect ratios, evaluated near the disc outer edge, of $H/r\gtrsim 0.05$, with a
weak dependence on viscosity in the wave-like regime of warp propagation. Lower
mass giant planets are more likely to have circumplanetary discs that satisfy
the conditions for instability. We show that the tilt instability can excite
the inclination to above the threshold where the circumplanetary disc becomes
unstable to Kozai--Lidov (KL) oscillations. Dissipation in the Kozai--Lidov
unstable regime caps further tilt growth, but the disc experiences large
oscillations in both inclination and eccentricity. Planetary accretion occurs
in episodic accretion events. We discuss implications of the joint tilt--KL
instability for the detectability of circumplanetary discs, for the obliquity
evolution of forming giant planets, and for the formation of satellite systems.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:21:07 GMT""}]","2021-02-03"
"2101.09389","Jenny Wan","Jenny T. Wan (1), Adam B. Mantz (2), Jack Sayers (1), Steven W. Allen
  (2 and 3), R. Glenn Morris (2 and 3), Sunil R. Golwala (1) ((1) Caltech, (2)
  KIPAC/Stanford, (3) SLAC)","Measuring $H_0$ using X-ray and SZ effect observations of dynamically
  relaxed galaxy clusters","16 pages, 9 figures, submitted to MNRAS",,"10.1093/mnras/stab948",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a sample of 14 massive, dynamically relaxed galaxy clusters to
constrain the Hubble Constant, $H_0$, by combining X-ray and Sunyaev-Zel'dovich
(SZ) effect signals measured with Chandra, Planck and Bolocam. This is the
first such analysis to marginalize over an empirical, data-driven prior on the
overall accuracy of X-ray temperature measurements, while our restriction to
the most relaxed, massive clusters also minimizes astrophysical systematics.
For a cosmological-constant model with $\Omega_m = 0.3$ and $\Omega_{\Lambda} =
0.7$, we find $H_0 = 67.3^{+21.3}_{-13.3}$ km/s/Mpc, limited by the temperature
calibration uncertainty (compared to the statistically limited constraint of
$H_0 = 72.3^{+7.6}_{-7.6}$ km/s/Mpc). The intrinsic scatter in the X-ray/SZ
pressure ratio is found to be $13 \pm 4$ per cent ($10 \pm 3$ per cent when two
clusters with significant galactic dust emission are removed from the sample),
consistent with being primarily due to triaxiality and projection. We discuss
the prospects for reducing the dominant systematic limitation to this analysis,
with improved X-ray calibration and/or precise measurements of the relativistic
SZ effect providing a plausible route to per cent level constraints on $H_0$.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:22:40 GMT""}]","2021-04-14"
"2101.09390","Jeremy Rouse","Alexis Newton and Jeremy Rouse","Integers that are sums of two rational sixth powers","14 pages. Our main result is now unconditional",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that $164634913$ is the smallest positive integer that is a sum of
two rational sixth powers but not a sum of two integer sixth powers. If $C_{k}$
is the curve $x^{6} + y^{6} = k$, we use the existence of morphisms from
$C_{k}$ to elliptic curves, together with the Mordell-Weil sieve, to rule out
the existence of rational points on $C_{k}$ for various $k$.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:58:58 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 01:18:07 GMT""}]","2022-01-27"
"2101.09391","Brendan Tidd","Brendan Tidd, Nicolas Hudson, Akansel Cosgun, Jurgen Leitner","Learning Setup Policies: Reliable Transition Between Locomotion
  Behaviours","Published in IEEE Robotics and Automation Letters ( Volume: 7, Issue:
  4, October 2022) Page(s): 11958 - 11965
  https://ieeexplore.ieee.org/document/9894663",,,,"cs.RO cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Dynamic platforms that operate over many unique terrain conditions typically
require many behaviours. To transition safely, there must be an overlap of
states between adjacent controllers. We develop a novel method for training
setup policies that bridge the trajectories between pre-trained Deep
Reinforcement Learning (DRL) policies. We demonstrate our method with a
simulated biped traversing a difficult jump terrain, where a single policy
fails to learn the task, and switching between pre-trained policies without
setup policies also fails. We perform an ablation of key components of our
system, and show that our method outperforms others that learn transition
policies. We demonstrate our method with several difficult and diverse terrain
types, and show that we can use setup policies as part of a modular control
suite to successfully traverse a sequence of complex terrains. We show that
using setup policies improves the success rate for traversing a single
difficult jump terrain (from 51.3% success rate with the best comparative
method to 82.2%), and traversing a random sequence of difficult obstacles (from
1.9% without setup policies to 71.2%).
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:17:07 GMT""},{""version"":""v2"",""created"":""Thu, 6 Oct 2022 01:13:23 GMT""}]","2022-10-07"
"2101.09392","Kai Han","Kai Han and Miaomiao Liu and Dirk Schnieders and Kwan-Yee K. Wong","Fixed Viewpoint Mirror Surface Reconstruction under an Uncalibrated
  Camera","IEEE Transactions on Image Processing (TIP). Code available at
  https://github.com/k-han/mirror",,"10.1109/TIP.2021.3049946",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of mirror surface reconstruction, and
proposes a solution based on observing the reflections of a moving reference
plane on the mirror surface. Unlike previous approaches which require tedious
calibration, our method can recover the camera intrinsics, the poses of the
reference plane, as well as the mirror surface from the observed reflections of
the reference plane under at least three unknown distinct poses. We first show
that the 3D poses of the reference plane can be estimated from the reflection
correspondences established between the images and the reference plane. We then
form a bunch of 3D lines from the reflection correspondences, and derive an
analytical solution to recover the line projection matrix. We transform the
line projection matrix to its equivalent camera projection matrix, and propose
a cross-ratio based formulation to optimize the camera projection matrix by
minimizing reprojection errors. The mirror surface is then reconstructed based
on the optimized cross-ratio constraint. Experimental results on both synthetic
and real data are presented, which demonstrate the feasibility and accuracy of
our method.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:20:55 GMT""}]","2021-01-26"
"2101.09393","Manuel Lamp\'on Gonz\'alez-Albo","M. Lamp\'on, M. L\'opez-Puertas, J. Sanz-Forcada, A.
  S\'anchez-L\'opez, K. Molaverdikhani, S. Czesla, A. Quirrenbach, E. Pall\'e,
  J. A. Caballero, Th. Henning, M. Salz, L. Nortmann, J. Aceituno, P. J. Amado,
  F. F. Bauer, D. Montes, E. Nagel, A. Reiners, and I. Ribas","Modelling the He I triplet absorption at 10830 Angstroms in the
  atmospheres of HD 189733 b and GJ 3470 b","Accepted to A&A. 16 Pages","A&A 647, A129 (2021)","10.1051/0004-6361/202039417",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Characterising the atmospheres of exoplanets is key to understanding their
nature and provides hints about their formation and evolution. High-resolution
measurements of the helium triplet, He(2$^{3}$S), absorption of highly
irradiated planets have been recently reported, which provide a new mean to
study their atmospheric escape. In this work, we study the escape of the upper
atmospheres of HD 189733 b and GJ 3470 b by analysing high-resolution
He(2$^{3}$S) absorption measurements and using a 1D hydrodynamic model coupled
with a non-LTE model for the He(2$^{3}$S) state. We also use the H density
derived from Ly$\alpha$ observations to further constrain their temperatures,
T, mass-loss rates,$\dot M$, and H/He ratios. We have significantly improved
our knowledge of the upper atmospheres of these planets. While HD 189733 b has
a rather compressed atmosphere and small gas radial velocities, GJ 3470 b, with
a gravitational potential ten times smaller, exhibits a very extended
atmosphere and large radial outflow velocities. Hence, although GJ 3470 b is
much less irradiated in the XUV, and its upper atmosphere is much cooler, it
evaporates at a comparable rate. In particular, we find that the upper
atmosphere of HD 189733 b is compact and hot, with a maximum T of
12400$^{+400}_{-300}$ K, with very low mean molecular mass
(H/He=(99.2/0.8)$\pm0.1$), almost fully ionised above 1.1 R$_p$, and with $\dot
M$=(1.1$\pm0.1$)$\times$10$^{11}$ g/s. In contrast, the upper atmosphere of GJ
3470 b is highly extended and relatively cold, with a maximum T of 5100$\pm900$
K, also with very low mean molecular mass (H/He=(98.5/1.5)$^{+1.0}_{-1.5}$),
not strongly ionised and with $\dot M$=(1.9$\pm1.1$)$\times$10$^{11}$ g/s.
Furthermore, our results suggest that the upper atmospheres of giant planets
undergoing hydrodynamic escape tend to have very low mean molecular mass
(H/He$\gtrsim$97/3).
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:25:10 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 11:55:14 GMT""}]","2021-03-24"
"2101.09394","Jaehyuk Choi","Jaehyuk Choi, Desheng Ge, Kyu Ho Kang, Sungbin Sohn","Yield Spread Selection in Predicting Recession Probabilities: A Machine
  Learning Approach",,,,,"econ.EM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The literature on using yield curves to forecast recessions customarily uses
10-year--three-month Treasury yield spread without verification on the pair
selection. This study investigates whether the predictive ability of spread can
be improved by letting a machine learning algorithm identify the best maturity
pair and coefficients. Our comprehensive analysis shows that, despite the
likelihood gain, the machine learning approach does not significantly improve
prediction, owing to the estimation error. This is robust to the forecasting
horizon, control variable, sample period, and oversampling of the recession
observations. Our finding supports the use of the 10-year--three-month spread.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:26:54 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 02:19:36 GMT""}]","2022-01-07"
"2101.09395","Xiaodong Wang","Xiaodong Wang and Fushing Hsieh","Unraveling S&P500 stock volatility and networks -- An
  encoding-and-decoding approach",,,,,"q-fin.ST stat.AP","http://creativecommons.org/licenses/by/4.0/","  Volatility of financial stock is referring to the degree of uncertainty or
risk embedded within a stock's dynamics. Such risk has been received huge
amounts of attention from diverse financial researchers. By following the
concept of regime-switching model, we proposed a non-parametric approach, named
encoding-and-decoding, to discover multiple volatility states embedded within a
discrete time series of stock returns. The encoding is performed across the
entire span of temporal time points for relatively extreme events with respect
to a chosen quantile-based threshold. As such the return time series is
transformed into Bernoulli-variable processes. In the decoding phase, we
computationally seek for locations of change points via estimations based on a
new searching algorithm in conjunction with the information criterion applied
on the observed collection of recurrence times upon the binary process. Besides
the independence required for building the Geometric distributional likelihood
function, the proposed approach can functionally partition the entire return
time series into a collection of homogeneous segments without any assumptions
of dynamic structure and underlying distributions. In the numerical
experiments, our approach is found favorably compared with parametric models
like Hidden Markov Model. In the real data applications, we introduce the
application of our approach in forecasting stock returns. Finally, volatility
dynamic of every single stock of S&P500 is revealed, and a stock network is
consequently established to represent dependency relations derived through
concurrent volatility states among S&P500.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:30:19 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 23:46:07 GMT""},{""version"":""v3"",""created"":""Thu, 21 Oct 2021 18:28:02 GMT""}]","2021-10-25"
"2101.09396","Misha Chai","Misha Chai and Yueheng Lan","Symbolic partition in chaotic maps",,"Chaos 1 March 2021; 31 (3): 033144","10.1063/5.0042705",,"nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we only use data on the unstable manifold to locate the
partition boundaries by checking folding points at different levels, which
practically coincide with homoclinic tangencies (HTs). The method is then
applied to the classic two-dimensional Henon map and a well-known
three-dimensional map. Comparison with previous results is made in the Henon
case and Lyapunov exponents are computed through the metric entropy based on
the partition, to show the validity of the current scheme.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:46:49 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 15:14:04 GMT""}]","2023-05-23"
"2101.09397","Juan Irving Vasquez-Gomez","J. Irving Vasquez-Gomez and David Troncoso and Israel Becerra and
  Enrique Sucar and Rafael Murrieta-Cid","Next-best-view Regression using a 3D Convolutional Neural Network","Accepted to Machine Vision and Applications","Machine Vision and Applications 32, 42 (2021)","10.1007/s00138-020-01166-2",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated three-dimensional (3D) object reconstruction is the task of
building a geometric representation of a physical object by means of sensing
its surface. Even though new single view reconstruction techniques can predict
the surface, they lead to incomplete models, specially, for non commons objects
such as antique objects or art sculptures. Therefore, to achieve the task's
goals, it is essential to automatically determine the locations where the
sensor will be placed so that the surface will be completely observed. This
problem is known as the next-best-view problem. In this paper, we propose a
data-driven approach to address the problem. The proposed approach trains a 3D
convolutional neural network (3D CNN) with previous reconstructions in order to
regress the \btxt{position of the} next-best-view. To the best of our
knowledge, this is one of the first works that directly infers the
next-best-view in a continuous space using a data-driven approach for the 3D
object reconstruction task. We have validated the proposed approach making use
of two groups of experiments. In the first group, several variants of the
proposed architecture are analyzed. Predicted next-best-views were observed to
be closely positioned to the ground truth. In the second group of experiments,
the proposed approach is requested to reconstruct several unseen objects,
namely, objects not considered by the 3D CNN during training nor validation.
Coverage percentages of up to 90 \% were observed. With respect to current
state-of-the-art methods, the proposed approach improves the performance of
previous next-best-view classification approaches and it is quite fast in
running time (3 frames per second), given that it does not compute the
expensive ray tracing required by previous information metrics.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:50:26 GMT""}]","2021-01-27"
"2101.09398","Jann Spiess","Lea Bottmer, Guido Imbens, Jann Spiess, Merrill Warnick","A Design-Based Perspective on Synthetic Control Methods",,,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since their introduction in Abadie and Gardeazabal (2003), Synthetic Control
(SC) methods have quickly become one of the leading methods for estimating
causal effects in observational studies in settings with panel data. Formal
discussions often motivate SC methods by the assumption that the potential
outcomes were generated by a factor model. Here we study SC methods from a
design-based perspective, assuming a model for the selection of the treated
unit(s) and period(s). We show that the standard SC estimator is generally
biased under random assignment. We propose a Modified Unbiased Synthetic
Control (MUSC) estimator that guarantees unbiasedness under random assignment
and derive its exact, randomization-based, finite-sample variance. We also
propose an unbiased estimator for this variance. We document in settings with
real data that under random assignment, SC-type estimators can have root
mean-squared errors that are substantially lower than that of other common
estimators. We show that such an improvement is weakly guaranteed if the
treated period is similar to the other periods, for example, if the treated
period was randomly selected. While our results only directly apply in settings
where treatment is assigned randomly, we believe that they can complement
model-based approaches even for observational studies.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 01:57:45 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 23:39:57 GMT""},{""version"":""v3"",""created"":""Mon, 1 May 2023 03:31:53 GMT""}]","2023-05-02"
"2101.09399","Julia Roman-Duval","Julia Roman-Duval, Edward B. Jenkins, Kirill Tchernyshyov, Benjamin
  Williams, Christopher J.R. Clark, Karl D. Gordon, Margaret Meixner, Lea
  Hagen, Joshua Peek, Karin Sandstrom, Jessica Werk, Petia Yanchulova
  Merica-Jones","METAL: The Metal Evolution, Transport, and Abundance in the Large
  Magellanic Cloud Hubble program. II. Variations of interstellar depletions
  and dust-to-gas ratio within the LMC",,,"10.3847/1538-4357/abdeb6",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key component of the baryon cycle in galaxies is the depletion of metals
from the gas to the dust phase in the neutral ISM. The METAL (Metal Evolution,
Transport and Abundance in the Large Magellanic Cloud) program on the Hubble
Space Telescope acquired UV spectra toward 32 sightlines in the half-solar
metallicity LMC, from which we derive interstellar depletions (gas-phase
fractions) of Mg, Si, Fe, Ni, S, Zn, Cr, and Cu. The depletions of different
elements are tightly correlated, indicating a common origin. Hydrogen column
density is the main driver for depletion variations. Correlations are weaker
with volume density, probed by CI fine structure lines, and distance to the LMC
center. The latter correlation results from an East-West variation of the
gas-phase metallicity. Gas in the East, compressed side of the LMC encompassing
30 Doradus and the Southeast HI over-density is enriched by up to +0.3dex,
while gas in the West side is metal-deficient by up to -0.5dex. Within the
parameter space probed by METAL, no correlation with molecular fraction or
radiation field intensity are found. We confirm the factor 3-4 increase in
dust-to-metal and dust-to-gas ratios between the diffuse (logN(H)~20 cm-2) and
molecular (logN(H)~22 cm-2) ISM observed from far-infrared, 21 cm, and CO
observations. The variations of dust-to-metal and dust-to-gas ratios with
column density have important implications for the sub-grid physics of chemical
evolution, gas and dust mass estimates throughout cosmic times, and for the
chemical enrichment of the Universe measured via spectroscopy of damped
Lyman-alpha systems.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:06:32 GMT""}]","2021-04-07"
"2101.09400","Jaime Arango","Jaime Arango","Oscillation time and damping coefficients in a nonlinear pendulum","This paper is dedicated to the memory of Prof. Alan Lazer
  (1938-2020), University of Miami",,,,"math.CA math.AP","http://creativecommons.org/licenses/by/4.0/","  We establish a relationship between the normalized damping coefficients and
the time that takes a nonlinear pendulum to complete one oscillation starting
from an initial position with vanishing velocity. We establish some conditions
on the nonlinear restitution force so that this oscillation time does not
depend monotonically on the viscosity damping coefficient.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:23:04 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 22:43:45 GMT""}]","2021-06-28"
"2101.09401","Ningshan Xu","Ningshan Xu","Adaptively Sparse Regularization for Blind Image Restoration","10 pages, 5 figures, 3 tables",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Image quality is the basis of image communication and understanding tasks.
Due to the blur and noise effects caused by imaging, transmission and other
processes, the image quality is degraded. Blind image restoration is widely
used to improve image quality, where the main goal is to faithfully estimate
the blur kernel and the latent sharp image. In this study, based on
experimental observation and research, an adaptively sparse regularized
minimization method is originally proposed. The high-order gradients combine
with low-order ones to form a hybrid regularization term, and an adaptive
operator derived from the image entropy is introduced to maintain a good
convergence. Extensive experiments were conducted on different blur kernels and
images. Compared with existing state-of-the-art blind deblurring methods, our
method demonstrates superiority on the recovery accuracy.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:40:01 GMT""}]","2021-01-26"
"2101.09402","Stephen Finbow","Alexander Clow and Stephen Finbow","Advances in finding ideal play on poset games","11 pages, 8 figures. Keywords: Combinatorial Game Theory, PO-set
  games",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Poset games are a class of combinatorial game that remain unsolved. Soltys
and Wilson proved that computing wining strategies is in \textbf{PSPACE} and
aside from special cases such as Nim and N-Free games, \textbf{P} time
algorithms for finding ideal play are unknown. This paper presents methods
calculate the nimber of posets games allowing for the classification of winning
or losing positions. The results present an equivalence of ideal strategies on
posets that are seemingly unrelated.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:48:30 GMT""}]","2021-01-26"
"2101.09403","Hamid Laga","Hamid Laga, Marcel Padilla, Ian H. Jermyn, Sebastian Kurtek, Mohammed
  Bennamoun, Anuj Srivastava","4D Atlas: Statistical Analysis of the Spatiotemporal Variability in
  Longitudinal 3D Shape Data",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a novel framework to learn the spatiotemporal variability in
longitudinal 3D shape data sets, which contain observations of objects that
evolve and deform over time. This problem is challenging since surfaces come
with arbitrary parameterizations and thus, they need to be spatially
registered. Also, different deforming objects, also called 4D surfaces, evolve
at different speeds and thus they need to be temporally aligned. We solve this
spatiotemporal registration problem using a Riemannian approach. We treat a 3D
surface as a point in a shape space equipped with an elastic Riemannian metric
that measures the amount of bending and stretching that the surfaces undergo. A
4D surface can then be seen as a trajectory in this space. With this
formulation, the statistical analysis of 4D surfaces can be cast as the problem
of analyzing trajectories embedded in a nonlinear Riemannian manifold. However,
performing the spatiotemporal registration, and subsequently computing
statistics, on such nonlinear spaces is not straightforward as they rely on
complex nonlinear optimizations. Our core contribution is the mapping of the
surfaces to the space of Square-Root Normal Fields where the L2 metric is
equivalent to the partial elastic metric in the space of surfaces. Thus, by
solving the spatial registration in the SRNF space, the problem of analyzing 4D
surfaces becomes the problem of analyzing trajectories embedded in the SRNF
space, which has a Euclidean structure. In this paper, we develop the building
blocks that enable such analysis. These include: (1) the spatiotemporal
registration of arbitrarily parameterized 4D surfaces in the presence of large
elastic deformations and large variations in their execution rates; (2) the
computation of geodesics between 4D surfaces; (3) the computation of
statistical summaries; and (4) the synthesis of random 4D surfaces.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:59:55 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 15:19:36 GMT""}]","2021-08-23"
"2101.09404","Xiuhong Wei","Xiuhong Wei, Decai Shen, and Linglong Dai","Channel Estimation for RIS Assisted Wireless Communications: Part I --
  Fundamentals, Solutions, and Future Opportunities","This paper has been accepted by the IEEE Communications Letters as an
  invited paper",,,,"cs.IT math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  The reconfigurable intelligent surface (RIS) with low hardware cost and
energy consumption has been recognized as a potential technique for future 6G
communications to enhance coverage and capacity. To achieve this goal, accurate
channel state information (CSI) in RIS assisted wireless communication system
is essential for the joint beamforming at the base station (BS) and the RIS.
However, channel estimation is challenging, since a large number of passive RIS
elements cannot transmit, receive, or process signals. In the first part of
this invited paper, we provide an overview of the fundamentals, solutions, and
future opportunities of channel estimation in the RIS assisted wireless
communication system. It is noted that a new channel estimation scheme with low
pilot overhead will be provided in the second part of this paper.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:01:09 GMT""}]","2021-01-26"
"2101.09405","Xiuhong Wei","Xiuhong Wei, Decai Shen, and Linglong Dai","Channel Estimation for RIS Assisted Wireless Communications: Part II --
  An Improved Solution Based on Double-Structured Sparsity","This paper has been accepted by the IEEE Communications Letters as an
  invited paper. Simulation codes are provided to reproduce the results
  presented in this paper:
  http://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html",,,,"cs.IT math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  Reconfigurable intelligent surface (RIS) can manipulate the wireless
communication environment by controlling the coefficients of RIS elements.
However, due to the large number of passive RIS elements without signal
processing capability, channel estimation in RIS assisted wireless
communication system requires high pilot overhead. In the second part of this
invited paper, we propose to exploit the double-structured sparsity of the
angular cascaded channels among users to reduce the pilot overhead.
Specifically, we first reveal the double-structured sparsity, i.e., different
angular cascaded channels for different users enjoy the completely common
non-zero rows and the partially common non-zero columns. By exploiting this
double-structured sparsity, we further propose the double-structured orthogonal
matching pursuit (DS-OMP) algorithm, where the completely common non-zero rows
and the partially common non-zero columns are jointly estimated for all users.
Simulation results show that the pilot overhead required by the proposed scheme
is lower than existing schemes.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:04:22 GMT""}]","2021-01-26"
"2101.09406","Ya-Ping Li","Ya-Ping Li (1), Adam M. Dempsey (1), Shengtai Li (1), Hui Li (1) and
  Jiaru Li (1) ((1) LANL)","Orbital evolution of binary black holes in active galactic nucleus
  disks: a disk channel for binary black hole mergers?","accepted by ApJ, a new Table 2 is added",,"10.3847/1538-4357/abed48","LA-UR-20-28080","astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a series of high-resolution 2D hydrodynamical simulations of
equal-mass binary black holes (BBHs) embedded in active galactic nucleus (AGN)
accretion disks to study whether these binaries can be driven to merger by the
surrounding gas. We find that the gravitational softening adopted for the BBH
has a profound impact on this result. When the softening is less than ten
percent of the binary separation, we show that, in agreement with recent
simulations of isolated equal-mass binaries, prograde BBHs expand in time
rather than contract. Eventually, however, the binary separation becomes large
enough that the tidal force of the central AGN disrupts them. Only when the
softening is relatively large do we find that prograde BBHs harden. We
determine through detailed analysis of the binary torque, that this dichotomy
is due to a loss of spiral structure in the circum-single disks orbiting each
BH when the softening is a significant fraction of the binary separation.
Properly resolving these spirals -- both with high resolution and small
softening -- results in a significant source of binary angular momentum. Only
for retrograde BBHs do we find consistent hardening, regardless of softening,
as these BBHs lack the important spiral structure in their circum-single disks.
This suggests that the gas-driven inspiral of retrograde binaries can produce a
population of compact BBHs in the gravitational-wave-emitting regime in AGN
disks, which may contribute a large fraction to the observed BBH mergers.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:05:06 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 20:55:12 GMT""}]","2021-05-05"
"2101.09407","Juan D'Etigny","Joaqu\'in Prieto, Andr\'es Escala, George Privon and Juan d'Etigny","Black hole fueling in galaxy mergers: A high-resolution analysis","13 pages, 9 figures","Monthly Notices of the Royal Astronomical Society, Volume 508,
  Issue 3, December 2021, Pages 3672-3683","10.1093/mnras/stab2740",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Using parsec scale resolution hydrodynamical adaptive mesh refinement
simulations we have studied the mass transport process throughout a galactic
merger. The aim of such study is to connect both the peaks of mass accretion
rate onto the BHs and star formation bursts with both gravitational and
hydrodynamic torques acting on the galactic gaseous component. Our merger
initial conditions were chosen to mimic a realistic system.
  The simulations include gas cooling, star formation, supernovae feedback, and
AGN feedback. Gravitational and hydrodynamic torques near pericenter passes
trigger gas funneling to the nuclei which is associated with bursts of star
formation and black hole growth. Such episodes are intimately related with both
kinds of torques acting on the galactic gas. Pericenters trigger both star
formation and mass accretion rates of $\sim$ few $(1-10)$ $M_\odot$/yr. Such
episodes last $\sim$ $(50-75)$ Myrs. Close passes also can produce black hole
accretion that approaches and reaches the Eddington rate, lasting $\sim$ few
Myrs. Our simulation shows that both gravitational and hydrodynamic torques are
enhanced at pericenter passes with gravitational torques tending to have higher
values than the hydrodynamic torques throughout the merger. We also find that
in the closest encounters, hydrodynamic and gravitational torques can be
comparable in their effect on the gas, the two helping in the redistribution of
both angular momentum and mass in the galactic disc. Such phenomena allow
inward mass transport onto the BH influence radius, fueling the compact object
and lighting up the galactic nuclei.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:12:18 GMT""}]","2022-03-18"
"2101.09408","Shin-Cheng Mu","Shin-Cheng Mu","Equational reasoning for non-determinism monad: the case of Spark
  aggregation",,,,"TR-IIS-19-002,Institute of Information Science, Academia Sinica","cs.PL","http://creativecommons.org/licenses/by-sa/4.0/","  As part of the author's studies on equational reasoning for monadic programs,
this report focus on non-determinism monad.
  We discuss what properties this monad should satisfy, what additional
operators and notations can be introduced to facilitate equational reasoning
about non-determinism, and put them to the test by proving a number of
properties in our example problem inspired by the author's previous work on
proving properties of Spark aggregation.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:17:31 GMT""}]","2021-01-26"
"2101.09409","Shin-Cheng Mu","Shin-Cheng Mu","Calculating a backtracking algorithm: an exercise in monadic program
  derivation",,,,"TR-IIS-19-003, Institute of Information Science, Academia Sinica","cs.PL","http://creativecommons.org/licenses/by-sa/4.0/","  Equational reasoning is among the most important tools that functional
programming provides us. Curiously, relatively less attention has been paid to
reasoning about monadic programs.
  In this report we derive a backtracking algorithm for problem specifications
that use a monadic unfold to generate possible solutions, which are filtered
using a $\mathit{scanl}$-like predicate. We develop theorems that convert a
variation of $\mathit{scanl}$ to a $\mathit{foldr}$ that uses the state monad,
as well as theorems constructing hylomorphism. The algorithm is used to solve
the $n$-queens puzzle, our running example. The aim is to develop theorems and
patterns useful for the derivation of monadic programs, focusing on the
intricate interaction between state and non-determinism.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:27:20 GMT""}]","2021-01-26"
"2101.09410","Ahmad Mokhtar","Nathan Ilten, Ahmad Mokhtar","Khovanskii-finite rational curves of arithmetic genus 2","22 pages, 5 tables; minor revisions to v1",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the existence of Khovanskii-finite valuations for rational curves of
arithmetic genus two. We provide a semi-explicit description of the locus of
degree $n+2$ rational curves in $\mathbb{P}^n$ of arithmetic genus two that
admit a Khovanskii-finite valuation. Furthermore, we describe an effective
method for determining if a rational curve of arithmetic genus two defined over
a number field admits a Khovanskii-finite valuation. This provides a criterion
for deciding if such curves admit a toric degeneration. Finally, we show that
rational curves with a single unibranched singularity are always
Khovanskii-finite if their arithmetic genus is sufficiently small.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:48:46 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 21:53:46 GMT""}]","2022-03-21"
"2101.09411","Gary Froyland","Fadi Antown, Gary Froyland, Stefano Galatolo","Optimal linear response for Markov Hilbert-Schmidt integral operators
  and stochastic dynamical systems",,,"10.1007/s00332-022-09839-0",,"math.DS math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider optimal control problems for discrete-time random dynamical
systems, finding unique perturbations that provoke maximal responses of
statistical properties of the system. We treat systems whose transfer operator
has an $L^2$ kernel, and we consider the problems of finding (i) the
infinitesimal perturbation maximising the expectation of a given observable and
(ii) the infinitesimal perturbation maximising the spectral gap, and hence the
exponential mixing rate of the system. Our perturbations are either (a)
perturbations of the kernel or (b) perturbations of a deterministic map
subjected to additive noise. We develop a general setting in which these
optimisation problems have a unique solution and construct explicit formulae
for the unique optimal perturbations. We apply our results to a
Pomeau-Manneville map and an interval exchange map, both subjected to additive
noise, to explicitly compute the perturbations provoking maximal responses.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:50:00 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 04:20:52 GMT""}]","2022-09-21"
"2101.09412","Yazhou Yao","Huafeng Liu, Chuanyi Zhang, Yazhou Yao, Xiushen Wei, Fumin Shen, Jian
  Zhang, and Zhenmin Tang","Exploiting Web Images for Fine-Grained Visual Recognition by Eliminating
  Noisy Samples and Utilizing Hard Ones",,"IEEE Transactions on Multimedia, 2021",,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Labeling objects at a subordinate level typically requires expert knowledge,
which is not always available when using random annotators. As such, learning
directly from web images for fine-grained recognition has attracted broad
attention. However, the presence of label noise and hard examples in web images
are two obstacles for training robust fine-grained recognition models.
Therefore, in this paper, we propose a novel approach for removing irrelevant
samples from real-world web images during training, while employing useful hard
examples to update the network. Thus, our approach can alleviate the harmful
effects of irrelevant noisy web images and hard examples to achieve better
performance. Extensive experiments on three commonly used fine-grained datasets
demonstrate that our approach is far superior to current state-of-the-art
web-supervised methods.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 03:58:10 GMT""}]","2021-01-26"
"2101.09413","Weiquan Jiang","Weiquan Jiang and Guoqian Chen","Transient dispersion process of active particles","34 pages,21 figures","J. Fluid Mech. 927, A11 (2021)","10.1017/jfm.2021.747",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active particles often swim in confined environments. The transport
mechanisms, especially the global one as reflected by the Taylor dispersion
model, are of great practical interest to various applications. For active
dispersion process in confined flows, previous analytical studies focused on
the long-time asymptotic values of dispersion characteristics. Only several
numerical studies preliminarily investigated the temporal evolution. Extending
recent studies of Jiang & Chen (J. Fluid Mech., vol. 877, 2019, pp. 1--34; J.
Fluid Mech., vol. 899, 2020, A18), this work makes the first analytical attempt
to investigate the transient process. The temporal evolution of the local
distribution in the confined-section--orientation space, drift, dispersivity
and skewness, is explored based on moments of distributions. We introduce the
biorthogonal expansion method for solutions because the classic integral
transform method for passive transport problems is not applicable due to the
self-propulsion effect. Two types of boundary condition, the reflective
condition and the Robin condition for wall accumulation, are imposed
respectively. A detailed study on spherical and ellipsoidal swimmers dispersing
in a plane Poiseuille flow demonstrates the influences of the swimming, shear
flow, wall accumulation and particle shape on the transient dispersion process
after a point-source release. The swimming-induced diffusion makes the local
distribution reach its equilibrium state faster than that of passive particles.
Though the wall accumulation significantly affects the evolution of the local
distribution and the drift, the time scale to reach the Taylor regime is not
obviously changed. The shear-induced alignment of ellipsoidal particles can
enlarge the dispersivity but has less influence on the drift and the skewness.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 04:14:59 GMT""}]","2021-09-23"
"2101.09414","Yota Otachi","Tatsuya Gima, Tesshu Hanaka, Masashi Kiyomi, Yasuaki Kobayashi, Yota
  Otachi","Exploring the Gap Between Treedepth and Vertex Cover Through Vertex
  Integrity","30 pages, 5 figures, CIAC 2021",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For intractable problems on graphs of bounded treewidth, two graph parameters
treedepth and vertex cover number have been used to obtain fine-grained
complexity results. Although the studies in this direction are successful, we
still need a systematic way for further investigations because the graphs of
bounded vertex cover number form a rather small subclass of the graphs of
bounded treedepth. To fill this gap, we use vertex integrity, which is placed
between the two parameters mentioned above. For several graph problems, we
generalize fixed-parameter tractability results parameterized by vertex cover
number to the ones parameterized by vertex integrity. We also show some finer
complexity contrasts by showing hardness with respect to vertex integrity or
treedepth.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 04:32:07 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 09:45:12 GMT""}]","2023-04-03"
"2101.09415","Maria Capeluto","Rebeca Falcione, Maria Virginia Roldan, Nora Pellegri, Silvia Goyanes,
  Silvia Ledesma, Maria Gabriela Capeluto","Increase of SRG modulation depth in azopolymers-nanoparticles hybrid
  materials","14 pages, 6 figures, full paper",,"10.1016/j.optmat.2021.111015",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Thin films of azopolymer-nanoparticles hybrid materials were fabricated with
poly[1-[4-(3-carboxy-4-hydroxyphenylazo) benzenesulfonamido]-1,2-ethanediyl]
(PAZO) and different concentrations of Ag and AgAu nanoparticles (NPs). By
illuminating the films with polarized interference patterns, surface relief
gratings (SRGs) were recorded. It was found that for some concentrations of NPs
their modulations and diffraction efficiency were higher than the obtained for
PAZO films without NPs. The effect was mainly explained by the increase of the
free volume available for the photoisomerization for certain concentrations of
NPs. The dependence of the diffraction efficiency on concentration was directly
related to changes in modulation depth. When doping with NPs, the maximum
efficiency increases more than two times the efficiency without NPs.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 04:34:55 GMT""}]","2021-04-14"
"2101.09416","Hadi Zanddizari","Hadi Zanddizari, Sreeraman Rajan, Hassan Rabah, Houman Zarrabi","Privacy Assured Recovery of Compressively Sensed ECG signals",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cloud computing for storing data and running complex algorithms have been
steadily increasing. As connected IoT devices such as wearable ECG recorders
generally have less storage and computational capacity, acquired signals get
sent to a remote center for storage and possible analysis on demand. Recently,
compressive sensing (CS) has been used as secure, energy-efficient method of
signal sampling in such recorders. In this paper, we propose a secure procedure
to outsource the total recovery of CS measurement to the cloud and introduce a
privacy-assured signal recovery technique in the cloud. We present a fast, and
lightweight encryption for secure CS recovery outsourcing that can be used in
wearable devices, such as ECG Holter monitors. In the proposed technique,
instead of full recovery of CS-compressed ECG signal in the cloud, to preserve
privacy, an encrypted version of ECG signal is recovered by using a randomly
bipolar permuted measurement matrix. The user with a key, decrypts the
encrypted ECG from the cloud to obtain the original ECG signal. We demonstrate
our proposed method using the ECG signals available in the MITBIH Arrhythmia
Database. We also demonstrate the strength of the proposed method against
partial exposure of the key.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 04:46:06 GMT""}]","2021-01-26"
"2101.09417","James Flamino","James Flamino, Ross DeVito, Boleslaw K. Szymanski, Omar Lizardo","A Machine Learning Approach to Predicting Continuous Tie Strengths","14 Pages, 1 Table, 2 Figures",,,,"cs.SI cs.LG physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Relationships between people constantly evolve, altering interpersonal
behavior and defining social groups. Relationships between nodes in social
networks can be represented by a tie strength, often empirically assessed using
surveys. While this is effective for taking static snapshots of relationships,
such methods are difficult to scale to dynamic networks. In this paper, we
propose a system that allows for the continuous approximation of relationships
as they evolve over time. We evaluate this system using the NetSense study,
which provides comprehensive communication records of students at the
University of Notre Dame over the course of four years. These records are
complemented by semesterly ego network surveys, which provide discrete samples
over time of each participant's true social tie strength with others. We
develop a pair of powerful machine learning models (complemented by a suite of
baselines extracted from past works) that learn from these surveys to interpret
the communications records as signals. These signals represent dynamic tie
strengths, accurately recording the evolution of relationships between the
individuals in our social networks. With these evolving tie values, we are able
to make several empirically derived observations which we compare to past
works.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:01:05 GMT""}]","2021-01-26"
"2101.09418","Xinyue Chang","Xinyue Chang, Zhengyuan Zhu, Xiongtao Dai and Jonathan Hobbs","A Geospatial Functional Model For OCO-2 Data with Application on
  Imputation and Land Fraction Estimation",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data from NASA's Orbiting Carbon Observatory-2 (OCO-2) satellite is essential
to many carbon management strategies. A retrieval algorithm is used to estimate
CO2 concentration using the radiance data measured by OCO-2. However, due to
factors such as cloud cover and cosmic rays, the spatial coverage of the
retrieval algorithm is limited in some areas of critical importance for carbon
cycle science. Mixed land/water pixels along the coastline are also not used in
the retrieval processing due to the lack of valid ancillary variables including
land fraction. We propose an approach to model spatial spectral data to solve
these two problems by radiance imputation and land fraction estimation. The
spectral observations are modeled as spatially indexed functional data with
footprint-specific parameters and are reduced to much lower dimensions by
functional principal component analysis. The principal component scores are
modeled as random fields to account for the spatial dependence, and the missing
spectral observations are imputed by kriging the principal component scores.
The proposed method is shown to impute spectral radiance with high accuracy for
observations over the Pacific Ocean. An unmixing approach based on this model
provides much more accurate land fraction estimates in our validation study
along Greece coastlines.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:09:33 GMT""}]","2021-01-26"
"2101.09419","Min Chen","Min Chen and Jun Sun","Alexandrov-Fenchel type inequalities in the sphere",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we attempt to use two types of flows to study the relations
between quermassintegrals $\mathcal{A}_k$ (see Definition 1.1), which
correspond to the Alexandrov-Fenchel inequalities for closed convex
$C^2$-hypersurfaces in $\mathbb{S}_+^{n+1}.$
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:14:32 GMT""}]","2021-01-26"
"2101.09420","Li Yaning","Yaning Li, Xue Wang, Hao Zhu, Guoqing Zhou, and Qing Wang","Deep Anti-aliasing of Whole Focal Stack Using Slice Spectrum",,,"10.1109/TCI.2021.3132194",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper aims at removing the aliasing effects of the whole focal stack
generated from a sparse-sampled {4D} light field, while keeping the consistency
across all the focal layers. We first explore the structural characteristics
embedded in the focal stack slice and its corresponding frequency-domain
representation, i.e., the Focal Stack Spectrum (FSS). We observe that the
energy distribution of the FSS always resides within the same triangular area
under different angular sampling rates, additionally the continuity of the
Point Spread Function (PSF) is intrinsically maintained in the FSS. Based on
these two observations, we propose a learning-based FSS reconstruction approach
for one-time aliasing removing over the whole focal stack. Moreover, a novel
conjugate-symmetric loss function is proposed for the optimization. Compared to
previous works, our method avoids an explicit depth estimation, and can handle
challenging large-disparity scenarios. Experimental results on both synthetic
and real light field datasets show the superiority of the proposed approach for
different scenes and various angular sampling rates.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:14:49 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 00:26:49 GMT""}]","2022-04-04"
"2101.09421","Gita Sukthankar","Ayesha Enayet and Gita Sukthankar","Analyzing Team Performance with Embeddings from Multiparty Dialogues","To be published in the 15th IEEE International Conference on Semantic
  Computing",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Good communication is indubitably the foundation of effective teamwork. Over
time teams develop their own communication styles and often exhibit
entrainment, a conversational phenomena in which humans synchronize their
linguistic choices. This paper examines the problem of predicting team
performance from embeddings learned from multiparty dialogues such that teams
with similar conflict scores lie close to one another in vector space.
Embeddings were extracted from three types of features: 1) dialogue acts 2)
sentiment polarity 3) syntactic entrainment. Although all of these features can
be used to effectively predict team performance, their utility varies by the
teamwork phase. We separate the dialogues of players playing a cooperative game
into stages: 1) early (knowledge building) 2) middle (problem-solving) and 3)
late (culmination). Unlike syntactic entrainment, both dialogue act and
sentiment embeddings are effective for classifying team performance, even
during the initial phase. This finding has potential ramifications for the
development of conversational agents that facilitate teaming.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:18:12 GMT""}]","2021-01-26"
"2101.09422","Arvind  Kiwelekar","Sanjay Thakare, Arvind W Kiwelekar","Recovery and Analysis of Architecture Descriptions using Centrality
  Measures","This is the reviewed version of the paper submitted for International
  Conference on Software Architetcure (ICSA 2021)",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The necessity of an explicit architecture description has been continuously
emphasized to communicate the system functionality and for system maintenance
activities. This paper presents an approach to extract architecture
descriptions using the {\em centrality measures} from the theory of Social
Network Analysis. The architecture recovery approach presented in this paper
works in two phases. The first phase aims to calculate centrality measures for
each program element in the system. The second phase assumes that the system
has been designed around the layered architecture style and assigns layers to
each program element. Two techniques to assign program elements are presented.
The first technique of layer assignment uses a set of pre-defined rules, while
the second technique learns the rules of assignment from a pre-labelled data
set. The paper presents the evaluation of both approaches.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:22:46 GMT""}]","2021-01-26"
"2101.09423","Haruya Mizutani","Kazuki Aoki, Takahisa Inui, Hayato Miyazaki, Haruya Mizutani, Kota
  Uriya","Modified scattering for inhomogeneous nonlinear Schr\""odinger equations
  with and without inverse-square potential","27 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the final state problem for the inhomogeneous nonlinear
Schr\""odinger equation with a critical long-range nonlinearity. Given a
prescribed asymptotic profile, which has a logarithmic phase correction
compared with the free evolution, we construct a unique global solution which
converges to the profile. As a consequence, the existence of modified wave
operators for localized small scattering data is obtained. We also study the
same problem for the case with the critical inverse-square potential under the
radial symmetry. In particular, we construct the modified wave operators for
the long-range nonlinear Schr\""odinger equation with the critical
inverse-square potential in three space dimensions, under the radial symmetry.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:32:13 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 14:58:45 GMT""}]","2021-05-05"
"2101.09424","Zezhong Wang","Zezhong Wang and Inez Maria Zwetsloot","A Change-Point Based Control Chart for Detecting Sparse Changes in
  High-Dimensional Heteroscedastic Data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Because of the curse-of-dimensionality, high-dimensional processes present
challenges to traditional multivariate statistical process monitoring (SPM)
techniques. In addition, the unknown underlying distribution and complicated
dependency among variables such as heteroscedasticity increase uncertainty of
estimated parameters, and decrease the effectiveness of control charts. In
addition, the requirement of sufficient reference samples limits the
application of traditional charts in high dimension low sample size scenarios
(small n, large p). More difficulties appear in detecting and diagnosing
abnormal behaviors that are caused by a small set of variables, i.e., sparse
changes. In this article, we propose a changepoint based control chart to
detect sparse shifts in the mean vector of high-dimensional heteroscedastic
processes. Our proposed method can start monitoring when the number of
observations is a lot smaller than the dimensionality. The simulation results
show its robustness to nonnormality and heteroscedasticity. A real data example
is used to illustrate the effectiveness of the proposed control chart in
high-dimensional applications. Supplementary material and code are provided
online.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:38:17 GMT""}]","2021-01-26"
"2101.09425","Shuaige Qiao","Shuaige Qiao","Bubble tree compactification of instanton moduli spaces on 4-orbifolds","55 pages, 18 figures",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In the study of moduli spaces defined by the anti-self-dual (ASD) Yang-Mills
equations on $SU(2)$ or $SO(3)$ bundles over closed oriented Riemannian
4-manifolds $M$, the bubble tree compactification was defined in [T88], [F95],
[C02], [C10], [F14] and [F15]. The smooth orbifold structure of the bubble tree
compactification away from the trivial stratum is defined in [C02] and [C10].
In this paper, we apply the technique to 4-orbifolds of the form $M/\mathbb
Z_\alpha$ satisfying Condition \ref{the assumption of group action in this
thesis} to get a bubble tree compactification of the instanton moduli space on
this particular kind of 4-orbifolds.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 05:48:20 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 02:09:13 GMT""},{""version"":""v3"",""created"":""Tue, 23 Feb 2021 23:50:05 GMT""}]","2021-02-25"
"2101.09426","Jianfei Yu","Jianfei Yu, Chunxiao Yin, Linlin Liu, and Tao Jia","A paper's corresponding affiliation and first affiliation are consistent
  at the country level in Web of Science","12 pages, 3 figures",,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this study is to explore the relationship between the first
affiliation and the corresponding affiliation at the different levels via the
scientometric analysis We select over 18 million papers in the core collection
database of Web of Science (WoS) published from 2000 to 2015, and measure the
percentage of match between the first and the corresponding affiliation at the
country and institution level. We find that a paper's the first affiliation and
the corresponding affiliation are highly consistent at the country level, with
over 98% of the match on average. However, the match at the institution level
is much lower, which varies significantly with time and country. Hence, for
studies at the country level, using the first and corresponding affiliations
are almost the same. But we may need to take more cautions to select
affiliation when the institution is the focus of the investigation. In the
meanwhile, we find some evidence that the recorded corresponding information in
the WoS database has undergone some changes since 2013, which sheds light on
future studies on the comparison of different databases or the affiliation
accuracy of WoS. Our finding relies on the records of WoS, which may not be
entirely accurate. Given the scale of the analysis, our findings can serve as a
useful reference for further studies when country allocation or institute
allocation is needed. Existing studies on comparisons of straight counting
methods usually cover a limited number of papers, a particular research field
or a limited range of time. More importantly, using the number counted can not
sufficiently tell if the corresponding and first affiliation are similar. This
paper uses a metric similar to Jaccard similarity to measure the percentage of
the match and performs a comprehensive analysis based on a large-scale
bibliometric database.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:09:00 GMT""}]","2021-01-26"
"2101.09427","Abhishek Potnis","Abhishek V. Potnis, Rajat C. Shinde, Surya S. Durbha","Towards Natural Language Question Answering over Earth Observation
  Linked Data using Attention-based Neural Machine Translation","Accepted at IEEE International Geoscience and Remote Sensing
  Symposium (IGARSS) 2020",,"10.1109/IGARSS39084.2020.9323183",,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With an increase in Geospatial Linked Open Data being adopted and published
over the web, there is a need to develop intuitive interfaces and systems for
seamless and efficient exploratory analysis of such rich heterogeneous
multi-modal datasets. This work is geared towards improving the exploration
process of Earth Observation (EO) Linked Data by developing a natural language
interface to facilitate querying. Questions asked over Earth Observation Linked
Data have an inherent spatio-temporal dimension and can be represented using
GeoSPARQL. This paper seeks to study and analyze the use of RNN-based neural
machine translation with attention for transforming natural language questions
into GeoSPARQL queries. Specifically, it aims to assess the feasibility of a
neural approach for identifying and mapping spatial predicates in natural
language to GeoSPARQL's topology vocabulary extension including - Egenhofer and
RCC8 relations. The queries can then be executed over a triple store to yield
answers for the natural language questions. A dataset consisting of mappings
from natural language questions to GeoSPARQL queries over the Corine Land
Cover(CLC) Linked Data has been created to train and validate the deep neural
network. From our experiments, it is evident that neural machine translation
with attention is a promising approach for the task of translating spatial
predicates in natural language questions to GeoSPARQL queries.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:12:20 GMT""}]","2021-02-22"
"2101.09428","WenJie Song","Song WenJie, Shen Xuan","Vertical federated learning based on DFP and BFGS",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  As data privacy is gradually valued by people, federated learning(FL) has
emerged because of its potential to protect data. FL uses homomorphic
encryption and differential privacy encryption on the promise of ensuring data
security to realize distributed machine learning by exchanging encrypted
information between different data providers. However, there are still many
problems in FL, such as the communication efficiency between the client and the
server and the data is non-iid. In order to solve the two problems mentioned
above, we propose a novel vertical federated learning framework based on the
DFP and the BFGS(denoted as BDFL), then apply it to logistic regression.
Finally, we perform experiments using real datasets to test efficiency of BDFL
framework.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:15:04 GMT""}]","2021-01-26"
"2101.09429","Sheikh Rabiul Islam","Sheikh Rabiul Islam, William Eberle, Sheikh Khaled Ghafoor, Mohiuddin
  Ahmed","Explainable Artificial Intelligence Approaches: A Survey",,,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The lack of explainability of a decision from an Artificial Intelligence (AI)
based ""black box"" system/model, despite its superiority in many real-world
applications, is a key stumbling block for adopting AI in many high stakes
applications of different domain or industry. While many popular Explainable
Artificial Intelligence (XAI) methods or approaches are available to facilitate
a human-friendly explanation of the decision, each has its own merits and
demerits, with a plethora of open challenges. We demonstrate popular XAI
methods with a mutual case study/task (i.e., credit default prediction),
analyze for competitive advantages from multiple perspectives (e.g., local,
global), provide meaningful insight on quantifying explainability, and
recommend paths towards responsible or human-centered AI using XAI as a medium.
Practitioners can use this work as a catalog to understand, compare, and
correlate competitive advantages of popular XAI methods. In addition, this
survey elicits future research directions towards responsible or human-centric
AI systems, which is crucial to adopt AI in high stakes applications.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:15:34 GMT""}]","2021-01-26"
"2101.09430","Anjasha Gangopadhyay","Mridweeka Singh, Kuntal Misra, Stefano Valenti, Griffin Hosseinzadeh,
  Andrea Pastorello, Shubham Srivastav, Anjasha Gangopadhyay, Raya Dastidar,
  Lina Tomasella, Iair Arcavi, Stefano Benetti, Emma Callis, Enrico Cappellaro,
  Nancy Elias-Rosa, D. Andrew Howell, Sang Chul Kim, Curtis McCully, Leonardo
  Tartaglia, Giacomo Terreran, and Massimo Turatto","The fast evolving type Ib Supernova SN 2015dj in NGC 7371","16 pages, 11 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abdf5c",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the detailed optical evolution of a type Ib SN 2015dj in NGC 7371,
using data spanning up to $\sim$ 170 days after discovery. SN 2015dj shares
similarity in light curve shape with SN 2007gr and peaks at M$_{V}$ =
$-17.37\pm$0.02 mag. Analytical modelling of the quasi bolometric light curve
yields 0.06$\pm$0.01 M$_{\odot}$ of $^{56}$Ni, ejecta mass $M_{\rm ej} =
1.4^{+1.3}_{-0.5}$ \msol\, and kinetic energy $E_{\rm k} = 0.7^{+0.6}_{-0.3}
\times 10^{51}$ erg. The spectral features show a fast evolution and resemble
those of spherically symmetric ejecta. The analysis of nebular phase spectral
lines indicate a progenitor mass between 13-20 M$_{\odot}$ suggesting a binary
scenario.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:22:05 GMT""}]","2021-03-17"
"2101.09431","Lijing Shao","Rui Xu, Yong Gao, Lijing Shao","Signature of Lorentz Violation in Continuous Gravitational-Wave Spectra
  of Ellipsoidal Neutron Stars","8 pages, 4 figures; Invited research article to special issue
  ""Lorentz Violation in Astroparticles and Gravitational Waves"", in press","Galaxies 2021, 9:12","10.3390/galaxies9010012",,"gr-qc astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study effects of Lorentz-invariance violation on the rotation of neutron
stars (NSs) in the minimal gravitational Standard-Model Extension framework,
and calculate the quadrupole radiation generated by them. Aiming at testing
Lorentz invariance with observations of continuous gravitational waves (GWs)
from rotating NSs in the future, we compare the GW spectra of a rotating
ellipsoidal NS under Lorentz-violating gravity with those of a
Lorentz-invariant one. The former are found to possess frequency components
higher than the second harmonic, which does not happen for the latter,
indicating those higher frequency components to be potential signatures of
Lorentz violation in continuous GW spectra of rotating NSs.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:31:41 GMT""}]","2021-02-01"
"2101.09432","Tomi Ohtsuki","Tomohiro Mano and Tomi Ohtsuki","Machine learning the dynamics of quantum kicked rotor","published version. Proceedings of Localisation 2020. Annals of
  Physics",,"10.1016/j.aop.2021.168500",,"cond-mat.dis-nn cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Using the multilayer convolutional neural network (CNN), we can detect the
quantum phases in random electron systems, and phase diagrams of two and higher
dimensional Anderson transitions and quantum percolations as well as disordered
topological systems have been obtained. Here, instead of using CNN to analyze
the wave functions, we analyze the dynamics of wave packets via long short-term
memory network (LSTM). We adopt the quasi-periodic quantum kicked rotors, which
simulate the three and four dimensional Anderson transitions. By supervised
training, we let LSTM extract the features of the time series of wave packet
displacements in localized and delocalized phases. We then simulate the wave
packets in unknown phases and let LSTM classify the time series to localized
and delocalized phases. We compare the phase diagrams obtained by LSTM and
those obtained by CNN.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:45:06 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 00:11:12 GMT""}]","2021-05-11"
"2101.09433","Jinyeong Chae","Jinyeong Chae, Ki Yong Hong, Jihie Kim","A Pressure Ulcer Care System For Remote Medical Assistance: Residual
  U-Net with an Attention Model Based for Wound Area Segmentation","Accepted by AAAI 2021 Workshop",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Increasing numbers of patients with disabilities or elderly people with
mobility issues often suffer from a pressure ulcer. The affected areas need
regular checks, but they have a difficulty in accessing a hospital. Some remote
diagnosis systems are being used for them, but there are limitations in
checking a patient's status regularly. In this paper, we present a remote
medical assistant that can help pressure ulcer management with image processing
techniques. The proposed system includes a mobile application with a deep
learning model for wound segmentation and analysis. As there are not enough
data to train the deep learning model, we make use of a pretrained model from a
relevant domain and data augmentation that is appropriate for this task. First
of all, an image preprocessing method using bilinear interpolation is used to
resize images and normalize the images. Second, for data augmentation, we use
rotation, reflection, and a watershed algorithm. Third, we use a pretrained
deep learning model generated from skin wound images similar to pressure ulcer
images. Finally, we added an attention module that can provide hints on the
pressure ulcer image features. The resulting model provides an accuracy of
99.0%, an intersection over union (IoU) of 99.99%, and a dice similarity
coefficient (DSC) of 93.4% for pressure ulcer segmentation, which is better
than existing results.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:45:52 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 10:24:09 GMT""}]","2021-04-16"
"2101.09434","Arvind  Kiwelekar","Arvind W Kiwelekar","A Software Architecture Teacher's Dilemmas","This is the reviewed version of the paper submitted to International
  Conference on Software Architecture (ICSA 2021)",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  An instructor teaching a course on Software Architecture needs to be more
reflective to engage students productively in the learning activities. In this
reflective essay, the author identifies a few decisive moments referred to as
instructional dilemmas at which a teacher reflects upon choices and their
consequences so that meaningful learning happens. These situations are referred
to as dilemmas because they offer two options to instructors. Some of these
dilemmas arise from the inherent nature of Software Architecture as a
discipline, while the source of others is the background knowledge of learners.
The paper suggests a set of principles and small-teaching methods to make
teaching and learning more effective in such situations.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:01:38 GMT""}]","2021-01-26"
"2101.09435","Erik Fredenberg","Erik Fredenberg, Mats Lundqvist, Magnus Aslund, Magnus Hemmendorff,
  Bjorn Cederstrom, Mats Danielsson","A photon-counting detector for dual-energy breast tomosynthesis",,"Proc. SPIE 7258, Medical Imaging 2009: Physics of Medical Imaging,
  72581J (2009)","10.1117/12.813037",,"physics.med-ph physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present the first evaluation of a recently developed silicon-strip
detector for photon-counting dual-energy breast tomosynthesis. The detector is
well suited for tomosynthesis with high dose efficiency and intrinsic scatter
rejection. A method was developed for measuring the spatial resolution of a
system based on the detector in terms of the three-dimensional modulation
transfer function (MTF). The measurements agreed well with theoretical
expectations, and it was seen that depth resolution was won at the cost of a
slightly decreased lateral resolution. This may be a justifiable trade-off as
clinical images acquired with the system indicate improved conspicuity of
breast lesions. The photon-counting detector enables dual-energy subtraction
imaging with electronic spectrumsplitting. This improved the detectability of
iodine in phantom measurements, and the detector was found to be stable over
typical clinical acquisition times. A model of the energy resolution showed
that further improvements are within reach by optimization of the detector.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:09:08 GMT""}]","2021-01-26"
"2101.09436","Xudong Sun","Xudong Sun, Florian Buettner","Hierarchical Variational Auto-Encoding for Unsupervised Domain
  Generalization","Presented at ICLR 2021 RobustML Workshop",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the task of domain generalization, where the goal is to train a
predictive model such that it is able to generalize to a new, previously unseen
domain. We choose a hierarchical generative approach within the framework of
variational autoencoders and propose a domain-unsupervised algorithm that is
able to generalize to new domains without domain supervision. We show that our
method is able to learn representations that disentangle domain-specific
information from class-label specific information even in complex settings
where domain structure is not observed during training. Our interpretable
method outperforms previously proposed generative algorithms for domain
generalization as well as other non-generative state-of-the-art approaches in
several hierarchical domain settings including sequential overlapped near
continuous domain shift. It also achieves competitive performance on the
standard domain generalization benchmark dataset PACS compared to
state-of-the-art approaches which rely on observing domain-specific information
during training, as well as another domain unsupervised method. Additionally,
we proposed model selection purely based on Evidence Lower Bound (ELBO) and
also proposed weak domain supervision where implicit domain information can be
added into the algorithm.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:09:59 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 19:00:48 GMT""},{""version"":""v3"",""created"":""Sat, 27 Feb 2021 13:35:03 GMT""},{""version"":""v4"",""created"":""Thu, 6 May 2021 17:36:04 GMT""},{""version"":""v5"",""created"":""Fri, 14 May 2021 20:51:15 GMT""}]","2021-05-18"
"2101.09437","Huanhuan Yang","Huanhuan Yang, Lingling Song, Yunshan Cao, X. R. Wang, and Peng Yan","Experimental observation of edge-dependent quantum pseudospin Hall
  effect",,,"10.1103/PhysRevB.104.235427",,"cond-mat.mes-hall cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  It is a conventional wisdom that the helical edge states of quantum spin Hall
(QSH) insulator are particularly stable due to the topological protection of
time-reversal symmetry. Here, we report the first experimental observation of
an edge-dependent quantum (pseudo-)spin Hall effect by employing two Kekule
electric circuits with molecule-zigzag and partially-bearded edges, where the
chirality of the circulating current in the unit cell mimics the electron spin.
We observe a helicity flipping of the topological in-gap modes emerging in
opposite parameter regions for the two edge geometries. Experimental findings
are interpreted in terms of the mirror winding number defined in the unit cell,
the choice of which exclusively depends on the edge shape. Our work offers a
deeper understanding of the boundary effect on the QSH phase, and pave the way
for studying the spin-dependent topological physics in electric circuits.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:12:54 GMT""}]","2022-01-05"
"2101.09438","Dheeraj Baby","Dheeraj Baby and Xuandong Zhao and Yu-Xiang Wang","An Optimal Reduction of TV-Denoising to Adaptive Online Learning","To appear at AISTATS 2021",,,,"cs.LG math.OC stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We consider the problem of estimating a function from $n$ noisy samples whose
discrete Total Variation (TV) is bounded by $C_n$. We reveal a deep connection
to the seemingly disparate problem of Strongly Adaptive online learning
(Daniely et al, 2015) and provide an $O(n \log n)$ time algorithm that attains
the near minimax optimal rate of $\tilde O (n^{1/3}C_n^{2/3})$ under squared
error loss. The resulting algorithm runs online and optimally adapts to the
unknown smoothness parameter $C_n$. This leads to a new and more versatile
alternative to wavelets-based methods for (1) adaptively estimating TV bounded
functions; (2) online forecasting of TV bounded trends in time series.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:13:53 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 06:55:03 GMT""}]","2021-01-27"
"2101.09439","Erik Fredenberg","Moa Yveborg, Cheng Xu, Erik Fredenberg, Mats Danielsson","Photon-counting CT with silicon detectors: feasibility for pediatric
  imaging",,"Proc. SPIE 7258, Medical Imaging 2009: Physics of Medical Imaging,
  725825 (2009)","10.1117/12.813733",,"physics.ins-det physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  X-ray detectors made of crystalline silicon have several advantages including
low dark currents, fast charge collection and high energy resolution. For
high-energy x-rays, however, silicon suffers from its low atomic number, which
might result in low detection efficiency, as well as low energy and spatial
resolution due to Compton scattering. We have used a monte-carlo model to
investigate the feasibility of a detector for pediatric CT with 30 to 40 mm of
silicon using x-ray spectra ranging from 80 to 140 kVp. A detection efficiency
of 0.74 was found at 80 kVp, provided the noise threshold could be set low.
Scattered photons were efficiently blocked by a thin metal shielding between
the detector units, and Compton scattering in the detector could be well
separated from photo absorption at 80 kVp. Hence, the detector is feasible at
low acceleration voltages, which is also suitable for pediatric imaging. We
conclude that silicon detectors may be an alternative to other designs for this
special case.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:14:39 GMT""}]","2021-01-26"
"2101.09440","Erik Fredenberg","Erik Fredenberg, Magnus Aslund, Bjorn Cederstrom, Mats Lundqvist, Mats
  Danielsson","Observer model optimization of a spectral mammography system",,"Proc. SPIE 7622, Medical Imaging 2010: Physics of Medical Imaging,
  762210 (2010)","10.1117/12.845480",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spectral imaging is a method in medical x-ray imaging to extract information
about the object constituents by the material-specific energy dependence of
x-ray attenuation. Contrast-enhanced spectral imaging has been thoroughly
investigated, but unenhanced imaging may be more useful because it comes as a
bonus to the conventional non-energy-resolved absorption image at screening;
there is no additional radiation dose and no need for contrast medium. We have
used a previously developed theoretical framework and system model that include
quantum and anatomical noise to characterize the performance of a
photon-counting spectral mammography system with two energy bins for unenhanced
imaging. The theoretical framework was validated with synthesized images.
Optimal combination of the energy-resolved images for detecting large
unenhanced tumors corresponded closely, but not exactly, to minimization of the
anatomical noise, which is commonly referred to as energy subtraction. In that
case, an ideal-observer detectability index could be improved close to 50%
compared to absorption imaging. Optimization with respect to the
signal-to-quantum-noise ratio, commonly referred to as energy weighting,
deteriorated detectability. For small microcalcifications or tumors on uniform
backgrounds, however, energy subtraction was suboptimal whereas energy
weighting provided a minute improvement. The performance was largely
independent of beam quality, detector energy resolution, and bin count
fraction. It is clear that inclusion of anatomical noise and imaging task in
spectral optimization may yield completely different results than an analysis
based solely on quantum noise.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:19:32 GMT""}]","2021-01-26"
"2101.09441","Qiuyi Lyu","Qiuyi Lyu, Yuchen Li, Bingsheng He, Bin Gong","DBL: Efficient Reachability Queries on Dynamic Graphs (Complete Version)",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reachability query is a fundamental problem on graphs, which has been
extensively studied in academia and industry. Since graphs are subject to
frequent updates in many applications, it is essential to support efficient
graph updates while offering good performance in reachability queries. Existing
solutions compress the original graph with the Directed Acyclic Graph (DAG) and
propose efficient query processing and index update techniques. However, they
focus on optimizing the scenarios where the Strong Connected Components(SCCs)
remain unchanged and have overlooked the prohibitively high cost of the DAG
maintenance when SCCs are updated. In this paper, we propose DBL, an efficient
DAG-free index to support the reachability query on dynamic graphs with
insertion-only updates. DBL builds on two complementary indexes: Dynamic
Landmark (DL) label and Bidirectional Leaf (BL) label. The former leverages
landmark nodes to quickly determine reachable pairs whereas the latter prunes
unreachable pairs by indexing the leaf nodes in the graph. We evaluate DBL
against the state-of-the-art approaches on dynamic reachability index with
extensive experiments on real-world datasets. The results have demonstrated
that DBL achieves orders of magnitude speedup in terms of index update, while
still producing competitive query efficiency.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:22:38 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 05:18:22 GMT""}]","2021-04-16"
"2101.09442","Erik Fredenberg","Erik Fredenberg, Bjorn Svensson, Mats Danielsson, Barbara Lazzari,
  Bjorn Cederstrom","Optimization of mammography with respect to anatomical noise",,"Proc. SPIE 7961, Medical Imaging 2011: Physics of Medical Imaging,
  796112 (2011)","10.1117/12.877985",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Beam quality optimization in mammography traditionally considers detection of
a target obscured by quantum noise on a homogenous background. It can be argued
that this scheme does not correspond well to the clinical imaging task because
real mammographic images contain a complex superposition of anatomical
structures, resulting in anatomical noise that may dominate over quantum noise.
Using a newly developed spectral mammography system, we measured the
correlation and magnitude of the anatomical noise in a set of mammograms. The
results from these measurements were used as input to an observer-model
optimization that included quantum noise as well as anatomical noise. We found
that, within this framework, the detectability of tumors and
microcalcifications behaved very differently with respect to beam quality and
dose. The results for small microcalcifications were similar to what
traditional optimization methods would yield, which is to be expected since
quantum noise dominates over anatomical noise at high spatial frequencies. For
larger tumors, however, low-frequency anatomical noise was the limiting factor.
Because anatomical structure has similar energy dependence as tumor contrast,
optimal x-ray energy was significantly higher and the useful energy region
wider than traditional methods suggest. Measurements on a tissue phantom
confirmed these theoretical results. Furthermore, since quantum noise
constitutes only a small fraction of the noise, the dose could be reduced
substantially without sacrificing tumor detectability. Exposure settings used
clinically are therefore not necessarily optimal for this imaging task. The
impact of these findings on the mammographic imaging task as a whole is,
however, at this stage unclear.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:25:17 GMT""}]","2021-01-26"
"2101.09443","Shuang Zhao","Hai-Liang Li, Shuang Zhao, Han-Wen Zuo","Existence and Nonlinear Stability of Steady-States to Outflow Problem
  for the Full Two-Phase Flow","31 pages","J. Differential Equations 309 (2022)","10.1016/j.jde.2021.11.040",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The outflow problem for the viscous full two-phase flow model in a half line
is investigated in the present paper. The existence, uniqueness and nonlinear
stability of the steady-state are shown respectively corresponding to the
supersonic, sonic or subsonic state at far field. This is different from the
outflow problem for the isentropic Navier-Stokes equations, where there is no
steady-state for the subsonic state. Furthermore, we obtain either exponential
time decay rates for the supersonic state or algebraic time decay rates for
supersonic and sonic states in weighted Sobolev spaces.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:26:16 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 09:36:42 GMT""}]","2022-07-14"
"2101.09444","Daniel Perales Anaya","Daniel Perales","On the anti-commutator of two free random variables",,,,,"math.OA math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(\kappa_n(a))_{n\geq 1}$ denote the sequence of free cumulants of a
random variable $a$ in a non-commutative probability space
$(\mathcal{A},\varphi)$. Based on some considerations on bipartite graphs, we
provide a formula to compute the cumulants $(\kappa_n(ab+ba))_{n\geq 1}$ in
terms of $(\kappa_n(a))_{n\geq 1}$ and $(\kappa_n(b))_{n\geq 1}$, where $a$ and
$b$ are freely independent. Our formula expresses the $n$-th free cumulant of
$ab+ba$ as a sum indexed by partitions in the set $\mathcal{Y}_{2n}$ of
non-crossing partitions of the form
  \[ \sigma=\{B_1,B_3,\dots, B_{2n-1},E_1,\dots,E_r\}, \quad \text{with }r\geq
0, \]
  such that $i\in B_{i}$ for $i=1,3,\dots,2n-1$ and $|E_j|$ even for $j\leq r$.
Therefore, by studying the sets $\mathcal{Y}_{2n}$ we obtain new results
regarding the distribution of $ab+ba$. For instance, the size
$|\mathcal{Y}_{2n}|$ is closely related to the case when $a,b$ are free Poisson
random variables of parameter 1. Our formula can also be expressed in terms of
cacti graphs. This graph theoretic approach suggests a natural generalization
that allows us to study quadratic forms in $k$ free random variables.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:26:22 GMT""}]","2021-01-26"
"2101.09445","Alik Panja","Alik Panja, Wen Ping Chen, Somnath Dutta, Yan Sun, Yu Gao, and Soumen
  Mondal","Sustaining Star Formation in the Galactic Star Cluster M 36?","24 pages, 14 figures, 4 tables",,"10.3847/1538-4357/abded4",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present comprehensive characterization of the Galactic open cluster M 36.
Some two hundred member candidates, with an estimated contamination rate of
$\sim$8%, have been identified on the basis of proper motion and parallax
measured by the $Gaia$ DR2. The cluster has a proper motion grouping around
($\mu_{\alpha} \cos\delta = -$0.15 $\pm$ 0.01 mas yr$^{-1}$, and $\mu_{\delta}
= -$3.35 $\pm$ 0.02 mas yr$^{-1}$), distinctly separated from the field
population. Most member candidates have parallax values 0.7$-$0.9 mas, with a
median value of 0.82 $\pm$ 0.07 mas (distance $\sim$1.20 $\pm$ 0.13 kpc). The
angular diameter of 27$'$ $\pm$ $0\farcm4$ determined from the radial density
profile then corresponds to a linear extent of 9.42 $\pm$ 0.14 pc. With an
estimated age of $\sim$15 Myr, M 36 is free of nebulosity. To the south-west of
the cluster, we discover a highly obscured ($A_{V}$ up to $\sim$23 mag),
compact ($\sim$ $1\farcm9 \times 1\farcm2$) dense cloud, within which three
young stellar objects in their infancy (ages $\lesssim$ 0.2 Myr) are
identified. The molecular gas, 3.6 pc in extent, contains a total mass of
(2$-$3)$\times$10$^{2}$ M$_{\odot}$, and has a uniform velocity continuity
across the cloud, with a velocity range of $-$20 to $-$22 km s$^{-1}$,
consistent with the radial velocities of known star members. In addition, the
cloud has a derived kinematic distance marginally in agreement with that of the
star cluster. If physical association between M 36 and the young stellar
population can be unambiguously established, this manifests a convincing
example of prolonged star formation activity spanning up to tens of Myrs in
molecular clouds.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:27:52 GMT""}]","2021-04-07"
"2101.09446","Yunzhen Yao","Yunzhen Yao, Liangzu Peng and Manolis C. Tsakiris","Unlabeled Principal Component Analysis",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of principal component analysis from a data matrix
where the entries of each column have undergone some unknown permutation,
termed Unlabeled Principal Component Analysis (UPCA). Using algebraic geometry,
we establish that for generic enough data, and up to a permutation of the
coordinates of the ambient space, there is a unique subspace of minimal
dimension that explains the data. We show that a permutation-invariant system
of polynomial equations has finitely many solutions, with each solution
corresponding to a row permutation of the ground-truth data matrix. Allowing
for missing entries on top of permutations leads to the problem of unlabeled
matrix completion, for which we give theoretical results of similar flavor. We
also propose a two-stage algorithmic pipeline for UPCA suitable for the
practically relevant case where only a fraction of the data has been permuted.
Stage-I of this pipeline employs robust-PCA methods to estimate the
ground-truth column-space. Equipped with the column-space, stage-II applies
methods for linear regression without correspondences to restore the permuted
data. A computational study reveals encouraging findings, including the ability
of UPCA to handle face images from the Extended Yale-B database with
arbitrarily permuted patches of arbitrary size in $0.3$ seconds on a standard
desktop computer.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:34:48 GMT""}]","2021-01-26"
"2101.09447","Maximilien Cazayous","M. Revelli Beaumont, P. Hemme, Y. Gallais, A. Sacuto, K. Jacob, L.
  Valade, D. de Caro, C. Faulmann, and M. Cazayous","Possible observation of the signature of the bad metal phase and its
  crossover to a Fermi liquid in K(BEDT-TTF)2Cu(NCS)2 bulk and nanoparticles by
  Raman scattering",,"J. Phys.: Condens. Matter 33 125403(2021)","10.1088/1361-648X/abd813",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  K(BEDT-TTF)2Cu(NCS)2 has been investigated by Raman scattering in both bulk
and nanoparticle compounds. Phonon modes from 20 to 1600 cm-1 have been
assigned. Focusing on the unexplored low frequency phonons, a plateau in
frequencies is observed in the bulk phonons between 50 and 100 K and assigned
to the signature of the bad metal phase. Nanoparticles of K(BEDT-TTF)2Cu(NCS)2
exhibit anomalies at 50 K associated to the crossover from a bad metal to a
Fermi liquid whose origins are discussed.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:41:55 GMT""}]","2021-01-26"
"2101.09448","Alex Kodess","Alex Kodess, Brian G. Kronenthal, Diego Manzano-Ruiz, Ethan Noe","Classification by girth of three-dimensional algebraically defined
  monomial graphs over the real numbers","8 pages",,"10.1016/j.disc.2020.112286",,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For positive integers $s,t,u,v$, we define a bipartite graph
$\Gamma_{\mathbb{R}}(X^s Y^t,X^u Y^v)$ where each partite set is a copy of
$\mathbb{R}^3$, and a vertex $(a_1,a_2,a_3)$ in the first partite set is
adjacent to a vertex $[x_1,x_2,x_3]$ in the second partite set if and only if
  \[
  a_2 + x_2 = a_1^s x_1^t
  \quad
  \text{and}
  \quad
  a_3+x_3=a_1^ux_1^v.
  \] In this paper, we classify all such graphs according to girth.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:43:28 GMT""}]","2021-01-26"
"2101.09449","Rajdeep Mukherjee","Rajdeep Mukherjee, Shreyas Shetty, Subrata Chattopadhyay, Subhadeep
  Maji, Samik Datta and Pawan Goyal","Reproducibility, Replicability and Beyond: Assessing Production
  Readiness of Aspect Based Sentiment Analysis in the Wild","12 pages, accepted at ECIR 2021",,"10.1007/978-3-030-72240-1_7",,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  With the exponential growth of online marketplaces and user-generated content
therein, aspect-based sentiment analysis has become more important than ever.
In this work, we critically review a representative sample of the models
published during the past six years through the lens of a practitioner, with an
eye towards deployment in production. First, our rigorous empirical evaluation
reveals poor reproducibility: an average 4-5% drop in test accuracy across the
sample. Second, to further bolster our confidence in empirical evaluation, we
report experiments on two challenging data slices, and observe a consistent
12-55% drop in accuracy. Third, we study the possibility of transfer across
domains and observe that as little as 10-25% of the domain-specific training
dataset, when used in conjunction with datasets from other domains within the
same locale, largely closes the gap between complete cross-domain and complete
in-domain predictive performance. Lastly, we open-source two large-scale
annotated review corpora from a large e-commerce portal in India in order to
aid the study of replicability and transfer, with the hope that it will fuel
further growth of the field.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:45:27 GMT""}]","2021-05-12"
"2101.09450","Jaeyun Yi","Jaeyun Yi","Macroscopic multi-fractality of Gaussian random fields and linear SPDEs
  with colored noise","19pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the linear stochastic heat and wave equations with generalized
Gaussian noise that is white in time and spatially correlated. Under the
assumption that the homogeneous spatial correlation $f$ satisfies some mild
conditions, we show that the solutions to the linear stochastic heat and wave
equations exhibit tall peaks in macroscopic scales, which means they are
macroscopically multi-fractal. We compute the macroscopic Hausdorff dimension
of the peaks for Gaussian random fields with vanishing correlation and then
apply this result to the solution of the linear stochastic heat and wave
equations. We also study the spatio-temporal multi-fractality of the linear
stochastic heat and wave equations. Our result is an extension of Khoshnevisan,
Kim, and Xiao \cite{KKX,KKX2} and Kim \cite{K} to a more general class of the
linear stochastic partial differential equations and Gaussian random fields.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:48:01 GMT""}]","2021-01-26"
"2101.09451","Shao-Yuan Lo","Shao-Yuan Lo and Vishal M. Patel","Error Diffusion Halftoning Against Adversarial Examples","Accepted at IEEE International Conference on Image Processing (ICIP)
  2021",,,,"cs.CV cs.CR cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial examples contain carefully crafted perturbations that can fool
deep neural networks (DNNs) into making wrong predictions. Enhancing the
adversarial robustness of DNNs has gained considerable interest in recent
years. Although image transformation-based defenses were widely considered at
an earlier time, most of them have been defeated by adaptive attacks. In this
paper, we propose a new image transformation defense based on error diffusion
halftoning, and combine it with adversarial training to defend against
adversarial examples. Error diffusion halftoning projects an image into a 1-bit
space and diffuses quantization error to neighboring pixels. This process can
remove adversarial perturbations from a given image while maintaining
acceptable image quality in the meantime in favor of recognition. Experimental
results demonstrate that the proposed method is able to improve adversarial
robustness even under advanced adaptive attacks, while most of the other image
transformation-based defenses do not. We show that a proper image
transformation can still be an effective defense approach. Code:
https://github.com/shaoyuanlo/Halftoning-Defense
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:55:02 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 23:03:02 GMT""},{""version"":""v3"",""created"":""Sat, 24 Jul 2021 06:59:58 GMT""}]","2021-07-27"
"2101.09452","Jian Chen","Jian Chen, Chenhao Wan, Andy Chong and Qiwen Zhan","Experimental demonstration of cylindrical vector spatiotemporal optical
  vortex","5 pages, 5 figures",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally generate cylindrically polarized wavepackets with
transverse orbital angular momentum, demonstrating the coexistence of
spatiotemporal optical vortex with spatial polarization singularity. The
results in this paper extend the study of spatiotemporal wavepackets to a
broader scope, paving the way for its applications in various areas such as
light-matter interaction, optical tweezers, spatiotemporal spin-orbit angular
momentum coupling, etc.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:56:20 GMT""}]","2021-01-26"
"2101.09453","Linxing Jiang","Linxing Preston Jiang, Luciano de la Iglesia","Improved Training of Sparse Coding Variational Autoencoder via Weight
  Normalization",,,,,"cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning a generative model of visual information with sparse and
compositional features has been a challenge for both theoretical neuroscience
and machine learning communities. Sparse coding models have achieved great
success in explaining the receptive fields of mammalian primary visual cortex
with sparsely activated latent representation. In this paper, we focus on a
recently proposed model, sparse coding variational autoencoder (SVAE) (Barello
et al., 2018), and show that the end-to-end training scheme of SVAE leads to a
large group of decoding filters not fully optimized with noise-like receptive
fields. We propose a few heuristics to improve the training of SVAE and show
that a unit $L_2$ norm constraint on the decoder is critical to produce sparse
coding filters. Such normalization can be considered as local lateral
inhibition in the cortex. We verify this claim empirically on both natural
image patches and MNIST dataset and show that projection of the filters onto
unit norm drastically increases the number of active filters. Our results
highlight the importance of weight normalization for learning sparse
representation from data and suggest a new way of reducing the number of
inactive latent components in VAE learning.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:07:20 GMT""}]","2021-01-26"
"2101.09454","Jiahuan Wang","Jiahuan Wang, Pingzhi Fan, Des McLernon and Zhiguo Ding","Complementary Waveforms for Range-Doppler Sidelobe Suppression Based on
  a Null Space Approach","12 pages, 12 figures, submitted to IEEE Transactions on Signal
  Processing",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Doppler resilient complementary waveforms have previously been
considered to suppress range sidelobes within a Doppler interval of interest in
radar systems, their capability of Doppler resilience has not been fully
utilized. In this paper, a new construction of Doppler resilient complementary
waveforms based on a null space is proposed. With this new construction, one
can flexibly include a specified Doppler interval of interest or even an
overall Doppler interval into a term which results in range sidelobes. We can
force this term to zero, which can be solved to obtain a null space. From the
null space, the characteristic vector to control the transmission of basic
Golay waveforms, and the coefficients of the receiver filter for Golay
complementary waveform can be extracted. Besides, based on the derived null
space, two challenging non-convex optimization problems are formulated and
solved for maximizing the signal-to-noise ratio (SNR). Moreover, the
coefficients of the receiver filter and the characteristic vector can be
applied to fully polarimetric radar systems to achieve nearly perfect Doppler
resilient performance, and hence fully suppress the inter-antenna
interferences.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:09:46 GMT""}]","2021-01-26"
"2101.09455","Maximilien Cazayous","M. Revelli Beaumont, Y. Gallais, A. Sacuto, K. Jacob, L. Valade, D. de
  Caro, C. Faulmann, and M. Cazayous","Amplitude mode of charge density wave in TTF[Ni(dmit)2]2 observed by
  electronic Raman scattering",,"Phys. Rev. B 103, 035139 (2021)","10.1103/PhysRevB.103.035139",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We measured the optical signature of the charge density waves (CDWs) in the
multiband conductor TTF[Ni(dmit)2]2 by electronic Raman scattering. At low
energies, a hump develops below 60 K. This hump is associated to the amplitude
mode of the CDW with an energy around 9 meV. Raman symmetry-resolved
measurements show that the CDW amplitude mode is anisotropic and that the CDW
can be associated to the band nesting of Ni(dmit)2 chains.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:29:40 GMT""}]","2021-01-26"
"2101.09456","Zhen-Ming Xu","Zhen-Ming Xu, Bin Wu, and Wen-Li Yang","van der Waals fluid and charged AdS black hole in the Landau theory","10 pages, 5 figures; v2:add References and some comments; v3:
  clarifications added; v4: match published version","Class. Quantum Grav. 38 (2021) 205008","10.1088/1361-6382/ac25dd",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By introducing the general construction of Landau functional of the van der
Waals system and charged AdS black hole system, we have preliminarily realized
the Landau continuous phase transition theory in black hole thermodynamics. The
results show that the Landau functional constructed in present paper can
directly reflect the physical process of black hole phase transition.
Specifically, the splitting of the global minimum of the Landau functional
corresponds to the second-order phase transition of the black hole, and the
transformation of the global minimum reflects the first-order phase transition
of the black hole.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:34:01 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 08:48:27 GMT""},{""version"":""v3"",""created"":""Tue, 13 Apr 2021 06:41:11 GMT""},{""version"":""v4"",""created"":""Thu, 30 Sep 2021 03:19:09 GMT""}]","2021-10-01"
"2101.09457","Fritz Gesztesy","S. Blake Allan and Fritz Gesztesy","On critical dipoles in dimensions $n\geq 3$","37 pages, 1 figure, 1 table, introduction and references updated,
  some typos removed",,,,"math.AP math.SP","http://creativecommons.org/licenses/by/4.0/","  We reconsider generalizations of Hardy's inequality corresponding to the case
of (point) dipole potentials $V_{\gamma}(x) = \gamma (u, x) |x|^{-3}$, $x \in
\mathbb{R}^n \backslash \{0\}$, $\gamma \in [0,\infty)$, $u \in \mathbb{R}^n$,
$|u|=1$, $n \in \mathbb{N}$, $n \geq 3$. More precisely, for $n \geq 3$, we
provide an alternative proof of the existence of a critical dipole coupling
constant $\gamma_{c,n} > 0$, such that \begin{align*} &\text{for all $\gamma
\in [0,\gamma_{c,n}]$, and all $u \in \mathbb{R}^n$, $|u|=1$,} \\ &\quad
\int_{\mathbb{R}^n} d^n x \, |(\nabla f)(x)|^2 \geq \pm \gamma
\int_{\mathbb{R}^n} d^n x \, (u, x) |x|^{-3} |f(x)|^2, \quad f \in
D^1(\mathbb{R}^n). \end{align*} with $D^1(\mathbb{R}^n)$ denoting the
completion of $C_0^{\infty}(\mathbb{R}^n)$ with respect to the norm induced by
the gradient. Here $\gamma_{c,n}$ is sharp, that is, the largest possible such
constant, and we discuss a numerical scheme for its computation. Moreover, we
discuss upper and lower bounds for $\gamma_{c,n} > 0$.
  We also consider the case of multicenter dipole interactions with dipoles
centered on an infinite discrete set.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:46:10 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 06:16:03 GMT""}]","2021-08-18"
"2101.09458","William Whitney","William F. Whitney, Michael Bloesch, Jost Tobias Springenberg, Abbas
  Abdolmaleki, Kyunghyun Cho, Martin Riedmiller","Decoupled Exploration and Exploitation Policies for Sample-Efficient
  Reinforcement Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the close connection between exploration and sample efficiency, most
state of the art reinforcement learning algorithms include no considerations
for exploration beyond maximizing the entropy of the policy. In this work we
address this seeming missed opportunity. We observe that the most common
formulation of directed exploration in deep RL, known as bonus-based
exploration (BBE), suffers from bias and slow coverage in the few-sample
regime. This causes BBE to be actively detrimental to policy learning in many
control tasks. We show that by decoupling the task policy from the exploration
policy, directed exploration can be highly effective for sample-efficient
continuous control. Our method, Decoupled Exploration and Exploitation Policies
(DEEP), can be combined with any off-policy RL algorithm without modification.
When used in conjunction with soft actor-critic, DEEP incurs no performance
penalty in densely-rewarding environments. On sparse environments, DEEP gives a
several-fold improvement in data efficiency due to better exploration.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:51:04 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 16:03:55 GMT""}]","2021-07-02"
"2101.09459","Chongming Gao","Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, Tat-Seng
  Chua","Advances and Challenges in Conversational Recommender Systems: A Survey","33 pages, 8 figures, 6 tables","AI Open. Vol. 2. (2021) 100-126","10.1016/j.aiopen.2021.06.002",,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems exploit interaction history to estimate user preference,
having been heavily used in a wide range of industry applications. However,
static recommendation models are difficult to answer two important questions
well due to inherent shortcomings: (a) What exactly does a user like? (b) Why
does a user like an item? The shortcomings are due to the way that static
models learn user preference, i.e., without explicit instructions and active
feedback from users. The recent rise of conversational recommender systems
(CRSs) changes this situation fundamentally. In a CRS, users and the system can
dynamically communicate through natural language interactions, which provide
unprecedented opportunities to explicitly obtain the exact preference of users.
  Considerable efforts, spread across disparate settings and applications, have
been put into developing CRSs. Existing models, technologies, and evaluation
methods for CRSs are far from mature. In this paper, we provide a systematic
review of the techniques used in current CRSs. We summarize the key challenges
of developing CRSs in five directions: (1) Question-based user preference
elicitation. (2) Multi-turn conversational recommendation strategies. (3)
Dialogue understanding and generation. (4) Exploitation-exploration trade-offs.
(5) Evaluation and user simulation. These research directions involve multiple
research fields like information retrieval (IR), natural language processing
(NLP), and human-computer interaction (HCI). Based on these research
directions, we discuss some future challenges and opportunities. We provide a
road map for researchers from multiple communities to get started in this area.
We hope this survey can help to identify and address challenges in CRSs and
inspire future research.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 08:53:15 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 13:26:00 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jan 2021 09:10:08 GMT""},{""version"":""v4"",""created"":""Thu, 4 Feb 2021 15:45:37 GMT""},{""version"":""v5"",""created"":""Sun, 7 Feb 2021 03:58:16 GMT""},{""version"":""v6"",""created"":""Thu, 27 May 2021 04:10:53 GMT""},{""version"":""v7"",""created"":""Fri, 24 Sep 2021 02:20:45 GMT""}]","2021-09-27"
"2101.09460","Sodiq Adewole","Sali Rasoul, Sodiq Adewole, Alphonse Akakpo","Feature Selection Using Reinforcement Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the decreasing cost of data collection, the space of variables or
features that can be used to characterize a particular predictor of interest
continues to grow exponentially. Therefore, identifying the most characterizing
features that minimizes the variance without jeopardizing the bias of our
models is critical to successfully training a machine learning model. In
addition, identifying such features is critical for interpretability,
prediction accuracy and optimal computation cost. While statistical methods
such as subset selection, shrinkage, dimensionality reduction have been applied
in selecting the best set of features, some other approaches in literature have
approached feature selection task as a search problem where each state in the
search space is a possible feature subset. In this paper, we solved the feature
selection problem using Reinforcement Learning. Formulating the state space as
a Markov Decision Process (MDP), we used Temporal Difference (TD) algorithm to
select the best subset of features. Each state was evaluated using a robust and
low cost classifier algorithm which could handle any non-linearities in the
dataset.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:24:37 GMT""}]","2021-01-26"
"2101.09461","Gennaro Vessio Dr.","Moises Diaz, Momina Moetesum, Imran Siddiqi, Gennaro Vessio","Sequence-based Dynamic Handwriting Analysis for Parkinson's Disease
  Detection with One-dimensional Convolutions and BiGRUs",,"Expert Systems with Applications, Volume 168, 15 April 2021,
  114405","10.1016/j.eswa.2020.114405",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Parkinson's disease (PD) is commonly characterized by several motor symptoms,
such as bradykinesia, akinesia, rigidity, and tremor. The analysis of patients'
fine motor control, particularly handwriting, is a powerful tool to support PD
assessment. Over the years, various dynamic attributes of handwriting, such as
pen pressure, stroke speed, in-air time, etc., which can be captured with the
help of online handwriting acquisition tools, have been evaluated for the
identification of PD. Motion events, and their associated spatio-temporal
properties captured in online handwriting, enable effective classification of
PD patients through the identification of unique sequential patterns. This
paper proposes a novel classification model based on one-dimensional
convolutions and Bidirectional Gated Recurrent Units (BiGRUs) to assess the
potential of sequential information of handwriting in identifying Parkinsonian
symptoms. One-dimensional convolutions are applied to raw sequences as well as
derived features; the resulting sequences are then fed to BiGRU layers to
achieve the final classification. The proposed method outperformed
state-of-the-art approaches on the PaHaW dataset and achieved competitive
results on the NewHandPD dataset.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:25:13 GMT""}]","2021-01-26"
"2101.09462","Luis Zuluaga","Rodolfo Quintero, David Bernal, Tam\'as Terlaky, and Luis F. Zuluaga","Characterization of QUBO reformulations for the maximum $k$-colorable
  subgraph problem",,,,,"quant-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum devices can be used to solve constrained combinatorial optimization
(COPT) problems thanks to the use of penalization methods to embed the COPT
problem's constraints in its objective to obtain a quadratic unconstrained
binary optimization (QUBO) reformulation of the COPT. However, the particular
way in which this penalization is carried out, affects the value of the penalty
parameters, as well as the number of additional binary variables that are
needed to obtain the desired QUBO reformulation. In turn, these factors
substantially affect the ability of quantum computers to efficiently solve
these constrained COPT problems. This efficiency is key towards the goal of
using quantum computers to solve constrained COPT problems more efficiently
than with classical computers. Along these lines, we consider an important
constrained COPT problem; namely, the maximum $k$-colorable subgraph (M$k$CS)
problem, in which the aim is to find an induced $k$-colorable subgraph with
maximum cardinality in a given graph. This problem arises in channel assignment
in spectrum sharing networks, VLSI design, human genetic research, and
cybersecurity. We derive two QUBO reformulations for the M$k$CS problem, and
fully characterize the range of the penalty parameters that can be used in the
QUBO reformulations. Further, one of the QUBO reformulations of the M$k$CS
problem is obtained without the need to introduce additional binary variables.
To illustrate the benefits of obtaining and characterizing these QUBO
reformulations, we benchmark different QUBO reformulations of the M$k$CS
problem by performing numerical tests on D-Wave's quantum annealing devices.
These tests also illustrate the numerical power gained by using the latest
D-Wave's quantum annealing device.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:28:33 GMT""}]","2021-01-26"
"2101.09463","Sebastian Wenderoth","Sebastian Wenderoth, Heinz-Peter Breuer, Michael Thoss","Non-Markovian effects in the spin-boson model at zero temperature","12 pages (incl. Supplemental Material), 7 figures","Phys. Rev. A 104, 012213 (2021)","10.1103/PhysRevA.104.012213",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate memory effects in the spin-boson model using a recently
proposed measure for non-Markovian behavior based on the information exchange
between an open system and its environment. Employing the numerical exact
multilayer multiconfguration time-dependent Hartree approach, we simulate the
dynamics of the spin-boson model at zero temperature for a broad range of
parameters. For a fast bath, i.e. in the scaling limit, we find non-Markovian
dynamics for a coherently decaying spin at weak system-bath coupling, whereas
memory effects are absent for stronger coupling in the regimes of incoherent
decay and localization. If the time scales of system and bath are comparable, a
complex, non-monotonic dependence of non-Markovianity on the system-bath
coupling strength is observed.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:39:22 GMT""}]","2021-07-28"
"2101.09464","Akanksha Nalhotra","Akanksha Malhotra and Sudhir Kamle","ARTH: Algorithm For Reading Text Handily -- An AI Aid for People having
  Word Processing Issues",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of this project is to solve one of the major problems faced by
the people having word processing issues like trauma, or mild mental
disability. ""ARTH"" is the short form of Algorithm for Reading Handily. ARTH is
a self-learning set of algorithms that is an intelligent way of fulfilling the
need for ""reading and understanding the text effortlessly"" which adjusts
according to the needs of every user. The research project propagates in two
steps. In the first step, the algorithm tries to identify the difficult words
present in the text based on two features -- the number of syllables and usage
frequency -- using a clustering algorithm. After the analysis of the clusters,
the algorithm labels these clusters, according to their difficulty level. In
the second step, the algorithm interacts with the user. It aims to test the
user's comprehensibility of the text and his/her vocabulary level by taking an
automatically generated quiz. The algorithm identifies the clusters which are
difficult for the user, based on the result of the analysis. The meaning of
perceived difficult words is displayed next to them. The technology ""ARTH""
focuses on the revival of the joy of reading among those people, who have a
poor vocabulary or any word processing issues.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:39:45 GMT""}]","2021-01-26"
"2101.09465","Lu Chen","Xingyu Chen, Zihan Zhao, Lu Chen, Danyang Zhang, Jiabao Ji, Ao Luo,
  Yuxuan Xiong, Kai Yu","WebSRC: A Dataset for Web-Based Structural Reading Comprehension","EMNLP 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Web search is an essential way for humans to obtain information, but it's
still a great challenge for machines to understand the contents of web pages.
In this paper, we introduce the task of structural reading comprehension (SRC)
on web. Given a web page and a question about it, the task is to find the
answer from the web page. This task requires a system not only to understand
the semantics of texts but also the structure of the web page. Moreover, we
proposed WebSRC, a novel Web-based Structural Reading Comprehension dataset.
WebSRC consists of 400K question-answer pairs, which are collected from 6.4K
web pages. Along with the QA pairs, corresponding HTML source code,
screenshots, and metadata are also provided in our dataset. Each question in
WebSRC requires a certain structural understanding of a web page to answer, and
the answer is either a text span on the web page or yes/no. We evaluate various
baselines on our dataset to show the difficulty of our task. We also
investigate the usefulness of structural information and visual features. Our
dataset and baselines have been publicly available at
https://x-lance.github.io/WebSRC/.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:43:44 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 08:31:44 GMT""}]","2021-11-09"
"2101.09466","Michele Buzzicotti","Michele Buzzicotti and Guillaume Tauzin","Inertial range statistics of the Entropic Lattice Boltzmann in 3D
  turbulence",,"Phys. Rev. E 104, 015302 (2021)","10.1103/PhysRevE.104.015302",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present a quantitative analysis of the inertial range statistics produced
by Entropic Lattice Boltzmann Method (ELBM) in the context of 3d homogeneous
and isotropic turbulence. ELBM is a promising mesoscopic model particularly
interesting for the study of fully developed turbulent flows because of its
intrinsic scalability and its unconditional stability. In the hydrodynamic
limit, the ELBM is equivalent to the Navier-Stokes equations with an extra eddy
viscosity term [1]. From this macroscopic formulation, we have derived a new
hydrodynamical model that can be implemented as a Large-Eddy Simulation (LES)
closure. This model is not positive definite, hence, able to reproduce
backscatter events of energy transferred from the subgrid to the resolved
scales. A statistical comparison of both mesoscopic and macroscopic entropic
models based on the ELBM approach is presented and validated against fully
resolved Direct Numerical Simulations (DNS). Besides, we provide a second
comparison of the ELBM with respect to the well known Smagorinsky closure. We
found that ELBM is able to extend the energy spectrum scaling range preserving
at the same time the simulation stability. Concerning the statistics of higher
order, inertial range observables, ELBM accuracy is shown to be comparable with
other approaches such as Smagorinsky model.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:45:10 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 14:59:54 GMT""}]","2021-07-14"
"2101.09467","Vladimir Nazarov","Vladimir U. Nazarov, Roi Baer","High frequency limit of spectroscopy","17 pages, 10 figures","the Journal of Chemical Physics 157, 084112 (2022)","10.1063/5.0100317",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We consider an arbitrary quantum mechanical system, initially in its
ground-state, exposed to a time-dependent electromagnetic pulse with a carrier
frequency $\omega_0$ and a slowly varying envelope of finite duration. By
working out a solution to the time-dependent Schr\""odinger equation in the
high-$\omega_0$ limit, we find that, to the leading order in $\omega_0^{-1}$, a
perfect self-cancellation of the system's linear response occurs as the pulse
switches off. Surprisingly, the system's observables are, nonetheless,
describable in terms of a combination of its linear density response function
and nonlinear functions of the electric field. An analysis of jellium slab and
jellium sphere models reveals a very high surface sensitivity of the considered
setup, producing a richer excitation spectrum than accessible within the
conventional linear response regime. On this basis, we propose a new
spectroscopic technique, which we provisionally name the Nonlinear
High-Frequency Pulsed Spectroscopy (NLHFPS). Combining the advantages of the
extraordinary surface sensitivity, the absence of constraints by the
traditional dipole selection rules, and the clarity of theoretical
interpretation utilizing the linear response time-dependent density functional
theory, NLHFPS has a potential to evolve into a powerful characterization
method for nanoscience and nanotechnology.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:45:11 GMT""},{""version"":""v2"",""created"":""Sun, 14 Nov 2021 08:15:22 GMT""},{""version"":""v3"",""created"":""Thu, 4 Aug 2022 16:46:19 GMT""}]","2022-08-25"
"2101.09468","Dorota Strozik-Kotlorz","A. Kotlorz, D. Kotlorz and O. V. Teryaev","Evaluation of the Gottfried sum with use of the truncated moments method","15 pages, 6 figures (11 eps plots)",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We reanalyze the experimental NMC data on the nonsinglet structure function
$F_2^p-F_2^n$ and E866 data on the nucleon sea asymmetry $\bar{d}/\bar{u}$
using the truncated moments approach elaborated in our previous papers. With
help of the special truncated sum one can overcome the problem of the
unavoidable experimental restrictions on the Bjorken $x$ and effectively study
the fundamental sum rules for the parton distributions and structure functions.
Using only the data from the measured region of $x$, we obtain the Gottfried
sum $\int_0^1 F_2^{ns}/x\, dx$ and the integrated nucleon sea asymmetry
$\int_0^1 (\bar{d}-\bar{u})\, dx$. We compare our results with the reported
experimental values and with the predictions obtained for different global
parametrizations for the parton distributions. We also discuss the discrepancy
between the NMC and E866 results on $\int_0^1 (\bar{d}-\bar{u})\, dx$. We
demonstrate that this discrepancy can be resolved by taking into account the
higher-twist effects.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:56:35 GMT""}]","2021-01-26"
"2101.09469","Victor Junqiu Wei","Junqiu Wei, Qun Liu, Yinpeng Guo, Xin Jiang","Training Multilingual Pre-trained Language Model with Byte-level
  Subwords",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pre-trained language models have achieved great successes in various
natural language understanding (NLU) tasks due to its capacity to capture the
deep contextualized information in text by pre-training on large-scale corpora.
One of the fundamental components in pre-trained language models is the
vocabulary, especially for training multilingual models on many different
languages. In the technical report, we present our practices on training
multilingual pre-trained language models with BBPE: Byte-Level BPE (i.e., Byte
Pair Encoding). In the experiment, we adopted the architecture of NEZHA as the
underlying pre-trained language model and the results show that NEZHA trained
with byte-level subwords consistently outperforms Google multilingual BERT and
vanilla NEZHA by a notable margin in several multilingual NLU tasks. We release
the source code of our byte-level vocabulary building tools and the
multilingual pre-trained language models.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:01:28 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 14:37:37 GMT""}]","2021-06-04"
"2101.09470","Ufuk Soylu","Ufuk Soylu, Yoram Bresler","Circumventing the resolution-time tradeoff in Ultrasound Localization
  Microscopy by Velocity Filtering","17 pages, 16 figures",,,,"eess.SP eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrasound Localization Microscopy (ULM) offers a cost-effective modality for
microvascular imaging by using intravascular contrast agents (microbubbles).
However, ULM has a fundamental trade-off between acquisition time and spatial
resolution, which makes clinical translation challenging. In this paper, in
order to circumvent the trade-off, we introduce a spatiotemporal filtering
operation dubbed velocity filtering, which is capable of separating contrast
agents into different groups based on their vector velocities thus reducing
interference in the localization step, while simultaneously offering blood
velocity mapping at super resolution, without tracking individual microbubbles.
As side benefit, the velocity filter provides noise suppression before
microbubble localization that could enable substantially increased penetration
depth in tissue typically by 4cm or more. We provide a theoretical analysis of
the performance of velocity filter. Numerical experiments confirm that the
proposed velocity filter is able to separate the microbubbles with respect to
the speed and direction of their motion. In combination with subsequent
localization of microbubble centers, e.g. by matched filtering, the velocity
filter improves the quality of the reconstructed vasculature significantly and
provides blood flow information. Overall, the proposed imaging pipeline in this
paper enables the use of higher concentrations of microbubbles while preserving
spatial resolution, thus helping circumvent the trade-off between acquisition
time and spatial resolution. Conveniently, because the velocity filtering
operation can be implemented by fast Fourier transforms(FFTs) it admits fast,
and potentially real-time realization. We believe that the proposed velocity
filtering method has the potential to pave the way to clinical translation of
ULM.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:14:11 GMT""}]","2021-01-26"
"2101.09471","Zoltan Buczolich","Zolt\'an Buczolich, Bruce Hanson, Bal\'azs Maga, and G\'asp\'ar
  V\'ertesy","Strong one-sided density without uniform density","Revised version after referee's report. Period Math Hung (2022)",,"10.1007/s10998-022-00455-9",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give an example of a closed, strongly one-sided dense set
which is not of uniform density type. We also show that there is a set of
uniform density type which is not of strong uniform density type.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:17:55 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 08:36:25 GMT""}]","2022-08-26"
"2101.09472","Giovanni Scilla","Christopher Goodrich and Giovanni Scilla and Bianca Stroffolini","Partial regularity for minimizers of discontinuous quasiconvex integrals
  with general growth",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the partial H\""older continuity for minimizers of quasiconvex
functionals \[ \mathcal{F}({\bf u}) \colon =\int_{\Omega} f(x,{\bf u},D{\bf
u})\,\mathrm{d}x, \] where $f$ satisfies a uniform VMO condition with respect
to the $x$-variable and is continuous with respect to ${\bf u}$. The growth
condition with respect to the gradient variable is assumed a general one.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:23:11 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jan 2021 17:16:34 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 13:45:29 GMT""}]","2021-08-27"
"2101.09473","Ahmed Jellal","Nadia Benlakhouy, Abderrahim El Mouhafid, Ahmed Jellal","Transport Properties in Gapped Bilayer Graphene","9 pages, 2 column, 7 figures",,"10.1016/j.physe.2021.114835",,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate transport properties through a rectangular potential barrier
in AB-stacked bilayer graphene (AB-BLG) gapped by dielectric layers. Using the
Dirac-like Hamiltonian with a transfer matrix approach we obtain transmission
and reflection probabilities as well as the associated conductance. For
two-band model and at normal incidence, we find extra resonances appearing in
transmission compared to biased AB-BLG, which are Fabry-P\'erot resonance type.
Now by taking into account the inter-layer bias, we show that both of
transmission and anti-Klein tunneling are diminished. Regarding four band
model, we find that the gap suppresses transmission in an energy range by
showing some behaviors look like ""Mexican hats"". We examine the total
conductance and show that it is affected by the gap compared to AA-stacked
bilayer graphene. In addition, we find that the suppression in conductance is
more important than that for biased AB-BLG.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:24:51 GMT""}]","2021-06-30"
"2101.09474","Viswanatha V","Viswanatha V, Venkata Siva Reddy R","Microcontroller based bidirectional buck boost converter for photo
  voltaic power plant",,"https://www.sciencedirect.com/science/article/pii/S231471721730017X -2018","10.1016/j.jesit.2017.04.002",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  A common configuration for a stand-alone PV power system may consist of three
converters: a buck converter for the PV panelto charge the battery, a boost
converter for the battery to discharge to the load and one for the load voltage
regulation. Such a systemrequires a coordinated control scheme for three
converters which can be complicated. A simple structure for a stand-alone PV
plantconsists of a PV array, a battery unit, and its associated bidirectional
converter which is a combination of a buck and boost converter.When controlled
properly the system can provide uninterrupted power to the load, despite the
intermittent availability of sunlight. Inthis paper complete design of the
converter is carried out and the simulation has been performed using Psim. From
the simulation,the graphs are presented to show the converter working in buck
mode and boost mode. Controller is designed to take care of modetransition,
buck to boost and boost to buck mode automatically based on source voltage.
Hardware implementation has been doneusing microcontroller (8051).
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:34:29 GMT""}]","2021-01-26"
"2101.09475","Jorge Campos-Gonzalez-Angulo","Jorge A. Campos-Gonzalez-Angulo, Raphael F. Ribeiro, Joel Yuen-Zhou","Generalization of the Tavis-Cummings model for multi-level anharmonic
  systems","37 pages, 4 figures",,"10.1088/1367-2630/ac00d7",,"physics.optics physics.chem-ph quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The interaction between anharmonic quantum emitters (e.g., molecular
vibrations) and confined electromagnetic fields gives rise to quantum states
with optical and chemical properties that are different from those of their
precursors. The exploration of these properties has been typically constrained
to the first excitation manifold, the harmonic approximation, ensembles of
two-level systems [Tavis-Cummings (TC) model], or the anharmonic
single-molecule case. The present work studies, for the first time, a
collective ensemble of identical multi-level anharmonic emitters and their
dipolar interaction with a photonic cavity mode. The permutational properties
of the system allow identifying symmetry classified submanifolds in the energy
spectrum. Notably, in this approach, the number of particles, typically in the
order of several millions, becomes only a parameter from the operational
standpoint, and the size of the dimension of the matrices to diagonalize is
independent of it. The formalism capabilities are illustrated by showing the
energy spectrum structure, up to the third excitation manifold, and the
calculation of the photon contents as a permutationally invariant quantity.
Emphasis is placed on (a) the collective (superradiant) scalings of
light-matter couplings and the various submanifolds of dark (subradiant) states
with no counterpart in the single-molecule case, as well as (b) the delocalized
modes containing more than one excitation per molecule with no equivalent in
the TC model. We expect these findings to be applicable in the study of
non-linear spectroscopy and chemistry of polaritons.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:40:00 GMT""}]","2021-08-11"
"2101.09476","Margaret Reid","M. D. Reid and M. Thenabadu","Weak versus deterministic macroscopic realism",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We construct a mapping of Bell and bipartite Leggett-Garg experiments for
microscopic qubits onto a gedanken experiment for macroscopic qubits based on
two macroscopically distinct coherent states. This provides an unusual
situation where the dichotomic measurements (and associated hidden variables)
involved in the Bell tests need only discriminate between two macroscopically
distinct states of a system i.e. correspond to coarse-grained measurements that
do not specify values to a level of precision of order $\sim\hbar$. Violations
of macro-realism and macroscopic local realism are predicted. We show how one
may obtain consistency with a weak form of macroscopic realism (wMR): that for
a system prepared in a superposition of macroscopically distinct pointer
eigenstates, the outcome of the coarse-grained pointer measurement $\hat{M}$ is
predetermined. Macroscopic realism does not however hold in a deterministic
fashion, where one assumes the predetermination of outcomes prior to the
unitary rotations that define the choice of measurement setting in the Bell
experiment. We illustrate an analogy with the Einstein-Podolsky-Rosen (EPR)
argument, showing how wMR can be regarded as inconsistent with the completeness
of quantum mechanics.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:44:01 GMT""}]","2021-01-26"
"2101.09477","Dushyant Behl","Dushyant Behl, Palanivel Kodeswaran, Venkatraman Ramakrishna,
  Sayandeep Sen, Dhinakaran Vinayagamurthy","Trusted Data Notifications from Private Blockchains","9 pages","IEEE International Conference on Blockchain, Blockchain 2020,
  Rhodes Island, Greece, November 2-6, 2020, pages {53--61}","10.1109/Blockchain50366.2020.00015",,"cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Private blockchain networks are used by enterprises to manage decentralized
processes without trusted mediators and without exposing their assets publicly
on an open network like Ethereum. Yet external parties that cannot join such
networks may have a compelling need to be informed about certain data items on
their shared ledgers along with certifications of data authenticity; e.g., a
mortgage bank may need to know about the sale of a mortgaged property from a
network managing property deeds. These parties are willing to compensate the
networks in exchange for privately sharing information with proof of
authenticity and authorization for external use. We have devised a novel and
cryptographically secure protocol to effect a fair exchange between rational
network members and information recipients using a public blockchain and atomic
swap techniques. Using our protocol, any member of a private blockchain can
atomically reveal private blockchain data with proofs in exchange for a
monetary reward to an external party if and only if the external party is a
valid recipient. The protocol preserves confidentiality of data for the
recipient, and in addition, allows it to mount a challenge if the data turns
out to be inauthentic. We also formally analyze the security and privacy of
this protocol, which can be used in a wide array of practical scenarios
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:45:52 GMT""}]","2021-01-26"
"2101.09478","Tingge Gao","Yao Li, Xuekai Ma, Zaharias Hatzopoulos, Pavlos Savvidis, Stefan
  Schumacher and Tingge Gao","Switching off microcavity polariton condensate near the exceptional
  point",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Gain and loss modulation are ubiquitous in nature. An exceptional point
arises when both the eigenvectors and eigenvalues coalesce, which in a physical
system can be achieved by engineering the gain and loss coefficients, leading
to a wide variety of counter-intuitive phenomena. In this work we demonstrate
the existence of an exceptional point in an exciton polariton condensate in a
double-well potential. Remarkably, near the exceptional point, the polariton
condensate localized in one potential well can be switched off by an additional
optical excitation in the other well with very low (far below threshold) laser
power which surprisingly induces additional loss into the system. Increasing
the power of the additional laser leads to a situation in which gain dominates
in both wells again, such that the polaritons re-condense with almost the same
density in the two potential wells. Our results offer a simple way to optically
manipulate the polariton lasing process in a double-well potential structure.
Extending such configuration to complex potential well lattices offers exciting
prospects to explore high-order exceptional points and non-Hermitian
topological photonics in a non-equilibrium many-body system.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:49:22 GMT""}]","2021-01-26"
"2101.09479","Long Chen","Taushif Ahmed, Long Chen and Micha{\l} Czakon","Renormalization of the flavor-singlet axial-vector current and its
  anomaly in dimensional regularization","23 pages, 4 figures and 1 table, references updated, matched with the
  published version in JHEP",,"10.1007/JHEP05(2021)087","TTK-21-04, P3H-21-004","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  The renormalization constant $Z_J$ of the flavor-singlet axial-vector current
with a non-anticommuting $\gamma_5$ in dimensional regularization is determined
to order $\alpha_s^3$ in QCD with massless quarks. The result is obtained by
computing the matrix elements of the operators appearing in the axial-anomaly
equation $\big[\partial_{\mu} J^{\mu}_{5} \big]_{R} = \frac{\alpha_s}{4 \pi}\,
n_f\, {\displaystyle \mathrm{T}_{F}} \, \big[F \tilde{F} \big]_{R}$ between the
vacuum and a state of two (off-shell) gluons to 4-loop order. Furthermore,
through this computation, the conjectured equality between the
$\overline{\mathrm{MS}}$ renormalization constant $Z_{F\tilde{F}}$ associated
with the operator $\big[F \tilde{F} \big]_{R}$ and that of $\alpha_s$ is
verified explicitly to hold true at 4-loop order. This equality automatically
ensures a relation between the respective anomalous dimensions,
$\gamma_{{\scriptscriptstyle J}} = \frac{\alpha_s}{4 \pi}\, n_f\,
{\displaystyle \mathrm{T}_{F}} \, \gamma_{{\scriptscriptstyle FJ}} $, at order
$\alpha_s^4$ given the validity of the axial-anomaly equation which was used to
determine the non-$\overline{\mathrm{MS}}$ piece of $Z_J$ for the particular
$\gamma_5$ prescription in use.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:53:54 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 12:13:50 GMT""}]","2021-06-02"
"2101.09480","Maria Jose Pacifico","Maria Jos\'e Pacifico, Fan Yang and Jiagang Yang","An entropy dichotomy for singular star flows","24 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1901.07436",,,,"math.DS","http://creativecommons.org/publicdomain/zero/1.0/","  We show that non-trivial chain recurrent classes for generic $C^1$ star flows
satisfy a dichotomy: either they have zero topological entropy, or they must be
isolated. Moreover, chain recurrent classes for generic star flows with zero
entropy must be sectional hyperbolic, and cannot be detected by any non-trivial
ergodic invariant probability. As a result, we show that $C^1$ generic star
flows have only finitely many Lyapunov stable chain recurrent classes.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 10:54:14 GMT""}]","2021-01-26"
"2101.09481","Daria Holik","Daria Holik, Marek Kara\'s","Dependence of Homogeneous Components of Polynomials with Small Degree of
  Poisson Bracket",,,,,"math.AC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let F,G in C[x_1,...,x_n] be two polynomials in n variables x_1,...,x_n over
the complex numbers field C. In this paper, we prove that if the degree of the
Poisson bracket [F,G] is small enough then there are strict constraints for
homogeneous components of these polynomials. We also prove that there is a
relationship between the homogeneous components of the polynomial F of degrees
deg(F)-1 and deg(F)-2 as well some results about divisibility of the
homogeneous component of degree deg(F)-1.
  Moreover we propose, possibly an appropriate, reformulation of the conjecture
of Yu regarding the estimation of the Poisson bracket degree of two
polynomials.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:01:43 GMT""}]","2021-01-26"
"2101.09482","Panpan Ren","Panpan Ren and Shen Wang","Moderate Deviation Principles for Unbounded Additive Functionals of
  Distribution Dependent SDEs","16 pages",,,,"math.PR","http://creativecommons.org/publicdomain/zero/1.0/","  By comparing the original equations with the corresponding stationary ones,
the moderate deviation principle (MDP) is established for unbounded additive
functionals of several different models of distribution dependent SDEs, with
non-degenerate and degenerate noises.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:10:46 GMT""}]","2021-01-26"
"2101.09483","Yao Guo Dr.","Mengmeng Bai, Yanqing Zhao, Shuting Xu, Yao Guo","Origin of Robust Rectification in Geometric Diodes",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometric diodes, which take advantage of geometric asymmetry to achieve
current flow preference, are promising for THz current rectification. Previous
studies relate geometric diodes' rectification to quantum coherent or ballistic
transport, which is fragile and critical of the high-quality transport system.
Here we propose a different physical picture and demonstrate a robust current
rectification originating from the asymmetric bias induced barrier lowering,
which generally applies to common semiconductors in normal environments. Key
factors to the diode's performance are carefully analyzed, and an intrinsic
rectification ability at up to 1.1 THz is demonstrated.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:18:18 GMT""}]","2021-01-26"
"2101.09484","Tomasz Brzezinski","Ryszard R. Adruszkiewicz, Tomasz Brzezi\'nski and Bernard
  Rybo{\l}owicz","Ideal ring extensions and trusses","42 pages",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that there is a close relationship between ideal extensions of
rings and trusses, that is, sets with a semigroup operation distributing over a
ternary abelian heap operation. Specifically, a truss can be associated to
every element of an extension ring that projects down to an idempotent in the
extending ring; every weak equivalence of extensions yields an isomorphism of
corresponding trusses. Furthermore, equivalence classes of ideal extensions of
rings by integers are in one-to-one correspondence with associated trusses up
to isomorphism given by a translation. Conversely, to any truss $T$ and an
element of this truss one can associate a ring and its extension by integers in
which $T$ is embedded as a truss. Consequently any truss can be understood as
arising from an ideal extension by integers. The key role is played by
interpretation of ideal extensions by integers as extensions defined by double
homothetisms of Redei [L.\ Redei, Die Verallgemeinerung der Schreierschen
Erweiterungstheorie, {\em Acta Sci.\ Math.\ Szeged}, {\bf 14} (1952), 252--273]
or by self-permutable bimultiplications of Mac Lane [S.\ Mac Lane, Extensions
and obstructions for rings, {\em Illinois J.\ Math.} {\bf 2} (1958), 316--345],
that is, as {\em integral homothetic extensions}. It is shown that integral
homothetic extensions of trusses are universal as extensions of trusses to
rings but still enjoy a particular smallness property: they do not contain any
subrings to which the truss inclusion map corestricts. Minimal extensions of
trusses into rings are defined. The correspondence between homothetic ring
extensions and trusses is used to classify fully up to isomorphism trusses
arising from rings with zero multiplication and rings with trivial
annihilators.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:18:21 GMT""}]","2021-01-26"
"2101.09485","Yifeng Liu","Chao Li, Yifeng Liu","Chow groups and $L$-derivatives of automorphic motives for unitary
  groups, II","v2: 70 pages; revised in accordance with [LL]. arXiv admin note: text
  overlap with arXiv:2006.06139",,,,"math.NT math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we improve our main results from \emph{Chow groups and
$L$-derivatives of automorphic motives for unitary groups} in two direction:
First, we allow ramified places in the CM extension $E/F$ at which we consider
representations that are spherical with respect to a certain special maximal
compact subgroup, by formulating and proving an analogue of the Kudla--Rapoport
conjecture for exotic smooth Rapoport--Zink spaces. Second, we lift the
restriction on the components at split places of the automorphic
representation, by proving a more general vanishing result on certain
cohomology of integral models of unitary Shimura varieties with Drinfeld level
structures.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:22:36 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 02:23:21 GMT""}]","2021-04-13"
"2101.09486","Siyuan Chen","Siyuan Chen and Jiahai Wang and Guoqing Li","Neural Relational Inference with Efficient Message Passing Mechanisms","Accepted by AAAI 2021, 13 pages, 9 figures, 4 tables",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Many complex processes can be viewed as dynamical systems of interacting
agents. In many cases, only the state sequences of individual agents are
observed, while the interacting relations and the dynamical rules are unknown.
The neural relational inference (NRI) model adopts graph neural networks that
pass messages over a latent graph to jointly learn the relations and the
dynamics based on the observed data. However, NRI infers the relations
independently and suffers from error accumulation in multi-step prediction at
dynamics learning procedure. Besides, relation reconstruction without prior
knowledge becomes more difficult in more complex systems. This paper introduces
efficient message passing mechanisms to the graph neural networks with
structural prior knowledge to address these problems. A relation interaction
mechanism is proposed to capture the coexistence of all relations, and a
spatio-temporal message passing mechanism is proposed to use historical
information to alleviate error accumulation. Additionally, the structural prior
knowledge, symmetry as a special case, is introduced for better relation
prediction in more complex systems. The experimental results on simulated
physics systems show that the proposed method outperforms existing
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:27:31 GMT""}]","2021-01-26"
"2101.09487","Yao Guo Dr.","Yan Sun, Alvin Tang, Ching-Hua Wang, Yanqing Zhao, Mengmeng Bai,
  Shuting Xu, Zheqi Xu, Tao Tang, Sheng Wang, Chenguang Qiu, Kang Xu, Xubiao
  Peng, Junfeng Han, Eric Pop, and Yang Chai, Yao Guo","Field-effect at electrical contacts to two-dimensional materials",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inferior electrical contact to two-dimensional (2D) materials is a
critical challenge for their application in post-silicon very large-scale
integrated circuits. Electrical contacts were generally related to their
resistive effect, quantified as contact resistance. With a systematic
investigation, this work demonstrates a capacitive
metal-insulator-semiconductor (MIS) field-effect at the electrical contacts to
2D materials: the field-effect depletes or accumulates charge carriers,
redistributes the voltage potential, and give rise to abnormal current
saturation and nonlinearity. On the one hand, the current saturation hinders
the devices' driving ability, which can be eliminated with carefully engineered
contact configurations. On the other hand, by introducing the nonlinearity to
monolithic analog artificial neural network circuits, the circuits' perception
ability can be significantly enhanced, as evidenced using a COVID-19 critical
illness prediction model. This work provides a comprehension of the
field-effect at the electrical contacts to 2D materials, which is fundamental
to the design, simulation, and fabrication of electronics based on 2D material.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:27:40 GMT""}]","2021-01-26"
"2101.09488","Vadim Ksenzov","V.G. Ksenzov","Chiral Condensate in Two Dimensional Models","10 pages, 4 figures",,,,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We investigate two different models. In one of them massive fermions interact
with a massive scalar field and in the other the fermion field is in an
electrical field (QED2). The chiral condensates are calculated in one-loop
approximation. We found that the chiral condensate in the case of the Yukawa
interaction the fermions and scalar field does not vanish if the mass of the
fermion field tends to zero. The chiral condensate disappears in QED2, if the
fermion mass is zero.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:38:41 GMT""}]","2021-01-26"
"2101.09489","Philip Lightfoot Prof","Philip Lightfoot and Jason A. McNulty","Structural Chemistry of Layered Lead Halide Perovskites Containing
  Single Octahedral Layers","62 pages, 20 figures, 5 tables",,,,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a comprehensive review of the structural chemistry of hybrid lead
halides of stoichiometry APbX4, A2PbX4 or AAPbX4, where A and A are organic
ammonium cations and X = Cl, Br or I. These compounds may be considered as
layered perovskites, containing isolated, infinite layers of corner-sharing
PbX4 octahedra separated by the organic species. We first extract over 250
crystal structures from the CCDC and classify them in terms of unit cell
metrics and crystal symmetry. Symmetry mode analysis is then used to identify
the nature of key structural distortions of the [PbX4] layers. Two generic
types of distortion are prevalent in this family: tilting of the octahedral
units and shifts of the inorganic layers relative to each other. Although the
octahedral tilting modes are well-known in the crystallography of purely
inorganic perovskites, the additional layer shift modes are shown to enrich
enormously the structural options available in layered hybrid perovskites. Some
examples and trends are discussed in more detail in order to show how the
nature of the interlayer organic species can influence the overall structural
architecture, although the main aim of the paper is to encourage workers in the
field to make use of the systematic crystallographic methods used here to
further understand and rationalise their own compounds, and perhaps to be able
to design-in particular structural features in future work.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:40:47 GMT""}]","2021-01-26"
"2101.09490","Jean Cleymans","J. Cleymans and M. W. Paradza","Tsallis Statistics in High Energy Physics: Chemical and Thermal
  Freeze-Outs","12 pages, 6 figures","MDPI Physics 2, 654-664 (2020)",,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present an overview of a proposal in relativistic proton-proton ($pp$)
collisions emphasizing the thermal or kinetic freeze-out stage in the framework
of the Tsallis distribution. In this paper we take into account the chemical
potential present in the Tsallis distribution by following a two step
procedure. In the first step we used the redundancy present in the variables
such as the system temperature, $T$, volume, $V$, Tsallis exponent, $q$,
chemical potential, $\mu$, and performed all fits by effectively setting to
zero the chemical potential. In the second step the value $q$ is kept fixed at
the value determined in the first step. This way the complete set of variables
$T, q, V$ and $\mu$ can be determined. The final results show a weak energy
dependence in $pp$ collisions at the centre-of-mass energy $\sqrt{s}= 6$ GeV to
13 TeV. The chemical potential $\mu$ at kinetic freeze-out shows an increase
with beam energy. This simplifies the description of the thermal freeze-out
stage in $pp$ collisions as the values of $T$ and of the freeze-out radius $R$
vary only mildly over a wide range of beam energies.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:45:14 GMT""}]","2021-01-26"
"2101.09491","Daniel Mitchell MEng","Daniel Mitchell, Jamie Blanche, Osama Zaki, Joshua Roe, Leo Kong,
  Samuel Harper, Valentin Robu, Theodore Lim, David Flynn","Symbiotic System of Systems Design for Safe and Resilient Autonomous
  Robotics in Offshore Wind Farms","A preprint submit to IEEE Access Reliability Society Section",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  To reduce Operation and Maintenance (O&M) costs on offshore wind farms,
wherein 80% of the O&M cost relates to deploying personnel, the offshore wind
sector looks to Robotics and Artificial Intelligence (RAI) for solutions.
Barriers to Beyond Visual Line of Sight (BVLOS) robotics include operational
safety compliance and resilience, inhibiting the commercialization of
autonomous services offshore. To address safety and resilience challenges we
propose a Symbiotic System Of Systems Approach (SSOSA), reflecting the
lifecycle learning and co-evolution with knowledge sharing for mutual gain of
robotic platforms and remote human operators. Our novel methodology enables the
run-time verification of safety, reliability and resilience during autonomous
missions. To achieve this, a Symbiotic Digital Architecture (SDA) was developed
to synchronize digital models of the robot, environment, infrastructure, and
integrate front-end analytics and bidirectional communication for autonomous
adaptive mission planning and situation reporting to a remote operator. A
reliability ontology for the deployed robot, based on our holistic
hierarchical-relational model, supports computationally efficient platform data
analysis. We demonstrate an asset inspection mission within a confined space
through Cooperative, Collaborative and Corroborative (C3) governance (internal
and external symbiosis) via decision-making processes and the associated
structures. We create a hyper enabled human interaction capability to analyze
the mission status, diagnostics of critical sub-systems within the robot to
provide automatic updates to our AI-driven run-time reliability ontology. This
enables faults to be translated into failure modes for decision-making during
the mission.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 11:58:16 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 16:40:27 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 15:01:55 GMT""}]","2021-07-23"
"2101.09492","Xuecan Yang","Xuecan Yang, Sumanta Chaudhuri, Laurence Likforman, Lirida Naviner","MinConvNets: A new class of multiplication-less Neural Networks",,,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional Neural Networks have achieved unprecedented success in image
classification, recognition, or detection applications. However, their
large-scale deployment in embedded devices is still limited by the huge
computational requirements, i.e., millions of MAC operations per layer. In this
article, MinConvNets where the multiplications in the forward propagation are
approximated by minimum comparator operations are introduced. Hardware
implementation of minimum operation is much simpler than multipliers. Firstly,
a methodology to find approximate operations based on statistical correlation
is presented. We show that it is possible to replace multipliers by minimum
operations in the forward propagation under certain constraints, i.e. given
similar mean and variances of the feature and the weight vectors. A modified
training method which guarantees the above constraints is proposed. And it is
shown that equivalent precision can be achieved during inference with
MinConvNets by using transfer learning from well trained exact CNNs.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:18:52 GMT""}]","2021-01-26"
"2101.09493","Reza Parvaz","Reza Parvaz","A new type of 4D Hybrid Chaos Systems",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper a new type of chaotic system based on sin and logistic systems
is introduced. Also the behavior of this new system is studied by using various
tests. The results of these tests indicate the appropriate behavior for the
proposed new system.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:39:53 GMT""}]","2021-01-26"
"2101.09494","Omar Khadir","Leila Zahhafi and Omar Khadir","A DSA-like digital signature protocol",,"JDMSC, 2020",,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper we propose a new digital signature protocol inspired by the DSA
algorithm. The security and the complexity are analyzed. Our method constitutes
an alternative if the classical scheme DSA is broken.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:48:34 GMT""}]","2021-01-26"
"2101.09495","Can Gao","Can Gao, Jie Zhoua, Duoqian Miao, Xiaodong Yue, Jun Wan","Granular conditional entropy-based attribute reduction for partially
  labeled data with proxy labels","22 pages, 5 figures, and 5 tables. Preprint submitted to Information
  Sciences",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Attribute reduction is one of the most important research topics in the
theory of rough sets, and many rough sets-based attribute reduction methods
have thus been presented. However, most of them are specifically designed for
dealing with either labeled data or unlabeled data, while many real-world
applications come in the form of partial supervision. In this paper, we propose
a rough sets-based semi-supervised attribute reduction method for partially
labeled data. Particularly, with the aid of prior class distribution
information about data, we first develop a simple yet effective strategy to
produce the proxy labels for unlabeled data. Then the concept of information
granularity is integrated into the information-theoretic measure, based on
which, a novel granular conditional entropy measure is proposed, and its
monotonicity is proved in theory. Furthermore, a fast heuristic algorithm is
provided to generate the optimal reduct of partially labeled data, which could
accelerate the process of attribute reduction by removing irrelevant examples
and excluding redundant attributes simultaneously. Extensive experiments
conducted on UCI data sets demonstrate that the proposed semi-supervised
attribute reduction method is promising and even compares favourably with the
supervised methods on labeled data and unlabeled data with true labels in terms
of classification performance.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:50:09 GMT""}]","2021-01-26"
"2101.09496","Ozlem Dagli","Ozlem Dagli, A. Gunes Tanir, Gokhan Kurt","Analysis Of Radiation Dose Distribution Inhomogenity Effects In Gamma
  Knife Radiosurgery Using Geant4",,,"10.2339/politeknik.674718",,"physics.med-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The Monte Carlo method is widely used in the Gamma Knife dose distribution
calculations. In this study, Monte-Carlo simulation with Geant4 was applied to
determine Leksell Gamma Knife dose distribution for homogeneous solid water and
heterogeneous brain phantoms, and primarily focused on the differences arising
from the effects of inhomogeneity. The relative dose graphs were displayed for
different collimator diameters. The dose values from the maximal interval
regions were determined and compared. It seen that when the collimator size was
4mm, the mean maximum relative dose point was at 47mm for water phantom and at
44mm for the brain. The difference found was about 6.38%. The differences among
the results determined for water and brain were ranged from 2 to 17%. As a
result, the inhomogeneity effect should be considered in dose calculation in
Gamma Knife planning system.
  Keywords: Radiosurgery, Gamma Knife, {\gamma}-Rays, Inhomogeneity, Brain
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:03:19 GMT""}]","2021-01-26"
"2101.09497","Antonio M. Moro","M. G\'omez Ramos, J. G\'omez-Camacho, Jin Lei, A. M. Moro","The Hussein-McVoy formula for inclusive breakup revisited. A Tribute to
  Mahir Hussein","To be published in EPJA in the special issue ""Cluster Structure and
  Dynamics of Nuclei - A Tribute to Mahir Hussein""",,,,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  In 1985, Hussein and McVoy [Nuc. Phys. A445 (1985) 124] elucidated a formula
for the evaluation of the nonelastic breakup (""stripping"") contribution in
inclusive breakup reactions. The formula, based on the spectator core model,
acquires a particularly simple and appealing form in the eikonal limit, to the
extent that it has become the standard procedure to analyze single-nucleon
knockout reactions at intermediate energies. In this contribution, a critical
assessment of this formula is presented and its connection with other,
noneikonal expressions discussed. Some calculations comparing the different
formulae are also presented for the one-nucleon removal of $^{14}$O+$^{9}$Be
reaction at several incident energies.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:05:34 GMT""}]","2021-01-26"
"2101.09498","Danding Wang","Danding Wang, Wencan Zhang and Brian Y. Lim","Show or Suppress? Managing Input Uncertainty in Machine Learning Model
  Explanations","to be published in Artificial Intelligence Special Issue on
  Explainable Artificial Intelligence",,,,"cs.LG cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature attribution is widely used in interpretable machine learning to
explain how influential each measured input feature value is for an output
inference. However, measurements can be uncertain, and it is unclear how the
awareness of input uncertainty can affect the trust in explanations. We propose
and study two approaches to help users to manage their perception of
uncertainty in a model explanation: 1) transparently show uncertainty in
feature attributions to allow users to reflect on, and 2) suppress attribution
to features with uncertain measurements and shift attribution to other features
by regularizing with an uncertainty penalty. Through simulation experiments,
qualitative interviews, and quantitative user evaluations, we identified the
benefits of moderately suppressing attribution uncertainty, and concerns
regarding showing attribution uncertainty. This work adds to the understanding
of handling and communicating uncertainty for model interpretability.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:10:48 GMT""}]","2021-01-26"
"2101.09499","Yizhao Gao","Yizhao Gao, Nanyi Fei, Guangzhen Liu, Zhiwu Lu, Tao Xiang, Songfang
  Huang","Contrastive Prototype Learning with Augmented Embeddings for Few-Shot
  Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most recent few-shot learning (FSL) methods are based on meta-learning with
episodic training. In each meta-training episode, a discriminative feature
embedding and/or classifier are first constructed from a support set in an
inner loop, and then evaluated in an outer loop using a query set for model
updating. This query set sample centered learning objective is however
intrinsically limited in addressing the lack of training data problem in the
support set. In this paper, a novel contrastive prototype learning with
augmented embeddings (CPLAE) model is proposed to overcome this limitation.
First, data augmentations are introduced to both the support and query sets
with each sample now being represented as an augmented embedding (AE) composed
of concatenated embeddings of both the original and augmented versions. Second,
a novel support set class prototype centered contrastive loss is proposed for
contrastive prototype learning (CPL). With a class prototype as an anchor, CPL
aims to pull the query samples of the same class closer and those of different
classes further away. This support set sample centered loss is highly
complementary to the existing query centered loss, fully exploiting the limited
training data in each episode. Extensive experiments on several benchmarks
demonstrate that our proposed CPLAE achieves new state-of-the-art.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:22:44 GMT""}]","2021-01-26"
"2101.09500","Mark Zolotas","Mark Zolotas, Yiannis Demiris","Disentangled Sequence Clustering for Human Intention Inference","7 pages, 7 figures. Accepted for publication at 2022 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)",,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  Equipping robots with the ability to infer human intent is a vital
precondition for effective collaboration. Most computational approaches towards
this objective derive a probability distribution of ""intent"" conditioned on the
robot's perceived state. However, these approaches typically assume
task-specific labels of human intent are known a priori. To overcome this
constraint, we propose the Disentangled Sequence Clustering Variational
Autoencoder (DiSCVAE), a clustering framework capable of learning such a
distribution of intent in an unsupervised manner. The proposed framework
leverages recent advances in unsupervised learning to disentangle latent
representations of sequence data, separating time-varying local features from
time-invariant global attributes. As a novel extension, the DiSCVAE also infers
a discrete variable to form a latent mixture model and thus enable clustering
over these global sequence concepts, e.g. high-level intentions. We evaluate
the DiSCVAE on a real-world human-robot interaction dataset collected using a
robotic wheelchair. Our findings reveal that the inferred discrete variable
coincides with human intent, holding promise for collaborative settings, such
as shared control.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:39:34 GMT""},{""version"":""v2"",""created"":""Sun, 12 Dec 2021 10:05:35 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 23:46:24 GMT""},{""version"":""v4"",""created"":""Mon, 1 Aug 2022 04:11:30 GMT""}]","2022-08-02"
"2101.09501","Lloyd Trefethen","Lloyd N. Trefethen","Exactness of quadrature formulas",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standard design principle for quadrature formulas is that they should be
exact for integrands of a given class, such as polynomials of a fixed degree.
We show how this principle fails to predict the actual behavior in four cases:
Newton-Cotes, Clenshaw-Curtis, Gauss-Legendre, and Gauss-Hermite quadrature.
Three further examples are mentioned more briefly.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:43:26 GMT""}]","2021-01-26"
"2101.09502","Mohamed Ali Belloum","Mohamed Ali Belloum","A generalized model interpolating between the random energy model and
  the branching random walk",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a generalization of the model introduced by Kistler and Schmidt in
$2015$, that interpolates between the random energy model (REM) and the
branching random walk (BRW). More precisely, we are interested in the
asymptotic behaviour of the extremal process associated to this model. Kistler
and Schmidt show that the extremal process of the $GREM(N^{\alpha})$,
$\alpha\in{[0,1)}$ converges weakly to a simple Poisson point process. This
contrasts with the extremal process of the branching random walk $(\alpha=1)$
which was shown to converge toward a decorate Poisson point process by Madaule.
In this paper we propose a generalized model of the $GREM(N^{\alpha})$, that
has the structure of a tree with $k_n$ levels, where $(k_n\leq n)$ is a
non-decreasing sequence of positive integers. We study a generalized case,
where the position of the particles are not necessarily Gaussian variables and
the reproduction law is not necessarily binary. We show that as long as
$b_n=\lfloor{\frac{n}{k_n}}\rfloor\to_{n\to \infty}\infty$ in the Gaussian case
(with the assumption $\frac{b_n}{\log(n)^2}\to\infty$ as $n\to \infty$ in the
non Gaussian case) the decoration disappears and we have convergence to a
simple Poisson point process.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:51:52 GMT""},{""version"":""v2"",""created"":""Sun, 19 Dec 2021 13:57:36 GMT""}]","2021-12-21"
"2101.09503","Adrien Druart","Vincent Maquet, Adrien Druart, Andr\'e Messiaen","Analytical edge power loss at the lower hybrid resonance: comparison
  with ANTITER IV and application to ICRH systems","13 pages, 9 figures, under consideration for publication in Journal
  of Plasma Physics",,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In non-inverted heating scenarios, a lower hybrid (LH) resonance can appear
in the plasma edge of tokamaks. This resonance can lead to large edge power
deposition when heating in the ion cyclotron resonance frequency (ICRF) range.
In this paper, the edge power loss associated with this LH resonance is
analytically computed for a cold plasma description using an asymptotic
approach and analytical continuation. This power loss can be directly linked to
the local radial electric field and is then compared to the corresponding power
loss computed with the semi-analytical code ANTITER IV. This method offers the
possibility to check the precision of the numerical integration made in ANTITER
IV and gives insights in the physics underlying the edge power absorption.
Finally, solutions to minimize this edge power absorption are investigated and
applied to the case of ITER's ion cyclotron resonance heating (ICRH) launcher.
This study is also of direct relevance to DEMO.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:54:07 GMT""}]","2021-01-26"
"2101.09504","Katsuhiko Suzuki","Hayato Aoi and Katsuhiko Suzuki","Chirality imbalance and chiral magnetic effect under a parallel
  electromagnetic field","29 pages, 6 figures, revised version is accepted for publication in
  Phys.Rev.D","Phys. Rev. D 103, 036002 (2021)","10.1103/PhysRevD.103.036002",,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We study the time evolution of the chirality imbalance $n_5$ and the chiral
magnetic effect (CME) under the external parallel electromagnetic fields
without assuming the artificial chiral asymmetric source. We adopt the
time-dependent Sauter-type electric and constant magnetic field, and obtain
analytical solutions of the Dirac equation for a massive fermion. We use the
point-split regularization to calculate the vacuum contribution in the gauge
invariant way. As a result, we find that $n_5$ and CME current increase
substantially as the electric field increases, and stay finite after the
electric field is switched off. The chirality imbalance and CME current are
shown to consist of a dominant contribution, which is essentially proportional
to relativistic velocity, and a small oscillating part. We find a simple
analytical relation between $n_5$ and the fermion pair-production rate from the
vacuum. We also discuss dynamical origin of the chirality imbalance in detail.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:54:17 GMT""}]","2021-02-10"
"2101.09505","Youngmin Kim","Youngmin Kim, Richard Allmendinger and Manuel L\'opez-Ib\'a\~nez","Safe Learning and Optimization Techniques: Towards a Survey of the State
  of the Art","The final authenticated publication was made In: Heintz F., Milano
  M., O'Sullivan B. (eds) Trustworthy AI - Integrating Learning, Optimization
  and Reasoning. TAILOR 2020. Lecture Notes in Computer Science, vol 12641.
  Springer, Cham. The final authenticated publication is available online at
  \<https://doi.org/10.1007/978-3-030-73959-1_12>",,"10.1007/978-3-030-73959-1_12",,"cs.LG cs.NE math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Safe learning and optimization deals with learning and optimization problems
that avoid, as much as possible, the evaluation of non-safe input points, which
are solutions, policies, or strategies that cause an irrecoverable loss (e.g.,
breakage of a machine or equipment, or life threat). Although a comprehensive
survey of safe reinforcement learning algorithms was published in 2015, a
number of new algorithms have been proposed thereafter, and related works in
active learning and in optimization were not considered. This paper reviews
those algorithms from a number of domains including reinforcement learning,
Gaussian process regression and classification, evolutionary algorithms, and
active learning. We provide the fundamental concepts on which the reviewed
algorithms are based and a characterization of the individual algorithms. We
conclude by explaining how the algorithms are connected and suggestions for
future research.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 13:58:09 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 13:38:59 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 18:19:08 GMT""}]","2021-06-25"
"2101.09506","Clara Franchi","Clara Franchi and Mario Mainardis","A note on 2-generated symmetric axial algebras of Monster type","10 pages","J. Algebra 596 (2022), 200-218","10.1016/j.jalgebra.2022.01.004",,"math.RA","http://creativecommons.org/licenses/by/4.0/","  Recently Takahiro Yabe gave an almost complete classification of primitive
symmetric $2$-generated axial algebras of Monster type. In this note, we
construct a new infinite-dimensional primitive $2$-generated symmetric axial
algebra of Monster type $(2, \frac{1}{2})$ over a field of characteristic $5$,
and use this algebra to complete the last case left open.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:00:14 GMT""}]","2022-03-09"
"2101.09507","Harold Berjamin","Harold Berjamin","Nonlinear plane waves in saturated porous media with incompressible
  constituents",,,"10.1098/rspa.2021.0086",,"physics.flu-dyn cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the propagation of nonlinear plane waves in porous media within
the framework of the Biot-Coussy biphasic mixture theory. The tortuosity effect
is included in the model, and both constituents are assumed incompressible
(Yeoh-type elastic skeleton, and saturating fluid). In this case, the linear
dispersive waves governed by Biot's theory are either of compression or
shear-wave type, and nonlinear waves can be classified in a similar way. In the
special case of a neo-Hookean skeleton, we derive the explicit expressions for
the characteristic wave speeds, leading to the hyperbolicity condition. The
sound speeds for a Yeoh skeleton are estimated using a perturbation approach.
Then we arrive at the evolution equation for the amplitude of acceleration
waves. In general, it is governed by a Bernoulli equation. With the present
constitutive assumptions, we find that longitudinal jump amplitudes follow a
nonlinear evolution, while transverse jump amplitudes evolve in an almost
linearly degenerate fashion.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:01:47 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 16:20:27 GMT""},{""version"":""v3"",""created"":""Fri, 23 Apr 2021 09:19:09 GMT""}]","2021-07-07"
"2101.09508","Andre Nies","Andre Nies","Logic Blog 2020",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  This year's blog has focused on the connections of group theory with logic
and algorithms. The first post is on automata presentable groups. Then there
are several posts related to topological groups, for instance Ivanov and
Majcher showing that extreme amenability of closed subgroups of $S_\infty$ is a
Borel property. One post due to Harrison-Trainor and Nies reviews notes by
Segal on pseudofinite groups, and attempts an effective version. About 25
percent is on computability and randomness, in particular equivalence of
reducibilities weaker than Turing on the K-trivials by Greenberg, Nies and
Turetsky, and the effective SMB theorem in the quantum setting by Nies and
Tomamichel.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:14:10 GMT""}]","2021-01-26"
"2101.09509","Donlapark Ponnoprat","Donlapark Ponnoprat","Short-term daily precipitation forecasting with seasonally-integrated
  autoencoder","35 pages, 13 figures","Applied Soft Computing, 102, 107083 (2021)","10.1016/j.asoc.2021.107083",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Short-term precipitation forecasting is essential for planning of human
activities in multiple scales, ranging from individuals' planning, urban
management to flood prevention. Yet the short-term atmospheric dynamics are
highly nonlinear that it cannot be easily captured with classical time series
models. On the other hand, deep learning models are good at learning nonlinear
interactions, but they are not designed to deal with the seasonality in time
series. In this study, we aim to develop a forecasting model that can both
handle the nonlinearities and detect the seasonality hidden within the daily
precipitation data. To this end, we propose a seasonally-integrated autoencoder
(SSAE) consisting of two long short-term memory (LSTM) autoencoders: one for
learning short-term dynamics, and the other for learning the seasonality in the
time series. Our experimental results show that not only does the SSAE
outperform various time series models regardless of the climate type, but it
also has low output variance compared to other deep learning models. The
results also show that the seasonal component of the SSAE helped improve the
correlation between the forecast and the actual values from 4% at horizon 1 to
37% at horizon 3.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:19:56 GMT""}]","2021-01-26"
"2101.09510","Giada Peron","Giada Peron, Felix Aharonian, Sabrina Casanova, Ruizhi Yang and
  Roberta Zanin","Probing the Cosmic Ray density in the inner Galaxy",,"ApJL 907 L11 (2021)","10.3847/2041-8213/abcaa9",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The galactic diffuse $\gamma$-ray emission, as seen by Fermi Large Area
Telescope (LAT), shows a sharp peak in the region around 4 kpc from the
Galactic center, which can be interpreted either as due to an enhanced density
of cosmic-ray accelerators or to a modification of the particle diffusion in
that region. Observations of $\gamma$-rays originating in molecular clouds are
a unique tool to infer the cosmic-ray density point by point, in distant
regions of the Galaxy. We report here the analysis of 11 yr Fermi-LAT data,
obtained in the direction of nine molecular clouds located in the 1.5--4.5 kpc
region. The cosmic-ray density measured at the locations of these clouds is
compatible with the locally measured one. We demonstrate that the cosmic-ray
density gradient inferred from the diffuse gamma-ray emission is the result of
the presence of cosmic-ray accelerators rather than a global change of the sea
of Galactic cosmic rays due to their propagation.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:20:06 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 09:53:12 GMT""}]","2021-03-23"
"2101.09511","A. V. Syromyatnikov","A. V. Syromyatnikov and F. D. Timkovskii","Antiferromagnets with random vacancies and substitutional spins on the
  triangular lattice","15 pages, 4 figures","Phys. Rev. B 103, 134416 (2021)","10.1103/PhysRevB.103.134416",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss theoretically static and dynamical properties of $XY$ and
Heisenberg antiferromagnets on triangular lattice with random vacancies and
substitutional spins. It is shown that the distortion of $120^\circ$ magnetic
order produced by a single defect is described by electrostatic equations for a
field of an electrically neutral complex of six charges located around the
impurity. The first finite term in the multipole expansion of this field is the
octupole moment which decays as $1/r^3$ with the distance $r$. The linearity of
equations allows to describe analytically the distortion of the long-range
magnetic order at a small concentration $c$ of defects. We obtain analytically
renormalization of the elastic neutron scattering cross section and the magnon
spectrum $\epsilon_{\bf k}$ in the leading order in $c$. We find that the
scattering on impurities renormalizes weakly the bare spectrum $\epsilon_{\bf
k}\propto k$ at $k\gg\sqrt c$. However the renormalization is substantial of
the long-wavelength magnon spectrum at $k\ll\sqrt c$: $\epsilon_{\bf k}\propto
\sqrt{c /\ln(1/k)}$ at $k\to0$ and there is a parametrically large region in
which magnons with not too small momenta are overdamped and localized. This
strong modification of the long-wavelength spectrum leads to the stabilization
of the slightly distorted magnetic long-range order at $T<T_N\sim
S^2J/\ln(1/c)$ and to the considerable change in the density of states and in
the specific heat. The overdamped modes arise also in quasi-2D spin systems on
a stacked triangular lattice.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:35:34 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 14:31:25 GMT""},{""version"":""v3"",""created"":""Mon, 12 Apr 2021 14:33:54 GMT""}]","2021-04-21"
"2101.09512","Karthigan Sinnathamby","Karthigan Sinnathamby, Chang-Yu Hou, Lalitha Venkataramanan,
  Vasileios-Marios Gkortsas, Fran\c{c}ois Fleuret","Unsupervised clustering of series using dynamic programming",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are interested in clustering parts of a given single multi-variate series
in an unsupervised manner. We would like to segment and cluster the series such
that the resulting blocks present in each cluster are coherent with respect to
a known model (e.g. physics model). Data points are said to be coherent if they
can be described using this model with the same parameters. We have designed an
algorithm based on dynamic programming with constraints on the number of
clusters, the number of transitions as well as the minimal size of a block such
that the clusters are coherent with this process. We present an use-case:
clustering of petrophysical series using the Waxman-Smits equation.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:35:35 GMT""}]","2021-01-26"
"2101.09513","Carlos A. S. Almeida","F. C. E. Lima, A. Yu. Petrov, and C. A. S. Almeida","Vortex solutions in nonpolynomial scalar QED","26 pages, 13 figures","Phys. Rev. D 103, 096019 (2021)","10.1103/PhysRevD.103.096019",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to investigate possible topological vortex structures in generalized
models, we developed a perturbative generation approach for scalar-vector
theories. We demonstrate explicitly that the dielectric permeability functions
must have a nonpolynomial shape, i. e., the form of the logarithmic function.
Basing on this result, we built models in $(2+1)D$ with logarithmic dielectric
permeability in order to investigate the presence of topological vortex
structures in a Maxwell model. This type of scalar-vector models is important
because they can generate stationary field solutions in theories describing the
dynamics of the scalar field. As examples, we chose models of the complex
scalar field coupled to the Maxwell field. Subsequently, we investigated the
model's Bogomol'nyi equations to describe the field configurations. Then, we
demonstrate numerically, for an ansatz with rotational symmetry, that the
solutions of the complex scalar field generating minimum energy configurations
are topological structures depending on the parameters obtained in the
perturbative generation of the vector-scalar theory.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:36:57 GMT""}]","2021-05-26"
"2101.09514","Nadhir Ben Rached","Nadhir Ben Rached and Abdul-Lateef Haji-Ali and Gerardo Rubino and
  Raul Tempone","Efficient Importance Sampling for Large Sums of Independent and
  Identically Distributed Random Variables",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss estimating the probability that the sum of nonnegative independent
and identically distributed random variables falls below a given threshold,
i.e., $\mathbb{P}(\sum_{i=1}^{N}{X_i} \leq \gamma)$, via importance sampling
(IS). We are particularly interested in the rare event regime when $N$ is large
and/or $\gamma$ is small. The exponential twisting is a popular technique for
similar problems that, in most cases, compares favorably to other estimators.
However, it has some limitations: i) it assumes the knowledge of the moment
generating function of $X_i$ and ii) sampling under the new IS PDF is not
straightforward and might be expensive. The aim of this work is to propose an
alternative IS PDF that approximately yields, for certain classes of
distributions and in the rare event regime, at least the same performance as
the exponential twisting technique and, at the same time, does not introduce
serious limitations. The first class includes distributions whose probability
density functions (PDFs) are asymptotically equivalent, as $x \rightarrow 0$,
to $bx^{p}$, for $p>-1$ and $b>0$. For this class of distributions, the Gamma
IS PDF with appropriately chosen parameters retrieves approximately, in the
rare event regime corresponding to small values of $\gamma$ and/or large values
of $N$, the same performance of the estimator based on the use of the
exponential twisting technique. In the second class, we consider the Log-normal
setting, whose PDF at zero vanishes faster than any polynomial, and we show
numerically that a Gamma IS PDF with optimized parameters clearly outperforms
the exponential twisting IS PDF. Numerical experiments validate the efficiency
of the proposed estimator in delivering a highly accurate estimate in the
regime of large $N$ and/or small $\gamma$.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:42:14 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 15:35:32 GMT""}]","2021-10-04"
"2101.09515","Dheryta Jaisinghani","Dheryta Jaisinghani, Vinayak Naik, Rajesh Balan, Archan Misra, and
  Youngki Lee","Experiences & Challenges with Server-Side WiFi Indoor Localization Using
  Existing Infrastructure",,,,,"cs.NI cs.PF","http://creativecommons.org/licenses/by/4.0/","  Real-world deployments of WiFi-based indoor localization in large public
venues are few and far between as most state-of-the-art solutions require
either client or infrastructure-side changes. Hence, even though high location
accuracy is possible with these solutions, they are not practical due to cost
and/or client adoption reasons. Majority of the public venues use commercial
controller-managed WLAN solutions, %provided by Aruba, Cisco, etc., that
neither allow client changes nor infrastructure changes. In fact, for such
venues we have observed highly heterogeneous devices with very low adoption
rates for client-side apps.
  In this paper, we present our experiences in deploying a scalable location
system for such venues. We show that server-side localization is not trivial
and present two unique challenges associated with this approach, namely
Cardinality Mismatch and High Client Scan Latency. The ""Mismatch"" challenge
results in a significant mismatch between the set of access points (APs)
reporting a client in the offline and online phases, while the ""Latency""
challenge results in a low number of APs reporting data for any particular
client. We collect three weeks of detailed ground truth data (~200 landmarks),
from a WiFi setup that has been deployed for more than four years, to provide
evidences for the extent and understanding the impact of these problems. Our
analysis of real-world client devices reveal that the current trend for the
clients is to reduce scans, thereby adversely impacting their localization
accuracy. We analyze how localization is impacted when scans are minimal. We
propose heuristics to alleviate reduction in the accuracy despite lesser scans.
Besides the number of scans, we summarize the other challenges and pitfalls of
real deployments which hamper the localization accuracy.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:48:17 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 04:58:28 GMT""}]","2021-01-27"
"2101.09516","Andrea Plati","Andrea Plati and Andrea Puglisi","Long range correlations and slow time scales in a boundary driven
  granular model",,,,,"cond-mat.stat-mech cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We consider a velocity field with linear viscous interactions defined on a
one dimensional lattice. Brownian baths with different parameters can be
coupled to the boundary sites and to the bulk sites, determining different
kinds of non-equilibrium steady states or free-cooling dynamics. Analytical
results for spatial and temporal correlations are provided by analytical
diagonalisation of the system's equations in the infinite size limit. We
demonstrate that spatial correlations are scale-free and time-scales become
exceedingly long when the system is driven only at the boundaries. On the
contrary, in the case a bath is coupled to the bulk sites too, an exponential
correlation decay is found with a finite characteristic length. This is also
true in the free cooling regime, but in this case the correlation length grows
diffusively in time. We discuss the crucial role of boundary driving for
long-range correlations and slow time-scales, proposing an analogy between this
simplified dynamical model and dense vibro-fluidized granular materials.
Several generalizations and connections with the statistical physics of active
matter are also suggested.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:53:02 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 07:08:52 GMT""}]","2021-06-18"
"2101.09517","Giovanni Mana","Giovanni Mana","Interlaboratory consensus building challenge","Analytical and Bioanalytical Chemistry, Solution to interlaboratory
  consensus building challenge 5 pages, 4 figures",,"10.1088/1681-7575/ac0ea2",,"physics.data-an","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The manuscript is about an interlaboratory comparison which involved eleven
metrology institutes. It comprises four tasks: i) deriving a consensus value
from these results; ii) evaluating the associated standard uncertainty; iii)
producing a coverage interval that, with 95\% confidence, is believed to
include the true value of which the consensus value is an estimate; iv)
suggesting how the measurement result from NIST may be compared with the
consensus value.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:53:12 GMT""}]","2021-09-01"
"2101.09518","Partha Pratim Goswami","Partha Pratim Goswami, Rajeev Singh Rathour, and Aruna Goswami","Spectroscopic study of CEMP-(s & r/s) stars- Revisiting classification
  criteria and formation scenarios, highlighting i-process nucleosynthesis","27 pages, 16 figures, accepted for publication in Astronomy &
  Astrophysics (A&A)","A&A 649, A49 (2021)","10.1051/0004-6361/202038258",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have derived the stellar atmospheric parameters, the effective temperature
T$_{eff}$, the microturbulent velocity $\zeta$, the surface gravity log g, and
the metallicity [Fe/H] for HE 0017+0055, HE 2144-1832, HE 2339-0837, HD 145777,
and CD-27 14351 from local thermodynamic equilibrium analyses using model
atmospheres. Elemental abundances of C, N, $\alpha$-elements, iron-peak
elements, and several neutron-capture elements are estimated using the
equivalent width measurement technique as well as spectrum synthesis
calculations in some cases. In the context of the double enhancement observed
in four of the programme stars, we have critically examined whether the
literature i-process model yields ([X/Fe]) of heavy elements can explain the
observed abundance distribution. The estimated metallicity [Fe/H] of the
programme stars ranges from -1.63 to -2.74. All five stars show enhanced
abundance for Ba, and four of them exhibit enhanced abundance for Eu. Based on
our analysis, HE 0017+0055, HE 2144-1832, and HE 2339-0837 are found to be
CEMP-r/s stars, whereas HD 145777 and CD-27 14351 show characteristic
properties of CEMP-s stars. From a detailed analysis of different classifiers
of CEMP stars, using a large sample of similar stars from the literature, we
have identified the one which best describes the CEMP-s and CEMP-r/s stars. We
have also examined if [hs/ls] alone can be used as a classifier, and if there
are any limiting values for [hs/ls] ratio that can be used to distinguish
CEMP-s and CEMP-r/s stars. In spite of peaking at different values of [hs/ls],
CEMP-s and CEMP-r/s stars show an overlap in the range 0.0 < [hs/ls] < 1.5 and
hence this ratio alone can not be used to distinguish CEMP-s and CEMP-r/s
stars.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 14:53:54 GMT""}]","2021-05-12"
"2101.09519","Quang A Dang","Dang Quang A and Dang Quang Long","A unified approach to study the existence and numerical solution of
  functional differential equation","18 pages, 1 figure",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider a class of boundary value problems for third order
nonlinear functional differential equation. By the reduction of the problem to
operator equation we establish the existence and uniqueness of solution and
construct a numerical method for solving it. We prove that the method is of
second order accuracy and obtain an estimate for total error. Some examples
demonstrate the validity of the obtained theoretical results and the efficiency
of the numerical method. The approach used for the third order nonlinear
functional differential equation can be applied to functional differential
equations of any orders.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:00:44 GMT""}]","2021-01-26"
"2101.09520","John Fitzgerald","John Fitzgerald, Sanna Ojanper\""a, Neave O'Clery","Is academia becoming more localised? The growth of regional knowledge
  networks within international research collaboration","28 pages, 7 figures, accepted to Applied Network Science","Appl Netw Sci 6, 38 (2021)","10.1007/s41109-021-00371-w",,"cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  It is well-established that the process of learning and capability building
is core to economic development and structural transformation. Since knowledge
is `sticky', a key component of this process is learning-by-doing, which can be
achieved via a variety of mechanisms including international research
collaboration. Uncovering significant inter-country research ties using Scopus
co-authorship data, we show that within-region collaboration has increased over
the past five decades relative to international collaboration. Further
supporting this insight, we find that while communities present in the global
collaboration network before 2000 were often based on historical geopolitical
or colonial lines, in more recent years they increasingly align with a simple
partition of countries by regions. These findings are unexpected in light of a
presumed continual increase in globalisation, and have significant implications
for the design of programmes aimed at promoting international research
collaboration and knowledge diffusion.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:06:14 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 09:18:43 GMT""}]","2021-06-02"
"2101.09521","Alain Zemkoho","Andrey Tin and Alain B. Zemkoho","Levenberg-Marquardt method and partial exact penalty parameter selection
  in bilevel optimization","21 pages, 14 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the optimistic bilevel optimization problem, known to have a wide
range of applications in engineering, that we transform into a single-level
optimization problem by means of the lower-level optimal value function
reformulation. Subsequently, based on the partial calmness concept, we build an
equation system, which is parameterized by the corresponding partial exact
penalization parameter. We then design and analyze a Levenberg-Marquardt method
to solve this parametric system of equations. Considering the fact that the
selection of the partial exact penalization parameter is a critical issue when
numerically solving a bilevel optimization problem, we conduct a careful
experimental study to this effect, in the context the Levenberg-Marquardt
method, while using the Bilevel Optimization LIBrary (BOLIB) series of test
problems.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:06:59 GMT""}]","2021-01-26"
"2101.09522","Seunghyun Khim","S. Khim, J. F. Landaeta, J. Banda, N. Bannor, M. Brando, P. M. R.
  Brydon, D. Hafner, R. K\""uchler, R. Cardoso-Gil, U. Stockert, A. P.
  Mackenzie, D. F. Agterberg, C. Geibel, E. Hassinger","Field-induced transition from even to odd parity superconductivity in
  CeRh$_2$As$_2$",,"Science 373, 1012 (2021)","10.1126/science.abe7518",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We report the discovery of two-phase unconventional superconductivity in
CeRh$_2$As$_2$. Using thermodynamic probes, we establish that the
superconducting critical field of its high-field phase is as high as 14 T,
remarkable in a material whose transition temperature is 0.26 K. Furthermore, a
$c$-axis field drives a transition between two different superconducting
phases. In spite of the fact that CeRh$_2$As$_2$ is globally centrosymmetric,
we show that local inversion-symmetry breaking at the Ce sites enables Rashba
spin-orbit coupling to play a key role in the underlying physics. More detailed
analysis identifies the transition from the low- to high-field states to be
associated with one between states of even and odd parity.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:22:18 GMT""}]","2021-09-10"
"2101.09523","Masahiro Kaneko","Masahiro Kaneko and Danushka Bollegala","Debiasing Pre-trained Contextualised Embeddings","EACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In comparison to the numerous debiasing methods proposed for the static
non-contextualised word embeddings, the discriminative biases in contextualised
embeddings have received relatively little attention. We propose a fine-tuning
method that can be applied at token- or sentence-levels to debias pre-trained
contextualised embeddings. Our proposed method can be applied to any
pre-trained contextualised embedding model, without requiring to retrain those
models. Using gender bias as an illustrative example, we then conduct a
systematic study using several state-of-the-art (SoTA) contextualised
representations on multiple benchmark datasets to evaluate the level of biases
encoded in different contextualised embeddings before and after debiasing using
the proposed method. We find that applying token-level debiasing for all tokens
and across all layers of a contextualised embedding model produces the best
performance. Interestingly, we observe that there is a trade-off between
creating an accurate vs. unbiased contextualised embedding model, and different
contextualised embedding models respond differently to this trade-off.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:28:48 GMT""}]","2021-01-26"
"2101.09524","\""Ozg\""ur \""Okc\""u","\""Ozg\""ur \""Okc\""u, Ekrem Aydiner","Observational Tests of the Generalized Uncertainty Principle: Shapiro
  Time Delay, Gravitational Redshift, and Geodetic Precession","17 pages, 1 figure, 1 table. Accepted for publication in Nuclear
  Physics B",,"10.1016/j.nuclphysb.2021.115324",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is based on the study of the paper of Scardigli and Casadio [Eur.
Phys. J. C (2015) 75:425] where the authors computed the light deflection and
perihelion precession for the Generalized Uncertainty Principle (GUP) modified
Schwarzschild metric. In the present work, we computed the gravitational tests
such as Shapiro time delay, gravitational redshift, and geodetic precession for
the GUP modified Schwarzschild metric. Using the results of Solar system
experiments and observations, we obtain upper bounds for the GUP parameter
$\beta$. Finally, we compare our bounds with other bounds in the literature.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:35:42 GMT""}]","2021-01-26"
"2101.09525","Masahiro Kaneko","Masahiro Kaneko and Danushka Bollegala","Dictionary-based Debiasing of Pre-trained Word Embeddings","EACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Word embeddings trained on large corpora have shown to encode high levels of
unfair discriminatory gender, racial, religious and ethnic biases.
  In contrast, human-written dictionaries describe the meanings of words in a
concise, objective and an unbiased manner.
  We propose a method for debiasing pre-trained word embeddings using
dictionaries, without requiring access to the original training resources or
any knowledge regarding the word embedding algorithms used.
  Unlike prior work, our proposed method does not require the types of biases
to be pre-defined in the form of word lists, and learns the constraints that
must be satisfied by unbiased word embeddings automatically from dictionary
definitions of the words.
  Specifically, we learn an encoder to generate a debiased version of an input
word embedding such that it
  (a) retains the semantics of the pre-trained word embeddings,
  (b) agrees with the unbiased definition of the word according to the
dictionary, and
  (c) remains orthogonal to the vector space spanned by any biased basis
vectors in the pre-trained word embedding space.
  Experimental results on standard benchmark datasets show that the proposed
method can accurately remove unfair biases encoded in pre-trained word
embeddings, while preserving useful semantics.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:44:23 GMT""}]","2021-01-26"
"2101.09526","Weiwei Wan","Shogo Hayakawa, Weiwei Wan, Keisuke Koyama, and Kensuke Harada","A Dual-arm Robot that Autonomously Lifts Up and Tumbles Heavy Plates
  Using Crane Pulley Blocks",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper develops a planner that plans the action sequences and motion for
a dual-arm robot to lift up and flip heavy plates using crane pulley blocks.
The problem is motivated by the low payload of modern collaborative robots.
Instead of directly manipulating heavy plates that collaborative robots cannot
afford, the paper develops a planner for collaborative robots to operate crane
pulley blocks. The planner assumes a target plate is pre-attached to the crane
hook. It optimizes dual-arm action sequences and plans the robot's dual-arm
motion that pulls the rope of the crane pulley blocks to lift up the plate. The
crane pulley blocks reduce the payload that each robotic arm needs to bear.
When the plate is lifted up to a satisfying pose, the planner plans a pushing
motion for one of the robot arms to tumble over the plate while considering
force and moment constraints. The article presents the technical details of the
planner and several experiments and analysis carried out using a dual-arm robot
made by two Universal Robots UR3 arms. The influence of various parameters and
optimization goals are investigated and compared in depth. The results show
that the proposed planner is flexible and efficient.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:56:17 GMT""}]","2021-01-26"
"2101.09527","Jordi Bataller Mascarell","Jordi Bataller Mascarell","Formal Definitions of Memory Consistency Models",,,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Shared Memory is a mechanism that allows several processes to communicate
with each other by accessing -- writing or reading -- a set of variables that
they have in common. A Consistency Model defines how each process observes the
state of the Memory, according to the accesses performed by it and by the rest
of the processes in the system. Therefore, it determines what value a read
returns when a given process issues it. This implies that there must be an
agreement among all, or among processes in different subsets, on the order in
which all or a subset of the accesses happened. It is clear that a higher
quantity of accesses or proceses taking part in the agreement makes it possibly
harder or slower to be achieved. This is the main reason for which a number of
Consistency Models for Shared Memory have been introduced. This paper is a
handy summary of [2] and [3] where consistency models (Sequential, Causal,
PRAM, Cache, Processors, Slow), including synchronized ones (Weak, Release,
Entry), were formally defined. This provides a better understanding of those
models and a way to reason and compare them through a concise notation. There
are many papers on this subject in the literature such as [11] with which this
work shares some concepts.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 15:57:54 GMT""}]","2021-01-26"
"2101.10183","Prashant K Jha","Marvin Fritz, Prashant K. Jha, Tobias K\""oppl, J. Tinsley Oden,
  Andreas Wagner, Barbara Wohlmuth","Modeling and simulation of vascular tumors embedded in evolving
  capillary networks","36 pages, 22 figures","Computer Methods in Applied Mechanics and Engineering 384 (2021),
  p. 113975","10.1016/j.cma.2021.113975",,"q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  In this work, we present a coupled 3D-1D model of solid tumor growth within a
dynamically changing vascular network to facilitate realistic simulations of
angiogenesis. Additionally, the model includes erosion of the extracellular
matrix, interstitial flow, and coupled flow in blood vessels and tissue. We
employ continuum mixture theory with stochastic Cahn--Hilliard type phase-field
models of tumor growth. The interstitial flow is governed by a mesoscale
version of Darcy's law. The flow in the blood vessels is controlled by
Poiseuille flow, and Starling's law is applied to model the mass transfer in
and out of blood vessels. The evolution of the network of blood vessels is
orchestrated by the concentration of the tumor angiogenesis factors (TAFs);
blood vessels grow towards the increasing TAFs concentrations. This process is
not deterministic, allowing random growth of blood vessels and, therefore, due
to the coupling of nutrients in tissue and vessels, makes the growth of tumors
stochastic. We demonstrate the performance of the model by applying it to a
variety of scenarios. Numerical experiments illustrate the flexibility of the
model and its ability to generate satellite tumors. Simulations of the effects
of angiogenesis on tumor growth are presented as well as sample-independent
features of cancer.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 17:43:01 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 14:04:03 GMT""}]","2021-06-23"
"2101.10202","Prabhat .","Prabhat and Bikash K. Behera","Simulation of Lennard-Jones Potential on a Quantum Computer","The manuscript contains 14 pages and 16 figures",,"10.13140/RG.2.2.24765.08167",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Simulation of time dynamical physical problems has been a challenge for
classical computers due to their time-complexity. To demonstrate the dominance
of quantum computers over classical computers in this regime, here we simulate
a semi-empirical model where two neutral particles interact through
Lennard-Jones potential in a one-dimensional system. We implement the above
scenario on the IBM quantum experience platform using a 5-qubit real device. We
construct the Hamiltonian and then efficiently map it to quantum operators onto
quantum gates using the time-evolutionary unitary matrix obtained from the
Hamiltonian. We verify the results collected from the QASM-simulator and
compare it with that of the 5-qubit real chip ibmqx2.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 18:16:16 GMT""}]","2021-02-02"
"2101.10325","Antonio Leitao","S. Kindermann, A. Leitao","Regularization by dynamic programming","17 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:2101.09327; text overlap with arXiv:2101.09339","Journal of Inverse and Ill-Posed Problems 15 (2007), no. 3,
  295-310","10.1515/jiip.2007.016",,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate continuous regularization methods for linear inverse problems
of static and dynamic type. These methods are based on dynamic programming
approaches for linear quadratic optimal control problems. We prove
regularization properties and also obtain rates of convergence for our methods.
A numerical example concerning a dynamical electrical impedance tomography
(EIT) problem is used to illustrate the theoretical results.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:08:16 GMT""}]","2021-01-27"
"2101.10537","Joseph Marvin Imperial","Joseph Marvin Imperial, Ethel Ong","Application of Lexical Features Towards Improvement of Filipino
  Readability Identification of Children's Literature","8 tables, 1 figure. Presented at the Philippine Computing Science
  Congress 2020",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Proper identification of grade levels of children's reading materials is an
important step towards effective learning. Recent studies in readability
assessment for the English domain applied modern approaches in natural language
processing (NLP) such as machine learning (ML) techniques to automate the
process. There is also a need to extract the correct linguistic features when
modeling readability formulas. In the context of the Filipino language, limited
work has been done [1, 2], especially in considering the language's lexical
complexity as main features. In this paper, we explore the use of lexical
features towards improving the development of readability identification of
children's books written in Filipino. Results show that combining lexical
features (LEX) consisting of type-token ratio, lexical density, lexical
variation, foreign word count with traditional features (TRAD) used by previous
works such as sentence length, average syllable length, polysyllabic words,
word, sentence, and phrase counts increased the performance of readability
models by almost a 5% margin (from 42% to 47.2%). Further analysis and ranking
of the most important features were shown to identify which features contribute
the most in terms of reading complexity.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:54:37 GMT""}]","2021-01-27"
"2101.10539","Mohammed Mustafa Abdelgwad","Mohammed M.Abdelgwad, Taysir Hassan A Soliman, Ahmed I.Taloba, Mohamed
  Fawzy Farghaly","Arabic aspect based sentiment analysis using bidirectional GRU based
  models",,"Journal of King Saud University - Computer and Information
  Sciences (2021)","10.1016/j.jksuci.2021.08.030",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aspect-based Sentiment analysis (ABSA) accomplishes a fine-grained analysis
that defines the aspects of a given document or sentence and the sentiments
conveyed regarding each aspect. This level of analysis is the most detailed
version that is capable of exploring the nuanced viewpoints of the reviews. The
bulk of study in ABSA focuses on English with very little work available in
Arabic. Most previous work in Arabic has been based on regular methods of
machine learning that mainly depends on a group of rare resources and tools for
analyzing and processing Arabic content such as lexicons, but the lack of those
resources presents another challenge. In order to address these challenges,
Deep Learning (DL)-based methods are proposed using two models based on Gated
Recurrent Units (GRU) neural networks for ABSA. The first is a DL model that
takes advantage of word and character representations by combining
bidirectional GRU, Convolutional Neural Network (CNN), and Conditional Random
Field (CRF) making up the (BGRU-CNN-CRF) model to extract the main opinionated
aspects (OTE). The second is an interactive attention network based on
bidirectional GRU (IAN-BGRU) to identify sentiment polarity toward extracted
aspects. We evaluated our models using the benchmarked Arabic hotel reviews
dataset. The results indicate that the proposed methods are better than
baseline research on both tasks having 39.7% enhancement in F1-score for
opinion target extraction (T2) and 7.58% in accuracy for aspect-based sentiment
polarity classification (T3). Achieving F1 score of 70.67% for T2, and accuracy
of 83.98% for T3.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 02:54:30 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 05:01:16 GMT""},{""version"":""v3"",""created"":""Sun, 7 Mar 2021 10:32:15 GMT""},{""version"":""v4"",""created"":""Wed, 6 Oct 2021 23:31:30 GMT""}]","2021-10-08"
"2101.10861","Lucas Prado Osco","Lucas Prado Osco, Jos\'e Marcato Junior, Ana Paula Marques Ramos,
  L\'ucio Andr\'e de Castro Jorge, Sarah Narges Fatholahi, Jonathan de Andrade
  Silva, Edson Takashi Matsubara, Hemerson Pistori, Wesley Nunes Gon\c{c}alves,
  Jonathan Li","A Review on Deep Learning in UAV Remote Sensing","27 pages, 10 figures","International Journal of Applied Earth Observation and
  Geoinformation, 2022","10.1016/j.jag.2021.102456",,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Deep Neural Networks (DNNs) learn representation from data with an impressive
capability, and brought important breakthroughs for processing images,
time-series, natural language, audio, video, and many others. In the remote
sensing field, surveys and literature revisions specifically involving DNNs
algorithms' applications have been conducted in an attempt to summarize the
amount of information produced in its subfields. Recently, Unmanned Aerial
Vehicles (UAV) based applications have dominated aerial sensing research.
However, a literature revision that combines both ""deep learning"" and ""UAV
remote sensing"" thematics has not yet been conducted. The motivation for our
work was to present a comprehensive review of the fundamentals of Deep Learning
(DL) applied in UAV-based imagery. We focused mainly on describing
classification and regression techniques used in recent applications with
UAV-acquired data. For that, a total of 232 papers published in international
scientific journal databases was examined. We gathered the published material
and evaluated their characteristics regarding application, sensor, and
technique used. We relate how DL presents promising results and has the
potential for processing tasks associated with UAV-based image data. Lastly, we
project future perspectives, commentating on prominent DL paths to be explored
in the UAV remote sensing field. Our revision consists of a friendly-approach
to introduce, commentate, and summarize the state-of-the-art in UAV-based image
applications with DNNs algorithms in diverse subfields of remote sensing,
grouping it in the environmental, urban, and agricultural contexts.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:08:38 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jan 2021 14:09:43 GMT""},{""version"":""v3"",""created"":""Wed, 26 Apr 2023 19:02:35 GMT""}]","2023-04-28"
"2101.10862","Christian M. Dahl","Christian M. Dahl, Torben Johansen, Emil N. S{\o}rensen, Simon
  Wittrock","HANA: A HAndwritten NAme Database for Offline Handwritten Text
  Recognition",,,,,"cs.CV econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Methods for linking individuals across historical data sets, typically in
combination with AI based transcription models, are developing rapidly.
Probably the single most important identifier for linking is personal names.
However, personal names are prone to enumeration and transcription errors and
although modern linking methods are designed to handle such challenges, these
sources of errors are critical and should be minimized. For this purpose,
improved transcription methods and large-scale databases are crucial
components. This paper describes and provides documentation for HANA, a newly
constructed large-scale database which consists of more than 3.3 million names.
The database contain more than 105 thousand unique names with a total of more
than 1.1 million images of personal names, which proves useful for transfer
learning to other settings. We provide three examples hereof, obtaining
significantly improved transcription accuracy on both Danish and US census
data. In addition, we present benchmark results for deep learning models
automatically transcribing the personal names from the scanned documents.
Through making more challenging large-scale databases publicly available we
hope to foster more sophisticated, accurate, and robust models for handwritten
text recognition.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 16:23:01 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 07:27:25 GMT""}]","2022-03-11"
"2101.10863","Antonio Leitao","J. Baumeister, A. Leitao, G.N. Silva","On the value function for nonautonomous optimal control problems with
  infinite horizon","17 pages","Systems and Control Letters 56 (2007), no. 3, 188-196","10.1016/j.sysconle.2006.08.011",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider nonautonomous optimal control problems of infinite
horizon type, whose control actions are given by $L^1$-functions. We verify
that the value function is locally Lipschitz. The equivalence between dynamic
programming inequalities and Hamilton-Jacobi-Bellman (HJB) inequalities for
proximal sub (super) gradients is proven. Using this result we show that the
value function is a Dini solution of the HJB equation. We obtain a verification
result for the class of Dini sub-solutions of the HJB equation and also prove a
minimax property of the value function with respect to the sets of Dini
semi-solutions of the HJB equation. We introduce the concept of viscosity
solutions of the HJB equation in infinite horizon and prove the equivalence
between this and the concept of Dini solutions. In the appendix we provide an
existence theorem.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:04:55 GMT""}]","2021-01-27"
"2101.10864","Antoine Diez","Pierre Degond, Antoine Diez, Mingye Na","Bulk topological states in a new collective dynamics model",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  In this paper, we demonstrate the existence of topological states in a new
collective dynamics model. This individual-based model (IBM) describes
self-propelled rigid bodies moving with constant speed and adjusting their
rigid-body attitude to that of their neighbors. In previous works, a
macroscopic model has been derived from this IBM in a suitable scaling limit.
In the present work, we exhibit explicit solutions of the macroscopic model
characterized by a non-trivial topology. We show that these solutions are well
approximated by the IBM during a certain time but then the IBM transitions
towards topologically trivial states. Using a set of appropriately defined
topological indicators, we reveal that the breakage of the non-trivial topology
requires the system to go through a phase of maximal disorder. We also show
that similar but topologically trivial initial conditions result in markedly
different dynamics, suggesting that topology plays a key role in the dynamics
of this system.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:02:54 GMT""},{""version"":""v2"",""created"":""Fri, 21 Jan 2022 21:17:42 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 19:45:37 GMT""}]","2022-01-28"
"2101.10865","Jonathan Spring","Jonathan M. Spring and April Galyardt and Allen D. Householder and
  Nathan VanHoudnos","On managing vulnerabilities in AI/ML systems","16 pages. New Security Paradigms Workshop",,"10.1145/3442167.3442177",,"cs.CR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores how the current paradigm of vulnerability management
might adapt to include machine learning systems through a thought experiment:
what if flaws in machine learning (ML) were assigned Common Vulnerabilities and
Exposures (CVE) identifiers (CVE-IDs)? We consider both ML algorithms and model
objects. The hypothetical scenario is structured around exploring the changes
to the six areas of vulnerability management: discovery, report intake,
analysis, coordination, disclosure, and response. While algorithm flaws are
well-known in the academic research community, there is no apparent clear line
of communication between this research community and the operational
communities that deploy and manage systems that use ML. The thought experiments
identify some ways in which CVE-IDs may establish some useful lines of
communication between these two communities. In particular, it would start to
introduce the research community to operational security concepts, which
appears to be a gap left by existing efforts.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:59:44 GMT""}]","2021-01-27"
"2101.10866","Mohammad Javad Shabanpour","Fardin Ghorbani, Sina Beyraghi, Javad Shabanpour, Homayoon Oraizi,
  Hossein Soleimani, Mohammad Soleimani","Deep neural network-based automatic metasurface design with a wide
  frequency range",,,,,"eess.SP cs.SY eess.SY physics.app-ph physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Beyond the scope of conventional metasurface which necessitates plenty of
computational resources and time, an inverse design approach using machine
learning algorithms promises an effective way for metasurfaces design. In this
paper, benefiting from Deep Neural Network (DNN), an inverse design procedure
of a metasurface in an ultra-wide working frequency band is presented where the
output unit cell structure can be directly computed by a specified design
target. To reach the highest working frequency, for training the DNN, we
consider 8 ring-shaped patterns to generate resonant notches at a wide range of
working frequencies from 4 to 45 GHz. We propose two network architectures. In
one architecture, we restricted the output of the DNN, so the network can only
generate the metasurface structure from the input of 8 ring-shaped patterns.
This approach drastically reduces the computational time, while keeping the
network's accuracy above 91\%. We show that our model based on DNN can
satisfactorily generate the output metasurface structure with an average
accuracy of over 90\% in both network architectures. Determination of the
metasurface structure directly without time-consuming optimization procedures,
having an ultra-wide working frequency, and high average accuracy equip an
inspiring platform for engineering projects without the need for complex
electromagnetic theory.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:15:51 GMT""}]","2021-01-27"
"2101.10867","William Leeb","William Leeb","On the robustness of certain norms",,,,,"math.FA cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a family of norms defined for functions on an interval. These norms
are obtained by taking the $p$-norm of the Volterra operator applied to the
function. The corresponding distances have been previously studied in the
context of comparing probability measures, and special cases include the Earth
Mover's Distance and Kolmogorov Metric. We study their properties for general
signals, and show that they are robust to additive noise. We also show that the
norm-induced distance between a function and its perturbation is bounded by the
size of the perturbation, and that the distance between one-dimensional
projections of a two-dimensional function is bounded by the size of the
difference in projection directions. The results are illustrated in numerical
experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:53:11 GMT""}]","2021-01-27"
"2101.10868","Jiaqi Wang","Jiaqi Wang","An In-depth Review of Privacy Concerns Raised by the COVID-19 Pandemic",,,,,"cs.CR cs.SI","http://creativecommons.org/licenses/by/4.0/","  COVID-19 has hugely changed our lives, work, and interactions with people.
With more and more online activities, people are easily exposed to privacy
threats. In this paper, we explore how users self-disclose on social media and
privacy concerns raised from these behaviors. Based on recent news, techniques,
and research, we indicate three increasing privacy threats caused by the
COVID-19 pandemic. After that, we provide a systematic analysis of potential
privacy issues related to the COVID pandemic. Furthermore, we propose a series
of research directions about online user self-disclosure and privacy issues for
future work as well as possible solutions.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 06:58:40 GMT""}]","2021-01-27"
"2101.10869","Navjodh Singh Dhillon","Navjodh Singh Dhillon, Agustinus Sutandi, Manoj Vishwanath, Miranda M.
  Lim, Hung Cao, Dong Si","A Raspberry Pi-based Traumatic Brain Injury Detection System for
  Single-Channel Electroencephalogram","12 pages, 6 figures",,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by/4.0/","  Traumatic Brain Injury (TBI) is a common cause of death and disability.
However, existing tools for TBI diagnosis are either subjective or require
extensive clinical setup and expertise. The increasing affordability and
reduction in size of relatively high-performance computing systems combined
with promising results from TBI related machine learning research make it
possible to create compact and portable systems for early detection of TBI.
This work describes a Raspberry Pi based portable, real-time data acquisition,
and automated processing system that uses machine learning to efficiently
identify TBI and automatically score sleep stages from a single-channel
Electroen-cephalogram (EEG) signal. We discuss the design, implementation, and
verification of the system that can digitize EEG signal using an Analog to
Digital Converter (ADC) and perform real-time signal classification to detect
the presence of mild TBI (mTBI). We utilize Convolutional Neural Networks (CNN)
and XGBoost based predictive models to evaluate the performance and demonstrate
the versatility of the system to operate with multiple types of predictive
models. We achieve a peak classification accuracy of more than 90% with a
classification time of less than 1 s across 16 s - 64 s epochs for TBI vs
control conditions. This work can enable development of systems suitable for
field use without requiring specialized medical equipment for early TBI
detection applications and TBI research. Further, this work opens avenues to
implement connected, real-time TBI related health and wellness monitoring
systems.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 09:49:33 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jan 2021 06:26:14 GMT""}]","2021-02-01"
"2101.10870","Florenc Demrozi Dr.","Florenc Demrozi, Cristian Turetta, Graziano Pravadelli","B-HAR: an open-source baseline framework for in depth study of human
  activity recognition datasets and workflows","9 Pages, 3 Figures, 3 Tables, Link to B-HAR Library:
  https://github.com/B-HAR-HumanActivityRecognition/B-HAR",,,,"eess.SP cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human Activity Recognition (HAR), based on machine and deep learning
algorithms is considered one of the most promising technologies to monitor
professional and daily life activities for different categories of people
(e.g., athletes, elderly, kids, employers) in order to provide a variety of
services related, for example to well-being, empowering of technical
performances, prevention of risky situation, and educational purposes. However,
the analysis of the effectiveness and the efficiency of HAR methodologies
suffers from the lack of a standard workflow, which might represent the
baseline for the estimation of the quality of the developed pattern recognition
models. This makes the comparison among different approaches a challenging
task. In addition, researchers can make mistakes that, when not detected,
definitely affect the achieved results. To mitigate such issues, this paper
proposes an open-source automatic and highly configurable framework, named
B-HAR, for the definition, standardization, and development of a baseline
framework in order to evaluate and compare HAR methodologies. It implements the
most popular data processing methods for data preparation and the most commonly
used machine and deep learning pattern recognition models.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:42:41 GMT""}]","2021-01-27"
"2101.10881","Jan Verschelde","Jan Verschelde","Accelerated Polynomial Evaluation and Differentiation at Power Series in
  Multiple Double Precision","Improved the introduction, adding two citations to related work;
  fixed error, added table on the fluctuations of wall clock times. To appear
  in the Proceedings of the 2021 IEEE International Parallel and Distributed
  Processing Symposium Workshops (IPDPSW)",,,,"cs.MS cs.DC cs.NA cs.SC math.AG math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem is to evaluate a polynomial in several variables and its gradient
at a power series truncated to some finite degree with multiple double
precision arithmetic. To compensate for the cost overhead of multiple double
precision and power series arithmetic, data parallel algorithms for general
purpose graphics processing units are presented. The reverse mode of
algorithmic differentiation is organized into a massively parallel computation
of many convolutions and additions of truncated power series. Experimental
results demonstrate that teraflop performance is obtained in deca double
precision with power series truncated at degree 152. The algorithms scale well
for increasing precision and increasing degrees.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:42:43 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 16:14:34 GMT""},{""version"":""v3"",""created"":""Sat, 13 Mar 2021 00:22:10 GMT""}]","2021-03-16"
"2101.10907","Stephen Wolfram","Stephen Wolfram","Exploring Rulial Space: The Case of Turing Machines",,,,,"cs.DM cs.CC cs.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As an example of the concept of rulial space, we explore the case of simple
Turing machines. We construct the rulial multiway graph which represents the
behavior of all possible Turing machines with a certain class of rules. This
graph (which is a Cayley graph of a ""Turing machine group"") gives a map of the
space of non-deterministic Turing machines. We investigate the subgraph formed
by deterministic machines, and explore the relationship to the P vs. NP
problem. We also consider the implications of features of rulial space for
physics, including estimating the maximum speed \r{ho} in rulial space,
relations between rulial black holes and computational reducibility, and
interpretations of hypercomputation.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 21:10:49 GMT""}]","2021-01-27"
"2101.11106","Murphy E. Egwe","N.O. Okeke and M.E. Egwe","Groupoid approach to the dynamical system of commutative von Neumann
  Algebras","36. arXiv admin note: substantial text overlap with arXiv:2101.08159",,,,"math.DS math.FA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automorphism group $Aut(X,\mu)$ of a compact, complete metric space $X$
with a Radon measure $\mu$ is a subgroup of $\mathcal{U}(L^2(X,\mu))$-the
unitary group of operators on $L^2(X,\mu)$. The $Aut(X,\mu)$-action on the
generalized space $\mathcal{M}(X)$ is a proper action. Hence, there exists a
slice at each point of the generalized space $\mathcal{M}(X)$. Measure Groupoid
(virtual group) is subsequently employed to analyze the resulting dynamical
system as that of the ergodic action of the commutative algebra (a lattice)
$C(X)$ on the generalized space $\mathcal{M}(X)$ which is represented on a
commutative von Neumann algebra.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 12:06:08 GMT""}]","2021-01-28"
"2101.11713","Loris Nanni","Loris Nanni, Alessandra Lumini and Sheryl Brahnam","Neural networks for Anatomical Therapeutic Chemical (ATC) classification",,,,,"q-bio.QM cs.LG","http://creativecommons.org/licenses/by/4.0/","  Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification is
a critical and highly competitive area of research in bioinformatics because of
its potential for expediting drug develop-ment and research. Predicting an
unknown compound's therapeutic and chemical characteristics ac-cording to how
these characteristics affect multiple organs/systems makes automatic ATC
classifica-tion a challenging multi-label problem. Results: In this work, we
propose combining multiple multi-label classifiers trained on distinct sets of
features, including sets extracted from a Bidirectional Long Short-Term Memory
Network (BiLSTM). Experiments demonstrate the power of this approach, which is
shown to outperform the best methods reported in the literature, including the
state-of-the-art developed by the fast.ai research group. Availability: All
source code developed for this study is available at
https://github.com/LorisNanni. Contact: loris.nanni@unipd.it
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 19:49:47 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 23:06:44 GMT""},{""version"":""v3"",""created"":""Thu, 5 Aug 2021 22:23:46 GMT""}]","2021-08-09"
"2101.12016","Peter Bajcsy","Peter Bajcsy and Michael Majurski","Baseline Pruning-Based Approach to Trojan Detection in Neural Networks","The funding for all authors was provided by IARPA:
  IARPA-20001-D2020-2007180011",,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  This paper addresses the problem of detecting trojans in neural networks
(NNs) by analyzing systematically pruned NN models. Our pruning-based approach
consists of three main steps. First, detect any deviations from the reference
look-up tables of model file sizes and model graphs. Next, measure the accuracy
of a set of systematically pruned NN models following multiple pruning schemas.
Finally, classify a NN model as clean or poisoned by applying a mapping between
accuracy measurements and NN model labels. This work outlines a theoretical and
experimental framework for finding the optimal mapping over a large search
space of pruning parameters. Based on our experiments using Round 1 and Round 2
TrojAI Challenge datasets, the approach achieves average classification
accuracy of 69.73 % and 82.41% respectively with an average processing time of
less than 60 s per model. For both datasets random guessing would produce 50%
classification accuracy. Reference model graphs and source code are available
from GitHub.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 23:10:31 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 14:58:21 GMT""}]","2021-02-10"
"2102.00822","Xiaolong Wu","Xiaolong Wu","On zeros of the Riemann zeta function","13 pages",,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper shows that, in the critical strip, the Riemann zeta function
$\zeta(s)$ have the same set of zeros as $F(s):=\int_0^\infty
t^{s-1}(e^t+1)^{-1}dt$, and then discusses the behavior of $F(s)$.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 00:19:32 GMT""}]","2021-02-02"
"2102.04221","John Richards","Bran Knowles and John T. Richards","The Sanction of Authority: Promoting Public Trust in AI",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trusted AI literature to date has focused on the trust needs of users who
knowingly interact with discrete AIs. Conspicuously absent from the literature
is a rigorous treatment of public trust in AI. We argue that public distrust of
AI originates from the under-development of a regulatory ecosystem that would
guarantee the trustworthiness of the AIs that pervade society. Drawing from
structuration theory and literature on institutional trust, we offer a model of
public trust in AI that differs starkly from models driving Trusted AI efforts.
This model provides a theoretical scaffolding for Trusted AI research which
underscores the need to develop nothing less than a comprehensive and visibly
functioning regulatory ecosystem. We elaborate the pivotal role of externally
auditable AI documentation within this model and the work to be done to ensure
it is effective, and outline a number of actions that would promote public
trust in AI. We discuss how existing efforts to develop AI documentation within
organizations -- both to inform potential adopters of AI components and support
the deliberations of risk and ethics review boards -- is necessary but
insufficient assurance of the trustworthiness of AI. We argue that being
accountable to the public in ways that earn their trust, through elaborating
rules for AI and developing resources for enforcing these rules, is what will
ultimately make AI trustworthy enough to be woven into the fabric of our
society.
","[{""version"":""v1"",""created"":""Fri, 22 Jan 2021 22:01:30 GMT""}]","2021-02-09"
"2102.04304","Nipun Aggarwal Mr.","Nipun Aggarwal, Sanjay Kumar","Identifying Influential Nodes in Weighted Networks using k-shell based
  HookeRank Algorithm",,,,,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Finding influential spreaders is a crucial task in the field of network
analysis because of numerous theoretical and practical importance. These nodes
play vital roles in the information diffusion process, like viral marketing.
Many real-life networks are weighted networks, but relatively less work has
been done for finding influential nodes in the case of weighted networks as
compared to unweighted networks. In this paper, we propose a k-shell-based
HookeRank (KSHR) algorithm to identify spreaders in weighted networks. First,
we propose weighted k-shell centrality of the node u by using the k-shell value
of $u$, the k-shell value of its neighbors ($v$), and edge weight ($w_{uv}$)
between them. We model edges present in the network as springs and edge weights
as spring constants. Based on the notion of Hooke's law of elasticity, we
assume a force equal to the weighted k-shell value acts on each node. In this
arrangement, we formulate the KSHR centrality of each node using associated
weighted k-shell value and the equivalent edge weight by taking care of series
and parallel combination of edges up to 3-hop neighbors from the source node.
The proposed algorithm finds influential nodes that can spread the information
to the maximum number of nodes in the network. We compare our proposed
algorithm with popular existing algorithms and observe that it outperforms them
on many real-life and synthetic networks suing Susceptible-Infected-Recovered
(SIR) information diffusion model.
","[{""version"":""v1"",""created"":""Sat, 23 Jan 2021 07:34:01 GMT""}]","2021-02-09"

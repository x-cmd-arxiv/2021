"2101.12660","Michele Maggiore","Andreas Finke, Stefano Foffa, Francesco Iacovelli, Michele Maggiore
  and Michele Mancarella","Cosmology with LIGO/Virgo dark sirens: Hubble parameter and modified
  gravitational wave propagation","v2: several significant technical improvements, results changed v3:
  minor changes, Fig 9 added. The version to appear in JCAP",,"10.1088/1475-7516/2021/08/026",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed study of the methodology for correlating `dark sirens'
(compact binaries coalescences without electromagnetic counterpart) with galaxy
catalogs. We propose several improvements on the current state of the art, and
we apply them to the GWTC-2 catalog of LIGO/Virgo gravitational wave (GW)
detections, and the GLADE galaxy catalog, performing a detailed study of
several sources of systematic errors that, with the expected increase in
statistics, will eventually become the dominant limitation. We provide a
measurement of $H_0$ from dark sirens alone, finding as the best result
$H_0=67.3^{+27.6}_{-17.9}\,\,{\rm km}\, {\rm s}^{-1}\, {\rm Mpc}^{-1}$ ($68\%$
c.l.) which is, currently, the most stringent constraint obtained using only
dark sirens. Combining dark sirens with the counterpart for GW170817 we find
$H_0= 72.2^{+13.9}_{-7.5} \,{\rm km}\, {\rm s}^{-1}\, {\rm Mpc}^{-1}$.
  We also study modified GW propagation, which is a smoking gun of dark energy
and modifications of gravity at cosmological scales, and we show that current
observations of dark sirens already start to provide interesting limits. From
dark sirens alone, our best result for the parameter $\Xi_0$ that measures
deviations from GR (with $\Xi_0=1$ in GR) is $\Xi_0=2.1^{+3.2}_{-1.2}$. We
finally discuss limits on modified GW propagation under the tentative
identification of the flare ZTF19abanrhr as the electromagnetic counterpart of
the binary black hole coalescence GW190521, in which case our most stringent
result is $\Xi_0=1.8^{+0.9}_{-0.6}$.
  We release the publicly available code $\tt{DarkSirensStat}$, which is
available under open source license at
\url{https://github.com/CosmoStatGW/DarkSirensStat}.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:05:28 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 10:18:55 GMT""},{""version"":""v3"",""created"":""Fri, 16 Jul 2021 13:15:57 GMT""}]","2021-08-25"
"2101.12661","Alexandr Pimikov","S. V. Mikhailov, A. V. Pimikov, N. G. Stefanis","Extending the application of the LCSR method to low momenta using QCD
  renormalization-group summation. Theory and phenomenology","15 pages, 3 figures, 1 table, [v3] reformatted in two-column style,
  15 pages; references added, typos corrected, [v4] minor corrections","Phys. Rev. D 103, 096003 (2021)","10.1103/PhysRevD.103.096003","RUB-TPII-01/2021","hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that using renormalization-group summation to generate the QCD
radiative corrections to the $\pi-\gamma$ transition form factor, calculated
with lightcone sum rules (LCSR), renders the strong coupling free of Landau
singularities while preserving the QCD form-factor asymptotics. This enables a
reliable applicability of the LCSR method to momenta well below 1 GeV$^2$. This
way, one can use the new preliminary BESIII data with unprecedented accuracy
below 1.5 GeV$^2$ to fine tune the prefactor of the twist-six contribution.
Using a combined fit to all available data below 3.1 GeV$^2$, we are able to
determine all nonperturbative scale parameters and a few Gegenbauer
coefficients entering the calculation of the form factor. Employing these
ingredients, we determine a pion distribution amplitude with conformal
coefficients $(b_2,b_4)$ that agree at the $1\sigma$ level with the data for
$Q^2 \leqslant 3.1$ GeV$^2$ and fulfill at the same time the lattice
constraints on $b_2$ at N$^3$LO together with the constraints from QCD sum
rules with nonlocal condensates.The form-factor prediction calculated herewith
reproduces the data below 1 GeV$^2$ significantly better than analogous
predictions based on a fixed-order power-series expansion in the strong
coupling constant.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:06:28 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 14:47:08 GMT""},{""version"":""v3"",""created"":""Wed, 17 Feb 2021 12:56:37 GMT""},{""version"":""v4"",""created"":""Sun, 16 May 2021 08:49:27 GMT""}]","2021-05-18"
"2101.12662","Eike Fokken","Eike Fokken, Simone G\""ottlich","On the relation of powerflow and Telegrapher's equations: continuous and
  numerical Lyapunov stability","20 pages, 6 figures",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution we analyze the exponential stability of power networks
modeled with the Telegrapher's equations as a system of balance laws on the
edges. We show the equivalence of periodic solutions of these Telegrapher's
equations and solutions to the well-established powerflow equations. In
addition we provide a second-order accurate numerical scheme to integrate the
powerflow equations and show (up to the boundary conditions) Lyapunov stability
of the scheme.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:08:17 GMT""}]","2021-02-01"
"2101.12663","Pok Man Lo","Pok Man Lo, Krzysztof Redlich, Chihiro Sasaki","Fluctuations of order parameter in an $SU(N_c)$ effective model","15 pages, 6 figures, typos. corrected, version appear in PRD","Phys. Rev. D 103, 074026 (2021)","10.1103/PhysRevD.103.074026",,"hep-ph hep-lat hep-th nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate features of the deconfinement phase transition in an $SU(N_c)$
gauge theory as revealed by fluctuations of the order parameter. The tool of
choice is an effective model built from one-loop expressions of the field
determinants of gluon and ghost, in the presence of a Polyakov loop background
field. We show that the curvature masses associated with the Cartan angles,
which serve as a proxy to study the $A_0$-gluon screening mass, show a
characteristic dip in the vicinity of the transition temperature. The strength
of the observables, which reflects a competition between the confining and the
deconfining forces, is sensitive to assumptions of dynamics, thus provides an
interesting link between the $Z(N_c)$ vacuum structure and the properties of
gluon and ghost propagators.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:10:03 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 15:04:38 GMT""}]","2021-05-05"
"2101.12664","Elena Berardini","Elena Berardini and Alejandro J. Giangreco Maidana","Weil polynomials of abelian varieties over finite fields with many
  rational points","13 pages, title has changed, minor changes, comments are welcome",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the finite set of isogeny classes of $g$-dimensional abelian
varieties defined over the finite field $\mathbb{F}_q$ with endomorphism
algebra being a field. We prove that the class within this set whose varieties
have maximal number of rational points is unique, for any prime even power $q$
big enough and verifying mild conditions. We describe its Weil polynomial and
we prove that the class is ordinary and cyclic outside the primes dividing an
integer that only depends on $g$. In dimension $3$, we prove that the class is
ordinary and cyclic and give explicitly its Weil polynomial, for any prime even
power $q$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:11:57 GMT""},{""version"":""v2"",""created"":""Thu, 23 Dec 2021 10:45:11 GMT""}]","2021-12-24"
"2101.12665","Thomas Koerber","Michael Eichmair and Thomas Koerber","Large area-constrained Willmore surfaces in asymptotically Schwarzschild
  3-manifolds","Final version to appear in J. Differential Geom",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We apply the method of Lyapunov-Schmidt reduction to study large
area-constrained Willmore surfaces in Riemannian 3-manifolds asymptotic to
Schwarzschild. In particular, we prove that the end of such a manifold is
foliated by distinguished area-constrained Willmore spheres. The leaves are the
unique area-constrained Willmore spheres with large area, non-negative Hawking
mass, and distance to the center of the manifold at least a small multiple of
the area radius. Unlike previous related work, we only require that the scalar
curvature satisfies mild asymptotic conditions. We also give explicit examples
to show that these conditions on the scalar curvature are necessary.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:12:59 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 14:28:25 GMT""}]","2022-06-14"
"2101.12666","Feng Xu","Feng Xu and Matthew W. Morency and Sergiy A. Vorobyov","DOA Estimation for Transmit Beamspace MIMO Radar via Tensor
  Decomposition with Vandermonde Factor Matrix","14 pages, 9 figures, submitted to IEEE Transactions on Signal
  Processing",,"10.1109/TSP.2022.3176092",,"cs.IT eess.SP math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  We address the problem of tensor decomposition in application to
direction-of-arrival (DOA) estimation for transmit beamspace (TB)
multiple-input multiple-output (MIMO) radar. A general 4-order tensor model
that enables computationally efficient DOA estimation is designed. Whereas
other tensor decomposition-based methods treat all factor matrices as
arbitrary, the essence of the proposed DOA estimation method is to fully
exploit the Vandermonde structure of the factor matrices to take advantage of
the shift-invariance between and within different subarrays. Specifically, the
received signal of TB MIMO radar is expressed as a 4-order tensor. Depending on
the target Doppler shifts, the constructed tensor is reshaped into two distinct
3-order tensors. A computationally efficient tensor decomposition method is
proposed to decompose the Vandermonde factor matrices. The generators of the
Vandermonde factor matrices are computed to estimate the phase rotations
between subarrays, which can be utilized as a look-up table for finding target
DOA. It is further shown that our proposed method can be used in a more general
scenario where the subarray structures can be arbitrary but identical. The
proposed DOA estimation method requires no prior information about the tensor
rank and is guaranteed to achieve precise decomposition result. Simulation
results illustrate the performance improvement of the proposed DOA estimation
method as compared to conventional DOA estimation techniques for TB MIMO Radar.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:13:16 GMT""}]","2022-06-29"
"2101.12667","Cl\'emence Fontanive","Cl\'emence Fontanive and Daniella Bardalez Gagliuffi","The Census of Exoplanets in Visual Binaries: population trends from a
  volume-limited Gaia DR2 and literature search","Accepted for publication in Frontiers in Astronomy and Space
  Sciences: Exoplanets, 26 pages, 10 figures",,,,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present an extensive search in the literature and Gaia DR2 for visual
co-moving binary companions to stars hosting exoplanets and brown dwarfs within
200 pc. We found 218 planet hosts out of 938 to be part of multiple-star
systems, with 10 newly discovered binaries and 2 new tertiary stellar
components. This represents an overall raw multiplicity rate of 23.2$\pm$1.6%
for hosts to exoplanets across all spectral types, with multi-planet systems
found to have a lower duplicity frequency at the 2.2$\sigma$ level. We found
that more massive hosts are more often in binary configurations, and that
planet-bearing stars in multiple systems are predominantly the most massive
component of stellar binaries. Investigations of multiplicity as a function of
planet mass and separation revealed that giant planets with masses >0.1 MJup
are more frequently seen in stellar binaries than small sub-Jovian planets with
a 3.6$\sigma$ difference, a trend enhanced for the most massive (>7 MJup)
short-period (<0.5 AU) planets and brown dwarf companions. Binarity was found
to have no significant effect on the demographics of low-mass planets (<0.1
MJup) or warm and cool gas giants (>0.5 AU). While stellar companion mass
appears to have no impact on planet properties, binary separation seems to be
an important factor in the resulting structure of planetary systems. Stellar
companions on separations <1000 AU can play a role in the formation or
evolution of massive close-in planets, while planets in wider binaries show
similar properties to planets orbiting single stars. Finally, numerous stellar
companions on separations <1-3 arcsec likely remain undiscovered to this date.
Continuous efforts to complete our knowledge of stellar multiplicity on
separations of tens to hundreds of AU are essential to confirm the reported
trends and further our understanding of the roles played by multiplicity on
exoplanets.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:14:17 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 21:35:26 GMT""},{""version"":""v3"",""created"":""Tue, 11 May 2021 14:00:23 GMT""}]","2021-05-12"
"2101.12668","Gurtej Kanwar","William Detmold, Gurtej Kanwar, Henry Lamm, Michael L. Wagman, Neill
  C. Warrington","Path integral contour deformations for observables in $SU(N)$ gauge
  theory","25 pages, 12 figures","Phys. Rev. D 103, 094517 (2021)","10.1103/PhysRevD.103.094517","FERMILAB-PUB-21-014-T, INT-PUB-21-002, MIT-CTP/5270","hep-lat cond-mat.stat-mech nucl-th","http://creativecommons.org/licenses/by/4.0/","  Path integral contour deformations have been shown to mitigate sign and
signal-to-noise problems associated with phase fluctuations in lattice field
theories. We define a family of contour deformations applicable to $SU(N)$
lattice gauge theory that can reduce sign and signal-to-noise problems
associated with complex actions and complex observables. For observables, these
contours can be used to define deformed observables with identical expectation
value but different variance. As a proof-of-principle, we apply machine
learning techniques to optimize the deformed observables associated with Wilson
loops in two dimensional $SU(2)$ and $SU(3)$ gauge theory. We study loops
consisting of up to 64 plaquettes and achieve variance reduction of up to 4
orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:14:50 GMT""}]","2021-06-02"
"2101.12669","Van Cyr","Van Cyr and Bryna Kra","Characteristic measures for language stable subshifts",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of when a symbolic dynamical system supports a Borel
probability measure that is invariant under every element of its automorphism
group. It follows readily from a classical result of Parry that the full shift
on finitely many symbols, and more generally any mixing subshift of finite
type, supports such a measure. Frisch and Tamuz recently dubbed such measures
characteristic, and further showed that every zero entropy subshift has a
characteristic measure. While it remains open if every subshift over a finite
alphabet has a characteristic measure, we define a new class of shifts, which
we call language stable subshifts, and show that these shifts have
characteristic measures. This is a large class that is generic in several
senses and contains numerous positive entropy examples.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:14:52 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 16:04:59 GMT""}]","2021-06-25"
"2101.12670","Pawel Nurowski","Pawel Nurowski","Radiative Poincare type eon and its follower","In ver 2, a remark about the convergence of the power series was
  added. Also some styllistic changes were made",,,,"gr-qc math.DG","http://creativecommons.org/licenses/by/4.0/","  We consider two consecutive eons $\hat{M}$ and $\check{M}$ from Penrose's
Conformal Cyclic Cosmology and study how the matter content of the past eon
($\hat{M}$) determines the matter content of the present eon ($\check{M}$) by
means of the reciprocity hypothesis. We assume that the only matter content in
the final stages of the past eon is a spherical wave described by Einstein's
equations with the pure radiation energy momentum tensor $$\hat{T}^{ij} =
\hat{\Phi}K^iK^j, \quad \hat{g}_{ij} K^iK^j = 0,$$ and with cosmological
constant $\hat{\Lambda}$ . We solve these Einstein's equations associating to
$\hat{M}$ the metric $\hat{g}=t^{-2}\big(-d t^2+h_t\big)$, which is a
Lorentzian analog of the Poincar\'e-Einstein metric known from the theory of
conformal invariants. The solution is obtained under the assumption that the
3-dimensional conformal structure $[h]$ on the $\mathscr{I}^+$ of $\hat{M}$ is
flat, that the metric $\hat{g}$ admits a power series expansion in the time
variable $t$, and that $h_0\in [h]$. Such solution depends on one real
arbitrary function of the radial variable $r$. Applying the reciprocal
hypothesis, $\hat{g}\to \check{g}=t^4\hat{g}$, we show that the new eon
$(\check{M},\check{g})$ created from the one containing a single spherical
wave, is filled at its initial state with three types of radiation: (i) the
damped spherical wave which continues its life from the previous eon, (ii) the
in-going spherical wave obtained as a result of a collision of the wave from
the past eon with the Bang hypersurface and (3) randomly scattered waves that
could be interpreted as perfect fluid with the energy density $\check{\rho}$
and the isotropic pressure $\check{p}$ such that
$\check{p}=\tfrac13\check{\rho}$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:14:57 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 03:30:45 GMT""}]","2021-02-23"
"2101.12671","David J. Aldous","David J. Aldous","Covering a compact space by fixed-radius or growing random balls","16 pages",,,,"math.PR math.MG","http://creativecommons.org/licenses/by/4.0/","  Simple random coverage models, well studied in Euclidean space, can also be
defined on a general compact metric space. By analogy with the geometric
models, and with the discrete coupon collector's problem and with cover times
for finite Markov chains, one expects a ""weak concentration"" bound for the
distribution of the cover time to hold under minimal assumptions. We give two
such results, one for random fixed-radius balls and the other for sequentially
arriving randomly-centered and deterministically growing balls. Each is in fact
a simple application of a different more general bound, the former concerning
coverage by i.i.d. random sets with arbitrary distribution, and the latter
concerning hitting times for Markov chains with a strong monotonicity property.
The growth model seems generally more tractable, and we record some basic
results and open problems for that model.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:16:21 GMT""}]","2021-02-01"
"2101.12672","Nguyen Thanh Chinh","Thanh Chinh Nguyen, Van Nha Nguyen","NLPBK at VLSP-2020 shared task: Compose transformer pretrained models
  for Reliable Intelligence Identification on Social network","5 pages, 2 figures",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes our method for tuning a transformer-based pretrained
model, to adaptation with Reliable Intelligence Identification on Vietnamese
SNSs problem. We also proposed a model that combines bert-base pretrained
models with some metadata features, such as the number of comments, number of
likes, images of SNS documents,... to improved results for VLSP shared task:
Reliable Intelligence Identification on Vietnamese SNSs. With appropriate
training techniques, our model is able to achieve 0.9392 ROC-AUC on public test
set and the final version settles at top 2 ROC-AUC (0.9513) on private test
set.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:19:28 GMT""}]","2021-02-01"
"2101.12673","Ya-Chun Liang","Ya-Chun Liang, Chung-Shou Liao and Xinping Yi","Topological Interference Management with Adversarial Topology
  Perturbation: An Algorithmic Perspective",,,"10.1109/ISIT45174.2021.9518022",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the topological interference management (TIM)
problem in a dynamic setting, where an adversary perturbs network topology to
prevent the exploitation of sophisticated coding opportunities (e.g.,
interference alignment). Focusing on a special class of network topology -
chordal networks - we investigate algorithmic aspects of the TIM problem under
adversarial topology perturbation. In particular, given the adversarial
perturbation with respect to edge insertion/deletion, we propose a dynamic
graph coloring algorithm that allows for a constant number of re-coloring
updates against each inserted/deleted edge to achieve the information-theoretic
optimality. This is a sharp reduction of the general graph re-coloring, whose
optimal number of updates scales as the size of the network, thanks to the
delicate exploitation of the structural properties of chordal graph classes.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:27:45 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 14:07:38 GMT""}]","2022-06-09"
"2101.12674","Darshana Wickramaratne","Darshana Wickramaratne, Menashe Haim, Maxim Khodas, I.I. Mazin","Magnetism-driven unconventional effects in Ising superconductors: role
  of proximity, tunneling, and nematicity",,"Phys. Rev. B 104, 060501 (2021)","10.1103/PhysRevB.104.L060501",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Hybrid Ising superconductor-ferromagnetic insulator heterostructures provide
a unique opportunity to explore the interplay between proximity-induced
magnetism, spin-orbit coupling and superconductivity. Here we use a combination
of first-principles calculations of NbSe$_{2}$/CrBr$_{3}$ heterostructures and
an analytical theory of Ising superconductivity to analyze the existing
experiments and provide a complete explanation of highly nontrivial and largely
counterintuitive effects: an increase in the magnitude of the superconducting
gap accompanied by the broadening of the tunneling peaks; hysteretic behavior
of the tunneling conductance that sets in $\approx 2$ K below $T_c$; and
nematic symmetry breaking in the superconducting state. The microscopic reason
in all three cases appears to be the interplay between the proximity-induced
exchange splitting and intrinsic defects. Finally, we predict additional
interesting effects that at the moment cannot be addressed experimentally:
spin-filtering when tunneling across CrBr$_{3}$ and tunneling ``hot spots'' in
momentum space that are anticorrelated with regions where the spin-orbit
splitting is maximum.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:28:48 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 18:43:35 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 16:56:55 GMT""}]","2021-08-18"
"2101.12675","Bruno Dinis","Bruno Dinis and Pedro Pinto","Effective metastability for a method of alternating resolvents",,,,,"math.FA math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A generalized method of alternating resolvents was introduced by Boikanyo and
Moro{\c s}anu as a way to approximate common zeros of two maximal monotone
operators. In this paper we analyse the strong convergence of this algorithm
under two different sets of conditions. As a consequence we obtain effective
rates of metastability (in the sense of Terence Tao) and quasi-rates of
asymptotic regularity. Furthermore, we bypass the need for sequential weak
compactness in the original proofs. Our quantitative results are obtained using
proof-theoretical techniques in the context of the proof mining program.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:30:14 GMT""}]","2021-02-01"
"2101.12676","H\'ector Cadavid","H\'ector Cadavid, Vasilios Andrikopoulos, Paris Avgeriou, P. Chris
  Broekema","System- and Software-level Architecting Harmonization Practices for
  Systems-of-Systems -- An exploratory case study on a long-running large-scale
  scientific instrument","Paper accepted for publication at the 18TH IEEE International
  Conference on Software Architecture (ICSA 2021)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problems caused by the gap between system- and software-level
architecting practices, especially in the context of Systems of Systems where
the two disciplines inexorably meet, is a well known issue with a
disappointingly low amount of works in the literature dedicated to it. At the
same time, organizations working on Systems of Systems have been developing
solutions for closing this gap for many years now. This work aims to extract
such knowledge from practitioners by studying the case of a large-scale
scientific instrument, a geographically distributed radio telescope to be more
specific, developed as a sequence of projects during the last two decades. As
the means for collecting data for this study we combine online interviews with
a virtual focus group of practitioners from the organization responsible for
building the instrument. Through this process, we identify persisting problems
and the best practices that have been developed to deal with them, together
with the perceived benefits and drawbacks of applying the latter in practice.
Some of our major findings include the need to avoid over-reliance on the
flexibility of software to compensate for incomplete requirements, hidden
assumptions, as well as late involvement of system architecting, and to
facilitate the cooperation between the involved disciplines through dedicated
architecting roles and the adoption of unifying practices and standards.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:37:41 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 10:25:55 GMT""}]","2021-02-10"
"2101.12677","Benjamin Kiefer","Benjamin Kiefer, Martin Messmer, Andreas Zell","Diminishing Domain Bias by Leveraging Domain Labels in Object Detection
  on UAVs","Accepted for publication at ICAR 2021",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Object detection from Unmanned Aerial Vehicles (UAVs) is of great importance
in many aerial vision-based applications. Despite the great success of generic
object detection methods, a significant performance drop is observed when
applied to images captured by UAVs. This is due to large variations in imaging
conditions, such as varying altitudes, dynamically changing viewing angles, and
different capture times. These variations lead to domain imbalances and, thus,
trained models suffering from domain bias. We demonstrate that domain knowledge
is a valuable source of information and thus propose domain-aware object
detectors by using freely accessible sensor data. By splitting the model into
cross-domain and domain-specific parts, substantial performance improvements
are achieved on multiple data sets across various models and metrics without
changing the architecture. In particular, we achieve a new state-of-the-art
performance on UAVDT for embedded real-time detectors. Furthermore, we create a
new airborne image data set by annotating 13,713 objects in 2,900 images
featuring precise altitude and viewing angle annotations.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:42:52 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 16:19:47 GMT""}]","2021-10-19"
"2101.12678","Hannes K\""ohler","Hannes K\""ohler, Andreas Christmann","Total Stability of SVMs and Localized SVMs","30 pages, 1 figure",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regularized kernel-based methods such as support vector machines (SVMs)
typically depend on the underlying probability measure $\mathrm{P}$
(respectively an empirical measure $\mathrm{D}_n$ in applications) as well as
on the regularization parameter $\lambda$ and the kernel $k$. Whereas classical
statistical robustness only considers the effect of small perturbations in
$\mathrm{P}$, the present paper investigates the influence of simultaneous
slight variations in the whole triple $(\mathrm{P},\lambda,k)$, respectively
$(\mathrm{D}_n,\lambda_n,k)$, on the resulting predictor. Existing results from
the literature are considerably generalized and improved. In order to also make
them applicable to big data, where regular SVMs suffer from their super-linear
computational requirements, we show how our results can be transferred to the
context of localized learning. Here, the effect of slight variations in the
applied regionalization, which might for example stem from changes in
$\mathrm{P}$ respectively $\mathrm{D}_n$, is considered as well.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:44:14 GMT""}]","2021-02-01"
"2101.12679","Marco Palla","Marco Palla","The effects of different Type Ia SN yields on Milky Way chemical
  evolution","17 pages, 15 figures, 4 tables. Accepted for publication in MNRAS",,"10.1093/mnras/stab293",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of different Type Ia SN nucleosynthesis prescriptions on
the Milky Way chemical evolution. To this aim, we run detailed one-infall and
two-infall chemical evolution models, adopting a large compilation of yield
sets corresponding to different white dwarf progenitors (near-Chandrasekar and
sub-Chandrasekar) taken from the literature. We adopt a fixed delay time
distribution function for Type Ia SNe , in order to avoid degeneracies in the
analysis of the different nucleosynthesis channels. We also combine yields for
different Type Ia SN progenitors in order to test the contribution to chemical
evolution of different Type Ia SN channels. The results of the models are
compared with recent LTE and NLTE observational data. We find that ""classical""
W7 and WDD2 models produce Fe masses and [$\alpha$/Fe] abundance patterns
similar to more recent and physical near-Chandrasekar and sub- Chandrasekar
models. For Fe-peak elements, we find that the results strongly depend either
on the white dwarf explosion mechanism (deflagration-to-detonation, pure
deflagration, double detonation) or on the initial white dwarf conditions
(central density, explosion pattern). The comparison of chemical evolution
model results with observations suggests that a combination of
near-Chandrasekar and sub-Chandrasekar yields is necessary to reproduce the
data of V, Cr, Mn and Ni, with different fractions depending on the adopted
massive stars stellar yields. This comparison also suggests that NLTE and
singly ionised abundances should be definitely preferred when dealing with most
of Fe-peak elements at low metallicity.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:45:05 GMT""}]","2021-02-17"
"2101.12680","David Stark","David V. Stark, Karen L. Masters, Vladimir Avila-Reese, Rogemar
  Riffel, Rogerio Riffel, Nicholas Fraser Boardman, Zheng Zheng, Anne-Marie
  Weijmans, Sean Dillon, Catherine Fielder, Daniel Finnegan, Patricia Fofie,
  Julian Goddy, Emily Harrington, Zachary Pace, Wiphu Rujopakarn, Nattida
  Samanso, Shoaib Shamsi, Anubhav Sharma, Elizabeth Warrick, Catherine
  Witherspoon, Nathan Wolthuis","HI-MaNGA: Tracing the physics of the neutral and ionized ISM with the
  second data release","Accepted for publication in MNRAS, 23 pages, 13 figures, catalog
  available at https://greenbankobservatory.org/science/gbt-surveys/hi-manga/",,"10.1093/mnras/stab566",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the second data release for the HI-MaNGA programme of HI follow-up
observations for the SDSS-IV MaNGA survey. This release contains measurements
for 3669 unique galaxies, combining 2108 Green Bank Telescope observations with
an updated crossmatch of the MaNGA sample with the ALFALFA survey. We combine
these data with MaNGA spectroscopic measurements to examine relationships
between HI-to-stellar mass ratio (M_HI/M_*) and average ISM/star formation
properties probed by optical emission lines. M_HI/M_* is very weakly correlated
with the equivalent width of Halpha, implying a loose connection between the
instantaneous star formation rate and the HI reservoir, although the link
between M_HI/M_* and star formation strengthens when averaged even over only
moderate timescales (~30 Myrs). Galaxies with elevated HI depletion times have
enhanced [OI]/Halpha and depressed Halpha surface brightness, consistent with
more HI residing in a diffuse and/or shock heated phase which is less capable
of condensing into molecular clouds. Of all optical lines, M_HI/M_* correlates
most strongly with oxygen equivalent width, EW(O), which is likely a result of
the existing correlation between M_HI/M_* and gas-phase metallicity. Residuals
in the M_HI/M_*-EW(O) relation are again correlated with [OI]/Halpha and Halpha
surface brightness, suggesting they are also driven by variations in the
fraction of diffuse and/or shock-heated gas. We recover the strong
anti-correlation between M_HI/M_* and gas-phase metallicity seen in previous
studies. We also find a relationship between M_HI/M_* and [OI]/Halpha,
suggesting that higher fractions of diffuse and/or shock-heated gas are more
prevalent in gas-rich galaxies.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:46:32 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 16:12:49 GMT""}]","2021-03-17"
"2101.12681","Fengjiang Li","Fengjiang Li","Rigidity of Complete Gradient Steady Ricci Solitons with Harmonic Weyl
  Curvature","27 pages. arXiv admin note: text overlap with arXiv:1604.02827 by
  other authors",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Our main aim in this paper is to investigate the rigidity of complete
noncompact gradient steady Ricci solitons with harmonic Weyl tensor. More
precisely, we prove that an $n$-dimensional ($n\geq 5$) complete noncompact
gradient steady Ricci soliton with harmonic Weyl tensor and multiply warped
product metric is either Ricci flat or isometric to the Bryant soliton up to
scaling. Meanwhile, for $n\ge 5$, we provide a local structure theorem for
$n$-dimensional connected (not necessarily complete) gradient Ricci solitons
with harmonic Weyl curvature and multiply warped product metric.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:51:32 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 11:40:05 GMT""},{""version"":""v3"",""created"":""Wed, 17 May 2023 07:51:33 GMT""}]","2023-05-18"
"2101.12682","Siamak Taati","Nazim Fat\`es and Ir\`ene Marcovici and Siamak Taati","Self-stabilisation of cellular automata on tilings","56 pages, 28 figures","Fundamenta Informaticae, Volume 185, Issue 1 (March 10, 2022)
  fi:9184","10.3233/FI-222103",,"nlin.CG cs.DC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a finite set of local constraints, we seek a cellular automaton (i.e.,
a local and uniform algorithm) that self-stabilises on the configurations that
satisfy these constraints. More precisely, starting from a finite perturbation
of a valid configuration, the cellular automaton must eventually fall back into
the space of valid configurations where it remains still. We allow the cellular
automaton to use extra symbols, but in that case, the extra symbols can also
appear in the initial finite perturbation. For several classes of local
constraints (e.g., $k$-colourings with $k\neq 3$, and North-East deterministic
constraints), we provide efficient self-stabilising cellular automata with or
without additional symbols that wash out finite perturbations in linear or
quadratic time, but also show that there are examples of local constraints for
which the self-stabilisation problem is inherently hard. We note that the
optimal self-stabilisation speed is the same for all local constraints that are
isomorphic to one another. We also consider probabilistic cellular automata
rules and show that in some cases, the use of randomness simplifies the
problem. In the deterministic case, we show that if finite perturbations are
corrected in linear time, then the cellular automaton self-stabilises even
starting from a random perturbation of a valid configuration, that is, when
errors in the initial configuration occur independently with a sufficiently low
density.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:53:01 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 15:57:28 GMT""},{""version"":""v3"",""created"":""Sat, 5 Mar 2022 16:20:38 GMT""}]","2022-03-14"
"2101.12683","Roman Andriushchenko","Roman Andriushchenko, Milan Ceska, Sebastian Junges, Joost-Pieter
  Katoen","Inductive Synthesis for Probabilistic Programs Reaches New Horizons","Full version of TACAS'21 submission",,,,"cs.LO cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel method for the automated synthesis of
probabilistic programs. The starting point is a program sketch representing a
finite family of finite-state Markov chains with related but distinct
topologies, and a PCTL specification. The method builds on a novel inductive
oracle that greedily generates counter-examples (CEs) for violating programs
and uses them to prune the family. These CEs leverage the semantics of the
family in the form of bounds on its best- and worst-case behaviour provided by
a deductive oracle using an MDP abstraction. The method further monitors the
performance of the synthesis and adaptively switches between the inductive and
deductive reasoning. Our experiments demonstrate that the novel CE construction
provides a significantly faster and more effective pruning strategy leading to
acceleration of the synthesis process on a wide range of benchmarks. For
challenging problems, such as the synthesis of decentralized
partially-observable controllers, we reduce the run-time from a day to minutes.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:59:00 GMT""}]","2021-02-01"
"2101.12684","Michel van der Wel","Bart H.L. Overes and Michel van der Wel","Modelling Sovereign Credit Ratings: Evaluating the Accuracy and Driving
  Factors using Machine Learning Techniques",,,,,"q-fin.ST cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sovereign credit ratings summarize the creditworthiness of countries. These
ratings have a large influence on the economy and the yields at which
governments can issue new debt. This paper investigates the use of a Multilayer
Perceptron (MLP), Classification and Regression Trees (CART), Support Vector
Machines (SVM), Na\""ive Bayes (NB), and an Ordered Logit (OL) model for the
prediction of sovereign credit ratings. We show that MLP is best suited for
predicting sovereign credit ratings, with a random cross-validated accuracy of
68%, followed by CART (59%), SVM (41%), NB (38%), and OL (33%). Investigation
of the determining factors shows that there is some heterogeneity in the
important variables across the models. However, the two models with the highest
out-of-sample predictive accuracy, MLP and CART, show a lot of similarities in
the influential variables, with regulatory quality, and GDP per capita as
common important variables. Consistent with economic theory, a higher
regulatory quality and/or GDP per capita are associated with a higher credit
rating.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:06:18 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 09:11:25 GMT""}]","2021-07-16"
"2101.12685","Minghui Xu","Ming H. Xu, Susanne Lunz, James M. Anderson, Tuomas Savolainen,
  Nataliya Zubko and Harald Schuh","Evidence of the $Gaia$--VLBI position differences being related to radio
  source structure","13 pages, 7 figures, and 5 tables. Accepted to be published in
  Astronomy & Astrophysics","A&A 647, A189 (2021)","10.1051/0004-6361/202040168",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We report the relationship between the $Gaia$--VLBI position differences and
the magnitudes of source structure effects in VLBI observations. Because the
$Gaia$--VLBI position differences are statistically significant for a
considerable number of common sources, we attempt to discuss and explain these
position differences based on VLBI observations and available source images at
cm-wavelengths. Based on the derived closure amplitude root-mean-square
(CARMS), which quantifies the magnitudes of source structure effects in the
VLBI observations used for building the third realization of the International
Celestial Reference Frame, the arc lengths and normalized arc lengths of the
position differences are examined in detail. The radio jet directions and the
directions of the $Gaia$--VLBI position differences are investigated for a
small sample of sources. Both the arc lengths and normalized arc lengths of the
$Gaia$ and VLBI positions are found to increase with the CARMS values. The
majority of the sources with statistically significant position differences are
associated with the sources having extended structure. Radio source structure
is the one of the major factors of these position differences, and it can be
the dominate factor for a number of sources. The vectors of the $Gaia$ and VLBI
position differences are parallel to the radio-jet directions, which is
confirmed with stronger evidence.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:07:30 GMT""}]","2021-04-07"
"2101.12686","Gertraud Malsiner-Walli","Bettina Gr\""un, Gertraud Malsiner-Walli, Sylvia Fr\""uhwirth-Schnatter","How many data clusters are in the Galaxy data set? Bayesian cluster
  analysis in action",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  In model-based clustering, the Galaxy data set is often used as a benchmark
data set to study the performance of different modeling approaches. Aitkin
(2001) compares maximum likelihood and Bayesian analyses of the Galaxy data set
and expresses reservations about the Bayesian approach due to the fact that the
prior assumptions imposed remain rather obscure while playing a major role in
the results obtained and conclusions drawn.
  The aim of the paper is to address Aitkin's concerns about the Bayesian
approach by shedding light on how the specified priors influence the number of
estimated clusters. We perform a sensitivity analysis of different prior
specifications for the mixtures of finite mixture model, i.e., the mixture
model where a prior on the number of components is included. We use an
extensive set of different prior specifications in a full factorial design and
assess their impact on the estimated number of clusters for the Galaxy data
set. Results highlight the interaction effects of the prior specifications and
provide insights into which prior specifications are recommended to obtain a
sparse clustering solution. A simulation study with artificial data provides
further empirical evidence to support the recommendations.
  A clear understanding of the impact of the prior specifications removes
restraints preventing the use of Bayesian methods due to the complexity of
selecting suitable priors. Also, the regularizing properties of the priors may
be intentionally exploited to obtain a suitable clustering solution meeting
prior expectations and needs of the application.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:14:39 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 13:58:01 GMT""}]","2021-08-17"
"2101.12687","Todd Eisworth","Todd Eisworth","The Pseudopower Dichotomy","26 pages. Minor revisions to previous version. Submitted to Journal
  of Symbolic Logic",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate pseudopowers of singular cardinals, and show that deduce some
consequences for cardinal arithmetic. For example, we show that in {\sf ZFC}
that
$$\cov(\mu,\mu,\theta,\sigma)=\cov(\mu,\mu,(\cf\mu)^+,\sigma)+\cov(\mu,\mu,\theta,\sigma^+)$$
whenever $\aleph_1\leq\sigma=\cf(\sigma)<\cf(\mu)<\theta<\mu$, and use recent
work of Gitik to show that both summands in the equation are required.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:16:51 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 21:20:00 GMT""}]","2022-12-19"
"2101.12688","Gustav Mogull","Gustav Uhre Jakobsen, Gustav Mogull, Jan Plefka, Jan Steinhoff","Classical Gravitational Bremsstrahlung from a Worldline Quantum Field
  Theory","v3: additional supplementary material; accepted for publication in
  PRL","Phys. Rev. Lett. 126, 201103 (2021)","10.1103/PhysRevLett.126.201103","HU-EP-21/03-RTG","gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the recently established formalism of a worldline quantum field theory
(WQFT) description of the classical scattering of two spinless black holes, we
compute the far-field time-domain waveform of the gravitational waves produced
in the encounter at leading order in the post-Minkowskian (weak field, but
generic velocity) expansion. We reproduce previous results of Kovacs and Thorne
in a highly economic way. Then using the waveform we extract the leading-order
total radiated angular momentum and energy (including differential results).
Our work may enable crucial improvements of gravitational-wave predictions in
the regime of large relative velocities.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:17:17 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 18:53:23 GMT""},{""version"":""v3"",""created"":""Thu, 22 Apr 2021 15:48:02 GMT""}]","2021-05-26"
"2101.12689","Michael L\""onne","Klaus Hulek, Michael L\""onne","Moduli of elliptic $K3$ surfaces: monodromy and Shimada root lattice
  strata","55 pages, appendix by Markus Kirschmer, to appear in Algebraic
  Geometry",,,,"math.AG","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper we investigate two stratifications of the moduli space of
elliptically fibred K3 surfaces. The first comes from Shimada's classification
of connected components of elliptically fibred K3 surfaces and is closely
related to the root lattice of the fibration. The second is the monodromy
stratification defined by Bogomolov, Petrov and Tschinkel. The main result of
the paper is a classification of all positive-dimensional ambi-typical strata,
that is strata which are both Shimada root strata and monodromy strata. We
further discuss the connection with moduli spaces of lattice-polarised K3
surfaces. The paper contains an appendix by M. Kirschmer providing
computational results on the 1-dimensional ambi-typical strata.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:18:33 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 17:45:49 GMT""}]","2021-08-31"
"2101.12690","Theo Costain","Theo W. Costain, Victor Adrian Prisacariu","Towards Generalising Neural Implicit Representations","ECCVW 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural implicit representations have shown substantial improvements in
efficiently storing 3D data, when compared to conventional formats. However,
the focus of existing work has mainly been on storage and subsequent
reconstruction. In this work, we show that training neural representations for
reconstruction tasks alongside conventional tasks can produce more general
encodings that admit equal quality reconstructions to single task training,
whilst improving results on conventional tasks when compared to single task
encodings. We reformulate the semantic segmentation task, creating a more
representative task for implicit representation contexts, and through
multi-task experiments on reconstruction, classification, and segmentation,
show our approach learns feature rich encodings that admit equal performance
for each task.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:20:22 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 14:09:02 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 11:06:55 GMT""}]","2022-10-18"
"2101.12691","Tao Wang","Tao Wang, Xiangrui Yang, Gianni Antichi, Anirudh Sivaraman, Aurojit
  Panda","Isolation mechanisms for high-speed packet-processing pipelines",,"The 19th USENIX Symposium on Networked Systems Design and
  Implementation (NSDI '22), 2022",,,"cs.NI cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-plane programmability is now mainstream. As we find more use cases,
deployments need to be able to run multiple packet-processing modules in a
single device. These are likely to be developed by independent teams, either
within the same organization or from multiple organizations. Therefore, we need
isolation mechanisms to ensure that modules on the same device do not interfere
with each other. This paper presents Menshen, an extension of the
Reconfigurable Match Tables (RMT) pipeline that enforces isolation between
different packet-processing modules. Menshen is comprised of a set of
lightweight hardware primitives and an extension to the open source P4-16
reference compiler that act in conjunction to meet this goal. We have
prototyped Menshen on two FPGA platforms (NetFPGA and Corundum). We show that
our design provides isolation, and allows new modules to be loaded without
impacting the ones already running. Finally, we demonstrate that feasibility of
implementing Menshen on ASICs by using the FreePDK45nm technology library and
the Synopsys DC synthesis software, showing that our design meets timing at a
1GHz clock frequency and needs approximately 6% additional chip area. We have
open sourced the code for Menshen's hardware and software at
https://isolation.quest/.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:21:27 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 20:48:20 GMT""},{""version"":""v3"",""created"":""Fri, 17 Sep 2021 03:45:01 GMT""},{""version"":""v4"",""created"":""Wed, 2 Mar 2022 17:26:01 GMT""}]","2022-04-19"
"2101.12692","Azad Inshalla oglu Ahmadov","A. I. Ahmadov, S. M. Aslanova, M. Sh. Orujova, S. V. Badalov","Analytical bound-state solutions of the Klein-Fock-Gordon equation for
  the sum of Hulth\'en and Yukawa potential within SUSY quantum mechanics","13 pages, 1 figure",,,,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relativistic wave equations determine the dynamics of quantum fields in
the context of quantum field theory. One of the conventional tools for dealing
with the relativistic bound-state problem is the Klein-Fock-Gordon equation. In
this work, using a developed scheme, we present how to surmount the centrifugal
part and solve the modified Klein-Fock-Gordon equation for the linear
combination of Hulth\'en and Yukawa potentials. In particular, we show that the
relativistic energy eigenvalues and corresponding radial wave functions are
obtained from supersymmetric quantum mechanics by applying the shape invariance
concept. Here, both scalar potential conditions, which are whether equal and
non-equal to vector potential, are considered in the calculation. The energy
levels and corresponding normalized eigenfunctions are represented as a
recursion relation regarding the Jacobi polynomials for arbitrary $l$ states.
Beyond that, a closed-form of the normalization constant of the wave functions
is found. Furthermore, we state that the energy eigenvalues are quite sensitive
with potential parameters for the quantum states. The non-relativistic and
relativistic results obtained within SUSY QM overlap entirely with the results
obtained by ordinary quantum mechanics, and it displays that the mathematical
implementation of SUSY quantum mechanics is quite perfect.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:23:13 GMT""}]","2021-02-01"
"2101.12693","Xiaochun Meng","Carol Alexander, Michael Coulon, Yang Han, Xiaochun Meng","Evaluating the Discrimination Ability of Proper Multivariate Scoring
  Rules",,,,,"stat.ME q-fin.ST stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proper scoring rules are commonly applied to quantify the accuracy of
distribution forecasts. Given an observation they assign a scalar score to each
distribution forecast, with the the lowest expected score attributed to the
true distribution. The energy and variogram scores are two rules that have
recently gained some popularity in multivariate settings because their
computation does not require a forecast to have parametric density function and
so they are broadly applicable. Here we conduct a simulation study to compare
the discrimination ability between the energy score and three variogram scores.
Compared with other studies, our simulation design is more realistic because it
is supported by a historical data set containing commodity prices, currencies
and interest rates, and our data generating processes include a diverse
selection of models with different marginal distributions, dependence
structure, and calibration windows. This facilitates a comprehensive comparison
of the performance of proper scoring rules in different settings. To compare
the scores we use three metrics: the mean relative score, error rate and a
generalised discrimination heuristic. Overall, we find that the variogram score
with parameter p=0.5 outperforms the energy score and the other two variogram
scores.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:23:33 GMT""}]","2021-02-01"
"2101.12694","Martin Messmer","Martin Messmer, Benjamin Kiefer, Andreas Zell","Gaining Scale Invariance in UAV Bird's Eye View Object Detection by
  Adaptive Resizing","accepted for publication in ICPR 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This work introduces a new preprocessing step for object detection applicable
to UAV bird's eye view imagery, which we call Adaptive Resizing. By design, it
helps alleviate the challenges coming with the vast variances in objects'
scales, naturally inherent to UAV data sets. Furthermore, it improves inference
speed by two to three times on average. We test this extensively on UAVDT,
VisDrone, and on a new data set we captured ourselves and achieve consistent
improvements while being considerably faster. Moreover, we show how to apply
this method to generic UAV object detection tasks. Additionally, we
successfully test our approach on a height transfer task where we train on some
interval of altitudes and test on a different one. Furthermore, we introduce a
small, fast detector meant for deployment to an embedded GPU. Code will be made
publicly available on our website.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:26:38 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 14:22:27 GMT""}]","2022-04-11"
"2101.12695","Barbara Jasiulis-Go{\l}dyn","[M. Cadena, B. H. Jasiulis-Go{\l}dyn and E. Omey","Asymptotics for Kendall's renewal function",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An elementary renewal theorem and a Blackwell theorem provided by
Jasiulis-Go{\l}dyn et al. (2020) in a setting of Kendall convolutions are
proved under weaker hypothesis and extended to the Gamma class. Convergence
rates of the limits concerned in these theorems are analyzed.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:32:30 GMT""}]","2021-02-01"
"2101.12696","Anthony K. C. Tan","Anthony K. C. Tan, James Lourembam, Xiaoye Chen, Pin Ho, Hang Khume
  Tan, and Anjan Soumyanarayanan","Skyrmion generation from irreversible fission of stripes in chiral
  multilayer films","v1 with supplementary materials","Phys. Rev. Materials 4, 114419 (2020)","10.1103/PhysRevMaterials.4.114419",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Competing interactions produce finite-size textures in myriad condensed
matter systems, typically forming elongated stripe or round bubble domains.
Transitions between stripe and bubble phases, driven by field or temperature,
are expected to be reversible in nature. Here we report on the distinct
character of the analogous transition for nanoscale spin textures in chiral
Co/Pt-based multilayer films, known to host N\'{e}el skyrmions, using
microscopy, magnetometry, and micromagnetic simulations. Upon increasing field,
individual stripes fission into multiple skyrmions, and this transition
exhibits a macroscopic signature of irreversibility. Crucially, upon field
reversal, the skyrmions do not fuse back into stripes, with many skyrmions
retaining their morphology down to zero field. Both the macroscopic
irreversibility and the microscopic zero-field skyrmion density are governed by
the thermodynamic material parameter determining chiral domain stability. These
results establish the thermodynamic and microscopic framework underlying
ambient skyrmion generation and stability in chiral multilayer films and
provide immediate directions for their functionalization in devices.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:33:26 GMT""}]","2021-02-01"
"2101.12698","Mauro Carfora","Mauro Carfora and Francesca Familiari","A comparison theorem for cosmological lightcones","19 pages; A few notational quirks and typos corrected",,"10.1007/s11005-021-01393-2",,"gr-qc math-ph math.MP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $(M, g)$ denote a cosmological spacetime describing the evolution of a
universe which is isotropic and homogeneous on large scales, but highly
inhomogeneous on smaller scales. We consider two past lightcones, the first,
$\mathcal{C}^-_L(p, g)$, is associated with the physical observer $p\in\,M$ who
describes the actual physical spacetime geometry of $(M, g)$ at the length
scale $L$, whereas the second, $\mathcal{C}^-_L(p, \hat{g})$, is associated
with an idealized version of the observer $p$ who, notwithstanding the presence
of local inhomogeneities at the given scale $L$, wish to model $(M, g)$ with a
member $(M, \hat{g})$ of the family of Friedmann-Lemaitre-Robertson-Walker
spacetimes. In such a framework, we discuss a number of mathematical results
that allows a rigorous comparison between the two lightcones
$\mathcal{C}^-_L(p, g)$ and $\mathcal{C}^-_L(p, \hat{g})$. In particular, we
introduce a scale dependent ($L$) lightcone-comparison functional, defined by a
harmonic type energy, associated with a natural map between the physical
$\mathcal{C}^-_L(p, g)$ and the FLRW reference lightcone $\mathcal{C}^-_L(p,
\hat{g})$. This functional has a number of remarkable properties, in particular
it vanishes iff, at the given length-scale, the corresponding lightcone surface
sections (the celestial spheres) are isometric. We discuss in detail its
variational analysis and prove the existence of a minimum that characterizes a
natural scale-dependent distance functional between the two lightcones. We also
indicate how it is possible to extend our results to the case when caustics
develop on the physical past lightcone $\mathcal{C}^-_L(p, g)$. Finally, we
show how the distance functional is related to spacetime scalar curvature in
the causal past of the two lightcones, and briefly illustrate a number of its
possible applications.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:34:59 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 15:36:44 GMT""}]","2021-05-05"
"2101.12699","Weijie J. Su","Cong Fang, Hangfeng He, Qi Long, Weijie J. Su","Exploring Deep Neural Networks via Layer-Peeled Model: Minority Collapse
  in Imbalanced Training","Accepted at Proceedings of the National Academy of Sciences (PNAS);
  Changed the title",,"10.1073/pnas.2103091118",,"cs.LG cs.CV math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the \textit{Layer-Peeled Model}, a nonconvex yet
analytically tractable optimization program, in a quest to better understand
deep neural networks that are trained for a sufficiently long time. As the name
suggests, this new model is derived by isolating the topmost layer from the
remainder of the neural network, followed by imposing certain constraints
separately on the two parts of the network. We demonstrate that the
Layer-Peeled Model, albeit simple, inherits many characteristics of
well-trained neural networks, thereby offering an effective tool for explaining
and predicting common empirical patterns of deep learning training. First, when
working on class-balanced datasets, we prove that any solution to this model
forms a simplex equiangular tight frame, which in part explains the recently
discovered phenomenon of neural collapse \cite{papyan2020prevalence}. More
importantly, when moving to the imbalanced case, our analysis of the
Layer-Peeled Model reveals a hitherto unknown phenomenon that we term
\textit{Minority Collapse}, which fundamentally limits the performance of deep
learning models on the minority classes. In addition, we use the Layer-Peeled
Model to gain insights into how to mitigate Minority Collapse. Interestingly,
this phenomenon is first predicted by the Layer-Peeled Model before being
confirmed by our computational experiments.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:37:17 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 20:31:42 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 18:33:51 GMT""}]","2022-05-11"
"2101.12700","Matthew Dale","Matthew Dale, Richard F. L. Evans, Sarah Jenkins, Simon O'Keefe,
  Angelika Sebald, Susan Stepney, Fernando Torre, Martin Trefzer","Reservoir Computing with Thin-film Ferromagnetic Devices",,,,,"cs.ET cond-mat.mtrl-sci cs.AR cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advances in artificial intelligence are driven by technologies inspired by
the brain, but these technologies are orders of magnitude less powerful and
energy efficient than biological systems. Inspired by the nonlinear dynamics of
neural networks, new unconventional computing hardware has emerged with the
potential for extreme parallelism and ultra-low power consumption. Physical
reservoir computing demonstrates this with a variety of unconventional systems
from optical-based to spintronic. Reservoir computers provide a nonlinear
projection of the task input into a high-dimensional feature space by
exploiting the system's internal dynamics. A trained readout layer then
combines features to perform tasks, such as pattern recognition and time-series
analysis. Despite progress, achieving state-of-the-art performance without
external signal processing to the reservoir remains challenging. Here we show,
through simulation, that magnetic materials in thin-film geometries can realise
reservoir computers with greater than or similar accuracy to digital recurrent
neural networks. Our results reveal that basic spin properties of magnetic
films generate the required nonlinear dynamics and memory to solve machine
learning tasks. Furthermore, we show that neuromorphic hardware can be reduced
in size by removing the need for discrete neural components and external
processing. The natural dynamics and nanoscale size of magnetic thin-films
present a new path towards fast energy-efficient computing with the potential
to innovate portable smart devices, self driving vehicles, and robotics.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:37:17 GMT""}]","2021-02-01"
"2101.12701","Ville Vakkuri","Ville Vakkuri, Marianna Jantunen, Erika Halme, Kai-Kristian Kemell,
  Anh Nguyen-Duc, Tommi Mikkonen, Pekka Abrahamsson","Time for AI (Ethics) Maturity Model Is Now",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There appears to be a common agreement that ethical concerns are of high
importance when it comes to systems equipped with some sort of Artificial
Intelligence (AI). Demands for ethical AI are declared from all directions. As
a response, in recent years, public bodies, governments, and universities have
rushed in to provide a set of principles to be considered when AI based systems
are designed and used. We have learned, however, that high-level principles do
not turn easily into actionable advice for practitioners. Hence, also companies
are publishing their own ethical guidelines to guide their AI development. This
paper argues that AI software is still software and needs to be approached from
the software development perspective. The software engineering paradigm has
introduced maturity model thinking, which provides a roadmap for companies to
improve their performance from the selected viewpoints known as the key
capabilities. We want to voice out a call for action for the development of a
maturity model for AI software. We wish to discuss whether the focus should be
on AI ethics or, more broadly, the quality of an AI system, called a maturity
model for the development of AI systems.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:37:44 GMT""}]","2021-02-01"
"2101.12702","Jorge Kurchan","Jorge Kurchan","Time-reparametrization invariances, multithermalization and the Parisi
  scheme",,,,,"cond-mat.stat-mech hep-th math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  The Parisi scheme for equilibrium and the corresponding slow dynamics with
multithermalization - same temperature common to all observables, different
temperatures only possible at widely separated timescales -- imply one another.
Consistency requires that two systems brought into infinitesimal coupling be
able to rearrange their timescales in order that all their temperatures match:
this time reorganisation is only possible because the systems have a set of
time-reparametrization invariances, that are thus seen to be an essential
component of the scenario.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:39:12 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 09:50:06 GMT""},{""version"":""v3"",""created"":""Mon, 8 Mar 2021 14:02:07 GMT""},{""version"":""v4"",""created"":""Tue, 6 Sep 2022 14:20:33 GMT""},{""version"":""v5"",""created"":""Thu, 22 Sep 2022 12:15:06 GMT""}]","2022-09-23"
"2101.12703","Jonas Fritzsch","Jonas Fritzsch, Marvin Wyrich, Justus Bogner, Stefan Wagner","R\'esum\'e-Driven Development: A Definition and Empirical
  Characterization","10 pages, 5 figures",,"10.1109/ICSE-SEIS52602.2021.00011",,"cs.SE cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Technologies play an important role in the hiring process for software
professionals. Within this process, several studies revealed misconceptions and
bad practices which lead to suboptimal recruitment experiences. In the same
context, grey literature anecdotally coined the term R\'esum\'e-Driven
Development (RDD), a phenomenon describing the overemphasis of trending
technologies in both job offerings and resumes as an interaction between
employers and applicants. While RDD has been sporadically mentioned in books
and online discussions, there are so far no scientific studies on the topic,
despite its potential negative consequences. We therefore empirically
investigated this phenomenon by surveying 591 software professionals in both
hiring (130) and technical (558) roles and identified RDD facets in substantial
parts of our sample: 60% of our hiring professionals agreed that trends
influence their job offerings, while 82% of our software professionals believed
that using trending technologies in their daily work makes them more attractive
for prospective employers. Grounded in the survey results, we conceptualize a
theory to frame and explain R\'esum\'e-Driven Development. Finally, we discuss
influencing factors and consequences and propose a definition of the term. Our
contribution provides a foundation for future research and raises awareness for
a potentially systemic trend that may broadly affect the software industry.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:41:37 GMT""}]","2021-08-24"
"2101.12704","Hong Xing","Hong Xing and Osvaldo Simeone and Suzhi Bi","Federated Learning over Wireless Device-to-Device Networks: Algorithms
  and Convergence Analysis","46 pages, 9 figures, to appear in IEEE J. Sel. Areas Commun",,"10.1109/JSAC.2021.3118400",,"cs.IT cs.LG cs.NI eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proliferation of Internet-of-Things (IoT) devices and cloud-computing
applications over siloed data centers is motivating renewed interest in the
collaborative training of a shared model by multiple individual clients via
federated learning (FL). To improve the communication efficiency of FL
implementations in wireless systems, recent works have proposed compression and
dimension reduction mechanisms, along with digital and analog transmission
schemes that account for channel noise, fading, and interference. The prior art
has mainly focused on star topologies consisting of distributed clients and a
central server. In contrast, this paper studies FL over wireless
device-to-device (D2D) networks by providing theoretical insights into the
performance of digital and analog implementations of decentralized stochastic
gradient descent (DSGD). First, we introduce generic digital and analog
wireless implementations of communication-efficient DSGD algorithms, leveraging
random linear coding (RLC) for compression and over-the-air computation
(AirComp) for simultaneous analog transmissions. Next, under the assumptions of
convexity and connectivity, we provide convergence bounds for both
implementations. The results demonstrate the dependence of the optimality gap
on the connectivity and on the signal-to-noise ratio (SNR) levels in the
network. The analysis is corroborated by experiments on an image-classification
task.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:42:26 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 18:31:20 GMT""}]","2021-10-14"
"2101.12705","Radu Miculescu","Radu Miculescu and Alexandru Mihail","Diameter Diminishing To Zero IFSs",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce the notion of diameter diminishing to zero
iterated function system, study its properties and provide alternative
characterizations of it.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:55:27 GMT""}]","2021-02-01"
"2101.12706","Beno\^it Pairet","Beno\^it Pairet and Faustine Cantalloube and Laurent Jacques","Morphological components analysis for circumstellar disks imaging","in Proceedings of iTWIST'20, Paper-ID: 44, Nantes, France, December,
  2-4, 2020",,,,"astro-ph.IM astro-ph.EP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent developments in astronomical observations enable direct imaging of
circumstellar disks. Precise characterization of such extended structure is
essential to our understanding of stellar systems. However, the faint intensity
of the circumstellar disks compared to the brightness of the host star compels
astronomers to use tailored observation strategies, in addition to
state-of-the-art optical devices. Even then, extracting the signal of
circumstellar disks heavily relies on post-processing techniques. In this work,
we propose a morphological component analysis (MCA) approach that leverages
low-complexity models of both the disks and the stellar light corrupting the
data. In addition to disks, our method allows to image exoplanets. Our approach
is tested through numerical experiments.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:56:40 GMT""}]","2021-02-01"
"2101.12707","Oleg Karpenkov","Oleg Karpenkov","On Hermite's problem, Jacobi-Perron type algorithms, and Dirichlet
  groups","22 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1848 Ch.~Hermite asked if there exists some way to write cubic
irrationalities periodically. A little later in order to approach the problem
C.G.J.~Jacobi and O.~Perron generalized the classical continued fraction
algorithm to the three-dimensional case, this algorithm is called now the
Jacobi-Perron algorithm. This algorithm is known to provide periodicity only
for some cubic irrationalities.
  In this paper we introduce two new algorithms in the spirit of Jacobi-Perron
algorithm: the heuristic algebraic periodicity detecting algorithm and the
$\sin^2$-algorithm. The heuristic algebraic periodicity detecting algorithm is
a very fast and efficient algorithm, its output is periodic for numerous
examples of cubic irrationalities, however its periodicity for cubic
irrationalities is not proven. The $\sin^2$-algorithm is limited to the
totally-real cubic case (all the roots of cubic polynomials are real numbers).
In the recent paper~\cite{Karpenkov2021} we proved the periodicity of the
$\sin^2$-algorithm for all cubic totally-real irrationalities. To our best
knowledge this is the first Jacobi-Perron type algorithm for which the cubic
periodicity is proven. The $\sin^2$-algorithm provides the answer to Hermite's
problem for the totally real case (let us mention that the case of cubic
algebraic numbers with complex conjugate roots remains open).
  We conclude this paper with one important application of Jacobi-Perron type
algorithms to computation of independent elements in the maximal groups of
commuting matrices of algebraic irrationalities.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:57:44 GMT""}]","2021-02-01"
"2101.12708","Calvin Tsay","Jan Kronqvist and Ruth Misener and Calvin Tsay","Between steps: Intermediate relaxations between big-M and convex hull
  formulations","16 pages",,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work develops a class of relaxations in between the big-M and convex
hull formulations of disjunctions, drawing advantages from both. The proposed
""P-split"" formulations split convex additively separable constraints into P
partitions and form the convex hull of the partitioned disjuncts. Parameter P
represents the trade-off of model size vs. relaxation strength. We examine the
novel formulations and prove that, under certain assumptions, the relaxations
form a hierarchy starting from a big-M equivalent and converging to the convex
hull. We computationally compare the proposed formulations to big-M and convex
hull formulations on a test set including: K-means clustering, P_ball problems,
and ReLU neural networks. The computational results show that the intermediate
P-split formulations can form strong outer approximations of the convex hull
with fewer variables and constraints than the extended convex hull
formulations, giving significant computational advantages over both the big-M
and convex hull.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:03:15 GMT""}]","2021-02-01"
"2101.12709","L\'aszl\'o M\'arton T\'oth","\'Ad\'am Tim\'ar and L\'aszl\'o M\'arton T\'oth","A full characterization of invariant embeddability of unimodular planar
  graphs","Added a proof for Theorem 9. 32 pages, 3 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When can a unimodular random planar graph be drawn in the Euclidean or the
hyperbolic plane in a way that the distribution of the random drawing is
isometry-invariant? This question was answered for one-ended unimodular graphs
in earlier work of Benjamini and Tim\'ar, using the fact that such graphs
automatically have locally finite (simply connected) drawings into the plane.
For the case of graphs with multiple ends the question was left open. We
provide a graph theoretic characterization of graphs that have a locally finite
embedding into the plane. Then we prove that such graphs do have a locally
finite invariant embedding into the Euclidean or the hyperbolic plane,
depending on whether the graph is amenable or not.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:04:03 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 15:11:24 GMT""}]","2021-03-17"
"2101.12710","Nikolai Miklin","Nikolai Miklin and Marcin Paw{\l}owski","Information Causality without concatenation","5 pages, 1 figure, comments are welcome","Phys. Rev. Lett. 126, 220403 (2021)","10.1103/PhysRevLett.126.220403",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Information Causality is a physical principle which states that the amount of
randomly accessible data over a classical communication channel cannot exceed
its capacity, even if the sender and the receiver have access to a source of
nonlocal correlations. This principle can be used to bound the nonlocality of
quantum mechanics without resorting to its full formalism, with a notable
example of reproducing the Tsirelson's bound of the Clauser-Horne-Shimony-Holt
inequality. Despite being promising, the latter result found little
generalization to other Bell inequalities because of the limitations imposed by
the process of concatenation, in which several nonsignaling resources are put
together to produce tighter bounds. In this work, we show that concatenation
can be successfully replaced by limits on the communication channel capacity.
It allows us to re-derive and, in some cases, significantly improve all the
previously known results in a simpler manner and apply the Information
Causality principle to previously unapproachable Bell scenarios.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:05:40 GMT""}]","2021-06-09"
"2101.12711","Gioacchino Antonelli","Gioacchino Antonelli, Mattia Fogagnolo, Marco Pozzetta","The isoperimetric problem on Riemannian manifolds via Gromov-Hausdorff
  asymptotic analysis","Minor corrections and shortened exposition. Final version to appear
  in Communications in Contemporary Mathematics",,,,"math.DG math.MG","http://creativecommons.org/licenses/by/4.0/","  In this paper we prove the existence of isoperimetric regions of any volume
in Riemannian manifolds with Ricci bounded below assuming Gromov--Hausdorff
asymptoticity to the suitable simply connected model of constant sectional
curvature. The previous result is a consequence of a general structure theorem
for perimeter-minimizing sequences of sets of fixed volume on noncollapsed
Riemannian manifolds with a lower bound on the Ricci curvature. We show that,
without assuming any further hypotheses on the asymptotic geometry, all the
mass and the perimeter lost at infinity, if any, are recovered by at most
countably many isoperimetric regions sitting in some (possibly nonsmooth)
Gromov--Hausdorff limits at infinity. The Gromov--Hausdorff asymptotic analysis
allows us to recover and extend different previous existence theorems. While
studying the isoperimetric problem in the smooth setting, the nonsmooth
geometry naturally emerges, and thus our treatment combines techniques from
both the theories.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:09:35 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 14:17:49 GMT""},{""version"":""v3"",""created"":""Mon, 5 Sep 2022 14:26:30 GMT""}]","2022-09-07"
"2101.12712","Le Qiao Dr.","Le Qiao, Kai Szuttor, Christian Holm, Gary W. Slater","Ratcheting charged polymers through symmetric nanopores using pulsed
  fields: Designing a low pass filter for concentrating DNA",,,"10.1021/acs.nanolett.2c04588",,"cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a new concept for the separation of DNA molecules by contour
length that combines a nanofluidic ratchet, nanopore translocation and pulsed
fields. Using Langevin Dynamics simulations, we show that it is possible to
design pulsed field sequences to ratchet captured semiflexible molecules in
such a way that only short chains successfully translocate, effectively
transforming the nanopore process into a low pass molecular filter. We also
show that asymmetric pulses can significantly enhance the device efficiency.
The process itself can be performed with many pores in parallel, and it should
be possible to integrate it directly into nanopore sequencing devices,
increasing its potential utility.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:11:30 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 20:09:58 GMT""}]","2023-01-31"
"2101.12713","I. S. Burmistrov","I.S. Burmistrov, I.V. Gornyi, A.D. Mirlin","Multifractally-enhanced superconductivity in thin films","30 pages, 3 figures, accepted to Localisation 2020 volume of Annals
  of Physics",,"10.1016/j.aop.2021.168499",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multifractal superconducting state originates from the interplay of
Anderson localization and interaction effects. In this article we overview the
recent theory of the superconductivity enhancement by multifractality and
extend it to describe the spectral properties of superconductors on the scales
of the order of the superconducting gap. Specifically, using the approach based
on renormalization group within the nonlinear sigma model, we develop the
theory of a multifractal superconducting state in thin films. We derive a
modified Usadel equation that incorporates the interplay of disorder and
interactions at energy scales larger than the spectral gap and study the effect
of such an interplay on the low-energy physics. We determine the spectral gap
at zero temperature which occurs to be proportional to the multifracally
enhanced superconducting transition temperature. The modified Usadel equation
results in the disorder-averaged density of states that, near the spectral gap,
resembles the one obtained in the model of a spatially random superconducting
order parameter. We reveal strong mesoscopic fluctuations of the local density
of states in the superconducting state. Such strong mesoscopic fluctuations
imply that the interval of energies in which the superconducting gap
establishes is parametrically large in systems with multifractally-enhanced
superconductivity.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:12:05 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 18:48:01 GMT""}]","2021-06-08"
"2101.12714","Vjekoslav Kova\v{c}","Vjekoslav Kova\v{c}","Popular differences for right isosceles triangles","8 pages; v2: a few typos fixed, acknowledgments added; v3: references
  added, referee's suggestions incorporated","Electron. J. Combin. 28 (2021), Article P4.27","10.37236/10218",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a subset $A$ of $\{1,2,\ldots,N\}^2$ of size $\alpha N^2$ we show
existence of $(m,n)\neq(0,0)$ such that the set $A$ contains at least
$(\alpha^3 - o(1))N^2$ triples of points of the form $(a,b)$, $(a+m,b+n)$,
$(a-n,b+m)$. This answers a question by Ackelsberg, Bergelson, and Best from
arXiv:2101.02811. The same approach also establishes the corresponding result
for compact abelian groups. Furthermore, for a finite field $\mathbb{F}_q$ we
comment on exponential smallness of subsets of $(\mathbb{F}_q^n)^2$ that avoid
the aforementioned configuration. The proofs are minor modifications of the
existing proofs regarding three-term arithmetic progressions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:16:06 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 02:18:28 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 11:51:13 GMT""}]","2021-12-06"
"2101.12715","Tim Draws","Tim Draws, Zolt\'an Szl\'avik, Benjamin Timmermans, Nava Tintarev,
  Kush R. Varshney, Michael Hind","Disparate Impact Diminishes Consumer Trust Even for Advantaged Users",,"Persuasive Technology, Cham, 2021, p. 135-149","10.1007/978-3-030-79460-6_11",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems aiming to aid consumers in their decision-making (e.g., by
implementing persuasive techniques) are more likely to be effective when
consumers trust them. However, recent research has demonstrated that the
machine learning algorithms that often underlie such technology can act
unfairly towards specific groups (e.g., by making more favorable predictions
for men than for women). An undesired disparate impact resulting from this kind
of algorithmic unfairness could diminish consumer trust and thereby undermine
the purpose of the system. We studied this effect by conducting a
between-subjects user study investigating how (gender-related) disparate impact
affected consumer trust in an app designed to improve consumers' financial
decision-making. Our results show that disparate impact decreased consumers'
trust in the system and made them less likely to use it. Moreover, we find that
trust was affected to the same degree across consumer groups (i.e., advantaged
and disadvantaged users) despite both of these consumer groups recognizing
their respective levels of personal benefit. Our findings highlight the
importance of fairness in consumer-oriented artificial intelligence systems.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:25:09 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 17:38:45 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 16:27:23 GMT""}]","2021-07-06"
"2101.12716","Leonardo Garc\'ia-Heveling","Leonardo Garc\'ia-Heveling","Causality theory of spacetimes with continuous Lorentzian metrics
  revisited","Significant changes in v2: notation changed, references added,
  numbering of theorems shifted. 12 pages, 2 figures, 1 table","Class. Quantum Grav. 38 (2021) 145028","10.1088/1361-6382/ac067a",,"gr-qc math-ph math.DG math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider the usual causal structure $(I^+,J^+)$ on a spacetime, and a
number of alternatives based on Minguzzi's $D^+$ and Sorkin and Woolgar's
$K^+$, in the case where the spacetime metric is continuous, but not
necessarily smooth. We compare the different causal structures based on three
key properties, namely the validity of the push-up lemma, the openness of
chronological futures, and the existence of limit causal curves. Recall that if
the spacetime metric is smooth, $(I^+,J^+)$ satisfies all three properties, but
that in the continuous case, the push-up lemma fails. Among the proposed
alternative causal structures, there is one that satisfies push-up and open
futures, and one that has open futures and limit curves. Furthermore, we show
that spacetimes with continuous metrics do not, in general, admit a causal
structure satisfying all three properties at once.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:25:52 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 14:06:02 GMT""}]","2021-06-30"
"2101.12717","Erkan Bostanci","Emre Cihan Ates, Erkan Bostanci, Mehmet Serdar Guzel","Machine Translation, Sentiment Analysis, Text Similarity, Topic
  Modelling, and Tweets: Understanding Social Media Usage Among Police and
  Gendarmerie Organizations",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that social media has revolutionized communication.
Nowadays, citizens, companies, and public institutions actively use social
media in order to express themselves better to the population they address.
This active use is also carried out by the gendarmerie and police organizations
to communicate with the public with the purpose of improving social relations.
However, it has been seen that the posts by the gendarmerie and police
organizations did not attract much attention from their target audience from
time to time, and it has been discovered that there was not enough research in
the literature on this issue. In this study, it was aimed to investigate the
use of social media by the gendarmerie and police organizations operating in
Turkey (Jandarma - Polis), Italy (Carabinieri - Polizia), France (Gendarmerie -
Police) and Spain (Guardia Civil - Polic\'ia), and the extent to which they can
be effective on the followers, by comparatively examining their activity on
twitter. According to the obtained results, it was found that Jandarma (Turkey)
has the highest power of influence in the twitter sample, and the findings were
comparatively presented in the study.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:26:24 GMT""}]","2021-02-01"
"2101.12718","Erkan Bostanci","Emre Cihan Ates, Erkan Bostanci, Mehmet Serdar Guzel","Comparative Performance of Machine Learning Algorithms in Cyberbullying
  Detection: Using Turkish Language Preprocessing Techniques",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing use of the internet and social media, it is obvious that
cyberbullying has become a major problem. The most basic way for protection
against the dangerous consequences of cyberbullying is to actively detect and
control the contents containing cyberbullying. When we look at today's internet
and social media statistics, it is impossible to detect cyberbullying contents
only by human power. Effective cyberbullying detection methods are necessary in
order to make social media a safe communication space. Current research efforts
focus on using machine learning for detecting and eliminating cyberbullying.
Although most of the studies have been conducted on English texts for the
detection of cyberbullying, there are few studies in Turkish. Limited methods
and algorithms were also used in studies conducted on the Turkish language. In
addition, the scope and performance of the algorithms used to classify the
texts containing cyberbullying is different, and this reveals the importance of
using an appropriate algorithm. The aim of this study is to compare the
performance of different machine learning algorithms in detecting Turkish
messages containing cyberbullying. In this study, nineteen different
classification algorithms were used to identify texts containing cyberbullying
using Turkish natural language processing techniques. Precision, recall,
accuracy and F1 score values were used to evaluate the performance of
classifiers. It was determined that the Light Gradient Boosting Model (LGBM)
algorithm showed the best performance with 90.788% accuracy and 90.949% F1
Score value.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:28:44 GMT""}]","2021-02-01"
"2101.12719","Emma Benjaminson","Emma Benjaminson (1), Rebecca E. Taylor (1,2,3), Matthew Travers (4)
  ((1) Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, (2)
  Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA, (3)
  Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh
  PA, (4) Robotics Institute, Carnegie Mellon University, Pittsburgh, PA)","Predicting Nanorobot Shapes via Generative Models","8 pages, 2 figures, accepted to Machine Learning for Engineering
  Modeling, Simulation, and Design Workshop at Neural Information Processing
  Systems 2020, December 12, 2020",,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  The field of DNA nanotechnology has made it possible to assemble, with high
yields, different structures that have actionable properties. For example,
researchers have created components that can be actuated. An exciting next step
is to combine these components into multifunctional nanorobots that could,
potentially, perform complex tasks like swimming to a target location in the
human body, detect an adverse reaction and then release a drug load to stop it.
However, as we start to assemble more complex nanorobots, the yield of the
desired nanorobot begins to decrease as the number of possible component
combinations increases. Therefore, the ultimate goal of this work is to develop
a predictive model to maximize yield. However, training predictive models
typically requires a large dataset. For the nanorobots we are interested in
assembling, this will be difficult to collect. This is because high-fidelity
data, which allows us to characterize the shape and size of individual
structures, is very time-consuming to collect, whereas low-fidelity data is
readily available but only captures bulk statistics for different processes.
Therefore, this work combines low- and high-fidelity data to train a generative
model using a two-step process. We first use a relatively small, high-fidelity
dataset to train a generative model. At run time, the model takes low-fidelity
data and uses it to approximate the high-fidelity content. We do this by
biasing the model towards samples with specific properties as measured by
low-fidelity data. In this work we bias our distribution towards a desired node
degree of a graphical model that we take as a surrogate representation of the
nanorobots that this work will ultimately focus on. We have not yet accumulated
a high-fidelity dataset of nanorobots, so we leverage the MolGAN architecture
[1] and the QM9 small molecule dataset [2-3] to demonstrate our approach.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:29:51 GMT""}]","2021-02-01"
"2101.12720","Tim Breitenbach","Tim Breitenbach, Lauritz Rasbach, Chunguang Liang, Patrick Jahnke","A principle feature analysis","Published with new title: A principal feature analysis
  https://www.sciencedirect.com/science/article/pii/S1877750321001666?via%3Dihub","Journal of Computational Science (2021)","10.1016/j.jocs.2021.101502",,"stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A key task of data science is to identify relevant features linked to certain
output variables that are supposed to be modeled or predicted. To obtain a
small but meaningful model, it is important to find stochastically independent
variables capturing all the information necessary to model or predict the
output variables sufficiently. Therefore, we introduce in this work a framework
to detect linear and non-linear dependencies between different features. As we
will show, features that are actually functions of other features do not
represent further information. Consequently, a model reduction neglecting such
features conserves the relevant information, reduces noise and thus improves
the quality of the model. Furthermore, a smaller model makes it easier to adopt
a model of a given system. In addition, the approach structures dependencies
within all the considered features. This provides advantages for classical
modeling starting from regression ranging to differential equations and for
machine learning.
  To show the generality and applicability of the presented framework 2154
features of a data center are measured and a model for classification for
faulty and non-faulty states of the data center is set up. This number of
features is automatically reduced by the framework to 161 features. The
prediction accuracy for the reduced model even improves compared to the model
trained on the total number of features. A second example is the analysis of a
gene expression data set where from 9513 genes 9 genes are extracted from whose
expression levels two cell clusters of macrophages can be distinguished.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:30:38 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 14:48:02 GMT""}]","2021-12-23"
"2101.12721","Ehsan Khatami","Jacob Park and Ehsan Khatami","Thermodynamics of the disordered Hubbard model studied via numerical
  linked-cluster expansions","13 pages, 12 figures, same as the published version","Phys. Rev. B 104, 165102 (2021)","10.1103/PhysRevB.104.165102",,"cond-mat.str-el cond-mat.dis-nn cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interplay of disorder and strong correlations in quantum many-body
systems remains an open question. That is despite much progress made in recent
years with ultracold atoms in optical lattices to better understand phenomena
such as many-body localization or the effect of disorder on Mott
metal-insulator transitions. Here, we utilize the numerical linked-cluster
expansion technique, extended to treat disordered quantum lattice models, and
study exact thermodynamic properties of the disordered Fermi-Hubbard model on
the square and cubic geometries. We consider box distributions for the disorder
in the onsite energy, the interaction strength, as well as the hopping
amplitude and explore how energy, double occupancy, entropy, heat capacity and
magnetic correlations of the system in the thermodynamic limit evolve as the
strength of disorder changes. We compare our findings with those obtained from
determinant quantum Monte Carlo simulations and discuss the relevance of our
results to experiments with cold fermionic atoms in optical lattices.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:32:32 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 00:33:41 GMT""}]","2021-10-19"
"2101.12722","Alexander Davydov A.","Alexander A. Davydov, Stefano Marcugini, Fernanda Pambianco","On the weight distribution of the cosets of MDS codes","32 pages, 45 references. The text is edited. The connections between
  distinct parts of the paper are noted. Some transformations are simplified.
  New results are added. Open problems are formulated",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The weight distribution of the cosets of maximum distance separable (MDS)
codes is considered. In 1990, P.G. Bonneau proposed a relation to obtain the
full weight distribution of a coset of an MDS code with minimum distance $d$
using the known numbers of vectors of weights $\le d-2$ in this coset. In this
paper, the Bonneau formula is transformed into a more structured and convenient
form. The new version of the formula allows to consider effectively cosets of
distinct weights $W$. (The weight $W$ of a coset is the smallest Hamming weight
of any vector in the coset.) For each of the considered $W$ or regions of $W$,
special relations more simple than the general ones are obtained. For the MDS
code cosets of weight $W=1$ and weight $W=d-1$ we obtain formulas of the weight
distributions depending only on the code parameters. This proves that all the
cosets of weight $W=1$ (as well as $W=d-1$) have the same weight distribution.
The cosets of weight $W=2$ or $W=d-2$ may have different weight distributions;
in this case, we proved that the distributions are symmetrical in some sense.
The weight distributions of the cosets of MDS codes corresponding to arcs in
the projective plane $\mathrm{PG}(2,q)$ are also considered. For MDS codes of
covering radius $R=d-1$ we obtain the number of the weight $W=d-1$ cosets and
their weight distribution that gives rise to a certain classification of the
so-called deep holes. We show that any MDS code of covering radius $R=d-1$ is
an almost perfect multiple covering of the farthest-off points (deep holes);
moreover, it corresponds to an optimal multiple saturating set in the
projective space $\mathrm{PG}(N,q)$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:32:56 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 08:46:30 GMT""}]","2021-07-01"
"2101.12723","Luis Felipe Casta\~no Ledesma","F. Casta\~no, E. Fidalgo, E. Alegre, D. Chaves, M. Sanchez-Paniagua","State of the Art: Content-based and Hybrid Phishing Detection","6 pages, 1 table",,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Phishing attacks have evolved and increased over time and, for this reason,
the task of distinguishing between a legitimate site and a phishing site is
more and more difficult, fooling even the most expert users. The main proposals
focused on addressing this problem can be divided into four approaches:
List-based, URL based, content-based, and hybrid. In this state of the art, the
most recent techniques using web content-based and hybrid approaches for
Phishing Detection are reviewed and compared.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:34:59 GMT""}]","2021-02-01"
"2101.12724","Gui-Jun Ding","Peng Chen, Gui-Jun Ding, Stephen F. King","$SU(5)$ GUTs with $A_4$ modular symmetry","57 pages, 4 figures",,"10.1007/JHEP04(2021)239","USTC-ICTS/PCFT-21-06","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine $SU(5)$ Grand Unified Theories (GUTs) with $A_4$ modular symmetry
and present a comprehensive analysis of the resulting quark and lepton mass
matrices for all the simplest cases. Classifying the models according to the
representation assignments of the matter fields under $A_4$, we find that there
are seven types of $SU(5)$ models with $A_4$ modular symmetry. We present 53
benchmark models with the fewest free parameters. The parameter space of each
model is scanned to optimize the agreement between predictions and experimental
data, and predictions for the masses and mixing parameters of quarks and
leptons are given at the best fitting points. The best fit predictions for the
leptonic CP violating Dirac phase, the lightest neutrino mass and the
neutrinoless double beta decay parameter when displayed graphically are
observed to cover a wide range of possible values, but are clustered around
particular regions, allowing future neutrino experiments to discriminate
between the different types of models.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:35:30 GMT""}]","2021-05-12"
"2101.12725","Juste Raimbault","Juste Raimbault","Strong coupling between scales in a multi-scalar model of urban dynamics","15 pages, 7 figures, 1 table",,,,"physics.soc-ph cs.CY cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban evolution processes occur at different scales, with intricate
interactions between levels and relatively distinct type of processes. To what
extent actual urban dynamics include an actual strong coupling between scales,
in the sense of both top-down and bottom-up feedbacks, remains an open issue
with important practical implications for the sustainable management of
territories. We introduce in this paper a multi-scalar simulation model of
urban growth, coupling a system of cities interaction model at the macroscopic
scale with morphogenesis models for the evolution of urban form at the scale of
metropolitan areas. Strong coupling between scales is achieved through an
update of model parameters at each scale depending on trajectories at the other
scale. The model is applied and explored on synthetic systems of cities.
Simulation results show a non-trivial effect of the strong coupling. As a
consequence, an optimal action on policy parameters such as containing urban
sprawl is shifted. We also run a multi-objective optimization algorithm on the
model, showing showing that compromise between scales are captured. Our
approach opens new research directions towards more operational urban dynamics
models including a strong feedback between scales.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:37:44 GMT""}]","2021-02-01"
"2101.12726","Thomas Barrett","T. J. Barrett, W. Evans, A. Gadge, S. Bhumbra, S. Sleegers, R. Shah,
  J. Fekete, F. Orucevic, P. Kruger","An Environmental Monitoring Network for Quantum Gas Experiments and
  Devices","15 pages, 5 figures",,,,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  Quantum technology is approaching a level of maturity, recently demonstrated
in space-borne experiments and in-field measurements, which would allow for
adoption by non-specialist users. Parallel advancements made in
microprocessor-based electronics and database software can be combined to
create robust, versatile and modular experimental monitoring systems. Here, we
describe a monitoring network used across a number of cold atom laboratories
with a shared laser system. The ability to diagnose malfunction, unexpected or
unintended behaviour and passively collect data for key experimental
parameters, such as vacuum chamber pressure, laser beam power, or resistances
of important conductors, significantly reduces debugging time. This allows for
efficient control over a number of experiments and remote control when access
is limited.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:38:29 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 08:54:59 GMT""}]","2021-09-15"
"2101.12727","Samarth Mishra","Samarth Mishra, Kate Saenko, Venkatesh Saligrama","Surprisingly Simple Semi-Supervised Domain Adaptation with Pretraining
  and Consistency","Accepted to BMVC 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most modern unsupervised domain adaptation (UDA) approaches are rooted in
domain alignment, i.e., learning to align source and target features to learn a
target domain classifier using source labels. In semi-supervised domain
adaptation (SSDA), when the learner can access few target domain labels, prior
approaches have followed UDA theory to use domain alignment for learning. We
show that the case of SSDA is different and a good target classifier can be
learned without needing alignment. We use self-supervised pretraining (via
rotation prediction) and consistency regularization to achieve well separated
target clusters, aiding in learning a low error target classifier. With our
Pretraining and Consistency (PAC) approach, we achieve state of the art target
accuracy on this semi-supervised domain adaptation task, surpassing multiple
adversarial domain alignment methods, across multiple datasets. PAC, while
using simple techniques, performs remarkably well on large and challenging SSDA
benchmarks like DomainNet and Visda-17, often outperforming recent state of the
art by sizeable margins. Code for our experiments can be found at
https://github.com/venkatesh-saligrama/PAC
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:40:17 GMT""},{""version"":""v2"",""created"":""Sat, 23 Oct 2021 17:10:49 GMT""},{""version"":""v3"",""created"":""Fri, 26 Nov 2021 20:37:09 GMT""}]","2021-11-30"
"2101.12728","Wlodzimierz Jastrzebski","Jacek Szczepkowski, Anna Grochola, Wlodzimierz Jastrzebski, Pawel
  Kowalczyk","On the 3$^{1}\Pi_{u}$ state in caesium dimer","9 pages, 3 figures, link to Supplementary data",,"10.1016/j.saa.2021.119643",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polarisation labelling spectroscopy technique was employed to study the
3$^{1}\Pi_{u}$ state of Cs$_2$ molecule. The main equlibrium constants are
$T_e=20684.60$cm$^{-1}$, $\omega_e=30.61$cm$^{-1}$ and $R_e=5.27$\r{A}.
Vibrational levels $v=4-35$ of the 3$^{1}\Pi_{u}$ state were found to be
subject to strong perturbations by the neighbouring electronic states. Energies
of 3094 rovibronic levels of the perturbed complex were determined.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:40:50 GMT""}]","2021-04-14"
"2101.12729","Jordi Luque","Martin Kocour, Guillermo C\'ambara, Jordi Luque, David Bonet, Mireia
  Farr\'us, Martin Karafi\'at, Karel Vesel\'y and Jan ''Honza'' \^Cernock\'y","BCN2BRNO: ASR System Fusion for Albayzin 2020 Speech to Text Challenge","fusion, end-to-end model, hybrid model, semisupervised, automatic
  speech recognition, convolutional neural network",,,,"eess.AS cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper describes joint effort of BUT and Telef\'onica Research on
development of Automatic Speech Recognition systems for Albayzin 2020
Challenge. We compare approaches based on either hybrid or end-to-end models.
In hybrid modelling, we explore the impact of SpecAugment layer on performance.
For end-to-end modelling, we used a convolutional neural network with gated
linear units (GLUs). The performance of such model is also evaluated with an
additional n-gram language model to improve word error rates. We further
inspect source separation methods to extract speech from noisy environment
(i.e. TV shows). More precisely, we assess the effect of using a neural-based
music separator named Demucs. A fusion of our best systems achieved 23.33% WER
in official Albayzin 2020 evaluations. Aside from techniques used in our final
submitted systems, we also describe our efforts in retrieving high quality
transcripts for training.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:40:54 GMT""}]","2021-02-01"
"2101.12730","Max Lutz","Max Lutz and Thomas Meurer","Optimal Trajectory Planning and Model Predictive Control of
  Underactuated Marine Surface Vessels using a Flatness-Based Approach","Accepted for presentation at, and publication in the proceedings of,
  the 2021 American Control Conference (ACC)",,"10.23919/ACC50511.2021.9483265",,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper demonstrates a refined approach to solving dynamic optimization
problems for underactuated marine surface vessels. To this end the differential
flatness of a mathematical model assuming full actuation is exploited to derive
an efficient representation of a finite dimensional nonlinear programming
problem, which in turn is constrained to apply to the underactuated case. It is
illustrated how the properties of the flat output can be employed for the
generation of an initial guess to be used in the optimization algorithm in the
presence of static and dynamic obstacles. As an example energy optimal point to
point trajectory planning for a nonlinear 3 degrees of freedom dynamic model of
an underactuated surface vessel is undertaken. Input constraints, both in rate
and magnitude as well as state constraints due to convex and non-convex
obstacles in the area of operation are considered and simulation results for a
challenging scenario are reported. Furthermore, an extension to a trajectory
tracking controller using model predictive control is made where the benefits
of the flatness based direct method allow to introduce nonuniform sample times
that help to realize long prediction horizons while maintaining short term
accuracy and real time capability. This is also verified in simulation where
additional disturbances in the form of environmental disturbances, dynamic
obstacles and parameter mismatch are introduced.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:42:47 GMT""}]","2021-11-01"
"2101.12731","Beatrice Annemone Popescu Braileanu","B. Popescu Braileanu, V. S. Lukin, E. Khomenko, A. de Vicente","Two-fluid simulations of Rayleigh-Taylor instability in a magnetized
  solar prominence thread II. Effects of collisionality",,"A&A 650, A181 (2021)","10.1051/0004-6361/202140425",,"astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we explore the dynamical impacts and observable signatures of
two-fluid effects in the parameter regimes when ion-neutral collisions do not
fully couple the neutral and charged fluids. The purpose of this study is to
deepen our understanding of the RTI and the effects of the partial ionization
on the development of RTI using non-linear two-fluid numerical simulations. Our
two-fluid model takes into account neutral viscosity, thermal conductivity, and
collisional interaction between neutrals and charges: ionization/recombination,
energy and momentum transfer, and frictional heating. In this paper II, the
sensitivity of the RTI dynamics to collisional effects for different magnetic
field configurations supporting the prominence thread is explored. This is done
by artificially varying, or eliminating, effects of both elastic and inelastic
collisions by modifying the model equations. We find that ionization and
recombination reactions between ionized and neutral fluids, if in equilibrium
prior to the onset of the instability, do not substantially impact the
development of the primary RTI. However, such reactions can impact development
of secondary structures during mixing of the cold prominence and hotter
surrounding coronal material. We find that collisionality within and between
ionized and neutral particle populations play an important role in both linear
and non-linear development of RTI, with ion-neutral collision frequency as the
primary determining factor in development or damping of small scale structures.
We also observe that degree and signatures of flow decoupling between ion and
neutral fluids can depend both on the inter-particle collisionality and the
magnetic field configuration of the prominence thread.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:43:08 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 20:57:54 GMT""}]","2021-06-30"
"2101.12732","Jordi Luque","David Bonet, Guillermo C\'ambara, Fernando L\'opez, Pablo G\'omez,
  Carlos Segura, Jordi Luque","Speech Enhancement for Wake-Up-Word detection in Voice Assistants","keyword spotting, speech enhancement, wake-up-word, deep learning,
  convolutional neural network",,,,"eess.AS cs.CL","http://creativecommons.org/licenses/by/4.0/","  Keyword spotting and in particular Wake-Up-Word (WUW) detection is a very
important task for voice assistants. A very common issue of voice assistants is
that they get easily activated by background noise like music, TV or background
speech that accidentally triggers the device. In this paper, we propose a
Speech Enhancement (SE) model adapted to the task of WUW detection that aims at
increasing the recognition rate and reducing the false alarms in the presence
of these types of noises. The SE model is a fully-convolutional denoising
auto-encoder at waveform level and is trained using a log-Mel Spectrogram and
waveform reconstruction losses together with the BCE loss of a simple WUW
classification network. A new database has been purposely prepared for the task
of recognizing the WUW in challenging conditions containing negative samples
that are very phonetically similar to the keyword. The database is extended
with public databases and an exhaustive data augmentation to simulate different
noises and environments. The results obtained by concatenating the SE with a
simple and state-of-the-art WUW detectors show that the SE does not have a
negative impact on the recognition rate in quiet environments while increasing
the performance in the presence of noise, especially when the SE and WUW
detector are trained jointly end-to-end.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:44:05 GMT""}]","2021-02-01"
"2101.12733","Wei-Lin Wu","Albert Atserias, Phokion G. Kolaitis, Wei-Lin Wu","On the Expressive Power of Homomorphism Counts","27 pages, 2 figures",,,,"math.CO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A classical result by Lov\'asz asserts that two graphs $G$ and $H$ are
isomorphic if and only if they have the same left profile, that is, for every
graph $F$, the number of homomorphisms from $F$ to $G$ coincides with the
number of homomorphisms from $F$ to $H$. Dvor{\'{a}}k and later on Dell, Grohe,
and Rattan showed that restrictions of the left profile to a class of graphs
can capture several different relaxations of isomorphism, including equivalence
in counting logics with a fixed number of variables (which contains fractional
isomorphism as a special case) and co-spectrality (i.e., two graphs having the
same characteristic polynomial). On the other side, a result by Chaudhuri and
Vardi asserts that isomorphism is also captured by the right profile, that is,
two graphs $G$ and $H$ are isomorphic if and only if for every graph $F$, the
number of homomorphisms from $G$ to $F$ coincides with the number of
homomorphisms from $H$ to $F$. In this paper, we embark on a study of the
restrictions of the right profile by investigating relaxations of isomorphism
that can or cannot be captured by restricting the right profile to a fixed
class of graphs. Our results unveil striking differences between the expressive
power of the left profile and the right profile. We show that fractional
isomorphism, equivalence in counting logics with a fixed number of variables,
and co-spectrality cannot be captured by restricting the right profile to a
class of graphs. In the opposite direction, we show that chromatic equivalence
cannot be captured by restricting the left profile to a class of graphs, while,
clearly, it can be captured by restricting the right profile to the class of
all cliques.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:45:23 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 19:49:06 GMT""}]","2021-06-02"
"2101.12734","Weronika Ewa Narloch","W. Narloch, G. Pietrzy\'nski, W. Gieren, A. E. Piatti, M. G\'orski, P.
  Karczmarek, D. Graczyk, K. Suchomska, B. Zgirski, P. Wielg\'orski, B.
  Pilecki, M. Taormina, M. Ka{\l}uszy\'nski, W. Pych, G. Hajdu and G. Rojas
  Garc\'ia","Metallicities and ages for 35 star clusters and their surrounding fields
  in the Small Magellanic Cloud","22 pages, 12 figures, 6 tables, Published in A&A","A&A 647, A135 (2021)","10.1051/0004-6361/202039623",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study 35 stellar clusters in the Small Magellanic Cloud (SMC)
in order to provide their mean metallicities and ages. We also provide mean
metallicities of the fields surrounding the clusters. We used Str\""omgren
photometry obtained with the 4.1 m SOAR telescope and take advantage of $(b -
y)$ and $m1$ colors for which there is a metallicity calibration presented in
the literature. The spatial metallicity and age distributions of clusters
across the SMC are investigated using the results obtained by Str\""omgren
photometry. We confirm earlier observations that younger, more metal-rich star
clusters are concentrated in the central regions of the galaxy, while older,
more metal-poor clusters are located farther from the SMC center. We construct
the age-metallicity relation for the studied clusters and find good agreement
with theoretical models of chemical enrichment, and with other literature age
and metallicity values for those clusters. We also provide the mean
metallicities for old and young populations of the field stars surrounding the
clusters, and find the latter to be in good agreement with recent studies of
the SMC Cepheid population. Finally, the Str\""omgren photometry obtained for
this study is made publicly available.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:45:45 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 02:04:18 GMT""}]","2021-04-29"
"2101.12735","Igor Moskalenko","M. J. Boschini, S. Della Torre, M. Gervasi, D. Grandi, G. Johannesson,
  G. La Vacca, N. Masi, I. V. Moskalenko, S. Pensotti, T. A. Porter, L.
  Quadrani, P. G. Rancoita, D. Rozza, M. Tacconi","A discovery of a low-energy excess in cosmic-ray iron: an evidence of
  the past supernova activity in the Local Bubble","12 pages, 9 figures, 5 tables; Accepted for publication in the
  Astrophysical Journal. arXiv admin note: text overlap with arXiv:2006.01337","The Astrophysical Journal 913 (2021) 5","10.3847/1538-4357/abf11c",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Since its launch, the Alpha Magnetic Spectrometer - 02 (AMS-02) has delivered
outstanding quality measurements of the spectra of cosmic-ray (CR) species,
$\bar{p}$, $e^{\pm}$, and nuclei, $_1$H-$_8$O, $_{10}$Ne, $_{12}$Mg, $_{14}$Si,
which resulted in a number of breakthroughs. One of the latest long awaited
surprises is the spectrum of $_{26}$Fe just published by AMS-02. Because of the
large fragmentation cross section and large ionization energy losses, most of
CR iron at low energies is local, and may harbor some features associated with
relatively recent supernova (SN) activity in the solar neighborhood. Our
analysis of new iron spectrum together with Voyager 1 and ACE-CRIS data reveals
an unexpected bump in the iron spectrum and in the Fe/He, Fe/O, and Fe/Si
ratios at 1-2 GV, while a similar feature in the spectra of He, O, Si, and in
their ratios is absent, hinting at a local source of low-energy CRs. The found
excess fits well with recent discoveries of radioactive $^{60}$Fe deposits in
terrestrial and lunar samples, and in CRs. We provide an updated local
interstellar spectrum (LIS) of iron in the energy range from 1 MeV
nucleon$^{-1}$ to $\sim$10 TeV nucleon$^{-1}$. Our calculations employ the
GalProp-HelMod framework that is proved to be a reliable tool in deriving the
LIS of CR $\bar{p}$, $e^{-}$, and nuclei $Z\le28$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:47:14 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 03:07:13 GMT""}]","2021-09-07"
"2101.12736","Osman Ramadan","Osman Ramadan, James Withers, Douglas Orr","N-grams Bayesian Differential Privacy","12 pages, 6 figures",,,,"cs.CR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential privacy has gained popularity in machine learning as a strong
privacy guarantee, in contrast to privacy mitigation techniques such as
k-anonymity. However, applying differential privacy to n-gram counts
significantly degrades the utility of derived language models due to their
large vocabularies. We propose a differential privacy mechanism that uses
public data as a prior in a Bayesian setup to provide tighter bounds on the
privacy loss metric epsilon, and thus better privacy-utility trade-offs. It
first transforms the counts to log space, approximating the distribution of the
public and private data as Gaussian. The posterior distribution is then
evaluated and softmax is applied to produce a probability distribution. This
technique achieves up to 85% reduction in KL divergence compared to previously
known mechanisms at epsilon equals 0.1. We compare our mechanism to k-anonymity
in a n-gram language modelling task and show that it offers competitive
performance at large vocabulary sizes, while also providing superior privacy
protection.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:48:49 GMT""}]","2021-02-01"
"2101.12737","I. Elizabeth Kumar","Leif Hancox-Li and I. Elizabeth Kumar","Epistemic values in feature importance methods: Lessons from feminist
  epistemology","Accepted to ACM FAccT 2021",,"10.1145/3442188.3445943",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the public seeks greater accountability and transparency from machine
learning algorithms, the research literature on methods to explain algorithms
and their outputs has rapidly expanded. Feature importance methods form a
popular class of explanation methods. In this paper, we apply the lens of
feminist epistemology to recent feature importance research. We investigate
what epistemic values are implicitly embedded in feature importance methods and
how or whether they are in conflict with feminist epistemology. We offer some
suggestions on how to conduct research on explanations that respects feminist
epistemic values, taking into account the importance of social context, the
epistemic privileges of subjugated knowers, and adopting more interactional
ways of knowing.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:51:46 GMT""}]","2021-02-01"
"2101.12738","Charles Steinhardt","Charles L. Steinhardt, Michael I. Andersen, Gabriel B. Brammer, Lise
  Christensen, Johan P. U. Fynbo, Bo Milvang-Jensen, Pascal A. Oesch, Sune Toft","A more probable explanation for a continuum flash in the direction of a
  redshift $\approx$ 11 galaxy",,,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work reported the discovery of a gamma-ray burst (GRB) associated with
the galaxy GN-z11 at $z\sim 11$. The extreme improbability of the transient
source being a GRB in the very early Universe requires robust elimination of
all plausible alternative hypotheses. We identify numerous examples of similar
transient signals in separate archival MOSFIRE observations and argue that
Solar system objects -- natural or artificial -- are a far more probable
explanation for these phenomena. An appendix has been added in response to
additional points raised in Jiang et al. (2021), which do not change the
conclusion.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:52:22 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 17:29:17 GMT""}]","2021-02-23"
"2101.12739","S\'ebastien Lord","Anne Broadbent, Stacey Jeffery, S\'ebastien Lord, Supartha Podder,
  Aarthi Sundaram","Secure Software Leasing Without Assumptions","41 pages, 5 figures","Proceedings of the 19th Theory of Cryptography Conference (TCC
  2021), pp. 90-120","10.1007/978-3-030-90459-3_4",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum cryptography is known for enabling functionalities that are
unattainable using classical information alone. Recently, Secure Software
Leasing (SSL) has emerged as one of these areas of interest. Given a target
circuit $C$ from a circuit class, SSL produces an encoding of $C$ that enables
a recipient to evaluate $C$, and also enables the originator of the software to
verify that the software has been returned -- meaning that the recipient has
relinquished the possibility of any further use of the software. Clearly, such
a functionality is unachievable using classical information alone, since it is
impossible to prevent a user from keeping a copy of the software. Recent
results have shown the achievability of SSL using quantum information for a
class of functions called compute-and-compare (these are a generalization of
the well-known point functions). These prior works, however all make use of
setup or computational assumptions. Here, we show that SSL is achievable for
compute-and-compare circuits without any assumptions.
  Our technique involves the study of quantum copy-protection, which is a
notion related to SSL, but where the encoding procedure inherently prevents a
would-be quantum software pirate from splitting a single copy of an encoding
for $C$ into two parts, each of which enables a user to evaluate $C$. We show
that point functions can be copy-protected without any assumptions, for a novel
security definition involving one honest and one malicious evaluator; this is
achieved by showing that from any quantum message authentication code, we can
derive such an honest-malicious copy-protection scheme. We then show that a
generic honest-malicious copy-protection scheme implies SSL; by prior work,
this yields SSL for compute-and-compare functions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:52:43 GMT""}]","2023-04-04"
"2101.12740","Felix Weilacher","Felix Weilacher","Borel Vizing's Theorem for 2-Ended Groups",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We show that Vizing's Theorem holds in the Borel context for graphs induced
by actions of 2-ended groups, and ask whether it holds more generally for
everywhere two ended Borel graphs.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:54:18 GMT""}]","2021-02-01"
"2101.12741","Renshen Wang","Renshen Wang, Yasuhisa Fujii and Ashok C. Popat","Post-OCR Paragraph Recognition by Graph Convolutional Networks","Published in WACV 2022",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose a new approach for paragraph recognition in document images by
spatial graph convolutional networks (GCN) applied on OCR text boxes. Two
steps, namely line splitting and line clustering, are performed to extract
paragraphs from the lines in OCR results. Each step uses a beta-skeleton graph
constructed from bounding boxes, where the graph edges provide efficient
support for graph convolution operations. With only pure layout input features,
the GCN model size is 3~4 orders of magnitude smaller compared to R-CNN based
models, while achieving comparable or better accuracies on PubLayNet and other
datasets. Furthermore, the GCN models show good generalization from synthetic
training data to real-world images, and good adaptivity for variable document
styles.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:54:53 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 19:17:29 GMT""},{""version"":""v3"",""created"":""Wed, 26 May 2021 22:05:02 GMT""},{""version"":""v4"",""created"":""Tue, 20 Jul 2021 18:53:39 GMT""},{""version"":""v5"",""created"":""Thu, 16 Sep 2021 20:57:54 GMT""},{""version"":""v6"",""created"":""Tue, 15 Nov 2022 18:56:11 GMT""}]","2022-11-16"
"2101.12742","Eden Figueroa","Dounan Du, Paul Stankus, Olli-Pentti Saira, Mael Flament, Steven
  Sagona-Stophel, Mehdi Namazi, Dimitrios Katramatos, Eden Figueroa","An elementary 158 km long quantum network connecting room temperature
  quantum memories","17 pages, 11 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  First-generation long-distance quantum repeater networks require quantum
memories capable of interfacing with telecom photons to perform
quantum-interference-mediated entanglement generation operations. The ability
to demonstrate these interconnections using real-life fiber connections in a
long-distance setting is paramount to realize a scalable quantum internet. Here
we address these significant challenges by observing Hong-Ou-Mandel (HOM)
interference between indistinguishable telecom photons produced in two
independent room temperature quantum memories, separated by a distance of 158
km. We obtained interference visibilities after long-distance propagation of
$\rm \boldsymbol{V=(38\pm2)\%}$ for single-photon level experimental inputs.
This first-of-its-kind quantum network prototype connecting quantum
laboratories in Stony Brook University and Brookhaven National Laboratory is
envisioned to evolve into a large-scale memory-assisted entanglement
distribution quantum network, the basis for inter-city quantum communication.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:55:18 GMT""}]","2021-02-01"
"2101.12743","Mads Hustad Sand{\o}y","Johanne Haugland and Mads Hustad Sand{\o}y","Higher Koszul duality and connections with $n$-hereditary algebras","43 pages. Minor changes",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a connection between two areas of independent interest in
representation theory, namely Koszul duality and higher homological algebra.
This is done through a generalization of the notion of $T$-Koszul algebras, for
which we obtain a higher version of classical Koszul duality. Our approach is
motivated by and has applications for $n$-hereditary algebras. In particular,
we characterize an important class of $n$-$T$-Koszul algebras of highest degree
$a$ in terms of $(na-1)$-representation infinite algebras. As a consequence, we
see that an algebra is $n$-representation infinite if and only if its trivial
extension is $(n+1)$-Koszul with respect to its degree $0$ part. Furthermore,
we show that when an $n$-representation infinite algebra is $n$-representation
tame, then the bounded derived categories of graded modules over the trivial
extension and over the associated $(n+1)$-preprojective algebra are equivalent.
In the $n$-representation finite case, we introduce the notion of almost
$n$-$T$-Koszul algebras and obtain similar results.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:57:24 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 13:20:38 GMT""},{""version"":""v3"",""created"":""Tue, 5 Oct 2021 07:38:11 GMT""}]","2021-10-06"
"2101.12744","Giovanni Antonio Chirilli","Giovanni Antonio Chirilli","High-energy Operator Product Expansion at sub-eikonal level","82 pages, 16 figures, JHEP version with typos corrected, references
  added",,"10.1007/JHEP06(2021)096",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The high energy Operator Product Expansion for the product of two
electromagnetic currents is extended to the sub-eikonal level in a rigorous
way. I calculate the impact factors for polarized and unpolarized structure
functions, define new distribution functions, and derive the evolution
equations for unpolarized and polarized structure functions in the flavor
singlet and non-singlet case.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:57:52 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 18:59:13 GMT""},{""version"":""v3"",""created"":""Tue, 3 Aug 2021 10:03:26 GMT""}]","2021-08-04"
"2101.12745","Zihan Zhang","Zihan Zhang, Jiaqi Yang, Xiangyang Ji, Simon S. Du","Improved Variance-Aware Confidence Sets for Linear Bandits and Linear
  Mixture MDP","31 pages",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents new \emph{variance-aware} confidence sets for linear
bandits and linear mixture Markov Decision Processes (MDPs). With the new
confidence sets, we obtain the follow regret bounds: For linear bandits, we
obtain an $\tilde{O}(poly(d)\sqrt{1 + \sum_{k=1}^{K}\sigma_k^2})$
data-dependent regret bound, where $d$ is the feature dimension, $K$ is the
number of rounds, and $\sigma_k^2$ is the \emph{unknown} variance of the reward
at the $k$-th round. This is the first regret bound that only scales with the
variance and the dimension but \emph{no explicit polynomial dependency on $K$}.
When variances are small, this bound can be significantly smaller than the
$\tilde{\Theta}\left(d\sqrt{K}\right)$ worst-case regret bound. For linear
mixture MDPs, we obtain an $\tilde{O}(poly(d, \log H)\sqrt{K})$ regret bound,
where $d$ is the number of base models, $K$ is the number of episodes, and $H$
is the planning horizon. This is the first regret bound that only scales
\emph{logarithmically} with $H$ in the reinforcement learning with linear
function approximation setting, thus \emph{exponentially improving} existing
results, and resolving an open problem in \citep{zhou2020nearly}. We develop
three technical ideas that may be of independent interest: 1) applications of
the peeling technique to both the input norm and the variance magnitude, 2) a
recursion-based estimator for the variance, and 3) a new convex potential lemma
that generalizes the seminal elliptical potential lemma.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:57:52 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 15:46:46 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 14:02:24 GMT""},{""version"":""v4"",""created"":""Fri, 29 Oct 2021 08:14:46 GMT""}]","2021-11-01"
"2101.12746","Mads Hustad Sand{\o}y","Mads Hustad Sand{\o}y and Louis-Philippe Thibault","Classification results for $n$-hereditary monomial algebras","20 pages",,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify $n$-hereditary monomial algebras in three natural contexts:
First, we give a classification of the $n$-hereditary truncated path algebras.
We show that they are exactly the $n$-representation-finite Nakayama algebras
classified by Vaso. Next, we classify partially the $n$-hereditary quadratic
monomial algebras. In the case $n=2$, we prove that there are only two
examples, provided that the preprojective algebra is a planar quiver with
potential. The first one is a Nakayama algebra and the second one is obtained
by mutating $\mathbb A_3\otimes_k \mathbb A_3$, where $\mathbb A_3$ is the
Dynkin quiver of type $A$ with bipartite orientation. In the case $n\geq 3$, we
show that the only $n$-representation finite algebras are the
$n$-representation-finite Nakayama algebras with quadratic relations.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:57:58 GMT""}]","2021-02-01"
"2101.12747","Josefina L\'opez","Josefina L\'opez and Peter Stoll","The 3x+1 Periodicity Conjeture in $\mathbb{R}$","51 pages, 18 figures",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  The $3x+1$ map $T$ is defined on the $2$-adic integers $\mathbb{Z}_2$ by
$T(x)=x/2$ for even $x$ and $T(x)=(3x+1)/2$ for odd $x$. It is still unproved
that under iteration of $T$ the trajectory of any rational $2$-adic integer is
eventually cyclic. A $2$-adic integer is rational if and only if its
representation with $1$'s and $0$'s is eventually periodic. We prove that the
$3x+1$ conjugacy $\Phi$ maps aperiodic $v\in\mathbb{Z}_2$ onto aperiodic
$2$-adic integers provided that
$\underline{\lim}\;(\frac{h}{\ell})_{\ell=1}^{\infty} > \frac{\ln(2)}{\ln(3)}$
where $h$ is the number of $1$'s in the first $\ell$ digits of $v$ with the
following constraint: if there is a rational $2$-adic integer with a non-cyclic
trajectory, then necessarily
$\underline{\lim}\;(\frac{h}{\ell})_{\ell=1}^{\infty}=\frac{\ln(2)}{\ln(3)}$.
We study $\Phi$ as an infinite series in $\mathbb{R}$ and obtain negative
irrational numbers for which we compute their aperiodic $2$-adic expansion. We
find prominent behaviors of the orbit of $x$ taking Sturmian words as parity
vector. We also found amazing results of the terms of $\Phi$ in $\mathbb{R}$.
We define the $\ell$'th iterate of $T$ for $\ell\rightarrow \infty$ in the ring
of $3$-adic integers and obtain positive irrational numbers for which we
compute their aperiodic $3$-adic expansion.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:58:24 GMT""}]","2021-02-01"
"2102.00004","Ibrahima Ndoye","Abderrazak Chahid, Ibrahima N'Doye, John E. Majoris, Michael L.
  Berumen, Taous-Meriem Laleg-Kirati","Model Predictive Control Paradigms for Fish Growth Reference Tracking in
  Precision Aquaculture",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In precision aquaculture, the primary goal is to maximize biomass production
while minimizing production costs. This objective can be achieved by optimizing
factors that have a strong influence on fish growth, such as the feeding rate,
temperature, and dissolved oxygen. This paper provides a comparative study of
three model predictive control (MPC) strategies for fish growth reference
tracking under a representative bioenergetic growth model in precision
aquaculture. We propose to evaluate three candidate MPC formulations for fish
growth reference tracking based on the receding horizon. The first MPC
formulation tracks a desired fish growth trajectory while penalizing the feed
ration, temperature, and dissolved oxygen. The second MPC optimization strategy
directly penalizes the feed conversion ratio (FCR), which is the ratio between
food quantity and fish weight gain while minimizing the actual growth state's
deviation from the given reference growth trajectory. The third MPC formulation
includes a tradeoff between the growth rate trajectory tracking, the dynamic
energy and the cost of food. Numerical simulations that integrate a realistic
bioenergetic fish growth model of Nile tilapia (Oreochromis niloticus) are
illustrated to examine the comparative performance of the three proposed
optimal control strategies.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:11:34 GMT""}]","2021-02-02"
"2102.00005","Ore Gottlieb","Ore Gottlieb, Omer Bromberg, Amir Levinson, Ehud Nakar","Intermittent mildly magnetized jets as the source of GRBs",,,"10.1093/mnras/stab1068",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gamma-ray bursts (GRBs) are powered by relativistic jets that exhibit
intermittency over a broad range of timescales - from $ \sim $ ms to seconds.
Previous numerical studies have shown that hydrodynamic (i.e., unmagnetized)
jets that are expelled from a variable engine are subject to strong mixing of
jet and cocoon material, which strongly inhibits the GRB emission. In this
paper we conduct 3D RMHD simulations of mildly magnetized jets with power
modulation over durations of 0.1 s and 1 s, and a steady magnetic field at
injection. We find that when the jet magnetization at the launching site is
$\sigma \sim 0.1$, the initial magnetization is amplified by shocks formed in
the flow to the point where it strongly suppresses baryon loading. We estimate
that a significant contamination can be avoided if the magnetic energy at
injection constitutes at least a few percent of the jet energy. The variability
timescales of the jet after it breaks out of the star are then governed by the
injection cycles rather than by the mixing process, suggesting that in practice
jet injection should fluctuate on timescales as short as $ \sim 10 $ ms in
order to account for the observed light curves. Better stability is found for
jets with shorter modulations. We conclude that for sufficiently hot jets, the
Lorentz factor near the photosphere can be high enough to allow efficient
photospheric emission. Our results imply that jets with $ 10^{-2} < \sigma < 1
$ injected by a variable engine with $ \sim 10 $ ms duty cycle are plausible
sources of long GRBs.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 12:10:04 GMT""}]","2021-04-28"
"2102.00006","Wen Yin","Joerg Jaeckel and Wen Yin","The Spectrum of Dark Radiation as a Probe of Reheating","11 pages, 6 figures","Phys. Rev. D 103, 115019 (2021)","10.1103/PhysRevD.103.115019",,"hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After inflation the Universe presumably undergoes a phase of reheating which
in effect starts the thermal big bang cosmology. However, so far we have very
little direct experimental or observational evidence of this important phase of
the Universe. In this letter, we argue that measuring the spectrum of freely
propagating relativistic particles, i.e. dark radiation, produced during
reheating may provide us with powerful information on the reheating phase. To
demonstrate this possibility we consider a situation where the dark radiation
is produced in the decays of heavy, non-relativistic particles. We show that
the spectrum crucially depends on whether the heavy particle once dominated the
Universe or not. Characteristic features caused by the dependence on the number
of the relativistic degrees of freedom may even allow to infer the temperature
when the decay of the heavy particle occurred.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:00 GMT""}]","2021-06-23"
"2102.00007","Rodrigo Luger","Rodrigo Luger, Daniel Foreman-Mackey, Christina Hedges, and David W.
  Hogg","Mapping stellar surfaces I: Degeneracies in the rotational light curve
  problem","33 pages, 12 figures. To be submitted to AAS Journals. Updated
  references",,"10.3847/1538-3881/abfdb8",,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thanks to missions like Kepler and TESS, we now have access to tens of
thousands of high precision, fast cadence, and long baseline stellar
photometric observations. In principle, these light curves encode a vast amount
of information about stellar variability and, in particular, about the
distribution of starspots and other features on their surfaces. Unfortunately,
the problem of inferring stellar surface properties from a rotational light
curve is famously ill-posed, as it often does not admit a unique solution.
Inference about the number, size, contrast, and location of spots can therefore
depend very strongly on the assumptions of the model, the regularization
scheme, or the prior. The goal of this paper is twofold: (1) to explore the
various degeneracies affecting the stellar light curve ""inversion"" problem and
their effect on what can and cannot be learned from a stellar surface given
unresolved photometric measurements; and (2) to motivate ensemble analyses of
the light curves of many stars at once as a powerful data-driven alternative to
common priors adopted in the literature. We further derive novel results on the
dependence of the null space on stellar inclination and limb darkening and show
that single-band photometric measurements cannot uniquely constrain quantities
like the total spot coverage without the use of strong priors. This is the
first in a series of papers devoted to the development of novel algorithms and
tools for the analysis of stellar light curves and spectral time series, with
the explicit goal of enabling statistically robust inference about their
surface properties.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 14:24:41 GMT""}]","2021-09-08"
"2102.00008","Andrea Fontanella","Andrea Fontanella, Juan Miguel Nieto Garc\'ia and Alessandro Torrielli","Light-Cone Gauge in Non-Relativistic AdS$_5\times$S$^5$ String Theory","30 pages, Mathematica notebook attached, v4: the expansion is made
  around the BMN-like solution found in arXiv:2109.13240. New comments are
  added in the Introduction and Conclusions sections",,,"HU-EP-21/02, DMUS-MP-21/01","hep-th math-ph math.MP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We consider the problem of fixing uniform light-cone gauge in the bosonic
sector of non-relativistic AdS$_5\times$S$^5$ string theory found by J. Gomis,
J. Gomis and K. Kamimura. We show that if the common AdS$_5$ and S$^5$ radius
is kept large and we expand the action around the twisted BMN-like string
solution found in arXiv:2109.13240, the light-cone gauge fixed model describes
at leading order in the large string tension expansion the dynamics of 8
bosonic free massless scalars in Mink$_2$. We discuss limitations and potential
issues of fixing the light-cone gauge in the case where one evades the large
radius assumption.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 18:34:08 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 10:15:15 GMT""},{""version"":""v4"",""created"":""Wed, 29 Sep 2021 13:06:21 GMT""}]","2021-09-30"
"2102.00009","Paolo Simone Molignini","Paolo Molignini, Albert Gasull Celades, R. Chitra, Wei Chen","Cross-dimensional universality classes in static and periodically driven
  Kitaev models","14 pages, 11 figures","Phys. Rev. B 103, 184507 (2021)","10.1103/PhysRevB.103.184507",,"cond-mat.str-el cond-mat.stat-mech cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Kitaev model on the honeycomb lattice is a paradigmatic system known to
host a wealth of nontrivial topological phases and Majorana edge modes. In the
static case, the Majorana edge modes are nondispersive. When the system is
periodically driven in time, such edge modes can disperse and become chiral. We
obtain the full phase diagram of the driven model as a function of the coupling
and the driving period. We characterize the quantum criticality of the
different topological phase transitions in both the static and driven model via
the notions of Majorana-Wannier state correlation functions and
momentum-dependent fidelity susceptibilities. We show that the system hosts
cross-dimensional universality classes: although the static Kitaev model is
defined on a 2D honeycomb lattice, its criticality falls into the universality
class of 1D linear Dirac models. For the periodically driven Kitaev model,
besides the universality class of prototype 2D linear Dirac models, an
additional 1D nodal loop type of criticality exists owing to emergent
time-reversal and mirror symmetries, indicating the possibility of engineering
multiple universality classes by periodic driving. The manipulation of
time-reversal symmetry allows the periodic driving to control the chirality of
the Majorana edge states.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 12:58:33 GMT""}]","2021-05-19"
"2102.00010","Thomas Schuster","Thomas Schuster, Bryce Kobrin, Ping Gao, Iris Cong, Emil T.
  Khabiboulline, Norbert M. Linke, Mikhail D. Lukin, Christopher Monroe, Beni
  Yoshida, Norman Y. Yao","Many-body quantum teleportation via operator spreading in the
  traversable wormhole protocol","41 + 24 pages, 12 figures","Physical Review X 12, 031013 (2022)","10.1103/PhysRevX.12.031013",,"quant-ph cond-mat.quant-gas gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  By leveraging shared entanglement between a pair of qubits, one can teleport
a quantum state from one particle to another. Recent advances have uncovered an
intrinsically many-body generalization of quantum teleportation, with an
elegant and surprising connection to gravity. In particular, the teleportation
of quantum information relies on many-body dynamics, which originate from
strongly-interacting systems that are holographically dual to gravity; from the
gravitational perspective, such quantum teleportation can be understood as the
transmission of information through a traversable wormhole. Here, we propose
and analyze a new mechanism for many-body quantum teleportation -- dubbed
peaked-size teleportation. Intriguingly, peaked-size teleportation utilizes
precisely the same type of quantum circuit as traversable wormhole
teleportation, yet has a completely distinct microscopic origin: it relies upon
the spreading of local operators under generic thermalizing dynamics and not
gravitational physics. We demonstrate the ubiquity of peaked-size
teleportation, both analytically and numerically, across a diverse landscape of
physical systems, including random unitary circuits, the Sachdev-Ye-Kitaev
model (at high temperatures), one-dimensional spin chains and a bulk theory of
gravity with stringy corrections. Our results pave the way towards using
many-body quantum teleportation as a powerful experimental tool for: (i)
characterizing the size distributions of operators in strongly-correlated
systems and (ii) distinguishing between generic and intrinsically gravitational
scrambling dynamics. To this end, we provide a detailed experimental blueprint
for realizing many-body quantum teleportation in both trapped ions and Rydberg
atom arrays; effects of decoherence and experimental imperfections are
analyzed.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 21:22:29 GMT""}]","2022-08-09"
"2102.00011","Denis Krotov","Minjia Shi, Denis S. Krotov, Xiaoxiao Li, Patrick Sol\'e","Zero sum sets in abelian groups","The result is not new, see [J. Li and D. Wan, Counting subset sums of
  finite abelian groups, J. Combin. Theory, Ser. A, 119(1) (2012), 170-182]",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distribution of cardinalities of zero-sum sets in abelian groups is
completely determined. A complex summation involving the M\""obius function is
given for the general abelian group, while in many special cases, including the
case of elementary abelian groups, solved earlier by Li and Wan, it has a
compact form. The proof involves two different M\""obius transforms, on positive
integers and on set partitions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 16:13:07 GMT""}]","2021-02-09"
"2102.00012","Pablo Quilez","Luca Di Luzio, Belen Gavela, Pablo Quilez, Andreas Ringwald","An even lighter QCD axion","35 pages and 11 figures; matches JHEP version",,"10.1007/JHEP05(2021)184","DESY 21-010, IFT-UAM/CSIC-20-143, FTUAM-20-21","hep-ph hep-ex hep-th","http://creativecommons.org/licenses/by/4.0/","  We explore whether the axion which solves the strong CP problem can naturally
be much lighter than the canonical QCD axion. The $Z_\mathcal{N}$ symmetry
proposed by Hook, with $\mathcal{N}$ mirror and degenerate worlds coexisting in
Nature and linked by the axion field, is considered in terms of generic
effective axion couplings. We show that the total potential is safely
approximated by a single cosine in the large $\mathcal{N}$ limit, and we
determine the analytical formula for the exponentially suppressed axion mass.
The resulting universal enhancement of all axion interactions relative to those
of the canonical QCD axion has a strong impact on the prospects of axion-like
particle experiments such as ALPS II, IAXO and many others. The finite density
axion potential is also analyzed and we show that the $Z_\mathcal{N}$
asymmetric background of high-density stellar environments sets already
significant model-independent constraints: $3\le\mathcal{N}\lesssim47$ for an
axion scale $f_a\lesssim 2.4\times10^{15}$ GeV, with tantalizing discovery
prospects for any value of $f_a$ and down to $\mathcal{N}\sim9$ with future
neutron star and gravitational wave data, down to the ultra-light mass region.
In addition, two specific ultraviolet $Z_\mathcal{N}$ completions are
developed: a composite axion one and a KSVZ-like model with improved
Peccei-Quinn quality.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 12:28:03 GMT""}]","2021-08-12"
"2102.00013","Michal P. Heller","Hugo A. Camargo, Lucas Hackl, Michal P. Heller, Alexander Jahn, Bennet
  Windt","Long-distance entanglement of purification and reflected entropy in
  conformal field theory","5 pages, 2 figures + appendices; v2: previous results unchanged,
  added proof of the long-distance behaviour of EoP, reorganized presentation","Phys. Rev. Lett. 127, 141604 (2021)","10.1103/PhysRevLett.127.141604",,"hep-th cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantifying entanglement properties of mixed states in quantum field theory
via entanglement of purification and reflected entropy is a new and challenging
subject. In this work, we study both quantities for two spherical subregions
far away from each other in the vacuum of a conformal field theory in any
number of dimensions. Using lattice techniques, we find an elementary proof
that the decay of both, the entanglement of purification and reflected entropy,
is enhanced with respect to the mutual information behaviour by a logarithm of
the distance between the subregions. In the case of the Ising spin chain at
criticality and the related free fermion conformal field theory, we compute
also the overall coefficients numerically for the both quantities of interest.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 00:37:31 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 16:30:29 GMT""}]","2021-10-04"
"2102.00014","Emily Zinnia Zhang","Emily Z. Zhang, Li Ern Chern, Yong Baek Kim","Topological magnons for thermal Hall transport in frustrated magnets
  with bond-dependent interactions","9+4 pages, 17 figures","Phys. Rev. B 103, 174402 (2021)","10.1103/PhysRevB.103.174402",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal transport in topologically-ordered phases of matter provides valuable
insights as it can detect the charge-neutral quasiparticles that would not
directly couple to electromagnetic probes. An important example is edge heat
transport of Majorana fermions in a chiral spin liquid, which leads to a
half-quantized thermal Hall conductivity. This signature is precisely what has
recently been measured in $\alpha$-RuCl$_3$ under external magnetic fields. The
plateau-like behavior of the half-quantized thermal Hall conductivity as a
function of external magnetic field, and the peculiar sign change depending on
the magnetic field orientation, has been proposed as strong evidence for the
non-Abelian Kitaev spin liquid. Alternatively, for in-plane magnetic fields, it
was theoretically shown that such a sign structure can also arise from
topological magnons in the field-polarized state. In this work, we investigate
the full implications of topological magnons as heat carriers on thermal
transport measurements. We first prove analytically that for any commensurate
order with a finite magnetic unit cell, reversing the field direction leads to
a sign change in the magnon thermal Hall conductivity in two-dimensional
systems. We verify this proof numerically with nontrivial magnetic orders as
well as the field-polarized state in Kitaev magnets subjected to an in-plane
field. In the case of a tilted magnetic field, whereby there exist both finite
in-plane and out-of-plane field components, we find that the plateau-like
behavior of the thermal Hall conductivity and the sign change upon reversing
the in-plane component of the magnetic field arise in the partially-polarized
state, as long as the in-plane field contribution to the Zeeman energy is
significant. While these results are consistent with the experimental
observations, we comment on other aspects requiring investigation in future
studies.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 24 Jan 2023 21:26:47 GMT""}]","2023-01-26"
"2102.00015","Lorenz Zwick","Lorenz Zwick, Pedro R. Capelo, Elisa Bortolas, Veronica
  Vazquez-Aceves, Lucio Mayer, Pau Amaro-Seoane","Improved gravitational radiation time-scales II: spin-orbit
  contributions and environmental perturbations","Accepted for publication in MNRAS. Comments welcome!",,"10.1093/mnras/stab1818",,"astro-ph.GA astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peters' formula is an analytical estimate of the time-scale of gravitational
wave (GW)-induced coalescence of binary systems. It is used in countless
applications, where the convenience of a simple formula outweighs the need for
precision. However, many promising sources of the Laser Interferometer Space
Antenna (LISA), such as supermassive black hole binaries and extreme mass-ratio
inspirals (EMRIs), are expected to enter the LISA band with highly eccentric
($e \gtrsim$ 0.9) and highly relativistic orbits. These are exactly the two
limits in which Peters' estimate performs the worst. In this work, we expand
upon previous results and give simple analytical fits to quantify how the
inspiral time-scale is affected by the relative 1.5 post-Newtonian (PN)
hereditary fluxes and spin-orbit couplings. We discuss several cases that
demand a more accurate GW time-scale. We show how this can have a major
influence on quantities that are relevant for LISA event-rate estimates, such
as the EMRI critical semi-major axis. We further discuss two types of
environmental perturbations that can play a role in the inspiral phase: the
gravitational interaction with a third massive body and the energy loss due to
dynamical friction and torques from a surrounding gas medium ubiquitous in
galactic nuclei. With the aid of PN corrections to the time-scale in vacuum, we
find simple analytical expressions for the regions of phase space in which
environmental perturbations are of comparable strength to the effects of any
particular PN order, being able to qualitatively reproduce the results of much
more sophisticated analyses.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:05 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 18:23:21 GMT""}]","2021-07-07"
"2102.00016","Eduardo H. Da Silva Neto","F. Boschini, M. Minola, R. Sutarto, E. Schierle, M. Bluschke, S. Das,
  Y. Yang, M. Michiardi, Y. C. Shao, X. Feng, S. Ono, R. D. Zhong, J.
  Schneeloch, G. D. Guo, E. Weschke, F. He, Y. D. Chuang, B. Keimer, A.
  Damascelli, A. Frano, E. H. da Silva Neto","Dynamic electron correlations with charge order wavelength along all
  directions in the copper oxide plane","This is a post-peer-review, pre-copyedit version of an article
  published in Nature Communications. The final authenticated version is
  available online at: https://doi.org/10.1038/s41467-020-20824-7.
  Supplementary materials are available through the published version in Nature
  Communications","Nature Communications 12, 597 (2021)","10.1038/s41467-020-20824-7",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In strongly correlated systems the strength of Coulomb interactions between
electrons, relative to their kinetic energy, plays a central role in
determining their emergent quantum mechanical phases. We perform resonant x-ray
scattering on Bi$_2$Sr$_2$CaCu$_2$O$_{8+\delta}$, a prototypical cuprate
superconductor, to probe electronic correlations within the CuO$_2$ plane. We
discover a dynamic quasi-circular pattern in the $x$-$y$ scattering plane with
a radius that matches the wave vector magnitude of the well-known static charge
order. Along with doping- and temperature-dependent measurements, our
experiments reveal a picture of charge order competing with superconductivity
where short-range domains along $x$ and $y$ can dynamically rotate into any
other in-plane direction. This quasi-circular spectrum, a hallmark of
Brazovskii-type fluctuations, has immediate consequences to our understanding
of rotational and translational symmetry breaking in the cuprates. We discuss
how the combination of short- and long-range Coulomb interactions results in an
effective non-monotonic potential that may determine the quasi-circular
pattern.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:08 GMT""}]","2021-02-02"
"2102.00017","Matteo Breschi","Matteo Breschi, Rossella Gamba, Sebastiano Bernuzzi","${\tt bajes}$: Bayesian inference of multimessenger astrophysical data,
  methods and application to gravitational-waves",,"Phys. Rev. D 104, 042001 (2021)","10.1103/PhysRevD.104.042001",,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present ${\tt bajes}$, a parallel and lightweight framework for Bayesian
inference of multimessenger transients. ${\tt bajes}$ is a Python modular
package with minimal dependencies on external libraries adaptable to the
majority of the Bayesian models and to various sampling methods. We describe
the general workflow and the parameter estimation pipeline for
compact-binary-coalescence gravitational-wave transients. The latter is
validated against injections of binary black hole and binary neutron star
waveforms, including confidence interval tests that demonstrates the inference
is well-calibrated. Binary neutron star postmerger injections are also studied
using a network of five detectors made of LIGO, Virgo, KAGRA and Einstein
Telescope. Postmerger signals will be detectable for sources at
${\lesssim}80\,$Mpc, with Einstein Telescope contributing over 90\% of the
total signal-to-noise ratio. As a full scale application, we re-analyze the
GWTC-1 black hole transients using the effective-one-body ${\tt TEOBResumS}$
approximant, and reproduce selected results with other approximants. ${\tt
bajes}$ inferences are consistent with previous results; the direct comparison
of ${\tt bajes}$ and ${\tt bilby}$ analyses of GW150914 shows a maximum
Jensen-Shannon divergence of $5.2{\times}10^{-4}$. GW170817 is re-analyzed
using ${\tt TaylorF2}$ with 5.5PN point-mass and 7.5PN tides, ${\tt
TEOBResumSPA}$, and ${\tt IMRPhenomPv2\_NRTidal}$ with different
cutoff-frequencies of $1024\,$Hz and $2048\,$Hz. We find that the former choice
minimizes systematics on the reduced tidal parameter, while a larger amount of
tidal information is gained with the latter choice. ${\tt bajes}$ can perform
these analyses in about 1~day using 128 CPUs.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:13 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 14:40:19 GMT""}]","2021-08-18"
"2102.00018","Rabah Abdul Khalek","Rabah Abdul Khalek, Jacob J. Ethier, Emanuele R. Nocera, Juan Rojo","Self-consistent determination of proton and nuclear PDFs at the Electron
  Ion Collider","11 pages, 5 figures, In the context of the Electron-Ion collider
  yellow report","Phys. Rev. D 103, 096005 (2021)","10.1103/PhysRevD.103.096005","Nikhef-2020-041","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We quantify the impact of unpolarized lepton-proton and lepton-nucleus
inclusive deep-inelastic scattering (DIS) cross section measurements from the
future Electron-Ion Collider (EIC) on the proton and nuclear parton
distribution functions (PDFs). To this purpose we include neutral- and
charged-current DIS pseudodata in a self-consistent set of proton and nuclear
global PDF determinations based on the NNPDF methodology. We demonstrate that
the EIC measurements will reduce the uncertainty of the light quark PDFs of the
proton at large values of the momentum fraction $x$, and, more significantly,
of the quark and gluon PDFs of heavy nuclei, especially at small and large $x$.
We illustrate the implications of the improved precision of nuclear PDFs for
the interaction of ultra-high energy cosmic neutrinos with matter.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:16 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 16:51:40 GMT""}]","2021-05-19"
"2102.00019","Kevin Zhang","Kevin Zhang, Samuel Lederer, Kenny Choo, Titus Neupert, Giuseppe
  Carleo, Eun-Ah Kim","Hamiltonian reconstruction as metric for variational studies","6 pages, 3 figures, plus 5 pages of supplemental material",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational approaches are among the most powerful modern techniques to
approximately solve quantum many-body problems. These encompass both
variational states based on tensor or neural networks, and parameterized
quantum circuits in variational quantum eigensolvers. However, self-consistent
evaluation of the quality of variational wavefunctions is a notoriously hard
task. Using a recently developed Hamiltonian reconstruction method, we propose
a multi-faceted approach to evaluating the quality of neural-network based
wavefunctions. Specifically, we consider convolutional neural network (CNN) and
restricted Boltzmann machine (RBM) states trained on a square lattice spin-1/2
$J_1$-$J_2$ Heisenberg model. We find that the reconstructed Hamiltonians are
typically less frustrated, and have easy-axis anisotropy near the high
frustration point. Furthermore, the reconstructed Hamiltonians suppress quantum
fluctuations in the large $J_2$ limit. Our results highlight the critical
importance of the wavefunction's symmetry. Moreover, the multi-faceted insight
from the Hamiltonian reconstruction reveals that a variational wave function
can fail to capture the true ground state through suppression of quantum
fluctuations.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:25 GMT""}]","2021-02-02"
"2102.00020","Lu Cao","Belle Collaboration: L. Cao, W. Sutcliffe, R. Van Tonder, F. U.
  Bernlochner, I. Adachi, H. Aihara, S. Al Said, D. M. Asner, H. Atmacan, T.
  Aushev, R. Ayad, V. Babu, M. Bauer, P. Behera, K. Belous, J. Bennett, M.
  Bessner, V. Bhardwaj, T. Bilka, J. Biswal, G. Bonvicini, A. Bozek, M.
  Bra\v{c}ko, T. E. Browder, M. Campajola, D. \v{C}ervenkov, M.-C. Chang, P.
  Chang, V. Chekelian, A. Chen, B. G. Cheon, K. Chilikin, H. E. Cho, K. Cho,
  S.-J. Cho, S.-K. Choi, Y. Choi, S. Choudhury, D. Cinabro, S. Cunliffe, S.
  Das, N. Dash, G. De Nardo, F. Di Capua, J. Dingfelder, Z. Dole\v{z}al, T. V.
  Dong, S. Dubey, S. Eidelman, D. Epifanov, T. Ferber, D. Ferlewicz, A. Frey,
  B. G. Fulsom, R. Garg, V. Gaur, A. Garmash, A. Giri, P. Goldenzweig, Y. Guan,
  C. Hadjivasiliou, T. Hara, O. Hartbrich, K. Hayasaka, H. Hayashii, M. T.
  Hedges, M. Hernandez Villanueva, W.-S. Hou, C.-L. Hsu, T. Iijima, K. Inami,
  A. Ishikawa, R. Itoh, M. Iwasaki, Y. Iwasaki, W. W. Jacobs, E.-J. Jang, H. B.
  Jeon, S. Jia, Y. Jin, C. W. Joo, K. K. Joo, K. H. Kang, G. Karyan, T.
  Kawasaki, H. Kichimi, C. Kiesling, B. H. Kim, C. H. Kim, D. Y. Kim, H. J.
  Kim, K.-H. Kim, S. H. Kim, Y.-K. Kim, K. Kinoshita, P. Kody\v{s}, T. Konno,
  A. Korobov, S. Korpar, D. Kotchetkov, E. Kovalenko, P. Kri\v{z}an, R.
  Kroeger, P. Krokovny, T. Kuhr, M. Kumar, R. Kumar, K. Kumara, A. Kuzmin,
  Y.-J. Kwon, K. Lalwani, J. S. Lange, I. S. Lee, S. C. Lee, P. Lewis, C. H.
  Li, J. Li, L. K. Li, Y. B. Li, L. Li Gioi, J. Libby, K. Lieret, Z. Liptak, D.
  Liventsev, J. MacNaughton, C. MacQueen, M. Masuda, T. Matsuda, D. Matvienko,
  M. Merola, F. Metzner, K. Miyabayashi, R. Mizuk, G. B. Mohanty, T. J. Moon,
  T. Mori, M. Mrvar, R. Mussa, M. Nakao, Z. Natkaniec, A. Natochii, L. Nayak,
  M. Nayak, M. Niiyama, N. K. Nisar, S. Nishida, K. Nishimura, S. Ogawa, H.
  Ono, Y. Onuki, P. Oskin, P. Pakhlov, G. Pakhlova, T. Pang, S. Pardi, C. W.
  Park, H. Park, S.-H. Park, S. Patra, S. Paul, T. K. Pedlar, R. Pestotnik, L.
  E. Piilonen, T. Podobnik, V. Popov, E. Prencipe, M. T. Prim, M. Ritter, M.
  R\""ohrken, A. Rostomyan, N. Rout, M. Rozanska, G. Russo, D. Sahoo, Y. Sakai,
  S. Sandilya, A. Sangal, L. Santelj, T. Sanuki, V. Savinov, G. Schnell, J.
  Schueler, C. Schwanda, A. J. Schwartz, Y. Seino, K. Senyo, M. E. Sevior, M.
  Shapkin, C. Sharma, C. P. Shen, J.-G. Shiu, F. Simon, A. Sokolov, E.
  Solovieva, S. Stani\v{c}, M. Stari\v{c}, Z. S. Stottler, J. F. Strube, T.
  Sumiyoshi, M. Takizawa, U. Tamponi, K. Tanida, F. Tenchini, K. Trabelsi, M.
  Uchida, T. Uglov, Y. Unno, S. Uno, P. Urquijo, Y. Usov, S. E. Vahsen, G.
  Varner, K. E. Varvell, A. Vinokurova, V. Vorobyev, A. Vossen, E. Waheed, C.
  H. Wang, E. Wang, M.-Z. Wang, P. Wang, M. Watanabe, S. Watanuki, S. Wehle, J.
  Wiechczynski, E. Won, X. Xu, B. D. Yabsley, W. Yan, S. B. Yang, H. Ye, J. H.
  Yin, C. Z. Yuan, Y. Yusa, Z. P. Zhang, V. Zhilich, V. Zhukova and V. Zhulanov","Measurements of Partial Branching Fractions of Inclusive $B \to X_u \,
  \ell^+\, \nu_{\ell}$ Decays with Hadronic Tagging","34 pages, 23 figures, 7 tables. Accepted by Phys. Rev. D","Phys. Rev. D 104, 012008 (2021)","10.1103/PhysRevD.104.012008","Belle Preprint 2020-22, KEK Preprint 2020-39","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present measurements of partial branching fractions of inclusive
semileptonic $B \to X_u \, \ell^+\, \nu_{\ell}$ decays using the full Belle
data set of 711 fb$^{-1}$ of integrated luminosity at the $\Upsilon(4S)$
resonance and for $\ell = e, \mu$. Inclusive semileptonic $B \to X_u \,
\ell^+\, \nu_{\ell}$ decays are CKM suppressed and measurements are complicated
by the large background from CKM-favored $B \to X_c \, \ell^+\, \nu_{\ell}$
transitions, which have a similar signature. Using machine learning techniques,
we reduce this and other backgrounds effectively, whilst retaining access to a
large fraction of the $B \to X_u \, \ell^+\, \nu_{\ell}$ phase space and high
signal efficiency. We measure partial branching fractions in three phase-space
regions covering about $31\%$ to $86\%$ of the accessible $B \to X_u \,
\ell^+\, \nu_{\ell}$ phase space. The most inclusive measurement corresponds to
the phase space with lepton energies of $E_\ell^B > 1 $ GeV, and we obtain
$\Delta \mathcal{B}(B \to X_u \ell^+ \, \nu_\ell) = \left( 1.59 \pm 0.07 \pm
0.16 \right) \times 10^{-3}$ from a two-dimensional fit of the hadronic mass
spectrum and the four-momentum-transfer squared distribution, with the
uncertainties denoting the statistical and systematic error. We find $\left|
V_{ub} \right| = \left( 4.10 \pm 0.09 \pm 0.22 \pm 0.15 \right) \times 10^{-3}$
from an average of four calculations for the partial decay rate with the third
uncertainty denoting the average theory error. This value is higher but
compatible with the determination from exclusive semileptonic decays within 1.3
standard deviations. In addition, we report charmless inclusive partial
branching fractions separately for $B^+$ and $B^0$ mesons as well as for
electron and muon final states. No isospin breaking or lepton flavor
universality violating effects are observed.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:27 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 08:56:16 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 12:50:08 GMT""}]","2021-07-13"
"2102.00021","Christopher Portmann","Christopher Portmann and Renato Renner","Security in Quantum Cryptography","63 pages, 34 figures. In submission to RMP. Partly based on
  arXiv:1409.3525. v2: new references and minor edits",,"10.1103/RevModPhys.94.025008",,"quant-ph cs.CR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum cryptography exploits principles of quantum physics for the secure
processing of information. A prominent example is secure communication, i.e.,
the task of transmitting confidential messages from one location to another.
The cryptographic requirement here is that the transmitted messages remain
inaccessible to anyone other than the designated recipients, even if the
communication channel is untrusted. In classical cryptography, this can usually
only be guaranteed under computational hardness assumptions, e.g., that
factoring large integers is infeasible. In contrast, the security of quantum
cryptography relies entirely on the laws of quantum mechanics. Here we review
this physical notion of security, focusing on quantum key distribution and
secure communication.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:00:54 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 15:27:36 GMT""}]","2022-07-13"
"2102.00022","Joel Berg\'e","Joel Berg\'e, Martin Pernot-Borr\`as, Jean-Philippe Uzan, Philippe
  Brax, Ratana Chhun, Gilles M\'etris, Manuel Rodrigues, Pierre Touboul","MICROSCOPE's constraint on a short-range fifth force","Accepted for publication in CQG's MICROSCOPE special issue",,"10.1088/1361-6382/abe142",,"gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  The MICROSCOPE experiment was designed to test the weak equivalence principle
in space, by comparing the low-frequency dynamics of cylindrical ""free-falling""
test masses controlled by electrostatic forces. We use data taken during
technical sessions aimed at estimating the electrostatic stiffness of
MICROSCOPE's sensors to constrain a short-range Yukawa deviation from Newtonian
gravity. We take advantage of the fact that in the limit of small
displacements, the gravitational interaction (both Newtonian and Yukawa-like)
between nested cylinders is linear, and thus simply characterised by a
stiffness. By measuring the total stiffness of the forces acting on a test mass
as it moves, and comparing it with the theoretical electrostatic stiffness
(expected to dominate), it is a priori possible to infer constraints on the
Yukawa potential parameters. However, we find that measurement uncertainties
are dominated by the gold wires used to control the electric charge of the test
masses, though their related stiffness is indeed smaller than the expected
electrostatic stiffness. Moreover, we find a non-zero unaccounted for stiffness
that depends on the instrument's electric configuration, hinting at the
presence of patch-field effects. Added to significant uncertainties on the
electrostatic model, they only allow for poor constraints on the Yukawa
potential. This is not surprising, as MICROSCOPE was not designed for this
measurement, but this analysis is the first step to new experimental searches
for non-Newtonian gravity in space.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:01:05 GMT""}]","2022-09-28"
"2102.00023","Martin Pernot-Borr\`as","Martin Pernot-Borr\`as, Jo\""el Berg\'e, Philippe Brax, Jean-Philippe
  Uzan, Gilles M\'etris, Manuel Rodrigues and Pierre Touboul","Constraints on chameleon gravity from the measurement of the
  electrostatic stiffness of the MICROSCOPE mission accelerometers","Submitted to PRD","Phys. Rev. D 103, 064070 (2021)","10.1103/PhysRevD.103.064070",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  This article is dedicated to the use the MICROSCOPE mission's data to test
chameleon theory of gravity. We take advantage of the technical sessions aimed
to characterize the electrostatic stiffness of MICROSCOPE's instrument
intrinsic to its capacitive measurement system. Any discrepancy between the
expected and measured stiffness may result from unaccounted-for contributors,
i.e. extra-forces. This work considers the case of chameleon gravity as a
possible contributor. It was previously shown that in situations similar to
these measurement sessions, a chameleon fifth force appears and acts as a
stiffness for small displacements. The magnitude of this new component of the
stiffness is computed over the chameleon's parameter space. It allows us to
derive constraints by excluding any force inconsistent with the MICROSCOPE
data. As expected --since MICROSCOPE was not designed for the purpose of such
an analysis--, these new bounds are not competitive with state-of-the-art
constraints, but they could be improved by a better estimation of all effects
at play in these sessions. Hence our work illustrates this novel technique as a
new way of constraining fifth forces.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:02:01 GMT""}]","2021-03-31"
"2102.00024","Gemma Piquero","J. C. G. de Sande, Gemma Piquero, Juan Carlos Su\'arez-Bermejo and
  Massimo Santarsiero","Beams with propagation-invariant transverse polarization pattern",,,,,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A wide class of nonuniformly totally polarized beams is introduced that
preserve their transverse polarization pattern during paraxial propagation.
They are obtained as suitable combinations of Gaussian modes and find
applications in polarimetric techniques that use a single input beam for the
determination of the Mueller matrix of a homogeneous sample. The class also
includes beams that present all possible polarization states across their
transverse section (Full-Poincar\`e beams). An example of such beams and its
use in polarimetry is discussed in detail. The requirement of invariance of the
polarization pattern can be limited to the propagation in the far field, in
which case less restrictive conditions are found and a wider class of beams is
obtained.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:02:33 GMT""}]","2021-02-02"
"2102.00025","\'Arp\'ad P\'asztor","\'Arp\'ad P\'asztor, Alessandro Scarfato, Marcello Spera, Felix
  Flicker, C\'eline Barreteau, Enrico Giannini, Jasper van Wezel, Christoph
  Renner","Multiband charge density wave exposed in a transition metal
  dichalcogenide",,"Nat Commun 12, 6037 (2021)","10.1038/s41467-021-25780-4",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the presence of multiple bands, well-known electronic instabilities may
acquire new complexity. While multiband superconductivity is the subject of
extensive studies, the possibility of multiband charge density waves (CDWs) has
been largely ignored so far. Here, combining energy dependent scanning
tunnelling microscopy (STM) topography with a simple model of the charge
modulations and a self-consistent calculation of the CDW gap, we find evidence
for a multiband CDW in 2H-NbSe$_2$. This CDW not only involves the opening of a
gap on the inner band around the K-point, but also on the outer band. This
leads to spatially out-of-phase charge modulations from electrons on these two
bands, which we detect through a characteristic energy dependence of the CDW
contrast in STM images.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:05:23 GMT""}]","2021-10-19"
"2102.00026","Ian Melbourne","Ian Melbourne, Nicolo Paviato and Dalia Terhesiu","Decay in norm of transfer operators for semiflows","After refereeing, the first version has been separated into 2 papers.
  This version is the second main theorem; the first main theorem is mentioned
  in ref [17]","Studia Math. 266 (2022) 149-166",,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We establish exponential decay in H\""older norm of transfer operators applied
to smooth observables of uniformly and nonuniformly expanding semiflows with
exponential decay of correlations.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:06:50 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 21:16:03 GMT""}]","2022-07-07"
"2102.00027","Beatrice van Amsterdam","Beatrice van Amsterdam, Matthew J. Clarkson, Danail Stoyanov","Gesture Recognition in Robotic Surgery: a Review","in IEEE Transactions on Biomedical Engineering, 2021",,"10.1109/TBME.2021.3054828",,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objective: Surgical activity recognition is a fundamental step in
computer-assisted interventions. This paper reviews the state-of-the-art in
methods for automatic recognition of fine-grained gestures in robotic surgery
focusing on recent data-driven approaches and outlines the open questions and
future research directions. Methods: An article search was performed on 5
bibliographic databases with the following search terms: robotic,
robot-assisted, JIGSAWS, surgery, surgical, gesture, fine-grained, surgeme,
action, trajectory, segmentation, recognition, parsing. Selected articles were
classified based on the level of supervision required for training and divided
into different groups representing major frameworks for time series analysis
and data modelling. Results: A total of 52 articles were reviewed. The research
field is showing rapid expansion, with the majority of articles published in
the last 4 years. Deep-learning-based temporal models with discriminative
feature extraction and multi-modal data integration have demonstrated promising
results on small surgical datasets. Currently, unsupervised methods perform
significantly less well than the supervised approaches. Conclusion: The
development of large and diverse open-source datasets of annotated
demonstrations is essential for development and validation of robust solutions
for surgical gesture recognition. While new strategies for discriminative
feature extraction and knowledge transfer, or unsupervised and semi-supervised
approaches, can mitigate the need for data and labels, they have not yet been
demonstrated to achieve comparable performance. Important future research
directions include detection and forecast of gesture-specific errors and
anomalies. Significance: This paper is a comprehensive and structured analysis
of surgical gesture recognition methods aiming to summarize the status of this
rapidly evolving field.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:13:13 GMT""}]","2021-02-02"
"2102.00028","Graeme Addison","Graeme E. Addison","High $H_0$ Values from CMB E-mode Data: A Clue for Resolving the Hubble
  Tension?","9 pages, 1 figure, updated to match version accepted by ApJL",,"10.3847/2041-8213/abf56e",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The E-mode (EE) CMB power spectra measured by Planck, ACTPol, and SPTpol
constrain the Hubble constant to be $70.0\pm2.7$, $72.4^{+3.9}_{-4.8}$, and
$73.1^{+3.3}_{-3.9}$ km s$^{-1}$ Mpc$^{-1}$ within the standard $\Lambda$CDM
model (posterior mean and central 68% interval bounds). These values are higher
than the constraints from the Planck temperature (TT) power spectrum, and
consistent with the Cepheid-supernova distance ladder measurement
$H_0=73.2\pm1.3$ km s$^{-1}$ Mpc$^{-1}$. If this preference for a higher value
was strengthened in a joint analysis it could provide an intriguing hint at the
resolution of the Hubble disagreement. We show, however, that combining the
Planck, ACTPol, and SPTpol EE likelihoods yields $H_0=68.7\pm1.3$ km s$^{-1}$
Mpc$^{-1}$, $2.4\sigma$ lower than the distance ladder measurement. This is due
to different degeneracy directions across the full parameter space,
particularly involving the baryon density, $\Omega_bh^2$, and scalar tilt,
$n_s$, arising from sensitivity to different multipole ranges. We show that the
E-mode $\Lambda$CDM constraints are consistent across the different experiments
within $1.4\sigma$, and with the Planck TT results at $0.8\sigma$. Combining
the Planck, ACTPol, and SPTpol EE data constrains the phenomenological lensing
amplitude, $A_L=0.89\pm0.10$, consistent with the expected value of unity.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:15:11 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 13:26:36 GMT""}]","2021-05-05"
"2102.00029","Devin Willmott","Devin Willmott, Anit Kumar Sahu, Fatemeh Sheikholeslami, Filipe
  Condessa, Zico Kolter","You Only Query Once: Effective Black Box Adversarial Attacks with
  Minimal Repeated Queries",,,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers have repeatedly shown that it is possible to craft adversarial
attacks on deep classifiers (small perturbations that significantly change the
class label), even in the ""black-box"" setting where one only has query access
to the classifier. However, all prior work in the black-box setting attacks the
classifier by repeatedly querying the same image with minor modifications,
usually thousands of times or more, making it easy for defenders to detect an
ensuing attack. In this work, we instead show that it is possible to craft
(universal) adversarial perturbations in the black-box setting by querying a
sequence of different images only once. This attack prevents detection from
high number of similar queries and produces a perturbation that causes
misclassification when applied to any input to the classifier. In experiments,
we show that attacks that adhere to this restriction can produce untargeted
adversarial perturbations that fool the vast majority of MNIST and CIFAR-10
classifier inputs, as well as in excess of $60-70\%$ of inputs on ImageNet
classifiers. In the targeted setting, we exhibit targeted black-box universal
attacks on ImageNet classifiers with success rates above $20\%$ when only
allowed one query per image, and $66\%$ when allowed two queries per image.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:16:51 GMT""}]","2021-02-02"
"2102.00030","Anna Winnicki","Joseph Lubars, Anna Winnicki, Michael Livesay and R. Srikant","Optimistic Policy Iteration for MDPs with Acyclic Transient State
  Structure","16 pages, 3 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Markov Decision Processes (MDPs) in which every stationary policy
induces the same graph structure for the underlying Markov chain and further,
the graph has the following property: if we replace each recurrent class by a
node, then the resulting graph is acyclic. For such MDPs, we prove the
convergence of the stochastic dynamics associated with a version of optimistic
policy iteration (OPI), suggested in Tsitsiklis (2002), in which the values
associated with all the nodes visited during each iteration of the OPI are
updated.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:17:16 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 04:01:34 GMT""},{""version"":""v3"",""created"":""Tue, 9 Mar 2021 18:30:12 GMT""}]","2021-03-10"
"2102.00031","Ekaterina Marchenko","Sergey A. Fateev, Andrey A. Petrov, Ekaterina I. Marchenko, Yan V.
  Zubavichus, Victor N. Khrustalev, Andrey V. Petrov, Sergey M. Aksenov, Eugene
  A. Goodilin, Alexey B. Tarasov","FA2PbBr4: synthesis, structure and unusual optical properties of two
  polymorphs of formamidinium-based layered (110) hybrid perovskite","24 pages, 19 figures",,"10.1021/acs.chemmater.1c00382",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Small cations such as guanidinium and cesium can act as templating cations to
form low dimensional phases (2D, 1D, 0D) in the case of excess of organic
halides. However, such phases with the widely used formamidinium (FA+) cation
have not been reported so far. In this study, we discovered two novel low
dimensional phases with a composition of FA2PbBr4 and investigated the
prerequisites of their formation upon crystallization of FABr-excessive
solutions of FAPbBr3. We found that both phases have the structure of (110)
layered perovskite but are represented by two different polymorphs with
eclipsed and staggered arrangement of adjacent layers. It was shown that
FA2PbBr4 phases usually exist in a labile equilibrium with FAPbBr3 3D
perovskite and can form composites with it. The optical properties of both
polymorphs were comprehensively studied by means of absorption spectroscopy,
diffuse reflection spectroscopy and photoluminescence spectroscopy. DFT
calculations were applied to investigate the band structure of the FA2PbBr4 and
to corroborate the conclusions on their optoelectronic properties. As a result,
we found that FA2PbBr4 phases irradiated by UV can exhibit effective green
photoluminescence due to a transfer of excitation energy to defective states or
3D perovskite inclusions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:17:49 GMT""}]","2021-02-24"
"2102.00032","Cristina M Bernardes Monteiro","R.D.P. Mano, C.A.O. Henriques, F.D. Amaro and C.M.B. Monteiro","Electroluminescence yield in pure krypton",,,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  The krypton electroluminescence yield was studied, at room temperature, as a
function of electric field in the gas scintillation gap. A large area avalanche
photodiode has been used to allow the simultaneous detection of the
electroluminescence pulses as well as the direct interaction of x-rays, the
latter being used as a reference for the calculation of the number of charge
carriers produced by the electroluminescence pulses and, thus, the
determination of the number of photons impinging the photodiode. An
amplification parameter of 113 photons per kV per drifting electron and a
scintillation threshold of 2.7 Td ( 0.7 kV/cm/bar at 293 K ) was obtained, in
good agreement with the simulation data reported in the literature. On the
other hand, the ionisation threshold in krypton was found to be around 13.5 Td
(3.4 kV/cm/bar), less than what had been obtained by the most recent simulation
work-package. The krypton amplification parameter is about 80% and 140% of
those measured for xenon and argon, respectively. The electroluminescence yield
in krypton is of great importance for modeling krypton-based double-phase or
high-pressure gas detectors, which may be used in future rare event detection
experiments.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:21:54 GMT""}]","2021-02-02"
"2102.00033","Jos\'e Petronilho","K. Castillo, D. Mbouna, J. Petronilho","On the functional equation for classical orthogonal polynomials on
  lattices",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Necessary and sufficient conditions for the regularity of solutions of the
functional equation appearing in the theory of classical orthogonal polynomials
on lattices are stated. Moreover, the functional Rodrigues formula and a closed
formula for the recurrence coefficients are presented.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:24:45 GMT""}]","2021-02-02"
"2102.00034","Qing Zou","Qing Zou, Abdul Haseeb Ahmed, Prashant Nagpal, Stanley Kruger, Mathews
  Jacob","Dynamic imaging using a deep generative SToRM (Gen-SToRM) model",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  We introduce a generative smoothness regularization on manifolds (SToRM)
model for the recovery of dynamic image data from highly undersampled
measurements. The model assumes that the images in the dataset are non-linear
mappings of low-dimensional latent vectors. We use the deep convolutional
neural network (CNN) to represent the non-linear transformation. The parameters
of the generator as well as the low-dimensional latent vectors are jointly
estimated only from the undersampled measurements. This approach is different
from traditional CNN approaches that require extensive fully sampled training
data. We penalize the norm of the gradients of the non-linear mapping to
constrain the manifold to be smooth, while temporal gradients of the latent
vectors are penalized to obtain a smoothly varying time-series. The proposed
scheme brings in the spatial regularization provided by the convolutional
network. The main benefit of the proposed scheme is the improvement in image
quality and the orders-of-magnitude reduction in memory demand compared to
traditional manifold models. To minimize the computational complexity of the
algorithm, we introduce an efficient progressive training-in-time approach and
an approximate cost function. These approaches speed up the image
reconstructions and offers better reconstruction performance.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:32:24 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:11:35 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 03:44:58 GMT""}]","2021-03-12"
"2102.00035","Shamma Nasrin","Shamma Nasrin, Diaa Badawi, Ahmet Enis Cetin, Wilfred Gomes, and Amit
  Ranjan Trivedi","MF-Net: Compute-In-Memory SRAM for Multibit Precision Inference using
  Memory-immersed Data Conversion and Multiplication-free Operators",,,,,"cs.AR cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a co-design approach for compute-in-memory inference for deep
neural networks (DNN). We use multiplication-free function approximators based
on ell_1 norm along with a co-adapted processing array and compute flow. Using
the approach, we overcame many deficiencies in the current art of in-SRAM DNN
processing such as the need for digital-to-analog converters (DACs) at each
operating SRAM row/column, the need for high precision analog-to-digital
converters (ADCs), limited support for multi-bit precision weights, and limited
vector-scale parallelism. Our co-adapted implementation seamlessly extends to
multi-bit precision weights, it doesn't require DACs, and it easily extends to
higher vector-scale parallelism. We also propose an SRAM-immersed successive
approximation ADC (SA-ADC), where we exploit the parasitic capacitance of bit
lines of SRAM array as a capacitive DAC. Since the dominant area overhead in
SA-ADC comes due to its capacitive DAC, by exploiting the intrinsic parasitic
of SRAM array, our approach allows low area implementation of within-SRAM
SA-ADC. Our 8$\times$62 SRAM macro, which requires a 5-bit ADC, achieves
$\sim$105 tera operations per second per Watt (TOPS/W) with 8-bit input/weight
processing at 45 nm CMOS.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:35:19 GMT""}]","2021-02-02"
"2102.00036","Soya Park","Soya Park, April Wang, Ban Kawas, Q. Vera Liao, David Piorkowski,
  Marina Danilevsky","Facilitating Knowledge Sharing from Domain Experts to Data Scientists
  for Building NLP Models",,,,,"cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data scientists face a steep learning curve in understanding a new domain for
which they want to build machine learning (ML) models. While input from domain
experts could offer valuable help, such input is often limited, expensive, and
generally not in a form readily consumable by a model development pipeline. In
this paper, we propose Ziva, a framework to guide domain experts in sharing
essential domain knowledge to data scientists for building NLP models. With
Ziva, experts are able to distill and share their domain knowledge using domain
concept extractors and five types of label justification over a representative
data sample. The design of Ziva is informed by preliminary interviews with data
scientists, in order to understand current practices of domain knowledge
acquisition process for ML development projects. To assess our design, we run a
mix-method case-study to evaluate how Ziva can facilitate interaction of domain
experts and data scientists. Our results highlight that (1) domain experts are
able to use Ziva to provide rich domain knowledge, while maintaining low mental
load and stress levels; and (2) data scientists find Ziva's output helpful for
learning essential information about the domain, offering scalability of
information, and lowering the burden on domain experts to share knowledge. We
conclude this work by experimenting with building NLP models using the Ziva
output by our case study.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:37:05 GMT""}]","2021-02-02"
"2102.00037","Lent\'e Dreyer Ms","Lent\'e Dreyer and Markus B\""ottcher","Monte-Carlo Applications for Partially Polarised Inverse
  External-Compton Scattering (MAPPIES) -- I. Description of the code and First
  Results","Paper is published in The Astrophysical Journal","The Astrophysical Journal, 906(1), p.18 (2020)","10.3847/1538-4357/abc9b8",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The radiation mechanisms responsible for the multiwavelength emission from
relativistic jet sources are poorly understood. The modelling of the spectral
energy distributions (SEDs) and light curves alone is not adequate to
distinguish between existing models. Polarisation in the $X$-ray and
$\gamma$-ray regime of these sources may provide new and unique information
about the jet physics and radiation mechanisms. Several upcoming projects will
be able to deliver polarimetric measurements of the brightest $X$-ray sources,
including active galactic nuclei (AGN) jets and $\gamma$-ray bursts (GRBs).
This article describes the development of a new Monte-Carlo code -- MAPPIES
(Monte-Carlo Applications for Partially Polarised Inverse External-Compton
Scattering) -- for polarisation-dependent Compton scattering in relativistic
jet sources. Generic results for Compton polarisation in the Thomson and
Klein-Nishina regimes are presented.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:40:19 GMT""}]","2021-02-02"
"2102.00038","Christian Keller","Erhan Bayraktar and Christian Keller","Path-dependent Hamilton-Jacobi equations with super-quadratic growth in
  the gradient and the vanishing viscosity method","22 pages, to appear in SIAM Journal on Control and Optimization",,,,"math.PR math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The non-exponential Schilder-type theorem in Backhoff-Veraguas, Lacker and
Tangpi [Ann. Appl. Probab., 30 (2020), pp. 1321-1367] is expressed as a
convergence result for path-dependent partial differential equations with
appropriate notions of generalized solutions. This entails a non-Markovian
counterpart to the vanishing viscosity method.
  We show uniqueness of maximal subsolutions for path-dependent viscous
Hamilton-Jacobi equations related to convex super-quadratic backward stochastic
differential equations.
  We establish well-posedness for the Hamilton-Jacobi-Bellman equation
associated to a Bolza problem of the calculus of variations with path-dependent
terminal cost. In particular, uniqueness among lower semi-continuous solutions
holds and state constraints are admitted.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:42:41 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 04:04:50 GMT""}]","2022-03-01"
"2102.00039","Lent\'e Dreyer Ms","Lent\'e Dreyer and Markus B\""ottcher","Monte-Carlo Applications for Partially Polarized Inverse
  External-Compton Scattering (MAPPIES) II -- Application to the UV/Soft X-ray
  Excess in Blazar Spectra","Paper is accepted for publication in The Astrophysical Journal",,"10.3847/1538-4357/abe133",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The spectral energy distributions (SEDs) of some blazars exhibit an
ultraviolet (UV) and/or soft X-ray excess, which can be modelled with different
radiation mechanisms. Polarization measurements of the UV/X-ray emission from
blazars may provide new and unique information about the astrophysical
environment of blazar jets, and could thus help to distinguish between
different emission scenarios. In this paper, a new Monte-Carlo code -- MAPPIES
(Monte-Carlo Applications for Partially Polarized Inverse External-Compton
Scattering) -- for polarization-dependent Compton scattering is used to
simulate the polarization signatures in a model where the UV/soft X-ray excess
arises from the bulk Compton process. Predictions of the expected polarization
signatures of Compton emission from the soft X-ray excess in the SED of AO
0235+164, and the UV excess in the SED of 3C 279 are made for upcoming and
proposed polarimetry missions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:46:53 GMT""}]","2021-03-31"
"2102.00040","Deidre Hunter","Deidre A. Hunter, Bruce G. Elmegreen, Haylee Archer, Caroline E.
  Simpson, and Phil Cigan","A Search for correlations between turbulence and star formation in
  LITTLE THINGS dwarf irregular galaxies","In press in the Astronomical Journal",,"10.3847/1538-3881/abe1c0",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Turbulence has the potential for creating gas density enhancements that
initiate cloud and star formation (SF), and it can be generated locally by SF.
To study the connection between turbulence and SF, we looked for relationships
between SF traced by FUV images, and gas turbulence traced by kinetic energy
density (KED) and velocity dispersion ($v_{disp}$) in the LITTLE THINGS sample
of nearby dIrr galaxies. We performed 2D cross-correlations between FUV and KED
images, measured cross-correlations in annuli to produce correlation
coefficients as a function of radius, and determined the cumulative
distribution function of the cross correlation value. We also plotted on a
pixel-by-pixel basis the locally excess KED, $v_{disp}$, and HI mass surface
density, $\Sigma_{\rm HI}$, as determined from the respective values with the
radial profiles subtracted, versus the excess SF rate density $\Sigma_{\rm
SFR}$, for all regions with positive excess $\Sigma_{\rm SFR}$. We found that
$\Sigma_{\rm SFR}$ and KED are poorly correlated. The excess KED associated
with SF implies a $\sim0.5$% efficiency for supernova energy to pump local HI
turbulence on the scale of resolution here, which is a factor of $\sim2$ too
small for all of the turbulence on a galactic scale. The excess $v_{disp}$ in
SF regions is also small, only $\sim0.37$ km s$^{-1}$. The local excess in
$\Sigma_{\rm HI}$ corresponding to an excess in $\Sigma_{\rm SFR}$ is
consistent with an HI consumption time of $\sim1.6$ Gyr in the inner parts of
the galaxies. The similarity between this timescale and the consumption time
for CO implies that CO-dark molecular gas has comparable mass to HI in the
inner disks.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:58:34 GMT""}]","2021-03-24"
"2102.00041","Peter Reimitz","Peter Reimitz","MeV astronomy with Herwig?","11 pages, 2 figures, submitted to TOOLS2020 Proceedings, minor
  corrections + more references",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GeV-scale dark matter is an increasingly attractive target for direct
detection, indirect detection, and collider searches. Especially for masses in
the MeV to GeV range, indirect detection is expected to give a leading
constraint. In that range, dark matter annihilations into hadronic final states
produce a challenging zoo of light hadronic resonances. With an update of
Herwig7, we provide a modeling of these processes and study energy spectra from
annihilation through a vector mediator. We cover dark matter masses between 250
MeV and 5 GeV and include an error estimate. This opens up new opportunities
for fully studying indirect detection signals for hidden dark matter sectors
with vector mediators in the sub-GeV range.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:00:17 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 11:35:16 GMT""}]","2021-02-16"
"2102.00042","Mattia Magnabosco","Mattia Magnabosco","Example of an Highly Branching CD Space",,,,,"math.MG math.DG","http://creativecommons.org/licenses/by/4.0/","  Ketterer and Rajala showed an example of metric measure space, satisfying the
measure contraction property $MCP(0,3)$, that has different topological
dimensions at different regions of the space. In this article I propose a
refinement of that example, which satisfies the $CD(0,\infty)$ condition,
proving the non-constancy of topological dimension for CD spaces. This example
also shows that the weak curvature dimension bound, in the sense of
Lott-Sturm-Villani, is not sufficient to deduce any reasonable non-branching
condition. Moreover, it allows to answer to some open question proposed by
Schultz, about strict curvature dimension bounds and their stability with
respect to the measured Gromov Hausdorff convergence.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:01:07 GMT""}]","2021-02-02"
"2102.00043","Erik Burman","Erik Burman, Peter Hansbo, Mats G. Larson","Error estimates for the Smagorinsky turbulence model: enhanced stability
  through scale separation and numerical stabilization",,,"10.1007/s00021-021-00633-8",,"math.NA cs.NA physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work we show some results on the effect of the Smagorinsky
model on the stability of the associated perturbation equation. We show that in
the presence of a spectral gap, such that the flow can be decomposed in a large
scale with moderate gradient and a small amplitude fine scale with arbitratry
gradient, the Smagorinsky model admits stability estimates for perturbations,
with exponential growth depending only on the large scale gradient. We then
show in the context of stabilized finite element methods that the same result
carries over to the approximation and that in this context, for suitably chosen
finite element spaces the Smagorinsky model acts as a stabilizer yielding close
to optimal error estimates in the $L^2$-norm for smooth flows in the
pre-asymptotic high Reynolds number regime.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:01:20 GMT""}]","2021-12-01"
"2102.00044","Christina Hedges","Christina Hedges, Rodrigo Luger, Jessie Dotson, Daniel Foreman-Mackey,
  Geert Barentsen","Multi-Wavelength Photometry Derived from Monochromatic Kepler Data","20 pages, 17 figures, 1 table","Published 2021 January 29, The Astronomical Journal, Volume 161,
  Number 2","10.3847/1538-3881/abd31c",,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Kepler mission has provided a wealth of data, revealing new insights in
time-domain astronomy. However, Kepler's single band-pass has limited studies
to a single wavelength. In this work we build a data-driven, pixel-level model
for the Pixel Response Function (PRF) of Kepler targets, modeling the image
data from the spacecraft. Our model is sufficiently flexible to capture known
detector effects, such as non-linearity, intra-pixel sensitivity variations,
and focus change. In theory, the shape of the Kepler PRF should also be weakly
wavelength dependent, due to optical chromatic aberration and wavelength
dependent detector response functions. We are able to identify these predicted
shape changes to the PRF using the residuals between Kepler data and our model.
In this work, we show that these PRF changes correspond to wavelength
variability in Kepler targets using a small sample of eclipsing binaries. Using
our model, we demonstrate that pixel-level light curves of eclipsing binaries
show variable eclipse depths, ellipsoidal modulation and limb darkening. These
changes at the pixel level are consistent with multi-wavelength photometry. Our
work suggests each pixel in the Kepler data of a single target has a different
effective wavelength, ranging from $\approx$ 550-750 $nm$. In this proof of
concept, we demonstrate our model, and discuss possible use cases for the
wavelength dependent Pixel Response Function of Kepler. These use cases include
characterizing variable systems, and vetting exoplanet discoveries at the pixel
level. The chromatic PRF of Kepler is due to weak wavelength dependence in the
optical systems and detector of the telescope, and similar chromatic PRFs are
expected in other similar telescopes, notably the NASA TESS telescope.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:09:29 GMT""}]","2021-02-02"
"2102.00045","Mariah MacDonald","Sofia Z. Sheikh and Mariah G. MacDonald","A Statistical Analysis of the Nulling Pulsar Population","12 pages, 7 figures, accepted to MNRAS",,"10.1093/mnras/stab282",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximately 8% of the $\sim$2800 known pulsars exhibit ""nulling,"" a
temporary broadband cessation of normal pulsar emission. Nulling behaviour can
be coarsely quantified by the nulling fraction, which describes the percentage
of time a given pulsar will be found in a null state. In this paper, we perform
the most thorough statistical analysis thus far of the properties of 141 known
nulling pulsars. We find weak, non-linear correlations between nulling fraction
and pulse width, as well as nulling fraction and spin period which could be
attributed to selection effects. We also further investigate a
recently-hypothesized gap at 40% nulling fraction. While a local minimum does
exist in the distribution, we cannot confirm a consistent and unique break in
the distribution when we investigate with univariate and multivariate
clustering methods, nor can we prove the existence of two statistically
distinct populations about this minimum. Using the same methods, we find that
nulling pulsars are a statistically different population from normal, radio,
non-nulling pulsars, which has never been quantitatively verified. In addition,
we summarize the findings of the prior nulling pulsar statistics literature,
which are notoriously contradictory. This study, in context, furthers the idea
that nulling fraction alone does not contain enough information to describe the
behaviour of a nulling pulsar and that other parameters such as null lengths
and null randomness, in addition to a better understanding of selection
effects, are required to fully understand this phenomenon.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:11:28 GMT""}]","2021-02-10"
"2102.00046","Soham Chakraborty","Soham Chakraborty, Sourav Patel, Murti V Salapaka","Recovery of Power Flow to Critical Infrastructures using Mode-dependent
  Droop-based Inverters",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recovery of power flow to critical infrastructures, after grid failure, is a
crucial need arising in scenarios that are increasingly becoming more frequent.
This article proposes a power transition and recovery strategy by proposing a
mode-dependent droop control-based inverters. The control strategy of inverters
achieves the following objectives 1) regulate the output active and reactive
power by the droop-based inverters to a desired value while operating in
on-grid mode 2) seamless transition and recovery of power flow injections into
the critical loads in the network by inverters operating in off-grid mode after
the main grid fails; 3) require minimal information of grid/network status and
conditions for the mode transition of droop control. A framework for assessing
the stability of the system and to guide the choice of parameters for
controllers is developed using control-oriented modeling. A comprehensive
controller hardware-in-the-loop-based real-time simulation study on a
test-system based on the realistic electrical network of M-Health Fairview,
University of Minnesota Medical Center, corroborates the efficacy of the
proposed controller strategy.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:15:58 GMT""}]","2021-02-02"
"2102.00047","Hemant Kumar Aggarwal","Hemant Kumar Aggarwal, Mathews Jacob","Model Adaptation for Image Reconstruction using Generalized Stein's
  Unbiased Risk Estimator",,,,,"cs.LG cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Deep learning image reconstruction algorithms often suffer from model
mismatches when the acquisition scheme differs significantly from the forward
model used during training. We introduce a Generalized Stein's Unbiased Risk
Estimate (GSURE) loss metric to adapt the network to the measured k-space data
and minimize model misfit impact. Unlike current methods that rely on the mean
square error in kspace, the proposed metric accounts for noise in the
measurements. This makes the approach less vulnerable to overfitting, thus
offering improved reconstruction quality compared to schemes that rely on
mean-square error. This approach may be useful to rapidly adapt pre-trained
models to new acquisition settings (e.g., multi-site) and different contrasts
than training data
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:16:45 GMT""}]","2022-01-02"
"2102.00048","Mattia Magnabosco","Mattia Magnabosco","A Metric Stability Result for the Very Strict CD Condition",,,,,"math.MG","http://creativecommons.org/licenses/by/4.0/","  In (Calc.Var.PDE 2018) Schultz generalized the work of Rajala and Sturm
(Calc.Var.PDE 2014), proving that a weak non-branching condition holds in the
more general setting of very strict CD spaces. Anyway, similar to what happens
for the strong CD condition, the very strict CD condition seems not to be
stable with respect to the measured Gromov Hausdorff convergence. In this
article I prove a stability result for the very strict CD condition, assuming
some metric requirements on the converging sequence and on the limit space. The
proof relies on the notions of \textit{consistent geodesic flow} and
\textit{consistent plan selection}, which allow to treat separately the static
and the dynamic part of a Wasserstein geodesic. As an application, I prove that
the metric measure space $\mathbb R^N$ equipped with a crystalline norm and
with the Lebesgue measure satisfies the very strict $\ CD(0,\infty)$ condition.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:20:36 GMT""}]","2021-02-02"
"2102.00049","Dimitrios Ntalampekos","Christina Karafyllia and Dimitrios Ntalampekos","Extension of boundary homeomorphisms to mappings of finite distortion","20 pages, 2 figures","Proc. Lond. Math. Soc. 125 (2022), no. 3, 488-510","10.1112/plms.12462",,"math.CV math.CA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide sufficient conditions so that a homeomorphism of the real line or
of the circle admits an extension to a mapping of finite distortion in the
upper half-plane or the disk, respectively. Moreover, we can ensure that the
quasiconformal dilatation of the extension satisfies certain integrability
conditions, such as $p$-integrability or exponential integrability. Mappings
satisfying the latter integrability condition are also known as David
homeomorphisms. Our extension operator is the same as the one used by Beurling
and Ahlfors in their celebrated work. We prove an optimal bound for the
quasiconformal dilatation of the Beurling--Ahlfors extension of a homeomorphism
of the real line, in terms of its symmetric distortion function. More
specifically, the quasiconformal dilatation is bounded above by an average of
the symmetric distortion function and below by the symmetric distortion
function itself. As a consequence, the quasiconformal dilatation of the
Beurling--Ahlfors extension of a homeomorphism of the real line is
(sub)exponentially integrable, is $p$-integrable, or has a $BMO$ majorant if
and only if the symmetric distortion is (sub)exponentially integrable, is
$p$-integrable, or has a $BMO$ majorant, respectively. These theorems are all
new and reconcile several sufficient extension conditions that have been
established in the past.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:22:47 GMT""}]","2022-10-05"
"2102.00050","Yury Polyanskiy","Meir Feder and Yury Polyanskiy","Sequential prediction under log-loss and misspecification",,,,,"cs.LG cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the question of sequential prediction under the log-loss in terms
of cumulative regret. Namely, given a hypothesis class of distributions,
learner sequentially predicts the (distribution of the) next letter in sequence
and its performance is compared to the baseline of the best constant predictor
from the hypothesis class. The well-specified case corresponds to an additional
assumption that the data-generating distribution belongs to the hypothesis
class as well. Here we present results in the more general misspecified case.
Due to special properties of the log-loss, the same problem arises in the
context of competitive-optimality in density estimation, and model selection.
For the $d$-dimensional Gaussian location hypothesis class, we show that
cumulative regrets in the well-specified and misspecified cases asymptotically
coincide. In other words, we provide an $o(1)$ characterization of the
distribution-free (or PAC) regret in this case -- the first such result as far
as we know. We recall that the worst-case (or individual-sequence) regret in
this case is larger by an additive constant ${d\over 2} + o(1)$. Surprisingly,
neither the traditional Bayesian estimators, nor the Shtarkov's normalized
maximum likelihood achieve the PAC regret and our estimator requires special
""robustification"" against heavy-tailed data. In addition, we show two general
results for misspecified regret: the existence and uniqueness of the optimal
estimator, and the bound sandwiching the misspecified regret between
well-specified regrets with (asymptotically) close hypotheses classes.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:28:23 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 14:34:52 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 04:30:14 GMT""}]","2021-09-16"
"2102.00051","Alice Harpole","A. Harpole, N. M. Ford, K. Eiden, M. Zingale, D. E. Willcox, Y.
  Cavecchi, M. P. Katz","Dynamics of Laterally Propagating Flames in X-ray Bursts. II. Realistic
  Burning & Rotation","19 pages, 19 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abee87",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We continue to investigate two-dimensional laterally propagating flames in
type I X-ray bursts using fully compressible hydrodynamics simulations. In the
current study we relax previous approximations where we artificially boosted
the flames. We now use more physically realistic reaction rates, thermal
conductivities, and rotation rates, exploring the effects of neutron star
rotation rate and thermal structure on the flame. We find that at lower
rotation rates the flame becomes harder to ignite, whereas at higher rotation
rates the nuclear burning is enhanced by increased confinement from the
Coriolis force and the flame propagates steadily. At higher crustal
temperatures, the flame moves more quickly and accelerates as it propagates
through the atmosphere. If the temperature is too high, instead of a flame
propagating across the surface the entire atmosphere burns steadily. All of the
software used for these simulations is freely available.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:29:40 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 14:24:03 GMT""}]","2021-05-12"
"2102.00052","Niall Owens","Niall Owens, E.J.W. de Mooij, C.A. Watson, M.J. Hooton","Phase curve and variability analysis of WASP-12b using TESS photometry","11 pages, 5 figures. Accepted for publication in MNRAS Letters",,"10.1093/mnrasl/slab014",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse Sector 20 TESS photometry of the ultra-hot Jupiter WASP-12b, and
extract its phase curve to study the planet's atmospheric properties. We
successfully recover the phase curve with an amplitude of 549 $\pm$ 62 ppm, and
a secondary eclipse depth of 609$^{+74}_{-73}$ ppm. The peak of the phase curve
is shifted by 0.049 $\pm$ 0.015 in phase, implying that the brightest spot in
the atmosphere is shifted from the substellar point towards the planet's
evening terminator. Assuming zero albedo, the eclipse depth infers a day-side
brightness temperature of 3128$^{+64}_{-68}$ K. No significant detection of
flux from the night-side is found at 60 $\pm$ 97 ppm, implying a night-side
brightness temperature of $<$2529 K (1-$\sigma$). We do not detect any
significant variability in the light from the planet over the $\sim$27 days of
the TESS observations. Finally, we note that an ephemeris model taking orbital
decay into account provides a significantly better fit than a constant-period
model.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:30:02 GMT""}]","2021-02-08"
"2102.00053","Aleksander Czechowski","Aleksander Czechowski and Georgios Piliouras","Poincar\'{e}-Bendixson Limit Sets in Multi-Agent Learning",,,,,"cs.GT cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key challenge of evolutionary game theory and multi-agent learning is to
characterize the limit behavior of game dynamics. Whereas convergence is often
a property of learning algorithms in games satisfying a particular reward
structure (e.g., zero-sum games), even basic learning models, such as the
replicator dynamics, are not guaranteed to converge for general payoffs. Worse
yet, chaotic behavior is possible even in rather simple games, such as variants
of the Rock-Paper-Scissors game. Although chaotic behavior in learning dynamics
can be precluded by the celebrated Poincar\'e-Bendixson theorem, it is only
applicable to low-dimensional settings. Are there other characteristics of a
game that can force regularity in the limit sets of learning? We show that
behavior consistent with the Poincar\'e-Bendixson theorem (limit cycles, but no
chaotic attractor) can follow purely from the topological structure of the
interaction graph, even for high-dimensional settings with an arbitrary number
of players and arbitrary payoff matrices. We prove our result for a wide class
of follow-the-regularized leader (FoReL) dynamics, which generalize replicator
dynamics, for binary games characterized interaction graphs where the payoffs
of each player are only affected by one other player (i.e., interaction graphs
of indegree one). Since chaos occurs already in games with only two players and
three strategies, this class of non-chaotic games may be considered maximal.
Moreover, we provide simple conditions under which such behavior translates
into efficiency guarantees, implying that FoReL learning achieves time-averaged
sum of payoffs at least as good as that of a Nash equilibrium, thereby
connecting the topology of the dynamics to social-welfare analysis.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:32:25 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 17:50:48 GMT""}]","2022-02-09"
"2102.00054","Fabian Donat Natterer","Berk Zengin, Jens Oppliger, Danyang Liu, Lorena Niggli, Tohru
  Kurosawa, Fabian Donat Natterer","Fast spectroscopic mapping of two-dimensional quantum materials",,"Physical Review Research 3, L042025 (2021)","10.1103/PhysRevResearch.3.L042025",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectroscopic mapping refers to the massive recording of spectra whilst
varying an additional degree of freedom, such as: magnetic field, location,
temperature, or charge carrier concentration. As this involves two serial
tasks, spectroscopic mapping can become excruciatingly slow. We demonstrate
exponentially faster mapping through our combination of sparse sampling and
parallel spectroscopy. We exemplify our concept using quasiparticle
interference imaging of Au(111) and Bi2Sr2CaCu2O8 (Bi2212), as two well-known
model systems. Our method is accessible, straightforward to implement with
existing scanning tunneling microscopes, and can be easily extended to enhance
gate or field-mapping spectroscopy. In view of a possible four orders of
magnitude speed advantage, it is setting the stage to fundamentally promote the
discovery of novel quantum materials.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:34:27 GMT""}]","2021-11-15"
"2102.00055","Xiaohan Kang","Xiaohan Kang and Bruce Hajek","Lower Bounds on Information Requirements for Causal Network Inference","Full version of the ISIT paper",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Recovery of the causal structure of dynamic networks from noisy measurements
has long been a problem of intense interest across many areas of science and
engineering. Many algorithms have been proposed, but there is no work that
compares the performance of the algorithms to converse bounds in a
non-asymptotic setting. As a step to address this problem, this paper gives
lower bounds on the error probability for causal network support recovery in a
linear Gaussian setting. The bounds are based on the use of the Bhattacharyya
coefficient for binary hypothesis testing problems with mixture probability
distributions. Comparison of the bounds and the performance achieved by two
representative recovery algorithms are given for sparse random networks based
on the Erd\H{o}s-R\'enyi model.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:34:28 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 14:44:12 GMT""}]","2021-05-10"
"2102.00056","Mark Voit","G. M. Voit","A Graphical Interpretation of Circumgalactic Precipitation","10 pages, 3 figures, accepted to ApJ Letters",,"10.3847/2041-8213/abe11f",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Both observations and recent numerical simulations of the circumgalactic
medium (CGM) support the hypothesis that a self-regulating feedback loop
suspends the gas density of the ambient CGM close to the galaxy in a state with
a ratio of cooling time to freefall time >10. This limiting ratio is thought to
arise because circumgalactic gas becomes increasingly susceptible to multiphase
condensation as the ratio declines. If the timescale ratio gets too small, then
cold clouds precipitate out of the CGM, rain into the galaxy, and fuel
energetic feedback that raises the ambient cooling time. The astrophysical
origin of this so-called precipitation limit is not simple but is critical to
understanding the CGM and its role in galaxy evolution. This paper therefore
attempts to interpret its origin as simply as possible, relying mainly on
conceptual reasoning and schematic diagrams. It illustrates how the
precipitation limit can depend on both the global configuration of a galactic
atmosphere and the degree to which dynamical disturbances drive CGM
perturbations. It also frames some tests of the precipitation hypothesis that
can be applied to both CGM observations and numerical simulations of galaxy
evolution.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:36:47 GMT""}]","2021-02-24"
"2102.00057","Nicholas Sohre","Nicholas Sohre, Alisdair O. G. Wallis, and Stephen J. Guy","An Information-Theoretic Law Governing Human Multi-Task Navigation
  Decisions","6 pages, 5 figures, contains references to supplementary material",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  To better understand the process by which humans make navigation decisions
when tasked with multiple stopovers, we analyze motion data captured from
shoppers in a grocery store. We discover several trends in the data that are
consistent with a noisy decision making process for the order of item
retrieval, and decompose a shopping trip into a sequence of discrete choices
about the next item to retrieve. Our analysis reveals that the likelihood of
inverting any two items in the order is monotonically bound to the entropy of
the pair-wise ordering task. Based on this analysis, we propose a noisy
distance estimation model for predicting the order of item retrieval given a
shopping list. We show that our model theoretically reproduces the entropy law
seen in the data with high accuracy, and in practice matches the trends in the
data when used to simulate the same shopping lists. Our approach has direct
applications to improving simulations of human navigation in retail and other
settings.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:43:05 GMT""}]","2021-02-02"
"2102.00058","Jae-Kwang Kim","Hengfang Wang, Jae-Kwang Kim","Statistical Inference after Kernel Ridge Regression Imputation under
  item nonresponse",,,,,"stat.ME stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Imputation is a popular technique for handling missing data. We consider a
nonparametric approach to imputation using the kernel ridge regression
technique and propose consistent variance estimation. The proposed variance
estimator is based on a linearization approach which employs the entropy method
to estimate the density ratio. The root-n consistency of the imputation
estimator is established when a Sobolev space is utilized in the kernel ridge
regression imputation, which enables us to develop the proposed variance
estimator. Synthetic data experiments are presented to confirm our theory.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:46:33 GMT""}]","2021-02-02"
"2102.00059","Michael Chiu","Michael Chiu and Uro\v{s} Kalabi\'c","Debt Representation in UTXO Blockchains",,,,,"cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a UTXO model of blockchain transactions that is able to represent
both credit and debt on the same blockchain. Ordinarily, the UTXO model is
solely used to represent credit and the representation of credit and debit
together is achieved using the account model because of its support for
balances. However, the UTXO model provides superior privacy, safety, and
scalability when compared to the account model. In this work, we introduce a
UTXO model that has the flexibility of balances with the usual benefits of the
UTXO model. This model extends the conventional UTXO model, which represents
credits as unmatched outputs, by representing debts as unmatched inputs. We
apply our model to solving the problem of transparency in reverse mortgage
markets, in which some transparency is necessary for a healthy market but
complete transparency leads to adverse outcomes. Here the pseudonymous
properties of the UTXO model protect the privacy of loan recipients while still
allowing an aggregate view of the loan market. We present a prototype of our
implementation in Tendermint and discuss the design and its benefits.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:47:19 GMT""}]","2021-02-02"
"2102.00060","Nigel Bishop","Monos Naidoo, Nigel T Bishop, Petrus J van der Walt","Modifications to the signal from a gravitational wave event due to a
  surrounding shell of matter","13 pages, 4 figures","Gen. Rel. Grav. (2021) 53:77","10.1007/s10714-021-02841-z",,"gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In previous work, we established theoretical results concerning the effect of
matter shells surrounding a gravitational wave (GW) source, and we now apply
these results to astrophysical scenarios. Firstly, it is shown that GW echoes
that are claimed to be present in LIGO data of certain events, could not have
been caused by a matter shell. However, it is also shown that there are
scenarios in which matter shells could make modifications of order a few
percent to a GW signal; these scenarios include binary black hole mergers,
binary neutron star mergers, and core collapse supernovae.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:49:43 GMT""}]","2021-08-11"
"2102.00061","Deheng Song","Deheng Song, Oscar Macias, Shunsaku Horiuchi, Roland M. Crocker, David
  M. Nataf","Evidence for a high-energy tail in the gamma-ray spectra of globular
  clusters","16+9 pages, 13+4 figures, 4+1 tables. match the published version in
  MNRAS","MNRAS 507, 5161-5176 (2021)","10.1093/mnras/stab2406",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Millisecond pulsars are very likely the main source of gamma-ray emission
from globular clusters. However, the relative contributions of two separate
emission processes--curvature radiation from millisecond pulsar magnetospheres
vs. inverse Compton emission from relativistic pairs launched into the globular
cluster environment by millisecond pulsars--have long been unclear. To address
this, we search for evidence of inverse Compton emission in 8-year
$\textit{Fermi}$-LAT data from the directions of 157 Milky Way globular
clusters. We find a mildly statistically significant (3.8$\sigma$) correlation
between the measured globular cluster gamma-ray luminosities and their photon
field energy densities. However, this may also be explained by a hidden
correlation between the photon field densities and the stellar encounter rates
of globular clusters. Analysed $\textit{in toto}$, we demonstrate that the
gamma-ray emission of globular clusters can be resolved spectrally into two
components: i) an exponentially cut-off power law and ii) a pure power law. The
latter component--which we uncover at a significance of 8.2$\sigma$--has a
power index of 2.79 $\pm$ 0.25. It is most naturally interpreted as inverse
Compton emission by cosmic-ray electrons and positrons injected by millisecond
pulsars. We find the luminosity of this power-law component is comparable to,
or slightly smaller than, the luminosity of the curved component, suggesting
the fraction of millisecond pulsar spin-down luminosity into relativistic
leptons is similar to the fraction of the spin-down luminosity into prompt
magnetospheric radiation.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:50:23 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 03:59:56 GMT""},{""version"":""v3"",""created"":""Sun, 26 Sep 2021 21:47:24 GMT""}]","2021-10-13"
"2102.00062","Jae Shin Yoon","Jae Shin Yoon, Kihwan Kim, Jan Kautz, and Hyun Soo Park","Neural 3D Clothes Retargeting from a Single Image","20 pages, 21 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a method of clothes retargeting; generating the
potential poses and deformations of a given 3D clothing template model to fit
onto a person in a single RGB image. The problem is fundamentally ill-posed as
attaining the ground truth data is impossible, i.e., images of people wearing
the different 3D clothing template model at exact same pose. We address this
challenge by utilizing large-scale synthetic data generated from physical
simulation, allowing us to map 2D dense body pose to 3D clothing deformation.
With the simulated data, we propose a semi-supervised learning framework that
validates the physical plausibility of the 3D deformation by matching with the
prescribed body-to-cloth contact points and clothing silhouette to fit onto the
unlabeled real images. A new neural clothes retargeting network (CRNet) is
designed to integrate the semi-supervised retargeting task in an end-to-end
fashion. In our evaluation, we show that our method can predict the realistic
3D pose and deformation field needed for retargeting clothes models in
real-world examples.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:50:34 GMT""}]","2021-02-02"
"2102.00063","Conlain Kelly","Conlain Kelly, Surya R. Kalidindi","Recurrent Localization Networks applied to the Lippmann-Schwinger
  Equation","20 pages, 10 figures. Accepted to Computational Materials Science","Computational Materials Science Volume 192, May 2021, 110356","10.1016/j.commatsci.2021.110356",,"physics.comp-ph cond-mat.dis-nn cond-mat.mtrl-sci cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The bulk of computational approaches for modeling physical systems in
materials science derive from either analytical (i.e. physics based) or
data-driven (i.e. machine-learning based) origins. In order to combine the
strengths of these two approaches, we advance a novel machine learning approach
for solving equations of the generalized Lippmann-Schwinger (L-S) type. In this
paradigm, a given problem is converted into an equivalent L-S equation and
solved as an optimization problem, where the optimization procedure is
calibrated to the problem at hand. As part of a learning-based loop unrolling,
we use a recurrent convolutional neural network to iteratively solve the
governing equations for a field of interest. This architecture leverages the
generalizability and computational efficiency of machine learning approaches,
but also permits a physics-based interpretation. We demonstrate our learning
approach on the two-phase elastic localization problem, where it achieves
excellent accuracy on the predictions of the local (i.e., voxel-level) elastic
strains. Since numerous governing equations can be converted into an equivalent
L-S form, the proposed architecture has potential applications across a range
of multiscale materials phenomena.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 20:54:17 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 15:08:06 GMT""}]","2021-09-22"
"2102.00064","Ondrej Hutn\'ik","Michal Boczek, Ondrej Hutn\'ik, Marek Kaluszka","Choquet-Sugeno-like operator based on relation and conditional
  aggregation operators",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  We introduce a~\textit{Choquet-Sugeno-like operator} generalizing many
operators for bounded functions and monotone measures from the literature,
e.g., Sugeno-like operator, Lov\'{a}sz and Owen measure extensions,
$\rF$-decomposition integral with respect to a~partition decomposition system,
and others. The new operator is based on the concepts of dependence relation
and conditional aggregation operators, but it does not depend on $t$-level
sets. We also provide conditions for which the Choquet-Sugeno-like operator
coincides with some Choquet-like integrals defined on finite spaces and
appeared recently in the literature, e.g. reverse Choquet integral, $d$-Choquet
integral, $\rF$-based discrete Choquet-like integral, some version of
$C_{\rF_1\rF_2}$-integral, $\mathrm{C}\mathrm{C}$-integrals (or Choquet-like
Copula-based integral) and discrete inclusion-exclusion integral. Some basic
properties of the Choquet-Sugeno-like operator are studied.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:01:05 GMT""}]","2021-02-02"
"2102.00065","Arwa Dabbech","Arwa Dabbech, Audrey Repetti, Rick A. Perley, Oleg M. Smirnov and Yves
  Wiaux","Cygnus A jointly calibrated and imaged via non-convex optimisation from
  VLA data","22 pages,13 figures. Submitted to MNRAS",,"10.1093/mnras/stab1903",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio interferometric (RI) data are noisy under-sampled spatial Fourier
components of the unknown radio sky affected by direction-dependent antenna
gains. Failure to model these antenna gains accurately results in a radio sky
estimate with limited fidelity and resolution. The RI inverse problem has been
recently addressed via a joint calibration and imaging approach which consists
in solving a non-convex minimisation task, involving suitable priors for the
DDEs, namely temporal and spatial smoothness, and sparsity for the unknown
radio map via an $\ell_1$-norm prior, in the context of realistic RI
simulations. Building on these developments, we propose to promote sparsity of
the radio map via a log-sum prior, enforcing sparsity more strongly than the
$\ell_1$-norm. The resulting minimisation task is addressed via a sequence of
non-convex minimisation tasks composed of re-weighted $\ell_1$ image priors,
which are solved approximately. We demonstrate the efficiency of the approach
on RI observations of the celebrated radio galaxy Cygnus~A obtained with the
Karl G. Jansky Very Large Array at X, C, and S bands. More precisely, we
showcase that the approach enhances data fidelity significantly while achieving
high resolution high dynamic range radio maps, confirming the suitability of
the priors considered for the unknown DDEs and radio image. As a clear
qualitative indication of the high fidelity achieved by the data and the
proposed approach, we report the detection of three background sources in the
vicinity of Cyg~A, at S band.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:01:19 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 11:57:45 GMT""}]","2021-07-14"
"2102.00066","Maude Gull","Maude Gull (Berkeley, MIT), Anna Frebel (MIT), Karina Hinojosa (MIT),
  Ian U. Roederer (UMichigan, JINA), Alexander P. Ji (Carnegie) and Kaley
  Brauer (MIT)","R-process-rich stellar streams in the Milky Way","32 pages, 10 figures, accepted to ApJ",,"10.3847/1538-4357/abea1a",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present high-resolution Magellan/MIKE spectra of 22 bright ($9<V<13.5$)
metal-poor stars ($-3.18<\mbox{[Fe/H]}<-1.37$) in three different stellar
streams, the Helmi debris stream, the Helmi trail stream, and the $\omega$
Centauri progenitor stream. We augment our Helmi debris sample with results for
ten stars by Roederer et al. 2010 (arXiv:1001.1745), for a total of 32 stars.
Detailed chemical abundances of light elements as well as heavy neutron-capture
elements have been determined for our 22 stars. All three streams contain
carbon-enhanced stars. For 13 stars, neutron-capture element lines were
detectable and they all show signatures in agreement with the scaled solar
$r$-process pattern, albeit with a large spread of $-0.5<\mbox{[Eu/Fe]}<+1.3$.
Eight of these stars show an additional small $s$-process contribution
superposed onto their $r$-process pattern. This could be discerned because of
the relatively high $S/N$ of the spectra given that the stars are close by in
the halo. Our results suggest that the progenitors of these streams experienced
one or more $r$-process events, such as a neutron star merger or another
prolific $r$-process source, early on that widely enriched these host systems
before their accretion by the Milky Way. The small $s$-process contribution
suggests the presence of AGB stars and associated local (inhomogeneous)
enrichment as part of the ongoing chemical evolution by low mass stars. Stars
in stellar streams may thus be a promising avenue for studying the detailed
history of large dwarf galaxies and their role in halo assembly with easily
accessible targets for high-quality spectra of many stars.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:02:47 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 11:27:39 GMT""},{""version"":""v3"",""created"":""Wed, 3 Feb 2021 10:43:37 GMT""},{""version"":""v4"",""created"":""Mon, 8 Feb 2021 12:01:35 GMT""}]","2021-05-12"
"2102.00067","Lingjing Jiang","Lingjing Jiang, Chris Elrod, Jane J. Kim, Austin D. Swafford, Rob
  Knight, Wesley K. Thompson","Multi-Block Sparse Functional Principal Components Analysis for
  Longitudinal Microbiome Multi-Omics Data",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Microbiome researchers often need to model the temporal dynamics of multiple
complex, nonlinear outcome trajectories simultaneously. This motivates our
development of multivariate Sparse Functional Principal Components Analysis
(mSFPCA), extending existing SFPCA methods to simultaneously characterize
multiple temporal trajectories and their inter-relationships. As with existing
SFPCA methods, the mSFPCA algorithm characterizes each trajectory as a smooth
mean plus a weighted combination of the smooth major modes of variation about
the mean, where the weights are given by the component scores for each subject.
Unlike existing SFPCA methods, the mSFPCA algorithm allows estimation of
multiple trajectories simultaneously, such that the component scores, which are
constrained to be independent within a particular outcome for identifiability,
may be arbitrarily correlated with component scores for other outcomes. A
Cholesky decomposition is used to estimate the component score covariance
matrix efficiently and guarantee positive semi-definiteness given these
constraints. Mutual information is used to assess the strength of marginal and
conditional temporal associations across outcome trajectories. Importantly, we
implement mSFPCA as a Bayesian algorithm using R and stan, enabling easy use of
packages such as PSIS-LOO for model selection and graphical posterior
predictive checks to assess the validity of mSFPCA models. Although we focus on
application of mSFPCA to microbiome data in this paper, the mSFPCA model is of
general utility and can be used in a wide range of real-world applications.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:05:25 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 21:57:57 GMT""}]","2021-02-09"
"2102.00068","T. Taro Shimizu","GRAVITY Collaboration, A. Amorim, M. Baub\""ock, W. Brandner, M.
  Bolzer, Y. Cl\'enet, R. Davies, P. T. de Zeeuw, J. Dexter, A. Drescher, A.
  Eckart, F. Eisenhauer, N.M. F\""orster Schreiber, F. Gao, P. J. V. Garcia, R.
  Genzel, S. Gillessen, D. Gratadour, S. H\""onig, D. Kaltenbrunner, M.
  Kishimoto, S. Lacour, D. Lutz, F. Millour, H. Netzer, T. Ott, T. Paumard, K.
  Perraut, G. Perrin, B. M. Peterson, P. O. Petrucci, O. Pfuhl, M. A. Prieto,
  D. Rouan, J. Sanchez-Bermudez, J. Shangguan, T. Shimizu, M. Schartmann, J.
  Stadler, A. Sternberg, O. Straub, C. Straubmeier, E. Sturm, L. J. Tacconi, K.
  R. W. Tristram, P. Vermot, S. von Fellenberg, I. Waisberg, F. Widmann, and J.
  Woillez","The central parsec of NGC 3783: a rotating broad emission line region,
  asymmetric hot dust structure, and compact coronal line region","20 pages and 18 figures in main text, Accepted for publication in A&A","A&A 648, A117 (2021)","10.1051/0004-6361/202040061",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using VLTI/GRAVITY and SINFONI data, we investigate the sub-pc gas and dust
structure around the nearby type 1 AGN hosted by NGC 3783. The K-band coverage
of GRAVITY uniquely allows a simultaneous analysis of the size and kinematics
of the broad line region (BLR), the size and structure of the near-IR continuum
emitting hot dust, and the size of the coronal line region (CLR). We find the
BLR probed through broad Br$\gamma$ emission is well described by a rotating,
thick disk with a radial distribution of clouds peaking in the inner region. In
our BLR model the physical mean radius of 16 light days is nearly twice the 10
day time lag that would be measured, which matches very well the 10 day time
lag that has been measured by reverberation mapping. We measure a hot dust FWHM
size of 0.74 mas (0.14 pc) and further reconstruct an image of the hot dust
which reveals a faint (5% of the total flux) offset cloud which we interpret as
an accreting cloud heated by the central AGN. Finally, we directly measure the
FWHM size of the nuclear CLR as traced by the [CaVIII] and narrow Br$\gamma$
line. We find a FWHM size of 2.2 mas (0.4 pc), fully in line with the
expectation of the CLR located between the BLR and narrow line region.
Combining all of these measurements together with larger scale near-IR integral
field unit and mid-IR interferometry data, we are able to comprehensively map
the structure and dynamics of gas and dust from 0.01--100 pc.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:10:30 GMT""}]","2021-04-28"
"2102.00069","Mourad Boulsane","Boulsane Mourad and Souabni Ahmed","Bochner-Riesz Means Convergence of Prolate Spheroidal Series and Their
  Extensions","23 pages",,,,"math.CA math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the $L^p$-Bochner-Riesz mean summability problem
related to the spectrum of some particular Sturm-Liouville operators in the
weighted $L^p([a,b],\omega).$ Our purpose is to establish suitable conditions
under which the Bochner-Riesz expansion of a function $f \in
L^p([a,b],\omega)$,$1<p<\infty$, in two generalisations of Slepian's basis,
converges to $f$ in $L^p([a,b],\omega)$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:12:24 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 17:45:53 GMT""}]","2021-07-13"
"2102.00070","Anirban Chakraborti","Areejit Samal, Sunil Kumar, Yasharth Yadav, and Anirban Chakraborti","Network-centric indicators for fragility in global financial indices","32 pages, 18 figures, including supplementary material","Front. Phys. 8:624373 (2021)","10.3389/fphy.2020.624373",,"q-fin.ST physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last two decades, financial systems have been studied and analysed
from the perspective of complex networks, where the nodes and edges in the
network represent the various financial components and the strengths of
correlations between them. Here, we adopt a similar network-based approach to
analyse the daily closing prices of 69 global financial market indices across
65 countries over a period of 2000-2014. We study the correlations among the
indices by constructing threshold networks superimposed over minimum spanning
trees at different time frames. We investigate the effect of critical events in
financial markets (crashes and bubbles) on the interactions among the indices
by performing both static and dynamic analyses of the correlations. We compare
and contrast the structures of these networks during periods of crashes and
bubbles, with respect to the normal periods in the market. In addition, we
study the temporal evolution of traditional market indicators, various global
network measures and the recently developed edge-based curvature measures. We
show that network-centric measures can be extremely useful in monitoring the
fragility in the global financial market indices.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:13:56 GMT""}]","2021-02-02"
"2102.00071","Sergey Baryshev V","Mitchell Schneider, Emily Jevarjian, Tanvi Nikhar, Taha Y. Posos,
  Wanming Liu, Jiahang Shao and Sergey V. Baryshev","Ampere-class Bright Field Emission Cathode Operated at 100 MV/m",,,"10.1103/PhysRevAccelBeams.24.123401",,"physics.acc-ph physics.app-ph physics.plasm-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  High current bright sources are needed to power the next generation of
compact rf and microwave systems. A major requirement is that such a source
could be sustainably operated at high frequencies, well above 1 GHz, and high
gradients, well above 100 MV/m. Field emission sources offer simplicity and
scalability in a high frequency era of the injector design, but the output rf
cycle charge and high gradient operation remain a great and largely unaddressed
challenge. Here, a field emission cathode based on ultra-nano-crystalline
diamond or UNCD, an efficient planar field emission material, was tested at 100
MV/m in an L-band injector. A very high charge of 38 pC per rf cycle (300 nC
per rf pulse corresponding to rf pulse current of 120 mA) was demonstrated.
This operating condition revealed a space charge dominated emission from the
cathode and revealed a condition under which the 1D Child Langmuir limit was
surpassed. Finally, a beam brightness of $\sim 10^{14}-10^{15}$
A/m$^2\times$rad$^2$ was estimated.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:15:03 GMT""}]","2022-01-05"
"2102.00072","Ion Errea","Pugeng Hou, Francesco Belli, Raffaello Bianco, Ion Errea","Strong Anharmonic and Quantum Effects in Pm-3n AlH3 Under High Pressure:
  A First-Principles Study",,"Phys. Rev. B 103, 134305 (2021)","10.1103/PhysRevB.103.134305",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the absence of experimental superconductivity in the metallic
Pm-3n phase of AlH3 despite the predictions, we reanalyze its vibrational and
superconducting properties at pressures above 99 GPa making use of
first-principles techniques. In our calculations based on the self-consistent
harmonic approximation method that treats anharmonicity beyond perturbation
theory, we predict a strong anharmonic correction to the phonon spectra and
demonstrate that the superconducting critical temperatures predicted in
previous calculations based on the harmonic approximation are strongly
suppressed by anharmonicity. The electron-phonon coupling concentrates on the
lowest-energy hydrogen-character optical modes at the X point of the Brillouin
zone. As a consequence of the strong anharmonic enhancement of their frequency,
the electron-phonon coupling is suppressed by at least a 30%. The suppression
in {\lambda} makes Tc smaller than 4.2 K above 120 GPa, which is well
consistent with the experimental evidence. Our results underline that metal
hydrides with hydrogen atoms in interstitial sites are subject to huge
anharmonic effects.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:17:17 GMT""}]","2021-05-05"
"2102.00073","V. G. Kogan","V. G. Kogan, N. Nakagawa","Moving Pearl vortices in thin-film superconductors","6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2004.03663","Condensed Matter, 2021, 6, 4",,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnetic field $h_z$ of a moving Pearl vortex in a superconducting
thin-film in $(x,y)$ plane is studied with the help of time-dependent London
equation. It is found that for a vortex at the origin moving in $+x$ direction,
$h_z(x,y)$ is suppressed in front of the vortex, $x>0$, and enhanced behind
($x<0$). The distribution asymmetry is proportional to the velocity and to the
conductivity of normal quasiparticles. The vortex self-energy and the
interaction of two moving vortices are evaluated.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:20:22 GMT""}]","2021-02-02"
"2102.00074","Michael Combi","M.R. Combi, T. M\""akinen, J.-L. Bertaux, E. Qu\'emerais, S. Ferron","Water Production Rate of C/2020 F3 (NEOWISE) from SOHO/SWAN over Its
  Active Apparition","16 Pages, 4 Figures, 1 Table",,"10.3847/2041-8213/abd698",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  C/2020 F3 (NEOWISE) was discovered in images from the Near Earth Object
program of the Wide-Field Infrared Survey Explorer (NEOWISE) taken on 27 March
2020 and has become the Great Comet of 2020. The Solar Wind ANisotropies (SWAN)
camera on the Solar and Heliospheric Observatory (SOHO) spacecraft, located in
a halo orbit around the Earth-Sun L1 Lagrange point, makes daily full-sky
images of hydrogen Lyman-alpha. Water production rates were determined from the
SWAN hydrogen Lyman-alpha brightness and spatial distribution of the comet
measured over a 4-month period of time on either side of the comet's perihelion
on 3 July 2020. The water production rate in s^-1 was moderately asymmetric
around perihelion and varied with the heliocentric distance, r, in au as
(6.9+/-0.5) x 10^28 r^-2.5+/-0.2 and (10.1+/-0.5) x 10^28 r^-3.5+/-0.1 before
and after perihelion, respectively. This is consistent with the comet having
been through the planetary region of the solar system on one or more previous
apparitions. A water production rates as large as 5.27 x 10^30 s^-1 were
determined shortly after perihelion, once the comet was outside the solar
avoidance area of SWAN, when the comet was 0.324 au from the Sun.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:23:53 GMT""}]","2021-02-02"
"2102.00075","Mark Wilkening","Mark Wilkening, Udit Gupta, Samuel Hsia, Caroline Trippel, Carole-Jean
  Wu, David Brooks, Gu-Yeon Wei","RecSSD: Near Data Processing for Solid State Drive Based Recommendation
  Inference",,,,,"cs.AR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural personalized recommendation models are used across a wide variety of
datacenter applications including search, social media, and entertainment.
State-of-the-art models comprise large embedding tables that have billions of
parameters requiring large memory capacities. Unfortunately, large and fast
DRAM-based memories levy high infrastructure costs. Conventional SSD-based
storage solutions offer an order of magnitude larger capacity, but have worse
read latency and bandwidth, degrading inference performance. RecSSD is a near
data processing based SSD memory system customized for neural recommendation
inference that reduces end-to-end model inference latency by 2X compared to
using COTS SSDs across eight industry-representative models.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:25:34 GMT""}]","2021-02-02"
"2102.00076","Mario Agio","L. Hunold, S. Lagomarsino, A.M. Flatae, H. Kambalathmana, F. Sledz, S.
  Sciortino, N. Gelli, L. Giuntini, M. Agio","Scalable creation of silicon-vacancy color centers in diamond by ion
  implantation through a 1-$\mu$m pinhole","11 pages, 4 figures","Adv. Quantum Technol. 2100079 (2021)","10.1002/qute.202100079",,"quant-ph physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The controlled creation of quantum emitters in diamond represents a major
research effort in the fabrication of single-photon devices. Here, we present
the scalable production of silicon-vacancy (SiV) color centers in
single-crystal diamond by ion implantation. The lateral position of the SiV is
spatially controlled by a 1-$\mu$m pinhole placed in front of the sample, which
can be moved nanometer precise using a piezo stage. The initial implantation
position is controlled by monitoring the ion beam position with a camera.
Hereby, silicon ions are implanted at the desired spots in an area comparable
to the diffraction limit. We discuss the role of ions scattered by the pinhole
and the activation yield of the SiV color centers for the creation of single
quantum emitters.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:30:31 GMT""}]","2021-10-26"
"2102.00077","Sayak Mukherjee","Sayak Mukherjee, Renke Huang, Qiuhua Huang, Thanh Long Vu, Tianzhixi
  Yin","Scalable Voltage Control using Structure-Driven Hierarchical Deep
  Reinforcement Learning","8 pages, 13 figures",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel hierarchical deep reinforcement learning (DRL)
based design for the voltage control of power grids. DRL agents are trained for
fast, and adaptive selection of control actions such that the voltage recovery
criterion can be met following disturbances. Existing voltage control
techniques suffer from the issues of speed of operation, optimal coordination
between different locations, and scalability. We exploit the area-wise division
structure of the power system to propose a hierarchical DRL design that can be
scaled to the larger grid models. We employ an enhanced augmented random search
algorithm that is tailored for the voltage control problem in a two-level
architecture. We train area-wise decentralized RL agents to compute lower-level
policies for the individual areas, and concurrently train a higher-level DRL
agent that uses the updates of the lower-level policies to efficiently
coordinate the control actions taken by the lower-level agents. Numerical
experiments on the IEEE benchmark 39-bus model with 3 areas demonstrate the
advantages and various intricacies of the proposed hierarchical approach.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:30:59 GMT""}]","2021-02-02"
"2102.00078","Mathieu Renzo","M. Renzo, T. Callister, K. Chatziioannou, L. A. C. van Son, C. M. F.
  Mingarelli, M. Cantiello, K. E. S. Ford, B. McKernan, and G. Ashton","Prospects of gravitational-waves detections from common-envelope
  evolution with LISA","Accepted by ApJ -- author's version. Code available at:
  https://github.com/tcallister/LISA-and-CE-Evolution",,"10.3847/1538-4357/ac1110",,"astro-ph.SR gr-qc","http://creativecommons.org/licenses/by-sa/4.0/","  Understanding common envelope (CE) evolution is an outstanding problem in
binary evolution. Although the CE phase is not driven by gravitational-wave
(GW) emission, the in-spiraling binary emits GWs that passively trace the CE
dynamics. Detecting this GW signal would provide direct insight into the
gas-driven physics. Even a non-detection might offer invaluable constraints. We
investigate the prospects of detection of a Galactic CE by LISA. While the
dynamical phase of the CE is likely sufficiently loud for detection, it is
short and thus rare. We focus instead on the self-regulated phase that proceeds
on a thermal timescale. Based on population synthesis calculations and the
(unknown) signal duration in the LISA band, we expect $\sim 0.1-100$ sources in
the Galaxy during the mission duration. We map the GW observable parameter
space of frequency $f_\mathrm{GW}$ and its derivative $\dot f_\mathrm{GW}$
remaining agnostic on the specifics of the inspiral, and find that signals with
$\mathrm{SNR}>10$ are possible if the CE stalls at separations such that
$f_\mathrm{GW}\gtrsim2\times10^{-3}\,\mathrm{Hz}$. We investigate the
possibility of misidentifying the signal with other known sources. If the
second derivative $\ddot f_\mathrm{GW}$ can also be measured, the signal can be
distinguished from other sources using a GW braking-index. Alternatively,
coupling LISA with electromagnetic observations of peculiar red giant stars
and/or infrared and optical transients might allow for the disentangling of a
Galactic CE from other Galactic and extra-galactic GW sources.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:32:26 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 20:36:29 GMT""}]","2021-10-13"
"2102.00079","Pulkit Tandon","Pulkit Tandon, Mariana Afonso, Joel Sole, Luk\'a\v{s} Krasula","CAMBI: Contrast-aware Multiscale Banding Index","5 pages, 7 figures, 2 tables",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Banding artifacts are artificially-introduced contours arising from the
quantization of a smooth region in a video. Despite the advent of recent higher
quality video systems with more efficient codecs, these artifacts remain
conspicuous, especially on larger displays. In this work, a comprehensive
subjective study is performed to understand the dependence of the banding
visibility on encoding parameters and dithering. We subsequently develop a
simple and intuitive no-reference banding index called CAMBI (Contrast-aware
Multiscale Banding Index) which uses insights from Contrast Sensitivity
Function in the Human Visual System to predict banding visibility. CAMBI
correlates well with subjective perception of banding while using only a few
visually-motivated hyperparameters.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:36:41 GMT""}]","2021-02-02"
"2102.00080","Hayley Petras","Hayley R. Petras, William Z. Van Benschoten, Sai Kumar Ramadugu, James
  J. Shepherd","The sign problem in density matrix quantum Monte Carlo","18 pages, 23 figures",,,,"physics.chem-ph cond-mat.str-el physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Density matrix quantum Monte Carlo (DMQMC) is a recently-developed method for
stochastically sampling the $N$-particle thermal density matrix to obtain
exact-on-average energies for model and \emph{ab initio} systems. We report a
systematic numerical study of the sign problem in DMQMC based on simulations of
atomic and molecular systems. In DMQMC, the density matrix is written in an
outer product basis of Slater determinants and has a size of space which is the
square of the number of Slater determinants. In principle this means DMQMC
needs to sample a space which scales in the system size, $N$, as
$\mathcal{O}[(\exp(N))^2]$. In practice, there is a system-dependent critical
walker population ($N_c$) which must be exceeded in order to remove the sign
problem, and this imposes limitations by way of storage and computer time. We
establish that $N_c$ for DMQMC is the square of $N_c$ for FCIQMC. By contrast,
the minimum $N_c$ in the interaction picture modification of DMQMC (IP-DMQMC)
only is directly proportionate to the $N_c$ for FCIQMC. We find that this comes
from the asymmetric propagation of IP-DMQMC compared to the symmetric
propagation of canonical DMQMC. An asymmetric mode of propagation is
prohibitively expensive for DMQMC because it has a much greater stochastic
error. Finally, we find that the equivalence between IP-DMQMC and FCIQMC seems
to extend to the initiator approximation, which is often required to study
larger basis sets and other systems. This suggests IP-DMQMC offers a way to
ameliorate the cost of moving between a Slater determinant space and an outer
product basis.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:43:03 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 15:01:48 GMT""}]","2021-08-04"
"2102.00081","Zhihua Ma","Anatoliy Khait and Zhihua Ma","Phase shifting, dispersion variation and defocusing suppression in wave
  breaking","40 pages",,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an investigation of the fundamental physical processes involved in
deep water wave breaking. Our motivation is to identify the underlying reason
causing the deficiency of the eddy viscosity breaking model (EVBM) in
predicting surface elevation for strongly nonlinear waves. Owing to the
limitation of experimental methods in the provision of high-resolution flow
information, we propose a numerical methodology by developing an EVBM enclosed
standalone fully-nonlinear quasi-potential (FNP) flow model and a coupled FNP
plus Navier-Stokes flow model. The numerical models were firstly verified with
a wave train subject to modulational instability, then used to simulate a
series of broad-banded focusing wave trains under non-, moderate- and
strong-breaking conditions. A systematic analysis was carried out to
investigate the discrepancies of numerical solutions produced by the two models
in surface elevation and other important physical properties. It is found that
EVBM predicts accurately the energy dissipated by breaking and the amplitude
spectrum of free waves in terms of magnitude, but fails to capture accurately
breaking induced phase shifting. The shift of phase grows with breaking
intensity and is especially strong for high wavenumber components. This is
identified as a cause of the upshift of wave dispersion relation, which
increases the frequencies of large wavenumber components. Such a variation
drives large-wavenumber components to propagate at nearly the same speed, which
is significantly higher than the linear dispersion levels. This suppresses the
instant dispersive spreading of harmonics after the focal point, prolonging the
lifespan of focused waves and expanding their propagation space.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:44:02 GMT""}]","2021-02-02"
"2102.00082","Sophie H. Yu","Yihong Wu and Jiaming Xu and Sophie H. Yu","Settling the Sharp Reconstruction Thresholds of Random Graph Matching",,,,,"math.ST cs.IT math.IT stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the problem of recovering the hidden vertex correspondence
between two edge-correlated random graphs. We focus on the Gaussian model where
the two graphs are complete graphs with correlated Gaussian weights and the
Erd\H{o}s-R\'enyi model where the two graphs are subsampled from a common
parent Erd\H{o}s-R\'enyi graph $\mathcal{G}(n,p)$. For dense graphs with
$p=n^{-o(1)}$, we prove that there exists a sharp threshold, above which one
can correctly match all but a vanishing fraction of vertices and below which
correctly matching any positive fraction is impossible, a phenomenon known as
the ""all-or-nothing"" phase transition. Even more strikingly, in the Gaussian
setting, above the threshold all vertices can be exactly matched with high
probability. In contrast, for sparse Erd\H{o}s-R\'enyi graphs with
$p=n^{-\Theta(1)}$, we show that the all-or-nothing phenomenon no longer holds
and we determine the thresholds up to a constant factor. Along the way, we also
derive the sharp threshold for exact recovery, sharpening the existing results
in Erd\H{o}s-R\'enyi graphs.
  The proof of the negative results builds upon a tight characterization of the
mutual information based on the truncated second-moment computation and an
""area theorem"" that relates the mutual information to the integral of the
reconstruction error. The positive results follows from a tight analysis of the
maximum likelihood estimator that takes into account the cycle structure of the
induced permutation on the edges.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:49:50 GMT""},{""version"":""v2"",""created"":""Sat, 13 Nov 2021 15:38:03 GMT""},{""version"":""v3"",""created"":""Wed, 16 Feb 2022 17:10:43 GMT""}]","2022-02-17"
"2102.00083","Elizabeth Qian","Elizabeth Qian, Ionut-Gabriel Farcas, and Karen Willcox","Reduced operator inference for nonlinear partial differential equations",,,,,"math.NA cs.LG cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new scientific machine learning method that learns from data a
computationally inexpensive surrogate model for predicting the evolution of a
system governed by a time-dependent nonlinear partial differential equation
(PDE), an enabling technology for many computational algorithms used in
engineering settings. Our formulation generalizes to the function space PDE
setting the Operator Inference method previously developed in [B. Peherstorfer
and K. Willcox, Data-driven operator inference for non-intrusive
projection-based model reduction, Computer Methods in Applied Mechanics and
Engineering, 306 (2016)] for systems governed by ordinary differential
equations. The method brings together two main elements. First, ideas from
projection-based model reduction are used to explicitly parametrize the learned
model by low-dimensional polynomial operators which reflect the known form of
the governing PDE. Second, supervised machine learning tools are used to infer
from data the reduced operators of this physics-informed parametrization. For
systems whose governing PDEs contain more general (non-polynomial)
nonlinearities, the learned model performance can be improved through the use
of lifting variable transformations, which expose polynomial structure in the
PDE. The proposed method is demonstrated on two examples: a heat equation model
problem that demonstrates the benefits of the function space formulation in
terms of consistency with the underlying continuous truth, and a
three-dimensional combustion simulation with over 18 million degrees of
freedom, for which the learned reduced models achieve accurate predictions with
a dimension reduction of five orders of magnitude and model runtime reduction
of up to nine orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:50:20 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 16:36:39 GMT""}]","2022-02-28"
"2102.00084","Aditya Deshpande","Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li,
  Luca Zancato, Charless Fowlkes, Rahul Bhotika, Stefano Soatto, Pietro Perona","A linearized framework and a new benchmark for model selection for
  fine-tuning","14 pages",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-tuning from a collection of models pre-trained on different domains (a
""model zoo"") is emerging as a technique to improve test accuracy in the
low-data regime. However, model selection, i.e. how to pre-select the right
model to fine-tune from a model zoo without performing any training, remains an
open topic. We use a linearized framework to approximate fine-tuning, and
introduce two new baselines for model selection -- Label-Gradient and
Label-Feature Correlation. Since all model selection algorithms in the
literature have been tested on different use-cases and never compared directly,
we introduce a new comprehensive benchmark for model selection comprising of:
i) A model zoo of single and multi-domain models, and ii) Many target tasks.
Our benchmark highlights accuracy gain with model zoo compared to fine-tuning
Imagenet models. We show our model selection baseline can select optimal models
to fine-tune in few selections and has the highest ranking correlation to
fine-tuning accuracy compared to existing algorithms.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:57:15 GMT""}]","2021-02-02"
"2102.00085","Campbell Watson","Etienne E. Vos, Ashley Gritzman, Sibusisiwe Makhanya, Thabang
  Mashinini, Campbell D. Watson","Long-Range Seasonal Forecasting of 2m-Temperature with Machine Learning","5 pages, 3 figures, NeurIPS 2020, Tackling Climate Change with
  Machine Learning",,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  A significant challenge in seasonal climate prediction is whether a
prediction can beat climatology. We hereby present results from two data-driven
models - a convolutional (CNN) and a recurrent (RNN) neural network - that
predict 2 m temperature out to 52 weeks for six geographically-diverse
locations. The motivation for testing the two classes of ML models is to allow
the CNN to leverage information related to teleconnections and the RNN to
leverage long-term historical temporal signals. The ML models boast improved
accuracy of long-range temperature forecasts up to a lead time of 30 weeks for
PCC and up 52 weeks for RMSESS, however only for select locations. Further
iteration is required to ensure the ML models have value beyond regions where
the climatology has a noticeably reduced correlation skill, namely the tropics.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:58:49 GMT""}]","2021-02-02"
"2102.00086","Xuhui Zhou","Xuhui Zhou, Maarten Sap, Swabha Swayamdipta, Noah A. Smith, Yejin Choi","Challenges in Automated Debiasing for Toxic Language Detection","EACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Biased associations have been a challenge in the development of classifiers
for detecting toxic language, hindering both fairness and accuracy. As
potential solutions, we investigate recently introduced debiasing methods for
text classification datasets and models, as applied to toxic language
detection. Our focus is on lexical (e.g., swear words, slurs, identity
mentions) and dialectal markers (specifically African American English). Our
comprehensive experiments establish that existing methods are limited in their
ability to prevent biased behavior in current toxicity detectors. We then
propose an automatic, dialect-aware data correction method, as a
proof-of-concept. Despite the use of synthetic labels, this method reduces
dialectal associations with toxicity. Overall, our findings show that debiasing
a model trained on biased toxic language data is not as effective as simply
relabeling the data to remove existing biases.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:03:17 GMT""}]","2021-02-02"
"2102.00087","Amjad Dehman","Amjad Dehman, Bilal Farooq","Are Work Zones and Connected Automated Vehicles Ready for a Harmonious
  Coexistence? A Scoping Review and Research Agenda","This paper is published in Transportation Research Part C: Emerging
  Technologies journal","Transportation Research Part C: Emerging Technologies. Issue 133,
  Article Number 103422, 2021","10.1016/j.trc.2021.103422",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent advent of connected and automated vehicles (CAVs) is expected to
transform the transportation system. CAV technologies are being developed
rapidly and they are foreseen to penetrate the market at a rapid pace. On the
other hand, work zones (WZs) have become common areas on highway systems as a
result of the increasing construction and maintenance activities. The near
future will therefore bring the coexistence of CAVs and WZs which makes their
interaction inevitable. WZs expose all vehicles to a sudden and complex
geometric change in the roadway environment, something that may challenge many
of CAV navigation capabilities. WZs however also impose a space contraction
resulting in adverse traffic impacts, something that legitimately calls for
benefiting from the highly efficient CAV functions. CAVs should be able to
reliably traverse WZ geometry and WZs should benefit from CAV intelligent
functions. This paper reviews the state-of-the-art and the key concepts,
opportunities, and challenges of deploying CAV systems at WZs. The reviewed
subjects include traffic performance and behaviour, technologies and
infrastructure, and regulatory considerations. Eighteen CAV mobility, safety,
and environmental concepts and functions were distributed over the WZ area
which was subdivided into five segments: further upstream, approach area,
queuing area, WZ activity, and termination area. In addition, among other
topics reviewed and discussed are detection of WZ features, smart traffic
control devices, various technologies at connected WZs, cross-border
harmonization, liability, insurance, and privacy. The paper also provides a
research agenda with a list of research needs supported by experts rating and
inputs. The paper aims to provide a bird eye view, but with necessary details
that can benefit researchers, practitioners, and transportation agencies.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:05:48 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 15:47:52 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 16:54:39 GMT""}]","2021-11-18"
"2102.00088","Dae Yeol Lee","Dae Yeol Lee, Somdyuti Paul, Christos G. Bampis, Hyunsuk Ko, Jongho
  Kim, Se Yoon Jeong, Blake Homan, Alan C. Bovik","A Subjective and Objective Study of Space-Time Subsampled Video Quality",,,"10.1109/TIP.2021.3137658",,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video dimensions are continuously increasing to provide more realistic and
immersive experiences to global streaming and social media viewers. However,
increments in video parameters such as spatial resolution and frame rate are
inevitably associated with larger data volumes. Transmitting increasingly
voluminous videos through limited bandwidth networks in a perceptually optimal
way is a current challenge affecting billions of viewers. One recent practice
adopted by video service providers is space-time resolution adaptation in
conjunction with video compression. Consequently, it is important to understand
how different levels of space-time subsampling and compression affect the
perceptual quality of videos. Towards making progress in this direction, we
constructed a large new resource, called the ETRI-LIVE Space-Time Subsampled
Video Quality (ETRI-LIVE STSVQ) database, containing 437 videos generated by
applying various levels of combined space-time subsampling and video
compression on 15 diverse video contents. We also conducted a large-scale human
study on the new dataset, collecting about 15,000 subjective judgments of video
quality. We provide a rate-distortion analysis of the collected subjective
scores, enabling us to investigate the perceptual impact of space-time
subsampling at different bit rates. We also evaluated and compared the
performance of leading video quality models on the new database.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:05:57 GMT""}]","2022-01-19"
"2102.00089","Mengfan Yao","Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh","Stimuli-Sensitive Hawkes Processes for Personalized Student
  Procrastination Modeling",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  Student procrastination and cramming for deadlines are major challenges in
online learning environments, with negative educational and well-being side
effects. Modeling student activities in continuous time and predicting their
next study time are important problems that can help in creating personalized
timely interventions to mitigate these challenges. However, previous attempts
on dynamic modeling of student procrastination suffer from major issues: they
are unable to predict the next activity times, cannot deal with missing
activity history, are not personalized, and disregard important course
properties, such as assignment deadlines, that are essential in explaining the
cramming behavior. To resolve these problems, we introduce a new personalized
stimuli-sensitive Hawkes process model (SSHP), by jointly modeling all
student-assignment pairs and utilizing their similarities, to predict students'
next activity times even when there are no historical observations. Unlike
regular point processes that assume a constant external triggering effect from
the environment, we model three dynamic types of external stimuli, according to
assignment availabilities, assignment deadlines, and each student's time
management habits. Our experiments on two synthetic datasets and two real-world
datasets show a superior performance of future activity prediction, comparing
with state-of-the-art models. Moreover, we show that our model achieves a
flexible and accurate parameterization of activity intensities in students.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:07:07 GMT""}]","2021-02-02"
"2102.00090","Anna Skripka","Teun D.H. van Nuland, Anna Skripka","Spectral shift for relative Schatten class perturbations","added proof details, corrected errors",,,,"math.FA math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We affirmatively settle the question on existence of a real-valued higher
order spectral shift function for a pair of self-adjoint operators $H$ and $V$
such that $V$ is bounded and $V(H-iI)^{-1}$ belongs to a Schatten-von Neumann
ideal $\mathcal{S}^n$ of compact operators in a separable Hilbert space. We
also show that the function satisfies the same trace formula as in the known
case of $V\in\mathcal{S}^n$ and that it is unique up to a polynomial summand of
order $n-1$. Our result significantly advances earlier partial results where
counterparts of the spectral shift function for noncompact perturbations lacked
real-valuedness and aforementioned uniqueness as well as appeared in more
complicated trace formulas for much more restrictive sets of functions. Our
result applies to models arising in noncommutative geometry and mathematical
physics.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:08:13 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 16:44:04 GMT""},{""version"":""v3"",""created"":""Tue, 23 Aug 2022 23:08:43 GMT""}]","2022-08-25"
"2102.00091","Werner Riegler","Werner Riegler and Philipp Windischhofer","Time resolution and efficiency of SPADs and SiPMs for photons and
  charged particles",,,"10.1016/j.nima.2021.165265",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We give an analytic treatment of the time resolution and efficiency of Single
Photon Avalanche Diodes (SPADs) and Silicon Photomultipliers (SiPMs). We
provide closed-form expressions for structures with uniform electric fields and
efficient numerical prescriptions for arbitrary electric field configurations.
We discuss the sensor performance for single photon detection and also for
charged particle detection.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:10:38 GMT""}]","2021-05-05"
"2102.00092","Justin Dumouchelle","Justin Dumouchelle, Emma Frejinger, Andrea Lodi","Reinforcement Learning for Freight Booking Control Problems",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Booking control problems are sequential decision-making problems that occur
in the domain of revenue management. More precisely, freight booking control
focuses on the problem of deciding to accept or reject bookings: given a
limited capacity, accept a booking request or reject it to reserve capacity for
future bookings with potentially higher revenue. This problem can be formulated
as a finite-horizon stochastic dynamic program, where accepting a set of
requests results in a profit at the end of the booking period that depends on
the cost of fulfilling the accepted bookings. For many freight applications,
the cost of fulfilling requests is obtained by solving an operational
decision-making problem, which often requires the solutions to mixed-integer
linear programs. Routinely solving such operational problems when deploying
reinforcement learning algorithms may be too time consuming. The majority of
booking control policies are obtained by solving problem-specific mathematical
programming relaxations that are often non-trivial to generalize to new
problems and, in some cases, provide quite crude approximations.
  In this work, we propose a two-phase approach: we first train a supervised
learning model to predict the objective of the operational problem, and then we
deploy the model within reinforcement learning algorithms to compute control
policies. This approach is general: it can be used every time the objective
function of the end-of-horizon operational problem can be predicted, and it is
particularly suitable to those cases where such problems are computationally
hard. Furthermore, it allows one to leverage the recent advances in
reinforcement learning as routinely solving the operational problem is replaced
with a single prediction. Our methodology is evaluated on two booking control
problems in the literature, namely, distributional logistics and airline cargo
management.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:11:59 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 15:48:11 GMT""},{""version"":""v3"",""created"":""Wed, 5 Apr 2023 00:39:18 GMT""}]","2023-04-06"
"2102.00093","Mengfan Yao","Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh","Relaxed Clustered Hawkes Process for Procrastination Modeling in MOOCs",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  Hawkes processes have been shown to be efficient in modeling bursty sequences
in a variety of applications, such as finance and social network activity
analysis. Traditionally, these models parameterize each process independently
and assume that the history of each point process can be fully observed. Such
models could however be inefficient or even prohibited in certain real-world
applications, such as in the field of education, where such assumptions are
violated. Motivated by the problem of detecting and predicting student
procrastination in students Massive Open Online Courses (MOOCs) with missing
and partially observed data, in this work, we propose a novel personalized
Hawkes process model (RCHawkes-Gamma) that discovers meaningful student
behavior clusters by jointly learning all partially observed processes
simultaneously, without relying on auxiliary features. Our experiments on both
synthetic and real-world education datasets show that RCHawkes-Gamma can
effectively recover student clusters and their temporal procrastination
dynamics, resulting in better predictive performance of future student
activities. Our further analyses of the learned parameters and their
association with student delays show that the discovered student clusters
unveil meaningful representations of various procrastination behaviors in
students.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:20:38 GMT""}]","2021-02-02"
"2102.00094","Megan Farrah","Christopher R. Arumainayagam, Eric Herbst, A.N. Heays, Ella Mullikin,
  Megan Farrah, Michael G. Mavros","Extraterrestrial Photochemistry: Principles and Applications","30 pages, 14 figures",,,,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Energetic processing of interstellar ice mantles and planetary atmospheres
via photochemistry is a critical mechanism in the extraterrestrial synthesis of
prebiotic molecules. Photochemistry is defined as chemical processes initiated
by photon-induced electronic excitation, not involving ionization. In contrast,
photons with energies above the ionization threshold initiate radiation
chemistry (radiolysis). Vacuum-ultraviolet (6.2-12.4 eV) light may initiate
photochemistry and radiation chemistry because the threshold for producing
secondary electrons is lower in the condensed phase than in the gas phase.
Approximately half of cosmic-ray induced photons incident on interstellar ices
in star-forming regions initiate photochemistry while the rest initiate
radiation chemistry. While experimental techniques such as velocity map imaging
may be used to extract exquisite details about gas-phase photochemistry, such
detailed information cannot be obtained for condensed-phase photochemistry,
which involves greater complexity, including the production of excitons,
excimers, and exciplexes. Because a primary objective of chemistry is to
provide molecular-level mechanistic explanations for macroscopic phenomena, our
ultimate goal in this book chapter is to critically evaluate our current
understanding of the photochemistry that likely leads to the synthesis of
extraterrestrial prebiotic molecules.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:31:19 GMT""}]","2021-02-02"
"2102.00095","Miko{\l}aj Korzy\'nski","Miko{\l}aj Korzy\'nski, Jan Mi\'skiewicz, Julius Serbenta","Weighing the spacetime along the line of sight using times of arrival of
  electromagnetic signals","65 pages, 5 figures. Major revision, App. A and G added, corrections
  throughout the text","Phys. Rev. D 104, 024026 (2021)","10.1103/PhysRevD.104.024026",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new method of measuring the mass density along the line of
sight, based on precise measurements of the variations of the times of arrival
(TOA's) of electromagnetic signals propagating between two distant regions of
spacetime. The TOA variations are measured between a number of slightly
displaced pairs of points from the two regions. These variations are due to the
nonrelativistic geometric effects (Roemer delays and finite distance effects)
as well as the gravitational effects in the light propagation (gravitational
ray bending and Shapiro delays). We show that from a sufficiently broad sample
of TOA measurements we can determine two scalars quantifying the impact of the
spacetime curvature on the light propagation, directly related to the first two
moments of the mass density distribution along the line of sight. The values of
the scalars are independent of the angular positions or the states of motion of
the two clock ensembles we use for the measurement and free from any influence
of masses off the line of sight. These properties can make the mass density
measurements very robust. The downside of the method is the need for extremely
precise signal timing.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:35:30 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 16:55:34 GMT""}]","2021-07-14"
"2102.00096","EPTCS","Fabrizio Romano Genovese (University of Pisa, Statebox), Jelle Herold
  (Statebox), Fosco Loregian (Tallinn University of Technology), Daniele
  Palombi (Sapienza University of Rome)","A Categorical Semantics for Hierarchical Petri Nets","In Proceedings GCM 2021, arXiv:2112.10217","EPTCS 350, 2021, pp. 51-68","10.4204/EPTCS.350.4",,"math.CT cs.DC cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how a particular variety of hierarchical nets, where the firing of a
transition in the parent net must correspond to an execution in some child net,
can be modelled utilizing a functorial semantics from a free category --
representing the parent net -- to the category of sets and spans between them.
This semantics can be internalized via Grothendieck construction, resulting in
the category of executions of a Petri net representing the semantics of the
overall hierarchical net. We conclude the paper by giving an
engineering-oriented overview of how our model of hierarchical nets can be
implemented in a transaction-based smart contract environment.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:37:34 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 10:12:17 GMT""}]","2021-12-22"
"2102.00097","Huang Ling","Ling Huang, Su Ruan, Thierry Denoeux","Belief function-based semi-supervised learning for brain tumor
  segmentation","5 pages, 4 figures, ISBI2021 conference",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Precise segmentation of a lesion area is important for optimizing its
treatment. Deep learning makes it possible to detect and segment a lesion field
using annotated data. However, obtaining precisely annotated data is very
challenging in the medical domain. Moreover, labeling uncertainty and
imprecision make segmentation results unreliable. In this paper, we address the
uncertain boundary problem by a new evidential neural network with an
information fusion strategy, and the scarcity of annotated data by
semi-supervised learning. Experimental results show that our proposal has
better performance than state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:39:16 GMT""}]","2021-02-02"
"2102.00098","Sangjun Lee","Sangjun Lee and Byung-Cheol Min","Distributed Control of Multi-Robot Systems in the Presence of Deception
  and Denial of Service Attacks",,,,,"cs.RO math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This research proposes a distributed switching control to secure multi-robot
systems in the presence of cyberattacks. Two major types of cyberattack are
considered: deception attack and denial of service (DoS) attack, which
compromise the integrity and availability of resources, respectively. First, a
residual-based attack detection scheme is introduced to identify the type of
attacks. Then, a switching control is designed to neutralize the effect of the
identified attacks, satisfying the performance guarantees required for state
consensus among robots. For the type of a deception attack, coordination-free
consensus protocols are designed to tune the weights of each robot in a way
that uncompromised robots gain more weight than compromised robots. For the
type of a DoS attack, leader-follower protocols that reconfigure the
communication topology are utilized to transform the compromised robots into
sub-robots following the leaders. The performance of the proposed approach is
evaluated on the Robotarium multi-robot testbed. A full demonstration with
extensive cases is available at https://youtu.be/eSj0XS2pdxI.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:42:11 GMT""}]","2021-02-02"
"2102.00099","Henrique Ferraz de Arruda","Henrique F. de Arruda, Felipe M. Cardoso, Guilherme F. de Arruda,
  Alexis R. Hern\'andez, Luciano da F. Costa, Yamir Moreno","Modeling how social network algorithms can influence opinion
  polarization",,,"10.1016/j.ins.2021.12.069",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among different aspects of social networks, dynamics have been proposed to
simulate how opinions can be transmitted. In this study, we propose a model
that simulates the communication in an online social network, in which the
posts are created from external information. We considered the nodes and edges
of a network as users and their friendship, respectively. A real number is
associated with each user representing its opinion. The dynamics starts with a
user that has contact with a random opinion, and, according to a given
probability function, this individual can post this opinion. This step is
henceforth called post transmission. In the next step, called post
distribution, another probability function is employed to select the user's
friends that could see the post. Post transmission and distribution represent
the user and the social network algorithm, respectively. If an individual has
contact with a post, its opinion can be attracted or repulsed. Furthermore,
individuals that are repulsed can change their friendship through a rewiring.
These steps are executed various times until the dynamics converge. Several
impressive results were obtained, which include the formation of scenarios of
polarization and consensus of opinions. In the case of echo chambers, the
possibility of rewiring probability is found to be decisive. However, for
particular network topologies, with a well-defined community structure, this
effect can also happen. All in all, the results indicate that the post
distribution strategy is crucial to mitigate or promote polarization.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:42:20 GMT""}]","2022-01-11"
"2102.00100","Mauricio Sepulveda","Aissa Guesmia, Jaime Mu\~noz Rivera, Mauricio Sep\'ulveda, Octavio
  Vera","Laminated Timoshenko beams with interfacial slip and infinite memories",,"Math. Methods Appl. Sci. 45 (2022), no. 8, 4408-4427","10.1002/mma.8046",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study in this paper the well-posedness and stability of three structures
with interfacial slip and two infinite memories effective on the transverse
displacement and the rotation angle. We consider a large class of kernels and
prove that the system has a unique solution satisfying some regularity
properties. Moreover, without restrictions on the values of the parameters, we
show that the solution goes to zero at infinity and give an information on its
speed of convergence in terms of the growth of kernels at infinity. A numerical
analysis of the obtained theoretical results will be also given.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:42:23 GMT""}]","2023-01-20"
"2102.00101","Peimeng Yin","Hailiang Liu, Zhongming Wang, Peimeng Yin, Hui Yu","Positivity-preserving third order DG schemes for Poisson--Nernst--Planck
  equations","7 figures, 16 tables",,"10.1016/j.jcp.2021.110777",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we design and analyze third order positivity-preserving
discontinuous Galerkin (DG) schemes for solving the time-dependent system of
Poisson--Nernst--Planck (PNP) equations, which has found much use in diverse
applications. Our DG method with Euler forward time discretization is shown to
preserve the positivity of cell averages at all time steps. The positivity of
numerical solutions is then restored by a scaling limiter in reference to
positive weighted cell averages. The method is also shown to preserve steady
states. Numerical examples are presented to demonstrate the third order
accuracy and illustrate the positivity-preserving property in both one and two
dimensions.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:47:14 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 02:41:18 GMT""}]","2022-01-26"
"2102.00102","Ivana Malenica","Ivana Malenica, Aurelien Bibaut and Mark J. van der Laan","Adaptive Sequential Design for a Single Time-Series","arXiv admin note: text overlap with arXiv:1809.00734",,,,"math.ST cs.LG stat.ME stat.ML stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The current work is motivated by the need for robust statistical methods for
precision medicine; as such, we address the need for statistical methods that
provide actionable inference for a single unit at any point in time. We aim to
learn an optimal, unknown choice of the controlled components of the design in
order to optimize the expected outcome; with that, we adapt the randomization
mechanism for future time-point experiments based on the data collected on the
individual over time. Our results demonstrate that one can learn the optimal
rule based on a single sample, and thereby adjust the design at any point t
with valid inference for the mean target parameter. This work provides several
contributions to the field of statistical precision medicine. First, we define
a general class of averages of conditional causal parameters defined by the
current context for the single unit time-series data. We define a nonparametric
model for the probability distribution of the time-series under few
assumptions, and aim to fully utilize the sequential randomization in the
estimation procedure via the double robust structure of the efficient influence
curve of the proposed target parameter. We present multiple
exploration-exploitation strategies for assigning treatment, and methods for
estimating the optimal rule. Lastly, we present the study of the data-adaptive
inference on the mean under the optimal treatment rule, where the target
parameter adapts over time in response to the observed context of the
individual. Our target parameter is pathwise differentiable with an efficient
influence function that is doubly robust - which makes it easier to estimate
than previously proposed variations. We characterize the limit distribution of
our estimator under a Donsker condition expressed in terms of a notion of
bracketing entropy adapted to martingale settings.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:51:45 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 15:16:45 GMT""}]","2021-07-02"
"2102.00103","Nathan Clement","Nathan Clement, Alan Schoen, Arnold Boedihardjo, and Andrew Jenkins","Synthetic Data and Hierarchical Object Detection in Overhead Imagery","10 pages, 6 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of neural network models is often limited by the availability
of big data sets. To treat this problem, we survey and develop novel synthetic
data generation and augmentation techniques for enhancing low/zero-sample
learning in satellite imagery. In addition to extending synthetic data
generation approaches, we propose a hierarchical detection approach to improve
the utility of synthetic training samples. We consider existing techniques for
producing synthetic imagery--3D models and neural style transfer--as well as
introducing our own adversarially trained reskinning network, the
GAN-Reskinner, to blend 3D models. Additionally, we test the value of synthetic
data in a two-stage, hierarchical detection/classification model of our own
construction. To test the effectiveness of synthetic imagery, we employ it in
the training of detection models and our two stage model, and evaluate the
resulting models on real satellite images. All modalities of synthetic data are
tested extensively on practical, geospatial analysis problems. Our experiments
show that synthetic data developed using our approach can often enhance
detection performance, particularly when combined with some real training
images. When the only source of data is synthetic, our GAN-Reskinner often
boosts performance over conventionally rendered 3D models and in all cases the
hierarchical model outperforms the baseline end-to-end detection architecture.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:52:47 GMT""}]","2021-02-02"
"2102.00104","Melven R\""ohrig-Z\""ollner","Melven R\""ohrig-Z\""ollner and Jonas Thies and Achim Basermann","Performance of the low-rank tensor-train SVD (TT-SVD) for large dense
  tensors on modern multi-core CPUs","26 pages, 16 figures, accepted by SISC",,"10.1137/21M1395545",,"math.NA cs.MS cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are several factorizations of multi-dimensional tensors into
lower-dimensional components, known as `tensor networks'. We consider the
popular `tensor-train' (TT) format and ask: How efficiently can we compute a
low-rank approximation from a full tensor on current multi-core CPUs?
  Compared to sparse and dense linear algebra, kernel libraries for
multi-linear algebra are rare and typically not as well optimized. Linear
algebra libraries like BLAS and LAPACK may provide the required operations in
principle, but often at the cost of additional data movements for rearranging
memory layouts. Furthermore, these libraries are typically optimized for the
compute-bound case (e.g.\ square matrix operations) whereas low-rank tensor
decompositions lead to memory bandwidth limited operations.
  We propose a `tensor-train singular value decomposition' (TT-SVD) algorithm
based on two building blocks: a `Q-less tall-skinny QR' factorization, and a
fused tall-skinny matrix-matrix multiplication and reshape operation. We
analyze the performance of the resulting TT-SVD algorithm using the Roofline
performance model. In addition, we present performance results for different
algorithmic variants for shared-memory as well as distributed-memory
architectures. Our experiments show that commonly used TT-SVD implementations
suffer severe performance penalties. We conclude that a dedicated library for
tensor factorization kernels would benefit the community: Computing a low-rank
approximation can be as cheap as reading the data twice from main memory. As a
consequence, an implementation that achieves realistic performance will move
the limit at which one has to resort to randomized methods that only process
part of the data.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:56:55 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 19:38:58 GMT""},{""version"":""v3"",""created"":""Wed, 2 Mar 2022 12:55:39 GMT""}]","2023-04-18"
"2102.00105","Jae-Ho Lee","Jack H. Koolen, Jae-Ho Lee, Ying-Ying Tan","Remarks on pseudo-vertex-transitive graphs with small diameter","30 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Gamma$ denote a $Q$-polynomial distance-regular graph with vertex set
$X$ and diameter $D$. Let $A$ denote the adjacency matrix of $\Gamma$. For a
vertex $x\in X$ and for $0 \leq i \leq D$, let $E^*_i(x)$ denote the projection
matrix to the $i$th subconstituent space of $\Gamma$ with respect to $x$. The
Terwilliger algebra $T(x)$ of $\Gamma$ with respect to $x$ is the semisimple
subalgebra of $\mathrm{Mat}_X(\mathbb{C})$ generated by $A, E^*_0(x), E^*_1(x),
\ldots, E^*_D(x)$. Let $V$ denote a $\mathbb{C}$-vector space consisting of
complex column vectors with rows indexed by $X$. We say $\Gamma$ is
pseudo-vertex-transitive whenever for any vertices $x,y \in X$, there exists a
$\mathbb{C}$-vector space isomorphism $\rho:V\to V$ such that $(\rho A - A
\rho)V=0$ and $(\rho E^*_i(x) - E^*_i(y)\rho)V=0$ for all $0\leq i \leq D$. In
this paper, we discuss pseudo-vertex transitivity for distance-regular graphs
with diameter $D\in \{2,3,4\}$. For $D=2$, we show that a strongly regular
graph is pseudo-vertex-transitive if and only if all its local graphs have the
same spectrum. For $D = 3$, we consider the Taylor graphs and show that they
are pseudo-vertex transitive. For $D=4$, we consider the antipodal tight graphs
and show that they are pseudo-vertex transitive.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:16:01 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 22:05:02 GMT""},{""version"":""v3"",""created"":""Mon, 9 May 2022 17:03:08 GMT""}]","2022-05-10"
"2102.00106","Fritz Gesztesy","Fritz Gesztesy, Michael M. H. Pang, Jonathan Stanfill","Bessel-Type Operators and a refinement of Hardy's inequality","23 pages, updated references",,,,"math.SP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The principal aim of this paper is to employ Bessel-type operators in proving
the inequality \begin{align*} \int_0^\pi dx \, |f'(x)|^2 \geq
\dfrac{1}{4}\int_0^\pi dx \, \dfrac{|f(x)|^2}{\sin^2
(x)}+\dfrac{1}{4}\int_0^\pi dx \, |f(x)|^2,\quad f\in H_0^1 ((0,\pi)),
\end{align*} where both constants $1/4$ appearing in the above inequality are
optimal. In addition, this inequality is strict in the sense that equality
holds if and only if $f \equiv 0$. This inequality is derived with the help of
the exactly solvable, strongly singular, Dirichlet-type Schr\""{o}dinger
operator associated with the differential expression \begin{align*}
\tau_s=-\dfrac{d^2}{dx^2}+\dfrac{s^2-(1/4)}{\sin^2 (x)}, \quad s \in
[0,\infty), \; x \in (0,\pi). \end{align*}
  The new inequality represents a refinement of Hardy's classical inequality
\begin{align*} \int_0^\pi dx \, |f'(x)|^2 \geq \dfrac{1}{4}\int_0^\pi dx \,
\dfrac{|f(x)|^2}{x^2}, \quad f\in H_0^1 ((0,\pi)), \end{align*} it also
improves upon one of its well-known extensions in the form \begin{align*}
\int_0^\pi dx \, |f'(x)|^2 \geq \dfrac{1}{4}\int_0^\pi dx \,
\dfrac{|f(x)|^2}{d_{(0,\pi)}(x)^2}, \quad f\in H_0^1 ((0,\pi)), \end{align*}
where $d_{(0,\pi)}(x)$ represents the distance from $x \in (0,\pi)$ to the
boundary $\{0,\pi\}$ of $(0,\pi)$.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:19:28 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 02:41:30 GMT""},{""version"":""v3"",""created"":""Sat, 6 Mar 2021 20:26:54 GMT""},{""version"":""v4"",""created"":""Wed, 17 Mar 2021 06:51:54 GMT""},{""version"":""v5"",""created"":""Tue, 16 Nov 2021 00:09:19 GMT""}]","2021-11-17"
"2102.00107","Martin Pfaller","Martin R. Pfaller, Jonathan Pham, Nathan M. Wilson, David W. Parker,
  Alison L. Marsden","On the periodicity of cardiovascular fluid dynamics simulations",,,"10.1007/s10439-021-02796-x",,"cs.CE physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Three-dimensional cardiovascular fluid dynamics simulations typically require
computation of several cardiac cycles before they reach a periodic solution,
rendering them computationally expensive. Furthermore, there is currently no
standardized method to determine whether a simulation has yet reached that
periodic state. In this work, we propose use of the asymptotic error measure to
quantify the difference between simulation results and their ideal periodic
state using lumped-parameter modeling. We further show that initial conditions
are crucial in reducing computational time and develop an automated framework
to generate appropriate initial conditions from a one-dimensional model of
blood flow. We demonstrate the performance of our initialization method using
six patient-specific models from the Vascular Model Repository. In our
examples, our initialization protocol achieves periodic convergence within one
or two cardiac cycles, leading to a significant reduction in computational cost
compared to standard methods. All computational tools used in this work are
implemented in the open-source software platform SimVascular. Automatically
generated initial conditions have the potential to significantly reduce
computation time in cardiovascular fluid dynamics simulations.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:23:02 GMT""}]","2021-06-28"
"2102.00108","Rachel Somerville","Rachel S. Somerville, Charlotte Olsen, L. Y. Aaron Yung, Camilla
  Pacifici, Henry C. Ferguson, Peter Behroozi, Shannon Osborne, Risa H.
  Wechsler, Viraj Pandya, Sandra M. Faber, Joel R. Primack, Avishai Dekel","Mock Lightcones and Theory Friendly Catalogs for the CANDELS Survey","22 pages, 16 figures. To appear in MNRAS",,"10.1093/mnras/stab231",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present mock catalogs created to support the interpretation of the CANDELS
survey. We extract halos along past lightcones from the Bolshoi Planck
dissipationless N-body simulations and populate these halos with galaxies using
two different independently developed semi-analytic models of galaxy formation
and the empirical model UniverseMachine. Our mock catalogs have geometries that
encompass the footprints of observations associated with the five CANDELS
fields. In order to allow field-to-field variance to be explored, we have
created eight realizations of each field. In this paper, we present comparisons
with observable global galaxy properties, including counts in observed frame
bands, luminosity functions, color-magnitude distributions and color-color
distributions. We additionally present comparisons with physical galaxy
parameters derived from SED fitting for the CANDELS observations, such as
stellar masses and star formation rates. We find relatively good agreement
between the model predictions and CANDELS observations for luminosity and
stellar mass functions. We find poorer agreement for colors and star formation
rate distributions. All of the mock lightcones as well as curated ""theory
friendly"" versions of the observational CANDELS catalogs are made available
through a web-based data hub.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:34:25 GMT""}]","2021-03-10"
"2102.00109","Jasmine Sekhon","Jasmine Sekhon, Cody Fleming","SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent
  Prediction",,,,,"cs.CV cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Safe navigation of autonomous agents in human centric environments requires
the ability to understand and predict motion of neighboring pedestrians.
However, predicting pedestrian intent is a complex problem. Pedestrian motion
is governed by complex social navigation norms, is dependent on neighbors'
trajectories, and is multimodal in nature. In this work, we propose SCAN, a
Spatial Context Attentive Network that can jointly predict socially-acceptable
multiple future trajectories for all pedestrians in a scene. SCAN encodes the
influence of spatially close neighbors using a novel spatial attention
mechanism in a manner that relies on fewer assumptions, is parameter efficient,
and is more interpretable compared to state-of-the-art spatial attention
approaches. Through experiments on several datasets we demonstrate that our
approach can also quantitatively outperform state of the art trajectory
prediction methods in terms of accuracy of predicted intent.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:35:00 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 20:54:39 GMT""}]","2021-03-25"
"2102.00110","Dmitri Kharzeev","Dmitri E. Kharzeev","The mass radius of the proton","20 pages, 3 figures; 2 typos fixed","Phys. Rev. D 104, 054015 (2021)","10.1103/PhysRevD.104.054015",,"hep-ph hep-lat nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  The mass radius is a fundamental property of the proton that so far has not
been determined from experiment. Here we show that the mass radius of the
proton can be rigorously defined through the formfactor of the trace of the
energy-momentum tensor (EMT) of QCD in the weak gravitational field
approximation, as appropriate for this problem. We then demonstrate that the
scale anomaly of QCD enables the extraction of the formfactor of the trace of
the EMT from the data on threshold photoproduction of $J/\psi$ and $\Upsilon$
quarkonia, and use the recent GlueX Collaboration data to extract the r.m.s.
mass radius of the proton ${\rm R_m = 0.55 \pm 0.03 \ fm}$. The extracted mass
radius is significantly smaller than the charge radius of the proton ${\rm R_C
= 0.8409 \pm 0.0004 \ fm}$. We attribute this difference to the interplay of
asymptotic freedom and spontaneous breaking of chiral symmetry in QCD, and
outline future measurements needed to determine the mass radius more precisely.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:42:24 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 19:59:30 GMT""}]","2021-09-22"
"2102.00111","Jennifer Balakrishnan","Jennifer S. Balakrishnan, Ken Ono, and Wei-Lun Tsai","Even values of Ramanujan's tau-function","La Matematica (2021)",,"10.1007/s44007-021-00005-8",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the spirit of Lehmer's speculation that Ramanujan's tau-function never
vanishes, it is natural to ask whether any given integer $\alpha$ is a value of
$\tau(n)$. For odd $\alpha$, Murty, Murty, and Shorey proved that $\tau(n)\neq
\alpha$ for sufficiently large $n$. Several recent papers have identified
explicit examples of odd $\alpha$ which are not tau-values. Here we apply these
results (most notably the recent work of Bennett, Gherga, Patel, and Siksek) to
offer the first examples of even integers that are not tau-values. Namely, for
primes $\ell$ we find that $$ \tau(n)\not \in \{ \pm 2\ell \ : \ 3\leq \ell<
100\} \cup \{\pm 2\ell^2 \ : \ 3\leq \ell <100\} \cup \{\pm 2\ell^3 \ : \ 3\leq
\ell<100\ {\text {\rm with $\ell\neq 59$}}\}.$$ Moreover, we obtain such
results for infinitely many powers of each prime $3\leq \ell<100$. As an
example, for $\ell=97$ we prove that $$\tau(n)\not \in \{ 2\cdot 97^j \ : \
1\leq j\not \equiv 0\pmod{44}\}\cup \{-2\cdot 97^j \ : \ j\geq 1\}.$$ The
method of proof applies mutatis mutandis to newforms with residually reducible
mod 2 Galois representation and is easily adapted to generic newforms with
integer coefficients.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:55:01 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 21:42:22 GMT""},{""version"":""v3"",""created"":""Thu, 1 Jul 2021 02:46:15 GMT""},{""version"":""v4"",""created"":""Tue, 14 Dec 2021 02:40:17 GMT""}]","2021-12-15"
"2102.00112","Himanshu Akolkar","Seth Roffe, Himanshu Akolkar, Alan D. George, Bernab\'e
  Linares-barranco and Ryad Benosman","Neutron-Induced, Single-Event Effects on Neuromorphic Event-based Vision
  Sensor: A First Step Towards Space Applications",,"2021 IEEE ACCESS","10.1109/ACCESS.2021.3085136",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  This paper studies the suitability of neuromorphic event-based vision cameras
for spaceflight, and the effects of neutron radiation on their performance.
Neuromorphic event-based vision cameras are novel sensors that implement
asynchronous, clockless data acquisition, providing information about the
change in illuminance greater than 120dB with sub-millisecond temporal
precision. These sensors have huge potential for space applications as they
provide an extremely sparse representation of visual dynamics while removing
redundant information, thereby conforming to low-resource requirements. An
event-based sensor was irradiated under wide-spectrum neutrons at Los Alamos
Neutron Science Center and its effects were classified. We found that the
sensor had very fast recovery during radiation, showing high correlation of
noise event bursts with respect to source macro-pulses. No significant
differences were observed between the number of events induced at different
angles of incidence but significant differences were found in the spatial
structure of noise events at different angles. The results show that
event-based cameras are capable of functioning in a space-like, radiative
environment with a signal-to-noise ratio of 3.355. They also show that
radiation-induced noise does not affect event-level computation. We also
introduce the Event-based Radiation-Induced Noise Simulation Environment
(Event-RINSE), a simulation environment based on the noise-modelling we
conducted and capable of injecting the effects of radiation-induced noise from
the collected data to any stream of events in order to ensure that developed
code can operate in a radiative environment. To the best of our knowledge, this
is the first time such analysis of neutron-induced noise analysis has been
performed on a neuromorphic vision sensor, and this study shows the advantage
of using such sensors for space applications.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:56:16 GMT""}]","2021-06-14"
"2102.00113","Yanzhi Zhang","Yixuan Wu and Yanzhi Zhang","A universal solution scheme for fractional and classical PDEs","25 pages, 13 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a unified meshless method to solve classical and fractional PDE
problems with $(-\Delta)^{\frac{\alpha}{2}}$ for $\alpha \in (0, 2]$. The
classical ($\alpha = 2$) and fractional ($\alpha < 2$) Laplacians, one local
and the other nonlocal, have distinct properties. Therefore, their numerical
methods and computer implementations are usually incompatible. We notice that
for any $\alpha \ge 0$, the Laplacian $(-\Delta)^{\frac{\alpha}{2}}$ of
generalized inverse multiquadric (GIMQ) functions can be analytically written
by the Gauss hypergeometric function, and thus propose a GIMQ-based method. Our
method unifies the discretization of classical and fractional Laplacians and
also bypasses numerical approximation to the hypersingular integral of
fractional Laplacian. These two merits distinguish our method from other
existing methods for the fractional Laplacian. Extensive numerical experiments
are carried out to test the performance of our method. Compared to other
methods, our method can achieve high accuracy with fewer number of unknowns,
which effectively reduces the storage and computational requirements in
simulations of fractional PDEs. Moreover, the meshfree nature makes it free of
geometric constraints and enables simple implementation for any dimension $d
\ge 1$. Additionally, two approaches of selecting shape parameters, including
condition number-indicated method and random-perturbed method, are studied to
avoid the ill-conditioning issues when large number of points.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:06:14 GMT""}]","2021-02-02"
"2102.00114","Sergey Kravchenko","A. A. Shashkin and S. V. Kravchenko","Metal-insulator transition and low-density phases in a
  strongly-interacting two-dimensional electron system","A short review for the special issue ""Localisation 2020"" of Annals of
  Physics dedicated to P. W. Anderson","Ann. Phys. 435, 168542 (2021)","10.1016/j.aop.2021.168542",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We review recent experimental results on the metal-insulator transition and
low-density phases in strongly-interacting, low-disordered Si-based
two-dimensional electron systems. Special attention is given to the metallic
state in ultra-clean SiGe quantum wells and to the evidence for a flat band at
the Fermi level and a quantum electron solid.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:10:21 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 17:41:24 GMT""}]","2021-12-13"
"2102.00115","Parker Edwards","Parker B. Edwards, Jonathan D. Hauenstein, Clifford D. Smyth","Certified evaluations of H\""older continuous functions at roots of
  polynomials","15 pages, 1 figure, associated software package at
  https://github.com/P-Edwards/EvalCertification",,,,"cs.SC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various methods can obtain certified estimates for roots of polynomials. Many
applications in science and engineering additionally utilize the value of
functions evaluated at roots. For example, critical values are obtained by
evaluating an objective function at critical points. For analytic evaluation
functions, Newton's method naturally applies to yield certified estimates.
These estimates no longer apply, however, for H\""older continuous functions,
which are a generalization of Lipschitz continuous functions where continuous
derivatives need not exist. This work develops and analyzes an alternative
approach for certified estimates of evaluating locally H\""older continuous
functions at roots of polynomials. An implementation of the method in Maple
demonstrates efficacy and efficiency.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:14:39 GMT""}]","2021-02-02"
"2102.00116","Gizem Karaali","Gizem Karaali, Isabella Senturia, M\""uge Ta\c{s}kin","A New Partial Order on SYT",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a new partial order on $SYT_n$, the set of all standard Young
tableaux with $n$ cells, by combining the chain order with the notion of
horizontal strips. We prove various desirable properties of this new order.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:17:37 GMT""}]","2021-02-02"
"2102.00117","Yana Kinderknecht Butko","Christian Bender and Yana A. Butko","Stochastic solutions of generalized time-fractional evolution equations",,"Fractional Calculus and Applied Analysis, Vol. 25 N 2 2022","10.1007/s13540-022-00025-3",,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a general class of integro-differential evolution equations which
includes the governing equation of the generalized grey Brownian motion and the
time- and space-fractional heat equation. We present a general relation between
the parameters of the equation and the distribution of the underlying
stochastic processes, as well as discuss different classes of processes
providing stochastic solutions of these equations. For a subclass of evolution
equations, containing Saigo-Maeda generalized time-fractional operators, we
determine the parameters of the corresponding processes explicitly. Moreover,
we explain how self-similar stochastic solutions with stationary increments can
be obtained via linear fractional L\'evy motion for suitable
pseudo-differential operators in space.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:18:57 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 17:47:30 GMT""}]","2022-04-21"
"2102.00118","Kai Gong","Kai Gong and Claire E. White","Predicting CaO-(MgO)-Al2O3-SiO2 glass reactivity in alkaline
  environments from force field molecular dynamics simulations",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this investigation, force field-based molecular dynamics (MD) simulations
have been employed to generate detailed structural representations for a range
of amorphous quaternary CaO-MgO-Al2O3-SiO2 (CMAS) and ternary CaO-Al2O3-SiO2
(CAS) glasses. Comparison of the simulation results with select experimental
X-ray and neutron total scattering and literature data reveals that the
MD-generated structures have captured the key structural features of these CMAS
and CAS glasses. Based on the MD-generated structural representations, we have
developed two structural descriptors, specifically (i) average metal oxide
dissociation energy (AMODE) and (ii) average self-diffusion coefficient (ASDC)
of all the atoms at melting. Both structural descriptors are seen to more
accurately predict the relative glass reactivity than the commonly used degree
of depolymerization parameter, especially for the eight synthetic CAS glasses
that span a wide compositional range. Hence these descriptors hold great
promise for predicting CMAS and CAS glass reactivity in alkaline environments
from compositional information.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:35:20 GMT""}]","2021-02-02"
"2102.00119","Konpal Ali","Konpal Shaukat Ali, Ekram Hossain and Md. Jahangir Hossain","Partial Non-Orthogonal Multiple Access (NOMA) in Downlink Poisson
  Networks",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-orthogonal multiple access (NOMA) allows users sharing a resource-block
to efficiently reuse spectrum and improve cell sum rate $\mathcal{R}_{\rm tot}$
at the expense of increased interference. Orthogonal multiple access (OMA), on
the other hand, guarantees higher coverage. We introduce partial-NOMA in a
large two-user downlink network to provide both throughput and reliability. The
associated partial overlap controls interference while still offering spectrum
reuse. The nature of the partial overlap also allows us to employ
receive-filtering to further suppress interference. For signal decoding in our
partial-NOMA setup, we propose a new technique called flexible successive
interference cancellation (FSIC) decoding. We plot the rate region abstraction
and compare with OMA and NOMA. We formulate a problem to maximize
$\mathcal{R}_{\rm tot}$ constrained to a minimum throughput requirement for
each user and propose an algorithm to find a feasible resource allocation
efficiently. Our results show that partial-NOMA allows greater flexibility in
terms of performance. Partial-NOMA can also serve users that NOMA cannot. We
also show that with appropriate parameter selection and resource allocation,
partial-NOMA can outperform NOMA.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:36:16 GMT""}]","2021-02-02"
"2102.00120","Lourdes Bobbio","Lourdes D. Bobbio, Brandon Bocklund, Zi-Kui Liu, Allison M. Beese","Tensile behavior of stainless steel 304L to Ni-20Cr functionally graded
  material: experimental characterization and computational simulations","39 pages, 13 figures, 3 tables","Materialia 18 (2021) 101151","10.1016/j.mtla.2021.101151",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This study presents experimental and computational analyses of the phase
composition and mechanical behavior of a functionally graded material (FGM)
grading from 100 vol% 304L stainless steel (SS304L) to 100 vol% Ni-20Cr (NiCr)
in 10 vol% increments. The mechanical behavior of the FGM was evaluated by
extracting tensile specimens from SS304L-rich and NiCr-rich regions of the FGM,
with the former behaving in a ductile manner and the latter being relatively
brittle. The brittle response of the NiCr-rich sample was explained by the
presence of the eutectic FCC+BCC phase in this sample, as identified by
Scheil-Gulliver simulations along with experimental phase and composition
analyses. The spatially varying yield and flow behavior of the FGM was
determined through comparison of finite element analysis simulations with
experimentally measured stress-strain curves and surface strain contours. The
results highlight that the overall ductile behavior of SS304L and brittle
behavior of NiCr are preserved in the SS304L/NiCr FGM but the formation of the
brittle eutectic phase further reduced the ductility within the regions where
it formed (90 vol% NiCr/10 vol% SS304L).
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:37:16 GMT""}]","2021-08-12"
"2102.00121","Charikleia Iakovidou","Charikleia Iakovidou, Ermin Wei","S-NEAR-DGD: A Flexible Distributed Stochastic Gradient Method for
  Inexact Communication",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present and analyze a stochastic distributed method (S-NEAR-DGD) that can
tolerate inexact computation and inaccurate information exchange to alleviate
the problems of costly gradient evaluations and bandwidth-limited communication
in large-scale systems. Our method is based on a class of flexible, distributed
first order algorithms that allow for the trade-off of computation and
communication to best accommodate the application setting. We assume that all
the information exchange between nodes is subject to random distortion and that
only stochastic approximations of the true gradients are available. Our
theoretical results prove that the proposed algorithm converges linearly in
expectation to a neighborhood of the optimal solution for strongly convex
objective functions with Lipschitz gradients. We characterize the dependence of
this neighborhood on algorithm and network parameters, the quality of the
communication channel and the precision of the stochastic gradient
approximations used. Finally, we provide numerical results to evaluate the
empirical performance of our method.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 00:58:16 GMT""}]","2021-02-02"
"2102.00122","Fabio Eupen","GRAVITY Collaboration: F. Eupen (1), L. Labadie (1), R. Grellmann (1),
  K. Perraut (2), W. Brandner (3), G. Duch\^ene (4,2), R. K\""ohler (5), J.
  Sanchez-Bermudez (3,6), R. Garcia Lopez (3,7,8), A. Caratti o Garatti
  (3,7,8), M. Benisty (2,9), C. Dougados (2), P. Garcia (10,11), L. Klarmann
  (3), A. Amorim (10,16), M. Baub\""ock (13), J.P. Berger (2), P. Caselli (13),
  Y. Cl\'enet (12), V. Coud\'e du Foresto (12), P.T. de Zeeuw (13, 17), A.
  Drescher (13), G. Duvert (2), A. Eckart (1, 15), F. Eisenhauer (13), M. Filho
  (10, 11), V. Ganci (1), F. Gao (13), E. Gendron (12), R. Genzel (13), S.
  Gillessen (13), G. Heissel (12), Th. Henning (3), S. Hippler (3), M. Horrobin
  (1), Z. Hubert (2), A. Jim\'enez-Rosales (13), L. Jocou (2), P. Kervella
  (12), S. Lacour (12), V. Lapeyr\`ere (12), J.B. Le Bouquin (2), P. L\'ena
  (12), T. Ott (13), T. Paumard (12), G. Perrin (12), O. Pfuhl (14), G.
  Rodr\'iguez-Coira (12), G. Rousset (12), S. Scheithauer (3), J. Shangguan
  (13), T. Shimizu (13), J. Stadler (13), O. Straub (13), C. Straubmeier (2),
  E. Sturm (13), E. van Dishoeck (13, 17), F. Vincent (12), S.D. von Fellenberg
  (13), F. Widmann (13), J. Woillez (14), A. Wojtczak (1) ((1) I.
  Physikalisches Institut, Universit\""at zu K\""oln, (2) Univ. Grenoble Alpes,
  CNRS, IPAG, (3) Max Planck Institute for Astronomy, (4) Astronomy Department,
  University of California, (5) University of Vienna, Department of
  Astrophysics, (6) Instituto de Astronom\'ia, Universidad Nacional Aut\'onoma
  de M\'exico, (7) Dublin Institute for Advanced Studies, (8) School of
  Physics, University College Dublin, (9) Unidad Mixta Internacional
  Franco-Chilena de Astronom\'ia (CNRS UMI 3386), Departamento de Astronom\'ia,
  Universidad de Chile, (10) CENTRA, Centro de Astrof\'isica e
  Gravita\c{c}\~ao, Instituto Superior T\'ecnico, (11) Universidade do Porto,
  Faculdade de Engenharia, (12) LESIA, Observatoire de Paris, PSL Research
  University, CNRS, (13) Max Planck Institute for Extraterrestrial Physics,
  (14) European Southern Observatory, (15) Max-Planck-Institute for Radio
  Astronomy, (16) Universidade de Lisboa - Faculdade de Ci\^encias, (17)
  Sterrewacht Leiden, Leiden University)","The GRAVITY young stellar object survey V. The orbit of the T Tauri
  binary star WW Cha","Accepted for publication in A&A; 24 pages, 14 figures, 3 tables;
  affiliations corrected","A&A 648, A37 (2021)","10.1051/0004-6361/202039599",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The young T Tauri star WW Cha was recently proposed to be a close binary
object with strong infrared and submillimeter excess associated with
circum-system emission. This makes WW Cha a very interesting source for
studying the influence of dynamical effects on circumstellar as well as
circumbinary material. We derive the relative astrometric positions and flux
ratios of the stellar companion in WW Cha from the interferometric model
fitting of observations made with the VLTI instruments AMBER, PIONIER, and
GRAVITY in the near-infrared from 2011 to 2020. For two epochs, the resulting
uv-coverage in spatial frequencies permits us to perform the first image
reconstruction of the system in the K band. The positions of nine epochs are
used to determine the orbital elements and the total mass of the system. We
find the secondary star orbiting the primary with a period of T=206.55 days, a
semimajor axis of a=1.01 au, and a relatively high eccentricity of e=0.45.
Combining the orbital solution with distance measurements from Gaia DR2 and the
analysis of evolutionary tracks, the dynamical mass of Mtot=3.20 Msol can be
explained by a mass ratio between ~0.5 and 1. The orbital angular momentum
vector is in close alignment with the angular momentum vector of the outer disk
as measured by ALMA and SPHERE. The analysis of the relative photometry
suggests the presence of infrared excess surviving in the system and likely
originating from truncated circumstellar disks. The flux ratio between the two
components appears variable, in particular in the K band, and may hint at
periods of triggered higher and lower accretion or changes in the disks'
structures. The knowledge of the orbital parameters, combined with a relatively
short period, makes WW Cha an ideal target for studying the interaction of a
close young T Tauri binary with its surrounding material, such as
time-dependent accretion phenomena.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:04:42 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 10:14:08 GMT""}]","2021-04-14"
"2102.00123","Sergei Urazhdin","Sergei Ivanov and Sergei Urazhdin","Nearly ideal memristive functionality based on viscous magnetization
  dynamics","5 pages, 4 figures",,"10.1063/5.0092641",,"cond-mat.mtrl-sci cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally demonstrate a proof-of-principle implementation of an
almost ideal memristor - a two-terminal circuit element whose resistance is
approximately proportional to the integral of the input signal over time. The
demonstrated device is based on a thin-film ferromagnet/antiferromagnet
bilayer, where magnetic frustration results in viscous magnetization dynamics
enabling memristive functionality, while the external magnetic field plays the
role of the driving input. The demonstrated memristor concept is amenable to
downscaling and can be adapted for electronic driving, making it attractive for
applications in neuromorphic circuits.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:22:57 GMT""}]","2022-07-06"
"2102.00124","Beatriz Elizaga Navascu\'es","Beatriz Elizaga Navascu\'es and Guillermo A. Mena Marug\'an","Quantization ambiguities and the robustness of effective descriptions of
  primordial perturbations in hybrid Loop Quantum Cosmology","13 pages","Class. Quantum Grav. 39, 015017 (2021)","10.1088/1361-6382/ac3b9b",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the imprint that certain quantization ambiguities may leave in
effective regimes of the hybrid loop quantum description of cosmological
perturbations. More specifically, in the case of scalar perturbations we
investigate how to reconstruct the Mukhanov-Sasaki field in the effective
regime of Loop Quantum Cosmology, taking as starting point for the quantization
a canonical formulation in terms of other perturbative gauge invariants that
possess different dynamics. This formulation of the quantum theory, in terms of
variables other than the Mukhanov-Sasaki ones, is crucial to arrive at a
quantum Hamiltonian with a good behavior, elluding the problems with ill
defined Hamiltonian operators typical of quantum field theories. In the
reconstruction of the Mukhanov-Sasaki field, we ask that the effective
Mukhanov-Sasaki equations adopt a similar form and display the same Hamiltonian
structure as the classical ones, a property that has been widely assumed in
Loop Quantum Cosmology studies over the last decade. This condition actually
restricts the freedom inherent to certain quantization ambiguities. Once these
ambiguities are removed, the reconstruction of the Mukhanov-Sasaki field
naturally identifies a set of positive-frequency solutions to the effective
equations, and hence a choice of initial conditions for the perturbations. Our
analysis constitutes an important and necessary test of the robustness of
standard effective descriptions in Loop Quantum Cosmology, along with their
observational predictions on the primordial power spectrum, taking into account
that they should be the consequence of a more fundamental quantum theory with a
well-defined Hamiltonian, in the spirit of Dirac's long-standing ideas.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:23:08 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 02:24:40 GMT""},{""version"":""v3"",""created"":""Sun, 26 Dec 2021 16:43:59 GMT""}]","2021-12-28"
"2102.00125","Fritz Gesztesy","Fritz Gesztesy, Roger Nichols, Jonathan Stanfill","A survey of some norm inequalities","28 pages, some updates added","Complex Analysis and Operator Theory 15, No. 23 (2021)","10.1007/s11785-020-01060-9",,"math.FA math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We survey some classical norm inequalities of Hardy, Kallman, Kato,
Kolmogorov, Landau, Littlewood, and Rota of the type \[ \|A f\|_{\mathcal{X}}^2
\leq C \|f\|_{\mathcal{X}} \big\|A^2 f\big\|_{\mathcal{X}}, \quad f \in
dom\big(A^2\big), \] and recall that under exceedingly stronger hypotheses on
the operator $A$ and/or the Banach space $\mathcal{X}$, the optimal constant
$C$ in these inequalities diminishes from $4$ (e.g., when $A$ is the generator
of a $C_0$ contraction semigroup on a Banach space $\mathcal{X}$) all the way
down to $1$ (e.g., when $A$ is a symmetric operator on a Hilbert space
$\mathcal{H}$).
  We also survey some results in connection with an extension of the
Hardy-Littlewood inequality involving quadratic forms as initiated by Everitt.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:35:04 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 23:19:43 GMT""}]","2021-03-09"
"2102.00126","Mladen Pavicic","Mladen Pavicic","How Secure Are Two-Way Ping-Pong and LM05 QKD Protocols under a
  Man-in-the-Middle Attack?","8 pages, 2 figures","Entropy 2021, 23(2), 163","10.3390/e23020163",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a man-in-the-middle attack on two-way quantum key distribution
ping-pong and LM05 protocols in which an eavesdropper copies all messages in
the message mode, while being undetectable in the mode. Under the attack there
is therefore no disturbance in the message mode and the mutual information
between the sender and the receiver is always constant and equal to one and
messages copied by the eavesdropper are always genuine. An attack can only be
detected in the control mode but the level of detection at which the protocol
should be aborted is not defined. We examine steps of the protocol to evaluate
its security and find that the protocol should be redesigned. We also compare
it with the security of a one-way asymmetric BB84-like protocol in which one
basis serves as the message mode and the other as the control mode but which
does have the level of detection at which the protocol should be aborted
defined.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:43:40 GMT""}]","2021-02-02"
"2102.00127","Maruan Al-Shedivat","Maruan Al-Shedivat, Liam Li, Eric Xing, Ameet Talwalkar","On Data Efficiency of Meta-learning","Preliminary version. An updated version is to appear in AISTATS 2021",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Meta-learning has enabled learning statistical models that can be quickly
adapted to new prediction tasks. Motivated by use-cases in personalized
federated learning, we study the often overlooked aspect of the modern
meta-learning algorithms -- their data efficiency. To shed more light on which
methods are more efficient, we use techniques from algorithmic stability to
derive bounds on the transfer risk that have important practical implications,
indicating how much supervision is needed and how it must be allocated for each
method to attain the desired level of generalization. Further, we introduce a
new simple framework for evaluating meta-learning methods under a limit on the
available supervision, conduct an empirical study of MAML, Reptile, and
Protonets, and demonstrate the differences in the behavior of these methods on
few-shot and federated learning benchmarks. Finally, we propose active
meta-learning, which incorporates active data selection into learning-to-learn,
leading to better performance of all methods in the limited supervision regime.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:44:12 GMT""}]","2021-02-02"
"2102.00128","Nil-Jana Akpinar","Nil-Jana Akpinar, Maria De-Arteaga, Alexandra Chouldechova","The effect of differential victim crime reporting on predictive policing
  systems","Conference on Fairness, Accountability, and Transparency (FAccT 2021)",,"10.1145/3442188.3445877",,"cs.CY stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Police departments around the world have been experimenting with forms of
place-based data-driven proactive policing for over two decades. Modern
incarnations of such systems are commonly known as hot spot predictive
policing. These systems predict where future crime is likely to concentrate
such that police can allocate patrols to these areas and deter crime before it
occurs. Previous research on fairness in predictive policing has concentrated
on the feedback loops which occur when models are trained on discovered crime
data, but has limited implications for models trained on victim crime reporting
data. We demonstrate how differential victim crime reporting rates across
geographical areas can lead to outcome disparities in common crime hot spot
prediction models. Our analysis is based on a simulation patterned after
district-level victimization and crime reporting survey data for Bogot\'a,
Colombia. Our results suggest that differential crime reporting rates can lead
to a displacement of predicted hotspots from high crime but low reporting areas
to high or medium crime and high reporting areas. This may lead to
misallocations both in the form of over-policing and under-policing.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 01:57:22 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 22:52:55 GMT""}]","2021-02-08"
"2102.00129","Jingmin Xia","Jingmin Xia, Scott MacLachlan, Timothy J. Atherton, Patrick E. Farrell","Structural Landscapes in Geometrically Frustrated Smectics",,"Phys. Rev. Lett. 126, 177801 (2021)","10.1103/PhysRevLett.126.177801",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A phenomenological free energy model is proposed to describe the behavior of
smectic liquid crystals, an intermediate phase that exhibits orientational
order and layering at the molecular scale. Advantageous properties render the
functional amenable to numerical simulation. The model is applied to a number
of scenarios involving geometric frustration, leading to emergent structures
such as focal conic domains and oily streaks and enabling detailed elucidation
of the very rich energy landscapes that arise in these problems.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:07:27 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 07:29:51 GMT""},{""version"":""v3"",""created"":""Fri, 2 Apr 2021 02:02:11 GMT""}]","2021-05-05"
"2102.00130","Bongjae Kim","Bongjae Kim","Real-space charge distribution of the cobalt ion and its relation with
  charge and spin states",,,"10.1007/s40042-021-00066-6",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The charge state of an ion provides a simplified electronic picture of the
bonding in compounds, and heuristically explains the basic electronic structure
of a system. Despite its usefulness, the physical and chemical definition of a
charge state is not a trivial one, and the essential idea of electron transfer
is found to be not a realistic explanation. Here, we study the real-space
charge distribution of a cobalt ion in its various charge and spin states, and
examine the relation between the formal charge/spin states and the static
charge distribution. Taking the prototypical cobalt oxides, La/SrCoO$_3$, and
bulk Co metal, we confirm that no prominent static charge transfer exists for
different charge states. However, we show that small variations exist in the
integrated charges for different charge states, and these are compared to the
various spin state cases.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:15:30 GMT""}]","2021-02-02"
"2102.00131","Sihao Zhao","Ningyan Guo, Sihao Zhao, Xiao-Ping Zhang, Zheng Yao, Xiaowei Cui,
  Mingquan Lu","New Closed-form Joint Localization and Synchronization using Sequential
  One-way TOAs",,,"10.1109/TSP.2022.3168363",,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It is an essential technique for the moving user nodes (UNs) with clock
offset and clock skew to resolve the joint localization and synchronization
(JLAS) problem. Existing iterative maximum likelihood methods using sequential
one-way time-of-arrival (TOA) measurements from the anchor nodes' (AN)
broadcast signals require a good initial guess and have a computational
complexity that grows with the number of iterations, given the size of the
problem. In this paper, we propose a new closed-form JLAS approach, namely
CFJLAS, which achieves the asymptotically optimal solution in one shot without
initialization when the noise is small, and has a low computational complexity.
After squaring and differencing the sequential TOA measurement equations, we
devise two intermediate variables to reparameterize the non-linear problem. In
this way, we convert the problem to a simpler one of solving two simultaneous
quadratic equations. We then solve the equations analytically to obtain a raw
closed-form JLAS estimation. Finally, we apply a weighted least squares (WLS)
step to optimize the estimation. We derive the Cramer-Rao lower bound (CRLB),
analyze the estimation error, and show that the estimation accuracy of the
CFJLAS reaches the CRLB under the small noise condition. The complexity of the
new CFJLAS is only determined by the size of the problem, unlike the
conventional iterative method, whose complexity is additionally multiplied by
the number of iterations. Simulations in a 2D scene verify that the estimation
accuracies of the new CFJLAS method in position, velocity, clock offset, and
clock skew all reach the CRLB under the small noise condition. Compared with
the conventional iterative method, the proposed new CFJLAS method does not
require initialization, obtains the optimal solution under the small noise
condition, and has a low computational complexity.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:18:11 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 01:53:14 GMT""},{""version"":""v3"",""created"":""Fri, 15 Apr 2022 02:50:50 GMT""}]","2022-05-25"
"2102.00132","Cristian A. Vega-Mart\'inez","Cristian A. Vega-Mart\'inez, Facundo A. G\'omez, Sof\'ia A. Cora and
  Tom\'as Hough","A new analytic ram pressure profile for satellite galaxies","15 pages, 8 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stab2908",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new analytic fitting profile to model the ram pressure exerted
over satellite galaxies on different environments and epochs. The profile is
built using the information of the gas particle distribution in hydrodynamical
simulations of groups and clusters of galaxies to measure the ram pressure
directly. We show that predictions obtained by a previously introduced
$\beta$-profile model can not consistently reproduce the dependence of the ram
pressure on halocentric distance and redshift for a given halo mass. It
features a systematic underestimation of the predicted ram pressure at high
redshifts ($z > 1.5$), which increases towards the central regions of the
haloes and it is independent of halo mass, reaching differences larger than two
decades for satellites at $r<0.4R_\mathrm{vir}$. This behaviour reverses as
redshift decreases, featuring an increasing over-estimation with halocentric
distance at $z=0$. As an alternative, we introduce a new universal analytic
model for the profiles which can recover the ram pressure dependence on halo
mass, halocentric distance and redshift. We analyse the impact of our new
profile on galaxy properties by applying a semi-analytic model of galaxy
formation and evolution on top of the simulations. We show that galaxies
experiencing large amounts of cumulative ram pressure stripping typically have
low stellar masses ($M_\star \leq 10^{9.5} \text{M}_\odot$). Besides, their
specific star formation histories depend on the ram pressure modelling applied,
particularly at high redshifts ($z > 1.5$).
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:25:23 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 18:11:53 GMT""}]","2021-10-12"
"2102.00133","Ryo Nagata","Ryo Nagata, Toshiya Namikawa","A numerical study of observational systematic errors in lensing analysis
  of CMB polarization",,"Prog. Theor. Exp. Phys. 2021, 053E01","10.1093/ptep/ptab040",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Impacts of observational systematic errors on the lensing analysis of the
cosmic microwave background (CMB) polarization are investigated by numerical
simulations. We model errors of gain, angle, and pointing in observation of the
CMB polarization and simulate polarization fields modulated by the errors. We
discuss the response of systematics-induced $B$-modes to amplitude and spatial
scale of the imposed errors and show that the results of the lensing
reconstruction and delensing analysis behave according to it. It is observed
that error levels expected in the near future lead to no significant
degradation in delensing efficiency.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:27:08 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 07:55:54 GMT""}]","2021-06-10"
"2102.00134","Donald Stull","D. M. Stull","The Dimension Spectrum Conjecture for Planar Lines",,,,,"cs.CC math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $L_{a,b}$ be a line in the Euclidean plane with slope $a$ and intercept
$b$. The dimension spectrum $\spec(L_{a,b})$ is the set of all effective
dimensions of individual points on $L_{a,b}$. The dimension spectrum conjecture
states that, for every line $L_{a,b}$, the spectrum of $L_{a,b}$ contains a
unit interval.
  In this paper we prove that the dimension spectrum conjecture is true. Let
$(a,b)$ be a slope-intercept pair, and let $d = \min\{\dim(a,b), 1\}$. For
every $s \in (0, 1)$, we construct a point $x$ such that $\dim(x, ax + b) = d +
s$. Thus, we show that $\spec(L_{a,b})$ contains the interval $(d, 1+ d)$.
Results of Turetsky , and Lutz and Stull, show that $\spec(L_{a,b})$ contain
the endpoints $d$ and $1+d$. Taken together, $[d, 1 + d] \subseteq
\spec(L_{a,b})$, for every planar line $L_{a,b}$.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:30:07 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 04:01:30 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 18:13:32 GMT""}]","2021-11-08"
"2102.00135","Guanghui Lan","Guanghui Lan","Policy Mirror Descent for Reinforcement Learning: Linear Convergence,
  New Sampling Complexity, and Generalized Problem Classes",,,,,"cs.LG cs.AI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new policy mirror descent (PMD) methods for solving reinforcement
learning (RL) problems with either strongly convex or general convex
regularizers. By exploring the structural properties of these overall highly
nonconvex problems we show that the PMD methods exhibit fast linear rate of
convergence to the global optimality. We develop stochastic counterparts of
these methods, and establish an ${\cal O}(1/\epsilon)$ (resp., ${\cal
O}(1/\epsilon^2)$) sampling complexity for solving these RL problems with
strongly (resp., general) convex regularizers using different sampling schemes,
where $\epsilon$ denote the target accuracy. We further show that the
complexity for computing the gradients of these regularizers, if necessary, can
be bounded by ${\cal O}\{(\log_\gamma \epsilon) [(1-\gamma)L/\mu]^{1/2}\log
(1/\epsilon)\}$ (resp., ${\cal O} \{(\log_\gamma \epsilon )
(L/\epsilon)^{1/2}\}$)for problems with strongly (resp., general) convex
regularizers. Here $\gamma$ denotes the discounting factor. To the best of our
knowledge, these complexity bounds, along with our algorithmic developments,
appear to be new in both optimization and RL literature. The introduction of
these convex regularizers also greatly expands the flexibility and
applicability of RL models.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:30:45 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 01:59:41 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 18:03:56 GMT""},{""version"":""v4"",""created"":""Thu, 25 Feb 2021 14:11:23 GMT""},{""version"":""v5"",""created"":""Thu, 6 May 2021 20:11:08 GMT""},{""version"":""v6"",""created"":""Wed, 6 Apr 2022 19:01:01 GMT""}]","2022-04-08"
"2102.00136","Yoshiyuki Ninomiya","Daeju Kim, Shuichi Kawano, Yoshiyuki Ninomiya","Smoothly varying ridge regularization","21 pages, 6 figures, 3 tables",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  A basis expansion with regularization methods is much appealing to the
flexible or robust nonlinear regression models for data with complex
structures. When the underlying function has inhomogeneous smoothness, it is
well known that conventional reguralization methods do not perform well. In
this case, an adaptive procedure such as a free-knot spline or a local
likelihood method is often introduced as an effective method. However, both
methods need intensive computational loads. In this study, we consider a new
efficient basis expansion by proposing a smoothly varying regularization method
which is constructed by some special penalties. We call them adaptive-type
penalties. In our modeling, adaptive-type penalties play key rolls and it has
been successful in giving good estimation for inhomogeneous smoothness
functions. A crucial issue in the modeling process is the choice of a suitable
model among candidates. To select the suitable model, we derive an approximated
generalized information criterion (GIC). The proposed method is investigated
through Monte Carlo simulations and real data analysis. Numerical results
suggest that our method performs well in various situations.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 02:58:13 GMT""}]","2021-02-02"
"2102.00137","Yahia Djemmada","Hac\`ene Belbachir, Yahia Djemmada, Slimane Hadj-Brahim","Unified Bernoulli-Euler polynomials of Apostol type",,,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  The object of this paper is to introduce and study properties of unified
Apostol-Bernoulli and Apostol-Euler polynomials noted by
$\left\{\mathfrak{V_{n}}(x;\lambda;\mu)\right\}_{n \geq 0}$. We study some
arithmetic properties of $\left\{\mathfrak{V_{n}}(x;\lambda;\mu)\right\}_{n
\geq 0}$ as their connection to Apostol-Euler polynomials and Apostol-Bernoulli
polynomials. Also, we give derivation and integration representations of
$\left\{\mathfrak{V_{n}}(x;\lambda;\mu)\right\}_{n \geq 0}$. Finally, we use
the umbral calculus approach to deduce symmetric identities.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:06:43 GMT""}]","2021-02-02"
"2102.00138","Toshiyuki Sugawa","Bo-Yong Long, Toshiyuki Sugawa and Qi-Han Wang","Completely monotone sequences and harmonic mappings","15 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we will study geometric properties of harmonic mappings
whose analytic and co-analytic parts are (shifted) generated functions of
completely monotone sequences.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:12:44 GMT""}]","2021-02-02"
"2102.00139","Yahia Djemmada","Hac\'ene Belbachir, Yahia Djemmada, L\'aszl\'o N\'emeth","The deranged Bell numbers",,,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the ordered Bell numbers count all the ordered partitions of
the set $[n]=\{1,2,\dots,n\}$. In this paper, we introduce the deranged Bell
numbers that count the total number of deranged partitions of $[n]$. We first
study the classical properties of these numbers (generating function, explicit
formula, convolutions, etc.), we then present an asymptotic behavior of the
deranged Bell numbers. Finally, we give some brief results for their
$r$-versions.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:22:17 GMT""}]","2021-02-02"
"2102.00140","Bryan Quaife","Bryan Quaife and Ashley Gannon and Y.-N. Young","Hydrodynamics of a Semipermeable Vesicle Under Flow and Confinement",,"Phys. Rev. Fluids 6, 073601 (2021)","10.1103/PhysRevFluids.6.073601",,"cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lipid bilayer membranes have a native (albeit small) permeability for water
molecules. Under an external load, provided that the bilayer structure stays
intact and does not suffer from poration or rupture, a lipid membrane deforms
and its water influx/efflux is often assumed negligible in the absence of
osmolarity. In this work we use boundary integral simulations to investigate
the effects of water permeability on the vesicle hydrodynamics due to a
mechanical load, such as the viscous stress from an external flow deforming a
vesicle membrane in free space or pushing it through a confinement.
Incorporating the membrane permeability into the framework of Helfrich free
energy for an inextensible, elastic membrane as a model for a semipermeable
vesicle, we illustrate that, in the absence of an osmotic stress gradient, the
semipermeable vesicle is affected by water influx/efflux over a sufficiently
long time or under a strong confinement. Our simulations quantify the
conditions for water permeation to be negligible in terms of the time scales,
flow strength, and confinement. These results shed light on how microfluidic
confinement can be utilized to estimate membrane permeability.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:24:36 GMT""}]","2021-07-14"
"2102.00141","Abhisek Dash","Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh
  Mukherjee, Krishna P. Gummadi","When the Umpire is also a Player: Bias in Private Label Product
  Recommendations on E-commerce Marketplaces","This work has been accepted for presentation at the ACM Conference on
  Fairness, Accountability, and Transparency 2021 (ACM FAccT 2021)",,,,"cs.CY cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Algorithmic recommendations mediate interactions between millions of
customers and products (in turn, their producers and sellers) on large
e-commerce marketplaces like Amazon. In recent years, the producers and sellers
have raised concerns about the fairness of black-box recommendation algorithms
deployed on these marketplaces. Many complaints are centered around
marketplaces biasing the algorithms to preferentially favor their own `private
label' products over competitors. These concerns are exacerbated as
marketplaces increasingly de-emphasize or replace `organic' recommendations
with ad-driven `sponsored' recommendations, which include their own private
labels. While these concerns have been covered in popular press and have
spawned regulatory investigations, to our knowledge, there has not been any
public audit of these marketplace algorithms. In this study, we bridge this gap
by performing an end-to-end systematic audit of related item recommendations on
Amazon. We propose a network-centric framework to quantify and compare the
biases across organic and sponsored related item recommendations. Along a
number of our proposed bias measures, we find that the sponsored
recommendations are significantly more biased toward Amazon private label
products compared to organic recommendations. While our findings are primarily
interesting to producers and sellers on Amazon, our proposed bias measures are
generally useful for measuring link formation bias in any social or content
networks.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:24:38 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 04:24:33 GMT""}]","2021-02-03"
"2102.00142","Ivan Bajic","Ivan V. Baji\'c","Latent-Space Inpainting for Packet Loss Concealment in Collaborative
  Object Detection","Extended version of the paper ""Latent Space Inpainting for
  Loss-Resilient Collaborative Object Detection,"" to be presented at the IEEE
  International Conference on Communications (ICC), Montreal, Canada, June
  14-23, 2021",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  Edge devices, such as cameras and mobile units, are increasingly capable of
performing sophisticated computation in addition to their traditional roles in
sensing and communicating signals. The focus of this paper is on collaborative
object detection, where deep features computed on the edge device from input
images are transmitted to the cloud for further processing. We consider the
impact of packet loss on the transmitted features and examine several ways for
recovering the missing data. In particular, through theory and experiments, we
show that methods for image inpainting based on partial differential equations
work well for the recovery of missing features in the latent space. The
obtained results represent the new state of the art for missing data recovery
in collaborative object detection.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:32:19 GMT""}]","2021-02-02"
"2102.00143","Ricky Li","Ricky Li","Dynamic Random Choice","26 pages",,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  I study dynamic random utility with finite choice sets and exogenous total
menu variation, which I refer to as stochastic utility (SU). First, I
characterize SU when each choice set has three elements. Next, I prove several
mathematical identities for joint, marginal, and conditional Block--Marschak
sums, which I use to obtain two characterizations of SU when each choice set
but the last has three elements. As a corollary under the same cardinality
restrictions, I sharpen an axiom to obtain a characterization of SU with full
support over preference tuples. I conclude by characterizing SU without
cardinality restrictions. All of my results hold over an arbitrary finite
discrete time horizon.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:32:56 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 20:11:28 GMT""}]","2022-06-22"
"2102.00144","S. I. Matveenko","S. I. Matveenko, S. I. Mukhin","Pair density wave solution for self-consistent model","10 pages, 2 figures",,,,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the t-U-V Hubbard model on the square lattice we found self-consistent
analytic solution for the ground state with coexisting d-wave symmetric bond
ordered pair density wave (PDW) and spin (SDW) or charge (CDW) density waves,
as observed in some high-temperature superconductors. In particular, the
solution gives the same periodicity for CDW and PDW, and a pseudogap in the
fermi-excitation spectrum.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:41:15 GMT""}]","2021-02-02"
"2102.00145","Shahram Mollahasani","Shahram Mollahasani, Melike Erol-Kantarci, Mahdi Hirab, Hoda Dehghan,
  Rodney Wilson","Actor-Critic Learning Based QoS-Aware Scheduler for Reconfigurable
  Wireless Networks",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  The flexibility offered by reconfigurable wireless networks, provide new
opportunities for various applications such as online AR/VR gaming,
high-quality video streaming and autonomous vehicles, that desire
high-bandwidth, reliable and low-latency communications. These applications
come with very stringent Quality of Service (QoS) requirements and increase the
burden over mobile networks. Currently, there is a huge spectrum scarcity due
to the massive data explosion and this problem can be solved by helps of
Reconfigurable Wireless Networks (RWNs) where nodes have reconfiguration and
perception capabilities. Therefore, a necessity of AI-assisted algorithms for
resource block allocation is observed. To tackle this challenge, in this paper,
we propose an actor-critic learning-based scheduler for allocating resource
blocks in a RWN. Various traffic types with different QoS levels are assigned
to our agents to provide more realistic results. We also include mobility in
our simulations to increase the dynamicity of networks. The proposed model is
compared with another actor-critic model and with other traditional schedulers;
proportional fair (PF) and Channel and QoS Aware (CQA) techniques. The proposed
models are evaluated by considering the delay experienced by user equipment
(UEs), successful transmissions and head-of-the-line delays. The results show
that the proposed model noticeably outperforms other techniques in different
aspects.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:46:00 GMT""}]","2021-02-02"
"2102.00146","Roel Van Beeumen","Roel Van Beeumen, Lana Peri\v{s}a, Daniel Kressner, Chao Yang","A Flexible Power Method for Solving Infinite Dimensional Tensor
  Eigenvalue Problems","33 pages, 7 figures, 2 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a flexible power method for computing the leftmost, i.e.,
algebraically smallest, eigenvalue of an infinite dimensional tensor eigenvalue
problem, $H x = \lambda x$, where the infinite dimensional symmetric matrix $H$
exhibits a translational invariant structure. We assume the smallest eigenvalue
of $H$ is simple and apply a power iteration of $e^{-H}$ with the eigenvector
represented in a compact way as a translational invariant infinite Tensor Ring
(iTR). Hence, the infinite dimensional eigenvector can be represented by a
finite number of iTR cores of finite rank. In order to implement this power
iteration, we use a small parameter $t$ so that the infinite matrix-vector
operation $e^{-Ht}x$ can efficiently be approximated by the Lie product
formula, also known as Suzuki--Trotter splitting, and we employ a low rank
approximation through a truncated singular value decomposition on the iTR cores
in order to keep the cost of subsequent power iterations bounded. We also use
an efficient way for computing the iTR Rayleigh quotient and introduce a finite
size iTR residual which is used to monitor the convergence of the Rayleigh
quotient and to modify the timestep $t$. In this paper, we discuss 2 different
implementations of the flexible power algorithm and illustrate the automatic
timestep adaption approach for several numerical examples.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 03:50:15 GMT""}]","2021-02-02"
"2102.00147","Mingliang Xiong","Mingliang Xiong, Mingqing Liu, Qingwei Jiang, Jie Zhou, Qingwen Liu,
  Hao Deng","Retro-Reflective Beam Communications with Spatially Separated Laser
  Resonator",,,"10.1109/TWC.2021.3062945",,"eess.SY cs.SY physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical wireless communications (OWC) utilizing infrared or visible light as
the carrier attracts great attention in 6G research. Resonant beam
communications (RBCom) is an OWC technology which simultaneously satisfies the
needs of non-mechanical mobility and high signal-to-noise ratio~(SNR). It has
the self-alignment feature and therefore avoids positioning and pointing
operations. However, RBCom undergoes echo interference. Here we propose an
echo-interference-free RBCom system design based on second harmonic generation.
The transmitter and the receiver constitute a spatially separated laser
resonator, in which the retro-reflective resonant beam is formed and tracks the
receiver automatically. This structure provides the channel with adaptive
capability in beamforming and alignment, which is similar to the concept of
intelligent reflecting surface (IRS) enhanced communications, but without
hardware and software controllers. Besides, we establish an analytical model to
evaluate the beam radius, the beam power, and the channel capacity. The results
show that our system achieves longer distance and smaller beam diameter for the
transmission beyond 10 Gbit/s, compared with the existing OWC technologies.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 04:19:15 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 08:54:00 GMT""}]","2021-06-28"
"2102.00148","Zhen Zhang","Zhen Zhang, Renata M. Wentzcovitch","\textit{Ab initio} lattice thermal conductivity of MgSiO$_3$ across
  perovskite-postperovskite phase transition",,"Phys. Rev. B 103, 144103 (2021)","10.1103/PhysRevB.103.144103",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lattice thermal conductivity ($\kappa_{lat}$) of MgSiO$_3$ postperovskite
(MgPPv) under the Earth's lower mantle high pressure-temperature conditions is
studied using the phonon quasiparticle approach by combing \textit{ab initio}
molecular dynamics and lattice dynamics simulations. Phonon lifetimes are
extracted from the phonon quasiparticle calculations, and the phonon group
velocities are computed from the anharmonic phonon dispersions, which in
principle capture full anharmonicity. It is found that throughout the lowermost
mantle, including the D"" region, $\kappa_{lat}$ of MgPPv is ~25% larger than
that of MgSiO$_3$ perovskite (MgPv), mainly due to MgPPv's higher phonon
velocities. Such a difference in phonon velocities between the two phases
originates in the MgPPv's relatively smaller primitive cell. Systematic results
of temperature and pressure dependences of both MgPPv's and MgPv's
$\kappa_{lat}$ are demonstrated.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 04:33:56 GMT""}]","2021-04-21"
"2102.00149","Christopher Crawford","C. B. Crawford and Joseph P. Straley","Improved prescription for winding an electromagnet","4 pages, 2 figures",,"10.1063/5.0063057",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe an improvement on the magnetic scalar potential approach to the
design of an electromagnet, which incorporates the need to wind the coil as a
helix. Any magnetic field that can be described by a magnetic scalar potential
is produced with high fidelity within a Target region; all fields are confined
within a larger Return. The helical winding only affects the field in the
Return.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 04:42:11 GMT""}]","2022-01-12"
"2102.00150","Haruya Sakashita","Haruya Sakashita, Christoph Flothow, Noriko Takemura, Yusuke Sugano","DRIV100: In-The-Wild Multi-Domain Dataset and Evaluation for Real-World
  Domain Adaptation of Semantic Segmentation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Together with the recent advances in semantic segmentation, many domain
adaptation methods have been proposed to overcome the domain gap between
training and deployment environments. However, most previous studies use
limited combinations of source/target datasets, and domain adaptation
techniques have never been thoroughly evaluated in a more challenging and
diverse set of target domains. This work presents a new multi-domain dataset
DRIV100 for benchmarking domain adaptation techniques on in-the-wild road-scene
videos collected from the Internet. The dataset consists of pixel-level
annotations for 100 videos selected to cover diverse scenes/domains based on
two criteria; human subjective judgment and an anomaly score judged using an
existing road-scene dataset. We provide multiple manually labeled ground-truth
frames for each video, enabling a thorough evaluation of video-level domain
adaptation where each video independently serves as the target domain. Using
the dataset, we quantify domain adaptation performances of state-of-the-art
methods and clarify the potential and novel challenges of domain adaptation
techniques. The dataset is available at https://doi.org/10.5281/zenodo.4389243.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 04:43:22 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 05:19:42 GMT""}]","2021-02-26"
"2102.00151","Paarth Neekhara","Paarth Neekhara, Shehzeen Hussain, Shlomo Dubnov, Farinaz Koushanfar,
  Julian McAuley","Expressive Neural Voice Cloning","12 pages, 2 figures, 2 tables",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Voice cloning is the task of learning to synthesize the voice of an unseen
speaker from a few samples. While current voice cloning methods achieve
promising results in Text-to-Speech (TTS) synthesis for a new voice, these
approaches lack the ability to control the expressiveness of synthesized audio.
In this work, we propose a controllable voice cloning method that allows
fine-grained control over various style aspects of the synthesized speech for
an unseen speaker. We achieve this by explicitly conditioning the speech
synthesis model on a speaker encoding, pitch contour and latent style tokens
during training. Through both quantitative and qualitative evaluations, we show
that our framework can be used for various expressive voice cloning tasks using
only a few transcribed or untranscribed speech samples for a new speaker. These
cloning tasks include style transfer from a reference speech, synthesizing
speech directly from text, and fine-grained style control by manipulating the
style conditioning variables during inference.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:09:57 GMT""}]","2021-02-02"
"2102.00152","Matthew Kovach","Matthew Kovach","Conservative Updating",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a behavioral analysis of conservatism in beliefs. I
introduce a new axiom, Dynamic Conservatism, that relaxes Dynamic Consistency
when information and prior beliefs ""conflict."" When the agent is a subjective
expected utility maximizer, Dynamic Conservatism implies that conditional
beliefs are a convex combination of the prior and the Bayesian posterior.
Conservatism may result in belief dynamics consistent with confirmation bias,
representativeness, and the good news-bad news effect, suggesting a deeper
behavioral connection between these biases. An index of conservatism and a
notion of comparative conservatism are characterized. Finally, I extend
conservatism to the case of an agent with incomplete preferences that admit a
multiple priors representation.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:13:23 GMT""}]","2021-02-02"
"2102.00153","Kazuo Makishima","Kazuo Makishima, Teruaki Enoto, Hiroki Yoneda, and Hirokazu Odaka","A NuSTAR confirmation of the 36 ks hard X-ray pulse-phase modulation in
  the magnetar 1E 1547.0$-$5408","Accepted for publication in MNRAS; 20 pages, 19 figures, and 2 tables","2021MNRAS.tmp..198M","10.1093/mnras/stab149",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper describes an analysis of the NuSTAR data of the fastest-rotating
magnetar 1E 1547$-$5408, acquired in 2016 April for a time lapse of 151 ks. The
source was detected with a 1-60 keV flux of $1.7 \times 10^{-11}$ ergs s$^{-1}$
cm$^{-2}$, and its pulsation at a period of $2.086710(5)$ sec. In 8-25 keV, the
pulses were phase-modulated with a period of $T=36.0 \pm 2.3$ ks, and an
amplitude of $\sim 0.2$ sec. This reconfirms the Suzaku discovery of the same
effect at $T=36.0 ^{+4.5}_{-2.5} $ ks, made in the 2009 outburst. These results
strengthen the view derived from the Suzaku data, that this magnetar performs
free precession as a result of its axial deformation by $\sim 0.6 \times
10^{-4}$, possibly caused by internal toroidal magnetic fields reaching $\sim
10^{16}$ G. Like in the Suzaku case, the modulation was not detected in
energies below $\sim 8$ keV. Above 10 keV, the pulse-phase behaviour, including
the 36 ks modulation parameters, exhibited complex energy dependences: at $\sim
22$ keV, the modulation amplitude increased to $\sim 0.5$ sec, and the
modulation phase changed by $\sim 65^\circ$ over 10--27 keV, followed by a
phase reversal. Although the pulse significance and pulsed fraction were
originally very low in $>10$ keV, they both increased noticeably, when the
arrival times of individual photons were corrected for these systematic
pulse-phase variations. Possible origins of these complex phenomena are
discussed, in terms of several physical processes that are specific to
ultra-strong magnetic fields.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:21:05 GMT""}]","2021-02-17"
"2102.00154","Xiaofei Li","Xiaofei Li","Semi-supervised Sound Event Detection using Random Augmentation and
  Consistency Regularization",,,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Sound event detection is a core module for acoustic environmental analysis.
Semi-supervised learning technique allows to largely scale up the dataset
without increasing the annotation budget, and recently attracts lots of
research attention. In this work, we study on two advanced semi-supervised
learning techniques for sound event detection. Data augmentation is important
for the success of recent deep learning systems. This work studies the
audio-signal random augmentation method, which provides an augmentation
strategy that can handle a large number of different audio transformations. In
addition, consistency regularization is widely adopted in recent
state-of-the-art semi-supervised learning methods, which exploits the
unlabelled data by constraining the prediction of different transformations of
one sample to be identical to the prediction of this sample. This work finds
that, for semi-supervised sound event detection, consistency regularization is
an effective strategy, especially the best performance is achieved when it is
combined with the MeanTeacher model.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:22:13 GMT""}]","2021-02-02"
"2102.00155","Zhengzhong Tu","Zhengzhong Tu, Chia-Ju Chen, Li-Heng Chen, Yilin Wang, Neil Birkbeck,
  Balu Adsumilli, and Alan C. Bovik","Regression or Classification? New Methods to Evaluate No-Reference
  Picture and Video Quality Models","ICASSP2021",,,,"cs.CV cs.MM eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Video and image quality assessment has long been projected as a regression
problem, which requires predicting a continuous quality score given an input
stimulus. However, recent efforts have shown that accurate quality score
regression on real-world user-generated content (UGC) is a very challenging
task. To make the problem more tractable, we propose two new methods - binary,
and ordinal classification - as alternatives to evaluate and compare
no-reference quality models at coarser levels. Moreover, the proposed new tasks
convey more practical meaning on perceptually optimized UGC transcoding, or for
preprocessing on media processing platforms. We conduct a comprehensive
benchmark experiment of popular no-reference quality models on recent
in-the-wild picture and video quality datasets, providing reliable baselines
for both evaluation methods to support further studies. We hope this work
promotes coarse-grained perceptual modeling and its applications to efficient
UGC processing.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:40:14 GMT""}]","2021-02-02"
"2102.00156","Zheng Chang","Shiheng Zhao and Zheng Chang","Elastic wave velocities in finitely pre-stretched soft fibers","27 pages, 6 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Elastic wave velocity in a soft fiber that varies depending on material
constitution and axial stress level is an essential measure of mechanical
signals in many technical applications. In this work, based on the
small-on-large theory, we establish a model of linear elastic wave propagation
in a finitely pre-stretched soft fiber. The formulas of longitudinal (Primary,
P-) and transverse (Secondary, S-) wave velocities are provided and validated
by numerical simulations as well as by experimental data on spider silk. The
influences of material constitution, compressibility, and pre-stress on the
wave propagation are investigated. We found that with increasing pre-stress,
the variation of P-wave velocity highly relies on the concavity of the
stress-strain curve. In contrast, an increase of S-wave velocity exhibits
regardless of any constitutive model. For both P- and S-waves, the variation of
the velocities is more significant in a compressible fiber than that in a
nearly-incompressible one. Moreover, for minuscule pre-stress, we propose a
modified formula for S-wave velocity based on the Rayleigh beam theory, which
reveals the competition mechanism between ""string vibration"" and ""beam
vibration."" This may provide a reliable theoretical basis for precise
mechanical characterization of soft fibers and open a route for lightweight,
tunable wave manipulation devices.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:48:04 GMT""}]","2021-02-02"
"2102.00157","Andreas Heinemann","Alexander Zeier and Alexander Wiesmaier and Andreas Heinemann","Zur Integration von Post-Quantum Verfahren in bestehende
  Softwareprodukte","to be published at 17. Deutscher IT-Sicherheitskongress des BSI,
  2021. in german, 12 pages",,,,"cs.CR","http://creativecommons.org/licenses/by-sa/4.0/","  Currently, PQC algorithms are being standardized to address the emerging
threat to conventional asymmetric algorithms from quantum computing. These new
algorithms must then be integrated into existing protocols, applications and
infrastructures. Integration problems are to be expected, due to
incompatibilities with existing standards and implementations on the one hand,
but also due to a lack of knowledge among software developers about how to
handle PQC algorithms. To illustrate incompatibilities, we integrate two
different PQC algorithms into two different existing software products (the
InboxPager email client for the Android OS and the TLS implementation of the
Bouncy Castle crypto library). Here, we rely on the highly-abstract crypto
library eUCRITE, which hides technical details about the correct usage of
classical and PCQ algorithms and thus prevents some potential implementation
errors.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:54:56 GMT""}]","2021-02-02"
"2102.00158","Ayan Mitra","Michael R.R. Good, Ayan Mitra, Vasileios Zarikas","Dual-temperature acceleration radiation","Accepted to Astronomy Reports. 10 pages, 4 figures","Astron. Rep. 65, 942-946 (2021)","10.1134/S1063772921100115",,"gr-qc astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We solve for a system that emits acceleration radiation at two different
temperatures. The equilibrium states occur asymptotically in Planck
distributions and transition non-thermally. The model is simple enough to
obtain a global solution for the radiation spectrum analytically. We present it
as a potentially useful model for investigation of non-thermal vacuum
acceleration radiation in the presence of final(initial) asymptotic
thermodynamic horizon(less) states in equilibrium.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:55:32 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 09:48:25 GMT""}]","2021-10-29"
"2102.00159","Theerawit Wilaiprasitporn","Soravitt Sangnark, Phairot Autthasan, Puntawat Ponglertnapakorn,
  Phudit Chalekarn, Thapanun Sudhawiyangkul, Manatsanan Trakulruangroj, Sarita
  Songsermsawad, Rawin Assabumrungrat, Supalak Amplod, Kajornvut Ounjai, and
  Theerawit Wilaiprasitporn","Revealing Preference in Popular Music Through Familiarity and Brain
  Response",,"IEEE Sensors Journal, 2021","10.1109/JSEN.2021.3073040",,"cs.HC eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Music preference was reported as a factor, which could elicit innermost music
emotion, entailing accurate ground-truth data and music therapy efficiency.
This study executes statistical analysis to investigate the distinction of
music preference through familiarity scores, response times (response rates),
and brain response (EEG). Twenty participants did self-assessment after
listening to two types of popular music's chorus section: music without lyrics
(Melody) and music with lyrics (Song). \textcolor{red}{We then conduct a music
preference classification using a support vector machine, random forest, and
k-nearest neighbors with the familiarity scores, the response rates, and EEG as
the feature vectors. The statistical analysis and F1-score of EEG are
congruent, which is the brain's right side outperformed its left side in
classification performance.} Finally, these behavioral and brain studies
support that preference, familiarity, and response rates can contribute to the
music emotion experiment's design to understand music, emotion, and listener.
Not only to the music industry, the biomedical and healthcare industry can also
exploit this experiment to collect data from patients to improve the efficiency
of healing by music.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 05:56:29 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 12:35:37 GMT""}]","2021-04-13"
"2102.00160","S.H.Shabbeer Basha","S.H.Shabbeer Basha, Mohammad Farazuddin, Viswanath Pulabaigari, Shiv
  Ram Dubey, Snehasis Mukherjee","Deep Model Compression based on the Training History",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Convolutional Neural Networks (DCNNs) have shown promising performances
in several visual recognition problems which motivated the researchers to
propose popular architectures such as LeNet, AlexNet, VGGNet, ResNet, and many
more. These architectures come at a cost of high computational complexity and
parameter storage. To get rid of storage and computational complexity, deep
model compression methods have been evolved. We propose a ""History Based Filter
Pruning (HBFP)"" method that utilizes network training history for filter
pruning. Specifically, we prune the redundant filters by observing similar
patterns in the filter's L1-norms (absolute sum of weights) over the training
epochs. We iteratively prune the redundant filters of a CNN in three steps.
First, we train the model and select the filter pairs with redundant filters in
each pair. Next, we optimize the network to ensure an increased measure of
similarity between the filters in a pair. This optimization of the network
facilitates us to prune one filter from each pair based on its importance
without much information loss. Finally, we retrain the network to regain the
performance, which is dropped due to filter pruning. We test our approach on
popular architectures such as LeNet-5 on MNIST dataset; VGG-16, ResNet-56, and
ResNet-110 on CIFAR-10 dataset, and ResNet-50 on ImageNet. The proposed pruning
method outperforms the state-of-the-art in terms of FLOPs reduction
(floating-point operations) by 97.98%, 83.42%, 78.43%, 74.95%, and 75.45% for
LeNet-5, VGG-16, ResNet-56, ResNet-110, and ResNet-50, respectively, while
maintaining the less error rate.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:04:21 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 08:59:31 GMT""}]","2022-05-13"
"2102.00161","Jie Liu","Jie Liu, Xiaoyu Mao, Jianxin Zhong, Rudolf A. R\""omer","Localization properties in Lieb lattices and their extensions",,"Annals of Physics 168544 (2021)","10.1016/j.aop.2021.168544",,"cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  We study the localization properties of generalized, two- and
three-dimensional Lieb lattices, $\mathcal{L}_2(n)$ and $\mathcal{L}_3(n)$, $n=
1, 2, 3$ and $4$, at energies corresponding to flat and dispersive bands using
the transfer matrix method (TMM) and finite size scaling (FSS). We find that
the scaling properties of the flat bands are different from scaling in
dispersive bands for all $\mathcal{L}_d(n)$. For the $d=3$ dimensional case,
states are extended for disorders $W$ down to $W=0.01 t$ at the flat bands,
indicating that the disorder can lift the degeneracy of the flat bands quickly.
The phase diagram with periodic boundary condition for $\mathcal{L}_3(1)$ looks
similar to the one for hard boundaries. We present the critical disorder $W_c$
at energy $E=0$ and find a decreasing $W_c$ for increasing $n$ for
$\mathcal{L}_3(n)$, up to $n=3$. Last, we show a table of FSS parameters
including so-called irrelevant variables; but the results indicate that the
accuracy is too low to determine these reliably. \end{abstract}
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:14:39 GMT""}]","2021-08-03"
"2102.00162","Mykyta Onizhuk","Krishnendu Ghosh, He Ma, Mykyta Onizhuk, Vikram Gavini, Giulia Galli","Spin-spin interactions in solids from mixed all-electron and
  pseudopotential calculations $-$ a path to screening materials for spin
  qubits",,,,,"cond-mat.mtrl-sci quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the quantum dynamics of spin defects and their coherence
properties requires accurate modeling of spin-spin interaction in solids and
molecules, for example by using spin Hamiltonians with parameters obtained from
first-principles calculations. We present a real-space approach based on
density functional theory for the calculation of spin-Hamiltonian parameters,
where only selected atoms are treated at the all-electron level, while the rest
of the system is described with the pseudopotential approximation. Our approach
permits calculations for systems containing more than 1000 atoms, as
demonstrated for defects in diamond and silicon carbide. We show that only a
small number of atoms surrounding the defect needs to be treated at the
all-electron level, in order to obtain an overall all-electron accuracy for
hyperfine and zero-field splitting tensors. We also present results for
coherence times, computed with the cluster correlation expansion method,
highlighting the importance of accurate spin-Hamiltonian parameters for
quantitative predictions of spin dynamics.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:22:21 GMT""}]","2021-02-02"
"2102.00163","Shahram Abbassi","Mohammad Mahdi Motiei, Mohammad Hosseinirad and Shahram Abbassi","Gravitational instability of non-isothermal filamentary molecular
  clouds, in presence of external pressure","Accepted for publication in MNRAS",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Filamentary molecular clouds are omnipresent in the cold interstellar medium.
Observational evidences show that the non-isothermal equations of state
describe the filaments properties better than the isothermal one. In this paper
we use the logatropic and the polytropic equations of state to study the
gravitational instability of the pressure-confined filaments in presence of a
uniform axial magnetic field. To fully explore the parameter space we carry out
very large surveys of stability analysis that cover filaments with different
radii in various magnetic fields. Our results show that for all the equations
of state the instability of thinner filaments is more sensitive to the magnetic
field variations than the thicker ones. Moreover, for all the equations of
state, an intermediate magnetic field can entirely stabilize the thinner
filaments. Albeit for the thicker ones this effect is suppressed for the
magnetic field stronger than B ' 70 micro G.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:23:27 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 12:00:12 GMT""}]","2021-02-04"
"2102.00164","Lin He","Yi-Wen Liu, Ya-Ning Ren, Chen-Yue Hao, Lin He","Direct observation of magneto-electric Aharonov-Bohm effect in
  moir\'e-scale quantum paths of minimally twisted bilayer graphene",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Aharonov-Bohm (AB) effect, the well-known archetype of electron-wave
interference phenomena, has been explored extensively through transport
measurements. However, these techniques lack spatial resolution that would be
indispensable for studying the magnetic and electrostatic AB oscillations at
the nanometer scale. Here, we demonstrated that scanning tunneling microscopy
(STM) can be used as an AB interferometer operating on nanometer length scales
and the magneto-electric Aharonov-Bohm effect in minimally twisted bilayer
graphene (TBG) was directly measured by using STM. In the minimally TBG, there
is a triangular network of chiral one-dimensional states hosted by domain
boundaries due to structural reconstruction. Taking advantage of the high
spatial resolution of the STM, both the magnetic and electrostatic AB
oscillations arising from electron interference along moir\'e-scale triangular
quantum paths in the minimally TBG were measured. Our work enables measure and
control of the AB effect and other electron-wave interference at the nanoscale.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:29:19 GMT""}]","2021-02-02"
"2102.00165","Vandana Sharma","Vandana Sharma, Jyotshana V. Prajapat","Global Existence of Solutions to Reaction Diffusion Systems with Mass
  Transport Type Boundary Conditions on an Evolving Domain","27 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We consider reaction-diffusion systems where components diffuse inside the
domain and react on the surface through mass transport type boundary conditions
on an evolving domain. Using Lyapunov functional and duality arguments, we
establish the existence of component-wise non-negative global solutions.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:44:44 GMT""}]","2021-02-02"
"2102.00166","Kaitao Zhang","Zhenghao Liu, Kaitao Zhang, Chenyan Xiong, Zhiyuan Liu and Maosong Sun","OpenMatch: An Open Source Library for Neu-IR Research","4 pages",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  OpenMatch is a Python-based library that serves for Neural Information
Retrieval (Neu-IR) research. It provides self-contained neural and traditional
IR modules, making it easy to build customized and higher-capacity IR systems.
In order to develop the advantages of Neu-IR models for users, OpenMatch
provides implementations of recent neural IR models, complicated experiment
instructions, and advanced few-shot training methods. OpenMatch reproduces
corresponding ranking results of previous work on widely-used IR benchmarks,
liberating users from surplus labor in baseline reimplementation. Our
OpenMatch-based solutions conduct top-ranked empirical results on various
ranking tasks, such as ad hoc retrieval and conversational retrieval,
illustrating the convenience of OpenMatch to facilitate building an effective
IR system. The library, experimental methodologies and results of OpenMatch are
all publicly available at https://github.com/thunlp/OpenMatch.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:47:21 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 03:42:44 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 14:56:54 GMT""}]","2021-05-07"
"2102.00167","Peter Biro Dr.","P\'eter Bir\'o and Flip Klijn and Xenia Klimentova and Ana Viana","Shapley-Scarf Housing Markets: Respecting Improvement, Integer
  Programming, and Kidney Exchange",,,,,"econ.TH cs.GT","http://creativecommons.org/licenses/by/4.0/","  In a housing market of Shapley and Scarf, each agent is endowed with one
indivisible object and has preferences over all objects. An allocation of the
objects is in the (strong) core if there exists no (weakly) blocking coalition.
In this paper we show that in the case of strict preferences the unique strong
core allocation (or competitive allocation) respects improvement: if an agent's
object becomes more attractive for some other agents, then the agent's
allotment in the unique strong core allocation weakly improves. We obtain a
general result in case of ties in the preferences and provide new integer
programming formulations for computing (strong) core and competitive
allocations. Finally, we conduct computer simulations to compare the
game-theoretical solutions with maximum size and maximum weight exchanges for
markets that resemble the pools of kidney exchange programmes.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:50:42 GMT""}]","2021-02-02"
"2102.00168","Ambedkar Dukkipati","Ambedkar Dukkipati, Rajarshi Banerjee, Ranga Shaarad Ayyagari, Dhaval
  Parmar Udaybhai","Learning Skills to Navigate without a Master: A Sequential Multi-Policy
  Reinforcement Learning Algorithm","IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS): 2022",,,,"cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving complex problems using reinforcement learning necessitates breaking
down the problem into manageable tasks and learning policies to solve these
tasks. These policies, in turn, have to be controlled by a master policy that
takes high-level decisions. Hence learning policies involves hierarchical
decision structures. However, training such methods in practice may lead to
poor generalization, with either sub-policies executing actions for too few
time steps or devolving into a single policy altogether. In our work, we
introduce an alternative approach to learn such skills sequentially without
using an overarching hierarchical policy. We propose this method in the context
of environments where a major component of the objective of a learning agent is
to prolong the episode for as long as possible. We refer to our proposed method
as Sequential Soft Option Critic. We demonstrate the utility of our approach on
navigation and goal-based tasks in a flexible simulated 3D navigation
environment that we have developed. We also show that our method outperforms
prior methods such as Soft Actor-Critic and Soft Option Critic on various
environments, including the Atari River Raid environment and the Gym-Duckietown
self-driving car simulator.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:55:35 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 06:54:21 GMT""},{""version"":""v3"",""created"":""Sun, 7 Aug 2022 08:00:24 GMT""}]","2022-08-09"
"2102.00169","Cristian Lazo","Cristian Lazo","Segmentation of skin lesions and their attributes using Generative
  Adversarial Networks","LatinX in AI Research at NeurIPS 2019",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is about the semantic segmentation of skin lesion boundary and
their attributes using Image-to-Image Translation with Conditional Adversarial
Nets. Melanoma is a type of skin cancer that can be cured if detected in time.
Segmentation into dermoscopic images is an essential procedure for
computer-assisted diagnosis due to its existing artifacts typical of skin
images. To alleviate the image annotation process, we propose to use a modified
Pix2Pix network. The discriminator network learns the mapping from a dermal
image as an input and a mask image of six channels as an output. Likewise, the
discriminative network output called PatchGAN is varied for one channel and six
output channels. The photos used come from the 2018 ISIC Challenge, where 500
photographs are used with their respective semantic map, divided into 75% for
training and 35% for testing. Obtaining for 100 training epochs high Jaccard
indices for all attributes of the segmentation map.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:57:54 GMT""}]","2021-02-02"
"2102.00170","JaeHwan Shim","JaeHwan Shim, Juyong Lee, Jaejun Yu","Efficient discovery of multiple minimum action pathways using Gaussian
  process","Update surface calculations",,,,"physics.comp-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new efficient transition pathway search method based on the
least action principle and the Gaussian process regression method. Most pathway
search methods developed so far rely on string representations, which
approximate a transition pathway by a series of slowly varying system replicas.
Such string methods are computationally expensive in general because they
require many replicas to obtain smooth pathways. Here, we present an approach
employing the Gaussian process regression method, which infers the shape of a
potential energy surface with a few observed data and Gaussian-shaped kernel
functions. We demonstrate a drastic elevation of computing efficiency of the
method about five orders of magnitude than existing methods. Further, to
demonstrate its real-world capabilities, we apply our method to find multiple
conformational transition pathways of alanine dipeptide using a quantum
mechanical potential. Owing to the improved efficiency of our method, Gaussian
process action optimiza tion (GPAO), we obtain the multiple transition pathways
of alaninedipeptide and calculate their transition probabilities successfully
with ab initio accuracy. In addition, GPAO successfully finds the isomerization
pathways of small molecules and the rearrangement of atoms on a metallic
surface.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:02:22 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 15:09:03 GMT""},{""version"":""v3"",""created"":""Sun, 11 Sep 2022 07:40:47 GMT""}]","2022-09-13"
"2102.00171","Jiarong Hong","Cheng Li, Ruichen He, Zilong He, S. Santosh Kumar, Steven A.
  Fredericks, Christopher J. Hogan Jr., and Jiarong Hong","Spatially-Resolved Characterization of Oil-in-Water Emulsion Sprays","23 pages, 13 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  This study concerns the effects of pressure, spatial location, and
application of oil emulsions on the resulting droplet size, eccentricity, as
well as velocity distributions, all of which are crucial information in
determining the dispersion dynamics of the droplets during the spray
applications. Experiments were conducted with the abovementioned droplets
information measured using digital inline holography (DIH). Results show that
the volumetric droplet size distributions (VDSD) span widely from sub-200 um to
over 2 mm in size. The application of an oil-in-water emulsion results largely
in the suppression of smaller droplets, while the VDSD is relatively
insensitive to increasing the oil volume fraction beyond a critical level. DIH
additionally enables the determination of size-dependent droplet eccentricity
and velocity measurements. Interestingly, the application of oil-in-water
emulsion generally decreases the eccentricity, more significantly at the center
than at the edge of the spray fan. We attribute this decrease to the increase
in lamella sheet thickness and thus decrease in characteristic shrinkage rates,
consistent with the observation using high-speed shadowgraphs. In all
instances, oil-in-water emulsion droplets have higher velocities than
equivalent sized water droplets. We attribute this to the earlier action of the
spray breakup process in the oil-in-water emulsion, reduced surface energy
generation during a breakup (larger droplets), and reduce energy dissipation
during breakup with oil-in-water emulsions, leading to increased translational
energy after the breakup process. Therefore, it appears that oil-in-water
emulsion application simultaneously suppresses small droplet formation and
increases droplet velocity, and hence spray penetration in agricultural
application.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:02:46 GMT""}]","2021-02-02"
"2102.00172","Erik Fredenberg","Erik Fredenberg, Klaus Erhard, Karl Berggren, David R Dance, Kenneth C
  Young, Bjorn Cederstrom, Henrik Johansson, Mats Lundqvist, Elin Moa, Hanno
  Homan, Paula Willsher, Fleur Kilburn-Toppin, Matthew Wallis","X-ray attenuation of adipose breast tissue: in-vitro and in-vivo
  measurements using spectral imaging","arXiv admin note: text overlap with arXiv:2101.02449","Proc. SPIE 9412, Medical Imaging 2015, 94121U","10.1117/12.2081747",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The development of new x-ray imaging techniques often requires prior
knowledge of tissue attenuation, but the sources of such information are
sparse. We have measured the attenuation of adipose breast tissue using
spectral imaging, in vitro and in vivo. For the in-vitro measurement, fixed
samples of adipose breast tissue were imaged on a spectral mammography system,
and the energy-dependent x-ray attenuation was measured in terms of equivalent
thicknesses of aluminum and poly-methyl methacrylate (PMMA). For the in-vivo
measurement, a similar procedure was applied on a number of spectral screening
mammograms. The results of the two measurements agreed well and were consistent
with published attenuation data and with measurements on tissue-equivalent
material.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:06:37 GMT""}]","2021-02-02"
"2102.00173","Masamitsu Hayashi","Masashi Kawaguchi, Kenji Tanabe, Keisuke Yamada, Takuya Sawa, Shun
  Hasegawa, Masamitsu Hayashi, Yoshinobu Nakatani","Determination of the Dzyaloshinskii-Moriya interaction using pattern
  recognition and machine learning",,"npj Computational Materials 7, 20 (2021)","10.1038/s41524-020-00485-2",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning is applied to a large number of modern devices that are
essential in building energy efficient smart society. Audio and face
recognition are among the most well-known technologies that make use of such
artificial intelligence. In materials research, machine learning is adapted to
predict materials with certain functionalities, an approach often referred to
as materials informatics. Here we show that machine learning can be used to
extract material parameters from a single image obtained in experiments. The
Dzyaloshinskii-Moriya (DM) interaction and the magnetic anisotropy distribution
of thin film heterostructures, parameters that are critical in developing next
generation storage class magnetic memory technologies, are estimated from a
magnetic domain image. Micromagnetic simulation is used to generate thousands
of random images for training and model validation. A convolutional neural
network system is employed as the learning tool. The DM exchange constant of
typical Co-based thin film heterostructures is studied using the trained
system: the estimated values are in good agreement with experiments. Moreover,
we show that the system can independently determine the magnetic anisotropy
distribution, demonstrating the potential of pattern recognition. This approach
can considerably simplify experimental processes and broaden the scope of
materials research.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:08:52 GMT""}]","2021-02-02"
"2102.00174","Erik Fredenberg","Karl Berggren, Mats Danielsson, Erik Fredenberg","Rayleigh imaging in spectral mammography",,"Proc. SPIE 9783, Medical Imaging 2016: Physics of Medical Imaging,
  97830A (2016)","10.1117/12.2217048",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spectral imaging is the acquisition of multiple images of an object at
different energy spectra. In mammography, dual-energy imaging (spectral imaging
with two energy levels) has been investigated for several applications, in
particular material decomposition, which allows for quantitative analysis of
breast composition and quantitative contrast-enhanced imaging. Material
decomposition with dual-energy imaging is based on the assumption that there
are two dominant photon interaction effects that determine linear attenuation:
the photoelectric effect and Compton scattering. This assumption limits the
number of basis materials, i.e. the number of materials that are possible to
differentiate between, to two. However, Rayleigh scattering may account for
more than 10% of the linear attenuation in the mammography energy range. In
this work, we show that a modified version of a scanning multi-slit spectral
photon-counting mammography system is able to acquire three images at different
spectra and can be used for triple-energy imaging. We further show that
triple-energy imaging in combination with the efficient scatter rejection of
the system enables measurement of Rayleigh scattering, which adds an additional
energy dependency to the linear attenuation and enables material decomposition
with three basis materials. Three available basis materials have the potential
to improve virtually all applications of spectral imaging.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:09:52 GMT""}]","2021-02-02"
"2102.00175","Erik Fredenberg","Bjorn Cederstrom, Erik Fredenberg, Karl Berggren, Klaus Erhard, Mats
  Danielsson, Matthew Wallis","Lesion characterization in spectral photon-counting tomosynthesis",,"Proc. SPIE 10132, Medical Imaging 2017: Physics of Medical
  Imaging, 1013205 (2017)","10.1117/12.2253966",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It has previously been shown that 2D spectral mammography can be used to
discriminate between (likely benign) cystic and (potentially malignant) solid
lesions in order to reduce unnecessary recalls in mammography. One limitation
of the technique is, however, that the composition of overlapping tissue needs
to be interpolated from a region surrounding the lesion. The purpose of this
investigation was to demonstrate that lesion characterization can be done with
spectral tomosynthesis, and to investigate whether the 3D information available
in tomosynthesis can reduce the uncertainty from the interpolation of
surrounding tissue. A phantom experiment was designed to simulate a cyst and a
tumor, where the tumor was overlaid with a structure that made it mimic a cyst.
In 2D, the two targets appeared similar in composition, whereas spectral
tomosynthesis revealed the exact compositional difference. However, the loss of
discrimination signal due to spread from the plane of interest was of the same
strength as the reduction of anatomical noise. Results from a preliminary
investigation on clinical tomosynthesis images of solid lesions yielded results
that were consistent with the phantom experiments, but were still to some
extent inconclusive. We conclude that lesion characterization is feasible in
spectral tomosynthesis, but more data, as well as refinement of the calibration
and discrimination algorithms, are needed to draw final conclusions about the
benefit compared to 2D.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:14:34 GMT""}]","2021-02-02"
"2102.00176","Weizhe Yuan","Weizhe Yuan and Pengfei Liu and Graham Neubig","Can We Automate Scientific Reviewing?","TLDR: This paper proposes to use NLP models to generate first-pass
  peer reviews for scientific papers . (Generated by our system.)",,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  The rapid development of science and technology has been accompanied by an
exponential growth in peer-reviewed scientific publications. At the same time,
the review of each paper is a laborious process that must be carried out by
subject matter experts. Thus, providing high-quality reviews of this growing
number of papers is a significant challenge. In this work, we ask the question
""can we automate scientific reviewing?"", discussing the possibility of using
state-of-the-art natural language processing (NLP) models to generate
first-pass peer reviews for scientific papers. Arguably the most difficult part
of this is defining what a ""good"" review is in the first place, so we first
discuss possible evaluation measures for such reviews. We then collect a
dataset of papers in the machine learning domain, annotate them with different
aspects of content covered in each review, and train targeted summarization
models that take in papers to generate reviews. Comprehensive experimental
results show that system-generated reviews tend to touch upon more aspects of
the paper than human-written reviews, but the generated text can suffer from
lower constructiveness for all aspects except the explanation of the core ideas
of the papers, which are largely factually correct. We finally summarize eight
challenges in the pursuit of a good review generation system together with
potential solutions, which, hopefully, will inspire more future research on
this subject. We make all code, and the dataset publicly available:
https://github.com/neulab/ReviewAdvisor, as well as a ReviewAdvisor system:
http://review.nlpedia.ai/.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:16:53 GMT""}]","2021-02-02"
"2102.00177","Chao Li","Chao Li, Balaji Palanisamy, Runhua Xu, Jinlai Xu, and Jingzhe Wang","SteemOps: Extracting and Analyzing Key Operations in Steemit
  Blockchain-based Social Media Platform","Accepted by ACM CODASPY'21. arXiv admin note: text overlap with
  arXiv:1904.07310",,"10.1145/3422337.3447845",,"cs.CR cs.DB cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advancements in distributed ledger technologies are driving the rise of
blockchain-based social media platforms such as Steemit, where users interact
with each other in similar ways as conventional social networks. These
platforms are autonomously managed by users using decentralized consensus
protocols in a cryptocurrency ecosystem. The deep integration of social
networks and blockchains in these platforms provides potential for numerous
cross-domain research studies that are of interest to both the research
communities. However, it is challenging to process and analyze large volumes of
raw Steemit data as it requires specialized skills in both software engineering
and blockchain systems and involves substantial efforts in extracting and
filtering various types of operations. To tackle this challenge, we collect
over 38 million blocks generated in Steemit during a 45 month time period from
2016/03 to 2019/11 and extract ten key types of operations performed by the
users. The results generate SteemOps, a new dataset that organizes more than
900 million operations from Steemit into three sub-datasets namely (i)
social-network operation dataset (SOD), (ii) witness-election operation dataset
(WOD) and (iii) value-transfer operation dataset (VOD). We describe the dataset
schema and its usage in detail and outline possible future research studies
using SteemOps. SteemOps is designed to facilitate future research aimed at
providing deeper insights on emerging blockchain-based social media platforms.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:18:39 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 05:51:39 GMT""}]","2021-02-11"
"2102.00178","Ronald Chang","Tz-Wei Mo, Ronald Y. Chang, Te-Yi Kan","Deep Reinforcement Learning Aided Monte Carlo Tree Search for MIMO
  Detection",,,,,"eess.SP cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel multiple-input multiple-output (MIMO) symbol
detector that incorporates a deep reinforcement learning (DRL) agent into the
Monte Carlo tree search (MCTS) detection algorithm. We first describe how the
MCTS algorithm, used in many decision-making problems, is applied to the MIMO
detection problem. Then, we introduce a self-designed deep reinforcement
learning agent, consisting of a policy value network and a state value network,
which is trained to detect MIMO symbols. The outputs of the trained networks
are adopted into a modified MCTS detection algorithm to provide useful node
statistics and facilitate enhanced tree search process. The resulted scheme,
termed the DRL-MCTS detector, demonstrates significant improvements over the
original MCTS detection algorithm and exhibits favorable performance compared
to other existing linear and DNN-based detection methods under varying channel
conditions.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:29:04 GMT""}]","2021-02-02"
"2102.00179","Tiffany Hwu","Tiffany Hwu, Mia Levy, Steven Skorheim, David Huber","Matching Representations of Explainable Artificial Intelligence and Eye
  Gaze for Human-Machine Interaction",,,,,"cs.HC cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rapid non-verbal communication of task-based stimuli is a challenge in
human-machine teaming, particularly in closed-loop interactions such as
driving. To achieve this, we must understand the representations of information
for both the human and machine, and determine a basis for bridging these
representations. Techniques of explainable artificial intelligence (XAI) such
as layer-wise relevance propagation (LRP) provide visual heatmap explanations
for high-dimensional machine learning techniques such as deep neural networks.
On the side of human cognition, visual attention is driven by the bottom-up and
top-down processing of sensory input related to the current task. Since both
XAI and human cognition should focus on task-related stimuli, there may be
overlaps between their representations of visual attention, potentially
providing a means of nonverbal communication between the human and machine. In
this work, we examine the correlations between LRP heatmap explanations of a
neural network trained to predict driving behavior and eye gaze heatmaps of
human drivers. The analysis is used to determine the feasibility of using such
a technique for enhancing driving performance. We find that LRP heatmaps show
increasing levels of similarity with eye gaze according to the task specificity
of the neural network. We then propose how these findings may assist humans by
visually directing attention towards relevant areas. To our knowledge, our work
provides the first known analysis of LRP and eye gaze for driving tasks.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:42:56 GMT""}]","2021-02-02"
"2102.00180","Xiaohan Wei","Xiaohan Wei","I. Asynchronous Optimization over weakly Coupled Renewal Systems","Phd Thesis; University of Southern California",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A renewal system divides the slotted timeline into back to back time periods
called renewal frames. At the beginning of each frame, it chooses a policy from
a set of options for that frame. The policy determines the duration of the
frame, the penalty incurred during the frame (such as energy expenditure), and
a vector of performance metrics (such as instantaneous number of jobs served).
The starting points of this line of research are Chapter 7 of the book
[Nee10a], the seminal work [Nee13a], and Chapter 5 of the PhD thesis of
Chih-ping Li [Li11]. These works consider stochastic optimization over a single
renewal system. By way of contrast, this thesis considers optimization over
multiple parallel renewal systems, which is computationally more challenging
and yields much more applications. The goal is to minimize the time average
overall penalty subject to time average overall constraints on the
corresponding performance metrics. The main difficulty, which is not present in
earlier works, is that these systems act asynchronously due to the fact that
the renewal frames of different renewal systems are not aligned. The goal of
the thesis is to resolve this difficulty head-on via a new asynchronous
algorithm and a novel supermartingale stopping time analysis which shows our
algorithms not only converge to the optimal solution but also enjoy fast
convergence rates. Based on this general theory, we further develop novel
algorithms for data center server provision problems with performance
guarantees as well as new heuristics for the multi-user file downloading
problems.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:47:01 GMT""}]","2021-02-02"
"2102.00181","Yan Lyu","Yan Lyu, Hui Tong, Takuya Sugiura, Sinya Aoki, Takumi Doi, Tetsuo
  Hatsuda, Jie Meng, Takaya Miyamoto","Dibaryon with highest charm number near unitarity from lattice QCD","6 pages, 4 figures; Supplemental Material(1 page, 1 figure); Accepted
  for publication in Physical Review Letters","Phys. Rev. Lett. 127, 072003 (2021)","10.1103/PhysRevLett.127.072003","RIKEN-iTHEMS-Report-21,RIKEN-QHP-491","hep-lat hep-ex hep-ph nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A pair of triply charmed baryons, $\Omega_{ccc}\Omega_{ccc}$, is studied as
an ideal dibaryon system by (2+1)-flavor lattice QCD with nearly physical
light-quark masses and the relativistic heavy quark action with the physical
charm quark mass. The spatial baryon-baryon correlation is related to their
scattering parameters on the basis of the HAL QCD method. The
$\Omega_{ccc}\Omega_{ccc}$ in the ${^1S_0}$ channel taking into account the
Coulomb repulsion with the charge form factor of $\Omega_{ccc}$ leads to the
scattering length $a^{\rm C}_0\simeq -19~\text{fm}$ and the effective range
$r^{\rm C}_{\mathrm{eff}}\simeq 0.45~\text{fm}$. The ratio $r^{\rm
C}_{\mathrm{eff}}/a^{\rm C}_0 \simeq -0.024$, whose magnitude is considerably
smaller than that of the dineutron ($-0.149$), indicates that
$\Omega_{ccc}\Omega_{ccc}$ is located in the unitary regime.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:51:24 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 00:42:56 GMT""},{""version"":""v3"",""created"":""Wed, 14 Jul 2021 02:47:12 GMT""}]","2021-08-18"
"2102.00182","Federico Ricci-Tersenghi","Matteo Bellitti, Federico Ricci-Tersenghi and Antonello Scardicchio","Entropic barriers as a reason for hardness in both classical and quantum
  algorithms","16 pages, 17 figures","Phys. Rev. Research 3, 043015 (2021)","10.1103/PhysRevResearch.3.043015",,"cond-mat.dis-nn cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study both classical and quantum algorithms to solve a hard optimization
problem, namely 3-XORSAT on 3-regular random graphs. By introducing a new
quasi-greedy algorithm that is not allowed to jump over large energy barriers,
we show that the problem hardness is mainly due to entropic barriers. We study,
both analytically and numerically, several optimization algorithms, finding
that entropic barriers affect in a similar way classical local algorithms and
quantum annealing. For the adiabatic algorithm, the difficulty we identify is
distinct from that of tunnelling under large barriers, but does, nonetheless,
give rise to exponential running (annealing) times.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:58:24 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 14:22:12 GMT""}]","2021-10-13"
"2102.00183","Charles-Antoine Gu\'erin","Baptiste Domps, Julien Marmain and Charles-Antoine Gu\'erin","Improved Observation of Transient Phenomena with Doppler Radars: a
  Common Framework for Oceanic and Atmospheric Sensing","4 pages, 3 figures submitted for publication to the IEEE
  International Geoscience and Remote Sensing Symposium (IGARSS), Brussels,
  Belgium, July 11-16, 2021",,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Doppler radars are routinely used for the remote sensing of oceanic surface
currents and atmospheric wind profiles. Even though they operate at different
frequencies and address different media, they follow very similar processing
for the extraction of measured velocities. In particular they both face the
challenging issue of capturing geophysical phenomena which vary rapidly with
respect to the typical integration time. Recently, the authors applied a
non-spectral formalism based on autoregressive processes to model the
backscattered time series obtained from High-Frequency oceanic radars. They
showed that it allows to calculate Doppler spectra for very short integration
times without losing in frequency resolution nor signal-to-noise ratio. We
apply this technique to synthetic and experimental data within a common
framework and show for the first time the strong potential of the method for
the study of transient atmospheric phenomena.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:26:48 GMT""}]","2021-02-02"
"2102.00184","Jie Wang","Jie Wang, Jingbei Li, Xintao Zhao, Zhiyong Wu, Shiyin Kang, Helen Meng","Adversarially learning disentangled speech representations for robust
  multi-factor voice conversion",,,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Factorizing speech as disentangled speech representations is vital to achieve
highly controllable style transfer in voice conversion (VC). Conventional
speech representation learning methods in VC only factorize speech as speaker
and content, lacking controllability on other prosody-related factors.
State-of-the-art speech representation learning methods for more speechfactors
are using primary disentangle algorithms such as random resampling and ad-hoc
bottleneck layer size adjustment,which however is hard to ensure robust speech
representationdisentanglement. To increase the robustness of highly
controllable style transfer on multiple factors in VC, we propose a
disentangled speech representation learning framework based on adversarial
learning. Four speech representations characterizing content, timbre, rhythm
and pitch are extracted, and further disentangled by an adversarial
Mask-And-Predict (MAP)network inspired by BERT. The adversarial network is used
tominimize the correlations between the speech representations,by randomly
masking and predicting one of the representationsfrom the others. Experimental
results show that the proposedframework significantly improves the robustness
of VC on multiple factors by increasing the speech quality MOS from 2.79 to3.30
and decreasing the MCD from 3.89 to 3.58.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:29:55 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 07:20:00 GMT""}]","2021-12-06"
"2102.00185","Alexey Naumov","Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, Hoi-To
  Wai","On the Stability of Random Matrix Product with Markovian Noise:
  Application to Linear Stochastic Approximation and TD Learning",,,,,"stat.ML cs.LG math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the exponential stability of random matrix products driven
by a general (possibly unbounded) state space Markov chain. It is a cornerstone
in the analysis of stochastic algorithms in machine learning (e.g. for
parameter tracking in online learning or reinforcement learning). The existing
results impose strong conditions such as uniform boundedness of the
matrix-valued functions and uniform ergodicity of the Markov chains. Our main
contribution is an exponential stability result for the $p$-th moment of random
matrix product, provided that (i) the underlying Markov chain satisfies a
super-Lyapunov drift condition, (ii) the growth of the matrix-valued functions
is controlled by an appropriately defined function (related to the drift
condition). Using this result, we give finite-time $p$-th moment bounds for
constant and decreasing stepsize linear stochastic approximation schemes with
Markovian noise on general state space. We illustrate these findings for linear
value-function estimation in reinforcement learning. We provide finite-time
$p$-th moment bound for various members of temporal difference (TD) family of
algorithms.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:39:38 GMT""}]","2021-02-02"
"2102.00186","Xianlin Song","Xianlin Song, Jianshuang Wei, Qi Jiang, Lingfang Song","Research on the photoacoustic spectrum analysis using k-Wave",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Photoacoustic imaging is a new non-destructive medical imaging technology
based on photoacoustic effect. It can reflect the difference of light
absorption energy by detecting photoacoustic signal. At present, the analysis
methods of photoacoustic signals in biological tissues can be divided into two
categories, namely, time-domain analysis of signals and frequency-domain
analysis of signals. In time domain analysis, the envelope of the received
photoacoustic signal is usually used to reconstruct the image. However, due to
the influence of various external factors, the time domain signal cannot
accurately reflect the characteristics of the absorber itself. Here,
photoacoustic spectrum analysis was performed by using k-Wave to obtains the
relationship between the structure, size, density of the absorber and the
photoacoustic spectrum. Firstly, the relationship between the size of absorber
and the photoacoustic spectrum is studied, and the slope and intercept are used
to analyze the spectrum. Conversely, the relationship was used to predict the
size of the absorber Finally, we used this relationship to predict the size of
blood vessels.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:39:47 GMT""}]","2021-02-03"
"2102.00187","Babak Vakili","Fatimah Tavakoli, Babak Vakili and Hossein Ardehali","Ho\v{r}ava-Lifshitz scalar field cosmology: classical and quantum
  viewpoints","17 pages, 12 figures, typos corrected, Refs. added, Final version","Adv. High Energy Phys. (2021), 6617910","10.1155/2021/6617910",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study a projectable Ho\v{r}ava-Lifshitz cosmology without
the detailed balance condition minimally coupled to a non-linear self-coupling
scalar field. In the minisuperspace framework, the super Hamiltonian of the
presented model is constructed by means of which, some classical solutions for
scale factor and scalar field are obtained. Since these solutions exhibit
various types of singularities, we came up with the quantization of the model
in the context of the Wheeler-DeWitt approach of quantum cosmology. The
resulting quantum wave functions are then used to investigate the possibility
of the avoidance of classical singularities due to quantum effects which show
themselves important near these singularities.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:42:49 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 14:15:05 GMT""}]","2021-02-25"
"2102.00188","Letizia Jaccheri","Letizia Jaccheri, Cristina Pereira, Swetlana Fast","Gender Issues in Computer Science: Lessons Learnt and Reflections for
  the Future",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Women are underrepresented in Computer Science disciplines at all levels,
from undergraduate and graduate studies to participation and leadership in
academia and industry. Increasing female representation in the field is a grand
challenge for academics, policymakers, and society. Although the problem has
been addressed for many years, progress has been difficult to be measured and
compared across countries and institutions, and has been invariably slow,
despite all the momentum and impulse for change taking place across several
countries. Therefore, it is important to reflect on knowledge, experiences,
successes, and challenges of existing policies, initiatives and interventions.
The main goal of this paper is to provide an overview of several initiatives,
studies, projects, and their outcomes. It contributes to building a body of
knowledge about gender aspects in several areas: research, education, projects,
networks and resources. This paper is mainly based on discussions in working
groups and the material collected for and during a series of talks on the topic
held by the first author and by feedback received by the community. This paper
provides the academic community, policymakers, industry and other stakeholders
with numerous examples of best practices, as well as studies and
recommendations on how to address key challenges about attracting, retaining,
encouraging, and inspiring women to pursue a career in Computer Science. Future
work should address the issue in a systematic and research based way.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:47:39 GMT""}]","2021-02-02"
"2102.00189","Berengere Dubrulle","B. Dubrulle, and J. D. Gibbon","A correspondence between the multifractal model of turbulence and the
  Navier-Stokes equations","9 pages, 1 figure",,"10.1098/rsta.2021.0092",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a correspondence between the multifractal model of turbulence and
the Navier-Stokes equations in $d$ spatial dimensions by comparing their
respective dissipation length scales. In Kolmogorov's 1941 theory the key
parameter $h$, which is an exponent in the Navier-Stokes invariance scaling, is
fixed at $h=1/3$ but is allowed a spectrum of values in multifractal theory.
Taking into account all derivatives of the Navier-Stokes equations, it is found
that for this correspondence to hold the multifractal spectrum $C(h)$ must be
bounded from below such that $C(h) \geq 1-3h$, which is consistent with the
four-fifths law. Moreover, $h$ must also be bounded from below such that $h
\geq (1-d)/3$. When $d=3$ the allowed range of $h$ is given by $h \geq -2/3$
thereby bounding $h$ away from $h=-1$. The implications of this are discussed.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:48:56 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 08:54:21 GMT""},{""version"":""v3"",""created"":""Thu, 15 Apr 2021 09:16:57 GMT""}]","2022-02-16"
"2102.00190","Daisuke Kishimoto","Kouyemon Iriye, Daisuke Kishimoto","Golod and tight 3-manifolds","19 pages",,,,"math.CO math.AT math.GT","http://creativecommons.org/licenses/by/4.0/","  The notions Golodness and tightness for simplicial complexes come from
algebra and geometry, respectively. We prove these two notions are equivalent
for 3-manifold triangulations, through a topological characterization of a
polyhedral product for a tight-neighborly manifold triangulation of dimension
$\ge 3$.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:51:44 GMT""}]","2021-02-02"
"2102.00191","Santanu Saha","Franz M. Rohrhofer, Santanu Saha, Simone Di Cataldo, Bernhard C.
  Geiger, Wolfgang von der Linden and Lilia Boeri","Importance of feature engineering and database selection in a machine
  learning model: A case study on carbon crystal structures","18 pages, 11 figures",,,,"cond-mat.mtrl-sci cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Drive towards improved performance of machine learning models has led to the
creation of complex features representing a database of condensed matter
systems. The complex features, however, do not offer an intuitive explanation
on which physical attributes do improve the performance. The effect of the
database on the performance of the trained model is often neglected. In this
work we seek to understand in depth the effect that the choice of features and
the properties of the database have on a machine learning application. In our
experiments, we consider the complex phase space of carbon as a test case, for
which we use a set of simple, human understandable and cheaply computable
features for the aim of predicting the total energy of the crystal structure.
Our study shows that (i) the performance of the machine learning model varies
depending on the set of features and the database, (ii) is not transferable to
every structure in the phase space and (iii) depends on how well structures are
represented in the database.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 08:54:01 GMT""}]","2021-02-02"
"2102.00192","Rajesh Kumar","Rajesh Kumar, Arvind Kumar","$\eta$ mesons in hot magnetized nuclear matter","34 pages, 11 figures",,,,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  The $\eta N$ interactions are investigated in the hot magnetized asymmetric
nuclear matter using chiral SU(3) model and chiral perturbation theory (ChPT).
In the chiral model, the in-medium properties of $\eta$-meson are calculated by
the medium modified scalar densities under the influence of an external
magnetic field. Further, in the combined approach of chiral model and ChPT,
off-shell contributions of $\eta N$ interactions are evaluated from the ChPT
effective $\eta N$ Lagrangian, and the in-medium effect of scalar densities are
incorporated from the chiral SU(3) model. We observe a significant effect of
magnetic field on the in-medium mass and optical potential of $\eta$ meson. We
observe a deeper mass-shift in the combined approach of ChPT and chiral model
compared to the effect of solo chiral SU(3) model. In both approaches, no
additional mass-shift is observed due to the uncharged nature of $\eta$ mesons
in the presence of magnetic field.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:09:40 GMT""}]","2021-02-02"
"2102.00193","Zizhe Wang","Zizhe Wang, Shaomeng Shen, Jiabei Mu","Coupling innovation method and feasibility analysis of garbage
  classification","a series significant mistakes were found. need a thorough rewrite",,,,"cs.LG cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  In order to solve the recent defect in garbage classification - including low
level of intelligence, low accuracy and high cost of equipment, this paper
presents a series of methods in identification and judgment in intelligent
garbage classification, including a material identification based on thermal
principle and non-destructive laser irradiation, another material
identification based on optical diffraction and phase analysis, a profile
identification which utilizes a scenery thermal image after PCA and histogram
correction, another profile identification which utilizes computer vision with
innovated data sets and algorithms. Combining AHP and Bayesian formula, the
paper innovates a coupling algorithm which helps to make a comprehensive
judgment of the garbage sort, based on the material and profile identification.
This paper also proposes a method for real-time space measurement of garbage
cans, which based on the characteristics of air as fluid, and analyses the
functions of air cleaning and particle disposing. Instead of the single use of
garbage image recognition, this paper provides a comprehensive method to judge
the garbage sort by material and profile identifications, which greatly
enhancing the accuracy and intelligence in garbage classification.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:15:46 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 03:18:51 GMT""},{""version"":""v3"",""created"":""Wed, 25 Aug 2021 04:02:51 GMT""}]","2021-08-26"
"2102.00194","Enore Guadagnini","Enore Guadagnini and Vittoria Urso","Renormalized Schwinger-Dyson functional","15 pages, 2 figures",,"10.1140/epjc/s10052-021-08868-5",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We consider the perturbative renormalization of the Schwinger-Dyson
functional, which is the generating functional of the expectation values of the
products of the composite operator given by the field derivative of the action.
It is argued that this functional plays an important role in the topological
Chern-Simons and BF quantum field theories. It is shown that, by means of the
renormalized perturbation theory, a canonical renormalization procedure for the
Schwinger-Dyson functional is obtained. The combinatoric structure of the
Feynman diagrams is illustrated in the case of scalar models. For the
Chern-Simons and the BF gauge theories, the relationship between the
renormalized Schwinger-Dyson functional and the generating functional of the
correlation functions of the gauge fields is produced.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:17:41 GMT""}]","2021-02-24"
"2102.00195","Zhengfang Duanmu","Zhengfang Duanmu, Wentao Liu, Zhongling Wang, Zhou Wang","Quantifying Visual Image Quality: A Bayesian View","24 pages, 6 figures. Annual Review of Vision Science",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image quality assessment (IQA) models aim to establish a quantitative
relationship between visual images and their perceptual quality by human
observers. IQA modeling plays a special bridging role between vision science
and engineering practice, both as a test-bed for vision theories and
computational biovision models, and as a powerful tool that could potentially
make profound impact on a broad range of image processing, computer vision, and
computer graphics applications, for design, optimization, and evaluation
purposes. IQA research has enjoyed an accelerated growth in the past two
decades. Here we present an overview of IQA methods from a Bayesian
perspective, with the goals of unifying a wide spectrum of IQA approaches under
a common framework and providing useful references to fundamental concepts
accessible to vision scientists and image processing practitioners. We discuss
the implications of the successes and limitations of modern IQA methods for
biological vision and the prospect for vision science to inform the design of
future artificial vision systems.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:34:23 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 04:03:20 GMT""}]","2021-02-23"
"2102.00196","Karn Watcharasupat","Karn Watcharasupat and Anh H. T. Nguyen and Ching-Hui Ooi and Andy W.
  H. Khong","Directional Sparse Filtering using Weighted Lehmer Mean for Blind
  Separation of Unbalanced Speech Mixtures","(c) 2021 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","Proceedings of the 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 4485-4489","10.1109/ICASSP39728.2021.9414336",,"eess.AS cs.LG cs.SD eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In blind source separation of speech signals, the inherent imbalance in the
source spectrum poses a challenge for methods that rely on single-source
dominance for the estimation of the mixing matrix. We propose an algorithm
based on the directional sparse filtering (DSF) framework that utilizes the
Lehmer mean with learnable weights to adaptively account for source imbalance.
Performance evaluation in multiple real acoustic environments show improvements
in source separation compared to the baseline methods.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:36:36 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 02:55:41 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 15:34:51 GMT""}]","2021-07-21"
"2102.00197","Nicola Melluso","Nicola Melluso, Andrea Bonaccorsi, Filippo Chiarello, Gualtiero
  Fantoni","Rapid detection of fast innovation under the pressure of COVID-19","Published in PlOs One in 12/31/2020","PLOS ONE (2020) 15(12): e0244175","10.1371/journal.pone.0244175",,"cs.IR econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Covid-19 has rapidly redefined the agenda of technological research and
development both for academics and practitioners. If the medical scientific
publication system has promptly reacted to this new situation, other domains,
particularly in new technologies, struggle to map what is happening in their
contexts. The pandemic has created the need for a rapid detection of
technological convergence phenomena, but at the same time it has made clear
that this task is impossible on the basis of traditional patent and publication
indicators. This paper presents a novel methodology to perform a rapid
detection of the fast technological convergence phenomenon that is occurring
under the pressure of the Covid-19 pandemic. The fast detection has been
performed thanks to the use of a novel source: the online blogging platform
Medium. We demonstrate that the hybrid structure of this social journalism
platform allows a rapid detection of innovation phenomena, unlike other
traditional sources. The technological convergence phenomenon has been modelled
through a network-based approach, analysing the differences of networks
computed during two time periods (pre and post COVID-19). The results led us to
discuss the repurposing of technologies regarding ""Remote Control"", ""Remote
Working"", ""Health"" and ""Remote Learning"".
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:37:40 GMT""}]","2021-02-02"
"2102.00198","Li Zhao","Weicong Xu, Li Zhao","A conjecture of thermo-gravitation based on geometry, classical physics
  and classical thermodynamics",,,,,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  One of the goals that physicists have been pursuing is to get the same
explanation from different angles for the same phenomenon, so as to realize the
unity of basic physical laws. Geometry, classical mechanics and classical
thermodynamics are three relatively old disciplines. Their research methods and
perspectives for the same phenomenon are quite different. However, there must
be some undetermined connections and symmetries among them. In previous
studies, there is a lack of horizontal analogical research on the basic
theories of different disciplines, but revealing the deep connections between
them will help to deepen the understanding of the existing system and promote
the common development of multiple disciplines. Using the method of analogy
analysis, five basic axioms of geometry, four laws of classical mechanics and
four laws of thermodynamics are compared and analyzed. The similarity and
relevance of basic laws between different disciplines is proposed. Then, by
comparing the axiom of circle in geometry and Newton's law of universal
gravitation, the conjecture of the law of thermo-gravitation is put forward.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:41:04 GMT""}]","2021-02-02"
"2102.00199","Nikita Puchkin","Denis Belomestny, Eric Moulines, Alexey Naumov, Nikita Puchkin, and
  Sergey Samsonov","Rates of convergence for density estimation with generative adversarial
  networks","43 pages",,,,"math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this work we undertake a thorough study of the non-asymptotic properties
of the vanilla generative adversarial networks (GANs). We prove a sharp oracle
inequality for the Jensen-Shannon (JS) divergence between the underlying
density $\mathsf{p}^*$ and the GAN estimate. We also study the rates of
convergence in the context of nonparametric density estimation. In particular,
we show that the JS-divergence between the GAN estimate and $\mathsf{p}^*$
decays as fast as $(\log{n}/n)^{2\beta/(2\beta+d)}$ where $n$ is the sample
size and $\beta$ determines the smoothness of $\mathsf{p}^*$. To the best of
our knowledge, this is the first result in the literature on density estimation
using vanilla GANs with JS convergence rates faster than $n^{-1/2}$ in the
regime $\beta > d/2$. Moreover, we show that the obtained rate is minimax
optimal (up to logarithmic factors) for the considered class of densities.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:59:14 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 16:22:03 GMT""},{""version"":""v3"",""created"":""Thu, 19 Jan 2023 08:29:23 GMT""}]","2023-01-20"
"2102.00200","Zhiqin Xu","Yaoyu Zhang, Tao Luo, Zheng Ma, and Zhi-Qin John Xu","Linear Frequency Principle Model to Understand the Absence of
  Overfitting in Neural Networks","to appear in Chinese Physics Letters",,"10.1088/0256-307X/38/3/038701",,"cs.LG physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Why heavily parameterized neural networks (NNs) do not overfit the data is an
important long standing open question. We propose a phenomenological model of
the NN training to explain this non-overfitting puzzle. Our linear frequency
principle (LFP) model accounts for a key dynamical feature of NNs: they learn
low frequencies first, irrespective of microscopic details. Theory based on our
LFP model shows that low frequency dominance of target functions is the key
condition for the non-overfitting of NNs and is verified by experiments.
Furthermore, through an ideal two-layer NN, we unravel how detailed microscopic
NN training dynamics statistically gives rise to a LFP model with quantitative
prediction power.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:11:37 GMT""}]","2021-05-26"
"2102.00201","Andres Ferraro","Andres Ferraro, Yuntae Kim, Soohyeon Lee, Biho Kim, Namjun Jo, Semi
  Lim, Suyon Lim, Jungtaek Jang, Sehwan Kim, Xavier Serra, Dmitry Bogdanov","Melon Playlist Dataset: a public dataset for audio-based playlist
  generation and music tagging","2021 IEEE International Conference on Acoustics, Speech and Signal
  Processing",,,,"cs.SD cs.IR cs.LG cs.MM eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One of the main limitations in the field of audio signal processing is the
lack of large public datasets with audio representations and high-quality
annotations due to restrictions of copyrighted commercial music. We present
Melon Playlist Dataset, a public dataset of mel-spectrograms for 649,091tracks
and 148,826 associated playlists annotated by 30,652 different tags. All the
data is gathered from Melon, a popular Korean streaming service. The dataset is
suitable for music information retrieval tasks, in particular, auto-tagging and
automatic playlist continuation. Even though the latter can be addressed by
collaborative filtering approaches, audio provides opportunities for research
on track suggestions and building systems resistant to the cold-start problem,
for which we provide a baseline. Moreover, the playlists and the annotations
included in the Melon Playlist Dataset make it suitable for metric learning and
representation learning.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:13:10 GMT""}]","2021-02-02"
"2102.00202","Mingze Ding","Mingze Ding and Jiahui Li and Mengyao Ma and Xiaopeng Fan","SNR-adaptive deep joint source-channel coding for wireless image
  transmission","Accepted in IEEE ICASSP 2021",,,,"eess.SP eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Considering the problem of joint source-channel coding (JSCC) for multi-user
transmission of images over noisy channels, an autoencoder-based novel deep
joint source-channel coding scheme is proposed in this paper. In the proposed
JSCC scheme, the decoder can estimate the signal-to-noise ratio (SNR) and use
it to adaptively decode the transmitted image. Experiments demonstrate that the
proposed scheme achieves impressive results in adaptability for different SNRs
and is robust to the decoder's estimation error of the SNR. To the best of our
knowledge, this is the first deep JSCC scheme that focuses on the adaptability
for different SNRs and can be applied to multi-user scenarios.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:30:04 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 12:28:09 GMT""}]","2021-02-03"
"2102.00203","Antonio Garc\'ia Mu\~noz","A. Garc\'ia Mu\~noz, L. Fossati, A. Youngblood, N. Nettelmann, D.
  Gandolfi, J. Cabrera, and H. Rauer","A Heavy Molecular Weight Atmosphere for the Super-Earth {\pi} Men c","40 pages","The Astrophysical Journal Letters, 907:L36 (14pp), 2021 February 1","10.3847/2041-8213/abd9b8",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Strongly irradiated exoplanets develop extended atmospheres that can be
utilized to probe the deeper planet layers. This connection is particularly
useful in the study of small exoplanets, whose bulk atmospheres are challenging
to characterize directly. Here, we report the 3.4{\sigma} detection of C II
ions during a single transit of the super-Earth {\pi} Men c in front of its
Sun-like host star. The transit depth and Doppler velocities are consistent
with the ions filling the planet's Roche lobe and moving preferentially away
from the star, an indication that they are escaping the planet. We argue that
{\pi} Men c possesses a thick atmosphere with abundant heavy volatiles ($>=$
50{\%} by mass of atmosphere) but that needs not be carbon rich. Our reasoning
relies upon cumulative evidence from the reported C II detection, the
nondetection of H I atoms in a past transit, modeling of the planet's interior,
and the assumption that the atmosphere, having survived the most active phases
of its Sun-like host star, will survive another 0.2-2 Gyr. Depending on the
current mass of atmosphere, {\pi} Men c may still transition into a bare rocky
core. Our findings confirm the hypothesized compositional diversity of small
exoplanets, and represent a milestone toward understanding the planets'
formation and evolution paths through the investigation of their extended
atmospheres.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:31:11 GMT""}]","2021-02-02"
"2102.00204","Zhicheng Wang","Zhi-Cheng Wang, Jared D. Rogers, Xiaohan Yao, Renee Nichols, Kemal
  Atay, Bochao Xu, Jacob Franklin, Ilya Sochnikov, Philip J. Ryan, Daniel
  Haskel, Fazel Tafti","Colossal Magnetoresistance without Mixed Valence in a Layered Phosphide
  Crystal",,"Adv. Mater. 2021, 2005755","10.1002/adma.202005755",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Materials with strong magnetoresistive responses are the backbone of
spintronic technology, magnetic sensors, and hard drives. Among them, manganese
oxides with a mixed valence and a cubic perovskite structure stand out due to
their colossal magnetoresistance (CMR). A double exchange interaction underlies
the CMR in manganates, whereby charge transport is enhanced when the spins on
neighboring Mn3+ and Mn4+ ions are parallel. Prior efforts to find different
materials or mechanisms for CMR resulted in a much smaller effect. Here we show
an enormous CMR at low temperatures in EuCd2P2 without manganese, oxygen, mixed
valence, or cubic perovskite structure. EuCd2P2 has a layered trigonal lattice
and exhibits antiferromagnetic ordering at 11 K. The magnitude of CMR (104
percent) in as-grown crystals of EuCd2P2 rivals the magnitude in optimized thin
films of manganates. Our magnetization, transport, and synchrotron X-ray data
suggest that strong magnetic fluctuations are responsible for this phenomenon.
The realization of CMR at low temperatures without heterovalency leads to a new
regime for materials and technologies related to antiferromagnetic spintronics.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:34:52 GMT""}]","2021-02-02"
"2102.00205","Hao Wang","Gang Peng, Zhenyu Ren, Hao Wang, Xinde Li","A self-supervised learning-based 6-DOF grasp planning method for
  manipulator",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To realize a robust robotic grasping system for unknown objects in an
unstructured environment, large amounts of grasp data and 3D model data for the
object are required, the sizes of which directly affect the rate of successful
grasps. To reduce the time cost of data acquisition and labeling and increase
the rate of successful grasps, we developed a self-supervised learning
mechanism to control grasp tasks performed by manipulators. First, a
manipulator automatically collects the point cloud for the objects from
multiple perspectives to increase the efficiency of data acquisition. The
complete point cloud for the objects is obtained by utilizing the hand-eye
vision of the manipulator, and the TSDF algorithm. Then, the point cloud data
for the objects is used to generate a series of six-degrees-of-freedom grasp
poses, and the force-closure decision algorithm is used to add the grasp
quality label to each grasp pose to realize the automatic labeling of grasp
data. Finally, the point cloud in the gripper closing area corresponding to
each grasp pose is obtained; it is then used to train the grasp-quality
classification model for the manipulator. The results of data acquisition
experiments demonstrate that the proposed method allows high-quality data to be
obtained. The simulated results prove the effectiveness of the proposed
grasp-data acquisition method. The results of performing actual grasping
experiments demonstrate that the proposed self-supervised learning method can
increase the rate of successful grasps for the manipulator.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:35:38 GMT""}]","2021-02-02"
"2102.00206","Nazaret Ortiz Hernandez","N. Ortiz Hernandez, Z. Salman, T. Prokscha, A. Suter, J. R. L.
  Mardegan, S. Moser, A. Zakharova, C. Piamonteze, und U. Staub","Magnetic order of tetragonal CuO ultra-thin films","11 Figures","Phys. Rev. B 103, 224429 (2021)","10.1103/PhysRevB.103.224429",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We present a detailed low-energy muon spin rotation and x-ray magnetic
circular dichroism (XMCD) investigation of the magnetic structure in ultra-thin
tetragonal (T)-CuO films. The measured muon-spin polarization decay indicates
an antiferromagnetic (AFM) order with a transition temperature higher than
200K. The XMCD signal obtained around the Cu $L_{2,3}$ edges indicates the
presence of pinned Cu$^{2+}$ moments that are parallel to the sample surface,
and additionally, isotropic paramagnetic moments. The pinning of some of the Cu
moments is caused by an AFM ordering consisting of moments that lie most likely
in the plane of the film. Moreover, pinned moments show a larger orbital
magnetic moment contribution with an approximate ratio of $m_{orb}/m_{spin} =
2$, indicating that these spins are located at sites with reduced symmetry.
Some fractions of the pinned moments remain pinned from an AFM background even
at 360K, indicating that $T_N >$ 360K. A simple model could explain
qualitatively these experimental findings; however, it is in contrast to
theoretical predictions, showing that the magnetic properties of ultra-thin
T-CuO films differ from bulk expectations and is more complex.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:39:45 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 10:08:03 GMT""}]","2021-06-30"
"2102.00207","Boris N. Narozhny","B.N. Narozhny and I.V. Gornyi","Hydrodynamic approach to electronic transport in graphene: energy
  relaxation","7 pages","Frontiers in Physics 9, 640649 (2021)","10.3389/fphy.2021.640649",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el physics.flu-dyn physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In nearly compensated graphene, disorder-assisted electron-phonon scattering
or ""supercollisions"" are responsible for both quasiparticle recombination and
energy relaxation. Within the hydrodynamic approach, these processes contribute
weak decay terms to the continuity equations at local equilibrium, i.e., at the
level of ""ideal"" hydrodynamics. Here we report the derivation of the decay term
due to weak violation of energy conservation. Such terms have to be considered
on equal footing with the well-known recombination terms due to nonconservation
of the number of particles in each band. At high enough temperatures in the
""hydrodynamic regime"" supercollisions dominate both types of the interaction).
We also discuss the contribution of supercollisions to the heat transfer
equation (generalizing the continuity equation for the energy density in
viscous hydrodynamics).
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:42:29 GMT""},{""version"":""v2"",""created"":""Sat, 24 Apr 2021 15:34:37 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 21:31:09 GMT""}]","2021-04-30"
"2102.00208","Christian M. Dahl","Christian M. Dahl, Emil N. S{\o}rensen","Time Series (re)sampling using Generative Adversarial Networks",,,,,"cs.LG econ.EM stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel bootstrap procedure for dependent data based on Generative
Adversarial networks (GANs). We show that the dynamics of common stationary
time series processes can be learned by GANs and demonstrate that GANs trained
on a single sample path can be used to generate additional samples from the
process. We find that temporal convolutional neural networks provide a suitable
design for the generator and discriminator, and that convincing samples can be
generated on the basis of a vector of iid normal noise. We demonstrate the
finite sample properties of GAN sampling and the suggested bootstrap using
simulations where we compare the performance to circular block bootstrapping in
the case of resampling an AR(1) time series processes. We find that resampling
using the GAN can outperform circular block bootstrapping in terms of empirical
coverage.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:58:15 GMT""}]","2021-02-02"
"2102.00209","Anthony Bourached","George Cann, Anthony Bourached, Ryan-Rhys Griffiths, and David Stork","Resolution enhancement in the recovery of underdrawings via style
  transfer by generative adversarial deep neural networks","Accepted for Publication at Computer Vision and Art Analysis, IS&T,
  Springfield, VA, 2021",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply generative adversarial convolutional neural networks to the problem
of style transfer to underdrawings and ghost-images in x-rays of fine art
paintings with a special focus on enhancing their spatial resolution. We build
upon a neural architecture developed for the related problem of synthesizing
high-resolution photo-realistic image from semantic label maps. Our neural
architecture achieves high resolution through a hierarchy of generators and
discriminator sub-networks, working throughout a range of spatial resolutions.
This coarse-to-fine generator architecture can increase the effective
resolution by a factor of eight in each spatial direction, or an overall
increase in number of pixels by a factor of 64. We also show that even just a
few examples of human-generated image segmentations can greatly improve --
qualitatively and quantitatively -- the generated images. We demonstrate our
method on works such as Leonardo's Madonna of the carnation and the
underdrawing in his Virgin of the rocks, which pose several special problems in
style transfer, including the paucity of representative works from which to
learn and transfer style information.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:11:59 GMT""}]","2021-02-02"
"2102.00210","Nicolas Cherroret","Nicolas Cherroret, Thibault Scoquart and Dominique Delande","Coherent multiple scattering of out-of-equilibrium interacting Bose
  gases",,"Annals of Physics, 2021, 168543","10.1016/j.aop.2021.168543",,"cond-mat.quant-gas cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review recent theoretical and experimental progresses in the coherent
multiple scattering of weakly interacting disordered Bose gases. These systems
have allowed, in the recent years, a characterization of weak and strong
localization phenomena in disorder at an unprecedented level of control. In
this paper, we first discuss the main physical concepts and recent experimental
achievements associated with a few emblematic ""mesoscopic"" effects in disorder
like coherent back scattering, coherent forward scattering or mesoscopic echos,
focusing on the context of out-of-equilibrium cold-atom setups. We then address
the role of weak particle interactions and explain how, depending on their
relative strength with respect to the disorder and on the time scales probed,
they can give rise to a dephasing mechanism for weak localization, thermalize a
non-equilibrium Bose gas or make it become a superfluid.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:31:09 GMT""}]","2021-06-22"
"2102.00211","Masato Ishizuka","Masato Ishizuka, Hajime Kawahara, Stevanus K. Nugroho, Yui Kawashima,
  Teruyuki Hirano, and Motohide Tamura","Neutral metals in the atmosphere of HD149026b","Accepted for publication in AJ",,"10.3847/1538-3881/abdb25",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent progress in high-dispersion spectroscopy has revealed the presence of
vaporized heavy metals and ions in the atmosphere of hot Jupiters whose dayside
temperature is larger than 2000 K, categorized as ultra hot Jupiters (UHJs).
Using the archival data of high resolution transmission spectroscopy obtained
with the Subaru telescope, we searched for neutral metals in HD149026b, a hot
Jupiter cooler than UHJs. By removing stellar and telluric absorption and using
a cross-correlation technique, we report tentative detection of neutral
titanium with 4.4 sigma and a marginal signal of neutral iron with 2.8 sigma in
the atmosphere. This is the first detection of neutral titanium in an
exoplanetary atmosphere. In this temperature range, titanium tends to form
titanium oxide (TiO). The fact that we did not detect any signal from TiO
suggests that the C/O ratio in the atmosphere is higher than the solar value.
The detection of metals in the atmosphere of hot Jupiters cooler than UHJs will
be useful for understanding the atmospheric structure and formation history of
hot Jupiters.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:35:37 GMT""}]","2021-03-10"
"2102.00212","Jaime Moraga","Jaime Moraga (1), Gurbet Gurkan (1), Sebnem Duzgun (1) ((1) Colorado
  School of Mines, Golden, Colorado)","Monitoring the Impacts of a Tailings Dam Failure Using Satellite Images","11 pages, 7 figures, Submitted to USSD 2020 Annual Conference
  Preprint, Denver, CO, 2020-04-09",,"10.13140/RG.2.2.18504.75529",,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Monitoring dam failures using satellite images provides first responders with
efficient management of early interventions. It is also equally important to
monitor spatial and temporal changes in the inundation area to track the
post-disaster recovery. On January 25th, 2019, the tailings dam of the
C\'orrego do Feij\~ao iron ore mine, located in Brumadinho, Brazil, collapsed.
This disaster caused more than 230 fatalities and 30 missing people leading to
damage on the order of multiple billions of dollars. This study uses Sentinel-2
satellite images to map the inundation area and assess and delineate the land
use and land cover impacted by the dam failure. The images correspond to data
captures from January 22nd (3 days before), and February 02 (7 days after the
collapse). Satellite images of the region were classified for before and
aftermath of the disaster implementing a machine learning algorithm. In order
to have sufficient land cover types to validate the quality and accuracy of the
algorithm, 7 classes were defined: mine, forest, build-up, river, agricultural,
clear water, and grassland. The developed classification algorithm yielded a
high accuracy (99%) for the image before the collapse. This paper determines
land cover impact using two different models, 1) by using the trained network
in the ""after"" image, and 2) by creating a second network, trained in a subset
of points of the ""after"" image, and then comparing the land cover results of
the two trained networks. In the first model, applying the trained network to
the ""after"" image, the accuracy is still high (86%), but lower than using the
second model (98%). This strategy can be applied at a low cost for monitoring
and assessment by using openly available satellite information and, in case of
dam collapse or with a larger budget, higher resolution and faster data can be
obtained by fly-overs on the area of concern.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:35:47 GMT""}]","2021-02-02"
"2102.00213","Prabir Banik","Prabir Banik, Arunava Bhadra, Abhijit Bhattacharyya","Interpreting correlated observations of cosmic rays and gamma-rays from
  Centaurus A with a proton blazar inspired model","9 pages, 3 figures","Monthly Notices of the Royal Astronomical Society, Volume 500,
  Issue 1, January 2021, Pages 1087-1094","10.1093/mnras/staa3343",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The nearest active radio galaxy Centaurus (Cen) A is a gamma-ray emitter in
GeV to TeV energy scale. The High Energy Stereoscopic System (H.E.S.S.) and
non-simultaneous Fermi-LAT observation indicate an unusual spectral hardening
above few GeV energies in the gamma-ray spectrum of Cen A. Very recently the
H.E.S.S. observatory resolved the kilo parsec (kpc)-scale jets in Centaurus A
at TeV energies. On the other hand, the Pierre Auger Observatory (PAO) detects
a few ultra high energy cosmic ray (UHECR) events from Cen-A. The proton blazar
inspired model, which considers acceleration of both electrons and hadronic
cosmic rays in AGN jet, can explain the observed coincident high energy
neutrinos and gamma rays from Ice-cube detected AGN jets. Here we have employed
the proton blazar inspired model to explain the observed GeV to TeV gamma-ray
spectrum features including the spectrum hardening at GeV energies along with
the PAO observation on cosmic rays from Cen-A. Our findings suggest that the
model can explain consistently the observed electromagnetic spectrum in
combination with the appropriate number of UHECRs from Cen A.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:52:41 GMT""}]","2021-02-02"
"2102.00214","Nikita Desai Prof","Nikita P. Desai, Prof.(Dr.) Vipul K. Dabhi","Taxonomic survey of Hindi Language NLP systems",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Natural Language processing (NLP) represents the task of automatic handling
of natural human language by machines.There is large spectrum of possible
applications of NLP which help in automating tasks like translating text from
one language to other, retrieving and summarizing data from very huge
repositories, spam email filtering, identifying fake news in digital media,
find sentiment and feedback of people, find political opinions and views of
people on various government policies, provide effective medical assistance
based on past history records of patient etc. Hindi is the official language of
India with nearly 691 million users in India and 366 million in rest of world.
At present, a number of government and private sector projects and researchers
in India and abroad, are working towards developing NLP applications and
resources for Indian languages. This survey gives a report of the resources and
applications available for Hindi language NLP.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:53:56 GMT""}]","2021-02-02"
"2102.00215","Claudio Puglia","Claudio Puglia, Giorgio De Simoni, Francesco Giazotto","Gate control of superconductivity in mesoscopic all-metallic devices",,"Materials 2021, 14(5), 1243 (2021)","10.3390/ma14051243",,"cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  It was recently demonstrated the possibility to tune, through the application
of a control gate voltage, the superconducting properties of mesoscopic devices
based on Bardeen-Cooper-Schrieffer metals. In spite of the several experimental
evidence obtained on different materials and geometries, a description of the
microscopic mechanism at the basis of such unconventional effect has not been
provided yet. This work discusses the technological potential of gate control
of superconductivity in metallic superconductors and revises the experimental
results which provide information regarding a possible thermal origin of the
effect: in the first place, we review experiments performed on high critical
temperature elemental superconductors (niobium and vanadium) and show how
devices based on these materials can be exploited to realize basic electronic
tools such as, e. g., a half-wave rectifier. In a second part, we discuss the
origin of the gating effect by showing the gate-driven suppression of the
supercurrent in a suspended titanium wire and by providing a comparison between
thermal and electric switching current probability distributions. Furthermore,
we discuss the cold field-emission of electrons from the gate by means of
finite element simulations and compare the results with experimental data.
Finally, the presented data provide a strong indication regarding the
unlikelihood of thermal origin of the gating effect.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:09:44 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 22:02:21 GMT""}]","2021-03-09"
"2102.00216","Pingliang Huang","Pingliang Huang and Youde Wang","Gradient Estimates And Liouville Theorems For A Class of Nonlinear
  Elliptic Equations",,,,,"math.AP","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, first we study carefully the positive solutions to $\Delta
u+\lambda_{1}u\ln u +\lambda_{2}u^{b+1}=0$ defined on a complete noncompact
Riemannian manifold $(M, g)$ with $Ric(g)\geq -Kg$, which can be regarded as
Lichnerowicz-type equations, and obtain the gradient estimates of positive
solutions to these equations which do not depend on the bounds of the solutions
and the Laplacian of the distance function on $(M, g)$. Then, we extend our
techniques to a class of more general semilinear elliptic equations $\Delta
u(x)+uh(\ln u)=0$ and obtain some similar results under some suitable analysis
conditions on these equations. Moreover, we also obtain some Liouville-type
theorems for these equations when $Ric(g)\geq 0$ and establish some Harnack
inequalities as consequences.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:17:25 GMT""}]","2021-02-02"
"2102.00217","Ana Paula Luz","V. S. Pinto, D. S. Fini, V. C. Miguel, V. C. Pandolfelli, M. H.
  Moreira, T. Venancio, A. P. Luz","Fast drying of high-alumina MgO-bonded refractory castables",,"Ceramics International 46 [8] (2020) 11137-11148","10.1016/j.ceramint.2020.01.134",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Refractory producers face many challenges in terms of producing
MgO-containing castables due to the high likelihood of magnesia to hydrate in
contact with water, resulting in Mg(OH)2 generation. The expansive feature of
this transformation affects the performance of such refractories, as (i) if
this hydrated phase is not accommodated in the formed microstructure, ceramic
linings with cracks and low green mechanical strength will be obtained; and
(ii) if crack-free pieces are prepared, they should present low porosity and
reduced permeability, which require special attention when heating these
materials. This work investigated the ability of various additives in the
optimization of the drying behavior of Al2O3-MgO castables. Vibratable
compositions were tested after incorporating polymeric fibers (PF), an organic
salt (OAS), SiO2-based additive (SM) or permeability enhancing active compound
(MP) into the dry-mixtures. Various experimental measurements were performed to
infer the role of the drying agents to prevent the samples explosion and
whether they would also influence other properties of the castables. As
observed, OAS and MP helped to inhibit the MgO-bonded samples explosion even
under severe heating conditions (2-20C/min) and increased their green
mechanical strength and slag infiltration resistance when compared to the
additive-free composition. On the other hand, the addition of polymeric fibers
(PF) or silica-based compound (SM) to the formulations was not able to prevent
the castables explosion when using a high heating rate and other side effects
could also be observed when testing these materials. Thus, the selection of
suitable drying agents is a key issue, as they may allow the development of
MgO-bonded castables with enhanced properties and lower spalling risk during
their first thermal treatment.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:33:07 GMT""}]","2021-02-02"
"2102.00218","Ari Pakman","Ari Pakman, Amin Nejatbakhsh, Dar Gilboa, Abdullah Makkeh, Luca
  Mazzucato, Michael Wibral, Elad Schneidman","Estimating the Unique Information of Continuous Variables",,"NeurIPS 2021",,,"cs.IT math.IT stat.CO","http://creativecommons.org/licenses/by/4.0/","  The integration and transfer of information from multiple sources to multiple
targets is a core motive of neural systems. The emerging field of partial
information decomposition (PID) provides a novel information-theoretic lens
into these mechanisms by identifying synergistic, redundant, and unique
contributions to the mutual information between one and several variables.
While many works have studied aspects of PID for Gaussian and discrete
distributions, the case of general continuous distributions is still uncharted
territory. In this work we present a method for estimating the unique
information in continuous distributions, for the case of one versus two
variables. Our method solves the associated optimization problem over the space
of distributions with fixed bivariate marginals by combining copula
decompositions and techniques developed to optimize variational autoencoders.
We obtain excellent agreement with known analytic results for Gaussians, and
illustrate the power of our new approach in several brain-inspired neural
models. Our method is capable of recovering the effective connectivity of a
chaotic network of rate neurons, and uncovers a complex trade-off between
redundancy, synergy and unique information in recurrent networks trained to
solve a generalized XOR task.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:34:42 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 19:41:17 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 09:34:39 GMT""},{""version"":""v4"",""created"":""Wed, 23 Jun 2021 07:33:21 GMT""},{""version"":""v5"",""created"":""Wed, 27 Oct 2021 02:16:04 GMT""}]","2021-10-28"
"2102.00219","Artto Aurola MSc","Artto Aurola, Vladislav Marochkin, and Mika Laiho","Novel depletion mode JFET based low static power complementary circuit
  technology","23 pages, 18 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The lack of an easily realizable complementary circuit technology offering
low static power consumption has been limiting the utilization of other
semiconductor materials than silicon. In this publication, a novel depletion
mode JFET based complementary circuit technology is presented and herein after
referred to as Complementary Semiconductor (CS) circuit technology. The fact
that JFETs are pure semiconductor devices, i.e. a carefully optimized Metal
Oxide Semiconductor (MOS) gate stack is not required, facilitates the
implementation of CS circuit technology to many semiconductor materials, like
e.g. germanium and silicon carbide. Furthermore, when the CS circuit technology
is idle there are neither conductive paths between nodes that are biased at
different potentials nor forward biased p-n junctions and thus it enables low
static power consumption. Moreover, the fact that the operation of depletion
mode JFETs does not necessitate the incorporation of forward biased p-n
junctions means that CS circuit technology is not limited to wide band-gap
semiconductor materials, low temperatures, and/or low voltage spans. In this
paper the operation of the CS logic is described and proven via simulations.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:40:31 GMT""}]","2021-02-02"
"2102.00220","John Lee Grenfell","Stefanie Gebauer, Iva Vilovi\'c, John Lee Grenfell, Fabian Wunderlich,
  Franz Schreier, Heike Rauer","Influence of Biomass Emissions upon Habitability, Biosignatures and
  Detectability in Earth-like Atmospheres",,,"10.3847/1538-4357/abd9cc",,"astro-ph.EP physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate atmospheric responses of modeled hypothetical Earth-like
planets in the habitable zone of the M-dwarf AD Leonis to reduced oxygen (O2),
removed biomass (dead Earth), varying carbon dioxide (CO2) and surface relative
humidity (sRH). Results suggest large O2 differences between the reduced O2 and
dead scenarios in the lower but not the upper atmosphere. Ozone (O3) and
nitrous oxide (N2O) also show this behavior. Methane depends on hydroxyl (OH),
its main sink. Abiotic production of N2O occurs in the upper layers.
Chloromethane (CH3Cl) decreases everywhere on decreasing biomass. Changing CO2
(from x1 to x100 present atmospheric level (PAL)) and surface relative humidity
(sRH) (from 0.1 percent to 100 percent) does not influence CH3Cl as much as
lowering biomass. Therefore, CH3Cl can be considered a good biosignature.
Changing sRH and CO2 has a greater influence on temperature than O2 and biomass
alone. Changing the biomass produces ~6 kilometer (km) in effective height (H)
in transmission compared with changing CO2 and sRH ( about 25km). In
transmission O2 is discernible at 0.76 microns for greater than 0.1 PAL. The O3
9.6 micron band was weak for the low O2 runs and difficult to discern from dead
Earth, however O3 at 0.3 microns could serve as an indicator to distinguish
between reduced O2 and dead Earth. Spectral features of N2O and CH3Cl
corresponded to some km H. CH4 could be detectable tens of parsecs away with
ELT except for the 10-4 and 10-6 PAL O2 scenarios. O2 is barely detectable for
the 1 PAL O2 case and unfeasible at lower abundances.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:43:42 GMT""}]","2021-03-17"
"2102.00221","Jiawei Zhang","Jiawei Zhang, Yanchun Zhang, Xiaowei Xu","ObjectAug: Object-level Data Augmentation for Semantic Image
  Segmentation","8 pages, 7 figures, 9 tables, Accepted by IJCNN2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic image segmentation aims to obtain object labels with precise
boundaries, which usually suffers from overfitting. Recently, various data
augmentation strategies like regional dropout and mix strategies have been
proposed to address the problem. These strategies have proved to be effective
for guiding the model to attend on less discriminative parts. However, current
strategies operate at the image level, and objects and the background are
coupled. Thus, the boundaries are not well augmented due to the fixed semantic
scenario. In this paper, we propose ObjectAug to perform object-level
augmentation for semantic image segmentation. ObjectAug first decouples the
image into individual objects and the background using the semantic labels.
Next, each object is augmented individually with commonly used augmentation
methods (e.g., scaling, shifting, and rotation). Then, the black area brought
by object augmentation is further restored using image inpainting. Finally, the
augmented objects and background are assembled as an augmented image. In this
way, the boundaries can be fully explored in the various semantic scenarios. In
addition, ObjectAug can support category-aware augmentation that gives various
possibilities to objects in each category, and can be easily combined with
existing image-level augmentation methods to further boost performance.
Comprehensive experiments are conducted on both natural image and medical image
datasets. Experiment results demonstrate that our ObjectAug can evidently
improve segmentation performance.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:46:20 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 09:48:49 GMT""}]","2021-04-22"
"2102.00222","Bo Li","Hui Yu, Bo Li, Shaoxia Chen, Mingzhe Guo","Resonant Damping of Kink Modes in Solar Coronal Slabs","Accepted for publication in Solar Physics, subject to further
  stylistic changes",,"10.1007/s11207-021-01839-9",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We examine resonantly damped kink modes in straight coronal slabs, paying
special attention to the effects of the formulation for the transverse density
distribution (""profile""). We work in the framework of pressure-less,
gravity-free, resistive magnetohydrodynamics, and we adopt the
dissipative-eigenmode perspective. The density profile is restricted to be
one-dimensional, but nonetheless allowed to take a generic form characterized
by a continuous transition layer connecting a uniform interior to a uniform
exterior. A dispersion relation (DR) is derived in the thin-boundary limit,
yielding analytical expressions for the eigenfrequencies that generalize known
results in various aspects. We find that the analytical rather than the
numerical solutions to the thin-boundary DR serve better the purpose for
validating our self-consistent resistive solutions. More importantly, the
eigenfrequencies are found to be sensitive to profile specifications, the ratio
of the imaginary to the real part readily varying by a factor of two when one
profile is used in place of another. Our eigenmode computations are also
examined in the context of impulsively excited kink waves, suggesting the
importance of resonant absorption for sufficiently oblique components when the
spatial scale of the exciter is comparable to the slab half-width.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:05:29 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 15:05:20 GMT""}]","2021-06-23"
"2102.00223","Patrick Diehl","Patrick Diehl and Dominic Marcello and Parsa Amini and Hartmut Kaiser
  and Sagiv Shiber and Geoffrey C. Clayton and Juhan Frank and Gregor Dai{\ss}
  and Dirk Pfl\""uger and David Eder and Alice Koniges and Kevin Huck","Performance Measurements within Asynchronous Task-based Runtime Systems:
  A Double White Dwarf Merger as an Application",,,"10.1109/MCSE.2021.3073626",,"cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Analyzing performance within asynchronous many-task-based runtime systems is
challenging because millions of tasks are launched concurrently. Especially for
long-term runs the amount of data collected becomes overwhelming. We study HPX
and its performance-counter framework and APEX to collect performance data and
energy consumption. We added HPX application-specific performance counters to
the Octo-Tiger full 3D AMR astrophysics application. This enables the combined
visualization of physical and performance data to highlight bottlenecks with
respect to different solvers. We examine the overhead introduced by these
measurements, which is around 1%, with respect to the overall application
runtime. We perform a convergence study for four different levels of refinement
and analyze the application's performance with respect to adaptive grid
refinement. The measurements' overheads are small, enabling the combined use of
performance data and physical properties with the goal of improving the code's
performance. All of these measurements were obtained on NERSC's Cori, Louisiana
Optical Network Infrastructure's QueenBee2, and Indiana University's Big Red 3.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:08:30 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 01:16:11 GMT""},{""version"":""v3"",""created"":""Thu, 29 Apr 2021 02:09:31 GMT""},{""version"":""v4"",""created"":""Wed, 9 Jun 2021 14:57:35 GMT""}]","2021-06-10"
"2102.00224","Young Sul Cho","Yejun Kang and Young Sul Cho","Scaling behavior of information entropy in explosive percolation
  transitions","7 figures, published version","Phys. Rev. E 104, 014310 (2021)","10.1103/PhysRevE.104.014310",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An explosive percolation transition is the abrupt emergence of a giant
cluster at a threshold caused by a suppression of the growth of large clusters.
In this paper, we consider the information entropy of the cluster size
distribution, which is the probability distribution for the size of a randomly
chosen cluster. It has been reported that information entropy does not reach
its maximum at the threshold in explosive percolation models, a result
seemingly contrary to other previous results that the cluster size distribution
shows power-law behavior and the cluster size diversity (number of distinct
cluster sizes) is maximum at the threshold. Here, we show that this phenomenon
is due to that the scaling form of the cluster size distribution is given
differently below and above the threshold. We also establish the scaling
behaviors of the first and second derivatives of the information entropy near
the threshold to explain why the first derivative has a negative minimum at the
threshold and the second derivative diverges negatively (positively) at the
left (right) limit of the threshold, as predicted through previous simulation.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:12:11 GMT""},{""version"":""v2"",""created"":""Fri, 23 Jul 2021 08:42:49 GMT""}]","2021-07-28"
"2102.00225","Tong Guo","Tong Guo","Learning From How Humans Correct",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In industry NLP application, our manually labeled data has a certain number
of noisy data. We present a simple method to find the noisy data and re-label
them manually, meanwhile we collect the correction information. Then we present
novel method to incorporate the human correction information into deep learning
model. Human know how to correct noisy data. So the correction information can
be inject into deep learning model. We do the experiment on our own text
classification dataset, which is manually labeled, because we re-label the
noisy data in our dataset for our industry application. The experiment result
shows that our method improve the classification accuracy from 91.7% to 92.5%.
The 91.7% accuracy is trained on the corrected dataset, which improve the
baseline from 83.3% to 91.7%.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:13:50 GMT""},{""version"":""v10"",""created"":""Sat, 24 Dec 2022 08:45:12 GMT""},{""version"":""v11"",""created"":""Thu, 29 Dec 2022 02:20:46 GMT""},{""version"":""v12"",""created"":""Tue, 31 Jan 2023 01:19:59 GMT""},{""version"":""v13"",""created"":""Thu, 9 Feb 2023 13:23:32 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 02:19:10 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 02:01:56 GMT""},{""version"":""v4"",""created"":""Mon, 13 Sep 2021 02:51:49 GMT""},{""version"":""v5"",""created"":""Tue, 26 Oct 2021 02:26:14 GMT""},{""version"":""v6"",""created"":""Mon, 8 Nov 2021 02:37:55 GMT""},{""version"":""v7"",""created"":""Thu, 24 Mar 2022 01:18:01 GMT""},{""version"":""v8"",""created"":""Mon, 16 May 2022 06:30:48 GMT""},{""version"":""v9"",""created"":""Sat, 10 Dec 2022 01:50:30 GMT""}]","2023-02-10"
"2102.00226","Matteo Macchini","Matteo Macchini, Manana Lortkipanidze, Fabrizio Schiano and Dario
  Floreano","The Impact of Virtual Reality and Viewpoints in Body Motion Based Drone
  Teleoperation",,,,,"cs.RO cs.HC","http://creativecommons.org/licenses/by/4.0/","  The operation of telerobotic systems can be a challenging task, requiring
intuitive and efficient interfaces to enable inexperienced users to attain a
high level of proficiency. Body-Machine Interfaces (BoMI) represent a promising
alternative to standard control devices, such as joysticks, because they
leverage intuitive body motion and gestures. It has been shown that the use of
Virtual Reality (VR) and first-person view perspectives can increase the user's
sense of presence in avatars. However, it is unclear if these beneficial
effects occur also in the teleoperation of non-anthropomorphic robots that
display motion patterns different from those of humans. Here we describe
experimental results on teleoperation of a non-anthropomorphic drone showing
that VR correlates with a higher sense of spatial presence, whereas viewpoints
moving coherently with the robot are associated with a higher sense of
embodiment. Furthermore, the experimental results show that spontaneous body
motion patterns are affected by VR and viewpoint conditions in terms of
variability, amplitude, and robot correlates, suggesting that the design of
BoMIs for drone teleoperation must take into account the use of Virtual Reality
and the choice of the viewpoint.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:33:21 GMT""}]","2021-02-02"
"2102.00227","Radu Dogaru","Radu Dogaru and Ioana Dogaru","NL-CNN: A Resources-Constrained Deep Learning Model based on Nonlinear
  Convolution","4 pages, reprint submitted to ATEE 2021 conference",,,,"cs.LG cs.CV cs.NE","http://creativecommons.org/licenses/by/4.0/","  A novel convolution neural network model, abbreviated NL-CNN is proposed,
where nonlinear convolution is emulated in a cascade of convolution +
nonlinearity layers. The code for its implementation and some trained models
are made publicly available. Performance evaluation for several widely known
datasets is provided, showing several relevant features: i) for small / medium
input image sizes the proposed network gives very good testing accuracy, given
a low implementation complexity and model size; ii) compares favorably with
other widely known resources-constrained models, for instance in comparison to
MobileNetv2 provides better accuracy with several times less training times and
up to ten times less parameters (memory occupied by the model); iii) has a
relevant set of hyper-parameters which can be easily and rapidly tuned due to
the fast training specific to it. All these features make NL-CNN suitable for
IoT, smart sensing, bio-medical portable instrumentation and other applications
where artificial intelligence must be deployed in energy-constrained
environments.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:38:42 GMT""}]","2021-02-03"
"2102.00228","Chengwei Zhang","Chengwei Zhang, Yangzhou Jiang, Wei Zhang, Chengyu Gu","MUSE: Multi-Scale Temporal Features Evolution for Knowledge Tracing","the AAAI-2021 workshop on Imagining Post-COVID Education with AI",,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Transformer based knowledge tracing model is an extensively studied problem
in the field of computer-aided education. By integrating temporal features into
the encoder-decoder structure, transformers can processes the exercise
information and student response information in a natural way. However, current
state-of-the-art transformer-based variants still share two limitations. First,
extremely long temporal features cannot well handled as the complexity of
self-attention mechanism is O(n2). Second, existing approaches track the
knowledge drifts under fixed a window size, without considering different
temporal-ranges. To conquer these problems, we propose MUSE, which is equipped
with multi-scale temporal sensor unit, that takes either local or global
temporal features into consideration. The proposed model is capable to capture
the dynamic changes in users knowledge states at different temporal-ranges, and
provides an efficient and powerful way to combine local and global features to
make predictions. Our method won the 5-th place over 3,395 teams in the Riiid
AIEd Challenge 2020.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:52:46 GMT""}]","2021-02-02"
"2102.00229","Or Katz","Or Katz, Roy Shaham, Ofer Firstenberg","Coupling light to a nuclear spin gas with a two-photon linewidth of five
  millihertz",,"Science Advances Vol. 7, no. 14, eabe9164 (2021)","10.1126/sciadv.abe9164",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nuclear spins of noble gases feature extremely long coherence times but are
inaccessible to optical photons. Here we realize a coherent interface between
light and noble-gas spins that is mediated by alkali atoms. We demonstrate the
optical excitation of the noble-gas spins and observe the coherent back-action
on the light in the form of high-contrast two-photon spectra. We report on a
record two-photon linewidth of 5$\pm$0.7 mHz (millihertz) above
room-temperature, corresponding to a one-minute coherence time. This experiment
provides a demonstration of coherent bi-directional coupling between light and
noble-gas spins, rendering their long-lived spin coherence accessible for
manipulations in the optical domain.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:57:17 GMT""}]","2021-04-06"
"2102.00230","Raviraj Joshi","Pranali Bora, Tulika Awalgaonkar, Himanshu Palve, Raviraj Joshi, Purvi
  Goel","ICodeNet -- A Hierarchical Neural Network Approach for Source Code
  Author Identification","Accepted at ICMLC 2021",,"10.1145/3457682.3457709",,"cs.LG cs.CV cs.IR cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the open-source revolution, source codes are now more easily accessible
than ever. This has, however, made it easier for malicious users and
institutions to copy the code without giving regards to the license, or credit
to the original author. Therefore, source code author identification is a
critical task with paramount importance. In this paper, we propose ICodeNet - a
hierarchical neural network that can be used for source code file-level tasks.
The ICodeNet processes source code in image format and is employed for the task
of per file author identification. The ICodeNet consists of an ImageNet trained
VGG encoder followed by a shallow neural network. The shallow network is based
either on CNN or LSTM. Different variations of models are evaluated on a source
code author classification dataset. We have also compared our image-based
hierarchical neural network model with simple image-based CNN architecture and
text-based CNN and LSTM models to highlight its novelty and efficiency.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:05:22 GMT""}]","2021-06-24"
"2102.00231","Wei Zhong","Ruo Li and Wei Zhong","An efficient mapped WENO scheme using approximate constant mapping",,"Numer. Math. Theor. Meth. Appl. Published online 22 September 2021","10.4208/nmtma.OA-2021-0074",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel mapping approach for WENO schemes through the use of an
approximate constant mapping function which is constructed by employing an
approximation of the classic signum function. The new approximate constant
mapping function is designed to meet the overall criteria for a proper mapping
function required in the design of the WENO-PM6 scheme. The WENO-PM6 scheme was
proposed to overcome the potential loss of accuracy of the WENO-M scheme which
was developed to recover the optimal convergence order of the WENO-JS scheme at
critical points. Our new mapped WENO scheme, denoted as WENO-ACM, maintains
almost all advantages of the WENO-PM6 scheme, including low dissipation and
high resolution, while decreases the number of mathematical operations
remarkably in every mapping process leading to a significant improvement of
efficiency. The convergence rates of the WENO-ACM scheme have been shown
through one-dimensional linear advection equation with various initial
conditions. Numerical results of one-dimensional Euler equations for the
Riemann problems, the Mach 3 shock-density wave interaction and the
Woodward-Colella interacting blastwaves are improved in comparison with the
results obtained by the WENO-JS, WENO-M and WENO-PM6 schemes. Numerical
experiments with two-dimensional problems as the 2D Riemann problem, the
shock-vortex interaction, the 2D explosion problem, the double Mach reflection
and the forward-facing step problem modeled via the two dimensional Euler
equations have been conducted to demonstrate the high resolution and the
effectiveness of the WENO-ACM scheme. The WENO-ACM scheme provides
significantly better resolution than the WENO-M scheme and slightly better
resolution than the WENO-PM6 scheme, and compared to the WENO-M and WENO-PM6
schemes, the extra computational cost is reduced by more than 83% and 93%,
respectively.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:28:16 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 09:21:46 GMT""}]","2022-02-04"
"2102.00232","Joseph Pollard","Joseph Pollard and Gareth P. Alexander","Intrinsic Geometry and Director Reconstruction for Three-Dimensional
  Liquid Crystals","13 pages, 2 figures","New J. Phys. 23, 063006 (2021)","10.1088/1367-2630/abfdf4",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a description of the intrinsic geometry of elastic distortions in
three-dimensional nematic liquid crystals and establish necessary and
sufficient conditions for a set of functions to represent these distortions by
describing how they couple to the curvature tensor. We demonstrate that, in
contrast to the situation in two dimensions, the first-order gradients of the
director alone are not sufficient for full reconstruction of the director field
from its intrinsic geometry: it is necessary to provide additional information
about the second-order director gradients. We describe several different
methods by which the director field may be reconstructed from its intrinsic
geometry. Finally, we discuss the coupling between individual distortions and
curvature from the perspective of Lie algebras and groups and describe
homogeneous spaces on which pure modes of distortion can be realised.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:30:49 GMT""}]","2021-06-28"
"2102.00233","Matheus E. Leusin","Matheus E. Leusin, Bjoern Jindra, Daniel S. Hain","An evolutionary view on the emergence of Artificial Intelligence","Keywords: Artificial Intelligence; technological space; evolutionary
  economic geography; technological relatedness; knowledge complexity",,,,"econ.GN cs.AI q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper draws upon the evolutionary concepts of technological relatedness
and knowledge complexity to enhance our understanding of the long-term
evolution of Artificial Intelligence (AI). We reveal corresponding patterns in
the emergence of AI - globally and in the context of specific geographies of
the US, Japan, South Korea, and China. We argue that AI emergence is associated
with increasing related variety due to knowledge commonalities as well as
increasing complexity. We use patent-based indicators for the period between
1974-2018 to analyse the evolution of AI's global technological space, to
identify its technological core as well as changes to its overall relatedness
and knowledge complexity. At the national level, we also measure countries'
overall specialisations against AI-specific ones. At the global level, we find
increasing overall relatedness and complexity of AI. However, for the
technological core of AI, which has been stable over time, we find decreasing
related variety and increasing complexity. This evidence points out that AI
innovations related to core technologies are becoming increasingly distinct
from each other. At the country level, we find that the US and Japan have been
increasing the overall relatedness of their innovations. The opposite is the
case for China and South Korea, which we associate with the fact that these
countries are overall less technologically developed than the US and Japan.
Finally, we observe a stable increasing overall complexity for all countries
apart from China, which we explain by the focus of this country in technologies
not strongly linked to AI.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:46:23 GMT""}]","2021-02-03"
"2102.00234","Xiao Liu Dr","Xuejun Li, Ran Ding, Xiao Liu, Jia Xu, Yun Yang and John Grundy","EdgeWorkflowReal: An Edge Computing based Workflow Execution Engine for
  Smart Systems","4 pages, 6 figures. For the demo video, please visit:
  https://youtu.be/2e7Vm7rM5Zc",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Current cloud-based smart systems suffer from weaknesses such as high
response latency, limited network bandwidth and the restricted computing power
of smart end devices which seriously affect the system's QoS (Quality of
Service). Recently, given its advantages of low latency, high bandwidth and
location awareness, edge computing has become a promising solution for smart
systems. However, the development of edge computing based smart systems is a
very challenging job for software developers who do not have the skills for the
creation of edge computing environments. The management of edge computing
resources and computing tasks is also very challenging. Workflow technology has
been widely used in smart systems to automate task and resource management, but
there does not yet exist a real-world deployable edge computing based workflow
execution engine. To fill this gap, we present EdgeWorkflowReal, an edge
computing based workflow execution engine for smart systems. EdgeWorkflowReal
supports: 1) automatic creation of a real edge computing environment according
to user settings; 2) visualized modelling of edge workflow applications; and 3)
automatic deployment, monitoring and performance evaluation of edge workflow
applications in a smart system.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:53:09 GMT""}]","2021-02-02"
"2102.00235","Lekshmi Ramesh","Lekshmi Ramesh, Chandra R. Murthy, Himanshu Tyagi","Phase Transitions for Support Recovery from Gaussian Linear Measurements",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of recovering the common $k$-sized support of a set of
$n$ samples of dimension $d$, using $m$ noisy linear measurements per sample.
Most prior work has focused on the case when $m$ exceeds $k$, in which case $n$
of the order $(k/m)\log(d/k)$ is both necessary and sufficient. Thus, in this
regime, only the total number of measurements across the samples matter, and
there is not much benefit in getting more than $k$ measurements per sample. In
the measurement-constrained regime where we have access to fewer than $k$
measurements per sample, we show an upper bound of $O((k^{2}/m^{2})\log d)$ on
the sample complexity for successful support recovery when $m\ge 2\log d$.
Along with the lower bound from our previous work, this shows a phase
transition for the sample complexity of this problem around $k/m=1$. In fact,
our proposed algorithm is sample-optimal in both the regimes. It follows that,
in the $m\ll k$ regime, multiple measurements from the same sample are more
valuable than measurements from different samples.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 14:54:17 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 18:14:13 GMT""}]","2021-05-14"
"2102.00236","Francesco Orabona","Francesco Orabona and D\'avid P\'al","Parameter-free Stochastic Optimization of Variationally Coherent
  Functions",,,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design and analyze an algorithm for first-order stochastic optimization of
a large class of functions on $\mathbb{R}^d$. In particular, we consider the
\emph{variationally coherent} functions which can be convex or non-convex. The
iterates of our algorithm on variationally coherent functions converge almost
surely to the global minimizer $\boldsymbol{x}^*$. Additionally, the very same
algorithm with the same hyperparameters, after $T$ iterations guarantees on
convex functions that the expected suboptimality gap is bounded by
$\widetilde{O}(\|\boldsymbol{x}^* - \boldsymbol{x}_0\| T^{-1/2+\epsilon})$ for
any $\epsilon>0$. It is the first algorithm to achieve both these properties at
the same time. Also, the rate for convex functions essentially matches the
performance of parameter-free algorithms. Our algorithm is an instance of the
Follow The Regularized Leader algorithm with the added twist of using
\emph{rescaled gradients} and time-varying linearithmic regularizers.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:05:34 GMT""}]","2021-02-02"
"2102.00237","Kamal Choudhary","Kamal Choudhary, Kevin F. Garrity, Nirmal J. Ghimire, Naween Anand,
  Francesca Tavazza","High-throughput search for magnetic topological materials using
  spin-orbit spillage, machine-learning and experiments",,"Phys. Rev. B 103, 155131 (2021)","10.1103/PhysRevB.103.155131",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Magnetic topological insulators and semi-metals have a variety of properties
that make them attractive for applications including spintronics and quantum
computation, but very few high-quality candidate materials are known. In this
work, we use systematic high-throughput density functional theory calculations
to identify magnetic topological materials from 40000 three-dimensional
materials in the JARVIS-DFT database (https://jarvis.nist.gov/jarvisdft).
First, we screen materials with net magnetic moment > 0.5 {\mu}B and spin-orbit
spillage > 0.25, resulting in 25 insulating and 564 metallic candidates. The
spillage acts as a signature of spin-orbit induced band-inversion. Then, we
carry out calculations of Wannier charge centers, Chern numbers, anomalous Hall
conductivities, surface bandstructures, and Fermi-surfaces to determine
interesting topological characteristics of the screened compounds. We also
train machine learning models for predicting the spillage, bandgaps, and
magnetic moments of new compounds, to further accelerate the screening process.
We experimentally synthesize and characterize a few candidate materials to
support our theoretical predictions.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:09:49 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 16:37:35 GMT""}]","2021-04-21"
"2102.00238","Raviraj Joshi","Rutuja Taware, Shraddha Varat, Gaurav Salunke, Chaitanya Gawande,
  Geetanjali Kale, Rahul Khengare, Raviraj Joshi","ShufText: A Simple Black Box Approach to Evaluate the Fragility of Text
  Classification Models",,,"10.1007/978-3-030-95467-3_18",,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text classification is the most basic natural language processing task. It
has a wide range of applications ranging from sentiment analysis to topic
classification. Recently, deep learning approaches based on CNN, LSTM, and
Transformers have been the de facto approach for text classification. In this
work, we highlight a common issue associated with these approaches. We show
that these systems are over-reliant on the important words present in the text
that are useful for classification. With limited training data and
discriminative training strategy, these approaches tend to ignore the semantic
meaning of the sentence and rather just focus on keywords or important n-grams.
We propose a simple black box technique ShutText to present the shortcomings of
the model and identify the over-reliance of the model on keywords. This
involves randomly shuffling the words in a sentence and evaluating the
classification accuracy. We see that on common text classification datasets
there is very little effect of shuffling and with high probability these models
predict the original class. We also evaluate the effect of language model
pretraining on these models and try to answer questions around model robustness
to out of domain sentences. We show that simple models based on CNN or LSTM as
well as complex models like BERT are questionable in terms of their syntactic
and semantic understanding.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:18:35 GMT""}]","2022-02-04"
"2102.00239","Ben Johns","Ben Johns, Shashwata Chattopadhyay and Joy Mitra","Tailoring Infrared Absorption and Thermal Emission with Ultrathin-film
  Interferences in Epsilon-Near-Zero Media","Main & supplementary; Added analysis and 1 figure in Main",,"10.1002/adpr.202100153",,"physics.optics cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Engineering nanophotonic mode dispersions in ultrathin, planar structures
enables significant control over infrared perfect absorption (PA) and thermal
emission characteristics. Here, using simulations, the wavelength and angular
ranges over which ultrathin, low loss, epsilon-near-zero (ENZ) films on a
reflecting surface most efficiently absorb and re-radiate are identified, and
the design parameters that tailor the ENZ mode dispersion within these limits
are investigated. While the absorption is spectrally limited to wavelengths
where the refractive index ($n$) lies below unity, the angular limits are
determined by the ENZ material dispersion in this range. A model of
ultrathin-film interference is developed to provide physical insight into the
absorption resonances in this regime, occurring well below the conventional
quarter-wavelength thickness limit. Driven by non-trivial phase shifts incurred
on reflection at the $n<1$ surface, these resonant interferences are shown to
be universal wave phenomena in planar structures having appropriate index
contrast, extending beyond ENZ materials. Selective choice of material, film
thickness and loss allows fine-tailoring the mode dispersions, enabling wide
variation in spectral range ($ \sim 0.1 - 1.0 \mu m$) and precise directional
control of spectrally and angularly narrow-band PA and thermal radiation,
paving the way towards efficient ENZ-based infrared optical and thermal
coatings.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:19:37 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 19:02:00 GMT""}]","2022-01-14"
"2102.00240","Qing-Long Zhang","Qing-Long Zhang Yu-Bin Yang","SA-Net: Shuffle Attention for Deep Convolutional Neural Networks","ICASSP 2021 paper: SA-Net: Shuffle Attention for Deep Convolutional
  Neural Networks",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Attention mechanisms, which enable a neural network to accurately focus on
all the relevant elements of the input, have become an essential component to
improve the performance of deep neural networks. There are mainly two attention
mechanisms widely used in computer vision studies, \textit{spatial attention}
and \textit{channel attention}, which aim to capture the pixel-level pairwise
relationship and channel dependency, respectively. Although fusing them
together may achieve better performance than their individual implementations,
it will inevitably increase the computational overhead. In this paper, we
propose an efficient Shuffle Attention (SA) module to address this issue, which
adopts Shuffle Units to combine two types of attention mechanisms effectively.
Specifically, SA first groups channel dimensions into multiple sub-features
before processing them in parallel. Then, for each sub-feature, SA utilizes a
Shuffle Unit to depict feature dependencies in both spatial and channel
dimensions. After that, all sub-features are aggregated and a ""channel shuffle""
operator is adopted to enable information communication between different
sub-features. The proposed SA module is efficient yet effective, e.g., the
parameters and computations of SA against the backbone ResNet50 are 300 vs.
25.56M and 2.76e-3 GFLOPs vs. 4.12 GFLOPs, respectively, and the performance
boost is more than 1.34% in terms of Top-1 accuracy. Extensive experimental
results on common-used benchmarks, including ImageNet-1k for classification, MS
COCO for object detection, and instance segmentation, demonstrate that the
proposed SA outperforms the current SOTA methods significantly by achieving
higher accuracy while having lower model complexity. The code and models are
available at https://github.com/wofmanaf/SA-Net.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:23:17 GMT""}]","2021-02-02"
"2102.00241","Kimball A. Milton","Yang Li, Kimball A. Milton, Prachi Parashar, and Lujun Hong","Negativity of the Casimir self-entropy in spherical geometries","10 pages, 11 figures","Entropy 2021, 23(2), 214","10.3390/e23020214",,"quant-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  It has been recognized for some time that even for perfect conductors, the
interaction Casimir entropy, due to quantum/thermal fluctuations, can be
negative. This result was not considered problematic because it was thought
that the self-entropies of the bodies would cancel this negative interaction
entropy, yielding a total entropy that was positive. In fact, this cancellation
seems not to occur. The positive self-entropy of a perfectly conducting sphere
does indeed just cancel the negative interaction entropy of a system consisting
of a perfectly conducting sphere and plate, but a model with weaker coupling in
general possesses a regime where negative self-entropy appears. The physical
meaning of this surprising result remains obscure. In this paper we re-examine
these issues, using improved physical and mathematical techniques, partly based
on the Abel-Plana formula, and present numerical results for arbitrary
temperatures and couplings, which exhibit the same remarkable features.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:27:02 GMT""}]","2021-03-05"
"2102.00242","Kiyoshi Kanazawa","Kiyoshi Kanazawa and Didier Sornette","Ubiquitous power law scaling in nonlinear self-excited Hawkes processes","To appear in Phys. Rev. Lett. (5 pages, 2 figures + Appendices)","Phys. Rev. Lett. 127, 188301 (2021)","10.1103/PhysRevLett.127.188301",,"cond-mat.stat-mech q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The origin(s) of the ubiquity of probability distribution functions (PDF)
with power law tails is still a matter of fascination and investigation in many
scientific fields from linguistic, social, economic, computer sciences to
essentially all natural sciences. In parallel, self-excited dynamics is a
prevalent characteristic of many systems, from the physics of shot noise and
intermittent processes, to seismicity, financial and social systems. Motivated
by activation processes of the Arrhenius form, we bring the two threads
together by introducing a general class of nonlinear self-excited point
processes with fast-accelerating intensities as a function of ""tension"".
Solving the corresponding master equations, we find that a wide class of such
nonlinear Hawkes processes have the PDF of their intensities described by a
power law on the condition that (i) the intensity is a fast-accelerating
function of tension, (ii) the distribution of marks is two-sided with
non-positive mean, and (iii) it has fast-decaying tails. In particular, Zipf's
scaling is obtained in the limit where the average mark is vanishing. This
unearths a novel mechanism for power laws including Zipf's law, providing a new
understanding of their ubiquity.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:31:04 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 13:10:32 GMT""}]","2021-11-01"
"2102.00243","Federico Lopez Armengol","Federico G. Lopez Armengol, Luciano Combi, Manuela Campanelli, Scott
  C. Noble, Julian H. Krolik, Dennis B. Bowen, Mark J. Avara, Vassilios Mewes,
  Hiroyuki Nakano","Circumbinary Disk Accretion into Spinning Black Hole Binaries","23 pages, 15 figures, Submitted to ApJ",,"10.3847/1538-4357/abf0af",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supermassive black hole binaries are likely to accrete interstellar gas
through a circumbinary disk. Shortly before merger, the inner portions of this
circumbinary disk are subject to general relativistic effects. To study this
regime, we approximate the spacetime metric of close orbiting black holes by
superimposing two boosted Kerr-Schild terms. After demonstrating the quality of
this approximation, we carry out very long-term general relativistic
magnetohydrodynamic simulations of the circumbinary disk. We consider black
holes with spin dimensionless parameters of magnitude 0.9, in one simulation
parallel to the orbital angular momentum of the binary, but in another
anti-parallel. These are contrasted with spinless simulations. We find that,
for a fixed surface mass density in the inner circumbinary disk, aligned spins
of this magnitude approximately reduce the mass accretion rate by 14% and
counter-aligned spins increase it by 45%, leaving many other disk properties
unchanged.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:33:08 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 16:55:47 GMT""}]","2021-06-02"
"2102.00244","Andrei Shiryaev A","Evgenii P. Barannik, Andrey A. Shiryaev, Thomas Hainschwang","Shift of CO2-I absorption bands in diamond: a pressure or compositional
  effect? A FTIR mapping study",,"Diamond and related materials, 113 (2021) 108280","10.1016/j.diamond.2021.108280",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infra-red maps and profiles with high spatial resolution were obtained for
two single crystal diamonds with pronounced CO2 IR absorption peaks. Detailed
examination allows unambiguous assignment of the spectral features to solid
CO2-I phase. It is shown that the distribution of IR band positions,
intensities and widths in the sample follows regular patterns and is not
chaotic as was suggested in previous works where spectra of a few individual
spots were analysed. Consequently, pressure effects alone fail to explain all
observed features and shifts of the CO2 bands. Experimental data can be
explained by presence of impurities (such as water, N2, etc.) in the trapped
CO2. This implies that spectroscopic barometry of CO2 microinclusions in
diamond may be subject to poorly controlled bias. However, barometry is still
possible if Davydov splitting of the CO2-I {\nu}2 band is unequivocally
observed, as this indicates high purity of the CO2 ice.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:35:38 GMT""}]","2021-02-16"
"2102.00245","Yoichi Takeda","Yoichi Takeda","Rubidium abundances of galactic disk stars","24 pages, 13 figures, accepted for publication in Astronomische
  Nachrichten, with supplementary online material",,"10.1002/asna.202123873",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectroscopic determinations of Rubidium abundances were conducted by
applying the spectrum fitting method to the Rb I 7800 line for an extensive
sample of ~500 late-type dwarfs as well as giants (including Hyades cluster
stars) belonging to the galactic disk population, with an aim of establishing
the behaviour of [Rb/Fe] ratio for disk stars in the metallicity range of
-0.6<[Fe/H]<+0.3. An inspection of the resulting Rb abundances for Hyades
dwarfs revealed that they show a systematic Teff-dependent trend at >5500K;
this means that the results for mid-G to F stars (including the Sun) are not
reliable (i.e., more or less overestimated), which might be due to some
imperfect treatment of surface convection in classical model atmospheres. As
such, it was decided to confine only to late-G and K stars at Teff<5500K and
adopt the solar-system (meteoritic) value as the reference Rb abundance. The
[Rb/Fe] vs.[Fe/H] relations derived for field dwarfs and giants turned out to
be consistent with each other, showing a gradual increase of [Rb/Fe] with a
decrease in [Fe/H] (with d[Rb/Fe]/d[Fe/H] gradient of ~-0.4 around the solar
metallicity), which is favourably compared with the theoretical prediction of
chemical evolution models. Accordingly, this study could not confirm the
anomalous behaviour of [Rb/Fe] ratio (tending to be subsolar but steeply
increasing toward supersolar metallicity) recently reported for M dwarf stars
of -0.3<[Fe/H]<+0.3.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:35:52 GMT""}]","2021-04-28"
"2102.00246","Jane Tan","Paul Balister, Emil Powierski, Alex Scott, Jane Tan","A note on infinite antichain density","Minor correction: added condition that $f_{n_0}=1$ to the statement
  of Theorem 3, 6 pages","SIAM Journal on Discrete Mathematics, Vol. 36 (2022) 573-577","10.1137/21M143025X",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{F}$ be an antichain of finite subsets of $\mathbb{N}$. How
quickly can the quantities $|\mathcal{F}\cap 2^{[n]}|$ grow as $n\to\infty$? We
show that for any sequence $(f_n)_{n\ge n_0}$ of positive integers satisfying
$\sum_{n=n_0}^\infty f_n/2^n \le 1/4$, $f_{n_0}=1$ and $f_n\le f_{n+1}\le
2f_n$, there exists an infinite antichain $\mathcal{F}$ of finite subsets of
$\mathbb{N}$ such that $|\mathcal{F}\cap 2^{[n]}| \geq f_n$ for all $n\ge n_0$.
It follows that for any $\varepsilon>0$ there exists an antichain
$\mathcal{F}\subseteq 2^\mathbb{N}$ such that $$\liminf_{n \to \infty}
|\mathcal{F}\cap 2^{[n]}| \cdot \left(\frac{2^n}{n\log^{1+\varepsilon}
n}\right)^{-1} > 0.$$ This resolves a problem of Sudakov, Tomon and Wagner in a
strong form, and is essentially tight.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:36:29 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jun 2022 20:51:42 GMT""}]","2022-06-14"
"2102.00247","Shilun Lin","Shilun Lin, Fenglong Xie, Li Meng, Xinhui Li, Li Lu","Triple M: A Practical Text-to-speech Synthesis System With
  Multi-guidance Attention And Multi-band Multi-time LPCNet",,,,,"cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a robust and efficient text-to-speech (TTS) synthesis system
named Triple M is proposed for large-scale online application. The key
components of Triple M are: 1) A sequence-to-sequence model adopts a novel
multi-guidance attention to transfer complementary advantages from guiding
attention mechanisms to the basic attention mechanism without in-domain
performance loss and online service modification. Compared with single
attention mechanism, multi-guidance attention not only brings better
naturalness to long sentence synthesis, but also reduces the word error rate by
26.8%. 2) A new efficient multi-band multi-time vocoder framework, which
reduces the computational complexity from 2.8 to 1.0 GFLOP and speeds up LPCNet
by 2.75x on a single CPU.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:38:36 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 13:26:29 GMT""},{""version"":""v3"",""created"":""Tue, 9 Feb 2021 07:04:35 GMT""},{""version"":""v4"",""created"":""Wed, 7 Apr 2021 14:54:13 GMT""}]","2021-04-08"
"2102.00248","Christophe Coreixas","Rapha\""el Conradin, Christophe Coreixas, Jonas Latt and Bastien
  Chopard","PalaCell2D: A framework for detailed tissue morphogenesis","Revised version",,,,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In silico, cell based approaches for modeling biological morphogenesis are
used to test and validate our understanding of the biological and mechanical
process that are at work during the growth and the organization of multi-cell
tissues. As compared to in vivo experiments, computer based frameworks
dedicated to tissue modeling allow us to easily test different hypotheses, and
to quantify the impact of various biophysically relevant parameters.
  Here, we propose a formalism based on a detailed, yet simple, description of
cells that accounts for intra-, inter- and extra-cellular mechanisms. More
precisely, the cell growth and division is described through the space and time
evolution of the membrane vertices. These vertices follow a Newtonian dynamics,
meaning that their evolution is controlled by different types of forces: a
membrane force (spring and bending), an adherence force (inter cellular
spring), external and internal pressure forces. In addition to the cells
dynamics, our formalism further relies on a lattice Boltzmann method, using the
Palabos library, to simulate the diffusion of chemical signals. The latter aims
at driving the growth and migration of a tissue by simply changing the state of
the cells.
  All of this leads to an accurate description of the growth and division of
cells, with realistic cell shapes and where membranes can have different
properties. While this work is of methodological nature, we also propose to
validate our framework through simple, yet biologically relevant benchmark
tests at both single-cell and full tissue scales. This includes free and
chemically controlled cell tissue growth in an unbounded domain. The ability of
our framework to simulate cell migration, cell compression and morphogenesis
under external constraints is also investigated in a qualitative manner.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:43:53 GMT""},{""version"":""v2"",""created"":""Sat, 13 Mar 2021 16:01:08 GMT""}]","2021-03-16"
"2102.00249","Evandro Konzen","Evandro Konzen, Yafeng Cheng, Jian Qing Shi","Gaussian Process for Functional Data Analysis: The GPFDA Package for R",,,,,"stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present and describe the GPFDA package for R. The package provides
flexible functionalities for dealing with Gaussian process regression (GPR)
models for functional data. Multivariate functional data, functional data with
multidimensional inputs, and nonseparable and/or nonstationary covariance
structures can be modeled. In addition, the package fits functional regression
models where the mean function depends on scalar and/or functional covariates
and the covariance structure is modeled by a GPR model. In this paper, we
present the versatility of GPFDA with respect to mean function and covariance
function specifications and illustrate the implementation of estimation and
prediction of some models through reproducible numerical examples.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:45:07 GMT""}]","2021-02-02"
"2102.00250","Shi Yan","Yiqiu Dong and Chunlin Wu and Shi Yan","A fast method for simultaneous reconstruction and segmentation in X-ray
  CT application",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we propose a fast method for simultaneous reconstruction and
segmentation (SRS) in X-ray computed tomography (CT). Our work is based on the
SRS model where Bayes' rule and the maximum a posteriori (MAP) are used on
hidden Markov measure field model (HMMFM). The original method leads to a
logarithmic-summation (log-sum) term, which is non-separable to the
classification index. The minimization problem in the model was solved by using
constrained gradient descend method, Frank-Wolfe algorithm, which is very
time-consuming especially when dealing with large-scale CT problems. The
starting point of this paper is the commutativity of log-sum operations, where
the log-sum problem could be transformed into a sum-log problem by introducing
an auxiliary variable. The corresponding sum-log problem for the SRS model is
separable. After applying alternating minimization method, this problem turns
into several easy-to-solve convex sub-problems. In the paper, we also study an
improved model by adding Tikhonov regularization, and give some convergence
results. Experimental results demonstrate that the proposed algorithms could
produce comparable results with the original SRS method with much less CPU
time.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:46:22 GMT""}]","2021-02-02"
"2102.00251","Sean Ravenhall","Sean Ravenhall, Benjamin Yuen and Chris Foot","A high-flux, adjustable, compact cold-atom source","16 pages, 7 figures, 1 table",,"10.1364/OE.423662",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magneto-optical traps (MOTs) are widely used for laser cooling of atoms. We
have developed a high-flux compact cold-atom source based on a pyramid MOT with
a unique adjustable aperture that is highly suitable for portable quantum
technology devices, including space-based experiments. The adjustability
enabled an investigation into the previously unexplored impact of aperture size
on the atomic flux, and optimisation of the aperture size allowed us to
demonstrate a higher flux than any reported cold-atom sources that use a
pyramid, LVIS, 3D-MOT or grating MOT. We achieved 2.0(1)x10^10 atoms/s of 87-Rb
with a mean velocity of 32(1)m/s, FWHM of 27.6(9)m/s and divergence of
58(3)mrad. Halving the total optical power to 195mW caused only a 26% reduction
of the flux, and a 33% decrease in mean velocity. Methods to further decrease
the velocity as required have been identified. The low power consumption and
small size make this design suitable for a wide range of cold-atom
technologies.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:49:51 GMT""}]","2021-07-07"
"2102.00252","Emiliano Valdez","Banghee So, Jean-Philippe Boucher, Emiliano A. Valdez","Synthetic Dataset Generation of Driver Telematics","24 pages, 11 figures, 6 tables",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article describes techniques employed in the production of a synthetic
dataset of driver telematics emulated from a similar real insurance dataset.
The synthetic dataset generated has 100,000 policies that included observations
about driver's claims experience together with associated classical risk
variables and telematics-related variables. This work is aimed to produce a
resource that can be used to advance models to assess risks for usage-based
insurance. It follows a three-stage process using machine learning algorithms.
The first stage is simulating values for the number of claims as multiple
binary classifications applying feedforward neural networks. The second stage
is simulating values for aggregated amount of claims as regression using
feedforward neural networks, with number of claims included in the set of
feature variables. In the final stage, a synthetic portfolio of the space of
feature variables is generated applying an extended $\texttt{SMOTE}$ algorithm.
The resulting dataset is evaluated by comparing the synthetic and real datasets
when Poisson and gamma regression models are fitted to the respective data.
Other visualization and data summarization produce remarkable similar
statistics between the two datasets. We hope that researchers interested in
obtaining telematics datasets to calibrate models or learning algorithms will
find our work valuable.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:52:56 GMT""}]","2021-02-02"
"2102.00253","Edilson Alfonso Reyes Rojas","A. R. Fazio and E. A. Reyes R.","A functional approach to the next to eikonal approximation of high
  energy gravitational scattering","21 pages","Mod. Phys. Lett. A, Vol. 36, No. 20, 2150138 (2021)","10.1142/S0217732321501388",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The Fradkin-Schwinger functional methods to represent a Green function in an
external gravitational field are used to study the eikonal and the
next-to-eikonal limit, including the nonlinear gravitational interactions, of
the scattering amplitudes of an ultra-relativistic scalar particle on a static
super-massive scalar target in the nearly forward limit. The functional
approach confirms the exponentiation of the leading eikonal which also applies
to the first non-leading power in the energy of the light particle, moreover
includes the interaction at impact parameter much larger than the Schwarzschild
radius associated with the center of mass energy in the ultra-relativistic
limit.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:53:20 GMT""}]","2021-07-20"
"2102.00254","Tom\'a\v{s} Roub\'i\v{c}ek","Tom\'a\v{s} Roub\'i\v{c}ek","Fine metrizable convex relaxations of parabolic optimal control problems",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Nonconvex optimal-control problems governed by evolution problems in
infinite-dimensional spaces (as e.g. parabolic boundary-value problems) needs a
continuous (and possibly also smooth) extension on some (preferably convex)
compactification, called relaxation, to guarantee existence of their solutions
and to facilitate analysis by relatively conventional tools. When the control
is valued in some subsets of Lebesgue spaces, the usual extensions are either
too coarse (allowing in fact only very restricted nonlinearities) or too fine
(being nonmetrizable). To overcome these drawbacks, a compromising convex
compactification is here devised, combining classical techniques for Young
measures with Choquet theory. This is applied to parabolic optimal control
problems as far as existence and optimality conditions concerns.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:54:50 GMT""}]","2021-02-02"
"2102.00255","Amnon Yekutieli","Amnon Yekutieli","Rigidity, Residues and Duality: Overview and Recent Progress","20 pages",,,,"math.AG math.AC math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we explain the theory of rigid residue complexes in
commutative algebra and algebraic geometry, summarizing the background, recent
results and anticipated future results. Unlike all previous approaches to
Grothendiec Duality, the rigid approach concentrates on the construction of
rigid residue complexes over rings, and their intricate yet robust properties.
The geometrization, i.e. the passage to rigid residue complexes on schemes and
Deligne-Mumford (DM) stacks, by gluing, is fairly easy. In the geometric part
of the theory, the main results are the Rigid Residue Theorem and the Rigid
Duality Theorem for proper maps between schemes, and for tame proper maps
between DM stacks.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:56:45 GMT""}]","2021-02-02"
"2102.00256","Edward Shuryak","Edward Shuryak and Ismail Zahed","How to observe the QCD instanton/sphaleron processes at hadron
  colliders?","v2 contain small improvements",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The instanton/sphaleron processes involve gauge fields with changing topology
through a nonzero variation of the Chern-Simons number $\delta N_{CS}=\pm 1$.
In QCD this leads to the production of $2N_f \delta N_{CS}$ units of axial
charge, and in the electroweak theory to the production of 12 fermions, with
$\Delta B=\delta L=3$ units of baryon and lepton number, a key mechanism in
baryogenesis. While this is all known for a long time, and is one of the
pillars of the nonperturbative theory of the QCD vacuum, to see these phenomena
directly in colliders remains an unfulfilled promise. Motivated by the recent
CERN workshop on the topic, we review the field. We also put forward our own
suggestions to utilize double-diffractive (or Pomeron-Pomeron) collisions to
this goal, which maximizes the entrance factor and minimizes the backgrounds.
  We consider separately clusters of small ($M=3-10\, {\rm GeV}$), medium
($10-30\, {\rm GeV}$) and high $M\sim 100 \, {\rm GeV}$ invariant masses. Among
the proposed signals are specific flavor combination of channels, originating
from well-defined 6-, 8- and 10-quark-antiquark operators, as well as
correlation of quark chiralities to be potentially detected via $\Lambda$
hyperon decays.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:57:02 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 18:21:18 GMT""}]","2021-06-28"
"2102.00257","Carlos M. R. Rocha","C. M. R. Rocha and H. Linnartz","Theoretical studies of carbon isotopic fractionation in reactions of C
  with C$_{2}$: dynamics, kinetics, and isotopologue equilibria","Accepted for publication in A&A","A&A 647, A142 (2021)","10.1051/0004-6361/202040093",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our current understanding of interstellar carbon fractionation hinges on the
interpretation of astrochemical kinetic models. Yet, the various reactions
included carry large uncertainties in their (estimated) rate coefficients,
notably those involving C with C$_{2}$. In this work, we provide theoretical
thermal rate coefficients as a function of the temperature for all possible
gas-phase isotope-exchange reactions of
C+C$_{2}(X^{1}\Sigma_{g}^{+},a^{3}\Pi_{u})$. For this, we employ the
quasi-classical trajectory method, with the previously obtained potential
energy surfaces of C$_{3}$ dictating the forces between the colliding partners.
The calculated rate coefficients show a positive temperature dependence and are
markedly different from previous theoretical estimates. While the forward
reactions are fast and inherently exothermic owing to the lower zero-point
energy content of the products, the reverse processes have temperature
thresholds. For each reaction considered, analytic three-parameter
Arrhenius-Kooij formulas are provided that readily interpolate/extrapolate the
associated forward and backward rates. These forms can further be introduced in
astrochemical networks. Apart from the proper kinetic attributes, we also
provide equilibrium constants for these processes, thence confirming their
prominence in the overall C fractionation chemistry. In this respect, the
$^{13}$C + $^{12}$C$_{2}(X^{1}{\Sigma}^{+}_{g})$ and $^{13}$C +
$^{12}$C$_{2}(a^{3}{\Pi}_{u})$ reactions are found to be particularly
conspicuous, notably at the typical temperatures of dense molecular clouds. For
these reactions and considering both equilibrium and time-dependent chemistry,
theoretical $^{12}$C/$^{13}$C ratios as a function of the gas kinetic
temperature are also derived and shown to be consistent with available model
chemistry and observational data on C$_{2}$
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:59:08 GMT""}]","2021-03-24"
"2102.00258","Christoph Welling","Christoph Welling, Philipp Frank, Torsten A. En{\ss}lin, Anna Nelles","Reconstructing non-repeating radio pulses with Information Field Theory",,,"10.1088/1475-7516/2021/04/071",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle showers in dielectric media produce radio signals which are used for
the detection of both ultra-high energy cosmic rays and neutrinos with energies
above a few PeV. The amplitude, polarization, and spectrum of these short,
broadband radio pulses allow us to draw conclusions about the primary particles
that caused them, as well as the mechanics of shower development and radio
emission. However, confidently reconstructing the radio signals can pose a
challenge, as they are often obscured by background noise. Information Field
Theory offers a robust approach to this challenge by using Bayesian inference
to calculate the most likely radio signal, given the recorded data. In this
paper, we describe the application of Information Field Theory to radio signals
from particle showers in both air and ice and demonstrate how accurately pulse
parameters can be obtained from noisy data.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:59:18 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 15:53:51 GMT""}]","2021-05-05"
"2102.00812","Ahsan Zeb","M. Ahsan Zeb","Efficient linear scaling mapping for permutation symmetric Fock spaces","9 pages, 2 figures, with fortran library source",,"10.1016/j.cpc.2022.108347",,"physics.comp-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerically solving a second quantised many-body model in the permutation
symmetric Fock space can be challenging for two reasons: (i) an increased
complication in the calculations of the matrix elements of various operators,
and (ii) a poor scaling of the cost of these calculations with the Fock space
size. We present a method that solves both these problems. We find a mapping
that can be used to simplify the calculations of the matrix elements. The
mapping is directly generated so its computational cost scales only linearly
with the space size and is negligible even for large enough sizes that approach
the thermodynamic limit. A fortran implementation of the method as a library -
FockMap - is provided along with a test program.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:44:15 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 07:22:45 GMT""}]","2022-04-13"
"2102.00861","Antonino Drago Prof.","Antonino Drago","A Review of The Algebraic Approaches to Quantum Mechanics. Appraisals on
  Their Theoretical Relevance","I show that in the past the scholars reflecting on the foundations of
  quantum mechanics missed to take into account the progressive relevance
  acquired by the algebraic approach. 13 pages",,,,"physics.hist-ph math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I review the various algebraic foundations of quantum mechanics. They have
been suggested since the birth of this theory till up to last year. They are
the following ones: Heisenberg-Born-Jordan (1925), Weyl (1928), Dirac (1930),
von Neumann (1936), Segal (1947), T.F. Jordan (1986), Morchio and Strocchi
(2009) and Buchholz and Fregenhagen (2019). Three cases are stressed: 1) the
misinterpretation of Dirac foundation; 2) von Neumann conversion from the
analytic approach of Hilbert space to the algebraic approach of the rings of
operators; 3) the recent foundation of quantum mechanics upon the algebra of
perturbation Lagrangians. Moreover, historical considerations on the
go-and-stop path performed by the algebraic approach in the history of QM are
offered. The level of formalism has increased from the mere introduction of
matrices till up to group theory and C*-algebras. But there was no progress in
approaching closer the foundations of physics; therefore the problem of
discovering an algebraic formulation of QM organized as a problem-based theory
and making use of no more than constructive mathematics is open.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:57:29 GMT""}]","2021-02-02"
"2102.00862","Iuliana Marin","Iuliana Marin, Nicolae Goga, Maria Goga","Benchmarking MD systems simulations on the Graphics Processing Unit and
  Multi-Core Systems",,"2016 IEEE International Symposium on Systems Engineering (ISSE)","10.1109/SysEng.2016.7753133",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular dynamics facilitates the simulation of a complex system to be
analyzed at molecular and atomic levels. Simulations can last a long period of
time, even months. Due to this cause the graphics processing units (GPUs) and
multi-core systems are used as solutions to overcome this impediment. The
current paper describes a comparison done between these two kinds of systems.
The first system used implies the graphics processing unit, respectively CUDA
with the OpenMM molecular dynamics package and OpenCL that allows the kernels
to run on the GPU. This simulation is done on a new thermostat which mixes the
Berendsen thermostat with the Langevin dynamics. The second comprises the
molecular dynamics simulation and energy minimization package GROMACS which is
based on a parallelization through MPI (Message Passing Interface) on
multi-core systems. The second simulation uses another new thermostat algorithm
related respectively, dissipative particle dynamics - isotropic type (DPD-ISO).
Both thermostats are innovative, based on a new theory developed by us. Results
show that parallelization on multi-core systems has a performance up to 33
times greater than the one performed on the graphics processing unit. In both
cases temperature of the system was maintained close to the one taken as
reference. For the simulation using the CUDA GPU, the faster runtime was
obtained when the number of processors was equal to four, the simulation speed
being 3.67 times faster compared to the case of only one processor.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:50:28 GMT""}]","2021-02-02"
"2102.00869","Ming Du","Ming Du, Xiaojing Huang, Chris Jacobsen","Using a modified double deep image prior for crosstalk mitigation in
  multislice ptychography","10 pages, 5 figures",,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  Multislice ptychography is a high-resolution microscopy technique used to
image multiple separate axial planes using a single illumination direction.
However, multislice ptychography reconstructions are often degraded by
crosstalk, where some features on one plane erroneously contribute to the
reconstructed image of another plane. Here, we demonstrate the use of a
modified ""double deep image prior"" (DDIP) architecture in mitigating crosstalk
artifacts in multislice ptychography. Utilizing the tendency of generative
neural networks to produce natural images, a modified DDIP method yielded good
results on experimental data. For one of the datasets, we show that using DDIP
could remove the need of using additional experimental data, such as from x-ray
fluorescence, to suppress the crosstalk. Our method may help x-ray multislice
ptychography work for more general experimental scenarios.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:00:40 GMT""}]","2021-02-02"
"2102.00960","Dalton Sakthivadivel","Dalton A R Sakthivadivel","Magnetisation and Mean Field Theory in the Ising Model","20 pages, two figures. Revisions to presentation","SciPost Phys. Lect. Notes 35 (2022)","10.21468/SciPostPhysLectNotes.35",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  In this set of notes, a complete, pedagogical tutorial for applying mean
field theory to the two-dimensional Ising model is presented. Beginning with
the motivation and basis for mean field theory, we formally derive the
Bogoliubov inequality and discuss mean field theory itself. We proceed with the
use of mean field theory to determine a magnetisation function, and the results
of the derivation are interpreted graphically, physically, and mathematically.
We give a new interpretation of the self-consistency condition in terms of
intersecting surfaces and constrained solution sets. We also include some more
general comments on the thermodynamics of the phase transition. We end by
evaluating symmetry considerations in magnetisation, and some more subtle
features of the Ising model. Together, a self-contained overview of the mean
field Ising model is given, with some novel presentation of important results.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:13:25 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 15:43:50 GMT""},{""version"":""v3"",""created"":""Mon, 14 Jun 2021 01:22:59 GMT""},{""version"":""v4"",""created"":""Wed, 13 Oct 2021 02:54:52 GMT""},{""version"":""v5"",""created"":""Wed, 19 Jan 2022 17:05:35 GMT""}]","2022-01-20"
"2102.01070","Mikhail Shneider","Mikhail Pekker, Mikhail N. Shneider","Transitional layer at the edge of a false vacuum in a cavitation model
  of the Big Bang",,,,,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  This paper considers the structure and physical processes in the transition
region at the border between the regions of false and physical vacuums in a
cavitation model of the inflationary stage of the Big Bang. It is shown that in
the process of the formation of physical vacuum bubbles in a false vacuum,
conditions for the formation of a narrow layer filled with matter arise in the
transition region, which is the precursor to bridges in the observed
large-scale cellular structure of the universe.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 21:56:30 GMT""}]","2021-02-03"
"2102.01071","Pramod Mane","Pramod C. Mane, Nagarajan Krishnamurthy, Kapil Ahuja","Resource Availability in the Social Cloud: An Economics Perspective","11 pages, 10 figures",,,,"cs.GT cs.DC econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on social cloud formation, where agents are involved in a
closeness-based conditional resource sharing and build their resource sharing
network themselves. The objectives of this paper are: (1) to investigate the
impact of agents' decisions of link addition and deletion on their local and
global resource availability, (2) to analyze spillover effects in terms of the
impact of link addition between a pair of agents on others' utility, (3) to
study the role of agents' closeness in determining what type of spillover
effects these agents experience in the network, and (4) to model the choices of
agents that suggest with whom they want to add links in the social cloud. The
findings include the following. Firstly, agents' decision of link addition
(deletion) increases (decreases) their local resource availability. However,
these observations do not hold in the case of global resource availability.
Secondly, in a connected network, agents experience either positive or negative
spillover effect and there is no case with no spillover effects. Agents observe
no spillover effects if and only if the network is disconnected and consists of
more than two components (sub-networks). Furthermore, if there is no change in
the closeness of an agent (not involved in link addition) due to a newly added
link, then the agent experiences negative spillover effect. Although an
increase in the closeness of agents is necessary in order to experience
positive spillover effects, the condition is not sufficient. By focusing on
parameters such as closeness and shortest distances, we provide conditions
under which agents choose to add links so as to maximise their resource
availability.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 06:00:03 GMT""}]","2021-02-03"
"2102.01170","Iuliana Marin","Hasan Naji, Iuliana Marin, Nicolae Goga, Cristian Taslitschi","Novel Design and Implementation of a Vehicle Controlling and Tracking
  System","International Journal of Advanced Computer Science and Applications
  2020",,"10.14569/IJACSA.2020.0110756",,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this project is to build a system that will quickly track the
location of a stolen vehicle, thereby reducing the cost and effort of police.
Moreover, the vehicle's computer system can be controlled remotely by the
owners of the vehicle or police. More precisely, the goal of this work is to
design a, develop remote control of the vehicle, and find the locations with
Latitude (LAT) and Longitude (LONG).
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:13:18 GMT""}]","2021-02-03"
"2102.01204","Junghyun Bae","Junghyun Bae, Stylianos Chatzidakis, Robert Bean","Effective Solid Angle Model and Monte Carlo Method: Improved Estimations
  to Measure Cosmic Muon Intensity at Sea Level in All Zenith Angles","Proceedings of the 2021 International Conference on Nuclear
  Engineering ICONE2021 August 4-6, 2021, Virtual, Online ICONE28-63444",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  Cosmic muons are highly energetic and penetrative particles and these figures
are used for imaging of large and dense objects such as spent nuclear fuels in
casks and special nuclear materials in cargo. Cosmic muon intensity depends on
the incident angle (zenith angle). The low intensity of cosmic muon requires a
long measurement time to acquire statistically meaningful counts. Therefore,
high-energy particle simulations e.g., GEANT4, are often used to guide
measurement studies. However, the measurable cosmic muon count rate changes
upon detector geometry and configuration. Here we develop an effective solid
angle model to estimate experimental results more accurately than the simple
cosine-squared model. We show that the cosine-squared model has a large error
at high zenith angles, whereas our model provides improved estimations at all
zenith angles. We anticipate our model will enhance the ability to estimate
actual measurable cosmic muon count rates in muon imaging applications by
reducing the gap between simulation and measurement results. This will increase
the value of modeling results and improve the quality of experiments and
applications in muon detection and imaging.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 16:32:03 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 02:28:52 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 00:06:36 GMT""}]","2021-04-28"
"2102.01498","Iuliana Marin","Andrei Vasilateanu, Nicolae Goga, Elena-Alice Tanase, Iuliana Marin","Enterprise domain ontology learning from web-based corpus",,"2015 6th International Conference on Computing, Communication and
  Networking Technologies (ICCCNT)","10.1109/ICCCNT.2015.7395227",,"cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Enterprise knowledge is a key asset in the competing and fast-changing
corporate landscape. The ability to learn, store and distribute implicit and
explicit knowledge can be the difference between success and failure. While
enterprise knowledge management is a well-defined research domain, current
implementations lack orientation towards small and medium enterprise. We
propose a semantic search engine for relevant documents in an enterprise, based
on automatic generated domain ontologies. In this paper we focus on the
component for ontology learning and population.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:08:29 GMT""}]","2021-02-16"
"2102.01502","Satyapriya Krishna","Satyapriya Krishna, Rahul Gupta, Christophe Dupuy","ADePT: Auto-encoder based Differentially Private Text Transformation",,"The 16th conference of the European Chapter of the Association for
  Computational Linguistics (EACL), 2021",,,"cs.CR cs.AI cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Privacy is an important concern when building statistical models on data
containing personal information. Differential privacy offers a strong
definition of privacy and can be used to solve several privacy concerns (Dwork
et al., 2014). Multiple solutions have been proposed for the
differentially-private transformation of datasets containing sensitive
information. However, such transformation algorithms offer poor utility in
Natural Language Processing (NLP) tasks due to noise added in the process. In
this paper, we address this issue by providing a utility-preserving
differentially private text transformation algorithm using auto-encoders. Our
algorithm transforms text to offer robustness against attacks and produces
transformations with high semantic quality that perform well on downstream NLP
tasks. We prove the theoretical privacy guarantee of our algorithm and assess
its privacy leakage under Membership Inference Attacks(MIA) (Shokri et al.,
2017) on models trained with transformed data. Our results show that the
proposed model performs better against MIA attacks while offering lower to no
degradation in the utility of the underlying transformation process compared to
existing baselines.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 23:15:24 GMT""}]","2021-02-03"
"2102.01504","Sepideh Saber","Sepideh Saberhaghparvar and Hossein Panahi","Initial Value Problem for a Caputo Space-time Fractional Schrodinger
  Equation for the Delta Potential",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the initial value problem for a Caputo
space-time fractional Schrodinger equation for the delta potential. To solve
this equation, we use the joint Laplace transform on the spatial coordinate and
the Fourier transform on the time coordinate. Finally, the wave function and
the time dependent energy eigenvalues are obtained for a particle which is
subjected to the delta potential.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:49:34 GMT""}]","2021-02-03"
"2102.01515","Gadekallu Thippa Reddy","V. Priya, I. Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K.
  Aboudaif, Emad Abouel Nasr","Robust Attack Detection Approach for IIoT Using Ensemble Classifier",,,"10.32604/cmc.2021.013852",,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Generally, the risks associated with malicious threats are increasing for the
IIoT and its related applications due to dependency on the Internet and the
minimal resource availability of IoT devices. Thus, anomaly-based intrusion
detection models for IoT networks are vital. Distinct detection methodologies
need to be developed for the IIoT network as threat detection is a significant
expectation of stakeholders. Machine learning approaches are considered to be
evolving techniques that learn with experience, and such approaches have
resulted in superior performance in various applications, such as pattern
recognition, outlier analysis, and speech recognition. Traditional techniques
and tools are not adequate to secure IIoT networks due to the use of various
protocols in industrial systems and restricted possibilities of upgradation. In
this paper, the objective is to develop a two-phase anomaly detection model to
enhance the reliability of an IIoT network. In the first phase, SVM and Naive
Bayes are integrated using an ensemble blending technique. K-fold
cross-validation is performed while training the data with different training
and testing ratios to obtain optimized training and test sets. Ensemble
blending uses a random forest technique to predict class labels. An Artificial
Neural Network (ANN) classifier that uses the Adam optimizer to achieve better
accuracy is also used for prediction. In the second phase, both the ANN and
random forest results are fed to the model's classification unit, and the
highest accuracy value is considered the final result. The proposed model is
tested on standard IoT attack datasets, such as WUSTL_IIOT-2018, N_BaIoT, and
Bot_IoT. The highest accuracy obtained is 99%. The results also demonstrate
that the proposed model outperforms traditional techniques and thus improves
the reliability of an IIoT network.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:21:44 GMT""}]","2021-02-03"
"2102.01516","Deyang Duan","Deyang Duan and Yunjie Xia","True color night vision correlated imaging based on intensity
  correlation of light",,,,,"eess.IV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Night vision imaging is a technology that converts non-visible object to
human eyes into visible image in night and other low light environments.
However, the conventional night vision imaging can only directly produce
grayscale image. Here, we propose a novel night vision imaging method based on
intensity correlation of light. The object's information detected by infrared
non-visible light is expressed by visible light via the spatial intensity
correlation of light. With simple data processing, a color night vision image
can be directly produced by this approach without any pseudo-color image
processing. Theoretical and experimental results show that a color night vision
image comparable to classical visible light imaging quality can be obtained by
this method. Surprisingly, the color colorfulness index of the reconstructed
night vision image is significantly better than that of the conventional
visible light image and pseudo-color night vision image. Although the
reconstructed image can not completely restore the natural color of the object,
the color image obtained by this method is more natural sense than that
obtained by other pseudo-color image processing methods.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:48:38 GMT""}]","2021-02-03"
"2102.01754","Weiquan Fan","Weiquan Fan, Xiangmin Xu, Xiaofen Xing, Weidong Chen, Dongyan Huang","LSSED: a large-scale dataset and benchmark for speech emotion
  recognition",,,,,"cs.SD cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Speech emotion recognition is a vital contributor to the next generation of
human-computer interaction (HCI). However, current existing small-scale
databases have limited the development of related research. In this paper, we
present LSSED, a challenging large-scale english speech emotion dataset, which
has data collected from 820 subjects to simulate real-world distribution. In
addition, we release some pre-trained models based on LSSED, which can not only
promote the development of speech emotion recognition, but can also be
transferred to related downstream tasks such as mental health analysis where
data is extremely difficult to collect. Finally, our experiments show the
necessity of large-scale datasets and the effectiveness of pre-trained models.
The dateset will be released on https://github.com/tobefans/LSSED.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 11:15:32 GMT""}]","2021-02-04"
"2102.03351","Florenc Demrozi Dr.","Florenc Demrozi, Cristian Turetta, Fabio Chiarani, Philipp H. Kindt,
  and Graziano Pravadelli","Estimating indoor occupancy through low-cost BLE devices","7 Tabels, 2 Figures, 9 Pages",,"10.1109/JSEN.2021.3080632",,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting the presence of persons and estimating their quantity in an indoor
environment has grown in importance recently. For example, the information if a
room is unoccupied can be used for automatically switching off the light, air
conditioning, and ventilation, thereby saving significant amounts of energy in
public buildings. Most existing solutions rely on dedicated hardware
installations, which involve presence sensors, video cameras, and carbon
dioxide sensors. Unfortunately, such approaches are costly, are subject to
privacy concerns, have high computational requirements, and lack
ubiquitousness. The work presented in this article addresses these limitations
by proposing a low-cost occupancy detection system. Our approach builds upon
detecting variations in Bluetooth Low Energy (BLE) signals related to the
presence of humans. The effectiveness of this approach is evaluated by
performing comprehensive tests on five different datasets. We apply several
pattern recognition models and compare our methodology with systems building
upon IEEE 802.11 (WiFi). On average, in multifarious environments, we can
correctly classify the occupancy with an accuracy of 97.97%. When estimating
the number of people in a room, on average, the estimated number of subjects
differs from the actual one by 0.32 persons. We conclude that our system's
performance is comparable to that of existing ones based on WiFi, while
significantly reducing cost and installation effort. Hence, our approach makes
occupancy detection practical for real-world deployments.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 09:54:31 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 11:37:02 GMT""}]","2021-05-18"
"2102.03352","Ramiro Casal","Ramiro Casal, Leandro E. Di Persia, and Gast\'on Schlotthauer","Temporal convolutional networks and transformers for classifying the
  sleep stage in awake or asleep using pulse oximetry signals","13 pages, 4 figures",,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by/4.0/","  Sleep disorders are very widespread in the world population and suffer from a
generalized underdiagnosis, given the complexity of their diagnostic methods.
Therefore, there is an increasing interest in developing simpler screening
methods. A pulse oximeter is an ideal device for sleep disorder screenings
since it is a portable, low-cost and accessible technology. This device can
provide an estimation of the heart rate (HR), which can be useful to obtain
information regarding the sleep stage. In this work, we developed a network
architecture with the aim of classifying the sleep stage in awake or asleep
using only HR signals from a pulse oximeter. The proposed architecture has two
fundamental parts. The first part has the objective of obtaining a
representation of the HR by using temporal convolutional networks. Then, the
obtained representation is used to feed the second part, which is based on
transformers, a model built solely with attention mechanisms. Transformers are
able to model the sequence, learning the transition rules between sleep stages.
The performance of the proposed method was evaluated on Sleep Heart Health
Study dataset, composed of 5000 healthy and pathological subjects. The dataset
was split into three subsets: 2500 for training, $1250$ for validating, and
1250 for testing. The overall accuracy, specificity, sensibility, and Cohen's
Kappa coefficient were 90.0%, 94.9%, 78.1%, and 0.73.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 22:58:33 GMT""}]","2021-02-08"
"2102.04235","Fernando Almeida Dr.","Fernando Almeida and Jos\'e Monteiro","The Challenges of Assessing and Evaluating the Students at Distance","8 pages, 10 references","Journal of Online Higher Education, 2021",,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The COVID-19 pandemic has caused a strong effect on higher education
institutions with the closure of classroom teaching activities. In this
unprecedented crisis, of global proportion, educators and families had to deal
with unpredictability and learn new ways of teaching. This short essay aims to
explore the challenges posed to Portuguese higher education institutions and to
analyze the challenges posed to evaluation models. To this end, the relevance
of formative and summative assessment models in distance education is explored
and the perception of teachers and students about the practices adopted in
remote assessment is discussed. On the teachers' side, there is a high concern
about adopting fraud-free models, and an excessive focus on the summative
assessment component that in the distance learning model has less preponderance
when compared to the gradual monitoring and assessment processes of the
students, while on the students' side, problems arise regarding equipment to
follow the teaching sessions and concerns about their privacy, particularly
when intrusive IT solutions request the access to their cameras, audio, and
desktop.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 13:13:45 GMT""}]","2021-02-09"
"2102.04338","Xiuyi Yang","Xiuyi Yang","The Landscape of Multi-Layer Linear Neural Network From the Perspective
  of Algebraic Geometry",,,,,"math.AG cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The clear understanding of the non-convex landscape of neural network is a
complex incomplete problem. This paper studies the landscape of linear
(residual) network, the simplified version of the nonlinear network. By
treating the gradient equations as polynomial equations, we use algebraic
geometry tools to solve it over the complex number field, the attained solution
can be decomposed into different irreducible complex geometry objects. Then
three hypotheses are proposed, involving how to calculate the loss on each
irreducible geometry object, the losses of critical points have a certain range
and the relationship between the dimension of each irreducible geometry object
and strict saddle condition. Finally, numerical algebraic geometry is applied
to verify the rationality of these three hypotheses which further clarify the
landscape of linear network and the role of residual connection.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 04:50:45 GMT""}]","2021-02-09"
"2102.04960","Huan Yin","Huan Yin, Xuecheng Xu, Yue Wang and Rong Xiong","Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning","Published by Frontiers in Robotics and AI. The published version is
  available at
  https://www.frontiersin.org/articles/10.3389/frobt.2021.661199/full . The
  source code is available at
  https://github.com/ZJUYH/radar-to-lidar-place-recognition",,"10.3389/frobt.2021.661199",,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Place recognition is critical for both offline mapping and online
localization. However, current single-sensor based place recognition still
remains challenging in adverse conditions. In this paper, a heterogeneous
measurements based framework is proposed for long-term place recognition, which
retrieves the query radar scans from the existing lidar maps. To achieve this,
a deep neural network is built with joint training in the learning stage, and
then in the testing stage, shared embeddings of radar and lidar are extracted
for heterogeneous place recognition. To validate the effectiveness of the
proposed method, we conduct tests and generalization experiments on the
multi-session public datasets compared to other competitive methods. The
experimental results indicate that our model is able to perform multiple place
recognitions: lidar-to-lidar, radar-to-radar and radar-to-lidar, while the
learned model is trained only once. We also release the source code publicly:
https://github.com/ZJUYH/radar-to-lidar-place-recognition.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:34:58 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 09:31:08 GMT""}]","2021-06-21"
"2102.04969","Xiao-Wei Chen","Xiaowei Chen (Sun Yat-sen University)","Semantic Borrowing for Generalized Zero-Shot Learning",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized zero-shot learning (GZSL) is one of the most realistic but
challenging problems due to the partiality of the classifier to supervised
classes, especially under the class-inductive instance-inductive (CIII)
training setting, where testing data are not available. Instance-borrowing
methods and synthesizing methods solve it to some extent with the help of
testing semantics, but therefore neither can be used under CIII. Besides, the
latter require the training process of a classifier after generating examples.
In contrast, a novel non-transductive regularization under CIII called Semantic
Borrowing (SB) for improving GZSL methods with compatibility metric learning is
proposed in this paper, which not only can be used for training linear models,
but also nonlinear ones such as artificial neural networks. This regularization
item in the loss function borrows similar semantics in the training set, so
that the classifier can model the relationship between the semantics of
zero-shot and supervised classes more accurately during training. In practice,
the information of semantics of unknown classes would not be available for
training while this approach does NOT need it. Extensive experiments on GZSL
benchmark datasets show that SB can reduce the partiality of the classifier to
supervised classes and improve the performance of generalized zero-shot
classification, surpassing inductive GZSL state of the arts.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 12:14:28 GMT""},{""version"":""v2"",""created"":""Sun, 22 Aug 2021 03:55:22 GMT""}]","2021-08-24"
"2102.09346","Iuliana Marin","Iuliana Marin, Andrei Vasilateanu, Bujor Pavaloiu, Nicolae Goga","User Requirements and Analysis of Preeclampsia Detection done through a
  Smart Bracelet",,"12th International Technology, Education and Development
  Conference 2018","10.21125/inted.2018.2080",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical students along with the medical staff have to monitor the state of
the patients by using modern devices which have to offer precise results in a
short amount of time, so that the intervention to be done as soon as possible.
E-learning systems for blood pressure monitoring are used and new methods of
patient observation, evaluation and treatment are applied compared to classical
intervention. Based on this, medical students can improve their knowledge for
the practical training.
  In the medical activities specialized devices occupy an important place. A
device that can monitor the blood pressure is a smart bracelet that
incorporates a pressure sensor along the wrist for continuous recording of
blood pressure values. This enables the prediction of the emergency disorders
using a decision support system. It facilitates the learning of new
intervention approaches and boosts the responsiveness among learners. According
to the World Health Organization, hypertensive disorders affect about 10% of
pregnant women worldwide and are an important cause of disability and long-term
death among mothers and children. This paper is based on a survey completed by
persons of different ages and having various specialization domains regarding
the use of smart bracelets for detecting preeclampsia. The aim is to decide
upon its popularity among people and to determine the user requirements. The
pregnant women will be constantly monitored, doctors can update the diagnosis
of the patient. The medical students can learn from the critical situations and
benefit from these cases while learning. The results of the survey showed that
most of the interviewed persons consider the existence of such a device to be
very useful, mostly the female individuals would feel more comfortable to have
their blood pressure monitored during pregnancy.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 17:23:36 GMT""}]","2021-02-19"
"2102.09948","Soichiro Yamauchi","Naoki Egami, Soichiro Yamauchi","Using Multiple Pre-treatment Periods to Improve
  Difference-in-Differences and Staggered Adoption Design",,,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  While a difference-in-differences (DID) design was originally developed with
one pre- and one post-treatment period, data from additional pre-treatment
periods are often available. How can researchers improve the DID design with
such multiple pre-treatment periods under what conditions? We first use
potential outcomes to clarify three benefits of multiple pre-treatment periods:
(1) assessing the parallel trends assumption, (2) improving estimation
accuracy, and (3) allowing for a more flexible parallel trends assumption. We
then propose a new estimator, double DID, which combines all the benefits
through the generalized method of moments and contains the two-way fixed
effects regression as a special case. We show that the double DID requires a
weaker assumption about outcome trends and is more efficient than existing DID
estimators. We also generalize the double DID to the staggered adoption design
where different units can receive the treatment in different time periods. We
illustrate the proposed method with two empirical applications, covering both
the basic DID and staggered adoption designs. We offer an open-source R package
that implements the proposed methodologies.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:28:40 GMT""},{""version"":""v2"",""created"":""Fri, 11 Feb 2022 18:27:34 GMT""}]","2022-02-14"
"2102.09996","Galina Sinkevich","Galina Sinkevich","The history of the Russian study of Chinese astronomy","7 pages",,,,"physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  A short history of Russian researches in Chinese astronomy in 19-20 centuries
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 15:25:13 GMT""}]","2021-02-22"
"2103.03180","Pramod Mane","Pramod C. Mane, Kapil Ahuja, Pradeep Singh","A Critical Note on Social Cloud","4 pages",,,,"cs.DC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The idea of a social cloud has emerged as a resource sharing paradigm in a
social network context. Undoubtedly, state-of-the-art social cloud systems
demonstrate the potential of the social cloud acting as complementary to other
computing paradigms such as the cloud, grid, peer-to-peer and volunteer
computing. However, in this note, we have done a critical survey of the social
cloud literature and come to the conclusion that these initial efforts fail to
offer a general framework of the social cloud, also, to show the uniqueness of
the social cloud. This short note reveals that there are significant
differences regarding the concept of social cloud, resource definition,
resource sharing and allocation mechanism, and its application and
stakeholders. This study is an attempt to express a need for a general
framework of the social cloud, which can incorporate various views and resource
sharing setups discussed in the literature.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 19:12:08 GMT""}]","2021-03-05"
"2103.03358","Mark Bason Dr","Mark G. Bason, Thomas Coussens, Matthew Withers, Christopher Abel,
  Gary Kendall, Peter Kruger","Non-invasive Current Density Imaging of Lithium-Ion Batteries","7 pages, 4 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The rapid pace of replacing fossil fuel propelled transport by electric
vehicles is critically dependent on high-performing, high energy density and
efficient batteries. Optimal and safe use of existing battery cells and
development of much-needed novel battery chemistries and geometries require a
large range of diagnostic and monitoring tools. While structural and chemical
information is readily extracted through a host of imaging techniques,
non-invasive functional detection of interior battery processes remains
limited. Here we introduce sensitive magnetometry performed outside the battery
that reveals a battery cell's internal current distribution. As a key
application, we use an array of sensors to image the magnetic field present
under cycling of a pouch cell between charge states. We find good agreement
between measured and modelled fields with sufficient resolution to detect
percent-level deviations around areas of high current density. This opens the
path towards rapid and reliable assessment throughout the battery life cycle,
from battery development and manufacturing quality assurance to operational
safety and optimised use.
","[{""version"":""v1"",""created"":""Fri, 29 Jan 2021 18:16:46 GMT""}]","2021-03-08"
"2103.10932","Kei Ishida","Kei Ishida, Masato Kiyama, Ali Ercan, Motoki Amagasaki, Tongbi Tu","Multi-Time-Scale Input Approaches for Hourly-Scale Rainfall-Runoff
  Modeling based on Recurrent Neural Networks","11pages, 5 figures",,"10.2166/hydro.2021.095",,"physics.ao-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes two straightforward yet effective approaches to reduce
the required computational time of the training process for time-series
modeling through a recurrent neural network (RNN) using multi-time-scale
time-series data as input. One approach provides coarse and fine temporal
resolutions of the input time-series to RNN in parallel. The other concatenates
the coarse and fine temporal resolutions of the input time-series data over
time before considering them as the input to RNN. In both approaches, first,
finer temporal resolution data are utilized to learn the fine temporal scale
behavior of the target data. Next, coarser temporal resolution data are
expected to capture long-duration dependencies between the input and target
variables. The proposed approaches were implemented for hourly rainfall-runoff
modeling at a snow-dominated watershed by employing a long and short-term
memory (LSTM) network, which is a newer type of RNN. Subsequently, the daily
and hourly meteorological data were utilized as the input, and hourly flow
discharge was considered as the target data. The results confirm that both of
the proposed approaches can reduce the computational time for the training of
RNN significantly (up to 32.4 times). Furthermore, one of the proposed
approaches improves the estimation accuracy.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 07:51:55 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 18:45:14 GMT""}]","2021-11-11"
"2106.05847","Adam Gosztolai","Adam Gosztolai and Alexis Arnaudon","Unfolding the multiscale structure of networks with dynamical
  Ollivier-Ricci curvature",,,"10.1038/s41467-021-24884-1",,"physics.soc-ph cs.DM physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Describing networks geometrically through low-dimensional latent metric
spaces has helped design efficient learning algorithms, unveil network
symmetries and study dynamical network processes. However, latent space
embeddings are limited to specific classes of networks because incompatible
metric spaces generally result in information loss. Here, we study arbitrary
networks geometrically by defining a dynamic edge curvature measuring the
similarity between pairs of dynamical network processes seeded at nearby nodes.
We show that the evolution of the curvature distribution exhibits gaps at
characteristic timescales indicating bottleneck-edges that limit information
spreading. Importantly, curvature gaps are robust to large fluctuations in node
degrees, encoding communities until the phase transition of detectability,
where spectral and node-clustering methods fail. Using this insight, we derive
geometric modularity to find multiscale communities based on deviations from
constant network curvature in generative and real-world networks, significantly
outperforming most previous methods. Our work suggests using network geometry
for studying and controlling the structure of and information spreading on
networks.
","[{""version"":""v1"",""created"":""Sat, 30 Jan 2021 10:03:38 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 12:11:02 GMT""},{""version"":""v3"",""created"":""Wed, 14 Jul 2021 11:45:12 GMT""}]","2023-04-10"
